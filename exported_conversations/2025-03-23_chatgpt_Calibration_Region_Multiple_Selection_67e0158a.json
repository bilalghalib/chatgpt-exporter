{
  "id": "67e0158a-588c-8012-9279-530e2a9b69cf",
  "source": "chatgpt",
  "title": "Calibration Region Multiple Selection",
  "created_at": "2025-03-23T15:07:06.526408",
  "updated_at": "2025-03-23T17:46:31.654365",
  "summary": null,
  "message_count": 26,
  "messages": [
    {
      "id": "8ce8a5e1-9a40-4b09-981b-ed80ad12dd80",
      "role": "user",
      "content": "",
      "created_at": null,
      "sequence_order": 0,
      "parent_id": "8f38619b-4309-4980-a14a-bb8b31ec7022",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "30cdbf9e-5d59-4315-b588-a60f54ed1790",
      "role": "user",
      "content": "{'content_type': 'image_asset_pointer', 'asset_pointer': 'file-service://file-EPFXkNmMd9bgAud2xVfwGA', 'size_bytes': 5096949, 'width': 2048, 'height': 1358, 'fovea': None, 'metadata': {'dalle': None, 'gizmo': None, 'generation': None, 'container_pixel_height': None, 'container_pixel_width': None, 'emu_omit_glimpse_image': None, 'emu_patches_override': None, 'lpe_keep_patch_ijhw': None, 'sanitized': True, 'asset_pointer_link': None, 'watermarked_asset_pointer': None}}\nreview this code and tell me why i can't select other regions, i can make the regions and for some reason i can't calibrate it - review and return the fixed code in chunks then the file in full \n[[[<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Thikr Counter - Visual Pattern Recognition</title>\n  <script src=\"https://unpkg.com/wavesurfer.js@6.6.3\"></script>\n  <script src=\"https://unpkg.com/wavesurfer.js@6.6.3/dist/plugin/wavesurfer.regions.min.js\"></script>\n  <script src=\"https://unpkg.com/meyda@5.6.1/dist/web/meyda.min.js\"></script>\n  <style>\n    body {\n      font-family: system-ui, sans-serif;\n      max-width: 1000px;\n      margin: 0 auto;\n      padding: 20px;\n      background-color: #f5f5f5;\n    }\n    \n    .panel {\n      background: white;\n      border-radius: 8px;\n      padding: 20px;\n      margin-bottom: 20px;\n      box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n    }\n    \n    button {\n      background-color: #4c6ef5;\n      color: white;\n      border: none;\n      padding: 8px 16px;\n      margin: 5px;\n      border-radius: 4px;\n      cursor: pointer;\n      font-weight: 500;\n    }\n    \n    button:disabled {\n      background-color: #a5b4fc;\n      cursor: not-allowed;\n    }\n    \n    .waveform {\n      border: 1px solid #e9ecef;\n      border-radius: 4px;\n      overflow: hidden;\n      margin: 10px 0;\n      height: 128px; /* Explicitly set height */\n      width: 100%;\n      background-color: #f8f9fa;\n      position: relative;\n    }\n    \n    #counter {\n      font-size: 64px;\n      font-weight: bold;\n      text-align: center;\n      color: #4c6ef5;\n      padding: 20px;\n    }\n    \n    #confidenceDisplay {\n      height: 100px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      margin: 10px 0;\n      position: relative;\n    }\n    \n    .progress-bar {\n      position: absolute;\n      bottom: 0;\n      left: 0;\n      width: 100%;\n      background-color: #4c6ef5;\n      transition: height 0.1s;\n      height: 0%;\n    }\n    \n    .threshold-line {\n      position: absolute;\n      width: 100%;\n      height: 2px;\n      background-color: #fa5252;\n      z-index: 2;\n      bottom: 75%; /* Default position */\n    }\n    \n    #tokenContainer {\n      margin-top: 20px;\n    }\n    \n    #tokenSequence {\n      display: flex;\n      flex-wrap: wrap;\n      padding: 20px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      min-height: 80px;\n      margin: 10px 0;\n      position: relative;\n    }\n    \n    .token {\n      display: inline-flex;\n      align-items: center;\n      justify-content: center;\n      width: 50px;\n      height: 50px;\n      margin: 5px;\n      border-radius: 4px;\n      font-weight: bold;\n      font-size: 20px;\n      transition: all 0.3s ease;\n      position: relative;\n      box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n    }\n    \n    .token-label {\n      position: absolute;\n      top: -15px;\n      font-size: 10px;\n      color: #495057;\n    }\n    \n    #legend {\n      display: flex;\n      flex-wrap: wrap;\n      gap: 10px;\n      padding: 10px;\n      margin-top: 10px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .legend-item {\n      display: flex;\n      align-items: center;\n      margin-right: 15px;\n    }\n    \n    .legend-color {\n      width: 20px;\n      height: 20px;\n      border-radius: 3px;\n      margin-right: 5px;\n    }\n    \n    #liveActivity {\n      margin-top: 10px;\n      padding: 10px;\n      background-color: #e9ecef;\n      border-radius: 4px;\n      font-family: monospace;\n      font-size: 12px;\n      min-height: 60px;\n      overflow-y: auto;\n    }\n    \n    #diagnostics {\n      height: 200px;\n      overflow-y: auto;\n      font-family: monospace;\n      font-size: 12px;\n      background-color: #212529;\n      color: #f8f9fa;\n      padding: 10px;\n      border-radius: 4px;\n      white-space: pre-wrap;\n    }\n    \n    #calibrationInfo {\n      margin-top: 10px;\n      padding: 10px;\n      background-color: #e9ecef;\n      border-radius: 4px;\n      font-size: 14px;\n    }\n    \n    .detection-flash {\n      position: absolute;\n      width: 100%;\n      height: 100%;\n      background-color: rgba(76, 175, 80, 0.3);\n      top: 0;\n      left: 0;\n      z-index: 10;\n      animation: flash-animation 1.5s forwards;\n      pointer-events: none;\n    }\n    \n    .confidence-marker {\n      position: absolute;\n      height: 10px;\n      width: 10px;\n      border-radius: 50%;\n      background-color: green;\n      transform: translate(-50%, -50%);\n      z-index: 3;\n    }\n    \n    @keyframes flash-animation {\n      0% { opacity: 0.8; }\n      100% { opacity: 0; }\n    }\n    \n    @keyframes wave-animation {\n      0% { transform: scale(1); opacity: 0.7; }\n      50% { transform: scale(1.4); opacity: 1; }\n      100% { transform: scale(1); opacity: 0.7; }\n    }\n    \n    .wave-effect {\n      animation: wave-animation 0.5s ease;\n    }\n    \n    .control-group {\n      display: flex;\n      flex-wrap: wrap;\n      gap: 5px;\n      margin-bottom: 10px;\n    }\n    \n    h2 {\n      margin-top: 0;\n      color: #343a40;\n    }\n    \n    label {\n      font-weight: bold;\n      display: block;\n      margin-bottom: 5px;\n    }\n    \n    .instruction {\n      font-style: italic;\n      color: #6c757d;\n      margin-bottom: 10px;\n    }\n    \n    .region-count {\n      display: inline-block;\n      background-color: #4c6ef5;\n      color: white;\n      border-radius: 50%;\n      width: 24px;\n      height: 24px;\n      text-align: center;\n      line-height: 24px;\n      font-size: 14px;\n      margin-left: 10px;\n    }\n    \n    /* Enhanced Calibration Styles */\n    .calibration-panel {\n      margin-top: 20px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      padding: 15px;\n    }\n    \n    .region-list {\n      max-height: 300px;\n      overflow-y: auto;\n      margin: 10px 0;\n    }\n    \n    .region-item {\n      display: flex;\n      justify-content: space-between;\n      align-items: center;\n      padding: 8px 10px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      margin-bottom: 8px;\n      cursor: pointer;\n      transition: background-color 0.2s;\n    }\n    \n    .region-item:hover {\n      background-color: #e9ecef;\n    }\n    \n    .region-item.selected {\n      background-color: #cfe8ff;\n      border-color: #4c6ef5;\n    }\n    \n    .region-item .region-info {\n      flex-grow: 1;\n    }\n    \n    .region-item .region-actions {\n      display: flex;\n      gap: 5px;\n    }\n    \n    .region-item .similarity-score {\n      display: inline-block;\n      margin-left: 10px;\n      padding: 2px 6px;\n      background-color: #4c6ef5;\n      color: white;\n      border-radius: 10px;\n      font-size: 12px;\n    }\n    \n    /* Feature comparison visualization */\n    .feature-comparison {\n      margin-top: 15px;\n      padding: 10px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .comparison-chart {\n      height: 200px;\n      position: relative;\n      margin-top: 10px;\n      border-bottom: 1px solid #dee2e6;\n      border-left: 1px solid #dee2e6;\n    }\n    \n    .feature-series {\n      position: absolute;\n      bottom: 0;\n      left: 0;\n      display: flex;\n      align-items: flex-end;\n      height: 100%;\n      width: 100%;\n    }\n    \n    .feature-point {\n      flex: 1;\n      margin: 0 1px;\n      position: relative;\n    }\n    \n    .feature-bar {\n      width: 100%;\n      background-color: #4c6ef5;\n      position: absolute;\n      bottom: 0;\n    }\n    \n    .template-bar {\n      background-color: rgba(255, 86, 0, 0.6);\n    }\n    \n    .calibration-bar {\n      background-color: rgba(0, 200, 83, 0.6);\n    }\n    \n    .selected-region-bar {\n      background-color: rgba(76, 110, 245, 0.8);\n    }\n    \n    .feature-type-selector {\n      display: flex;\n      gap: 10px;\n      margin-bottom: 10px;\n    }\n    \n    .feature-type-selector label {\n      margin-bottom: 0;\n      font-weight: normal;\n    }\n    \n    .calibration-summary {\n      display: flex;\n      flex-wrap: wrap;\n      gap: 10px;\n      margin-top: 15px;\n    }\n    \n    .summary-card {\n      flex: 1;\n      min-width: 120px;\n      padding: 10px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      text-align: center;\n    }\n    \n    .summary-value {\n      font-size: 24px;\n      font-weight: bold;\n      margin: 5px 0;\n    }\n    \n    .summary-label {\n      font-size: 12px;\n      color: #6c757d;\n    }\n    \n    /* Threshold adjustment sliders */\n    .threshold-adjustment {\n      margin-top: 15px;\n      padding: 15px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .slider-container {\n      display: flex;\n      align-items: center;\n      margin-bottom: 10px;\n    }\n    \n    .slider-container label {\n      width: 150px;\n      margin-bottom: 0;\n    }\n    \n    .slider-container input[type=\"range\"] {\n      flex-grow: 1;\n      margin-right: 10px;\n    }\n    \n    .slider-value {\n      width: 40px;\n      text-align: right;\n    }\n    \n    /* Enhanced diagnostics styles */\n    .token-debug-info {\n      position: absolute;\n      bottom: -25px;\n      font-size: 9px;\n      color: #6c757d;\n      left: 0;\n      right: 0;\n      text-align: center;\n      white-space: nowrap;\n      overflow: hidden;\n      text-overflow: ellipsis;\n    }\n    \n    .diagnostic-controls {\n      margin-bottom: 10px;\n      display: flex;\n      gap: 10px;\n      align-items: center;\n    }\n    \n    .copy-diagnostics {\n      background-color: #212529;\n      color: white;\n      border: 1px solid #495057;\n      padding: 5px 10px;\n      border-radius: 4px;\n      cursor: pointer;\n      font-size: 12px;\n    }\n    \n    .diagnostics-options label {\n      display: inline-flex;\n      align-items: center;\n      margin-right: 10px;\n      font-weight: normal;\n      font-size: 12px;\n    }\n    \n    .diagnostic-section {\n      margin-top: 10px;\n      padding: 10px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      font-family: monospace;\n      font-size: 12px;\n    }\n    \n    #detectionData {\n      max-height: 150px;\n      overflow-y: auto;\n    }\n    \n    /* Visual debugging elements */\n    .visual-debug {\n      position: absolute;\n      bottom: -30px;\n      left: 0;\n      right: 0;\n      display: flex;\n      height: 20px;\n      justify-content: space-between;\n    }\n    \n    .debug-marker {\n      width: 2px;\n      position: absolute;\n      bottom: 0;\n      background-color: red;\n    }\n    \n    #debugOutput {\n      font-family: monospace;\n      white-space: pre;\n      font-size: 12px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      padding: 10px;\n      margin-top: 10px;\n      overflow-x: auto;\n    }\n    \n    .debug-help {\n      font-size: 12px;\n      color: #6c757d;\n      margin-top: 5px;\n      margin-bottom: 10px;\n      font-style: italic;\n    }\n  </style>\n</head>\n<body>\n  <h1>Thikr Counter - Visual Pattern Recognition</h1>\n  \n  <div class=\"panel\">\n    <h2>1. Record & Extract Template</h2>\n    <div class=\"instruction\">Record your thikr, then use your mouse to drag-select the region containing a single complete thikr recitation.</div>\n    <div class=\"control-group\">\n      <button id=\"recordBtn\">Record Audio</button>\n      <button id=\"stopBtn\" disabled>Stop Recording</button>\n      <button id=\"playBtn\" disabled>Play Audio</button>\n      <button id=\"resetBtn\">Reset</button>\n    </div>\n    \n    <div id=\"counter\">0</div>\n    \n    <div id=\"waveformContainer\">\n      <label>Waveform Display</label>\n      <div id=\"waveform\" class=\"waveform\"></div>\n      <div class=\"control-group\">\n        <button id=\"createTemplateBtn\" disabled>Extract Template Tokens</button>\n        <div id=\"calibrationControls\" style=\"display: none;\">\n          <button id=\"selectCalibrationBtn\">Add Calibration Region</button>\n          <span id=\"regionCount\" class=\"region-count\">0</span>\n          <button id=\"calibrateBtn\" disabled>Run Calibration</button>\n        </div>\n      </div>\n    </div>\n    \n    <div id=\"calibrationInfo\">\n      Record audio, then select a template region by dragging on the waveform.\n    </div>\n    \n    <!-- New Calibration Management UI -->\n    <div id=\"calibrationPanel\" class=\"calibration-panel\" style=\"display: none;\">\n      <h3>Calibration Regions</h3>\n      <p class=\"instruction\">Manage your calibration regions. Click on a region to select and view its features.</p>\n      \n      <!-- Region List -->\n      <div id=\"regionList\" class=\"region-list\">\n        <!-- Region items will be added here dynamically -->\n      </div>\n      \n      <!-- Feature Comparison Visualization -->\n      <div class=\"feature-comparison\">\n        <div class=\"feature-type-selector\">\n          <label><input type=\"radio\" name=\"featureType\" value=\"energy\" checked> Energy (RMS)</label>\n          <label><input type=\"radio\" name=\"featureType\" value=\"centroid\"> Spectral Centroid</label>\n          <label><input type=\"radio\" name=\"featureType\" value=\"zcr\"> Zero Crossing Rate</label>\n          <label><input type=\"radio\" name=\"featureType\" value=\"tokens\"> Token Types</label>\n        </div>\n        \n        <div id=\"comparisonChart\" class=\"comparison-chart\">\n          <!-- Feature visualization will be generated here -->\n        </div>\n      </div>\n      \n      <!-- Calibration Summary -->\n      <div class=\"calibration-summary\">\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"avgSimilarity\">-</div>\n          <div class=\"summary-label\">Average Similarity</div>\n        </div>\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"minSimilarity\">-</div>\n          <div class=\"summary-label\">Min Similarity</div>\n        </div>\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"maxSimilarity\">-</div>\n          <div class=\"summary-label\">Max Similarity</div>\n        </div>\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"stdDevSimilarity\">-</div>\n          <div class=\"summary-label\">Std Deviation</div>\n        </div>\n      </div>\n      \n      <!-- Threshold Adjustment -->\n      <div class=\"threshold-adjustment\">\n        <h4>Threshold Adjustments</h4>\n        <div class=\"slider-container\">\n          <label for=\"matchThresholdSlider\">Match Threshold:</label>\n          <input type=\"range\" id=\"matchThresholdSlider\" min=\"0\" max=\"100\" value=\"75\">\n          <span class=\"slider-value\" id=\"matchThresholdValue\">75%</span>\n        </div>\n        <div class=\"slider-container\">\n          <label for=\"minConfidenceSlider\">Min Confidence:</label>\n          <input type=\"range\" id=\"minConfidenceSlider\" min=\"0\" max=\"100\" value=\"30\">\n          <span class=\"slider-value\" id=\"minConfidenceValue\">30%</span>\n        </div>\n      </div>\n    </div>\n  </div>\n  \n  <div class=\"panel\" id=\"tokenContainer\" style=\"display: none;\">\n    <h2>2. Token Visualization</h2>\n    <div class=\"instruction\">These tokens represent the distinctive audio patterns in your thikr. During detection, they will grow and change color as matches are found.</div>\n    \n    <div id=\"legend\">\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #4dabf7;\"></div>\n        <span>A: Energy Rise (vowel onset)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #f783ac;\"></div>\n        <span>B: Energy Fall (syllable end)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #8ce99a;\"></div>\n        <span>C: High Frequency (consonants)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #ffd43b;\"></div>\n        <span>D: Low Frequency (low vowels)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #a5d8ff;\"></div>\n        <span>E: Transition</span>\n      </div>\n    </div>\n    \n    <div id=\"tokenSequence\"></div>\n  </div>\n  \n  <div class=\"panel\">\n    <h2>3. Live Pattern Detection</h2>\n    <div class=\"instruction\">Start analysis and recite your thikr. The system will detect patterns and show confidence levels in real-time.</div>\n    \n    <div class=\"control-group\">\n      <button id=\"startAnalysisBtn\" disabled>Start Analysis</button>\n      <button id=\"stopAnalysisBtn\" disabled>Stop Analysis</button>\n    </div>\n    \n    <label>Pattern Match Confidence</label>\n    <div id=\"confidenceDisplay\">\n      <div class=\"threshold-line\"></div>\n      <div class=\"progress-bar\"></div>\n    </div>\n    \n    <label>Live Activity</label>\n    <div id=\"liveActivity\">Waiting to start analysis...</div>\n  </div>\n  \n  <!-- Enhanced Diagnostics Panel -->\n  <div class=\"panel\">\n    <h2>Diagnostics</h2>\n    <div class=\"debug-help\">\n      This panel provides detailed information for debugging. All data can be copied and pasted to share with developers.\n    </div>\n    \n    <div class=\"diagnostic-controls\">\n      <button class=\"copy-diagnostics\" id=\"copyDiagnosticsBtn\">Copy All Diagnostics</button>\n      <div class=\"diagnostics-options\">\n        <label><input type=\"checkbox\" id=\"verboseLogging\" checked> Verbose Logging</label>\n        <label><input type=\"checkbox\" id=\"showFeatureValues\" checked> Show Feature Values</label>\n      </div>\n    </div>\n    \n    <div id=\"diagnostics\"></div>\n    \n    <!-- Pattern Detection Data -->\n    <h3>Pattern Detection Data</h3>\n    <div class=\"debug-help\">\n      The most recent pattern detection events with detailed metrics. This data is useful for troubleshooting false positives/negatives.\n    </div>\n    <div id=\"detectionData\" class=\"diagnostic-section\"></div>\n    \n    <!-- Debug Output for Copy/Paste -->\n    <h3>Recognition Debug Data</h3>\n    <div class=\"debug-help\">\n      This formatted data can be copied and shared to help debug the recognition process.\n    </div>\n    <pre id=\"debugOutput\"></pre>\n  </div>\n\n  <script>\n    // Global variables\n    let audioContext;\n    let wavesurfer;\n    let recorder;\n    let recordedChunks = [];\n    let isRecording = false;\n    let meydaAnalyzer = null;\n    let calibrationMode = false;\n    \n    // Audio processing configuration\n    const frameSize = 2048;\n    const hopSize = 1024;\n    \n    // Token types and colors\n    const tokenTypes = ['A', 'B', 'C', 'D', 'E']; // Different audio characteristics\n    const tokenColors = {\n      'A': '#4dabf7', // Blue - Energy rise\n      'B': '#f783ac', // Pink - Energy fall\n      'C': '#8ce99a', // Green - Spectral high\n      'D': '#ffd43b', // Yellow - Spectral low\n      'E': '#a5d8ff'  // Light blue - Background\n    };\n    \n    // Token type descriptions\n    const tokenDescriptions = {\n      'A': 'Energy Rise (vowel onset)',\n      'B': 'Energy Fall (syllable end)',\n      'C': 'High Frequency (consonants)',\n      'D': 'Low Frequency (low vowels)',\n      'E': 'Transition'\n    };\n    \n    // Pattern recognition parameters (will be auto-calibrated)\n    let matchThreshold = 0.75;\n    let minConfidence = 0.3;\n    \n    // Template data\n    let templateRegion = null;\n    let calibrationRegions = [];\n    let templateTokens = [];\n    let templateBuffer = null;\n    \n    // Detection state\n    let detectionCount = 0;\n    let isAnalyzing = false;\n    let currentTokens = [];\n    let liveTokenBuffer = [];\n    let confidenceHistory = [];\n    let lastDetectionTime = 0;\n    let lastTokenTime = 0;\n    let activeTokenTypes = new Set();\n    \n    // Enhanced calibration variables\n    let calibrationResults = [];\n    let selectedRegionId = null;\n    let regionFeatures = {};\n    let selectedFeatureType = 'energy';\n    \n    // Diagnostic logging\n    let detectionEvents = [];\n    let verboseLogging = true;\n    let showFeatureValues = true;\n    \n    // DOM elements\n    const recordBtn = document.getElementById('recordBtn');\n    const stopBtn = document.getElementById('stopBtn');\n    const playBtn = document.getElementById('playBtn');\n    const resetBtn = document.getElementById('resetBtn');\n    const createTemplateBtn = document.getElementById('createTemplateBtn');\n    const selectCalibrationBtn = document.getElementById('selectCalibrationBtn');\n    const calibrateBtn = document.getElementById('calibrateBtn');\n    const startAnalysisBtn = document.getElementById('startAnalysisBtn');\n    const stopAnalysisBtn = document.getElementById('stopAnalysisBtn');\n    const progressBar = document.querySelector('.progress-bar');\n    const thresholdLine = document.querySelector('.threshold-line');\n    const diagnosticsLog = document.getElementById('diagnostics');\n    const calibrationInfo = document.getElementById('calibrationInfo');\n    const counterDisplay = document.getElementById('counter');\n    const tokenSequence = document.getElementById('tokenSequence');\n    const liveActivity = document.getElementById('liveActivity');\n    const regionCount = document.getElementById('regionCount');\n    const calibrationControls = document.getElementById('calibrationControls');\n    const tokenContainer = document.getElementById('tokenContainer');\n    const detectionData = document.getElementById('detectionData');\n    const debugOutput = document.getElementById('debugOutput');\n    const copyDiagnosticsBtn = document.getElementById('copyDiagnosticsBtn');\n    const verboseLoggingCheckbox = document.getElementById('verboseLogging');\n    const showFeatureValuesCheckbox = document.getElementById('showFeatureValues');\n    \n    // Initialize the app\n    function init() {\n      initWavesurfer();\n      initAudioContext();\n      \n      // Setup event listeners\n      recordBtn.addEventListener('click', startRecording);\n      stopBtn.addEventListener('click', stopRecording);\n      playBtn.addEventListener('click', () => wavesurfer.playPause());\n      resetBtn.addEventListener('click', resetApp);\n      createTemplateBtn.addEventListener('click', createTemplate);\n      selectCalibrationBtn.addEventListener('click', enhancedSelectCalibrationRegion);\n      calibrateBtn.addEventListener('click', enhancedCalibrate);\n      startAnalysisBtn.addEventListener('click', startAnalysis);\n      stopAnalysisBtn.addEventListener('click', stopAnalysis);\n      \n      // Set threshold line position\n      updateThresholdLine();\n      \n      // Setup diagnostic controls\n      copyDiagnosticsBtn.addEventListener('click', copyAllDiagnostics);\n      verboseLoggingCheckbox.addEventListener('change', (e) => {\n        verboseLogging = e.target.checked;\n      });\n      showFeatureValuesCheckbox.addEventListener('change', (e) => {\n        showFeatureValues = e.target.checked;\n      });\n      \n      // Initialize enhanced calibration\n      initEnhancedCalibration();\n      \n      log('App initialized. Click \"Record Audio\" to begin.');\n    }\n    \n    // Initialize WaveSurfer\n    function initWavesurfer() {\n      wavesurfer = WaveSurfer.create({\n        container: '#waveform',\n        waveColor: '#4c6ef5',\n        progressColor: '#364fc7',\n        cursorColor: '#fa5252',\n        height: 128,\n        normalize: true,\n        plugins: [\n          WaveSurfer.regions.create({\n            dragSelection: true,\n            color: 'rgba(255, 86, 0, 0.2)',\n          })\n        ]\n      });\n      \n      wavesurfer.on('ready', function() {\n        playBtn.disabled = false;\n        createTemplateBtn.disabled = false;\n        log('Waveform ready - audio loaded successfully');\n      });\n      \n      wavesurfer.on('error', function(err) {\n        log('WaveSurfer error: ' + err);\n      });\n      \n      // Handle region creation\n      wavesurfer.on('region-created', function(region) {\n        // Handle new region depending on the current mode\n        if (calibrationMode) {\n          // Calibration region\n          region.id = 'calibration-' + Date.now();\n          region.color = 'rgba(0, 200, 83, 0.3)'; // Green\n          region.update();\n          \n          // Store metadata with the region\n          region.data = {\n            tokens: [],\n            similarity: null,\n            features: null\n          };\n          \n          calibrationRegions.push(region);\n          updateRegionCount();\n          \n          log(`Calibration region created: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n          \n          // Add immediately to the region list UI\n          addRegionToList(region);\n          \n          // Enable calibration if we have at least one region\n          if (calibrationRegions.length > 0) {\n            calibrateBtn.disabled = false;\n          }\n          \n          // Turn off calibration mode after adding one region\n          calibrationMode = false;\n          \n          // Show calibration panel if first region is added\n          document.getElementById('calibrationPanel').style.display = 'block';\n          \n        } else if (!templateRegion) {\n          // First region is template\n          region.id = 'template-' + Date.now();\n          log(`Template region created: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n        }\n      });\n      \n      // Handle region updates\n      wavesurfer.on('region-update-end', function(region) {\n        log(`Region updated: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n      });\n    }\n    \n    // Initialize Audio Context\n    function initAudioContext() {\n      audioContext = new (window.AudioContext || window.webkitAudioContext)();\n    }\n    \n    // Initialize enhanced calibration\n    function initEnhancedCalibration() {\n      // Add event listeners for the feature type selector\n      document.querySelectorAll('input[name=\"featureType\"]').forEach(radio => {\n        radio.addEventListener('change', event => {\n          selectedFeatureType = event.target.value;\n          updateFeatureComparison();\n        });\n      });\n      \n      // Add event listeners for threshold sliders\n      const matchThresholdSlider = document.getElementById('matchThresholdSlider');\n      const minConfidenceSlider = document.getElementById('minConfidenceSlider');\n      \n      matchThresholdSlider.addEventListener('input', function() {\n        const value = this.value / 100;\n        document.getElementById('matchThresholdValue').textContent = `${this.value}%`;\n        matchThreshold = value;\n        updateThresholdLine();\n      });\n      \n      minConfidenceSlider.addEventListener('input', function() {\n        const value = this.value / 100;\n        document.getElementById('minConfidenceValue').textContent = `${this.value}%`;\n        minConfidence = value;\n      });\n    }\n    \n    // Start recording audio\n    async function startRecording() {\n      if (isRecording) return;\n      \n      try {\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        recorder = new MediaRecorder(stream);\n        \n        recordedChunks = [];\n        isRecording = true;\n        \n        recordBtn.disabled = true;\n        stopBtn.disabled = false;\n        \n        // Handle data available\n        recorder.ondataavailable = function(e) {\n          recordedChunks.push(e.data);\n        };\n        \n        // Handle recording stop\n        recorder.onstop = function() {\n          isRecording = false;\n          \n          // Create audio blob and load into wavesurfer\n          const blob = new Blob(recordedChunks, { type: 'audio/webm' });\n          const url = URL.createObjectURL(blob);\n          wavesurfer.load(url);\n          \n          // Clean up\n          stream.getTracks().forEach(track => track.stop());\n          \n          log('Recording loaded into waveform display - drag to select a region');\n        };\n        \n        // Start recording\n        recorder.start();\n        log('Recording started...');\n        \n      } catch (err) {\n        console.error('Error accessing microphone:', err);\n        log('Error: ' + err.message);\n      }\n    }\n    \n    // Stop recording\n    function stopRecording() {\n      if (recorder && isRecording) {\n        recorder.stop();\n        recordBtn.disabled = false;\n        stopBtn.disabled = true;\n        log('Recording stopped');\n      }\n    }\n    \n    // Create template from selected region\n    async function createTemplate() {\n      // Check if any regions exist\n      const regions = Object.values(wavesurfer.regions.list);\n      if (regions.length === 0) {\n        log('Please select a region first by dragging on the waveform');\n        return;\n      }\n      \n      // Get the first region as template\n      templateRegion = regions[0];\n      \n      // Save region bounds before clearing\n      const templateStart = templateRegion.start;\n      const templateEnd = templateRegion.end;\n      \n      // Clear all regions\n      wavesurfer.clearRegions();\n      \n      // Recreate template region with fixed color\n      templateRegion = wavesurfer.addRegion({\n        id: 'template-' + Date.now(),\n        start: templateStart,\n        end: templateEnd,\n        color: 'rgba(255, 86, 0, 0.4)', // Orange for template\n        drag: false,\n        resize: false\n      });\n      \n      // Initialize data object for the template region\n      templateRegion.data = {\n        tokens: [],\n        features: null\n      };\n      \n      log(`Creating template from region: ${templateRegion.start.toFixed(2)}s - ${templateRegion.end.toFixed(2)}s`);\n      \n      // Extract audio from region\n      const audioBuffer = await extractRegionAudio(templateRegion);\n      templateBuffer = audioBuffer;\n      \n      if (!audioBuffer) {\n        log('Failed to extract audio from region');\n        return;\n      }\n      \n      // Extract frames for visualization\n      const frames = await extractFeatureFrames(audioBuffer);\n      templateRegion.data.features = frames;\n      \n      // Extract tokens from audio\n      const tokens = await extractTokensFromBuffer(audioBuffer);\n      templateTokens = tokens;\n      templateRegion.data.tokens = tokens;\n      \n      log(`Extracted ${tokens.length} tokens from template`);\n      \n      // Generate debug output\n      updateDebugOutput();\n      \n      // Display template tokens\n      displayTemplateTokens();\n      \n      // Show calibration controls\n      calibrationControls.style.display = 'inline-block';\n      \n      // Update UI\n      createTemplateBtn.disabled = true;\n      calibrationInfo.innerHTML = `\n        <strong>Template extracted:</strong> ${templateTokens.length} tokens from region ${templateRegion.start.toFixed(2)}s - ${templateRegion.end.toFixed(2)}s. \n        <br>Now add calibration regions by clicking \"Select Calibration Region\" and selecting other instances of the same thikr.\n      `;\n      \n      // Show token container\n      tokenContainer.style.display = 'block';\n    }\n    \n    // Select calibration region\n    function enhancedSelectCalibrationRegion() {\n      calibrationMode = true;\n      log('Click and drag on the waveform to select another instance of the same thikr pattern.');\n    }\n    \n    // Add a region to the UI list\n    function addRegionToList(region) {\n      const regionList = document.getElementById('regionList');\n      \n      // Create region item element\n      const regionItem = document.createElement('div');\n      regionItem.className = 'region-item';\n      regionItem.id = `region-item-${region.id}`;\n      regionItem.dataset.regionId = region.id;\n      \n      // Create region info\n      const regionInfo = document.createElement('div');\n      regionInfo.className = 'region-info';\n      regionInfo.textContent = `Region ${calibrationRegions.length}: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`;\n      \n      // Create similarity score display (initially empty)\n      const similarityScore = document.createElement('div');\n      similarityScore.className = 'similarity-score';\n      similarityScore.textContent = '...';\n      \n      // Create region actions\n      const regionActions = document.createElement('div');\n      regionActions.className = 'region-actions';\n      \n      const playButton = document.createElement('button');\n      playButton.className = 'play-region';\n      playButton.textContent = '▶';\n      playButton.addEventListener('click', (e) => {\n        e.stopPropagation();\n        playRegion(region);\n      });\n      \n      const removeButton = document.createElement('button');\n      removeButton.className = 'remove-region';\n      removeButton.textContent = '✕';\n      removeButton.addEventListener('click', (e) => {\n        e.stopPropagation();\n        removeCalibrationRegion(region.id);\n      });\n      \n      // Assemble the region item\n      regionActions.appendChild(playButton);\n      regionActions.appendChild(removeButton);\n      regionItem.appendChild(regionInfo);\n      regionItem.appendChild(similarityScore);\n      regionItem.appendChild(regionActions);\n      \n      // Add click event to select this region\n      regionItem.addEventListener('click', () => {\n        selectRegion(region.id);\n      });\n      \n      // Add to the list\n      regionList.appendChild(regionItem);\n    }\n    \n    // Play a specific region\n    function playRegion(region) {\n      // Set playback to start at region start\n      wavesurfer.setCurrentTime(region.start);\n      \n      // Play for the duration of the region\n      wavesurfer.play(region.start, region.end);\n      \n      log(`Playing region: ${region.start.toFixed(2)}s to ${region.end.toFixed(2)}s`);\n    }\n    \n    // Remove a calibration region\n    function removeCalibrationRegion(regionId) {\n      // Find the region in the list\n      const regionIndex = calibrationRegions.findIndex(r => r.id === regionId);\n      \n      if (regionIndex !== -1) {\n        // Remove the region from WaveSurfer\n        calibrationRegions[regionIndex].remove();\n        \n        // Remove from our array\n        calibrationRegions.splice(regionIndex, 1);\n        \n        // Remove from UI\n        const regionItem = document.getElementById(`region-item-${regionId}`);\n        if (regionItem) {\n          regionItem.remove();\n        }\n        \n        // Update region count\n        updateRegionCount();\n        \n        // Update calibrate button state\n        calibrateBtn.disabled = calibrationRegions.length === 0;\n        \n        // If selected region was removed, clear selection\n        if (selectedRegionId === regionId) {\n          selectedRegionId = null;\n          updateFeatureComparison();\n        }\n        \n        log(`Calibration region removed (${calibrationRegions.length} remaining)`);\n      }\n    }\n    \n    // Update the region counter display\n    function updateRegionCount() {\n      regionCount.textContent = calibrationRegions.length;\n    }\n    \n    // Select a region for inspection\n    function selectRegion(regionId) {\n      // Deselect previous region in UI\n      if (selectedRegionId) {\n        const prevSelected = document.getElementById(`region-item-${selectedRegionId}`);\n        if (prevSelected) {\n          prevSelected.classList.remove('selected');\n        }\n      }\n      \n      // Update selection\n      selectedRegionId = regionId;\n      \n      // Update UI selection\n      const selectedItem = document.getElementById(`region-item-${regionId}`);\n      if (selectedItem) {\n        selectedItem.classList.add('selected');\n      }\n      \n      // Update the feature comparison visualization\n      updateFeatureComparison();\n      \n      // Highlight the region in the waveform\n      calibrationRegions.forEach(region => {\n        region.color = region.id === regionId \n          ? 'rgba(76, 110, 245, 0.5)' // Highlight selected\n          : 'rgba(0, 200, 83, 0.3)';  // Default green\n        region.update();\n      });\n      \n      log(`Selected calibration region: ${regionId}`);\n    }\n    \n    // Extract audio buffer from a region\n    async function extractRegionAudio(region) {\n      if (!region || !wavesurfer || !wavesurfer.backend.buffer) {\n        log('Error: Missing region or audio data');\n        return null;\n      }\n      \n      const sourceBuffer = wavesurfer.backend.buffer;\n      const startSample = Math.floor(region.start * sourceBuffer.sampleRate);\n      const endSample = Math.floor(region.end * sourceBuffer.sampleRate);\n      \n      if (startSample >= endSample || startSample < 0 || endSample > sourceBuffer.length) {\n        log('Error: Invalid region boundaries');\n        return null;\n      }\n      \n      // Create a new buffer for the region\n      const regionBuffer = audioContext.createBuffer(\n        sourceBuffer.numberOfChannels,\n        endSample - startSample,\n        sourceBuffer.sampleRate\n      );\n      \n      // Copy audio data to region buffer\n      for (let channel = 0; channel < sourceBuffer.numberOfChannels; channel++) {\n        const sourceData = sourceBuffer.getChannelData(channel);\n        const regionData = regionBuffer.getChannelData(channel);\n        for (let i = 0; i < regionBuffer.length; i++) {\n          regionData[i] = sourceData[startSample + i];\n        }\n      }\n      \n      return regionBuffer;\n    }\n    \n    // Extract feature frames from audio buffer\n    async function extractFeatureFrames(buffer) {\n      return new Promise((resolve) => {\n        const frames = [];\n        const offlineCtx = new OfflineAudioContext(\n          buffer.numberOfChannels,\n          buffer.length,\n          buffer.sampleRate\n        );\n        \n        const source = offlineCtx.createBufferSource();\n        source.buffer = buffer;\n        \n        // Create Meyda analyzer\n        const analyzer = Meyda.createMeydaAnalyzer({\n          audioContext: offlineCtx,\n          source: source,\n          bufferSize: frameSize,\n          hopSize: hopSize,\n          featureExtractors: ['rms', 'mfcc', 'spectralCentroid', 'spectralFlatness', 'zcr'],\n          callback: (features) => {\n            frames.push({\n              time: frames.length * (hopSize / offlineCtx.sampleRate),\n              rms: features.rms,\n              mfcc: features.mfcc,\n              spectralCentroid: features.spectralCentroid,\n              spectralFlatness: features.spectralFlatness,\n              zcr: features.zcr\n            });\n          }\n        });\n        \n        analyzer.start();\n        source.connect(offlineCtx.destination);\n        source.start();\n        \n        // When rendering is complete, return frames\n        offlineCtx.startRendering().then(() => {\n          log(`Extracted ${frames.length} frames from buffer`);\n          resolve(frames);\n        }).catch(err => {\n          console.error('Feature extraction error:', err);\n          log(`Feature extraction error: ${err.message}`);\n          resolve([]);\n        });\n      });\n    }\n    \n    // Extract tokens from audio buffer\n    async function extractTokensFromBuffer(buffer) {\n      const tokens = [];\n      \n      // Track frame features\n      const frames = await extractFeatureFrames(buffer);\n      \n      // Find key points in the audio (peaks, valleys, transitions)\n      for (let i = 2; i < frames.length - 2; i++) {\n        const prevFrame2 = frames[i-2];\n        const prevFrame = frames[i-1];\n        const frame = frames[i];\n        const nextFrame = frames[i+1];\n        const nextFrame2 = frames[i+2];\n        \n        // Skip frames with very low energy\n        if (frame.rms < 0.01) continue;\n        \n        // Determine token type based on audio characteristics\n        let tokenType = determineTokenType(frame, prevFrame, nextFrame);\n        \n        // Only add if it's a significant point in the audio\n        if (isSignificantPoint(frame, prevFrame, nextFrame, prevFrame2, nextFrame2)) {\n          tokens.push({\n            type: tokenType,\n            time: frame.time,\n            rms: frame.rms,\n            spectralCentroid: frame.spectralCentroid,\n            mfcc: frame.mfcc.slice(0, 5), // Only keep first 5 coefficients\n            spectralFlux: calculateSpectralFlux(frame, prevFrame),\n            zcr: frame.zcr\n          });\n        }\n      }\n      \n      // Simplify to avoid too many tokens\n      return simplifyTokenSequence(tokens);\n    }\n    \n    // Calculate spectral flux (difference from previous frame)\n    function calculateSpectralFlux(frame, prevFrame) {\n      if (!prevFrame) return 0;\n      \n      // Use spectral centroid difference as a simple flux measure\n      return Math.abs(frame.spectralCentroid - prevFrame.spectralCentroid);\n    }\n    \n    // Determine if this is a significant point in the audio\n    function isSignificantPoint(frame, prevFrame, nextFrame, prevFrame2, nextFrame2) {\n      if (!prevFrame || !nextFrame) return false;\n      \n      // Energy peak (local maximum)\n      const isEnergyPeak = frame.rms > prevFrame.rms && \n                          frame.rms > nextFrame.rms && \n                          frame.rms > 0.02;\n      \n      // Energy valley (local minimum)\n      const isEnergyValley = frame.rms < prevFrame.rms && \n                            frame.rms < nextFrame.rms && \n                            prevFrame.rms > 0.02 && \n                            nextFrame.rms > 0.02;\n      \n      // Spectral centroid peak (local maximum - bright sounds)\n      const isSpectralPeak = frame.spectralCentroid > prevFrame.spectralCentroid && \n                            frame.spectralCentroid > nextFrame.spectralCentroid &&\n                            frame.spectralCentroid > 3000;\n      \n      // Sharp rising edge in energy\n      const isRisingEdge = prevFrame2 && \n                          (frame.rms - prevFrame2.rms) > 0.03;\n      \n      // Sharp falling edge in energy\n      const isFallingEdge = nextFrame2 && \n                           (frame.rms - nextFrame2.rms) > 0.03;\n      \n      // Zero crossing rate peak (consonant sounds)\n      const isZcrPeak = frame.zcr > prevFrame.zcr && \n                        frame.zcr > nextFrame.zcr && \n                        frame.zcr > 0.3;\n      \n      return isEnergyPeak || isEnergyValley || isSpectralPeak || isZcrPeak || isRisingEdge || isFallingEdge;\n    }\n    \n    // Determine token type based on audio characteristics\n    function determineTokenType(frame, prevFrame, nextFrame) {\n      if (!prevFrame || !nextFrame) return 'E';\n      \n      // Energy rising\n      if (frame.rms > prevFrame.rms * 1.2 && frame.rms > 0.02) {\n        return 'A';\n      }\n      \n      // Energy falling\n      if (frame.rms < prevFrame.rms * 0.8 && prevFrame.rms > 0.02) {\n        return 'B';\n      }\n      \n      // High spectral content (bright/sharp sounds)\n      if (frame.spectralCentroid > 5000 && frame.rms > 0.02) {\n        return 'C';\n      }\n      \n      // Low spectral content (dull/muffled sounds)\n      if (frame.spectralCentroid < 2000 && frame.rms > 0.02) {\n        return 'D';\n      }\n      \n      // Default token type for background/silence\n      return 'E';\n    }\n    \n    // Simplify token sequence to avoid too many tokens\n    function simplifyTokenSequence(tokens) {\n      if (tokens.length <= 10) return tokens;\n      \n      // Group tokens by type and proximity\n      const simplified = [];\n      let lastTokenType = null;\n      let lastTokenTime = -1;\n      \n      for (let i = 0; i < tokens.length; i++) {\n        // Keep token if:\n        // 1. It's a different type than the last one\n        // 2. It's sufficiently separated in time\n        // 3. It's one of the first or last tokens\n        // 4. It's evenly spaced throughout (keep ~15 tokens total)\n        const timeDiff = lastTokenTime >= 0 ? tokens[i].time - lastTokenTime : 999;\n        \n        if (tokens[i].type !== lastTokenType || \n            timeDiff > 0.1 || \n            i === 0 || \n            i === tokens.length - 1 ||\n            i % Math.ceil(tokens.length / 15) === 0) {\n          simplified.push(tokens[i]);\n          lastTokenType = tokens[i].type;\n          lastTokenTime = tokens[i].time;\n        }\n      }\n      \n      return simplified;\n    }\n    \n    // Display template tokens\n    function displayTemplateTokens() {\n      // Clear previous display\n      tokenSequence.innerHTML = '';\n      activeTokenTypes.clear();\n      \n      // Display each token\n      templateTokens.forEach((token, index) => {\n        const tokenEl = document.createElement('div');\n        tokenEl.className = 'token';\n        tokenEl.style.backgroundColor = tokenColors[token.type];\n        \n        // Use letters A-Z for first 26, then numbers\n        const letter = index < 26 ? String.fromCharCode(65 + index) : (index - 25);\n        tokenEl.textContent = letter;\n        \n        // Store token type for legend highlight\n        activeTokenTypes.add(token.type);\n        \n        // Add token type label\n        const labelEl = document.createElement('div');\n        labelEl.className = 'token-label';\n        labelEl.textContent = token.type;\n        tokenEl.appendChild(labelEl);\n        \n        // Add debug info tooltip\n        if (showFeatureValues) {\n          const debugInfo = document.createElement('div');\n          debugInfo.className = 'token-debug-info';\n          debugInfo.textContent = `RMS: ${token.rms.toFixed(3)}, SC: ${(token.spectralCentroid/1000).toFixed(1)}k`;\n          tokenEl.appendChild(debugInfo);\n        }\n        \n        tokenSequence.appendChild(tokenEl);\n      });\n      \n      // Update legend to highlight active token types\n      updateLegend();\n    }\n    \n    // Update legend to highlight active token types\n    function updateLegend() {\n      const legendItems = document.querySelectorAll('.legend-item');\n      \n      legendItems.forEach(item => {\n        const typeText = item.querySelector('span').textContent;\n        const type = typeText.charAt(0); // Get the letter (A, B, C, etc.)\n        \n        if (activeTokenTypes.has(type)) {\n          item.style.opacity = '1';\n          item.style.fontWeight = 'bold';\n        } else {\n          item.style.opacity = '0.5';\n          item.style.fontWeight = 'normal';\n        }\n      });\n    }\n    \n    // Enhanced calibration process\n    async function enhancedCalibrate() {\n      if (templateTokens.length === 0 || calibrationRegions.length === 0) {\n        log('Error: Need template tokens and at least one calibration region');\n        return;\n      }\n      \n      log(`Starting calibration with ${calibrationRegions.length} regions...`);\n      \n      calibrationResults = [];\n      regionFeatures = {};\n      \n      // Process all calibration regions\n      for (let i = 0; i < calibrationRegions.length; i++) {\n        const region = calibrationRegions[i];\n        log(`Processing region ${i+1}: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n        \n        // Extract audio from region\n        const audioBuffer = await extractRegionAudio(region);\n        \n        if (!audioBuffer) {\n          log(`Error extracting audio from region ${i+1}`);\n          continue;\n        }\n        \n        // Extract tokens from audio\n        const tokens = await extractTokensFromBuffer(audioBuffer);\n        \n        // Extract raw feature frames for visualization\n        const frames = await extractFeatureFrames(audioBuffer);\n        \n        // Store tokens and frames with the region for later comparison\n        region.data.tokens = tokens;\n        region.data.features = frames;\n        \n        // Compare with template\n        const similarity = compareTokenSequences(templateTokens, tokens);\n        region.data.similarity = similarity;\n        \n        // Store calibration result\n        calibrationResults.push({\n          regionId: region.id,\n          similarity: similarity,\n          tokens: tokens,\n          features: frames\n        });\n        \n        // Update the similarity display in the UI\n        const similarityEl = document.querySelector(`#region-item-${region.id} .similarity-score`);\n        if (similarityEl) {\n          similarityEl.textContent = `${(similarity * 100).toFixed(0)}%`;\n        }\n        \n        log(`Region ${i+1}: ${tokens.length} tokens, similarity: ${(similarity * 100).toFixed(1)}%`);\n        \n        // Verbose logging of token comparison if enabled\n        if (verboseLogging) {\n          const tokenComparison = compareTokenSequencesDetailed(templateTokens, tokens);\n          log(`Token comparison: ${JSON.stringify(tokenComparison)}`);\n        }\n      }\n      \n      // Calculate statistics\n      if (calibrationResults.length > 0) {\n        const similarities = calibrationResults.map(r => r.similarity);\n        const avgSimilarity = similarities.reduce((a, b) => a + b, 0) / similarities.length;\n        const minSimilarity = Math.min(...similarities);\n        const maxSimilarity = Math.max(...similarities);\n        \n        // Calculate standard deviation\n        const stdDev = Math.sqrt(\n          similarities.reduce((sum, val) => sum + Math.pow(val - avgSimilarity, 2), 0) / similarities.length\n        );\n        \n        // Update summary display\n        document.getElementById('avgSimilarity').textContent = `${(avgSimilarity * 100).toFixed(1)}%`;\n        document.getElementById('minSimilarity').textContent = `${(minSimilarity * 100).toFixed(1)}%`;\n        document.getElementById('maxSimilarity').textContent = `${(maxSimilarity * 100).toFixed(1)}%`;\n        document.getElementById('stdDevSimilarity').textContent = `${(stdDev * 100).toFixed(1)}%`;\n        \n        // Set match threshold to 85% of the average similarity to allow for variations\n        const recommendedThreshold = Math.max(0.5, minSimilarity * 0.9);\n        matchThreshold = recommendedThreshold;\n        minConfidence = recommendedThreshold * 0.4;\n        \n        // Update threshold sliders\n        document.getElementById('matchThresholdSlider').value = Math.round(matchThreshold * 100);\n        document.getElementById('matchThresholdValue').textContent = `${Math.round(matchThreshold * 100)}%`;\n        \n        document.getElementById('minConfidenceSlider').value = Math.round(minConfidence * 100);\n        document.getElementById('minConfidenceValue').textContent = `${Math.round(minConfidence * 100)}%`;\n        \n        // Update UI\n        updateThresholdLine();\n        updateFeatureComparison();\n        \n        calibrationInfo.innerHTML = `\n          <strong>Calibration complete:</strong> \n          Match threshold: ${(matchThreshold * 100).toFixed(1)}% | \n          Average similarity: ${(avgSimilarity * 100).toFixed(1)}% |\n          Regions analyzed: ${calibrationRegions.length}\n        `;\n        \n        log(`Calibration complete. Match threshold set to ${(matchThreshold * 100).toFixed(1)}%`);\n        \n        // Update debug output\n        updateDebugOutput();\n        \n        // Enable analysis\n        startAnalysisBtn.disabled = false;\n      } else {\n        log('Calibration failed - no valid regions processed');\n      }\n    }\n    \n    // Compare two token sequences and return similarity (0-1)\n    function compareTokenSequences(template, sequence) {\n      if (!template.length || !sequence.length) return 0;\n      \n      // Simple sliding window approach - find best match within sequence\n      let bestSimilarity = 0;\n      let bestOffset = 0;\n      \n      // Try different alignments to find best match\n      for (let startIdx = 0; startIdx <= sequence.length - Math.min(template.length, 3); startIdx++) {\n        const endIdx = Math.min(startIdx + template.length, sequence.length);\n        const window = sequence.slice(startIdx, endIdx);\n        \n        // Calculate how many tokens match by type\n        let matches = 0;\n        const minLength = Math.min(template.length, window.length);\n        \n        for (let i = 0; i < minLength; i++) {\n          // Compare token features with some tolerance\n          const templateToken = template[i];\n          const windowToken = window[i];\n          \n          // Base similarity on token type\n          const typeMatch = templateToken.type === windowToken.type ? 1 : 0;\n          \n          // Energy similarity\n          const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - windowToken.rms) / 0.2);\n          \n          // Spectral similarity\n          const spectralSimilarity = 1 - Math.min(1, Math.abs(templateToken.spectralCentroid - windowToken.spectralCentroid) / 5000);\n          \n          // Combined similarity for this token\n          const tokenSimilarity = typeMatch * 0.6 + energySimilarity * 0.3 + spectralSimilarity * 0.1;\n          \n          matches += tokenSimilarity;\n        }\n        \n        // Normalize by template length\n        const similarity = matches / template.length;\n        \n        if (similarity > bestSimilarity) {\n          bestSimilarity = similarity;\n          bestOffset = startIdx;\n        }\n      }\n      \n      return bestSimilarity;\n    }\n    \n    // Compare token sequences with detailed reporting for debugging\n    function compareTokenSequencesDetailed(template, sequence) {\n      if (!template.length || !sequence.length) return { similarity: 0, details: [] };\n      \n      // Simple sliding window approach - find best match within sequence\n      let bestSimilarity = 0;\n      let bestOffset = 0;\n      let bestDetails = [];\n      \n      // Try different alignments to find best match\n      for (let startIdx = 0; startIdx <= sequence.length - Math.min(template.length, 3); startIdx++) {\n        const endIdx = Math.min(startIdx + template.length, sequence.length);\n        const window = sequence.slice(startIdx, endIdx);\n        \n        // Calculate how many tokens match by type\n        let matches = 0;\n        const details = [];\n        const minLength = Math.min(template.length, window.length);\n        \n        for (let i = 0; i < minLength; i++) {\n          // Compare token features with some tolerance\n          const templateToken = template[i];\n          const windowToken = window[i];\n          \n          // Base similarity on token type\n          const typeMatch = templateToken.type === windowToken.type ? 1 : 0;\n          \n          // Energy similarity\n          const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - windowToken.rms) / 0.2);\n          \n          // Spectral similarity\n          const spectralSimilarity = 1 - Math.min(1, Math.abs(templateToken.spectralCentroid - windowToken.spectralCentroid) / 5000);\n          \n          // Combined similarity for this token\n          const tokenSimilarity = typeMatch * 0.6 + energySimilarity * 0.3 + spectralSimilarity * 0.1;\n          \n          matches += tokenSimilarity;\n          \n          details.push({\n            template: {\n              type: templateToken.type,\n              rms: templateToken.rms,\n              spectralCentroid: templateToken.spectralCentroid\n            },\n            window: {\n              type: windowToken.type,\n              rms: windowToken.rms, \n              spectralCentroid: windowToken.spectralCentroid\n            },\n            typeMatch: typeMatch,\n            energySimilarity: energySimilarity,\n            spectralSimilarity: spectralSimilarity,\n            tokenSimilarity: tokenSimilarity\n          });\n        }\n        \n        // Normalize by template length\n        const similarity = matches / template.length;\n        \n        if (similarity > bestSimilarity) {\n          bestSimilarity = similarity;\n          bestOffset = startIdx;\n          bestDetails = details;\n        }\n      }\n      \n      return {\n        similarity: bestSimilarity,\n        offset: bestOffset,\n        details: bestDetails\n      };\n    }\n    \n    // Update the feature comparison visualization\n    function updateFeatureComparison() {\n      const comparisonChart = document.getElementById('comparisonChart');\n      comparisonChart.innerHTML = '';\n      \n      // If no template or no selection, show a message\n      if (!templateTokens.length && !templateRegion) {\n        comparisonChart.innerHTML = '<div style=\"text-align: center; padding: 20px;\">No template available for comparison</div>';\n        return;\n      }\n      \n      if (selectedFeatureType === 'tokens') {\n        // Special visualization for token types\n        renderTokenTypeComparison(comparisonChart);\n      } else {\n        // Render time-series data for other feature types\n        renderFeatureTimeSeries(comparisonChart);\n      }\n    }\n    \n    // Render feature time series comparison\n    function renderFeatureTimeSeries(container) {\n      // Get template features\n      let templateFeatures = [];\n      if (templateRegion && templateRegion.data && templateRegion.data.features) {\n        templateFeatures = templateRegion.data.features;\n      } else if (templateBuffer) {\n        // If template features not stored, extract them\n        log('Template features not available, visualization may be incomplete');\n      }\n      \n      // Get selected region features\n      let selectedFeatures = [];\n      if (selectedRegionId) {\n        const selectedRegion = calibrationRegions.find(r => r.id === selectedRegionId);\n        if (selectedRegion && selectedRegion.data && selectedRegion.data.features) {\n          selectedFeatures = selectedRegion.data.features;\n        }\n      }\n      \n      // Create template series container\n      const templateSeries = document.createElement('div');\n      templateSeries.className = 'feature-series';\n      \n      // Get feature property based on selected type\n      const getFeatureValue = (frame) => {\n        switch (selectedFeatureType) {\n          case 'energy': return frame.rms;\n          case 'centroid': return frame.spectralCentroid / 10000; // Normalize\n          case 'zcr': return frame.zcr;\n          default: return frame.rms;\n        }\n      };\n      \n      // Render template features\n      if (templateFeatures.length > 0) {\n        renderFeatureSeries(templateSeries, templateFeatures, getFeatureValue, 'template-bar');\n      }\n      \n      // Render selected region features if available\n      if (selectedFeatures.length > 0) {\n        const selectedSeries = document.createElement('div');\n        selectedSeries.className = 'feature-series';\n        renderFeatureSeries(selectedSeries, selectedFeatures, getFeatureValue, 'selected-region-bar');\n        \n        // Add both to container\n        container.appendChild(templateSeries);\n        container.appendChild(selectedSeries);\n      } else {\n        // Just add template\n        container.appendChild(templateSeries);\n      }\n    }\n    \n    // Render a feature series\n    function renderFeatureSeries(container, features, valueAccessor, barClass) {\n      // Find max value for scaling\n      const maxValue = Math.max(...features.map(valueAccessor));\n      \n      // Only display a reasonable number of points (max 100)\n      const step = Math.max(1, Math.ceil(features.length / 100));\n      \n      // Create visible points\n      for (let i = 0; i < features.length; i += step) {\n        const feature = features[i];\n        const value = valueAccessor(feature);\n        \n        // Create feature point element\n        const pointEl = document.createElement('div');\n        pointEl.className = 'feature-point';\n        \n        // Create feature bar element (height represents value)\n        const barEl = document.createElement('div');\n        barEl.className = `feature-bar ${barClass}`;\n        \n        // Set height as percentage of max value\n        const heightPercent = (value / maxValue) * 100;\n        barEl.style.height = `${heightPercent}%`;\n        \n        // Add tooltip\n        barEl.title = `${selectedFeatureType}: ${value.toFixed(4)} at ${feature.time.toFixed(3)}s`;\n        \n        // Add to DOM\n        pointEl.appendChild(barEl);\n        container.appendChild(pointEl);\n      }\n    }\n    \n    // Render token type comparison\n    function renderTokenTypeComparison(container) {\n      // Create a chart showing the proportion of each token type\n      \n      // Get template tokens\n      const templateTokens = this.templateTokens || [];\n      \n      // Get selected region tokens\n      let selectedTokens = [];\n      if (selectedRegionId) {\n        const selectedRegion = calibrationRegions.find(r => r.id === selectedRegionId);\n        if (selectedRegion && selectedRegion.data && selectedRegion.data.tokens) {\n          selectedTokens = selectedRegion.data.tokens;\n        }\n      }\n      \n      // Count token types\n      const templateCounts = countTokenTypes(templateTokens);\n      const selectedCounts = countTokenTypes(selectedTokens);\n      \n      // Create container for the grouped bars\n      const barsContainer = document.createElement('div');\n      barsContainer.style.display = 'flex';\n      barsContainer.style.height = '100%';\n      barsContainer.style.alignItems = 'flex-end';\n      barsContainer.style.padding = '10px';\n      \n      // Create bars for each token type\n      for (const type of tokenTypes) {\n        // Create group for this token type\n        const groupEl = document.createElement('div');\n        groupEl.style.display = 'flex';\n        groupEl.style.flexDirection = 'column';\n        groupEl.style.alignItems = 'center';\n        groupEl.style.flex = '1';\n        groupEl.style.marginBottom = '25px';\n        \n        // Add token type label\n        const labelEl = document.createElement('div');\n        labelEl.textContent = `Type ${type}`;\n        labelEl.style.position = 'absolute';\n        labelEl.style.bottom = '-20px';\n        labelEl.style.fontSize = '12px';\n        \n        // Create container for the two bars\n        const barGroupEl = document.createElement('div');\n        barGroupEl.style.display = 'flex';\n        barGroupEl.style.width = '100%';\n        barGroupEl.style.height = '100%';\n        barGroupEl.style.position = 'relative';\n        \n        // Template bar\n        const templateBar = document.createElement('div');\n        templateBar.className = 'feature-bar template-bar';\n        templateBar.style.width = '45%';\n        templateBar.style.marginRight = '10%';\n        templateBar.style.height = `${templateCounts[type] || 0}%`;\n        templateBar.title = `Template: ${templateCounts[type] || 0}%`;\n        \n        // Selected region bar\n        const selectedBar = document.createElement('div');\n        selectedBar.className = 'feature-bar selected-region-bar';\n        selectedBar.style.width = '45%';\n        selectedBar.style.height = `${selectedCounts[type] || 0}%`;\n        selectedBar.title = `Selected: ${selectedCounts[type] || 0}%`;\n        \n        // Add bars to bar group\n        barGroupEl.appendChild(templateBar);\n        barGroupEl.appendChild(selectedBar);\n        barGroupEl.appendChild(labelEl);\n        \n        // Add to group element\n        groupEl.appendChild(barGroupEl);\n        \n        // Add to container\n        barsContainer.appendChild(groupEl);\n      }\n      \n      // Add legend\n      const legendEl = document.createElement('div');\n      legendEl.style.display = 'flex';\n      legendEl.style.justifyContent = 'center';\n      legendEl.style.marginTop = '30px';\n      legendEl.style.gap = '20px';\n      \n      const templateLegend = document.createElement('div');\n      templateLegend.innerHTML = '<span style=\"display:inline-block;width:12px;height:12px;background-color:rgba(255,86,0,0.6);margin-right:5px;\"></span> Template';\n      \n      const selectedLegend = document.createElement('div');\n      selectedLegend.innerHTML = '<span style=\"display:inline-block;width:12px;height:12px;background-color:rgba(76,110,245,0.8);margin-right:5px;\"></span> Selected Region';\n      \n      legendEl.appendChild(templateLegend);\n      legendEl.appendChild(selectedLegend);\n      \n      // Add all to main container\n      container.appendChild(barsContainer);\n      container.appendChild(legendEl);\n    }\n    \n    // Count token types as percentages\n    function countTokenTypes(tokens) {\n      const counts = {};\n      if (!tokens || tokens.length === 0) return counts;\n      \n      // Count occurrences of each type\n      for (const token of tokens) {\n        counts[token.type] = (counts[token.type] || 0) + 1;\n      }\n      \n      // Convert to percentages\n      for (const type in counts) {\n        counts[type] = (counts[type] / tokens.length) * 100;\n      }\n      \n      return counts;\n    }\n    \n    // Start real-time analysis\n    async function startAnalysis() {\n      if (templateTokens.length === 0) {\n        log('Error: Template tokens not available');\n        return;\n      }\n      \n      // Reset state\n      resetAnalysisState();\n      \n      try {\n        // Access microphone\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        const source = audioContext.createMediaStreamSource(stream);\n        \n        // Create Meyda analyzer\n        meydaAnalyzer = Meyda.createMeydaAnalyzer({\n          audioContext: audioContext,\n          source: source,\n          bufferSize: frameSize,\n          hopSize: hopSize,\n          featureExtractors: ['rms', 'mfcc', 'spectralCentroid', 'spectralFlatness', 'zcr'],\n          callback: processFrame\n        });\n        \n        meydaAnalyzer.start();\n        isAnalyzing = true;\n        \n        // Update UI\n        startAnalysisBtn.disabled = true;\n        stopAnalysisBtn.disabled = false;\n        liveActivity.innerHTML = 'Listening for thikr patterns...';\n        \n        log('Real-time analysis started. Recite thikr...');\n        \n      } catch (err) {\n        console.error('Error accessing microphone:', err);\n        log('Error: ' + err.message);\n      }\n    }\n    \n    // Stop real-time analysis\n    function stopAnalysis() {\n      if (meydaAnalyzer) {\n        meydaAnalyzer.stop();\n      }\n      \n      isAnalyzing = false;\n      \n      // Update UI\n      startAnalysisBtn.disabled = false;\n      stopAnalysisBtn.disabled = true;\n      liveActivity.innerHTML = 'Analysis stopped.';\n      \n      log('Analysis stopped.');\n    }\n    \n    // Process a frame from the real-time analyzer\n    let prevFrames = [];\n    \n    function processFrame(features) {\n      if (!isAnalyzing) return;\n      \n      const currentTime = audioContext.currentTime;\n      \n      // Create frame object\n      const frame = {\n        time: currentTime,\n        rms: features.rms || 0,\n        mfcc: features.mfcc || [],\n        spectralCentroid: features.spectralCentroid || 0,\n        spectralFlatness: features.spectralFlatness || 0,\n        zcr: features.zcr || 0\n      };\n      \n      // Add to frames buffer\n      prevFrames.push(frame);\n      if (prevFrames.length > 5) {\n        prevFrames.shift();\n      }\n      \n      // Need at least 3 frames to detect features\n      if (prevFrames.length < 3) return;\n      \n      // Get frames for context\n      const currentIdx = prevFrames.length - 1;\n      const prevFrame2 = prevFrames[Math.max(0, currentIdx - 2)];\n      const prevFrame = prevFrames[Math.max(0, currentIdx - 1)];\n      const currentFrame = prevFrames[currentIdx];\n      const nextFrame = null; // We don't have future frames in real-time\n      const nextFrame2 = null;\n      \n      // Check if this frame is a significant point AND enough time has passed since last token\n      if (isSignificantPoint(currentFrame, prevFrame, nextFrame, prevFrame2, nextFrame2) && \n          currentTime - lastTokenTime > 0.05) { // Minimum 50ms between tokens\n        \n        // Determine token type\n        const tokenType = determineTokenType(currentFrame, prevFrame, nextFrame);\n        \n        // Create token\n        const token = {\n          type: tokenType,\n          time: currentTime,\n          rms: currentFrame.rms,\n          spectralCentroid: currentFrame.spectralCentroid,\n          mfcc: currentFrame.mfcc.slice(0, 5),\n          spectralFlux: calculateSpectralFlux(currentFrame, prevFrame),\n          zcr: currentFrame.zcr\n        };\n        \n        // Add to token buffer\n        liveTokenBuffer.push(token);\n        lastTokenTime = currentTime;\n        \n        // Limit token buffer size (keep enough to match template)\n        const maxBuffer = Math.max(30, templateTokens.length * 2);\n        if (liveTokenBuffer.length > maxBuffer) {\n          liveTokenBuffer.shift();\n        }\n        \n        // Update activity display with more detailed token info\n        if (verboseLogging) {\n          updateLiveActivity(`Token ${tokenType} detected (RMS: ${token.rms.toFixed(3)}, SC: ${(token.spectralCentroid/1000).toFixed(1)}k Hz, ZCR: ${token.zcr.toFixed(3)})`);\n        } else {\n          updateLiveActivity(`Token ${tokenType} detected (${token.rms.toFixed(2)} energy)`);\n        }\n        \n        // Process for pattern matching\n        processTokenMatching();\n      }\n    }\n    \n    // Process token matching\n    function processTokenMatching() {\n      // Need a minimum number of tokens to start matching\n      if (liveTokenBuffer.length < Math.max(3, templateTokens.length / 2)) {\n        return;\n      }\n      \n      // Calculate similarity with template\n      const similarity = compareTokenSequences(templateTokens, liveTokenBuffer);\n      \n      // Add confidence marker\n      addConfidenceMarker(similarity);\n      \n      // Update confidence history\n      confidenceHistory.push(similarity);\n      if (confidenceHistory.length > 50) {\n        confidenceHistory.shift();\n      }\n      \n      // Update UI\n      updateProgressBar(similarity);\n      updateTokenVisualization(similarity);\n      \n      // Update activity display with confidence\n      updateLiveActivity(`Pattern match: ${(similarity * 100).toFixed(1)}% confidence`);\n      \n      if (verboseLogging) {\n        log(`Pattern match: ${(similarity * 100).toFixed(1)}% confidence`);\n      }\n      \n      // Check for detection\n      if (similarity >= matchThreshold && \n          audioContext.currentTime - lastDetectionTime > 2.0) { // Cooldown period\n        \n        // Register detection\n        detectionCount++;\n        counterDisplay.textContent = detectionCount;\n        lastDetectionTime = audioContext.currentTime;\n        \n        // Add to detection events log\n        const detectionEvent = {\n          id: detectionCount,\n          time: new Date().toISOString(),\n          similarity: similarity,\n          thresholdUsed: matchThreshold,\n          tokenCount: liveTokenBuffer.length,\n          tokenTypes: tokenTypeCounts(liveTokenBuffer)\n        };\n        detectionEvents.push(detectionEvent);\n        \n        // Update detection data display\n        updateDetectionData(detectionEvent);\n        \n        // Add detection flash\n        addDetectionFlash();\n        \n        // Apply wave animation\n        applyWaveAnimation();\n        \n        // Update activity display with detection\n        updateLiveActivity(`THIKR DETECTED (#${detectionCount}) with ${(similarity * 100).toFixed(1)}% confidence!`);\n        \n        log(`THIKR DETECTED (#${detectionCount}) with ${(similarity * 100).toFixed(1)}% confidence`);\n        \n        // Clear token buffer to look for next pattern\n        liveTokenBuffer = [];\n      }\n    }\n    \n    // Update detection data display\n    function updateDetectionData(event) {\n      // Format the detection data\n      const formattedData = `\n        <div style=\"border-bottom: 1px solid #dee2e6; padding-bottom: 10px; margin-bottom: 10px;\">\n          <strong>Detection #${event.id}</strong> (${new Date(event.time).toLocaleTimeString()})\n          <br>Confidence: ${(event.similarity * 100).toFixed(1)}% (threshold: ${(event.thresholdUsed * 100).toFixed(1)}%)\n          <br>Tokens: ${event.tokenCount} (${formatTokenTypeCounts(event.tokenTypes)})\n        </div>\n      `;\n      \n      // Add to detection data display\n      detectionData.innerHTML = formattedData + detectionData.innerHTML;\n      \n      // Keep only the last 10 events in the display\n      const items = detectionData.querySelectorAll('div');\n      if (items.length > 10) {\n        for (let i = 10; i < items.length; i++) {\n          items[i].remove();\n        }\n      }\n      \n      // Update debug output\n      updateDebugOutput();\n    }\n    \n    // Format token type counts\n    function formatTokenTypeCounts(counts) {\n      return Object.entries(counts)\n        .map(([type, count]) => `${type}:${count}`)\n        .join(', ');\n    }\n    \n    // Count token types\n    function tokenTypeCounts(tokens) {\n      const counts = {};\n      tokens.forEach(token => {\n        counts[token.type] = (counts[token.type] || 0) + 1;\n      });\n      return counts;\n    }\n    \n    // Update live activity display\n    function updateLiveActivity(message) {\n      const time = new Date().toLocaleTimeString();\n      const activityMessage = `[${time}] ${message}`;\n      \n      // Add new message at top\n      liveActivity.innerHTML = activityMessage + \"<br>\" + liveActivity.innerHTML;\n      \n      // Limit number of messages\n      const messages = liveActivity.innerHTML.split(\"<br>\");\n      if (messages.length > 10) {\n        liveActivity.innerHTML = messages.slice(0, 10).join(\"<br>\");\n      }\n    }\n    \n    // Add confidence marker to visualization\n    function addConfidenceMarker(confidence) {\n      // Create a marker\n      const marker = document.createElement('div');\n      marker.className = 'confidence-marker';\n      \n      // Position at the right edge, height based on confidence\n      const bottom = confidence * 100;\n      marker.style.bottom = `${bottom}%`;\n      marker.style.right = '0px';\n      \n      // Color based on threshold\n      if (confidence >= matchThreshold) {\n        marker.style.backgroundColor = 'green';\n      } else if (confidence >= minConfidence) {\n        marker.style.backgroundColor = 'yellow';\n      } else {\n        marker.style.backgroundColor = 'red';\n      }\n      \n      confidenceDisplay.appendChild(marker);\n      \n      // Animate movement\n      let position = 0;\n      const maxPosition = confidenceDisplay.offsetWidth;\n      const moveMarker = () => {\n        position += 2;\n        marker.style.right = `${position}px`;\n        \n        if (position <= maxPosition) {\n          requestAnimationFrame(moveMarker);\n        } else {\n          // Remove marker when it's off-screen\n          marker.remove();\n        }\n      };\n      \n      requestAnimationFrame(moveMarker);\n    }\n    \n    // Update token visualization\n    function updateTokenVisualization(overallConfidence) {\n      // Get all token elements\n      const tokenElements = tokenSequence.querySelectorAll('.token');\n      if (tokenElements.length === 0) return;\n      \n      // Calculate individual token matches\n      for (let i = 0; i < templateTokens.length && i < tokenElements.length; i++) {\n        const templateToken = templateTokens[i];\n        \n        // Find best matching token in live buffer\n        let bestMatch = 0;\n        for (let j = 0; j < liveTokenBuffer.length; j++) {\n          const liveToken = liveTokenBuffer[j];\n          if (templateToken.type === liveToken.type) {\n            const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - liveToken.rms) / 0.2);\n            bestMatch = Math.max(bestMatch, energySimilarity);\n          }\n        }\n        \n        // Reset animation\n        tokenElements[i].classList.remove('wave-effect');\n        void tokenElements[i].offsetWidth; // Force reflow to restart animation\n        \n        // Adjust token appearance based on match confidence\n        if (bestMatch > 0.7) {\n          // High confidence match\n          tokenElements[i].style.transform = `scale(${1 + bestMatch * 0.4})`;\n          \n          // Calculate color (yellow to green)\n          const r = Math.floor(255 * (1 - bestMatch));\n          const g = Math.floor(200);\n          const b = 0;\n          tokenElements[i].style.backgroundColor = `rgb(${r}, ${g}, ${b})`;\n          tokenElements[i].style.color = bestMatch > 0.8 ? 'white' : 'black';\n          tokenElements[i].style.boxShadow = `0 0 10px rgba(0, 255, 0, ${bestMatch * 0.8})`;\n          \n          // Add wave effect if high confidence\n          if (bestMatch > 0.85) {\n            tokenElements[i].classList.add('wave-effect');\n          }\n        } else if (bestMatch > 0.4) {\n          // Medium confidence match\n          tokenElements[i].style.transform = `scale(${1 + bestMatch * 0.2})`;\n          \n          // Yellow color\n          tokenElements[i].style.backgroundColor = `rgb(255, 204, 0)`;\n          tokenElements[i].style.color = 'black';\n          tokenElements[i].style.boxShadow = `0 0 5px rgba(255, 204, 0, ${bestMatch * 0.5})`;\n        } else {\n          // Low confidence or no match - reset to original\n          tokenElements[i].style.transform = 'scale(1)';\n          tokenElements[i].style.backgroundColor = tokenColors[templateToken.type];\n          tokenElements[i].style.color = 'black';\n          tokenElements[i].style.boxShadow = '0 2px 4px rgba(0,0,0,0.1)';\n        }\n        \n        // Update debug info on token\n        if (showFeatureValues) {\n          const debugInfo = tokenElements[i].querySelector('.token-debug-info');\n          if (debugInfo) {\n            debugInfo.textContent = `Match: ${(bestMatch * 100).toFixed(0)}%`;\n          }\n        }\n      }\n      \n      // If very high confidence, produce wave effect\n      if (overallConfidence > matchThreshold * 0.9) {\n        applyWaveAnimation();\n      }\n    }\n    \n    // Apply wave animation sequence to tokens\n    function applyWaveAnimation() {\n      const tokenElements = tokenSequence.querySelectorAll('.token');\n      \n      tokenElements.forEach((el, i) => {\n        setTimeout(() => {\n          el.classList.remove('wave-effect');\n          void el.offsetWidth; // Force reflow to restart animation\n          el.classList.add('wave-effect');\n        }, i * 100); // Stagger animation\n      });\n    }\n    \n    // Add detection flash\n    function addDetectionFlash() {\n      const flash = document.createElement('div');\n      flash.className = 'detection-flash';\n      tokenSequence.appendChild(flash);\n      \n      // Remove after animation completes\n      setTimeout(() => {\n        if (flash.parentNode) {\n          flash.parentNode.removeChild(flash);\n        }\n      }, 1500);\n    }\n    \n    // Update progress bar\n    function updateProgressBar(confidence) {\n      progressBar.style.height = `${confidence * 100}%`;\n    }\n    \n    // Update threshold line position\n    function updateThresholdLine() {\n      thresholdLine.style.bottom = `${matchThreshold * 100}%`;\n    }\n    \n    // Reset analysis state\n    function resetAnalysisState() {\n      liveTokenBuffer = [];\n      currentTokens = [];\n      confidenceHistory = [];\n      prevFrames = [];\n      lastTokenTime = 0;\n      lastDetectionTime = 0;\n      detectionCount = 0;\n      counterDisplay.textContent = detectionCount;\n      updateProgressBar(0);\n      liveActivity.innerHTML = 'Waiting to start analysis...';\n      \n      // Clear detection events\n      detectionEvents = [];\n      detectionData.innerHTML = '';\n      \n      // Reset token visualization\n      const tokenElements = tokenSequence.querySelectorAll('.token');\n      tokenElements.forEach((el, i) => {\n        if (i < templateTokens.length) {\n          const templateToken = templateTokens[i];\n          el.style.transform = 'scale(1)';\n          el.style.backgroundColor = tokenColors[templateToken.type];\n          el.style.color = 'black';\n          el.style.boxShadow = '0 2px 4px rgba(0,0,0,0.1)';\n        }\n      });\n      \n      // Clear confidence markers\n      document.querySelectorAll('.confidence-marker').forEach(el => el.remove());\n    }\n    \n    // Reset the app\n    function resetApp() {\n      // Stop recording if in progress\n      if (isRecording && recorder) {\n        recorder.stop();\n        isRecording = false;\n      }\n      \n      // Stop analysis if in progress\n      if (isAnalyzing) {\n        stopAnalysis();\n      }\n      \n      // Clear wavesurfer\n      wavesurfer.clearRegions();\n      wavesurfer.empty();\n      \n      // Reset variables\n      templateRegion = null;\n      calibrationRegions = [];\n      templateTokens = [];\n      templateBuffer = null;\n      calibrationMode = false;\n      \n      // Reset analysis state\n      resetAnalysisState();\n      \n      // Clear token display\n      tokenSequence.innerHTML = '';\n      \n      // Reset UI\n      recordBtn.disabled = false;\n      stopBtn.disabled = true;\n      playBtn.disabled = true;\n      createTemplateBtn.disabled = true;\n      calibrateBtn.disabled = true;\n      startAnalysisBtn.disabled = true;\n      stopAnalysisBtn.disabled = true;\n      \n      // Hide panels and reset counts\n      tokenContainer.style.display = 'none';\n      calibrationControls.style.display = 'none';\n      document.getElementById('calibrationPanel').style.display = 'none';\n      regionCount.textContent = '0';\n      \n      calibrationInfo.textContent = 'Record audio, then select a template region by dragging on the waveform.';\n      liveActivity.innerHTML = 'Waiting to start analysis...';\n      \n      // Clear diagnostics\n      diagnosticsLog.innerHTML = '';\n      detectionData.innerHTML = '';\n      debugOutput.innerHTML = '';\n      \n      log('App reset');\n    }\n    \n    // Update the debug output \n    function updateDebugOutput() {\n      // Create a formatted summary of the current state for easy copy/paste debugging\n      let output = \"=== THIKR COUNTER DEBUG DATA ===\\n\\n\";\n      \n      // Template info\n      output += \"TEMPLATE INFO:\\n\";\n      output += `--------------\\n`;\n      if (templateTokens.length > 0) {\n        output += `Token count: ${templateTokens.length}\\n`;\n        output += `Token sequence: ${templateTokens.map(t => t.type).join('')}\\n`;\n        \n        // Token type counts\n        const counts = {};\n        templateTokens.forEach(token => {\n          counts[token.type] = (counts[token.type] || 0) + 1;\n        });\n        \n        output += `Token distribution: ${Object.entries(counts)\n          .map(([type, count]) => `${type}:${count} (${Math.round(count/templateTokens.length*100)}%)`)\n          .join(', ')}\\n\\n`;\n          \n        // Detailed token data (first 5 tokens)\n        output += \"FIRST 5 TEMPLATE TOKENS:\\n\";\n        templateTokens.slice(0, 5).forEach((token, i) => {\n          output += `[${i}] Type:${token.type} | RMS:${token.rms.toFixed(3)} | SC:${token.spectralCentroid.toFixed(0)} | ZCR:${token.zcr ? token.zcr.toFixed(3) : 'N/A'}\\n`;\n        });\n      } else {\n        output += \"No template tokens available\\n\";\n      }\n      \n      // Calibration info\n      output += \"\\nCALIBRATION INFO:\\n\";\n      output += `-----------------\\n`;\n      output += `Regions: ${calibrationRegions.length}\\n`;\n      output += `Match threshold: ${(matchThreshold * 100).toFixed(1)}%\\n`;\n      output += `Min confidence: ${(minConfidence * 100).toFixed(1)}%\\n\\n`;\n      \n      // Calibration regions\n      if (calibrationRegions.length > 0) {\n        output += \"CALIBRATION REGIONS:\\n\";\n        calibrationRegions.forEach((region, i) => {\n          const similarity = region.data && region.data.similarity ? \n            (region.data.similarity * 100).toFixed(1) + '%' : 'Not calculated';\n            \n          output += `[${i}] Time: ${region.start.toFixed(2)}s-${region.end.toFixed(2)}s | Duration: ${(region.end - region.start).toFixed(2)}s | Similarity: ${similarity}\\n`;\n          \n          // Add token details if available\n          if (region.data && region.data.tokens && region.data.tokens.length > 0) {\n            const tokens = region.data.tokens;\n            output += `    Tokens: ${tokens.length} | Types: ${tokens.map(t => t.type).join('')}\\n`;\n          }\n        });\n      }\n      \n      // Detection history\n      output += \"\\nDETECTION HISTORY:\\n\";\n      output += `----------------\\n`;\n      if (detectionEvents.length > 0) {\n        detectionEvents.slice(-5).reverse().forEach(event => {\n          output += `[#${event.id}] Time: ${new Date(event.time).toLocaleTimeString()} | Confidence: ${(event.similarity * 100).toFixed(1)}%\\n`;\n          output += `    Tokens: ${event.tokenCount} | Types: ${formatTokenTypeCounts(event.tokenTypes)}\\n`;\n        });\n      } else {\n        output += \"No detections recorded\\n\";\n      }\n      \n      // Update the debug output element\n      debugOutput.textContent = output;\n    }\n    \n    // Copy all diagnostics to clipboard\n    function copyAllDiagnostics() {\n      // Combine all diagnostic data\n      const allData = debugOutput.textContent + \n        \"\\n\\n=== LOG MESSAGES ===\\n\" + \n        diagnosticsLog.textContent;\n      \n      // Copy to clipboard\n      navigator.clipboard.writeText(allData)\n        .then(() => {\n          alert(\"Diagnostic data copied to clipboard!\");\n        })\n        .catch(err => {\n          console.error('Error copying text: ', err);\n          alert(\"Failed to copy. Please select and copy the text manually.\");\n        });\n    }\n    \n    // Utility: Log message to diagnostics box\n    function log(message) {\n      const time = new Date().toLocaleTimeString();\n      diagnosticsLog.innerHTML += `[${time}] ${message}\\n`;\n      diagnosticsLog.scrollTop = diagnosticsLog.scrollHeight;\n      console.log(message); // Also log to console for debugging\n    }\n    \n    // Initialize the app when the page loads\n    window.addEventListener('load', init);\n  </script>\n</body>\n</html>]]]",
      "created_at": "2025-03-23T15:07:05.698000",
      "sequence_order": 1,
      "parent_id": "8ce8a5e1-9a40-4b09-981b-ed80ad12dd80",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "6a6e2537-547e-45cc-bd94-f52866ea19a0",
      "role": "tool",
      "content": "",
      "created_at": "2025-03-23T15:07:10.996575",
      "sequence_order": 2,
      "parent_id": "30cdbf9e-5d59-4315-b588-a60f54ed1790",
      "metadata": {
        "status": "finished_successfully",
        "weight": 0,
        "end_turn": null
      }
    },
    {
      "id": "c26bab6d-f3ae-4cc0-9314-89db97070632",
      "role": "assistant",
      "content": "Below is a walkthrough of **why** you can’t select multiple regions for calibration and **how** to fix it. After that, I’ll give you the revised code in two parts:\n\n1. The **key snippet** that needs changing.  \n2. The **full file** with the fix applied.\n\n---\n\n## **Why You Can’t Select Other Regions**\n\nInside your `wavesurfer.on('region-created', ...)` listener, you have this logic:\n\n```js\nwavesurfer.on('region-created', function(region) {\n  if (calibrationMode) {\n    // ... add calibration region ...\n    calibrationMode = false;  // <-- THIS line forces only one region in calibration mode\n  } else if (!templateRegion) {\n    // ... create template region ...\n  }\n});\n```\n\n**Problem**: You set `calibrationMode = false` immediately after creating **one** calibration region. This means you can only select **one** calibration region at a time unless you keep clicking “Select Calibration Region” again for each new region. If your goal is to allow multiple calibration regions in one continuous “drag and drop” session, you need to remove (or alter) that line so that `calibrationMode` stays `true` until you decide to turn it off.\n\n### How to Fix It\n\n1. Remove `calibrationMode = false` so that you can select multiple calibration regions in a single session.  \n2. (Optional) Provide a UI toggle or logic that sets `calibrationMode = false` when you are truly finished adding all the calibration regions you need.\n\n---\n\n## **1) Key Snippet Fix**\n\nBelow is the relevant section in smaller form. I’ll show only the part around the `region-created` listener, with the fix (removing `calibrationMode = false` inside that block). Also note the added comment at the bottom about turning off calibration mode when you’re done.\n\n```html\n<script>\n  // ...\n\n  wavesurfer.on('region-created', function(region) {\n    // Handle new region depending on the current mode\n    if (calibrationMode) {\n      // Calibration region\n      region.id = 'calibration-' + Date.now();\n      region.color = 'rgba(0, 200, 83, 0.3)'; // Green\n      region.update();\n      \n      // Store metadata with the region\n      region.data = {\n        tokens: [],\n        similarity: null,\n        features: null\n      };\n      \n      calibrationRegions.push(region);\n      updateRegionCount();\n      \n      log(`Calibration region created: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n      \n      // Add immediately to the region list UI\n      addRegionToList(region);\n      \n      // Enable calibration if we have at least one region\n      if (calibrationRegions.length > 0) {\n        calibrateBtn.disabled = false;\n      }\n      \n      // --- REMOVE THIS LINE ---\n      // calibrationMode = false; \n      // ------------------------\n      \n      // Show calibration panel if first region is added\n      document.getElementById('calibrationPanel').style.display = 'block';\n      \n    } else if (!templateRegion) {\n      // First region is template\n      region.id = 'template-' + Date.now();\n      log(`Template region created: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n    }\n  });\n\n  // ...\n  \n  // Example: a button or place in code where you eventually turn calibrationMode off:\n  // function finishSelectingRegions() {\n  //   calibrationMode = false;\n  //   log('Finished selecting calibration regions.');\n  // }\n  \n  // ...\n</script>\n```\n\nWith that change, you won’t be forced out of calibration mode after the first region. You can keep dragging new regions as needed. If you **want** the user to click “Select Calibration Region” every time they add a single region, that’s fine—but you’d leave `calibrationMode = false` in place. It just depends on your workflow.\n\n---\n\n## **2) Full Fixed File**\n\nBelow is the entire file with that **one** line removed (and a small comment added). Everything else is the same. I’ve added `<!-- FIX APPLIED HERE -->` near the change so it’s easy to spot:\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0\">\n  <title>Thikr Counter - Visual Pattern Recognition</title>\n  <script src=\"https://unpkg.com/wavesurfer.js@6.6.3\"></script>\n  <script src=\"https://unpkg.com/wavesurfer.js@6.6.3/dist/plugin/wavesurfer.regions.min.js\"></script>\n  <script src=\"https://unpkg.com/meyda@5.6.1/dist/web/meyda.min.js\"></script>\n  <style>\n    body {\n      font-family: system-ui, sans-serif;\n      max-width: 1000px;\n      margin: 0 auto;\n      padding: 20px;\n      background-color: #f5f5f5;\n    }\n    \n    .panel {\n      background: white;\n      border-radius: 8px;\n      padding: 20px;\n      margin-bottom: 20px;\n      box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n    }\n    \n    button {\n      background-color: #4c6ef5;\n      color: white;\n      border: none;\n      padding: 8px 16px;\n      margin: 5px;\n      border-radius: 4px;\n      cursor: pointer;\n      font-weight: 500;\n    }\n    \n    button:disabled {\n      background-color: #a5b4fc;\n      cursor: not-allowed;\n    }\n    \n    .waveform {\n      border: 1px solid #e9ecef;\n      border-radius: 4px;\n      overflow: hidden;\n      margin: 10px 0;\n      height: 128px; /* Explicitly set height */\n      width: 100%;\n      background-color: #f8f9fa;\n      position: relative;\n    }\n    \n    #counter {\n      font-size: 64px;\n      font-weight: bold;\n      text-align: center;\n      color: #4c6ef5;\n      padding: 20px;\n    }\n    \n    #confidenceDisplay {\n      height: 100px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      margin: 10px 0;\n      position: relative;\n    }\n    \n    .progress-bar {\n      position: absolute;\n      bottom: 0;\n      left: 0;\n      width: 100%;\n      background-color: #4c6ef5;\n      transition: height 0.1s;\n      height: 0%;\n    }\n    \n    .threshold-line {\n      position: absolute;\n      width: 100%;\n      height: 2px;\n      background-color: #fa5252;\n      z-index: 2;\n      bottom: 75%; /* Default position */\n    }\n    \n    #tokenContainer {\n      margin-top: 20px;\n    }\n    \n    #tokenSequence {\n      display: flex;\n      flex-wrap: wrap;\n      padding: 20px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      min-height: 80px;\n      margin: 10px 0;\n      position: relative;\n    }\n    \n    .token {\n      display: inline-flex;\n      align-items: center;\n      justify-content: center;\n      width: 50px;\n      height: 50px;\n      margin: 5px;\n      border-radius: 4px;\n      font-weight: bold;\n      font-size: 20px;\n      transition: all 0.3s ease;\n      position: relative;\n      box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n    }\n    \n    .token-label {\n      position: absolute;\n      top: -15px;\n      font-size: 10px;\n      color: #495057;\n    }\n    \n    #legend {\n      display: flex;\n      flex-wrap: wrap;\n      gap: 10px;\n      padding: 10px;\n      margin-top: 10px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .legend-item {\n      display: flex;\n      align-items: center;\n      margin-right: 15px;\n    }\n    \n    .legend-color {\n      width: 20px;\n      height: 20px;\n      border-radius: 3px;\n      margin-right: 5px;\n    }\n    \n    #liveActivity {\n      margin-top: 10px;\n      padding: 10px;\n      background-color: #e9ecef;\n      border-radius: 4px;\n      font-family: monospace;\n      font-size: 12px;\n      min-height: 60px;\n      overflow-y: auto;\n    }\n    \n    #diagnostics {\n      height: 200px;\n      overflow-y: auto;\n      font-family: monospace;\n      font-size: 12px;\n      background-color: #212529;\n      color: #f8f9fa;\n      padding: 10px;\n      border-radius: 4px;\n      white-space: pre-wrap;\n    }\n    \n    #calibrationInfo {\n      margin-top: 10px;\n      padding: 10px;\n      background-color: #e9ecef;\n      border-radius: 4px;\n      font-size: 14px;\n    }\n    \n    .detection-flash {\n      position: absolute;\n      width: 100%;\n      height: 100%;\n      background-color: rgba(76, 175, 80, 0.3);\n      top: 0;\n      left: 0;\n      z-index: 10;\n      animation: flash-animation 1.5s forwards;\n      pointer-events: none;\n    }\n    \n    .confidence-marker {\n      position: absolute;\n      height: 10px;\n      width: 10px;\n      border-radius: 50%;\n      background-color: green;\n      transform: translate(-50%, -50%);\n      z-index: 3;\n    }\n    \n    @keyframes flash-animation {\n      0% { opacity: 0.8; }\n      100% { opacity: 0; }\n    }\n    \n    @keyframes wave-animation {\n      0% { transform: scale(1); opacity: 0.7; }\n      50% { transform: scale(1.4); opacity: 1; }\n      100% { transform: scale(1); opacity: 0.7; }\n    }\n    \n    .wave-effect {\n      animation: wave-animation 0.5s ease;\n    }\n    \n    .control-group {\n      display: flex;\n      flex-wrap: wrap;\n      gap: 5px;\n      margin-bottom: 10px;\n    }\n    \n    h2 {\n      margin-top: 0;\n      color: #343a40;\n    }\n    \n    label {\n      font-weight: bold;\n      display: block;\n      margin-bottom: 5px;\n    }\n    \n    .instruction {\n      font-style: italic;\n      color: #6c757d;\n      margin-bottom: 10px;\n    }\n    \n    .region-count {\n      display: inline-block;\n      background-color: #4c6ef5;\n      color: white;\n      border-radius: 50%;\n      width: 24px;\n      height: 24px;\n      text-align: center;\n      line-height: 24px;\n      font-size: 14px;\n      margin-left: 10px;\n    }\n    \n    /* Enhanced Calibration Styles */\n    .calibration-panel {\n      margin-top: 20px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      padding: 15px;\n    }\n    \n    .region-list {\n      max-height: 300px;\n      overflow-y: auto;\n      margin: 10px 0;\n    }\n    \n    .region-item {\n      display: flex;\n      justify-content: space-between;\n      align-items: center;\n      padding: 8px 10px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      margin-bottom: 8px;\n      cursor: pointer;\n      transition: background-color 0.2s;\n    }\n    \n    .region-item:hover {\n      background-color: #e9ecef;\n    }\n    \n    .region-item.selected {\n      background-color: #cfe8ff;\n      border-color: #4c6ef5;\n    }\n    \n    .region-item .region-info {\n      flex-grow: 1;\n    }\n    \n    .region-item .region-actions {\n      display: flex;\n      gap: 5px;\n    }\n    \n    .region-item .similarity-score {\n      display: inline-block;\n      margin-left: 10px;\n      padding: 2px 6px;\n      background-color: #4c6ef5;\n      color: white;\n      border-radius: 10px;\n      font-size: 12px;\n    }\n    \n    /* Feature comparison visualization */\n    .feature-comparison {\n      margin-top: 15px;\n      padding: 10px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .comparison-chart {\n      height: 200px;\n      position: relative;\n      margin-top: 10px;\n      border-bottom: 1px solid #dee2e6;\n      border-left: 1px solid #dee2e6;\n    }\n    \n    .feature-series {\n      position: absolute;\n      bottom: 0;\n      left: 0;\n      display: flex;\n      align-items: flex-end;\n      height: 100%;\n      width: 100%;\n    }\n    \n    .feature-point {\n      flex: 1;\n      margin: 0 1px;\n      position: relative;\n    }\n    \n    .feature-bar {\n      width: 100%;\n      background-color: #4c6ef5;\n      position: absolute;\n      bottom: 0;\n    }\n    \n    .template-bar {\n      background-color: rgba(255, 86, 0, 0.6);\n    }\n    \n    .calibration-bar {\n      background-color: rgba(0, 200, 83, 0.6);\n    }\n    \n    .selected-region-bar {\n      background-color: rgba(76, 110, 245, 0.8);\n    }\n    \n    .feature-type-selector {\n      display: flex;\n      gap: 10px;\n      margin-bottom: 10px;\n    }\n    \n    .feature-type-selector label {\n      margin-bottom: 0;\n      font-weight: normal;\n    }\n    \n    .calibration-summary {\n      display: flex;\n      flex-wrap: wrap;\n      gap: 10px;\n      margin-top: 15px;\n    }\n    \n    .summary-card {\n      flex: 1;\n      min-width: 120px;\n      padding: 10px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      text-align: center;\n    }\n    \n    .summary-value {\n      font-size: 24px;\n      font-weight: bold;\n      margin: 5px 0;\n    }\n    \n    .summary-label {\n      font-size: 12px;\n      color: #6c757d;\n    }\n    \n    /* Threshold adjustment sliders */\n    .threshold-adjustment {\n      margin-top: 15px;\n      padding: 15px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .slider-container {\n      display: flex;\n      align-items: center;\n      margin-bottom: 10px;\n    }\n    \n    .slider-container label {\n      width: 150px;\n      margin-bottom: 0;\n    }\n    \n    .slider-container input[type=\"range\"] {\n      flex-grow: 1;\n      margin-right: 10px;\n    }\n    \n    .slider-value {\n      width: 40px;\n      text-align: right;\n    }\n    \n    /* Enhanced diagnostics styles */\n    .token-debug-info {\n      position: absolute;\n      bottom: -25px;\n      font-size: 9px;\n      color: #6c757d;\n      left: 0;\n      right: 0;\n      text-align: center;\n      white-space: nowrap;\n      overflow: hidden;\n      text-overflow: ellipsis;\n    }\n    \n    .diagnostic-controls {\n      margin-bottom: 10px;\n      display: flex;\n      gap: 10px;\n      align-items: center;\n    }\n    \n    .copy-diagnostics {\n      background-color: #212529;\n      color: white;\n      border: 1px solid #495057;\n      padding: 5px 10px;\n      border-radius: 4px;\n      cursor: pointer;\n      font-size: 12px;\n    }\n    \n    .diagnostics-options label {\n      display: inline-flex;\n      align-items: center;\n      margin-right: 10px;\n      font-weight: normal;\n      font-size: 12px;\n    }\n    \n    .diagnostic-section {\n      margin-top: 10px;\n      padding: 10px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      font-family: monospace;\n      font-size: 12px;\n    }\n    \n    #detectionData {\n      max-height: 150px;\n      overflow-y: auto;\n    }\n    \n    /* Visual debugging elements */\n    .visual-debug {\n      position: absolute;\n      bottom: -30px;\n      left: 0;\n      right: 0;\n      display: flex;\n      height: 20px;\n      justify-content: space-between;\n    }\n    \n    .debug-marker {\n      width: 2px;\n      position: absolute;\n      bottom: 0;\n      background-color: red;\n    }\n    \n    #debugOutput {\n      font-family: monospace;\n      white-space: pre;\n      font-size: 12px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      padding: 10px;\n      margin-top: 10px;\n      overflow-x: auto;\n    }\n    \n    .debug-help {\n      font-size: 12px;\n      color: #6c757d;\n      margin-top: 5px;\n      margin-bottom: 10px;\n      font-style: italic;\n    }\n  </style>\n</head>\n<body>\n  <h1>Thikr Counter - Visual Pattern Recognition</h1>\n  \n  <div class=\"panel\">\n    <h2>1. Record & Extract Template</h2>\n    <div class=\"instruction\">Record your thikr, then use your mouse to drag-select the region containing a single complete thikr recitation.</div>\n    <div class=\"control-group\">\n      <button id=\"recordBtn\">Record Audio</button>\n      <button id=\"stopBtn\" disabled>Stop Recording</button>\n      <button id=\"playBtn\" disabled>Play Audio</button>\n      <button id=\"resetBtn\">Reset</button>\n    </div>\n    \n    <div id=\"counter\">0</div>\n    \n    <div id=\"waveformContainer\">\n      <label>Waveform Display</label>\n      <div id=\"waveform\" class=\"waveform\"></div>\n      <div class=\"control-group\">\n        <button id=\"createTemplateBtn\" disabled>Extract Template Tokens</button>\n        <div id=\"calibrationControls\" style=\"display: none;\">\n          <button id=\"selectCalibrationBtn\">Add Calibration Region</button>\n          <span id=\"regionCount\" class=\"region-count\">0</span>\n          <button id=\"calibrateBtn\" disabled>Run Calibration</button>\n        </div>\n      </div>\n    </div>\n    \n    <div id=\"calibrationInfo\">\n      Record audio, then select a template region by dragging on the waveform.\n    </div>\n    \n    <!-- New Calibration Management UI -->\n    <div id=\"calibrationPanel\" class=\"calibration-panel\" style=\"display: none;\">\n      <h3>Calibration Regions</h3>\n      <p class=\"instruction\">Manage your calibration regions. Click on a region to select and view its features.</p>\n      \n      <!-- Region List -->\n      <div id=\"regionList\" class=\"region-list\">\n        <!-- Region items will be added here dynamically -->\n      </div>\n      \n      <!-- Feature Comparison Visualization -->\n      <div class=\"feature-comparison\">\n        <div class=\"feature-type-selector\">\n          <label><input type=\"radio\" name=\"featureType\" value=\"energy\" checked> Energy (RMS)</label>\n          <label><input type=\"radio\" name=\"featureType\" value=\"centroid\"> Spectral Centroid</label>\n          <label><input type=\"radio\" name=\"featureType\" value=\"zcr\"> Zero Crossing Rate</label>\n          <label><input type=\"radio\" name=\"featureType\" value=\"tokens\"> Token Types</label>\n        </div>\n        \n        <div id=\"comparisonChart\" class=\"comparison-chart\">\n          <!-- Feature visualization will be generated here -->\n        </div>\n      </div>\n      \n      <!-- Calibration Summary -->\n      <div class=\"calibration-summary\">\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"avgSimilarity\">-</div>\n          <div class=\"summary-label\">Average Similarity</div>\n        </div>\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"minSimilarity\">-</div>\n          <div class=\"summary-label\">Min Similarity</div>\n        </div>\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"maxSimilarity\">-</div>\n          <div class=\"summary-label\">Max Similarity</div>\n        </div>\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"stdDevSimilarity\">-</div>\n          <div class=\"summary-label\">Std Deviation</div>\n        </div>\n      </div>\n      \n      <!-- Threshold Adjustment -->\n      <div class=\"threshold-adjustment\">\n        <h4>Threshold Adjustments</h4>\n        <div class=\"slider-container\">\n          <label for=\"matchThresholdSlider\">Match Threshold:</label>\n          <input type=\"range\" id=\"matchThresholdSlider\" min=\"0\" max=\"100\" value=\"75\">\n          <span class=\"slider-value\" id=\"matchThresholdValue\">75%</span>\n        </div>\n        <div class=\"slider-container\">\n          <label for=\"minConfidenceSlider\">Min Confidence:</label>\n          <input type=\"range\" id=\"minConfidenceSlider\" min=\"0\" max=\"100\" value=\"30\">\n          <span class=\"slider-value\" id=\"minConfidenceValue\">30%</span>\n        </div>\n      </div>\n    </div>\n  </div>\n  \n  <div class=\"panel\" id=\"tokenContainer\" style=\"display: none;\">\n    <h2>2. Token Visualization</h2>\n    <div class=\"instruction\">These tokens represent the distinctive audio patterns in your thikr. During detection, they will grow and change color as matches are found.</div>\n    \n    <div id=\"legend\">\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #4dabf7;\"></div>\n        <span>A: Energy Rise (vowel onset)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #f783ac;\"></div>\n        <span>B: Energy Fall (syllable end)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #8ce99a;\"></div>\n        <span>C: High Frequency (consonants)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #ffd43b;\"></div>\n        <span>D: Low Frequency (low vowels)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #a5d8ff;\"></div>\n        <span>E: Transition</span>\n      </div>\n    </div>\n    \n    <div id=\"tokenSequence\"></div>\n  </div>\n  \n  <div class=\"panel\">\n    <h2>3. Live Pattern Detection</h2>\n    <div class=\"instruction\">Start analysis and recite your thikr. The system will detect patterns and show confidence levels in real-time.</div>\n    \n    <div class=\"control-group\">\n      <button id=\"startAnalysisBtn\" disabled>Start Analysis</button>\n      <button id=\"stopAnalysisBtn\" disabled>Stop Analysis</button>\n    </div>\n    \n    <label>Pattern Match Confidence</label>\n    <div id=\"confidenceDisplay\">\n      <div class=\"threshold-line\"></div>\n      <div class=\"progress-bar\"></div>\n    </div>\n    \n    <label>Live Activity</label>\n    <div id=\"liveActivity\">Waiting to start analysis...</div>\n  </div>\n  \n  <!-- Enhanced Diagnostics Panel -->\n  <div class=\"panel\">\n    <h2>Diagnostics</h2>\n    <div class=\"debug-help\">\n      This panel provides detailed information for debugging. All data can be copied and pasted to share with developers.\n    </div>\n    \n    <div class=\"diagnostic-controls\">\n      <button class=\"copy-diagnostics\" id=\"copyDiagnosticsBtn\">Copy All Diagnostics</button>\n      <div class=\"diagnostics-options\">\n        <label><input type=\"checkbox\" id=\"verboseLogging\" checked> Verbose Logging</label>\n        <label><input type=\"checkbox\" id=\"showFeatureValues\" checked> Show Feature Values</label>\n      </div>\n    </div>\n    \n    <div id=\"diagnostics\"></div>\n    \n    <!-- Pattern Detection Data -->\n    <h3>Pattern Detection Data</h3>\n    <div class=\"debug-help\">\n      The most recent pattern detection events with detailed metrics. This data is useful for troubleshooting false positives/negatives.\n    </div>\n    <div id=\"detectionData\" class=\"diagnostic-section\"></div>\n    \n    <!-- Debug Output for Copy/Paste -->\n    <h3>Recognition Debug Data</h3>\n    <div class=\"debug-help\">\n      This formatted data can be copied and shared to help debug the recognition process.\n    </div>\n    <pre id=\"debugOutput\"></pre>\n  </div>\n\n  <script>\n    // Global variables\n    let audioContext;\n    let wavesurfer;\n    let recorder;\n    let recordedChunks = [];\n    let isRecording = false;\n    let meydaAnalyzer = null;\n    let calibrationMode = false;\n    \n    // Audio processing configuration\n    const frameSize = 2048;\n    const hopSize = 1024;\n    \n    // Token types and colors\n    const tokenTypes = ['A', 'B', 'C', 'D', 'E']; // Different audio characteristics\n    const tokenColors = {\n      'A': '#4dabf7', // Blue - Energy rise\n      'B': '#f783ac', // Pink - Energy fall\n      'C': '#8ce99a', // Green - Spectral high\n      'D': '#ffd43b', // Yellow - Spectral low\n      'E': '#a5d8ff'  // Light blue - Background\n    };\n    \n    // Token type descriptions\n    const tokenDescriptions = {\n      'A': 'Energy Rise (vowel onset)',\n      'B': 'Energy Fall (syllable end)',\n      'C': 'High Frequency (consonants)',\n      'D': 'Low Frequency (low vowels)',\n      'E': 'Transition'\n    };\n    \n    // Pattern recognition parameters (will be auto-calibrated)\n    let matchThreshold = 0.75;\n    let minConfidence = 0.3;\n    \n    // Template data\n    let templateRegion = null;\n    let calibrationRegions = [];\n    let templateTokens = [];\n    let templateBuffer = null;\n    \n    // Detection state\n    let detectionCount = 0;\n    let isAnalyzing = false;\n    let currentTokens = [];\n    let liveTokenBuffer = [];\n    let confidenceHistory = [];\n    let lastDetectionTime = 0;\n    let lastTokenTime = 0;\n    let activeTokenTypes = new Set();\n    \n    // Enhanced calibration variables\n    let calibrationResults = [];\n    let selectedRegionId = null;\n    let regionFeatures = {};\n    let selectedFeatureType = 'energy';\n    \n    // Diagnostic logging\n    let detectionEvents = [];\n    let verboseLogging = true;\n    let showFeatureValues = true;\n    \n    // DOM elements\n    const recordBtn = document.getElementById('recordBtn');\n    const stopBtn = document.getElementById('stopBtn');\n    const playBtn = document.getElementById('playBtn');\n    const resetBtn = document.getElementById('resetBtn');\n    const createTemplateBtn = document.getElementById('createTemplateBtn');\n    const selectCalibrationBtn = document.getElementById('selectCalibrationBtn');\n    const calibrateBtn = document.getElementById('calibrateBtn');\n    const startAnalysisBtn = document.getElementById('startAnalysisBtn');\n    const stopAnalysisBtn = document.getElementById('stopAnalysisBtn');\n    const progressBar = document.querySelector('.progress-bar');\n    const thresholdLine = document.querySelector('.threshold-line');\n    const diagnosticsLog = document.getElementById('diagnostics');\n    const calibrationInfo = document.getElementById('calibrationInfo');\n    const counterDisplay = document.getElementById('counter');\n    const tokenSequence = document.getElementById('tokenSequence');\n    const liveActivity = document.getElementById('liveActivity');\n    const regionCount = document.getElementById('regionCount');\n    const calibrationControls = document.getElementById('calibrationControls');\n    const tokenContainer = document.getElementById('tokenContainer');\n    const detectionData = document.getElementById('detectionData');\n    const debugOutput = document.getElementById('debugOutput');\n    const copyDiagnosticsBtn = document.getElementById('copyDiagnosticsBtn');\n    const verboseLoggingCheckbox = document.getElementById('verboseLogging');\n    const showFeatureValuesCheckbox = document.getElementById('showFeatureValues');\n    \n    // Initialize the app\n    function init() {\n      initWavesurfer();\n      initAudioContext();\n      \n      // Setup event listeners\n      recordBtn.addEventListener('click', startRecording);\n      stopBtn.addEventListener('click', stopRecording);\n      playBtn.addEventListener('click', () => wavesurfer.playPause());\n      resetBtn.addEventListener('click', resetApp);\n      createTemplateBtn.addEventListener('click', createTemplate);\n      selectCalibrationBtn.addEventListener('click', enhancedSelectCalibrationRegion);\n      calibrateBtn.addEventListener('click', enhancedCalibrate);\n      startAnalysisBtn.addEventListener('click', startAnalysis);\n      stopAnalysisBtn.addEventListener('click', stopAnalysis);\n      \n      // Set threshold line position\n      updateThresholdLine();\n      \n      // Setup diagnostic controls\n      copyDiagnosticsBtn.addEventListener('click', copyAllDiagnostics);\n      verboseLoggingCheckbox.addEventListener('change', (e) => {\n        verboseLogging = e.target.checked;\n      });\n      showFeatureValuesCheckbox.addEventListener('change', (e) => {\n        showFeatureValues = e.target.checked;\n      });\n      \n      // Initialize enhanced calibration\n      initEnhancedCalibration();\n      \n      log('App initialized. Click \"Record Audio\" to begin.');\n    }\n    \n    // Initialize WaveSurfer\n    function initWavesurfer() {\n      wavesurfer = WaveSurfer.create({\n        container: '#waveform',\n        waveColor: '#4c6ef5',\n        progressColor: '#364fc7',\n        cursorColor: '#fa5252',\n        height: 128,\n        normalize: true,\n        plugins: [\n          WaveSurfer.regions.create({\n            dragSelection: true,\n            color: 'rgba(255, 86, 0, 0.2)',\n          })\n        ]\n      });\n      \n      wavesurfer.on('ready', function() {\n        playBtn.disabled = false;\n        createTemplateBtn.disabled = false;\n        log('Waveform ready - audio loaded successfully');\n      });\n      \n      wavesurfer.on('error', function(err) {\n        log('WaveSurfer error: ' + err);\n      });\n      \n      // Handle region creation\n      wavesurfer.on('region-created', function(region) {\n        // Handle new region depending on the current mode\n        if (calibrationMode) {\n          // Calibration region\n          region.id = 'calibration-' + Date.now();\n          region.color = 'rgba(0, 200, 83, 0.3)'; // Green\n          region.update();\n          \n          // Store metadata with the region\n          region.data = {\n            tokens: [],\n            similarity: null,\n            features: null\n          };\n          \n          calibrationRegions.push(region);\n          updateRegionCount();\n          \n          log(`Calibration region created: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n          \n          // Add immediately to the region list UI\n          addRegionToList(region);\n          \n          // Enable calibration if we have at least one region\n          if (calibrationRegions.length > 0) {\n            calibrateBtn.disabled = false;\n          }\n          \n          // FIX APPLIED HERE: Remove the line that immediately disables calibrationMode\n          // calibrationMode = false;  <-- removed\n          \n          // Show calibration panel if first region is added\n          document.getElementById('calibrationPanel').style.display = 'block';\n          \n        } else if (!templateRegion) {\n          // First region is template\n          region.id = 'template-' + Date.now();\n          log(`Template region created: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n        }\n      });\n      \n      // Handle region updates\n      wavesurfer.on('region-update-end', function(region) {\n        log(`Region updated: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n      });\n    }\n    \n    // Initialize Audio Context\n    function initAudioContext() {\n      audioContext = new (window.AudioContext || window.webkitAudioContext)();\n    }\n    \n    // Initialize enhanced calibration\n    function initEnhancedCalibration() {\n      // Add event listeners for the feature type selector\n      document.querySelectorAll('input[name=\"featureType\"]').forEach(radio => {\n        radio.addEventListener('change', event => {\n          selectedFeatureType = event.target.value;\n          updateFeatureComparison();\n        });\n      });\n      \n      // Add event listeners for threshold sliders\n      const matchThresholdSlider = document.getElementById('matchThresholdSlider');\n      const minConfidenceSlider = document.getElementById('minConfidenceSlider');\n      \n      matchThresholdSlider.addEventListener('input', function() {\n        const value = this.value / 100;\n        document.getElementById('matchThresholdValue').textContent = `${this.value}%`;\n        matchThreshold = value;\n        updateThresholdLine();\n      });\n      \n      minConfidenceSlider.addEventListener('input', function() {\n        const value = this.value / 100;\n        document.getElementById('minConfidenceValue').textContent = `${this.value}%`;\n        minConfidence = value;\n      });\n    }\n    \n    // Start recording audio\n    async function startRecording() {\n      if (isRecording) return;\n      \n      try {\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        recorder = new MediaRecorder(stream);\n        \n        recordedChunks = [];\n        isRecording = true;\n        \n        recordBtn.disabled = true;\n        stopBtn.disabled = false;\n        \n        // Handle data available\n        recorder.ondataavailable = function(e) {\n          recordedChunks.push(e.data);\n        };\n        \n        // Handle recording stop\n        recorder.onstop = function() {\n          isRecording = false;\n          \n          // Create audio blob and load into wavesurfer\n          const blob = new Blob(recordedChunks, { type: 'audio/webm' });\n          const url = URL.createObjectURL(blob);\n          wavesurfer.load(url);\n          \n          // Clean up\n          stream.getTracks().forEach(track => track.stop());\n          \n          log('Recording loaded into waveform display - drag to select a region');\n        };\n        \n        // Start recording\n        recorder.start();\n        log('Recording started...');\n        \n      } catch (err) {\n        console.error('Error accessing microphone:', err);\n        log('Error: ' + err.message);\n      }\n    }\n    \n    // Stop recording\n    function stopRecording() {\n      if (recorder && isRecording) {\n        recorder.stop();\n        recordBtn.disabled = false;\n        stopBtn.disabled = true;\n        log('Recording stopped');\n      }\n    }\n    \n    // Create template from selected region\n    async function createTemplate() {\n      // Check if any regions exist\n      const regions = Object.values(wavesurfer.regions.list);\n      if (regions.length === 0) {\n        log('Please select a region first by dragging on the waveform');\n        return;\n      }\n      \n      // Get the first region as template\n      templateRegion = regions[0];\n      \n      // Save region bounds before clearing\n      const templateStart = templateRegion.start;\n      const templateEnd = templateRegion.end;\n      \n      // Clear all regions\n      wavesurfer.clearRegions();\n      \n      // Recreate template region with fixed color\n      templateRegion = wavesurfer.addRegion({\n        id: 'template-' + Date.now(),\n        start: templateStart,\n        end: templateEnd,\n        color: 'rgba(255, 86, 0, 0.4)', // Orange for template\n        drag: false,\n        resize: false\n      });\n      \n      // Initialize data object for the template region\n      templateRegion.data = {\n        tokens: [],\n        features: null\n      };\n      \n      log(`Creating template from region: ${templateRegion.start.toFixed(2)}s - ${templateRegion.end.toFixed(2)}s`);\n      \n      // Extract audio from region\n      const audioBuffer = await extractRegionAudio(templateRegion);\n      templateBuffer = audioBuffer;\n      \n      if (!audioBuffer) {\n        log('Failed to extract audio from region');\n        return;\n      }\n      \n      // Extract frames for visualization\n      const frames = await extractFeatureFrames(audioBuffer);\n      templateRegion.data.features = frames;\n      \n      // Extract tokens from audio\n      const tokens = await extractTokensFromBuffer(audioBuffer);\n      templateTokens = tokens;\n      templateRegion.data.tokens = tokens;\n      \n      log(`Extracted ${tokens.length} tokens from template`);\n      \n      // Generate debug output\n      updateDebugOutput();\n      \n      // Display template tokens\n      displayTemplateTokens();\n      \n      // Show calibration controls\n      calibrationControls.style.display = 'inline-block';\n      \n      // Update UI\n      createTemplateBtn.disabled = true;\n      calibrationInfo.innerHTML = `\n        <strong>Template extracted:</strong> ${templateTokens.length} tokens from region ${templateRegion.start.toFixed(2)}s - ${templateRegion.end.toFixed(2)}s. \n        <br>Now add calibration regions by clicking \"Select Calibration Region\" and selecting other instances of the same thikr.\n      `;\n      \n      // Show token container\n      tokenContainer.style.display = 'block';\n    }\n    \n    // Select calibration region\n    function enhancedSelectCalibrationRegion() {\n      calibrationMode = true;\n      log('Click and drag on the waveform to select another instance of the same thikr pattern.');\n    }\n    \n    // Add a region to the UI list\n    function addRegionToList(region) {\n      const regionList = document.getElementById('regionList');\n      \n      // Create region item element\n      const regionItem = document.createElement('div');\n      regionItem.className = 'region-item';\n      regionItem.id = `region-item-${region.id}`;\n      regionItem.dataset.regionId = region.id;\n      \n      // Create region info\n      const regionInfo = document.createElement('div');\n      regionInfo.className = 'region-info';\n      regionInfo.textContent = `Region ${calibrationRegions.length}: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`;\n      \n      // Create similarity score display (initially empty)\n      const similarityScore = document.createElement('div');\n      similarityScore.className = 'similarity-score';\n      similarityScore.textContent = '...';\n      \n      // Create region actions\n      const regionActions = document.createElement('div');\n      regionActions.className = 'region-actions';\n      \n      const playButton = document.createElement('button');\n      playButton.className = 'play-region';\n      playButton.textContent = '▶';\n      playButton.addEventListener('click', (e) => {\n        e.stopPropagation();\n        playRegion(region);\n      });\n      \n      const removeButton = document.createElement('button');\n      removeButton.className = 'remove-region';\n      removeButton.textContent = '✕';\n      removeButton.addEventListener('click', (e) => {\n        e.stopPropagation();\n        removeCalibrationRegion(region.id);\n      });\n      \n      // Assemble the region item\n      regionActions.appendChild(playButton);\n      regionActions.appendChild(removeButton);\n      regionItem.appendChild(regionInfo);\n      regionItem.appendChild(similarityScore);\n      regionItem.appendChild(regionActions);\n      \n      // Add click event to select this region\n      regionItem.addEventListener('click', () => {\n        selectRegion(region.id);\n      });\n      \n      // Add to the list\n      regionList.appendChild(regionItem);\n    }\n    \n    // Play a specific region\n    function playRegion(region) {\n      // Set playback to start at region start\n      wavesurfer.setCurrentTime(region.start);\n      \n      // Play for the duration of the region\n      wavesurfer.play(region.start, region.end);\n      \n      log(`Playing region: ${region.start.toFixed(2)}s to ${region.end.toFixed(2)}s`);\n    }\n    \n    // Remove a calibration region\n    function removeCalibrationRegion(regionId) {\n      // Find the region in the list\n      const regionIndex = calibrationRegions.findIndex(r => r.id === regionId);\n      \n      if (regionIndex !== -1) {\n        // Remove the region from WaveSurfer\n        calibrationRegions[regionIndex].remove();\n        \n        // Remove from our array\n        calibrationRegions.splice(regionIndex, 1);\n        \n        // Remove from UI\n        const regionItem = document.getElementById(`region-item-${regionId}`);\n        if (regionItem) {\n          regionItem.remove();\n        }\n        \n        // Update region count\n        updateRegionCount();\n        \n        // Update calibrate button state\n        calibrateBtn.disabled = calibrationRegions.length === 0;\n        \n        // If selected region was removed, clear selection\n        if (selectedRegionId === regionId) {\n          selectedRegionId = null;\n          updateFeatureComparison();\n        }\n        \n        log(`Calibration region removed (${calibrationRegions.length} remaining)`);\n      }\n    }\n    \n    // Update the region counter display\n    function updateRegionCount() {\n      regionCount.textContent = calibrationRegions.length;\n    }\n    \n    // Select a region for inspection\n    function selectRegion(regionId) {\n      // Deselect previous region in UI\n      if (selectedRegionId) {\n        const prevSelected = document.getElementById(`region-item-${selectedRegionId}`);\n        if (prevSelected) {\n          prevSelected.classList.remove('selected');\n        }\n      }\n      \n      // Update selection\n      selectedRegionId = regionId;\n      \n      // Update UI selection\n      const selectedItem = document.getElementById(`region-item-${regionId}`);\n      if (selectedItem) {\n        selectedItem.classList.add('selected');\n      }\n      \n      // Update the feature comparison visualization\n      updateFeatureComparison();\n      \n      // Highlight the region in the waveform\n      calibrationRegions.forEach(region => {\n        region.color = region.id === regionId \n          ? 'rgba(76, 110, 245, 0.5)' // Highlight selected\n          : 'rgba(0, 200, 83, 0.3)';  // Default green\n        region.update();\n      });\n      \n      log(`Selected calibration region: ${regionId}`);\n    }\n    \n    // Extract audio buffer from a region\n    async function extractRegionAudio(region) {\n      if (!region || !wavesurfer || !wavesurfer.backend.buffer) {\n        log('Error: Missing region or audio data');\n        return null;\n      }\n      \n      const sourceBuffer = wavesurfer.backend.buffer;\n      const startSample = Math.floor(region.start * sourceBuffer.sampleRate);\n      const endSample = Math.floor(region.end * sourceBuffer.sampleRate);\n      \n      if (startSample >= endSample || startSample < 0 || endSample > sourceBuffer.length) {\n        log('Error: Invalid region boundaries');\n        return null;\n      }\n      \n      // Create a new buffer for the region\n      const regionBuffer = audioContext.createBuffer(\n        sourceBuffer.numberOfChannels,\n        endSample - startSample,\n        sourceBuffer.sampleRate\n      );\n      \n      // Copy audio data to region buffer\n      for (let channel = 0; channel < sourceBuffer.numberOfChannels; channel++) {\n        const sourceData = sourceBuffer.getChannelData(channel);\n        const regionData = regionBuffer.getChannelData(channel);\n        for (let i = 0; i < regionBuffer.length; i++) {\n          regionData[i] = sourceData[startSample + i];\n        }\n      }\n      \n      return regionBuffer;\n    }\n    \n    // Extract feature frames from audio buffer\n    async function extractFeatureFrames(buffer) {\n      return new Promise((resolve) => {\n        const frames = [];\n        const offlineCtx = new OfflineAudioContext(\n          buffer.numberOfChannels,\n          buffer.length,\n          buffer.sampleRate\n        );\n        \n        const source = offlineCtx.createBufferSource();\n        source.buffer = buffer;\n        \n        // Create Meyda analyzer\n        const analyzer = Meyda.createMeydaAnalyzer({\n          audioContext: offlineCtx,\n          source: source,\n          bufferSize: frameSize,\n          hopSize: hopSize,\n          featureExtractors: ['rms', 'mfcc', 'spectralCentroid', 'spectralFlatness', 'zcr'],\n          callback: (features) => {\n            frames.push({\n              time: frames.length * (hopSize / offlineCtx.sampleRate),\n              rms: features.rms,\n              mfcc: features.mfcc,\n              spectralCentroid: features.spectralCentroid,\n              spectralFlatness: features.spectralFlatness,\n              zcr: features.zcr\n            });\n          }\n        });\n        \n        analyzer.start();\n        source.connect(offlineCtx.destination);\n        source.start();\n        \n        // When rendering is complete, return frames\n        offlineCtx.startRendering().then(() => {\n          log(`Extracted ${frames.length} frames from buffer`);\n          resolve(frames);\n        }).catch(err => {\n          console.error('Feature extraction error:', err);\n          log(`Feature extraction error: ${err.message}`);\n          resolve([]);\n        });\n      });\n    }\n    \n    // Extract tokens from audio buffer\n    async function extractTokensFromBuffer(buffer) {\n      const tokens = [];\n      \n      // Track frame features\n      const frames = await extractFeatureFrames(buffer);\n      \n      // Find key points in the audio (peaks, valleys, transitions)\n      for (let i = 2; i < frames.length - 2; i++) {\n        const prevFrame2 = frames[i-2];\n        const prevFrame = frames[i-1];\n        const frame = frames[i];\n        const nextFrame = frames[i+1];\n        const nextFrame2 = frames[i+2];\n        \n        // Skip frames with very low energy\n        if (frame.rms < 0.01) continue;\n        \n        // Determine token type based on audio characteristics\n        let tokenType = determineTokenType(frame, prevFrame, nextFrame);\n        \n        // Only add if it's a significant point in the audio\n        if (isSignificantPoint(frame, prevFrame, nextFrame, prevFrame2, nextFrame2)) {\n          tokens.push({\n            type: tokenType,\n            time: frame.time,\n            rms: frame.rms,\n            spectralCentroid: frame.spectralCentroid,\n            mfcc: frame.mfcc.slice(0, 5), // Only keep first 5 coefficients\n            spectralFlux: calculateSpectralFlux(frame, prevFrame),\n            zcr: frame.zcr\n          });\n        }\n      }\n      \n      // Simplify to avoid too many tokens\n      return simplifyTokenSequence(tokens);\n    }\n    \n    // Calculate spectral flux (difference from previous frame)\n    function calculateSpectralFlux(frame, prevFrame) {\n      if (!prevFrame) return 0;\n      \n      // Use spectral centroid difference as a simple flux measure\n      return Math.abs(frame.spectralCentroid - prevFrame.spectralCentroid);\n    }\n    \n    // Determine if this is a significant point in the audio\n    function isSignificantPoint(frame, prevFrame, nextFrame, prevFrame2, nextFrame2) {\n      if (!prevFrame || !nextFrame) return false;\n      \n      // Energy peak (local maximum)\n      const isEnergyPeak = frame.rms > prevFrame.rms && \n                          frame.rms > nextFrame.rms && \n                          frame.rms > 0.02;\n      \n      // Energy valley (local minimum)\n      const isEnergyValley = frame.rms < prevFrame.rms && \n                            frame.rms < nextFrame.rms && \n                            prevFrame.rms > 0.02 && \n                            nextFrame.rms > 0.02;\n      \n      // Spectral centroid peak (local maximum - bright sounds)\n      const isSpectralPeak = frame.spectralCentroid > prevFrame.spectralCentroid && \n                            frame.spectralCentroid > nextFrame.spectralCentroid &&\n                            frame.spectralCentroid > 3000;\n      \n      // Sharp rising edge in energy\n      const isRisingEdge = prevFrame2 && \n                          (frame.rms - prevFrame2.rms) > 0.03;\n      \n      // Sharp falling edge in energy\n      const isFallingEdge = nextFrame2 && \n                           (frame.rms - nextFrame2.rms) > 0.03;\n      \n      // Zero crossing rate peak (consonant sounds)\n      const isZcrPeak = frame.zcr > prevFrame.zcr && \n                        frame.zcr > nextFrame.zcr && \n                        frame.zcr > 0.3;\n      \n      return isEnergyPeak || isEnergyValley || isSpectralPeak || isZcrPeak || isRisingEdge || isFallingEdge;\n    }\n    \n    // Determine token type based on audio characteristics\n    function determineTokenType(frame, prevFrame, nextFrame) {\n      if (!prevFrame || !nextFrame) return 'E';\n      \n      // Energy rising\n      if (frame.rms > prevFrame.rms * 1.2 && frame.rms > 0.02) {\n        return 'A';\n      }\n      \n      // Energy falling\n      if (frame.rms < prevFrame.rms * 0.8 && prevFrame.rms > 0.02) {\n        return 'B';\n      }\n      \n      // High spectral content (bright/sharp sounds)\n      if (frame.spectralCentroid > 5000 && frame.rms > 0.02) {\n        return 'C';\n      }\n      \n      // Low spectral content (dull/muffled sounds)\n      if (frame.spectralCentroid < 2000 && frame.rms > 0.02) {\n        return 'D';\n      }\n      \n      // Default token type for background/silence\n      return 'E';\n    }\n    \n    // Simplify token sequence to avoid too many tokens\n    function simplifyTokenSequence(tokens) {\n      if (tokens.length <= 10) return tokens;\n      \n      // Group tokens by type and proximity\n      const simplified = [];\n      let lastTokenType = null;\n      let lastTokenTime = -1;\n      \n      for (let i = 0; i < tokens.length; i++) {\n        // Keep token if:\n        // 1. It's a different type than the last one\n        // 2. It's sufficiently separated in time\n        // 3. It's one of the first or last tokens\n        // 4. It's evenly spaced throughout (keep ~15 tokens total)\n        const timeDiff = lastTokenTime >= 0 ? tokens[i].time - lastTokenTime : 999;\n        \n        if (tokens[i].type !== lastTokenType || \n            timeDiff > 0.1 || \n            i === 0 || \n            i === tokens.length - 1 ||\n            i % Math.ceil(tokens.length / 15) === 0) {\n          simplified.push(tokens[i]);\n          lastTokenType = tokens[i].type;\n          lastTokenTime = tokens[i].time;\n        }\n      }\n      \n      return simplified;\n    }\n    \n    // Display template tokens\n    function displayTemplateTokens() {\n      // Clear previous display\n      tokenSequence.innerHTML = '';\n      activeTokenTypes.clear();\n      \n      // Display each token\n      templateTokens.forEach((token, index) => {\n        const tokenEl = document.createElement('div');\n        tokenEl.className = 'token';\n        tokenEl.style.backgroundColor = tokenColors[token.type];\n        \n        // Use letters A-Z for first 26, then numbers\n        const letter = index < 26 ? String.fromCharCode(65 + index) : (index - 25);\n        tokenEl.textContent = letter;\n        \n        // Store token type for legend highlight\n        activeTokenTypes.add(token.type);\n        \n        // Add token type label\n        const labelEl = document.createElement('div');\n        labelEl.className = 'token-label';\n        labelEl.textContent = token.type;\n        tokenEl.appendChild(labelEl);\n        \n        // Add debug info tooltip\n        if (showFeatureValues) {\n          const debugInfo = document.createElement('div');\n          debugInfo.className = 'token-debug-info';\n          debugInfo.textContent = `RMS: ${token.rms.toFixed(3)}, SC: ${(token.spectralCentroid/1000).toFixed(1)}k`;\n          tokenEl.appendChild(debugInfo);\n        }\n        \n        tokenSequence.appendChild(tokenEl);\n      });\n      \n      // Update legend to highlight active token types\n      updateLegend();\n    }\n    \n    // Update legend to highlight active token types\n    function updateLegend() {\n      const legendItems = document.querySelectorAll('.legend-item');\n      \n      legendItems.forEach(item => {\n        const typeText = item.querySelector('span').textContent;\n        const type = typeText.charAt(0); // Get the letter (A, B, C, etc.)\n        \n        if (activeTokenTypes.has(type)) {\n          item.style.opacity = '1';\n          item.style.fontWeight = 'bold';\n        } else {\n          item.style.opacity = '0.5';\n          item.style.fontWeight = 'normal';\n        }\n      });\n    }\n    \n    // Enhanced calibration process\n    async function enhancedCalibrate() {\n      if (templateTokens.length === 0 || calibrationRegions.length === 0) {\n        log('Error: Need template tokens and at least one calibration region');\n        return;\n      }\n      \n      log(`Starting calibration with ${calibrationRegions.length} regions...`);\n      \n      calibrationResults = [];\n      regionFeatures = {};\n      \n      // Process all calibration regions\n      for (let i = 0; i < calibrationRegions.length; i++) {\n        const region = calibrationRegions[i];\n        log(`Processing region ${i+1}: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n        \n        // Extract audio from region\n        const audioBuffer = await extractRegionAudio(region);\n        \n        if (!audioBuffer) {\n          log(`Error extracting audio from region ${i+1}`);\n          continue;\n        }\n        \n        // Extract tokens from audio\n        const tokens = await extractTokensFromBuffer(audioBuffer);\n        \n        // Extract raw feature frames for visualization\n        const frames = await extractFeatureFrames(audioBuffer);\n        \n        // Store tokens and frames with the region for later comparison\n        region.data.tokens = tokens;\n        region.data.features = frames;\n        \n        // Compare with template\n        const similarity = compareTokenSequences(templateTokens, tokens);\n        region.data.similarity = similarity;\n        \n        // Store calibration result\n        calibrationResults.push({\n          regionId: region.id,\n          similarity: similarity,\n          tokens: tokens,\n          features: frames\n        });\n        \n        // Update the similarity display in the UI\n        const similarityEl = document.querySelector(`#region-item-${region.id} .similarity-score`);\n        if (similarityEl) {\n          similarityEl.textContent = `${(similarity * 100).toFixed(0)}%`;\n        }\n        \n        log(`Region ${i+1}: ${tokens.length} tokens, similarity: ${(similarity * 100).toFixed(1)}%`);\n        \n        // Verbose logging of token comparison if enabled\n        if (verboseLogging) {\n          const tokenComparison = compareTokenSequencesDetailed(templateTokens, tokens);\n          log(`Token comparison: ${JSON.stringify(tokenComparison)}`);\n        }\n      }\n      \n      // Calculate statistics\n      if (calibrationResults.length > 0) {\n        const similarities = calibrationResults.map(r => r.similarity);\n        const avgSimilarity = similarities.reduce((a, b) => a + b, 0) / similarities.length;\n        const minSimilarity = Math.min(...similarities);\n        const maxSimilarity = Math.max(...similarities);\n        \n        // Calculate standard deviation\n        const stdDev = Math.sqrt(\n          similarities.reduce((sum, val) => sum + Math.pow(val - avgSimilarity, 2), 0) / similarities.length\n        );\n        \n        // Update summary display\n        document.getElementById('avgSimilarity').textContent = `${(avgSimilarity * 100).toFixed(1)}%`;\n        document.getElementById('minSimilarity').textContent = `${(minSimilarity * 100).toFixed(1)}%`;\n        document.getElementById('maxSimilarity').textContent = `${(maxSimilarity * 100).toFixed(1)}%`;\n        document.getElementById('stdDevSimilarity').textContent = `${(stdDev * 100).toFixed(1)}%`;\n        \n        // Set match threshold to 85% of the average similarity to allow for variations\n        const recommendedThreshold = Math.max(0.5, minSimilarity * 0.9);\n        matchThreshold = recommendedThreshold;\n        minConfidence = recommendedThreshold * 0.4;\n        \n        // Update threshold sliders\n        document.getElementById('matchThresholdSlider').value = Math.round(matchThreshold * 100);\n        document.getElementById('matchThresholdValue').textContent = `${Math.round(matchThreshold * 100)}%`;\n        \n        document.getElementById('minConfidenceSlider').value = Math.round(minConfidence * 100);\n        document.getElementById('minConfidenceValue').textContent = `${Math.round(minConfidence * 100)}%`;\n        \n        // Update UI\n        updateThresholdLine();\n        updateFeatureComparison();\n        \n        calibrationInfo.innerHTML = `\n          <strong>Calibration complete:</strong> \n          Match threshold: ${(matchThreshold * 100).toFixed(1)}% | \n          Average similarity: ${(avgSimilarity * 100).toFixed(1)}% |\n          Regions analyzed: ${calibrationRegions.length}\n        `;\n        \n        log(`Calibration complete. Match threshold set to ${(matchThreshold * 100).toFixed(1)}%`);\n        \n        // Update debug output\n        updateDebugOutput();\n        \n        // Enable analysis\n        startAnalysisBtn.disabled = false;\n      } else {\n        log('Calibration failed - no valid regions processed');\n      }\n    }\n    \n    // Compare two token sequences and return similarity (0-1)\n    function compareTokenSequences(template, sequence) {\n      if (!template.length || !sequence.length) return 0;\n      \n      // Simple sliding window approach - find best match within sequence\n      let bestSimilarity = 0;\n      let bestOffset = 0;\n      \n      // Try different alignments to find best match\n      for (let startIdx = 0; startIdx <= sequence.length - Math.min(template.length, 3); startIdx++) {\n        const endIdx = Math.min(startIdx + template.length, sequence.length);\n        const window = sequence.slice(startIdx, endIdx);\n        \n        // Calculate how many tokens match by type\n        let matches = 0;\n        const minLength = Math.min(template.length, window.length);\n        \n        for (let i = 0; i < minLength; i++) {\n          // Compare token features with some tolerance\n          const templateToken = template[i];\n          const windowToken = window[i];\n          \n          // Base similarity on token type\n          const typeMatch = templateToken.type === windowToken.type ? 1 : 0;\n          \n          // Energy similarity\n          const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - windowToken.rms) / 0.2);\n          \n          // Spectral similarity\n          const spectralSimilarity = 1 - Math.min(1, Math.abs(templateToken.spectralCentroid - windowToken.spectralCentroid) / 5000);\n          \n          // Combined similarity for this token\n          const tokenSimilarity = typeMatch * 0.6 + energySimilarity * 0.3 + spectralSimilarity * 0.1;\n          \n          matches += tokenSimilarity;\n        }\n        \n        // Normalize by template length\n        const similarity = matches / template.length;\n        \n        if (similarity > bestSimilarity) {\n          bestSimilarity = similarity;\n          bestOffset = startIdx;\n        }\n      }\n      \n      return bestSimilarity;\n    }\n    \n    // Compare token sequences with detailed reporting for debugging\n    function compareTokenSequencesDetailed(template, sequence) {\n      if (!template.length || !sequence.length) return { similarity: 0, details: [] };\n      \n      // Simple sliding window approach - find best match within sequence\n      let bestSimilarity = 0;\n      let bestOffset = 0;\n      let bestDetails = [];\n      \n      // Try different alignments to find best match\n      for (let startIdx = 0; startIdx <= sequence.length - Math.min(template.length, 3); startIdx++) {\n        const endIdx = Math.min(startIdx + template.length, sequence.length);\n        const window = sequence.slice(startIdx, endIdx);\n        \n        // Calculate how many tokens match by type\n        let matches = 0;\n        const details = [];\n        const minLength = Math.min(template.length, window.length);\n        \n        for (let i = 0; i < minLength; i++) {\n          // Compare token features with some tolerance\n          const templateToken = template[i];\n          const windowToken = window[i];\n          \n          // Base similarity on token type\n          const typeMatch = templateToken.type === windowToken.type ? 1 : 0;\n          \n          // Energy similarity\n          const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - windowToken.rms) / 0.2);\n          \n          // Spectral similarity\n          const spectralSimilarity = 1 - Math.min(1, Math.abs(templateToken.spectralCentroid - windowToken.spectralCentroid) / 5000);\n          \n          // Combined similarity for this token\n          const tokenSimilarity = typeMatch * 0.6 + energySimilarity * 0.3 + spectralSimilarity * 0.1;\n          \n          matches += tokenSimilarity;\n          \n          details.push({\n            template: {\n              type: templateToken.type,\n              rms: templateToken.rms,\n              spectralCentroid: templateToken.spectralCentroid\n            },\n            window: {\n              type: windowToken.type,\n              rms: windowToken.rms, \n              spectralCentroid: windowToken.spectralCentroid\n            },\n            typeMatch: typeMatch,\n            energySimilarity: energySimilarity,\n            spectralSimilarity: spectralSimilarity,\n            tokenSimilarity: tokenSimilarity\n          });\n        }\n        \n        // Normalize by template length\n        const similarity = matches / template.length;\n        \n        if (similarity > bestSimilarity) {\n          bestSimilarity = similarity;\n          bestOffset = startIdx;\n          bestDetails = details;\n        }\n      }\n      \n      return {\n        similarity: bestSimilarity,\n        offset: bestOffset,\n        details: bestDetails\n      };\n    }\n    \n    // Update the feature comparison visualization\n    function updateFeatureComparison() {\n      const comparisonChart = document.getElementById('comparisonChart');\n      comparisonChart.innerHTML = '';\n      \n      // If no template or no selection, show a message\n      if (!templateTokens.length && !templateRegion) {\n        comparisonChart.innerHTML = '<div style=\"text-align: center; padding: 20px;\">No template available for comparison</div>';\n        return;\n      }\n      \n      if (selectedFeatureType === 'tokens') {\n        // Special visualization for token types\n        renderTokenTypeComparison(comparisonChart);\n      } else {\n        // Render time-series data for other feature types\n        renderFeatureTimeSeries(comparisonChart);\n      }\n    }\n    \n    // Render feature time series comparison\n    function renderFeatureTimeSeries(container) {\n      // Get template features\n      let templateFeatures = [];\n      if (templateRegion && templateRegion.data && templateRegion.data.features) {\n        templateFeatures = templateRegion.data.features;\n      } else if (templateBuffer) {\n        // If template features not stored, extract them\n        log('Template features not available, visualization may be incomplete');\n      }\n      \n      // Get selected region features\n      let selectedFeatures = [];\n      if (selectedRegionId) {\n        const selectedRegion = calibrationRegions.find(r => r.id === selectedRegionId);\n        if (selectedRegion && selectedRegion.data && selectedRegion.data.features) {\n          selectedFeatures = selectedRegion.data.features;\n        }\n      }\n      \n      // Create template series container\n      const templateSeries = document.createElement('div');\n      templateSeries.className = 'feature-series';\n      \n      // Get feature property based on selected type\n      const getFeatureValue = (frame) => {\n        switch (selectedFeatureType) {\n          case 'energy': return frame.rms;\n          case 'centroid': return frame.spectralCentroid / 10000; // Normalize\n          case 'zcr': return frame.zcr;\n          default: return frame.rms;\n        }\n      };\n      \n      // Render template features\n      if (templateFeatures.length > 0) {\n        renderFeatureSeries(templateSeries, templateFeatures, getFeatureValue, 'template-bar');\n      }\n      \n      // Render selected region features if available\n      if (selectedFeatures.length > 0) {\n        const selectedSeries = document.createElement('div');\n        selectedSeries.className = 'feature-series';\n        renderFeatureSeries(selectedSeries, selectedFeatures, getFeatureValue, 'selected-region-bar');\n        \n        // Add both to container\n        container.appendChild(templateSeries);\n        container.appendChild(selectedSeries);\n      } else {\n        // Just add template\n        container.appendChild(templateSeries);\n      }\n    }\n    \n    // Render a feature series\n    function renderFeatureSeries(container, features, valueAccessor, barClass) {\n      // Find max value for scaling\n      const maxValue = Math.max(...features.map(valueAccessor));\n      \n      // Only display a reasonable number of points (max 100)\n      const step = Math.max(1, Math.ceil(features.length / 100));\n      \n      // Create visible points\n      for (let i = 0; i < features.length; i += step) {\n        const feature = features[i];\n        const value = valueAccessor(feature);\n        \n        // Create feature point element\n        const pointEl = document.createElement('div');\n        pointEl.className = 'feature-point';\n        \n        // Create feature bar element (height represents value)\n        const barEl = document.createElement('div');\n        barEl.className = `feature-bar ${barClass}`;\n        \n        // Set height as percentage of max value\n        const heightPercent = (value / maxValue) * 100;\n        barEl.style.height = `${heightPercent}%`;\n        \n        // Add tooltip\n        barEl.title = `${selectedFeatureType}: ${value.toFixed(4)} at ${feature.time.toFixed(3)}s`;\n        \n        // Add to DOM\n        pointEl.appendChild(barEl);\n        container.appendChild(pointEl);\n      }\n    }\n    \n    // Render token type comparison\n    function renderTokenTypeComparison(container) {\n      // Create a chart showing the proportion of each token type\n      \n      // Get template tokens\n      const templateTokens = this.templateTokens || [];\n      \n      // Get selected region tokens\n      let selectedTokens = [];\n      if (selectedRegionId) {\n        const selectedRegion = calibrationRegions.find(r => r.id === selectedRegionId);\n        if (selectedRegion && selectedRegion.data && selectedRegion.data.tokens) {\n          selectedTokens = selectedRegion.data.tokens;\n        }\n      }\n      \n      // Count token types\n      const templateCounts = countTokenTypes(templateTokens);\n      const selectedCounts = countTokenTypes(selectedTokens);\n      \n      // Create container for the grouped bars\n      const barsContainer = document.createElement('div');\n      barsContainer.style.display = 'flex';\n      barsContainer.style.height = '100%';\n      barsContainer.style.alignItems = 'flex-end';\n      barsContainer.style.padding = '10px';\n      \n      // Create bars for each token type\n      for (const type of tokenTypes) {\n        // Create group for this token type\n        const groupEl = document.createElement('div');\n        groupEl.style.display = 'flex';\n        groupEl.style.flexDirection = 'column';\n        groupEl.style.alignItems = 'center';\n        groupEl.style.flex = '1';\n        groupEl.style.marginBottom = '25px';\n        \n        // Add token type label\n        const labelEl = document.createElement('div');\n        labelEl.textContent = `Type ${type}`;\n        labelEl.style.position = 'absolute';\n        labelEl.style.bottom = '-20px';\n        labelEl.style.fontSize = '12px';\n        \n        // Create container for the two bars\n        const barGroupEl = document.createElement('div');\n        barGroupEl.style.display = 'flex';\n        barGroupEl.style.width = '100%';\n        barGroupEl.style.height = '100%';\n        barGroupEl.style.position = 'relative';\n        \n        // Template bar\n        const templateBar = document.createElement('div');\n        templateBar.className = 'feature-bar template-bar';\n        templateBar.style.width = '45%';\n        templateBar.style.marginRight = '10%';\n        templateBar.style.height = `${templateCounts[type] || 0}%`;\n        templateBar.title = `Template: ${templateCounts[type] || 0}%`;\n        \n        // Selected region bar\n        const selectedBar = document.createElement('div');\n        selectedBar.className = 'feature-bar selected-region-bar';\n        selectedBar.style.width = '45%';\n        selectedBar.style.height = `${selectedCounts[type] || 0}%`;\n        selectedBar.title = `Selected: ${selectedCounts[type] || 0}%`;\n        \n        // Add bars to bar group\n        barGroupEl.appendChild(templateBar);\n        barGroupEl.appendChild(selectedBar);\n        barGroupEl.appendChild(labelEl);\n        \n        // Add to group element\n        groupEl.appendChild(barGroupEl);\n        \n        // Add to container\n        barsContainer.appendChild(groupEl);\n      }\n      \n      // Add legend\n      const legendEl = document.createElement('div');\n      legendEl.style.display = 'flex';\n      legendEl.style.justifyContent = 'center';\n      legendEl.style.marginTop = '30px';\n      legendEl.style.gap = '20px';\n      \n      const templateLegend = document.createElement('div');\n      templateLegend.innerHTML = '<span style=\"display:inline-block;width:12px;height:12px;background-color:rgba(255,86,0,0.6);margin-right:5px;\"></span> Template';\n      \n      const selectedLegend = document.createElement('div');\n      selectedLegend.innerHTML = '<span style=\"display:inline-block;width:12px;height:12px;background-color:rgba(76,110,245,0.8);margin-right:5px;\"></span> Selected Region';\n      \n      legendEl.appendChild(templateLegend);\n      legendEl.appendChild(selectedLegend);\n      \n      // Add all to main container\n      container.appendChild(barsContainer);\n      container.appendChild(legendEl);\n    }\n    \n    // Count token types as percentages\n    function countTokenTypes(tokens) {\n      const counts = {};\n      if (!tokens || tokens.length === 0) return counts;\n      \n      // Count occurrences of each type\n      for (const token of tokens) {\n        counts[token.type] = (counts[token.type] || 0) + 1;\n      }\n      \n      // Convert to percentages\n      for (const type in counts) {\n        counts[type] = (counts[type] / tokens.length) * 100;\n      }\n      \n      return counts;\n    }\n    \n    // Start real-time analysis\n    async function startAnalysis() {\n      if (templateTokens.length === 0) {\n        log('Error: Template tokens not available');\n        return;\n      }\n      \n      // Reset state\n      resetAnalysisState();\n      \n      try {\n        // Access microphone\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        const source = audioContext.createMediaStreamSource(stream);\n        \n        // Create Meyda analyzer\n        meydaAnalyzer = Meyda.createMeydaAnalyzer({\n          audioContext: audioContext,\n          source: source,\n          bufferSize: frameSize,\n          hopSize: hopSize,\n          featureExtractors: ['rms', 'mfcc', 'spectralCentroid', 'spectralFlatness', 'zcr'],\n          callback: processFrame\n        });\n        \n        meydaAnalyzer.start();\n        isAnalyzing = true;\n        \n        // Update UI\n        startAnalysisBtn.disabled = true;\n        stopAnalysisBtn.disabled = false;\n        liveActivity.innerHTML = 'Listening for thikr patterns...';\n        \n        log('Real-time analysis started. Recite thikr...');\n        \n      } catch (err) {\n        console.error('Error accessing microphone:', err);\n        log('Error: ' + err.message);\n      }\n    }\n    \n    // Stop real-time analysis\n    function stopAnalysis() {\n      if (meydaAnalyzer) {\n        meydaAnalyzer.stop();\n      }\n      \n      isAnalyzing = false;\n      \n      // Update UI\n      startAnalysisBtn.disabled = false;\n      stopAnalysisBtn.disabled = true;\n      liveActivity.innerHTML = 'Analysis stopped.';\n      \n      log('Analysis stopped.');\n    }\n    \n    // Process a frame from the real-time analyzer\n    let prevFrames = [];\n    \n    function processFrame(features) {\n      if (!isAnalyzing) return;\n      \n      const currentTime = audioContext.currentTime;\n      \n      // Create frame object\n      const frame = {\n        time: currentTime,\n        rms: features.rms || 0,\n        mfcc: features.mfcc || [],\n        spectralCentroid: features.spectralCentroid || 0,\n        spectralFlatness: features.spectralFlatness || 0,\n        zcr: features.zcr || 0\n      };\n      \n      // Add to frames buffer\n      prevFrames.push(frame);\n      if (prevFrames.length > 5) {\n        prevFrames.shift();\n      }\n      \n      // Need at least 3 frames to detect features\n      if (prevFrames.length < 3) return;\n      \n      // Get frames for context\n      const currentIdx = prevFrames.length - 1;\n      const prevFrame2 = prevFrames[Math.max(0, currentIdx - 2)];\n      const prevFrame = prevFrames[Math.max(0, currentIdx - 1)];\n      const currentFrame = prevFrames[currentIdx];\n      const nextFrame = null; // We don't have future frames in real-time\n      const nextFrame2 = null;\n      \n      // Check if this frame is a significant point AND enough time has passed since last token\n      if (isSignificantPoint(currentFrame, prevFrame, nextFrame, prevFrame2, nextFrame2) && \n          currentTime - lastTokenTime > 0.05) { // Minimum 50ms between tokens\n        \n        // Determine token type\n        const tokenType = determineTokenType(currentFrame, prevFrame, nextFrame);\n        \n        // Create token\n        const token = {\n          type: tokenType,\n          time: currentTime,\n          rms: currentFrame.rms,\n          spectralCentroid: currentFrame.spectralCentroid,\n          mfcc: currentFrame.mfcc.slice(0, 5),\n          spectralFlux: calculateSpectralFlux(currentFrame, prevFrame),\n          zcr: currentFrame.zcr\n        };\n        \n        // Add to token buffer\n        liveTokenBuffer.push(token);\n        lastTokenTime = currentTime;\n        \n        // Limit token buffer size (keep enough to match template)\n        const maxBuffer = Math.max(30, templateTokens.length * 2);\n        if (liveTokenBuffer.length > maxBuffer) {\n          liveTokenBuffer.shift();\n        }\n        \n        // Update activity display with more detailed token info\n        if (verboseLogging) {\n          updateLiveActivity(`Token ${tokenType} detected (RMS: ${token.rms.toFixed(3)}, SC: ${(token.spectralCentroid/1000).toFixed(1)}k Hz, ZCR: ${token.zcr.toFixed(3)})`);\n        } else {\n          updateLiveActivity(`Token ${tokenType} detected (${token.rms.toFixed(2)} energy)`);\n        }\n        \n        // Process for pattern matching\n        processTokenMatching();\n      }\n    }\n    \n    // Process token matching\n    function processTokenMatching() {\n      // Need a minimum number of tokens to start matching\n      if (liveTokenBuffer.length < Math.max(3, templateTokens.length / 2)) {\n        return;\n      }\n      \n      // Calculate similarity with template\n      const similarity = compareTokenSequences(templateTokens, liveTokenBuffer);\n      \n      // Add confidence marker\n      addConfidenceMarker(similarity);\n      \n      // Update confidence history\n      confidenceHistory.push(similarity);\n      if (confidenceHistory.length > 50) {\n        confidenceHistory.shift();\n      }\n      \n      // Update UI\n      updateProgressBar(similarity);\n      updateTokenVisualization(similarity);\n      \n      // Update activity display with confidence\n      updateLiveActivity(`Pattern match: ${(similarity * 100).toFixed(1)}% confidence`);\n      \n      if (verboseLogging) {\n        log(`Pattern match: ${(similarity * 100).toFixed(1)}% confidence`);\n      }\n      \n      // Check for detection\n      if (similarity >= matchThreshold && \n          audioContext.currentTime - lastDetectionTime > 2.0) { // Cooldown period\n        \n        // Register detection",
      "created_at": "2025-03-23T15:07:07.219201",
      "sequence_order": 3,
      "parent_id": "6a6e2537-547e-45cc-bd94-f52866ea19a0",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": false
      }
    },
    {
      "id": "b4eed32e-30c7-4721-ad07-1edbfaff25a3",
      "role": "assistant",
      "content": "**Summary of the Fix**  \n- The primary issue is that your code sets `calibrationMode = false` immediately after creating **one** calibration region.  \n- Remove (or comment out) that line so you can keep dragging additional calibration regions in the same “session.”  \n- If you do want one region at a time, you can leave that line in but must click **“Select Calibration Region”** each time you add a new region.  \n\n---\n\n### **How to Use the Fixed Version**\n\n1. **Create a template** (drag on the waveform, then click “Extract Template Tokens”).  \n2. **Click “Add Calibration Region”** which sets `calibrationMode = true`.  \n3. **Drag to create** as many calibration regions as you like.  \n4. Finally, **click “Run Calibration.”**\n\nYou should now be able to create multiple calibration regions and calibrate successfully.",
      "created_at": "2025-03-23T15:17:09.787826",
      "sequence_order": 4,
      "parent_id": "c26bab6d-f3ae-4cc0-9314-89db97070632",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "7283246a-3d7f-4ff6-ab3a-e87c99e6d9cb",
      "role": "user",
      "content": "Continue the code from where you left off ",
      "created_at": "2025-03-23T15:18:16.214000",
      "sequence_order": 5,
      "parent_id": "b4eed32e-30c7-4721-ad07-1edbfaff25a3",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "44a688e4-74c6-4180-99c1-4a09efc9a92a",
      "role": "tool",
      "content": "",
      "created_at": "2025-03-23T15:18:20.378121",
      "sequence_order": 6,
      "parent_id": "7283246a-3d7f-4ff6-ab3a-e87c99e6d9cb",
      "metadata": {
        "status": "finished_successfully",
        "weight": 0,
        "end_turn": null
      }
    },
    {
      "id": "0f454051-fe81-479c-b5ff-1ccabfc76891",
      "role": "assistant",
      "content": "Certainly! Here’s the rest of the **`<script>`** portion of your code, continuing exactly where we left off. (We’ll pick up from the detection block that checks `if (similarity >= matchThreshold ...)` and finish out the script.)\n\n```js\n        // Register detection\n        detectionCount++;\n        counterDisplay.textContent = detectionCount;\n        lastDetectionTime = audioContext.currentTime;\n\n        // Add to detection events log\n        const detectionEvent = {\n          id: detectionCount,\n          time: new Date().toISOString(),\n          similarity: similarity,\n          thresholdUsed: matchThreshold,\n          tokenCount: liveTokenBuffer.length,\n          tokenTypes: tokenTypeCounts(liveTokenBuffer)\n        };\n        detectionEvents.push(detectionEvent);\n\n        // Update detection data display\n        updateDetectionData(detectionEvent);\n\n        // Add detection flash\n        addDetectionFlash();\n\n        // Apply wave animation\n        applyWaveAnimation();\n\n        // Update activity display with detection\n        updateLiveActivity(`THIKR DETECTED (#${detectionCount}) with ${(similarity * 100).toFixed(1)}% confidence!`);\n\n        log(`THIKR DETECTED (#${detectionCount}) with ${(similarity * 100).toFixed(1)}% confidence`);\n\n        // Clear token buffer to look for next pattern\n        liveTokenBuffer = [];\n      }\n    }\n\n    // Update detection data display\n    function updateDetectionData(event) {\n      // Format the detection data\n      const formattedData = `\n        <div style=\"border-bottom: 1px solid #dee2e6; padding-bottom: 10px; margin-bottom: 10px;\">\n          <strong>Detection #${event.id}</strong> (${new Date(event.time).toLocaleTimeString()})\n          <br>Confidence: ${(event.similarity * 100).toFixed(1)}% (threshold: ${(event.thresholdUsed * 100).toFixed(1)}%)\n          <br>Tokens: ${event.tokenCount} (${formatTokenTypeCounts(event.tokenTypes)})\n        </div>\n      `;\n      \n      // Add to detection data display\n      detectionData.innerHTML = formattedData + detectionData.innerHTML;\n      \n      // Keep only the last 10 events in the display\n      const items = detectionData.querySelectorAll('div');\n      if (items.length > 10) {\n        for (let i = 10; i < items.length; i++) {\n          items[i].remove();\n        }\n      }\n      \n      // Update debug output\n      updateDebugOutput();\n    }\n\n    // Format token type counts\n    function formatTokenTypeCounts(counts) {\n      return Object.entries(counts)\n        .map(([type, count]) => `${type}:${count}`)\n        .join(', ');\n    }\n\n    // Count token types\n    function tokenTypeCounts(tokens) {\n      const counts = {};\n      tokens.forEach(token => {\n        counts[token.type] = (counts[token.type] || 0) + 1;\n      });\n      return counts;\n    }\n\n    // Update live activity display\n    function updateLiveActivity(message) {\n      const time = new Date().toLocaleTimeString();\n      const activityMessage = `[${time}] ${message}`;\n      \n      // Add new message at top\n      liveActivity.innerHTML = activityMessage + \"<br>\" + liveActivity.innerHTML;\n      \n      // Limit number of messages\n      const messages = liveActivity.innerHTML.split(\"<br>\");\n      if (messages.length > 10) {\n        liveActivity.innerHTML = messages.slice(0, 10).join(\"<br>\");\n      }\n    }\n\n    // Add confidence marker to visualization\n    function addConfidenceMarker(confidence) {\n      // Create a marker\n      const marker = document.createElement('div');\n      marker.className = 'confidence-marker';\n      \n      // Position at the right edge, height based on confidence\n      const bottom = confidence * 100;\n      marker.style.bottom = `${bottom}%`;\n      marker.style.right = '0px';\n      \n      // Color based on threshold\n      if (confidence >= matchThreshold) {\n        marker.style.backgroundColor = 'green';\n      } else if (confidence >= minConfidence) {\n        marker.style.backgroundColor = 'yellow';\n      } else {\n        marker.style.backgroundColor = 'red';\n      }\n      \n      confidenceDisplay.appendChild(marker);\n      \n      // Animate movement\n      let position = 0;\n      const maxPosition = confidenceDisplay.offsetWidth;\n      const moveMarker = () => {\n        position += 2;\n        marker.style.right = `${position}px`;\n        \n        if (position <= maxPosition) {\n          requestAnimationFrame(moveMarker);\n        } else {\n          // Remove marker when it's off-screen\n          marker.remove();\n        }\n      };\n      \n      requestAnimationFrame(moveMarker);\n    }\n\n    // Update token visualization\n    function updateTokenVisualization(overallConfidence) {\n      // Get all token elements\n      const tokenElements = tokenSequence.querySelectorAll('.token');\n      if (tokenElements.length === 0) return;\n      \n      // Calculate individual token matches\n      for (let i = 0; i < templateTokens.length && i < tokenElements.length; i++) {\n        const templateToken = templateTokens[i];\n        \n        // Find best matching token in live buffer\n        let bestMatch = 0;\n        for (let j = 0; j < liveTokenBuffer.length; j++) {\n          const liveToken = liveTokenBuffer[j];\n          if (templateToken.type === liveToken.type) {\n            const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - liveToken.rms) / 0.2);\n            bestMatch = Math.max(bestMatch, energySimilarity);\n          }\n        }\n        \n        // Reset animation\n        tokenElements[i].classList.remove('wave-effect');\n        void tokenElements[i].offsetWidth; // Force reflow to restart animation\n        \n        // Adjust token appearance based on match confidence\n        if (bestMatch > 0.7) {\n          // High confidence match\n          tokenElements[i].style.transform = `scale(${1 + bestMatch * 0.4})`;\n          \n          // Calculate color (yellow to green)\n          const r = Math.floor(255 * (1 - bestMatch));\n          const g = Math.floor(200);\n          const b = 0;\n          tokenElements[i].style.backgroundColor = `rgb(${r}, ${g}, ${b})`;\n          tokenElements[i].style.color = bestMatch > 0.8 ? 'white' : 'black';\n          tokenElements[i].style.boxShadow = `0 0 10px rgba(0, 255, 0, ${bestMatch * 0.8})`;\n          \n          // Add wave effect if high confidence\n          if (bestMatch > 0.85) {\n            tokenElements[i].classList.add('wave-effect');\n          }\n        } else if (bestMatch > 0.4) {\n          // Medium confidence match\n          tokenElements[i].style.transform = `scale(${1 + bestMatch * 0.2})`;\n          \n          // Yellow color\n          tokenElements[i].style.backgroundColor = `rgb(255, 204, 0)`;\n          tokenElements[i].style.color = 'black';\n          tokenElements[i].style.boxShadow = `0 0 5px rgba(255, 204, 0, ${bestMatch * 0.5})`;\n        } else {\n          // Low confidence or no match - reset to original\n          tokenElements[i].style.transform = 'scale(1)';\n          tokenElements[i].style.backgroundColor = tokenColors[templateToken.type];\n          tokenElements[i].style.color = 'black';\n          tokenElements[i].style.boxShadow = '0 2px 4px rgba(0,0,0,0.1)';\n        }\n        \n        // Update debug info on token\n        if (showFeatureValues) {\n          const debugInfo = tokenElements[i].querySelector('.token-debug-info');\n          if (debugInfo) {\n            debugInfo.textContent = `Match: ${(bestMatch * 100).toFixed(0)}%`;\n          }\n        }\n      }\n      \n      // If very high confidence, produce wave effect\n      if (overallConfidence > matchThreshold * 0.9) {\n        applyWaveAnimation();\n      }\n    }\n\n    // Apply wave animation sequence to tokens\n    function applyWaveAnimation() {\n      const tokenElements = tokenSequence.querySelectorAll('.token');\n      \n      tokenElements.forEach((el, i) => {\n        setTimeout(() => {\n          el.classList.remove('wave-effect');\n          void el.offsetWidth; // Force reflow to restart animation\n          el.classList.add('wave-effect');\n        }, i * 100); // Stagger animation\n      });\n    }\n\n    // Add detection flash\n    function addDetectionFlash() {\n      const flash = document.createElement('div');\n      flash.className = 'detection-flash';\n      tokenSequence.appendChild(flash);\n      \n      // Remove after animation completes\n      setTimeout(() => {\n        if (flash.parentNode) {\n          flash.parentNode.remove();\n        }\n      }, 1500);\n    }\n\n    // Update progress bar\n    function updateProgressBar(confidence) {\n      progressBar.style.height = `${confidence * 100}%`;\n    }\n\n    // Update threshold line position\n    function updateThresholdLine() {\n      thresholdLine.style.bottom = `${matchThreshold * 100}%`;\n    }\n\n    // Reset analysis state\n    function resetAnalysisState() {\n      liveTokenBuffer = [];\n      currentTokens = [];\n      confidenceHistory = [];\n      prevFrames = [];\n      lastTokenTime = 0;\n      lastDetectionTime = 0;\n      detectionCount = 0;\n      counterDisplay.textContent = detectionCount;\n      updateProgressBar(0);\n      liveActivity.innerHTML = 'Waiting to start analysis...';\n      \n      // Clear detection events\n      detectionEvents = [];\n      detectionData.innerHTML = '';\n      \n      // Reset token visualization\n      const tokenElements = tokenSequence.querySelectorAll('.token');\n      tokenElements.forEach((el, i) => {\n        if (i < templateTokens.length) {\n          const templateToken = templateTokens[i];\n          el.style.transform = 'scale(1)';\n          el.style.backgroundColor = tokenColors[templateToken.type];\n          el.style.color = 'black';\n          el.style.boxShadow = '0 2px 4px rgba(0,0,0,0.1)';\n        }\n      });\n      \n      // Clear confidence markers\n      document.querySelectorAll('.confidence-marker').forEach(el => el.remove());\n    }\n\n    // Reset the app\n    function resetApp() {\n      // Stop recording if in progress\n      if (isRecording && recorder) {\n        recorder.stop();\n        isRecording = false;\n      }\n      \n      // Stop analysis if in progress\n      if (isAnalyzing) {\n        stopAnalysis();\n      }\n      \n      // Clear wavesurfer\n      wavesurfer.clearRegions();\n      wavesurfer.empty();\n      \n      // Reset variables\n      templateRegion = null;\n      calibrationRegions = [];\n      templateTokens = [];\n      templateBuffer = null;\n      calibrationMode = false;\n      \n      // Reset analysis state\n      resetAnalysisState();\n      \n      // Clear token display\n      tokenSequence.innerHTML = '';\n      \n      // Reset UI\n      recordBtn.disabled = false;\n      stopBtn.disabled = true;\n      playBtn.disabled = true;\n      createTemplateBtn.disabled = true;\n      calibrateBtn.disabled = true;\n      startAnalysisBtn.disabled = true;\n      stopAnalysisBtn.disabled = true;\n      \n      // Hide panels and reset counts\n      tokenContainer.style.display = 'none';\n      calibrationControls.style.display = 'none';\n      document.getElementById('calibrationPanel').style.display = 'none';\n      regionCount.textContent = '0';\n      \n      calibrationInfo.textContent = 'Record audio, then select a template region by dragging on the waveform.';\n      liveActivity.innerHTML = 'Waiting to start analysis...';\n      \n      // Clear diagnostics\n      diagnosticsLog.innerHTML = '';\n      detectionData.innerHTML = '';\n      debugOutput.innerHTML = '';\n      \n      log('App reset');\n    }\n\n    // Update the debug output \n    function updateDebugOutput() {\n      // Create a formatted summary of the current state for easy copy/paste debugging\n      let output = \"=== THIKR COUNTER DEBUG DATA ===\\n\\n\";\n      \n      // Template info\n      output += \"TEMPLATE INFO:\\n\";\n      output += `--------------\\n`;\n      if (templateTokens.length > 0) {\n        output += `Token count: ${templateTokens.length}\\n`;\n        output += `Token sequence: ${templateTokens.map(t => t.type).join('')}\\n`;\n        \n        // Token type counts\n        const counts = {};\n        templateTokens.forEach(token => {\n          counts[token.type] = (counts[token.type] || 0) + 1;\n        });\n        \n        output += `Token distribution: ${Object.entries(counts)\n          .map(([type, count]) => `${type}:${count} (${Math.round(count/templateTokens.length*100)}%)`)\n          .join(', ')}\\n\\n`;\n          \n        // Detailed token data (first 5 tokens)\n        output += \"FIRST 5 TEMPLATE TOKENS:\\n\";\n        templateTokens.slice(0, 5).forEach((token, i) => {\n          output += `[${i}] Type:${token.type} | RMS:${token.rms.toFixed(3)} | SC:${token.spectralCentroid.toFixed(0)} | ZCR:${token.zcr ? token.zcr.toFixed(3) : 'N/A'}\\n`;\n        });\n      } else {\n        output += \"No template tokens available\\n\";\n      }\n      \n      // Calibration info\n      output += \"\\nCALIBRATION INFO:\\n\";\n      output += `-----------------\\n`;\n      output += `Regions: ${calibrationRegions.length}\\n`;\n      output += `Match threshold: ${(matchThreshold * 100).toFixed(1)}%\\n`;\n      output += `Min confidence: ${(minConfidence * 100).toFixed(1)}%\\n\\n`;\n      \n      // Calibration regions\n      if (calibrationRegions.length > 0) {\n        output += \"CALIBRATION REGIONS:\\n\";\n        calibrationRegions.forEach((region, i) => {\n          const similarity = region.data && region.data.similarity ? \n            (region.data.similarity * 100).toFixed(1) + '%' : 'Not calculated';\n            \n          output += `[${i}] Time: ${region.start.toFixed(2)}s-${region.end.toFixed(2)}s | Duration: ${(region.end - region.start).toFixed(2)}s | Similarity: ${similarity}\\n`;\n          \n          // Add token details if available\n          if (region.data && region.data.tokens && region.data.tokens.length > 0) {\n            const tokens = region.data.tokens;\n            output += `    Tokens: ${tokens.length} | Types: ${tokens.map(t => t.type).join('')}\\n`;\n          }\n        });\n      }\n      \n      // Detection history\n      output += \"\\nDETECTION HISTORY:\\n\";\n      output += `----------------\\n`;\n      if (detectionEvents.length > 0) {\n        detectionEvents.slice(-5).reverse().forEach(event => {\n          output += `[#${event.id}] Time: ${new Date(event.time).toLocaleTimeString()} | Confidence: ${(event.similarity * 100).toFixed(1)}%\\n`;\n          output += `    Tokens: ${event.tokenCount} | Types: ${formatTokenTypeCounts(event.tokenTypes)}\\n`;\n        });\n      } else {\n        output += \"No detections recorded\\n\";\n      }\n      \n      // Update the debug output element\n      debugOutput.textContent = output;\n    }\n\n    // Copy all diagnostics to clipboard\n    function copyAllDiagnostics() {\n      // Combine all diagnostic data\n      const allData = debugOutput.textContent + \n        \"\\n\\n=== LOG MESSAGES ===\\n\" + \n        diagnosticsLog.textContent;\n      \n      // Copy to clipboard\n      navigator.clipboard.writeText(allData)\n        .then(() => {\n          alert(\"Diagnostic data copied to clipboard!\");\n        })\n        .catch(err => {\n          console.error('Error copying text: ', err);\n          alert(\"Failed to copy. Please select and copy the text manually.\");\n        });\n    }\n\n    // Utility: Log message to diagnostics box\n    function log(message) {\n      const time = new Date().toLocaleTimeString();\n      diagnosticsLog.innerHTML += `[${time}] ${message}\\n`;\n      diagnosticsLog.scrollTop = diagnosticsLog.scrollHeight;\n      console.log(message); // Also log to console for debugging\n    }\n    \n    // Initialize the app when the page loads\n    window.addEventListener('load', init);\n  </script>\n</body>\n</html>\n```\n\nThat completes the **rest** of the `<script>` block and closes out your HTML file.",
      "created_at": "2025-03-23T15:18:16.856753",
      "sequence_order": 7,
      "parent_id": "44a688e4-74c6-4180-99c1-4a09efc9a92a",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "b6a3b1f6-c01f-49b7-b143-ae8a0c64c471",
      "role": "user",
      "content": "detectionEvents.length > 0) {\n        detectionEvents.slice(-5).reverse().forEach(event => {\n          output += `[#${event.id}] Time: ${new Date(event.time).toLocaleTimeString()} | Confidence: ${(event.similarity * 100).toFixed(1)}%\\n`;\n          output += `    Tokens: ${event.tokenCount} | Types: ${formatTokenTypeCounts(event.tokenTypes)}\\n`;\n        });\n      } else {\n        output += \"No detections recorded\\n\";\n      }\n      \n      // Update the debug output element\n      debugOutput.textContent = output;\n    }",
      "created_at": "2025-03-23T15:33:23.800000",
      "sequence_order": 8,
      "parent_id": "0f454051-fe81-479c-b5ff-1ccabfc76891",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "37decab7-726b-4d87-9d49-b8a0624f44a8",
      "role": "tool",
      "content": "",
      "created_at": "2025-03-23T15:33:27.441043",
      "sequence_order": 9,
      "parent_id": "b6a3b1f6-c01f-49b7-b143-ae8a0c64c471",
      "metadata": {
        "status": "finished_successfully",
        "weight": 0,
        "end_turn": null
      }
    },
    {
      "id": "ad4d5f04-80d2-4d1a-861f-883f189969a2",
      "role": "assistant",
      "content": "Here’s the **rest** of the code **after** the snippet you provided, which picks up right after:\n\n```js\n// Update the debug output element\ndebugOutput.textContent = output;\n}\n```\n\nContinuing on:\n\n```js\n    // Copy all diagnostics to clipboard\n    function copyAllDiagnostics() {\n      // Combine all diagnostic data\n      const allData = debugOutput.textContent + \n        \"\\n\\n=== LOG MESSAGES ===\\n\" + \n        diagnosticsLog.textContent;\n      \n      // Copy to clipboard\n      navigator.clipboard.writeText(allData)\n        .then(() => {\n          alert(\"Diagnostic data copied to clipboard!\");\n        })\n        .catch(err => {\n          console.error('Error copying text: ', err);\n          alert(\"Failed to copy. Please select and copy the text manually.\");\n        });\n    }\n\n    // Utility: Log message to diagnostics box\n    function log(message) {\n      const time = new Date().toLocaleTimeString();\n      diagnosticsLog.innerHTML += `[${time}] ${message}\\n`;\n      diagnosticsLog.scrollTop = diagnosticsLog.scrollHeight;\n      console.log(message); // Also log to console for debugging\n    }\n    \n    // Initialize the app when the page loads\n    window.addEventListener('load', init);\n  </script>\n</body>\n</html>\n```\n\nThat concludes the script and closes out the HTML.",
      "created_at": "2025-03-23T15:33:24.801864",
      "sequence_order": 10,
      "parent_id": "37decab7-726b-4d87-9d49-b8a0624f44a8",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "9da06925-e734-40dd-bbc4-da916cddd612",
      "role": "user",
      "content": "Region updated: 2.79s - 5.07s\n(index):2545 Click and drag on the waveform to select another instance of the same thikr pattern.\n25region.js:94  Uncaught TypeError: Cannot read properties of undefined (reading 'start')\n    at e.value (region.js:94:20)\n    at (index):859:18\n    at wavesurfer.js@6.6.3:3042:12\n    at Array.forEach (<anonymous>)\n    at WaveSurfer.fireEvent (wavesurfer.js@6.6.3:3041:28)\n    at new e (region.js:89:25)\n    at e.value (index.js:222:24)\n    at HTMLUnknownElement.b (index.js:378:31)\nvalue @ region.js:94\n(anonymous) @ (index):859\n(anonymous) @ wavesurfer.js@6.6.3:3042\nfireEvent @ wavesurfer.js@6.6.3:3041\ne @ region.js:89\nvalue @ index.js:222\nb @ index.js:378\n(index):2545 Region updated: 0.03s - 0.04s\n(index):2545 Region updated: 0.02s - 0.04s\n(index):2545 Region updated: 0.03s - 0.04s\n38region.js:94  Uncaught TypeError: Cannot read properties of undefined (reading 'start')\n    at e.value (region.js:94:20)\n    at (index):859:18\n    at wavesurfer.js@6.6.3:3042:12\n    at Array.forEach (<anonymous>)\n    at WaveSurfer.fireEvent (wavesurfer.js@6.6.3:3041:28)\n    at new e (region.js:89:25)\n    at e.value (index.js:222:24)\n    at HTMLUnknownElement.b (index.js:378:31)\nvalue @ region.js:94\n(anonymous) @ (index):859\n(anonymous) @ wavesurfer.js@6.6.3:3042\nfireEvent @ wavesurfer.js@6.6.3:3041\ne @ region.js:89\nvalue @ index.js:222\nb @ index.js:378\n(index):2545 Click and drag on the waveform to select another instance of the same thikr pattern.",
      "created_at": "2025-03-23T15:33:58.797000",
      "sequence_order": 11,
      "parent_id": "0f454051-fe81-479c-b5ff-1ccabfc76891",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "3ac7c6a6-4e30-4096-9e6c-2e610cd9968b",
      "role": "tool",
      "content": "",
      "created_at": "2025-03-23T15:34:09.746181",
      "sequence_order": 12,
      "parent_id": "9da06925-e734-40dd-bbc4-da916cddd612",
      "metadata": {
        "status": "finished_successfully",
        "weight": 0,
        "end_turn": null
      }
    },
    {
      "id": "8f132a3d-c6c1-4183-bd04-7be8bbb2afc7",
      "role": "assistant",
      "content": "This error usually appears when the **WaveSurfer Regions plugin** attempts to update or reference a region object that doesn’t exist (or whose `start`/`end` fields are undefined). In most cases, it’s caused by:\n\n1. **Very short regions** being created (e.g. a quick click-drag from 0.02s to 0.04s).  \n2. **A region getting removed** or invalidated before the plugin finishes creating/updating it.  \n3. A bug in older Wavesurfer versions (especially with quickly-dragged regions).\n\nBelow are some tips to **prevent** or **work around** this:\n\n---\n\n## 1) Add a Safety Check in Your “region-update-end” Callback\n\nBy default, you may have something like:\n```js\nwavesurfer.on('region-update-end', function(region) {\n  log(`Region updated: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n});\n```\n\nIf `region` or its `start` property is ever undefined, it’ll throw the exact error you’re seeing. To guard against that, do:\n\n```js\nwavesurfer.on('region-update-end', function(region) {\n  // If the region is somehow missing or removed, just skip\n  if (!region || typeof region.start === 'undefined') {\n    return;\n  }\n  \n  log(`Region updated: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n});\n```\n\nThis way, if the plugin fires the event with a destroyed or invalid region, your code won’t blow up.\n\n---\n\n## 2) Impose a Minimum Region Length\n\nWavesurfer sometimes glitches if you drag a region that’s only a few milliseconds long. A simple fix is to remove (or prevent) tiny regions:\n\n```js\nconst MIN_DURATION = 0.1; // 100ms, for example\n\nwavesurfer.on('region-update-end', function(region) {\n  if (!region || typeof region.start === 'undefined') return;\n  \n  const duration = region.end - region.start;\n  if (duration < MIN_DURATION) {\n    // Option A: remove it\n    region.remove();\n    console.warn('Removed region because it was too short:', duration);\n    \n    // Option B: forcibly expand it\n    // region.update({ end: region.start + MIN_DURATION });\n  }\n  \n  log(`Region updated: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n});\n```\n\nThat ensures you don’t end up with those 0.01s or 0.02s regions that can cause problems.\n\n---\n\n## 3) Update Wavesurfer / Regions Plugin\n\nIf you’re on an older Wavesurfer version, there have been some bugfixes related to region creation and edge cases. Try installing the latest 6.x or 7.x version:\n\n```bash\nnpm install wavesurfer.js@latest\n```\n\nThen confirm the Regions plugin matches that version (and that you’re loading the matching `.min.js` for regions).\n\n---\n\n## 4) Double-Check Region Creation Logic\n\nIn your own code, make sure you’re not accidentally:\n\n- Calling `region.remove()` immediately in `region-created` or `region-update-end`.  \n- Overwriting `region` with something else.  \n- Switching `calibrationMode` on/off in ways that might destroy the region behind the scenes.\n\nOften, the fix is as simple as **leaving `calibrationMode` = true** until you’re really done adding all the calibration regions, or ignoring extremely short drags.\n\n---\n\n### **Summary**\n\n- **The error** `Cannot read properties of undefined (reading 'start')` is triggered when Wavesurfer tries to reference `region.start` but `region` is `undefined`.  \n- **Short-term fix**: Add null checks in `region-update-end` and/or remove tiny regions.  \n- **Long-term fix**: Update Wavesurfer, keep an eye on region lifecycles, and ensure your code doesn’t remove or override the region object prematurely.  \n\nWith these safeguards, the error should go away and you’ll be able to drag-select new regions without that crash.",
      "created_at": "2025-03-23T15:34:00.975954",
      "sequence_order": 13,
      "parent_id": "3ac7c6a6-4e30-4096-9e6c-2e610cd9968b",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "9d68ea36-ed54-431c-933a-5b8317653a3f",
      "role": "user",
      "content": "region.js:94 \n Uncaught (in promise) TypeError: Cannot read properties of undefined (reading 'start')\n    at e.value (region.js:94:20)\n    at HTMLButtonElement.createTemplate ((index):2406:22)\n\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Thikr Counter - Visual Pattern Recognition</title>\n  <script src=\"https://unpkg.com/wavesurfer.js@6.6.3\"></script>\n  <script src=\"https://unpkg.com/wavesurfer.js@6.6.3/dist/plugin/wavesurfer.regions.min.js\"></script>\n  <script src=\"https://unpkg.com/wavesurfer.js@6.6.3/dist/plugin/wavesurfer.timeline.min.js\"></script>\n  <script src=\"https://unpkg.com/meyda@5.6.1/dist/web/meyda.min.js\"></script>\n  <style>\n    body {\n      font-family: system-ui, sans-serif;\n      max-width: 1000px;\n      margin: 0 auto;\n      padding: 20px;\n      background-color: #f5f5f5;\n    }\n    \n    .panel {\n      background: white;\n      border-radius: 8px;\n      padding: 20px;\n      margin-bottom: 20px;\n      box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n    }\n    \n    button {\n      background-color: #4c6ef5;\n      color: white;\n      border: none;\n      padding: 8px 16px;\n      margin: 5px;\n      border-radius: 4px;\n      cursor: pointer;\n      font-weight: 500;\n      transition: all 0.2s ease;\n    }\n    \n    button:hover:not(:disabled) {\n      background-color: #364fc7;\n      transform: translateY(-1px);\n    }\n    \n    button:disabled {\n      background-color: #a5b4fc;\n      cursor: not-allowed;\n    }\n    \n    .waveform {\n      border: 1px solid #e9ecef;\n      border-radius: 4px;\n      overflow: hidden;\n      margin: 10px 0;\n      height: 128px; /* Explicitly set height */\n      width: 100%;\n      background-color: #f8f9fa;\n      position: relative;\n    }\n    \n    #waveform-timeline {\n      height: 30px;\n      border-bottom: 1px solid #e9ecef;\n      margin-bottom: 10px;\n    }\n    \n    #counter {\n      font-size: 64px;\n      font-weight: bold;\n      text-align: center;\n      color: #4c6ef5;\n      padding: 20px;\n    }\n    \n    #confidenceDisplay {\n      height: 100px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      margin: 10px 0;\n      position: relative;\n    }\n    \n    .progress-bar {\n      position: absolute;\n      bottom: 0;\n      left: 0;\n      width: 100%;\n      background-color: #4c6ef5;\n      transition: height 0.1s;\n      height: 0%;\n    }\n    \n    .threshold-line {\n      position: absolute;\n      width: 100%;\n      height: 2px;\n      background-color: #fa5252;\n      z-index: 2;\n      bottom: 75%; /* Default position */\n    }\n    \n    #tokenContainer {\n      margin-top: 20px;\n    }\n    \n    #tokenSequence {\n      display: flex;\n      flex-wrap: wrap;\n      padding: 20px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      min-height: 80px;\n      margin: 10px 0;\n      position: relative;\n    }\n    \n    .token {\n      display: inline-flex;\n      align-items: center;\n      justify-content: center;\n      width: 50px;\n      height: 50px;\n      margin: 5px;\n      border-radius: 4px;\n      font-weight: bold;\n      font-size: 20px;\n      transition: all 0.3s ease;\n      position: relative;\n      box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n    }\n    \n    .token-label {\n      position: absolute;\n      top: -15px;\n      font-size: 10px;\n      color: #495057;\n    }\n    \n    #legend {\n      display: flex;\n      flex-wrap: wrap;\n      gap: 10px;\n      padding: 10px;\n      margin-top: 10px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .legend-item {\n      display: flex;\n      align-items: center;\n      margin-right: 15px;\n    }\n    \n    .legend-color {\n      width: 20px;\n      height: 20px;\n      border-radius: 3px;\n      margin-right: 5px;\n    }\n    \n    #liveActivity {\n      margin-top: 10px;\n      padding: 10px;\n      background-color: #e9ecef;\n      border-radius: 4px;\n      font-family: monospace;\n      font-size: 12px;\n      min-height: 60px;\n      overflow-y: auto;\n    }\n    \n    #diagnostics {\n      height: 200px;\n      overflow-y: auto;\n      font-family: monospace;\n      font-size: 12px;\n      background-color: #212529;\n      color: #f8f9fa;\n      padding: 10px;\n      border-radius: 4px;\n      white-space: pre-wrap;\n    }\n    \n    #calibrationInfo {\n      margin-top: 10px;\n      padding: 10px;\n      background-color: #e9ecef;\n      border-radius: 4px;\n      font-size: 14px;\n    }\n    \n    .detection-flash {\n      position: absolute;\n      width: 100%;\n      height: 100%;\n      background-color: rgba(76, 175, 80, 0.3);\n      top: 0;\n      left: 0;\n      z-index: 10;\n      animation: flash-animation 1.5s forwards;\n      pointer-events: none;\n    }\n    \n    .confidence-marker {\n      position: absolute;\n      height: 10px;\n      width: 10px;\n      border-radius: 50%;\n      background-color: green;\n      transform: translate(-50%, -50%);\n      z-index: 3;\n    }\n    \n    @keyframes flash-animation {\n      0% { opacity: 0.8; }\n      100% { opacity: 0; }\n    }\n    \n    @keyframes wave-animation {\n      0% { transform: scale(1); opacity: 0.7; }\n      50% { transform: scale(1.4); opacity: 1; }\n      100% { transform: scale(1); opacity: 0.7; }\n    }\n    \n    @keyframes pulse-animation {\n      0% { box-shadow: 0 0 0 0 rgba(76, 110, 245, 0.7); }\n      70% { box-shadow: 0 0 0 15px rgba(76, 110, 245, 0); }\n      100% { box-shadow: 0 0 0 0 rgba(76, 110, 245, 0); }\n    }\n    \n    .wave-effect {\n      animation: wave-animation 0.5s ease;\n    }\n    \n    .pulse-effect {\n      animation: pulse-animation 1.5s infinite;\n    }\n    \n    .control-group {\n      display: flex;\n      flex-wrap: wrap;\n      gap: 5px;\n      margin-bottom: 10px;\n    }\n    \n    h2 {\n      margin-top: 0;\n      color: #343a40;\n    }\n    \n    label {\n      font-weight: bold;\n      display: block;\n      margin-bottom: 5px;\n    }\n    \n    .instruction {\n      font-style: italic;\n      color: #6c757d;\n      margin-bottom: 10px;\n    }\n    \n    .region-count {\n      display: inline-block;\n      background-color: #4c6ef5;\n      color: white;\n      border-radius: 50%;\n      width: 24px;\n      height: 24px;\n      text-align: center;\n      line-height: 24px;\n      font-size: 14px;\n      margin-left: 10px;\n    }\n    \n    /* Enhanced Calibration Styles */\n    .calibration-panel {\n      margin-top: 20px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      padding: 15px;\n    }\n    \n    .region-list {\n      max-height: 300px;\n      overflow-y: auto;\n      margin: 10px 0;\n    }\n    \n    .region-item {\n      display: flex;\n      justify-content: space-between;\n      align-items: center;\n      padding: 10px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      margin-bottom: 8px;\n      cursor: pointer;\n      transition: all 0.2s ease;\n    }\n    \n    .region-item:hover {\n      background-color: #e9ecef;\n      transform: translateY(-1px);\n    }\n    \n    .region-item.selected {\n      background-color: #cfe8ff;\n      border-color: #4c6ef5;\n      box-shadow: 0 0 0 2px rgba(76, 110, 245, 0.5);\n    }\n    \n    .region-item .region-info {\n      flex-grow: 1;\n    }\n    \n    .region-item .region-actions {\n      display: flex;\n      gap: 5px;\n    }\n    \n    .region-item .similarity-score {\n      display: inline-block;\n      margin-left: 10px;\n      padding: 2px 8px;\n      background-color: #4c6ef5;\n      color: white;\n      border-radius: 10px;\n      font-size: 12px;\n      font-weight: bold;\n    }\n    \n    .region-item .region-color-indicator {\n      width: 12px;\n      height: 30px;\n      border-radius: 3px;\n      margin-right: 10px;\n    }\n    \n    /* Comparison visualization styles */\n    .comparison-container {\n      margin-top: 20px;\n      padding: 15px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .comparison-row {\n      display: flex;\n      align-items: center;\n      margin-bottom: 15px;\n      padding-bottom: 10px;\n      border-bottom: 1px solid #e9ecef;\n    }\n    \n    .comparison-label {\n      width: 120px;\n      font-weight: bold;\n      margin-right: 10px;\n    }\n    \n    .comparison-waveform {\n      flex-grow: 1;\n      height: 60px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      position: relative;\n      overflow: hidden;\n    }\n    \n    .comparison-tokens {\n      display: flex;\n      padding: 10px;\n      overflow-x: auto;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      margin-top: 5px;\n    }\n    \n    .mini-token {\n      display: inline-flex;\n      align-items: center;\n      justify-content: center;\n      min-width: 30px;\n      height: 30px;\n      margin-right: 3px;\n      border-radius: 3px;\n      font-weight: bold;\n      font-size: 12px;\n      box-shadow: 0 1px 2px rgba(0,0,0,0.1);\n    }\n    \n    /* Feature comparison visualization */\n    .feature-comparison {\n      margin-top: 15px;\n      padding: 10px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .comparison-chart {\n      height: 200px;\n      position: relative;\n      margin-top: 10px;\n      border-bottom: 1px solid #dee2e6;\n      border-left: 1px solid #dee2e6;\n    }\n    \n    .feature-series {\n      position: absolute;\n      bottom: 0;\n      left: 0;\n      display: flex;\n      align-items: flex-end;\n      height: 100%;\n      width: 100%;\n    }\n    \n    .feature-point {\n      flex: 1;\n      margin: 0 1px;\n      position: relative;\n    }\n    \n    .feature-bar {\n      width: 100%;\n      background-color: #4c6ef5;\n      position: absolute;\n      bottom: 0;\n    }\n    \n    .template-bar {\n      background-color: rgba(255, 86, 0, 0.6);\n    }\n    \n    .calibration-bar {\n      background-color: rgba(0, 200, 83, 0.6);\n    }\n    \n    .selected-region-bar {\n      background-color: rgba(76, 110, 245, 0.8);\n    }\n    \n    .feature-type-selector {\n      display: flex;\n      gap: 10px;\n      margin-bottom: 10px;\n    }\n    \n    .feature-type-selector label {\n      margin-bottom: 0;\n      font-weight: normal;\n    }\n    \n    .calibration-summary {\n      display: flex;\n      flex-wrap: wrap;\n      gap: 10px;\n      margin-top: 15px;\n    }\n    \n    .summary-card {\n      flex: 1;\n      min-width: 120px;\n      padding: 10px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      text-align: center;\n    }\n    \n    .summary-value {\n      font-size: 24px;\n      font-weight: bold;\n      margin: 5px 0;\n    }\n    \n    .summary-label {\n      font-size: 12px;\n      color: #6c757d;\n    }\n    \n    /* Threshold adjustment sliders */\n    .threshold-adjustment {\n      margin-top: 15px;\n      padding: 15px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .slider-container {\n      display: flex;\n      align-items: center;\n      margin-bottom: 10px;\n    }\n    \n    .slider-container label {\n      width: 150px;\n      margin-bottom: 0;\n    }\n    \n    .slider-container input[type=\"range\"] {\n      flex-grow: 1;\n      margin-right: 10px;\n    }\n    \n    .slider-value {\n      width: 40px;\n      text-align: right;\n    }\n    \n    /* Enhanced region visualization */\n    .region-color-palette {\n      display: flex;\n      margin: 10px 0;\n      gap: 10px;\n    }\n    \n    .color-item {\n      display: flex;\n      align-items: center;\n    }\n    \n    .color-swatch {\n      width: 20px;\n      height: 20px;\n      border-radius: 3px;\n      margin-right: 5px;\n    }\n    \n    /* Enhanced diagnostics styles */\n    .token-debug-info {\n      position: absolute;\n      bottom: -25px;\n      font-size: 9px;\n      color: #6c757d;\n      left: 0;\n      right: 0;\n      text-align: center;\n      white-space: nowrap;\n      overflow: hidden;\n      text-overflow: ellipsis;\n    }\n    \n    .diagnostic-controls {\n      margin-bottom: 10px;\n      display: flex;\n      gap: 10px;\n      align-items: center;\n    }\n    \n    .copy-diagnostics {\n      background-color: #212529;\n      color: white;\n      border: 1px solid #495057;\n      padding: 5px 10px;\n      border-radius: 4px;\n      cursor: pointer;\n      font-size: 12px;\n    }\n    \n    .diagnostics-options label {\n      display: inline-flex;\n      align-items: center;\n      margin-right: 10px;\n      font-weight: normal;\n      font-size: 12px;\n    }\n    \n    .diagnostic-section {\n      margin-top: 10px;\n      padding: 10px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      font-family: monospace;\n      font-size: 12px;\n    }\n    \n    #detectionData {\n      max-height: 150px;\n      overflow-y: auto;\n    }\n    \n    #debugOutput {\n      font-family: monospace;\n      white-space: pre;\n      font-size: 12px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      padding: 10px;\n      margin-top: 10px;\n      overflow-x: auto;\n    }\n    \n    .debug-help {\n      font-size: 12px;\n      color: #6c757d;\n      margin-top: 5px;\n      margin-bottom: 10px;\n      font-style: italic;\n    }\n    \n    /* Status indicator */\n    .status-indicator {\n      display: inline-flex;\n      align-items: center;\n      margin-left: 10px;\n      padding: 3px 8px;\n      border-radius: 12px;\n      font-size: 12px;\n      font-weight: bold;\n    }\n    \n    .status-ready {\n      background-color: #d3f9d8;\n      color: #2b8a3e;\n    }\n    \n    .status-pending {\n      background-color: #fff3bf;\n      color: #e67700;\n    }\n    \n    .status-error {\n      background-color: #ffe3e3;\n      color: #c92a2a;\n    }\n    \n    /* Tooltip styles */\n    .tooltip {\n      position: relative;\n      display: inline-block;\n      cursor: help;\n    }\n    \n    .tooltip .tooltip-text {\n      visibility: hidden;\n      width: 200px;\n      background-color: #212529;\n      color: #fff;\n      text-align: center;\n      border-radius: 6px;\n      padding: 5px;\n      position: absolute;\n      z-index: 1;\n      bottom: 125%;\n      left: 50%;\n      transform: translateX(-50%);\n      opacity: 0;\n      transition: opacity 0.3s;\n    }\n    \n    .tooltip:hover .tooltip-text {\n      visibility: visible;\n      opacity: 1;\n    }\n  </style>\n</head>\n<body>\n  <h1>Thikr Counter - Visual Pattern Recognition</h1>\n  \n  <div class=\"panel\">\n    <h2>1. Record & Extract Template</h2>\n    <div class=\"instruction\">Record your thikr, then use your mouse to drag-select the region containing a single complete thikr recitation.</div>\n    <div class=\"control-group\">\n      <button id=\"recordBtn\">Record Audio</button>\n      <button id=\"stopBtn\" disabled>Stop Recording</button>\n      <button id=\"playBtn\" disabled>Play Audio</button>\n      <button id=\"resetBtn\">Reset</button>\n    </div>\n    \n    <div id=\"counter\">0</div>\n    \n    <div id=\"waveformContainer\">\n      <label>Waveform Display</label>\n      <div id=\"waveform-timeline\"></div>\n      <div id=\"waveform\" class=\"waveform\"></div>\n      <div class=\"control-group\">\n        <button id=\"createTemplateBtn\" disabled>Extract Template Tokens</button>\n        <div id=\"calibrationControls\" style=\"display: none;\">\n          <button id=\"selectCalibrationBtn\">Add Calibration Region</button>\n          <span id=\"regionCount\" class=\"region-count\">0</span>\n          <button id=\"calibrateBtn\" disabled>Run Calibration</button>\n          <span id=\"calibrationStatus\" class=\"status-indicator status-pending\">Pending</span>\n        </div>\n      </div>\n    </div>\n    \n    <div id=\"calibrationInfo\">\n      Record audio, then select a template region by dragging on the waveform.\n    </div>\n    \n    <!-- Color legend for regions -->\n    <div id=\"regionColorLegend\" class=\"region-color-palette\" style=\"display: none;\">\n      <div class=\"color-item\">\n        <div class=\"color-swatch\" style=\"background-color: rgba(255, 86, 0, 0.6);\"></div>\n        <span>Template</span>\n      </div>\n      <div class=\"color-item\">\n        <div class=\"color-swatch\" style=\"background-color: rgba(0, 200, 83, 0.6);\"></div>\n        <span>Calibration Region</span>\n      </div>\n      <div class=\"color-item\">\n        <div class=\"color-swatch\" style=\"background-color: rgba(76, 110, 245, 0.8);\"></div>\n        <span>Selected Region</span>\n      </div>\n    </div>\n    \n    <!-- New Calibration Management UI -->\n    <div id=\"calibrationPanel\" class=\"calibration-panel\" style=\"display: none;\">\n      <h3>Calibration Regions</h3>\n      <p class=\"instruction\">Manage your calibration regions. Click on a region to select and view its features.</p>\n      \n      <!-- Region List -->\n      <div id=\"regionList\" class=\"region-list\">\n        <!-- Region items will be added here dynamically -->\n      </div>\n      \n      <!-- Calibration Comparison View -->\n      <div class=\"comparison-container\" id=\"comparisonContainer\">\n        <h3>Thikr Comparison View</h3>\n        <p class=\"instruction\">Visual comparison of all calibration regions against the template.</p>\n        <div id=\"comparisonRows\">\n          <!-- Comparison rows will be added here dynamically -->\n        </div>\n      </div>\n      \n      <!-- Feature Comparison Visualization -->\n      <div class=\"feature-comparison\">\n        <h3>Feature Analysis</h3>\n        <div class=\"feature-type-selector\">\n          <label><input type=\"radio\" name=\"featureType\" value=\"energy\" checked> Energy (RMS)</label>\n          <label><input type=\"radio\" name=\"featureType\" value=\"centroid\"> Spectral Centroid</label>\n          <label><input type=\"radio\" name=\"featureType\" value=\"zcr\"> Zero Crossing Rate</label>\n          <label><input type=\"radio\" name=\"featureType\" value=\"tokens\"> Token Types</label>\n        </div>\n        \n        <div id=\"comparisonChart\" class=\"comparison-chart\">\n          <!-- Feature visualization will be generated here -->\n        </div>\n      </div>\n      \n      <!-- Calibration Summary -->\n      <div class=\"calibration-summary\">\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"avgSimilarity\">-</div>\n          <div class=\"summary-label\">Average Similarity</div>\n        </div>\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"minSimilarity\">-</div>\n          <div class=\"summary-label\">Min Similarity</div>\n        </div>\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"maxSimilarity\">-</div>\n          <div class=\"summary-label\">Max Similarity</div>\n        </div>\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"stdDevSimilarity\">-</div>\n          <div class=\"summary-label\">Std Deviation</div>\n        </div>\n      </div>\n      \n      <!-- Threshold Adjustment -->\n      <div class=\"threshold-adjustment\">\n        <h4>Threshold Adjustments</h4>\n        <div class=\"slider-container\">\n          <label for=\"matchThresholdSlider\">Match Threshold:</label>\n          <input type=\"range\" id=\"matchThresholdSlider\" min=\"0\" max=\"100\" value=\"75\">\n          <span class=\"slider-value\" id=\"matchThresholdValue\">75%</span>\n        </div>\n        <div class=\"slider-container\">\n          <label for=\"minConfidenceSlider\">Min Confidence:</label>\n          <input type=\"range\" id=\"minConfidenceSlider\" min=\"0\" max=\"100\" value=\"30\">\n          <span class=\"slider-value\" id=\"minConfidenceValue\">30%</span>\n        </div>\n      </div>\n    </div>\n  </div>\n  \n  <div class=\"panel\" id=\"tokenContainer\" style=\"display: none;\">\n    <h2>2. Token Visualization</h2>\n    <div class=\"instruction\">These tokens represent the distinctive audio patterns in your thikr. During detection, they will grow and change color as matches are found.</div>\n    \n    <div id=\"legend\">\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #4dabf7;\"></div>\n        <span>A: Energy Rise (vowel onset)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #f783ac;\"></div>\n        <span>B: Energy Fall (syllable end)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #8ce99a;\"></div>\n        <span>C: High Frequency (consonants)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #ffd43b;\"></div>\n        <span>D: Low Frequency (low vowels)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #a5d8ff;\"></div>\n        <span>E: Transition</span>\n      </div>\n    </div>\n    \n    <div id=\"tokenSequence\"></div>\n  </div>\n  \n  <div class=\"panel\">\n    <h2>3. Live Pattern Detection</h2>\n    <div class=\"instruction\">Start analysis and recite your thikr. The system will detect patterns and show confidence levels in real-time.</div>\n    \n    <div class=\"control-group\">\n      <button id=\"startAnalysisBtn\" disabled>Start Analysis</button>\n      <button id=\"stopAnalysisBtn\" disabled>Stop Analysis</button>\n    </div>\n    \n    <label>Pattern Match Confidence</label>\n    <div id=\"confidenceDisplay\">\n      <div class=\"threshold-line\"></div>\n      <div class=\"progress-bar\"></div>\n    </div>\n    \n    <label>Live Activity</label>\n    <div id=\"liveActivity\">Waiting to start analysis...</div>\n  </div>\n  \n  <!-- Enhanced Diagnostics Panel -->\n  <div class=\"panel\">\n    <h2>Diagnostics</h2>\n    <div class=\"debug-help\">\n      This panel provides detailed information for debugging. All data can be copied and pasted to share with developers.\n    </div>\n    \n    <div class=\"diagnostic-controls\">\n      <button class=\"copy-diagnostics\" id=\"copyDiagnosticsBtn\">Copy All Diagnostics</button>\n      <div class=\"diagnostics-options\">\n        <label><input type=\"checkbox\" id=\"verboseLogging\" checked> Verbose Logging</label>\n        <label><input type=\"checkbox\" id=\"showFeatureValues\" checked> Show Feature Values</label>\n      </div>\n    </div>\n    \n    <div id=\"diagnostics\"></div>\n    \n    <!-- Pattern Detection Data -->\n    <h3>Pattern Detection Data</h3>\n    <div class=\"debug-help\">\n      The most recent pattern detection events with detailed metrics. This data is useful for troubleshooting false positives/negatives.\n    </div>\n    <div id=\"detectionData\" class=\"diagnostic-section\"></div>\n    \n    <!-- Debug Output for Copy/Paste -->\n    <h3>Recognition Debug Data</h3>\n    <div class=\"debug-help\">\n      This formatted data can be copied and shared to help debug the recognition process.\n    </div>\n    <pre id=\"debugOutput\"></pre>\n  </div>\n\n  <script>\n    // Global variables\n    let audioContext;\n    let wavesurfer;\n    let recorder;\n    let recordedChunks = [];\n    let isRecording = false;\n    let meydaAnalyzer = null;\n    let calibrationMode = false;\n    \n    // Audio processing configuration\n    const frameSize = 2048;\n    const hopSize = 1024;\n    \n    // Token types and colors\n    const tokenTypes = ['A', 'B', 'C', 'D', 'E']; // Different audio characteristics\n    const tokenColors = {\n      'A': '#4dabf7', // Blue - Energy rise\n      'B': '#f783ac', // Pink - Energy fall\n      'C': '#8ce99a', // Green - Spectral high\n      'D': '#ffd43b', // Yellow - Spectral low\n      'E': '#a5d8ff'  // Light blue - Background\n    };\n    \n    // Token type descriptions\n    const tokenDescriptions = {\n      'A': 'Energy Rise (vowel onset)',\n      'B': 'Energy Fall (syllable end)',\n      'C': 'High Frequency (consonants)',\n      'D': 'Low Frequency (low vowels)',\n      'E': 'Transition'\n    };\n    \n    // Region colors - enhanced palette\n    const regionColors = [\n      'rgba(255, 86, 0, 0.6)',   // Template (orange)\n      'rgba(0, 200, 83, 0.6)',   // Default calibration (green)\n      'rgba(76, 110, 245, 0.8)', // Selected (blue) \n      'rgba(142, 36, 170, 0.6)', // Alternative 1 (purple)\n      'rgba(225, 83, 97, 0.6)',  // Alternative 2 (rose)\n      'rgba(0, 150, 136, 0.6)',  // Alternative 3 (teal)\n      'rgba(255, 152, 0, 0.6)',  // Alternative 4 (amber)\n      'rgba(121, 85, 72, 0.6)'   // Alternative 5 (brown)\n    ];\n    \n    // Pattern recognition parameters (will be auto-calibrated)\n    let matchThreshold = 0.75;\n    let minConfidence = 0.3;\n    \n    // Template data\n    let templateRegion = null;\n    let calibrationRegions = [];\n    let templateTokens = [];\n    let templateBuffer = null;\n    \n    // Detection state\n    let detectionCount = 0;\n    let isAnalyzing = false;\n    let currentTokens = [];\n    let liveTokenBuffer = [];\n    let confidenceHistory = [];\n    let lastDetectionTime = 0;\n    let lastTokenTime = 0;\n    let activeTokenTypes = new Set();\n    \n    // Enhanced calibration variables\n    let calibrationResults = [];\n    let selectedRegionId = null;\n    let regionFeatures = {};\n    let selectedFeatureType = 'energy';\n    \n    // Diagnostic logging\n    let detectionEvents = [];\n    let verboseLogging = true;\n    let showFeatureValues = true;\n    \n    // DOM elements\n    const recordBtn = document.getElementById('recordBtn');\n    const stopBtn = document.getElementById('stopBtn');\n    const playBtn = document.getElementById('playBtn');\n    const resetBtn = document.getElementById('resetBtn');\n    const createTemplateBtn = document.getElementById('createTemplateBtn');\n    const selectCalibrationBtn = document.getElementById('selectCalibrationBtn');\n    const calibrateBtn = document.getElementById('calibrateBtn');\n    const startAnalysisBtn = document.getElementById('startAnalysisBtn');\n    const stopAnalysisBtn = document.getElementById('stopAnalysisBtn');\n    const progressBar = document.querySelector('.progress-bar');\n    const thresholdLine = document.querySelector('.threshold-line');\n    const diagnosticsLog = document.getElementById('diagnostics');\n    const calibrationInfo = document.getElementById('calibrationInfo');\n    const counterDisplay = document.getElementById('counter');\n    const tokenSequence = document.getElementById('tokenSequence');\n    const liveActivity = document.getElementById('liveActivity');\n    const regionCount = document.getElementById('regionCount');\n    const calibrationControls = document.getElementById('calibrationControls');\n    const tokenContainer = document.getElementById('tokenContainer');\n    const detectionData = document.getElementById('detectionData');\n    const debugOutput = document.getElementById('debugOutput');\n    const copyDiagnosticsBtn = document.getElementById('copyDiagnosticsBtn');\n    const verboseLoggingCheckbox = document.getElementById('verboseLogging');\n    const showFeatureValuesCheckbox = document.getElementById('showFeatureValues');\n    const regionColorLegend = document.getElementById('regionColorLegend');\n    const calibrationStatus = document.getElementById('calibrationStatus');\n    \n    // Initialize the app\n    function init() {\n      initWavesurfer();\n      initAudioContext();\n      \n      // Setup event listeners\n      recordBtn.addEventListener('click', startRecording);\n      stopBtn.addEventListener('click', stopRecording);\n      playBtn.addEventListener('click', () => wavesurfer.playPause());\n      resetBtn.addEventListener('click', resetApp);\n      createTemplateBtn.addEventListener('click', createTemplate);\n      selectCalibrationBtn.addEventListener('click', enhancedSelectCalibrationRegion);\n      calibrateBtn.addEventListener('click', enhancedCalibrate);\n      startAnalysisBtn.addEventListener('click', startAnalysis);\n      stopAnalysisBtn.addEventListener('click', stopAnalysis);\n      \n      // Set threshold line position\n      updateThresholdLine();\n      \n      // Setup diagnostic controls\n      copyDiagnosticsBtn.addEventListener('click', copyAllDiagnostics);\n      verboseLoggingCheckbox.addEventListener('change', (e) => {\n        verboseLogging = e.target.checked;\n      });\n      showFeatureValuesCheckbox.addEventListener('change', (e) => {\n        showFeatureValues = e.target.checked;\n      });\n      \n      // Initialize enhanced calibration\n      initEnhancedCalibration();\n      \n      log('App initialized. Click \"Record Audio\" to begin.');\n    }\n    \n    // Initialize WaveSurfer\n    function initWavesurfer() {\n      wavesurfer = WaveSurfer.create({\n        container: '#waveform',\n        waveColor: '#4c6ef5',\n        progressColor: '#364fc7',\n        cursorColor: '#fa5252',\n        height: 128,\n        normalize: true,\n        plugins: [\n          WaveSurfer.regions.create({\n            dragSelection: true,\n            color: 'rgba(255, 86, 0, 0.2)',\n          }),\n          WaveSurfer.timeline.create({\n            container: '#waveform-timeline',\n            primaryFontColor: '#666',\n            secondaryFontColor: '#999',\n            primaryColor: '#333',\n            secondaryColor: '#999'\n          })\n        ]\n      });\n      \n      wavesurfer.on('ready', function() {\n        playBtn.disabled = false;\n        createTemplateBtn.disabled = false;\n        log('Waveform ready - audio loaded successfully');\n      });\n      \n      wavesurfer.on('error', function(err) {\n        log('WaveSurfer error: ' + err);\n      });\n      \n      // Handle region creation - simplified\n      wavesurfer.on('region-created', function(region) {\n        // Only handle initial region creation here\n        if (!calibrationMode && !templateRegion) {\n          region.id = 'template-' + Date.now();\n          log(`Template region created: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n        }\n      });\n      \n      // Handle region updates\n      wavesurfer.on('region-update-end', function(region) {\n        log(`Region updated: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n      });\n      \n      // Handle region click\n      wavesurfer.on('region-click', function(region, e) {\n        e.stopPropagation(); // Prevent creating a new region\n        if (region !== templateRegion) {\n          selectRegion(region.id);\n        }\n      });\n    }\n    \n    // Enhanced calibration process\n    async function enhancedCalibrate() {\n      if (templateTokens.length === 0 || calibrationRegions.length === 0) {\n        log('Error: Need template tokens and at least one calibration region');\n        return;\n      }\n      \n      // Update status indicator\n      updateCalibrationStatus('processing');\n      \n      log(`Starting calibration with ${calibrationRegions.length} regions...`);\n      \n      calibrationResults = [];\n      regionFeatures = {};\n      \n      // Process all calibration regions\n      for (let i = 0; i < calibrationRegions.length; i++) {\n        const region = calibrationRegions[i];\n        log(`Processing region ${i+1}: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n        \n        // Extract audio from region\n        const audioBuffer = await extractRegionAudio(region);\n        \n        if (!audioBuffer) {\n          log(`Error extracting audio from region ${i+1}`);\n          continue;\n        }\n        \n        // Extract tokens from audio\n        const tokens = await extractTokensFromBuffer(audioBuffer);\n        \n        // Extract raw feature frames for visualization\n        const frames = await extractFeatureFrames(audioBuffer);\n        \n        // Store tokens and frames with the region for later comparison\n        region.data.tokens = tokens;\n        region.data.features = frames;\n        \n        // Compare with template\n        const similarity = compareTokenSequences(templateTokens, tokens);\n        region.data.similarity = similarity;\n        \n        // Store calibration result\n        calibrationResults.push({\n          regionId: region.id,\n          similarity: similarity,\n          tokens: tokens,\n          features: frames\n        });\n        \n        // Update the similarity display in the UI\n        const similarityEl = document.querySelector(`#region-item-${region.id} .similarity-score`);\n        if (similarityEl) {\n          similarityEl.textContent = `${(similarity * 100).toFixed(0)}%`;\n          \n          // Update color based on similarity\n          if (similarity >= 0.8) {\n            similarityEl.style.backgroundColor = '#40c057';\n          } else if (similarity >= 0.6) {\n            similarityEl.style.backgroundColor = '#fab005';\n          } else {\n            similarityEl.style.backgroundColor = '#fa5252';\n          }\n        }\n        \n        log(`Region ${i+1}: ${tokens.length} tokens, similarity: ${(similarity * 100).toFixed(1)}%`);\n        \n        // Verbose logging of token comparison if enabled\n        if (verboseLogging) {\n          const tokenComparison = compareTokenSequencesDetailed(templateTokens, tokens);\n          log(`Token comparison: ${JSON.stringify(tokenComparison)}`);\n        }\n      }\n      \n      // Calculate statistics\n      if (calibrationResults.length > 0) {\n        const similarities = calibrationResults.map(r => r.similarity);\n        const avgSimilarity = similarities.reduce((a, b) => a + b, 0) / similarities.length;\n        const minSimilarity = Math.min(...similarities);\n        const maxSimilarity = Math.max(...similarities);\n        \n        // Calculate standard deviation\n        const stdDev = Math.sqrt(\n          similarities.reduce((sum, val) => sum + Math.pow(val - avgSimilarity, 2), 0) / similarities.length\n        );\n        \n        // Update summary display\n        document.getElementById('avgSimilarity').textContent = `${(avgSimilarity * 100).toFixed(1)}%`;\n        document.getElementById('minSimilarity').textContent = `${(minSimilarity * 100).toFixed(1)}%`;\n        document.getElementById('maxSimilarity').textContent = `${(maxSimilarity * 100).toFixed(1)}%`;\n        document.getElementById('stdDevSimilarity').textContent = `${(stdDev * 100).toFixed(1)}%`;\n        \n        // Set match threshold to 85% of the average similarity to allow for variations\n        const recommendedThreshold = Math.max(0.5, minSimilarity * 0.9);\n        matchThreshold = recommendedThreshold;\n        minConfidence = recommendedThreshold * 0.4;\n        \n        // Update threshold sliders\n        document.getElementById('matchThresholdSlider').value = Math.round(matchThreshold * 100);\n        document.getElementById('matchThresholdValue').textContent = `${Math.round(matchThreshold * 100)}%`;\n        \n        document.getElementById('minConfidenceSlider').value = Math.round(minConfidence * 100);\n        document.getElementById('minConfidenceValue').textContent = `${Math.round(minConfidence * 100)}%`;\n        \n        // Update UI\n        updateThresholdLine();\n        updateFeatureComparison();\n        \n        // Create comparison visualization\n        createThikrComparisonView();\n        \n        calibrationInfo.innerHTML = `\n          <strong>Calibration complete:</strong> \n          Match threshold: ${(matchThreshold * 100).toFixed(1)}% | \n          Average similarity: ${(avgSimilarity * 100).toFixed(1)}% |\n          Regions analyzed: ${calibrationRegions.length}\n        `;\n        \n        // Update status\n        updateCalibrationStatus('ready');\n        \n        log(`Calibration complete. Match threshold set to ${(matchThreshold * 100).toFixed(1)}%`);\n        \n        // Update debug output\n        updateDebugOutput();\n        \n        // Enable analysis\n        startAnalysisBtn.disabled = false;\n      } else {\n        // Update status to error\n        updateCalibrationStatus('error');\n        log('Calibration failed - no valid regions processed');\n      }\n    }\n    \n    // Create thikr comparison visualization\n    function createThikrComparisonView() {\n      const comparisonRows = document.getElementById('comparisonRows');\n      comparisonRows.innerHTML = '';\n      \n      // Create template row first\n      if (templateRegion && templateTokens) {\n        const templateRow = createComparisonRow('Template', templateRegion, templateTokens, regionColors[0]);\n        comparisonRows.appendChild(templateRow);\n      }\n      \n      // Create rows for each calibration region\n      calibrationRegions.forEach((region, index) => {\n        if (region.data && region.data.tokens) {\n          // Use a color from our palette\n          const colorIndex = (index % (regionColors.length - 2)) + 2; // Skip first two colors (template and selected)\n          const row = createComparisonRow(\n            `Region ${index + 1}`, \n            region, \n            region.data.tokens, \n            region.id === selectedRegionId ? regionColors[2] : regionColors[colorIndex]\n          );\n          comparisonRows.appendChild(row);\n        }\n      });\n    }\n    \n    // Create a comparison row for thikr visualization\n    function createComparisonRow(label, region, tokens, color) {\n      const row = document.createElement('div');\n      row.className = 'comparison-row';\n      row.dataset.regionId = region.id;\n      \n      // Label with similarity if available\n      const labelDiv = document.createElement('div');\n      labelDiv.className = 'comparison-label';\n      \n      if (region.data && region.data.similarity !== undefined && region.id !== templateRegion.id) {\n        labelDiv.innerHTML = `${label}<br><span style=\"font-size:11px;\">${(region.data.similarity * 100).toFixed(1)}% match</span>`;\n      } else {\n        labelDiv.textContent = label;\n      }\n      \n      // Waveform visualization (simplified)\n      const waveformDiv = document.createElement('div');\n      waveformDiv.className = 'comparison-waveform';\n      waveformDiv.style.backgroundColor = color.replace('0.6', '0.2'); // Lighter background\n      waveformDiv.style.borderColor = color.replace('0.6', '1.0'); // Darker border\n      \n      // Add play button\n      const playBtn = document.createElement('button');\n      playBtn.textContent = '▶';\n      playBtn.style.position = 'absolute';\n      playBtn.style.left = '5px';\n      playBtn.style.top = '5px';\n      playBtn.style.padding = '2px 8px';\n      playBtn.style.fontSize = '12px';\n      playBtn.addEventListener('click', () => playRegion(region));\n      waveformDiv.appendChild(playBtn);\n      \n      // Add region duration\n      const durationSpan = document.createElement('span');\n      durationSpan.textContent = `${(region.end - region.start).toFixed(2)}s`;\n      durationSpan.style.position = 'absolute';\n      durationSpan.style.right = '10px';\n      durationSpan.style.top = '10px';\n      durationSpan.style.fontSize = '12px';\n      durationSpan.style.color = '#495057';\n      waveformDiv.appendChild(durationSpan);\n      \n      // Token visualization\n      const tokensDiv = document.createElement('div');\n      tokensDiv.className = 'comparison-tokens';\n      \n      // Create token elements\n      tokens.forEach(token => {\n        const tokenEl = document.createElement('div');\n        tokenEl.className = 'mini-token';\n        tokenEl.textContent = token.type;\n        tokenEl.style.backgroundColor = tokenColors[token.type];\n        tokensDiv.appendChild(tokenEl);\n      });\n      \n      // Add select button if not template\n      if (region.id !== templateRegion.id) {\n        const selectBtn = document.createElement('button');\n        selectBtn.textContent = 'Select';\n        selectBtn.style.position = 'absolute';\n        selectBtn.style.bottom = '5px';\n        selectBtn.style.right = '5px';\n        selectBtn.style.padding = '2px 8px';\n        selectBtn.style.fontSize = '12px';\n        selectBtn.addEventListener('click', () => selectRegion(region.id));\n        waveformDiv.appendChild(selectBtn);\n      }\n      \n      // Assemble row\n      row.appendChild(labelDiv);\n      row.appendChild(waveformDiv);\n      row.appendChild(tokensDiv);\n      \n      return row;\n    }\n    \n    // Update calibration status indicator\n    function updateCalibrationStatus(status) {\n      const statusEl = document.getElementById('calibrationStatus');\n      \n      switch(status) {\n        case 'ready':\n          statusEl.textContent = 'Ready';\n          statusEl.className = 'status-indicator status-ready';\n          break;\n        case 'processing':\n          statusEl.textContent = 'Processing...';\n          statusEl.className = 'status-indicator status-pending';\n          break;\n        case 'error':\n          statusEl.textContent = 'Error';\n          statusEl.className = 'status-indicator status-error';\n          break;\n        default:\n          statusEl.textContent = 'Pending';\n          statusEl.className = 'status-indicator status-pending';\n      }\n    }\n    \n    // Compare two token sequences and return similarity (0-1)\n    function compareTokenSequences(template, sequence) {\n      if (!template.length || !sequence.length) return 0;\n      \n      // Simple sliding window approach - find best match within sequence\n      let bestSimilarity = 0;\n      let bestOffset = 0;\n      \n      // Try different alignments to find best match\n      for (let startIdx = 0; startIdx <= sequence.length - Math.min(template.length, 3); startIdx++) {\n        const endIdx = Math.min(startIdx + template.length, sequence.length);\n        const window = sequence.slice(startIdx, endIdx);\n        \n        // Calculate how many tokens match by type\n        let matches = 0;\n        const minLength = Math.min(template.length, window.length);\n        \n        for (let i = 0; i < minLength; i++) {\n          // Compare token features with some tolerance\n          const templateToken = template[i];\n          const windowToken = window[i];\n          \n          // Base similarity on token type\n          const typeMatch = templateToken.type === windowToken.type ? 1 : 0;\n          \n          // Energy similarity\n          const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - windowToken.rms) / 0.2);\n          \n          // Spectral similarity\n          const spectralSimilarity = 1 - Math.min(1, Math.abs(templateToken.spectralCentroid - windowToken.spectralCentroid) / 5000);\n          \n          // Combined similarity for this token\n          const tokenSimilarity = typeMatch * 0.6 + energySimilarity * 0.3 + spectralSimilarity * 0.1;\n          \n          matches += tokenSimilarity;\n        }\n        \n        // Normalize by template length\n        const similarity = matches / template.length;\n        \n        if (similarity > bestSimilarity) {\n          bestSimilarity = similarity;\n          bestOffset = startIdx;\n        }\n      }\n      \n      return bestSimilarity;\n    }\n    \n    // Compare token sequences with detailed reporting for debugging\n    function compareTokenSequencesDetailed(template, sequence) {\n      if (!template.length || !sequence.length) return { similarity: 0, details: [] };\n      \n      // Simple sliding window approach - find best match within sequence\n      let bestSimilarity = 0;\n      let bestOffset = 0;\n      let bestDetails = [];\n      \n      // Try different alignments to find best match\n      for (let startIdx = 0; startIdx <= sequence.length - Math.min(template.length, 3); startIdx++) {\n        const endIdx = Math.min(startIdx + template.length, sequence.length);\n        const window = sequence.slice(startIdx, endIdx);\n        \n        // Calculate how many tokens match by type\n        let matches = 0;\n        const details = [];\n        const minLength = Math.min(template.length, window.length);\n        \n        for (let i = 0; i < minLength; i++) {\n          // Compare token features with some tolerance\n          const templateToken = template[i];\n          const windowToken = window[i];\n          \n          // Base similarity on token type\n          const typeMatch = templateToken.type === windowToken.type ? 1 : 0;\n          \n          // Energy similarity\n          const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - windowToken.rms) / 0.2);\n          \n          // Spectral similarity\n          const spectralSimilarity = 1 - Math.min(1, Math.abs(templateToken.spectralCentroid - windowToken.spectralCentroid) / 5000);\n          \n          // Combined similarity for this token\n          const tokenSimilarity = typeMatch * 0.6 + energySimilarity * 0.3 + spectralSimilarity * 0.1;\n          \n          matches += tokenSimilarity;\n          \n          details.push({\n            template: {\n              type: templateToken.type,\n              rms: templateToken.rms,\n              spectralCentroid: templateToken.spectralCentroid\n            },\n            window: {\n              type: windowToken.type,\n              rms: windowToken.rms, \n              spectralCentroid: windowToken.spectralCentroid\n            },\n            typeMatch: typeMatch,\n            energySimilarity: energySimilarity,\n            spectralSimilarity: spectralSimilarity,\n            tokenSimilarity: tokenSimilarity\n          });\n        }\n        \n        // Normalize by template length\n        const similarity = matches / template.length;\n        \n        if (similarity > bestSimilarity) {\n          bestSimilarity = similarity;\n          bestOffset = startIdx;\n          bestDetails = details;\n        }\n      }\n      \n      return {\n        similarity: bestSimilarity,\n        offset: bestOffset,\n        details: bestDetails\n      };\n    }\n    \n    // Update the feature comparison visualization\n    function updateFeatureComparison() {\n      const comparisonChart = document.getElementById('comparisonChart');\n      comparisonChart.innerHTML = '';\n      \n      // If no template or no selection, show a message\n      if (!templateTokens.length && !templateRegion) {\n        comparisonChart.innerHTML = '<div style=\"text-align: center; padding: 20px;\">No template available for comparison</div>';\n        return;\n      }\n      \n      if (selectedFeatureType === 'tokens') {\n        // Special visualization for token types\n        renderTokenTypeComparison(comparisonChart);\n      } else {\n        // Render time-series data for other feature types\n        renderFeatureTimeSeries(comparisonChart);\n      }\n    }\n    \n    // Render feature time series comparison\n    function renderFeatureTimeSeries(container) {\n      // Get template features\n      let templateFeatures = [];\n      if (templateRegion && templateRegion.data && templateRegion.data.features) {\n        templateFeatures = templateRegion.data.features;\n      } else if (templateBuffer) {\n        // If template features not stored, extract them\n        log('Template features not available, visualization may be incomplete');\n      }\n      \n      // Get selected region features\n      let selectedFeatures = [];\n      if (selectedRegionId) {\n        const selectedRegion = calibrationRegions.find(r => r.id === selectedRegionId);\n        if (selectedRegion && selectedRegion.data && selectedRegion.data.features) {\n          selectedFeatures = selectedRegion.data.features;\n        }\n      }\n      \n      // Create template series container\n      const templateSeries = document.createElement('div');\n      templateSeries.className = 'feature-series';\n      \n      // Get feature property based on selected type\n      const getFeatureValue = (frame) => {\n        switch (selectedFeatureType) {\n          case 'energy': return frame.rms;\n          case 'centroid': return frame.spectralCentroid / 10000; // Normalize\n          case 'zcr': return frame.zcr;\n          default: return frame.rms;\n        }\n      };\n      \n      // Render template features\n      if (templateFeatures.length > 0) {\n        renderFeatureSeries(templateSeries, templateFeatures, getFeatureValue, 'template-bar');\n      }\n      \n      // Render selected region features if available\n      if (selectedFeatures.length > 0) {\n        const selectedSeries = document.createElement('div');\n        selectedSeries.className = 'feature-series';\n        renderFeatureSeries(selectedSeries, selectedFeatures, getFeatureValue, 'selected-region-bar');\n        \n        // Add both to container\n        container.appendChild(templateSeries);\n        container.appendChild(selectedSeries);\n      } else {\n        // Just add template\n        container.appendChild(templateSeries);\n      }\n    }\n    \n    // Render a feature series\n    function renderFeatureSeries(container, features, valueAccessor, barClass) {\n      // Find max value for scaling\n      const maxValue = Math.max(...features.map(valueAccessor));\n      \n      // Only display a reasonable number of points (max 100)\n      const step = Math.max(1, Math.ceil(features.length / 100));\n      \n      // Create visible points\n      for (let i = 0; i < features.length; i += step) {\n        const feature = features[i];\n        const value = valueAccessor(feature);\n        \n        // Create feature point element\n        const pointEl = document.createElement('div');\n        pointEl.className = 'feature-point';\n        \n        // Create feature bar element (height represents value)\n        const barEl = document.createElement('div');\n        barEl.className = `feature-bar ${barClass}`;\n        \n        // Set height as percentage of max value\n        const heightPercent = (value / maxValue) * 100;\n        barEl.style.height = `${heightPercent}%`;\n        \n        // Add tooltip\n        barEl.title = `${selectedFeatureType}: ${value.toFixed(4)} at ${feature.time.toFixed(3)}s`;\n        \n        // Add to DOM\n        pointEl.appendChild(barEl);\n        container.appendChild(pointEl);\n      }\n    }\n    \n    // Render token type comparison\n    function renderTokenTypeComparison(container) {\n      // Create a chart showing the proportion of each token type\n      \n      // Get template tokens\n      const templateTokens = this.templateTokens || [];\n      \n      // Get selected region tokens\n      let selectedTokens = [];\n      if (selectedRegionId) {\n        const selectedRegion = calibrationRegions.find(r => r.id === selectedRegionId);\n        if (selectedRegion && selectedRegion.data && selectedRegion.data.tokens) {\n          selectedTokens = selectedRegion.data.tokens;\n        }\n      }\n      \n      // Count token types\n      const templateCounts = countTokenTypes(templateTokens);\n      const selectedCounts = countTokenTypes(selectedTokens);\n      \n      // Create container for the grouped bars\n      const barsContainer = document.createElement('div');\n      barsContainer.style.display = 'flex';\n      barsContainer.style.height = '100%';\n      barsContainer.style.alignItems = 'flex-end';\n      barsContainer.style.padding = '10px';\n      \n      // Create bars for each token type\n      for (const type of tokenTypes) {\n        // Create group for this token type\n        const groupEl = document.createElement('div');\n        groupEl.style.display = 'flex';\n        groupEl.style.flexDirection = 'column';\n        groupEl.style.alignItems = 'center';\n        groupEl.style.flex = '1';\n        groupEl.style.marginBottom = '25px';\n        \n        // Add token type label\n        const labelEl = document.createElement('div');\n        labelEl.textContent = `Type ${type}`;\n        labelEl.style.position = 'absolute';\n        labelEl.style.bottom = '-20px';\n        labelEl.style.fontSize = '12px';\n        \n        // Create container for the two bars\n        const barGroupEl = document.createElement('div');\n        barGroupEl.style.display = 'flex';\n        barGroupEl.style.width = '100%';\n        barGroupEl.style.height = '100%';\n        barGroupEl.style.position = 'relative';\n        \n        // Template bar\n        const templateBar = document.createElement('div');\n        templateBar.className = 'feature-bar template-bar';\n        templateBar.style.width = '45%';\n        templateBar.style.marginRight = '10%';\n        templateBar.style.height = `${templateCounts[type] || 0}%`;\n        templateBar.title = `Template: ${templateCounts[type] || 0}%`;\n        \n        // Selected region bar\n        const selectedBar = document.createElement('div');\n        selectedBar.className = 'feature-bar selected-region-bar';\n        selectedBar.style.width = '45%';\n        selectedBar.style.height = `${selectedCounts[type] || 0}%`;\n        selectedBar.title = `Selected: ${selectedCounts[type] || 0}%`;\n        \n        // Add bars to bar group\n        barGroupEl.appendChild(templateBar);\n        barGroupEl.appendChild(selectedBar);\n        barGroupEl.appendChild(labelEl);\n        \n        // Add to group element\n        groupEl.appendChild(barGroupEl);\n        \n        // Add to container\n        barsContainer.appendChild(groupEl);\n      }\n      \n      // Add legend\n      const legendEl = document.createElement('div');\n      legendEl.style.display = 'flex';\n      legendEl.style.justifyContent = 'center';\n      legendEl.style.marginTop = '30px';\n      legendEl.style.gap = '20px';\n      \n      const templateLegend = document.createElement('div');\n      templateLegend.innerHTML = '<span style=\"display:inline-block;width:12px;height:12px;background-color:rgba(255,86,0,0.6);margin-right:5px;\"></span> Template';\n      \n      const selectedLegend = document.createElement('div');\n      selectedLegend.innerHTML = '<span style=\"display:inline-block;width:12px;height:12px;background-color:rgba(76,110,245,0.8);margin-right:5px;\"></span> Selected Region';\n      \n      legendEl.appendChild(templateLegend);\n      legendEl.appendChild(selectedLegend);\n      \n      // Add all to main container\n      container.appendChild(barsContainer);\n      container.appendChild(legendEl);\n    }\n    \n    // Count token types as percentages\n    function countTokenTypes(tokens) {\n      const counts = {};\n      if (!tokens || tokens.length === 0) return counts;\n      \n      // Count occurrences of each type\n      for (const token of tokens) {\n        counts[token.type] = (counts[token.type] || 0) + 1;\n      }\n      \n      // Convert to percentages\n      for (const type in counts) {\n        counts[type] = (counts[type] / tokens.length) * 100;\n      }\n      \n      return counts;\n    }\n    \n    // Start real-time analysis\n    async function startAnalysis() {\n      if (templateTokens.length === 0) {\n        log('Error: Template tokens not available');\n        return;\n      }\n      \n      // Reset state\n      resetAnalysisState();\n      \n      try {\n        // Access microphone\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        const source = audioContext.createMediaStreamSource(stream);\n        \n        // Create Meyda analyzer\n        meydaAnalyzer = Meyda.createMeydaAnalyzer({\n          audioContext: audioContext,\n          source: source,\n          bufferSize: frameSize,\n          hopSize: hopSize,\n          featureExtractors: ['rms', 'mfcc', 'spectralCentroid', 'spectralFlatness', 'zcr'],\n          callback: processFrame\n        });\n        \n        meydaAnalyzer.start();\n        isAnalyzing = true;\n        \n        // Update UI\n        startAnalysisBtn.disabled = true;\n        stopAnalysisBtn.disabled = false;\n        liveActivity.innerHTML = 'Listening for thikr patterns...';\n        \n        log('Real-time analysis started. Recite thikr...');\n        \n      } catch (err) {\n        console.error('Error accessing microphone:', err);\n        log('Error: ' + err.message);\n      }\n    }\n    \n    // Stop real-time analysis\n    function stopAnalysis() {\n      if (meydaAnalyzer) {\n        meydaAnalyzer.stop();\n      }\n      \n      isAnalyzing = false;\n      \n      // Update UI\n      startAnalysisBtn.disabled = false;\n      stopAnalysisBtn.disabled = true;\n      liveActivity.innerHTML = 'Analysis stopped.';\n      \n      log('Analysis stopped.');\n    }\n    \n    // Process a frame from the real-time analyzer\n    let prevFrames = [];\n    \n    function processFrame(features) {\n      if (!isAnalyzing) return;\n      \n      const currentTime = audioContext.currentTime;\n      \n      // Create frame object\n      const frame = {\n        time: currentTime,\n        rms: features.rms || 0,\n        mfcc: features.mfcc || [],\n        spectralCentroid: features.spectralCentroid || 0,\n        spectralFlatness: features.spectralFlatness || 0,\n        zcr: features.zcr || 0\n      };\n      \n      // Add to frames buffer\n      prevFrames.push(frame);\n      if (prevFrames.length > 5) {\n        prevFrames.shift();\n      }\n      \n      // Need at least 3 frames to detect features\n      if (prevFrames.length < 3) return;\n      \n      // Get frames for context\n      const currentIdx = prevFrames.length - 1;\n      const prevFrame2 = prevFrames[Math.max(0, currentIdx - 2)];\n      const prevFrame = prevFrames[Math.max(0, currentIdx - 1)];\n      const currentFrame = prevFrames[currentIdx];\n      const nextFrame = null; // We don't have future frames in real-time\n      const nextFrame2 = null;\n      \n      // Check if this frame is a significant point AND enough time has passed since last token\n      if (isSignificantPoint(currentFrame, prevFrame, nextFrame, prevFrame2, nextFrame2) && \n          currentTime - lastTokenTime > 0.05) { // Minimum 50ms between tokens\n        \n        // Determine token type\n        const tokenType = determineTokenType(currentFrame, prevFrame, nextFrame);\n        \n        // Create token\n        const token = {\n          type: tokenType,\n          time: currentTime,\n          rms: currentFrame.rms,\n          spectralCentroid: currentFrame.spectralCentroid,\n          mfcc: currentFrame.mfcc.slice(0, 5),\n          spectralFlux: calculateSpectralFlux(currentFrame, prevFrame),\n          zcr: currentFrame.zcr\n        };\n        \n        // Add to token buffer\n        liveTokenBuffer.push(token);\n        lastTokenTime = currentTime;\n        \n        // Limit token buffer size (keep enough to match template)\n        const maxBuffer = Math.max(30, templateTokens.length * 2);\n        if (liveTokenBuffer.length > maxBuffer) {\n          liveTokenBuffer.shift();\n        }\n        \n        // Update activity display with more detailed token info\n        if (verboseLogging) {\n          updateLiveActivity(`Token ${tokenType} detected (RMS: ${token.rms.toFixed(3)}, SC: ${(token.spectralCentroid/1000).toFixed(1)}k Hz, ZCR: ${token.zcr.toFixed(3)})`);\n        } else {\n          updateLiveActivity(`Token ${tokenType} detected (${token.rms.toFixed(2)} energy)`);\n        }\n        \n        // Process for pattern matching\n        processTokenMatching();\n      }\n    }\n    \n    // Process token matching\n    function processTokenMatching() {\n      // Need a minimum number of tokens to start matching\n      if (liveTokenBuffer.length < Math.max(3, templateTokens.length / 2)) {\n        return;\n      }\n      \n      // Calculate similarity with template\n      const similarity = compareTokenSequences(templateTokens, liveTokenBuffer);\n      \n      // Add confidence marker\n      addConfidenceMarker(similarity);\n      \n      // Update confidence history\n      confidenceHistory.push(similarity);\n      if (confidenceHistory.length > 50) {\n        confidenceHistory.shift();\n      }\n      \n      // Update UI\n      updateProgressBar(similarity);\n      updateTokenVisualization(similarity);\n      \n      // Update activity display with confidence\n      updateLiveActivity(`Pattern match: ${(similarity * 100).toFixed(1)}% confidence`);\n      \n      if (verboseLogging) {\n        log(`Pattern match: ${(similarity * 100).toFixed(1)}% confidence`);\n      }\n      \n      // Check for detection\n      if (similarity >= matchThreshold && \n          audioContext.currentTime - lastDetectionTime > 2.0) { // Cooldown period\n        \n        // Register detection\n        detectionCount++;\n        counterDisplay.textContent = detectionCount;\n        lastDetectionTime = audioContext.currentTime;\n        \n        // Add to detection events log\n        const detectionEvent = {\n          id: detectionCount,\n          time: new Date().toISOString(),\n          similarity: similarity,\n          thresholdUsed: matchThreshold,\n          tokenCount: liveTokenBuffer.length,\n          tokenTypes: tokenTypeCounts(liveTokenBuffer)\n        };\n        detectionEvents.push(detectionEvent);\n        \n        // Update detection data display\n        updateDetectionData(detectionEvent);\n        \n        // Add detection flash\n        addDetectionFlash();\n        \n        // Apply wave animation\n        applyWaveAnimation();\n        \n        // Update activity display with detection\n        updateLiveActivity(`THIKR DETECTED (#${detectionCount}) with ${(similarity * 100).toFixed(1)}% confidence!`);\n        \n        log(`THIKR DETECTED (#${detectionCount}) with ${(similarity * 100).toFixed(1)}% confidence`);\n        \n        // Clear token buffer to look for next pattern\n        liveTokenBuffer = [];\n      }\n    }\n    \n    // Update detection data display\n    function updateDetectionData(event) {\n      // Format the detection data\n      const formattedData = `\n        <div style=\"border-bottom: 1px solid #dee2e6; padding-bottom: 10px; margin-bottom: 10px;\">\n          <strong>Detection #${event.id}</strong> (${new Date(event.time).toLocaleTimeString()})\n          <br>Confidence: ${(event.similarity * 100).toFixed(1)}% (threshold: ${(event.thresholdUsed * 100).toFixed(1)}%)\n          <br>Tokens: ${event.tokenCount} (${formatTokenTypeCounts(event.tokenTypes)})\n        </div>\n      `;\n      \n      // Add to detection data display\n      detectionData.innerHTML = formattedData + detectionData.innerHTML;\n      \n      // Keep only the last 10 events in the display\n      const items = detectionData.querySelectorAll('div');\n      if (items.length > 10) {\n        for (let i = 10; i < items.length; i++) {\n          items[i].remove();\n        }\n      }\n      \n      // Update debug output\n      updateDebugOutput();\n    }\n    \n    // Format token type counts\n    function formatTokenTypeCounts(counts) {\n      return Object.entries(counts)\n        .map(([type, count]) => `${type}:${count}`)\n        .join(', ');\n    }\n    \n    // Count token types\n    function tokenTypeCounts(tokens) {\n      const counts = {};\n      tokens.forEach(token => {\n        counts[token.type] = (counts[token.type] || 0) + 1;\n      });\n      return counts;\n    }\n    \n    // Update live activity display\n    function updateLiveActivity(message) {\n      const time = new Date().toLocaleTimeString();\n      const activityMessage = `[${time}] ${message}`;\n      \n      // Add new message at top\n      liveActivity.innerHTML = activityMessage + \"<br>\" + liveActivity.innerHTML;\n      \n      // Limit number of messages\n      const messages = liveActivity.innerHTML.split(\"<br>\");\n      if (messages.length > 10) {\n        liveActivity.innerHTML = messages.slice(0, 10).join(\"<br>\");\n      }\n    }\n    \n    // Add confidence marker to visualization\n    function addConfidenceMarker(confidence) {\n      // Create a marker\n      const marker = document.createElement('div');\n      marker.className = 'confidence-marker';\n      \n      // Position at the right edge, height based on confidence\n      const bottom = confidence * 100;\n      marker.style.bottom = `${bottom}%`;\n      marker.style.right = '0px';\n      \n      // Color based on threshold\n      if (confidence >= matchThreshold) {\n        marker.style.backgroundColor = 'green';\n      } else if (confidence >= minConfidence) {\n        marker.style.backgroundColor = 'yellow';\n      } else {\n        marker.style.backgroundColor = 'red';\n      }\n      \n      confidenceDisplay.appendChild(marker);\n      \n      // Animate movement\n      let position = 0;\n      const maxPosition = confidenceDisplay.offsetWidth;\n      const moveMarker = () => {\n        position += 2;\n        marker.style.right = `${position}px`;\n        \n        if (position <= maxPosition) {\n          requestAnimationFrame(moveMarker);\n        } else {\n          // Remove marker when it's off-screen\n          marker.remove();\n        }\n      };\n      \n      requestAnimationFrame(moveMarker);\n    }\n    \n    // Update token visualization\n    function updateTokenVisualization(overallConfidence) {\n      // Get all token elements\n      const tokenElements = tokenSequence.querySelectorAll('.token');\n      if (tokenElements.length === 0) return;\n      \n      // Calculate individual token matches\n      for (let i = 0; i < templateTokens.length && i < tokenElements.length; i++) {\n        const templateToken = templateTokens[i];\n        \n        // Find best matching token in live buffer\n        let bestMatch = 0;\n        for (let j = 0; j < liveTokenBuffer.length; j++) {\n          const liveToken = liveTokenBuffer[j];\n          if (templateToken.type === liveToken.type) {\n            const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - liveToken.rms) / 0.2);\n            bestMatch = Math.max(bestMatch, energySimilarity);\n          }\n        }\n        \n        // Reset animation\n        tokenElements[i].classList.remove('wave-effect');\n        void tokenElements[i].offsetWidth; // Force reflow to restart animation\n        \n        // Adjust token appearance based on match confidence\n        if (bestMatch > 0.7) {\n          // High confidence match\n          tokenElements[i].style.transform = `scale(${1 + bestMatch * 0.4})`;\n          \n          // Calculate color (yellow to green)\n          const r = Math.floor(255 * (1 - bestMatch));\n          const g = Math.floor(200);\n          const b = 0;\n          tokenElements[i].style.backgroundColor = `rgb(${r}, ${g}, ${b})`;\n          tokenElements[i].style.color = bestMatch > 0.8 ? 'white' : 'black';\n          tokenElements[i].style.boxShadow = `0 0 10px rgba(0, 255, 0, ${bestMatch * 0.8})`;\n          \n          // Add wave effect if high confidence\n          if (bestMatch > 0.85) {\n            tokenElements[i].classList.add('wave-effect');\n          }\n        } else if (bestMatch > 0.4) {\n          // Medium confidence match\n          tokenElements[i].style.transform = `scale(${1 + bestMatch * 0.2})`;\n          \n          // Yellow color\n          tokenElements[i].style.backgroundColor = `rgb(255, 204, 0)`;\n          tokenElements[i].style.color = 'black';\n          tokenElements[i].style.boxShadow = `0 0 5px rgba(255, 204, 0, ${bestMatch * 0.5})`;\n        } else {\n          // Low confidence or no match - reset to original\n          tokenElements[i].style.transform = 'scale(1)';\n          tokenElements[i].style.backgroundColor = tokenColors[templateToken.type];\n          tokenElements[i].style.color = 'black';\n          tokenElements[i].style.boxShadow = '0 2px 4px rgba(0,0,0,0.1)';\n        }\n        \n        // Update debug info on token\n        if (showFeatureValues) {\n          const debugInfo = tokenElements[i].querySelector('.token-debug-info');\n          if (debugInfo) {\n            debugInfo.textContent = `Match: ${(bestMatch * 100).toFixed(0)}%`;\n          }\n        }\n      }\n      \n      // If very high confidence, produce wave effect\n      if (overallConfidence > matchThreshold * 0.9) {\n        applyWaveAnimation();\n      }\n    }\n    \n    // Apply wave animation sequence to tokens\n    function applyWaveAnimation() {\n      const tokenElements = tokenSequence.querySelectorAll('.token');\n      \n      tokenElements.forEach((el, i) => {\n        setTimeout(() => {\n          el.classList.remove('wave-effect');\n          void el.offsetWidth; // Force reflow to restart animation\n          el.classList.add('wave-effect');\n        }, i * 100); // Stagger animation\n      });\n    }\n    \n    // Add detection flash\n    function addDetectionFlash() {\n      const flash = document.createElement('div');\n      flash.className = 'detection-flash';\n      tokenSequence.appendChild(flash);\n      \n      // Remove after animation completes\n      setTimeout(() => {\n        if (flash.parentNode) {\n          flash.parentNode.removeChild(flash);\n        }\n      }, 1500);\n    }\n    \n    // Update progress bar\n    function updateProgressBar(confidence) {\n      progressBar.style.height = `${confidence * 100}%`;\n    }\n    \n    // Update threshold line position\n    function updateThresholdLine() {\n      thresholdLine.style.bottom = `${matchThreshold * 100}%`;\n    }\n    \n    // Reset analysis state\n    function resetAnalysisState() {\n      liveTokenBuffer = [];\n      currentTokens = [];\n      confidenceHistory = [];\n      prevFrames = [];\n      lastTokenTime = 0;\n      lastDetectionTime = 0;\n      detectionCount = 0;\n      counterDisplay.textContent = detectionCount;\n      updateProgressBar(0);\n      liveActivity.innerHTML = 'Waiting to start analysis...';\n      \n      // Clear detection events\n      detectionEvents = [];\n      detectionData.innerHTML = '';\n      \n      // Reset token visualization\n      const tokenElements = tokenSequence.querySelectorAll('.token');\n      tokenElements.forEach((el, i) => {\n        if (i < templateTokens.length) {\n          const templateToken = templateTokens[i];\n          el.style.transform = 'scale(1)';\n          el.style.backgroundColor = tokenColors[templateToken.type];\n          el.style.color = 'black';\n          el.style.boxShadow = '0 2px 4px rgba(0,0,0,0.1)';\n        }\n      });\n      \n      // Clear confidence markers\n      document.querySelectorAll('.confidence-marker').forEach(el => el.remove());\n    }\n    \n    // Reset the app\n    function resetApp() {\n      // Stop recording if in progress\n      if (isRecording && recorder) {\n        recorder.stop();\n        isRecording = false;\n      }\n      \n      // Stop analysis if in progress\n      if (isAnalyzing) {\n        stopAnalysis();\n      }\n      \n      // Clear wavesurfer\n      wavesurfer.clearRegions();\n      wavesurfer.empty();\n      \n      // Reset variables\n      templateRegion = null;\n      calibrationRegions = [];\n      templateTokens = [];\n      templateBuffer = null;\n      calibrationMode = false;\n      \n      // Reset analysis state\n      resetAnalysisState();\n      \n      // Clear token display\n      tokenSequence.innerHTML = '';\n      \n      // Reset UI\n      recordBtn.disabled = false;\n      stopBtn.disabled = true;\n      playBtn.disabled = true;\n      createTemplateBtn.disabled = true;\n      calibrateBtn.disabled = true;\n      startAnalysisBtn.disabled = true;\n      stopAnalysisBtn.disabled = true;\n      \n      // Hide panels and reset counts\n      tokenContainer.style.display = 'none';\n      calibrationControls.style.display = 'none';\n      document.getElementById('calibrationPanel').style.display = 'none';\n      regionColorLegend.style.display = 'none';\n      regionCount.textContent = '0';\n      \n      // Reset calibration status\n      updateCalibrationStatus('pending');\n      \n      calibrationInfo.textContent = 'Record audio, then select a template region by dragging on the waveform.';\n      liveActivity.innerHTML = 'Waiting to start analysis...';\n      \n      // Clear diagnostics\n      diagnosticsLog.innerHTML = '';\n      detectionData.innerHTML = '';\n      debugOutput.innerHTML = '';\n      \n      log('App reset');\n    }\n    \n    // Update the debug output \n    function updateDebugOutput() {\n      // Create a formatted summary of the current state for easy copy/paste debugging\n      let output = \"=== THIKR COUNTER DEBUG DATA ===\\n\\n\";\n      \n      // Template info\n      output += \"TEMPLATE INFO:\\n\";\n      output += `--------------\\n`;\n      if (templateTokens.length > 0) {\n        output += `Token count: ${templateTokens.length}\\n`;\n        output += `Token sequence: ${templateTokens.map(t => t.type).join('')}\\n`;\n        \n        // Token type counts\n        const counts = {};\n        templateTokens.forEach(token => {\n          counts[token.type] = (counts[token.type] || 0) + 1;\n        });\n        \n        output += `Token distribution: ${Object.entries(counts)\n          .map(([type, count]) => `${type}:${count} (${Math.round(count/templateTokens.length*100)}%)`)\n          .join(', ')}\\n\\n`;\n          \n        // Detailed token data (first 5 tokens)\n        output += \"FIRST 5 TEMPLATE TOKENS:\\n\";\n        templateTokens.slice(0, 5).forEach((token, i) => {\n          output += `[${i}] Type:${token.type} | RMS:${token.rms.toFixed(3)} | SC:${token.spectralCentroid.toFixed(0)} | ZCR:${token.zcr ? token.zcr.toFixed(3) : 'N/A'}\\n`;\n        });\n      } else {\n        output += \"No template tokens available\\n\";\n      }\n      \n      // Calibration info\n      output += \"\\nCALIBRATION INFO:\\n\";\n      output += `-----------------\\n`;\n      output += `Regions: ${calibrationRegions.length}\\n`;\n      output += `Match threshold: ${(matchThreshold * 100).toFixed(1)}%\\n`;\n      output += `Min confidence: ${(minConfidence * 100).toFixed(1)}%\\n\\n`;\n      \n      // Calibration regions\n      if (calibrationRegions.length > 0) {\n        output += \"CALIBRATION REGIONS:\\n\";\n        calibrationRegions.forEach((region, i) => {\n          const similarity = region.data && region.data.similarity ? \n            (region.data.similarity * 100).toFixed(1) + '%' : 'Not calculated';\n            \n          output += `[${i}] Time: ${region.start.toFixed(2)}s-${region.end.toFixed(2)}s | Duration: ${(region.end - region.start).toFixed(2)}s | Similarity: ${similarity}\\n`;\n          \n          // Add token details if available\n          if (region.data && region.data.tokens && region.data.tokens.length > 0) {\n            const tokens = region.data.tokens;\n            output += `    Tokens: ${tokens.length} | Types: ${tokens.map(t => t.type).join('')}\\n`;\n          }\n        });\n      }\n      \n      // Detection history\n      output += \"\\nDETECTION HISTORY:\\n\";\n      output += `----------------\\n`;\n      if (detectionEvents.length > 0) {\n        detectionEvents.slice(-5).reverse().forEach(event => {\n          output += `[#${event.id}] Time: ${new Date(event.time).toLocaleTimeString()} | Confidence: ${(event.similarity * 100).toFixed(1)}%\\n`;\n          output += `    Tokens: ${event.tokenCount} | Types: ${formatTokenTypeCounts(event.tokenTypes)}\\n`;\n        });\n      } else {\n        output += \"No detections recorded\\n\";\n      }\n      \n      // Update the debug output element\n      debugOutput.textContent = output;\n    }\n    \n    // Copy all diagnostics to clipboard\n    function copyAllDiagnostics() {\n      // Combine all diagnostic data\n      const allData = debugOutput.textContent + \n        \"\\n\\n=== LOG MESSAGES ===\\n\" + \n        diagnosticsLog.textContent;\n      \n      // Copy to clipboard\n      navigator.clipboard.writeText(allData)\n        .then(() => {\n          alert(\"Diagnostic data copied to clipboard!\");\n        })\n        .catch(err => {\n          console.error('Error copying text: ', err);\n          alert(\"Failed to copy. Please select and copy the text manually.\");\n        });\n    }\n    \n    // Utility: Log message to diagnostics box\n    function log(message) {\n      const time = new Date().toLocaleTimeString();\n      diagnosticsLog.innerHTML += `[${time}] ${message}\\n`;\n      diagnosticsLog.scrollTop = diagnosticsLog.scrollHeight;\n      console.log(message); // Also log to console for debugging\n    }\n    \n    // Initialize the app when the page loads\n    window.addEventListener('load', init);\n    \n    // Initialize Audio Context\n    function initAudioContext() {\n      audioContext = new (window.AudioContext || window.webkitAudioContext)();\n    }\n    \n    // Initialize enhanced calibration\n    function initEnhancedCalibration() {\n      // Add event listeners for the feature type selector\n      document.querySelectorAll('input[name=\"featureType\"]').forEach(radio => {\n        radio.addEventListener('change', event => {\n          selectedFeatureType = event.target.value;\n          updateFeatureComparison();\n        });\n      });\n      \n      // Add event listeners for threshold sliders\n      const matchThresholdSlider = document.getElementById('matchThresholdSlider');\n      const minConfidenceSlider = document.getElementById('minConfidenceSlider');\n      \n      matchThresholdSlider.addEventListener('input', function() {\n        const value = this.value / 100;\n        document.getElementById('matchThresholdValue').textContent = `${this.value}%`;\n        matchThreshold = value;\n        updateThresholdLine();\n      });\n      \n      minConfidenceSlider.addEventListener('input', function() {\n        const value = this.value / 100;\n        document.getElementById('minConfidenceValue').textContent = `${this.value}%`;\n        minConfidence = value;\n      });\n    }\n    \n    // Start recording audio\n    async function startRecording() {\n      if (isRecording) return;\n      \n      try {\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        recorder = new MediaRecorder(stream);\n        \n        recordedChunks = [];\n        isRecording = true;\n        \n        recordBtn.disabled = true;\n        stopBtn.disabled = false;\n        \n        // Handle data available\n        recorder.ondataavailable = function(e) {\n          recordedChunks.push(e.data);\n        };\n        \n        // Handle recording stop\n        recorder.onstop = function() {\n          isRecording = false;\n          \n          // Create audio blob and load into wavesurfer\n          const blob = new Blob(recordedChunks, { type: 'audio/webm' });\n          const url = URL.createObjectURL(blob);\n          wavesurfer.load(url);\n          \n          // Clean up\n          stream.getTracks().forEach(track => track.stop());\n          \n          log('Recording loaded into waveform display - drag to select a region');\n        };\n        \n        // Start recording\n        recorder.start();\n        log('Recording started...');\n        \n      } catch (err) {\n        console.error('Error accessing microphone:', err);\n        log('Error: ' + err.message);\n      }\n    }\n    \n    // Stop recording\n    function stopRecording() {\n      if (recorder && isRecording) {\n        recorder.stop();\n        recordBtn.disabled = false;\n        stopBtn.disabled = true;\n        log('Recording stopped');\n      }\n    }\n    \n// Create template from selected region\nasync function createTemplate() {\n  // Check if wavesurfer is initialized\n  if (!wavesurfer || !wavesurfer.regions) {\n    log('Error: WaveSurfer not properly initialized');\n    return;\n  }\n  \n  // Check if any regions exist\n  const regions = Object.values(wavesurfer.regions.list || {});\n  if (regions.length === 0) {\n    log('Please select a region first by dragging on the waveform');\n    return;\n  }\n  \n  // Get the first region as template and verify it's valid\n  const region = regions[0];\n  if (!region || typeof region.start === 'undefined' || typeof region.end === 'undefined') {\n    log('Error: Invalid region selected. Please try selecting again.');\n    return;\n  }\n  \n  templateRegion = region;\n  \n  // Save region bounds\n  const templateStart = templateRegion.start;\n  const templateEnd = templateRegion.end;\n  \n  // Rest of the function remains the same...\n  // Clear other regions but keep the template\n  Object.values(wavesurfer.regions.list).forEach(r => {\n    if (r !== templateRegion) {\n      r.remove();\n    }\n  });\n      \n      // Update the template region appearance\n      templateRegion.id = 'template-' + Date.now();\n      templateRegion.color = regionColors[0]; // Template color\n      templateRegion.drag = false;\n      templateRegion.resize = false;\n      templateRegion.update();\n      \n      // Initialize data object for the template region\n      templateRegion.data = {\n        tokens: [],\n        features: null\n      };\n      \n      log(`Creating template from region: ${templateRegion.start.toFixed(2)}s - ${templateRegion.end.toFixed(2)}s`);\n      \n      // Extract audio from region\n      const audioBuffer = await extractRegionAudio(templateRegion);\n      templateBuffer = audioBuffer;\n      \n      if (!audioBuffer) {\n        log('Failed to extract audio from region');\n        return;\n      }\n      \n      // Extract frames for visualization\n      const frames = await extractFeatureFrames(audioBuffer);\n      templateRegion.data.features = frames;\n      \n      // Extract tokens from audio\n      const tokens = await extractTokensFromBuffer(audioBuffer);\n      templateTokens = tokens;\n      templateRegion.data.tokens = tokens;\n      \n      log(`Extracted ${tokens.length} tokens from template`);\n      \n      // Generate debug output\n      updateDebugOutput();\n      \n      // Display template tokens\n      displayTemplateTokens();\n      \n      // Show calibration controls and color legend\n      calibrationControls.style.display = 'inline-block';\n      regionColorLegend.style.display = 'flex';\n      \n      // Update UI\n      createTemplateBtn.disabled = true;\n      calibrationInfo.innerHTML = `\n        <strong>Template extracted:</strong> ${templateTokens.length} tokens from region ${templateRegion.start.toFixed(2)}s - ${templateRegion.end.toFixed(2)}s. \n        <br>Now add calibration regions by clicking \"Select Calibration Region\" and selecting other instances of the same thikr.\n      `;\n      \n      // Show token container\n      tokenContainer.style.display = 'block';\n    }\n    \n    // Select calibration region\n    function enhancedSelectCalibrationRegion() {\n      calibrationMode = true;\n      log('Click and drag on the waveform to select another instance of the same thikr pattern.');\n      \n      // Add a one-time event handler for the next region event\n      const handleNextRegionEvent = function(region) {\n        // Only handle this once\n        wavesurfer.un('region-update-end', handleNextRegionEvent);\n        wavesurfer.un('region-created', handleNextRegionEvent);\n        \n        // Skip if this is the template region\n        if (templateRegion && region.id === templateRegion.id) {\n          calibrationMode = false;\n          return;\n        }\n        \n        // Determine color index for this region\n        const colorIndex = (calibrationRegions.length % (regionColors.length - 2)) + 3; // Skip template and selected colors\n        \n        // Create a new calibration region\n        const calibRegion = wavesurfer.addRegion({\n          id: 'calibration-' + Date.now(),\n          start: region.start,\n          end: region.end,\n          color: regionColors[colorIndex], // Use color from palette\n          drag: true,\n          resize: true\n        });\n        \n        // Store metadata with the region\n        calibRegion.data = {\n          tokens: [],\n          similarity: null,\n          features: null,\n          colorIndex: colorIndex // Store color index for reference\n        };\n        \n        // Add to the calibration regions array\n        calibrationRegions.push(calibRegion);\n        updateRegionCount();\n        \n        log(`Calibration region created: ${calibRegion.start.toFixed(2)}s - ${calibRegion.end.toFixed(2)}s`);\n        \n        // Add to UI list with matching color\n        addRegionToList(calibRegion, regionColors[colorIndex]);\n        \n        // Enable calibration button\n        if (calibrationRegions.length > 0) {\n          calibrateBtn.disabled = false;\n        }\n        \n        // Show calibration panel\n        document.getElementById('calibrationPanel').style.display = 'block';\n        \n        // Turn off calibration mode\n        calibrationMode = false;\n        \n        // Remove the original region if it's not the template\n        if (region !== templateRegion) {\n          region.remove();\n        }\n      };\n      \n      // Listen for either region creation or update\n      wavesurfer.on('region-created', handleNextRegionEvent);\n      wavesurfer.on('region-update-end', handleNextRegionEvent);\n    }\n    \n    // Add a region to the UI list\n    function addRegionToList(region, color) {\n      const regionList = document.getElementById('regionList');\n      \n      // Create region item element\n      const regionItem = document.createElement('div');\n      regionItem.className = 'region-item';\n      regionItem.id = `region-item-${region.id}`;\n      regionItem.dataset.regionId = region.id;\n      \n      // Create color indicator\n      const colorIndicator = document.createElement('div');\n      colorIndicator.className = 'region-color-indicator';\n      colorIndicator.style.backgroundColor = color;\n      \n      // Create region info\n      const regionInfo = document.createElement('div');\n      regionInfo.className = 'region-info';\n      regionInfo.textContent = `Region ${calibrationRegions.length}: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`;\n      \n      // Create similarity score display (initially empty)\n      const similarityScore = document.createElement('div');\n      similarityScore.className = 'similarity-score';\n      similarityScore.textContent = '...';\n      \n      // Create region actions\n      const regionActions = document.createElement('div');\n      regionActions.className = 'region-actions';\n      \n      const playButton = document.createElement('button');\n      playButton.className = 'play-region';\n      playButton.innerHTML = '&#9658;'; // Play icon\n      playButton.title = 'Play this region';\n      playButton.addEventListener('click', (e) => {\n        e.stopPropagation();\n        playRegion(region);\n      });\n      \n      const removeButton = document.createElement('button');\n      removeButton.className = 'remove-region';\n      removeButton.innerHTML = '&#10005;'; // X icon\n      removeButton.title = 'Remove this region';\n      removeButton.addEventListener('click', (e) => {\n        e.stopPropagation();\n        removeCalibrationRegion(region.id);\n      });\n      \n      // Add pulse effect to indicate it's newly created\n      regionItem.classList.add('pulse-effect');\n      setTimeout(() => {\n        regionItem.classList.remove('pulse-effect');\n      }, 3000);\n      \n      // Assemble the region item\n      regionActions.appendChild(playButton);\n      regionActions.appendChild(removeButton);\n      regionItem.appendChild(colorIndicator);\n      regionItem.appendChild(regionInfo);\n      regionItem.appendChild(similarityScore);\n      regionItem.appendChild(regionActions);\n      \n      // Add click event to select this region\n      regionItem.addEventListener('click', () => {\n        selectRegion(region.id);\n      });\n      \n      // Add to the list\n      regionList.appendChild(regionItem);\n    }\n    \n    // Play a specific region\n    function playRegion(region) {\n      // Set playback to start at region start\n      wavesurfer.setCurrentTime(region.start);\n      \n      // Play for the duration of the region\n      wavesurfer.play(region.start, region.end);\n      \n      // Add visual feedback by highlighting the region temporarily\n      const originalColor = region.color;\n      region.color = 'rgba(252, 196, 25, 0.5)'; // Bright yellow for playing\n      region.update();\n      \n      // Reset color after playback\n      setTimeout(() => {\n        region.color = originalColor;\n        region.update();\n      }, (region.end - region.start) * 1000 + 100); // Convert to ms and add a small buffer\n      \n      log(`Playing region: ${region.start.toFixed(2)}s to ${region.end.toFixed(2)}s`);\n    }\n    \n    // Remove a calibration region\n    function removeCalibrationRegion(regionId) {\n      // Find the region in the list\n      const regionIndex = calibrationRegions.findIndex(r => r.id === regionId);\n      \n      if (regionIndex !== -1) {\n        // Remove the region from WaveSurfer\n        calibrationRegions[regionIndex].remove();\n        \n        // Remove from our array\n        calibrationRegions.splice(regionIndex, 1);\n        \n        // Remove from UI\n        const regionItem = document.getElementById(`region-item-${regionId}`);\n        if (regionItem) {\n          regionItem.remove();\n        }\n        \n        // Update region count\n        updateRegionCount();\n        \n        // Update calibrate button state\n        calibrateBtn.disabled = calibrationRegions.length === 0;\n        \n        // If selected region was removed, clear selection\n        if (selectedRegionId === regionId) {\n          selectedRegionId = null;\n          updateFeatureComparison();\n        }\n        \n        // Update comparison view\n        if (document.getElementById('comparisonRows').children.length > 0) {\n          createThikrComparisonView();\n        }\n        \n        log(`Calibration region removed (${calibrationRegions.length} remaining)`);\n      }\n    }\n    \n    // Update the region counter display\n    function updateRegionCount() {\n      regionCount.textContent = calibrationRegions.length;\n    }\n    \n    // Select a region for inspection\n    function selectRegion(regionId) {\n      // Deselect previous region in UI\n      if (selectedRegionId) {\n        const prevSelected = document.getElementById(`region-item-${selectedRegionId}`);\n        if (prevSelected) {\n          prevSelected.classList.remove('selected');\n        }\n        \n        // Reset color of previously selected region\n        const prevRegion = calibrationRegions.find(r => r.id === selectedRegionId);\n        if (prevRegion) {\n          // Restore original color\n          const colorIndex = prevRegion.data.colorIndex || 1;\n          prevRegion.color = regionColors[colorIndex];\n          prevRegion.update();\n        }\n      }\n      \n      // Update selection\n      selectedRegionId = regionId;\n      \n      // Update UI selection\n      const selectedItem = document.getElementById(`region-item-${regionId}`);\n      if (selectedItem) {\n        selectedItem.classList.add('selected');\n      }\n      \n      // Update the feature comparison visualization\n      updateFeatureComparison();\n      \n      // Also update comparison view to highlight the selected region\n      const comparisonRows = document.getElementById('comparisonRows').querySelectorAll('.comparison-row');\n      comparisonRows.forEach(row => {\n        if (row.dataset.regionId === regionId) {\n          row.style.backgroundColor = 'rgba(230, 245, 255, 0.5)';\n          row.style.borderLeft = '3px solid ' + regionColors[2];\n        } else {\n          row.style.backgroundColor = '';\n          row.style.borderLeft = '';\n        }\n      });\n      \n      // Highlight the region in the waveform\n      calibrationRegions.forEach(region => {\n        if (region.id === regionId) {\n          // Apply selected color\n          region.color = regionColors[2]; // Selected region color\n          region.update();\n          \n          // Scroll to region in wavesurfer\n          wavesurfer.setCurrentTime(region.start);\n        } else {\n          // Restore original color\n          const colorIndex = region.data.colorIndex || 1;\n          region.color = regionColors[colorIndex];\n          region.update();\n        }\n      });\n      \n      log(`Selected calibration region: ${regionId}`);\n    }\n    \n    // Extract audio buffer from a region\n    async function extractRegionAudio(region) {\n      if (!region || !wavesurfer || !wavesurfer.backend.buffer) {\n        log('Error: Missing region or audio data');\n        return null;\n      }\n      \n      const sourceBuffer = wavesurfer.backend.buffer;\n      const startSample = Math.floor(region.start * sourceBuffer.sampleRate);\n      const endSample = Math.floor(region.end * sourceBuffer.sampleRate);\n      \n      if (startSample >= endSample || startSample < 0 || endSample > sourceBuffer.length) {\n        log('Error: Invalid region boundaries');\n        return null;\n      }\n      \n      // Create a new buffer for the region\n      const regionBuffer = audioContext.createBuffer(\n        sourceBuffer.numberOfChannels,\n        endSample - startSample,\n        sourceBuffer.sampleRate\n      );\n      \n      // Copy audio data to region buffer\n      for (let channel = 0; channel < sourceBuffer.numberOfChannels; channel++) {\n        const sourceData = sourceBuffer.getChannelData(channel);\n        const regionData = regionBuffer.getChannelData(channel);\n        for (let i = 0; i < regionBuffer.length; i++) {\n          regionData[i] = sourceData[startSample + i];\n        }\n      }\n      \n      return regionBuffer;\n    }\n    \n    // Extract feature frames from audio buffer\n    async function extractFeatureFrames(buffer) {\n      return new Promise((resolve) => {\n        const frames = [];\n        const offlineCtx = new OfflineAudioContext(\n          buffer.numberOfChannels,\n          buffer.length,\n          buffer.sampleRate\n        );\n        \n        const source = offlineCtx.createBufferSource();\n        source.buffer = buffer;\n        \n        // Create Meyda analyzer\n        const analyzer = Meyda.createMeydaAnalyzer({\n          audioContext: offlineCtx,\n          source: source,\n          bufferSize: frameSize,\n          hopSize: hopSize,\n          featureExtractors: ['rms', 'mfcc', 'spectralCentroid', 'spectralFlatness', 'zcr'],\n          callback: (features) => {\n            frames.push({\n              time: frames.length * (hopSize / offlineCtx.sampleRate),\n              rms: features.rms,\n              mfcc: features.mfcc,\n              spectralCentroid: features.spectralCentroid,\n              spectralFlatness: features.spectralFlatness,\n              zcr: features.zcr\n            });\n          }\n        });\n        \n        analyzer.start();\n        source.connect(offlineCtx.destination);\n        source.start();\n        \n        // When rendering is complete, return frames\n        offlineCtx.startRendering().then(() => {\n          log(`Extracted ${frames.length} frames from buffer`);\n          resolve(frames);\n        }).catch(err => {\n          console.error('Feature extraction error:', err);\n          log(`Feature extraction error: ${err.message}`);\n          resolve([]);\n        });\n      });\n    }\n    \n    // Extract tokens from audio buffer\n    async function extractTokensFromBuffer(buffer) {\n      const tokens = [];\n      \n      // Track frame features\n      const frames = await extractFeatureFrames(buffer);\n      \n      // Find key points in the audio (peaks, valleys, transitions)\n      for (let i = 2; i < frames.length - 2; i++) {\n        const prevFrame2 = frames[i-2];\n        const prevFrame = frames[i-1];\n        const frame = frames[i];\n        const nextFrame = frames[i+1];\n        const nextFrame2 = frames[i+2];\n        \n        // Skip frames with very low energy\n        if (frame.rms < 0.01) continue;\n        \n        // Determine token type based on audio characteristics\n        let tokenType = determineTokenType(frame, prevFrame, nextFrame);\n        \n        // Only add if it's a significant point in the audio\n        if (isSignificantPoint(frame, prevFrame, nextFrame, prevFrame2, nextFrame2)) {\n          tokens.push({\n            type: tokenType,\n            time: frame.time,\n            rms: frame.rms,\n            spectralCentroid: frame.spectralCentroid,\n            mfcc: frame.mfcc.slice(0, 5), // Only keep first 5 coefficients\n            spectralFlux: calculateSpectralFlux(frame, prevFrame),\n            zcr: frame.zcr\n          });\n        }\n      }\n      \n      // Simplify to avoid too many tokens\n      return simplifyTokenSequence(tokens);\n    }\n    \n    // Calculate spectral flux (difference from previous frame)\n    function calculateSpectralFlux(frame, prevFrame) {\n      if (!prevFrame) return 0;\n      \n      // Use spectral centroid difference as a simple flux measure\n      return Math.abs(frame.spectralCentroid - prevFrame.spectralCentroid);\n    }\n    \n    // Determine if this is a significant point in the audio\n    function isSignificantPoint(frame, prevFrame, nextFrame, prevFrame2, nextFrame2) {\n      if (!prevFrame || !nextFrame) return false;\n      \n      // Energy peak (local maximum)\n      const isEnergyPeak = frame.rms > prevFrame.rms && \n                          frame.rms > nextFrame.rms && \n                          frame.rms > 0.02;\n      \n      // Energy valley (local minimum)\n      const isEnergyValley = frame.rms < prevFrame.rms && \n                            frame.rms < nextFrame.rms && \n                            prevFrame.rms > 0.02 && \n                            nextFrame.rms > 0.02;\n      \n      // Spectral centroid peak (local maximum - bright sounds)\n      const isSpectralPeak = frame.spectralCentroid > prevFrame.spectralCentroid && \n                            frame.spectralCentroid > nextFrame.spectralCentroid &&\n                            frame.spectralCentroid > 3000;\n      \n      // Sharp rising edge in energy\n      const isRisingEdge = prevFrame2 && \n                          (frame.rms - prevFrame2.rms) > 0.03;\n      \n      // Sharp falling edge in energy\n      const isFallingEdge = nextFrame2 && \n                           (frame.rms - nextFrame2.rms) > 0.03;\n      \n      // Zero crossing rate peak (consonant sounds)\n      const isZcrPeak = frame.zcr > prevFrame.zcr && \n                        frame.zcr > nextFrame.zcr && \n                        frame.zcr > 0.3;\n      \n      return isEnergyPeak || isEnergyValley || isSpectralPeak || isZcrPeak || isRisingEdge || isFallingEdge;\n    }\n    \n    // Determine token type based on audio characteristics\n    function determineTokenType(frame, prevFrame, nextFrame) {\n      if (!prevFrame || !nextFrame) return 'E';\n      \n      // Energy rising\n      if (frame.rms > prevFrame.rms * 1.2 && frame.rms > 0.02) {\n        return 'A';\n      }\n      \n      // Energy falling\n      if (frame.rms < prevFrame.rms * 0.8 && prevFrame.rms > 0.02) {\n        return 'B';\n      }\n      \n      // High spectral content (bright/sharp sounds)\n      if (frame.spectralCentroid > 5000 && frame.rms > 0.02) {\n        return 'C';\n      }\n      \n      // Low spectral content (dull/muffled sounds)\n      if (frame.spectralCentroid < 2000 && frame.rms > 0.02) {\n        return 'D';\n      }\n      \n      // Default token type for background/silence\n      return 'E';\n    }\n    \n    // Simplify token sequence to avoid too many tokens\n    function simplifyTokenSequence(tokens) {\n      if (tokens.length <= 10) return tokens;\n      \n      // Group tokens by type and proximity\n      const simplified = [];\n      let lastTokenType = null;\n      let lastTokenTime = -1;\n      \n      for (let i = 0; i < tokens.length; i++) {\n        // Keep token if:\n        // 1. It's a different type than the last one\n        // 2. It's sufficiently separated in time\n        // 3. It's one of the first or last tokens\n        // 4. It's evenly spaced throughout (keep ~15 tokens total)\n        const timeDiff = lastTokenTime >= 0 ? tokens[i].time - lastTokenTime : 999;\n        \n        if (tokens[i].type !== lastTokenType || \n            timeDiff > 0.1 || \n            i === 0 || \n            i === tokens.length - 1 ||\n            i % Math.ceil(tokens.length / 15) === 0) {\n          simplified.push(tokens[i]);\n          lastTokenType = tokens[i].type;\n          lastTokenTime = tokens[i].time;\n        }\n      }\n      \n      return simplified;\n    }\n    \n    // Display template tokens\n    function displayTemplateTokens() {\n      // Clear previous display\n      tokenSequence.innerHTML = '';\n      activeTokenTypes.clear();\n      \n      // Display each token\n      templateTokens.forEach((token, index) => {\n        const tokenEl = document.createElement('div');\n        tokenEl.className = 'token';\n        tokenEl.style.backgroundColor = tokenColors[token.type];\n        \n        // Use letters A-Z for first 26, then numbers\n        const letter = index < 26 ? String.fromCharCode(65 + index) : (index - 25);\n        tokenEl.textContent = letter;\n        \n        // Add tooltip with more info\n        tokenEl.title = `Token ${letter}: Type ${token.type} (${tokenDescriptions[token.type]})\nRMS: ${token.rms.toFixed(3)}\nSpectral Centroid: ${(token.spectralCentroid/1000).toFixed(1)}kHz`;\n        \n        // Store token type for legend highlight\n        activeTokenTypes.add(token.type);\n        \n        // Add token type label\n        const labelEl = document.createElement('div');\n        labelEl.className = 'token-label';\n        labelEl.textContent = token.type;\n        tokenEl.appendChild(labelEl);\n        \n        // Add debug info tooltip\n        if (showFeatureValues) {\n          const debugInfo = document.createElement('div');\n          debugInfo.className = 'token-debug-info';\n          debugInfo.textContent = `RMS: ${token.rms.toFixed(3)}, SC: ${(token.spectralCentroid/1000).toFixed(1)}k`;\n          tokenEl.appendChild(debugInfo);\n        }\n        \n        tokenSequence.appendChild(tokenEl);\n      });\n      \n      // Update legend to highlight active token types\n      updateLegend();\n    }\n    \n    // Update legend to highlight active token types\n    function updateLegend() {\n      const legendItems = document.querySelectorAll('.legend-item');\n      \n      legendItems.forEach(item => {\n        const typeText = item.querySelector('span').textContent;\n        const type = typeText.charAt(0); // Get the letter (A, B, C, etc.)\n        \n        if (activeTokenTypes.has(type)) {\n          item.style.opacity = '1';\n          item.style.fontWeight = 'bold';\n        } else {\n          item.style.opacity = '0.5';\n          item.style.fontWeight = 'normal';\n        }\n      });\n    }\n\n// Start real-time analysis\nasync function startAnalysis() {\n  if (templateTokens.length === 0) {\n    log('Error: Template tokens not available');\n    return;\n  }\n  \n  // Reset state\n  resetAnalysisState();\n  \n  try {\n    // Access microphone\n    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n    const source = audioContext.createMediaStreamSource(stream);\n    \n    // Create Meyda analyzer\n    meydaAnalyzer = Meyda.createMeydaAnalyzer({\n      audioContext: audioContext,\n      source: source,\n      bufferSize: frameSize,\n      hopSize: hopSize,\n      featureExtractors: ['rms', 'mfcc', 'spectralCentroid', 'spectralFlatness', 'zcr'],\n      callback: processFrame\n    });\n    \n    meydaAnalyzer.start();\n    isAnalyzing = true;\n    \n    // Update UI\n    startAnalysisBtn.disabled = true;\n    stopAnalysisBtn.disabled = false;\n    liveActivity.innerHTML = 'Listening for thikr patterns...';\n    \n    log('Real-time analysis started. Recite thikr...');\n    \n  } catch (err) {\n    console.error('Error accessing microphone:', err);\n    log('Error: ' + err.message);\n  }\n}\n\n// Stop real-time analysis\nfunction stopAnalysis() {\n  if (meydaAnalyzer) {\n    meydaAnalyzer.stop();\n  }\n  \n  isAnalyzing = false;\n  \n  // Update UI\n  startAnalysisBtn.disabled = false;\n  stopAnalysisBtn.disabled = true;\n  liveActivity.innerHTML = 'Analysis stopped.';\n  \n  log('Analysis stopped.');\n}\n\n\nfunction processFrame(features) {\n  if (!isAnalyzing) return;\n  \n  const currentTime = audioContext.currentTime;\n  \n  // Create frame object\n  const frame = {\n    time: currentTime,\n    rms: features.rms || 0,\n    mfcc: features.mfcc || [],\n    spectralCentroid: features.spectralCentroid || 0,\n    spectralFlatness: features.spectralFlatness || 0,\n    zcr: features.zcr || 0\n  };\n  \n  // Add to frames buffer\n  prevFrames.push(frame);\n  if (prevFrames.length > 5) {\n    prevFrames.shift();\n  }\n  \n  // Need at least 3 frames to detect features\n  if (prevFrames.length < 3) return;\n  \n  // Get frames for context\n  const currentIdx = prevFrames.length - 1;\n  const prevFrame2 = prevFrames[Math.max(0, currentIdx - 2)];\n  const prevFrame = prevFrames[Math.max(0, currentIdx - 1)];\n  const currentFrame = prevFrames[currentIdx];\n  const nextFrame = null; // We don't have future frames in real-time\n  const nextFrame2 = null;\n  \n  // Check if this frame is a significant point AND enough time has passed since last token\n  if (isSignificantPoint(currentFrame, prevFrame, nextFrame, prevFrame2, nextFrame2) && \n      currentTime - lastTokenTime > 0.05) { // Minimum 50ms between tokens\n    \n    // Determine token type\n    const tokenType = determineTokenType(currentFrame, prevFrame, nextFrame);\n    \n    // Create token\n    const token = {\n      type: tokenType,\n      time: currentTime,\n      rms: currentFrame.rms,\n      spectralCentroid: currentFrame.spectralCentroid,\n      mfcc: currentFrame.mfcc.slice(0, 5),\n      spectralFlux: calculateSpectralFlux(currentFrame, prevFrame),\n      zcr: currentFrame.zcr\n    };\n    \n    // Add to token buffer\n    liveTokenBuffer.push(token);\n    lastTokenTime = currentTime;\n    \n    // Limit token buffer size (keep enough to match template)\n    const maxBuffer = Math.max(30, templateTokens.length * 2);\n    if (liveTokenBuffer.length > maxBuffer) {\n      liveTokenBuffer.shift();\n    }\n    \n    // Update activity display with more detailed token info\n    if (verboseLogging) {\n      updateLiveActivity(`Token ${tokenType} detected (RMS: ${token.rms.toFixed(3)}, SC: ${(token.spectralCentroid/1000).toFixed(1)}k Hz, ZCR: ${token.zcr.toFixed(3)})`);\n    } else {\n      updateLiveActivity(`Token ${tokenType} detected (${token.rms.toFixed(2)} energy)`);\n    }\n    \n    // Process for pattern matching\n    processTokenMatching();\n  }\n}\n\n// Process token matching\nfunction processTokenMatching() {\n  // Need a minimum number of tokens to start matching\n  if (liveTokenBuffer.length < Math.max(3, templateTokens.length / 2)) {\n    return;\n  }\n  \n  // Calculate similarity with template\n  const similarity = compareTokenSequences(templateTokens, liveTokenBuffer);\n  \n  // Add confidence marker\n  addConfidenceMarker(similarity);\n  \n  // Update confidence history\n  confidenceHistory.push(similarity);\n  if (confidenceHistory.length > 50) {\n    confidenceHistory.shift();\n  }\n  \n  // Update UI\n  updateProgressBar(similarity);\n  updateTokenVisualization(similarity);\n  \n  // Update activity display with confidence\n  updateLiveActivity(`Pattern match: ${(similarity * 100).toFixed(1)}% confidence`);\n  \n  if (verboseLogging) {\n    log(`Pattern match: ${(similarity * 100).toFixed(1)}% confidence`);\n  }\n  \n  // Check for detection\n  if (similarity >= matchThreshold && \n      audioContext.currentTime - lastDetectionTime > 2.0) { // Cooldown period\n    \n    // Register detection\n    detectionCount++;\n    counterDisplay.textContent = detectionCount;\n    lastDetectionTime = audioContext.currentTime;\n    \n    // Add to detection events log\n    const detectionEvent = {\n      id: detectionCount,\n      time: new Date().toISOString(),\n      similarity: similarity,\n      thresholdUsed: matchThreshold,\n      tokenCount: liveTokenBuffer.length,\n      tokenTypes: tokenTypeCounts(liveTokenBuffer)\n    };\n    detectionEvents.push(detectionEvent);\n    \n    // Update detection data display\n    updateDetectionData(detectionEvent);\n    \n    // Add detection flash\n    addDetectionFlash();\n    \n    // Apply wave animation\n    applyWaveAnimation();\n    \n    // Update activity display with detection\n    updateLiveActivity(`THIKR DETECTED (#${detectionCount}) with ${(similarity * 100).toFixed(1)}% confidence!`);\n    \n    log(`THIKR DETECTED (#${detectionCount}) with ${(similarity * 100).toFixed(1)}% confidence`);\n    \n    // Clear token buffer to look for next pattern\n    liveTokenBuffer = [];\n  }\n}\n\n// Update detection data display\nfunction updateDetectionData(event) {\n  // Format the detection data\n  const formattedData = `\n    <div style=\"border-bottom: 1px solid #dee2e6; padding-bottom: 10px; margin-bottom: 10px;\">\n      <strong>Detection #${event.id}</strong> (${new Date(event.time).toLocaleTimeString()})\n      <br>Confidence: ${(event.similarity * 100).toFixed(1)}% (threshold: ${(event.thresholdUsed * 100).toFixed(1)}%)\n      <br>Tokens: ${event.tokenCount} (${formatTokenTypeCounts(event.tokenTypes)})\n    </div>\n  `;\n  \n  // Add to detection data display\n  detectionData.innerHTML = formattedData + detectionData.innerHTML;\n  \n  // Keep only the last 10 events in the display\n  const items = detectionData.querySelectorAll('div');\n  if (items.length > 10) {\n    for (let i = 10; i < items.length; i++) {\n      items[i].remove();\n    }\n  }\n  \n  // Update debug output\n  updateDebugOutput();\n}\n\n// Format token type counts\nfunction formatTokenTypeCounts(counts) {\n  return Object.entries(counts)\n    .map(([type, count]) => `${type}:${count}`)\n    .join(', ');\n}\n\n// Count token types\nfunction tokenTypeCounts(tokens) {\n  const counts = {};\n  tokens.forEach(token => {\n    counts[token.type] = (counts[token.type] || 0) + 1;\n  });\n  return counts;\n}\n\n// Update live activity display\nfunction updateLiveActivity(message) {\n  const time = new Date().toLocaleTimeString();\n  const activityMessage = `[${time}] ${message}`;\n  \n  // Add new message at top\n  liveActivity.innerHTML = activityMessage + \"<br>\" + liveActivity.innerHTML;\n  \n  // Limit number of messages\n  const messages = liveActivity.innerHTML.split(\"<br>\");\n  if (messages.length > 10) {\n    liveActivity.innerHTML = messages.slice(0, 10).join(\"<br>\");\n  }\n}\n\n// Add confidence marker to visualization\nfunction addConfidenceMarker(confidence) {\n  // Create a marker\n  const marker = document.createElement('div');\n  marker.className = 'confidence-marker';\n  \n  // Position at the right edge, height based on confidence\n  const bottom = confidence * 100;\n  marker.style.bottom = `${bottom}%`;\n  marker.style.right = '0px';\n  \n  // Color based on threshold\n  if (confidence >= matchThreshold) {\n    marker.style.backgroundColor = 'green';\n  } else if (confidence >= minConfidence) {\n    marker.style.backgroundColor = 'yellow';\n  } else {\n    marker.style.backgroundColor = 'red';\n  }\n  \n  confidenceDisplay.appendChild(marker);\n  \n  // Animate movement\n  let position = 0;\n  const maxPosition = confidenceDisplay.offsetWidth;\n  const moveMarker = () => {\n    position += 2;\n    marker.style.right = `${position}px`;\n    \n    if (position <= maxPosition) {\n      requestAnimationFrame(moveMarker);\n    } else {\n      // Remove marker when it's off-screen\n      marker.remove();\n    }\n  };\n  \n  requestAnimationFrame(moveMarker);\n}\n\n// Update token visualization\nfunction updateTokenVisualization(overallConfidence) {\n  // Get all token elements\n  const tokenElements = tokenSequence.querySelectorAll('.token');\n  if (tokenElements.length === 0) return;\n  \n  // Calculate individual token matches\n  for (let i = 0; i < templateTokens.length && i < tokenElements.length; i++) {\n    const templateToken = templateTokens[i];\n    \n    // Find best matching token in live buffer\n    let bestMatch = 0;\n    for (let j = 0; j < liveTokenBuffer.length; j++) {\n      const liveToken = liveTokenBuffer[j];\n      if (templateToken.type === liveToken.type) {\n        const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - liveToken.rms) / 0.2);\n        bestMatch = Math.max(bestMatch, energySimilarity);\n      }\n    }\n    \n    // Reset animation\n    tokenElements[i].classList.remove('wave-effect');\n    void tokenElements[i].offsetWidth; // Force reflow to restart animation\n    \n    // Adjust token appearance based on match confidence\n    if (bestMatch > 0.7) {\n      // High confidence match\n      tokenElements[i].style.transform = `scale(${1 + bestMatch * 0.4})`;\n      \n      // Calculate color (yellow to green)\n      const r = Math.floor(255 * (1 - bestMatch));\n      const g = Math.floor(200);\n      const b = 0;\n      tokenElements[i].style.backgroundColor = `rgb(${r}, ${g}, ${b})`;\n      tokenElements[i].style.color = bestMatch > 0.8 ? 'white' : 'black';\n      tokenElements[i].style.boxShadow = `0 0 10px rgba(0, 255, 0, ${bestMatch * 0.8})`;\n      \n      // Add wave effect if high confidence\n      if (bestMatch > 0.85) {\n        tokenElements[i].classList.add('wave-effect');\n      }\n    } else if (bestMatch > 0.4) {\n      // Medium confidence match\n      tokenElements[i].style.transform = `scale(${1 + bestMatch * 0.2})`;\n      \n      // Yellow color\n      tokenElements[i].style.backgroundColor = `rgb(255, 204, 0)`;\n      tokenElements[i].style.color = 'black';\n      tokenElements[i].style.boxShadow = `0 0 5px rgba(255, 204, 0, ${bestMatch * 0.5})`;\n    } else {\n      // Low confidence or no match - reset to original\n      tokenElements[i].style.transform = 'scale(1)';\n      tokenElements[i].style.backgroundColor = tokenColors[templateToken.type];\n      tokenElements[i].style.color = 'black';\n      tokenElements[i].style.boxShadow = '0 2px 4px rgba(0,0,0,0.1)';\n    }\n    \n    // Update debug info on token\n    if (showFeatureValues) {\n      const debugInfo = tokenElements[i].querySelector('.token-debug-info');\n      if (debugInfo) {\n        debugInfo.textContent = `Match: ${(bestMatch * 100).toFixed(0)}%`;\n      }\n    }\n  }\n  \n  // If very high confidence, produce wave effect\n  if (overallConfidence > matchThreshold * 0.9) {\n    applyWaveAnimation();\n  }\n}\n\n// Apply wave animation sequence to tokens\nfunction applyWaveAnimation() {\n  const tokenElements = tokenSequence.querySelectorAll('.token');\n  \n  tokenElements.forEach((el, i) => {\n    setTimeout(() => {\n      el.classList.remove('wave-effect');\n      void el.offsetWidth; // Force reflow to restart animation\n      el.classList.add('wave-effect');\n    }, i * 100); // Stagger animation\n  });\n}\n\n// Add detection flash\nfunction addDetectionFlash() {\n  const flash = document.createElement('div');\n  flash.className = 'detection-flash';\n  tokenSequence.appendChild(flash);\n  \n  // Remove after animation completes\n  setTimeout(() => {\n    if (flash.parentNode) {\n      flash.parentNode.removeChild(flash);\n    }\n  }, 1500);\n}\n\n// Update progress bar\nfunction updateProgressBar(confidence) {\n  progressBar.style.height = `${confidence * 100}%`;\n}\n\n// Update threshold line position\nfunction updateThresholdLine() {\n  thresholdLine.style.bottom = `${matchThreshold * 100}%`;\n}\n\n// Reset analysis state\nfunction resetAnalysisState() {\n  liveTokenBuffer = [];\n  currentTokens = [];\n  confidenceHistory = [];\n  prevFrames = [];\n  lastTokenTime = 0;\n  lastDetectionTime = 0;\n  detectionCount = 0;\n  counterDisplay.textContent = detectionCount;\n  updateProgressBar(0);\n  liveActivity.innerHTML = 'Waiting to start analysis...';\n  \n  // Clear detection events\n  detectionEvents = [];\n  detectionData.innerHTML = '';\n  \n  // Reset token visualization\n  const tokenElements = tokenSequence.querySelectorAll('.token');\n  tokenElements.forEach((el, i) => {\n    if (i < templateTokens.length) {\n      const templateToken = templateTokens[i];\n      el.style.transform = 'scale(1)';\n      el.style.backgroundColor = tokenColors[templateToken.type];\n      el.style.color = 'black';\n      el.style.boxShadow = '0 2px 4px rgba(0,0,0,0.1)';\n    }\n  });\n  \n  // Clear confidence markers\n  document.querySelectorAll('.confidence-marker').forEach(el => el.remove());\n}\n\n// Reset the app\nfunction resetApp() {\n  // Stop recording if in progress\n  if (isRecording && recorder) {\n    recorder.stop();\n    isRecording = false;\n  }\n  \n  // Stop analysis if in progress\n  if (isAnalyzing) {\n    stopAnalysis();\n  }\n  \n  // Clear wavesurfer\n  wavesurfer.clearRegions();\n  wavesurfer.empty();\n  \n  // Reset variables\n  templateRegion = null;\n  calibrationRegions = [];\n  templateTokens = [];\n  templateBuffer = null;\n  calibrationMode = false;\n  \n  // Reset analysis state\n  resetAnalysisState();\n  \n  // Clear token display\n  tokenSequence.innerHTML = '';\n  \n  // Reset UI\n  recordBtn.disabled = false;\n  stopBtn.disabled = true;\n  playBtn.disabled = true;\n  createTemplateBtn.disabled = true;\n  calibrateBtn.disabled = true;\n  startAnalysisBtn.disabled = true;\n  stopAnalysisBtn.disabled = true;\n  \n  // Hide panels and reset counts\n  tokenContainer.style.display = 'none';\n  calibrationControls.style.display = 'none';\n  document.getElementById('calibrationPanel').style.display = 'none';\n  regionColorLegend.style.display = 'none';\n  regionCount.textContent = '0';\n  \n  // Reset calibration status\n  updateCalibrationStatus('pending');\n  \n  calibrationInfo.textContent = 'Record audio, then select a template region by dragging on the waveform.';\n  liveActivity.innerHTML = 'Waiting to start analysis...';\n  \n  // Clear diagnostics\n  diagnosticsLog.innerHTML = '';\n  detectionData.innerHTML = '';\n  debugOutput.innerHTML = '';\n  \n  log('App reset');\n}\n\n// Update the debug output \nfunction updateDebugOutput() {\n  // Create a formatted summary of the current state for easy copy/paste debugging\n  let output = \"=== THIKR COUNTER DEBUG DATA ===\\n\\n\";\n  \n  // Template info\n  output += \"TEMPLATE INFO:\\n\";\n  output += `--------------\\n`;\n  if (templateTokens.length > 0) {\n    output += `Token count: ${templateTokens.length}\\n`;\n    output += `Token sequence: ${templateTokens.map(t => t.type).join('')}\\n`;\n    \n    // Token type counts\n    const counts = {};\n    templateTokens.forEach(token => {\n      counts[token.type] = (counts[token.type] || 0) + 1;\n    });\n    \n    output += `Token distribution: ${Object.entries(counts)\n      .map(([type, count]) => `${type}:${count} (${Math.round(count/templateTokens.length*100)}%)`)\n      .join(', ')}\\n\\n`;\n      \n    // Detailed token data (first 5 tokens)\n    output += \"FIRST 5 TEMPLATE TOKENS:\\n\";\n    templateTokens.slice(0, 5).forEach((token, i) => {\n      output += `[${i}] Type:${token.type} | RMS:${token.rms.toFixed(3)} | SC:${token.spectralCentroid.toFixed(0)} | ZCR:${token.zcr ? token.zcr.toFixed(3) : 'N/A'}\\n`;\n    });\n  } else {\n    output += \"No template tokens available\\n\";\n  }\n  \n  // Calibration info\n  output += \"\\nCALIBRATION INFO:\\n\";\n  output += `-----------------\\n`;\n  output += `Regions: ${calibrationRegions.length}\\n`;\n  output += `Match threshold: ${(matchThreshold * 100).toFixed(1)}%\\n`;\n  output += `Min confidence: ${(minConfidence * 100).toFixed(1)}%\\n\\n`;\n  \n  // Calibration regions\n  if (calibrationRegions.length > 0) {\n    output += \"CALIBRATION REGIONS:\\n\";\n    calibrationRegions.forEach((region, i) => {\n      const similarity = region.data && region.data.similarity ? \n        (region.data.similarity * 100).toFixed(1) + '%' : 'Not calculated';\n        \n      output += `[${i}] Time: ${region.start.toFixed(2)}s-${region.end.toFixed(2)}s | Duration: ${(region.end - region.start).toFixed(2)}s | Similarity: ${similarity}\\n`;\n      \n      // Add token details if available\n      if (region.data && region.data.tokens && region.data.tokens.length > 0) {\n        const tokens = region.data.tokens;\n        output += `    Tokens: ${tokens.length} | Types: ${tokens.map(t => t.type).join('')}\\n`;\n      }\n    });\n  }\n  \n  // Detection history\n  output += \"\\nDETECTION HISTORY:\\n\";\n  output += `----------------\\n`;\n  if (detectionEvents.length > 0) {\n    detectionEvents.slice(-5).reverse().forEach(event => {\n      output += `[#${event.id}] Time: ${new Date(event.time).toLocaleTimeString()} | Confidence: ${(event.similarity * 100).toFixed(1)}%\\n`;\n      output += `    Tokens: ${event.tokenCount} | Types: ${formatTokenTypeCounts(event.tokenTypes)}\\n`;\n    });\n  } else {\n    output += \"No detections recorded\\n\";\n  }\n  \n  // Update the debug output element\n  debugOutput.textContent = output;\n}\n\n// Copy all diagnostics to clipboard\nfunction copyAllDiagnostics() {\n  // Combine all diagnostic data\n  const allData = debugOutput.textContent + \n    \"\\n\\n=== LOG MESSAGES ===\\n\" + \n    diagnosticsLog.textContent;\n  \n  // Copy to clipboard\n  navigator.clipboard.writeText(allData)\n    .then(() => {\n      alert(\"Diagnostic data copied to clipboard!\");\n    })\n    .catch(err => {\n      console.error('Error copying text: ', err);\n      alert(\"Failed to copy. Please select and copy the text manually.\");\n    });\n}\n\n// Utility: Log message to diagnostics box\nfunction log(message) {\n  const time = new Date().toLocaleTimeString();\n  diagnosticsLog.innerHTML += `[${time}] ${message}\\n`;\n  diagnosticsLog.scrollTop = diagnosticsLog.scrollHeight;\n  console.log(message); // Also log to console for debugging\n}\n\n// Initialize the app when the page loads\nwindow.addEventListener('load', init);\n\n// Initialize Audio Context\nfunction initAudioContext() {\n  audioContext = new (window.AudioContext || window.webkitAudioContext)();\n}\n\n// Initialize enhanced calibration\nfunction initEnhancedCalibration() {\n  // Add event listeners for the feature type selector\n  document.querySelectorAll('input[name=\"featureType\"]').forEach(radio => {\n    radio.addEventListener('change', event => {\n      selectedFeatureType = event.target.value;\n      updateFeatureComparison();\n    });\n  });\n  \n  // Add event listeners for threshold sliders\n  const matchThresholdSlider = document.getElementById('matchThresholdSlider');\n  const minConfidenceSlider = document.getElementById('minConfidenceSlider');\n  \n  matchThresholdSlider.addEventListener('input', function() {\n    const value = this.value / 100;\n    document.getElementById('matchThresholdValue').textContent = `${this.value}%`;\n    matchThreshold = value;\n    updateThresholdLine();\n  });\n  \n  minConfidenceSlider.addEventListener('input', function() {\n    const value = this.value / 100;\n    document.getElementById('minConfidenceValue').textContent = `${this.value}%`;\n    minConfidence = value;\n  });\n}\n</script>\n</body>\n</html>",
      "created_at": "2025-03-23T15:57:04.986000",
      "sequence_order": 14,
      "parent_id": "8f132a3d-c6c1-4183-bd04-7be8bbb2afc7",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "2c58815f-e74d-466d-a8cf-de5c0a69a514",
      "role": "tool",
      "content": "**Debugging region.js error**\n\nThe user is facing an error related to reading `region.start` as undefined in `region.js` at line 94. It seems to happen when creating a template via the `createTemplate` function. The issue likely arises when the region is either not properly defined before accessing its `start` property, or there's an error in the callback that creates the region. I need to check the dependencies or initialization of the region object or look at any surrounding async behavior to debug this further.\n\n**Investigating region.js error**\n\nI see that in the `createTemplate` function, the code checks for regions but then calls `region.start` and `region.end` without confirming the region is still valid. The error in question happens when those properties are accessed on an undefined region. \n\nIt seems like `region.remove()` might be happening in the `enhancedSelectCalibrationRegion` function, which could lead to the region being undefined when accessed later. This could be the cause of the error when calling `createTemplate`.\n\nIt looks like the issue is how removed regions are handled — they might still be referenced, causing the error.\n\n**Investigating region.remove() and error**\n\nIn `createTemplate`, the region is checked for validity, but the error suggests that `region.start` may still be undefined. I suspect the problem arises when a region is removed in `enhancedSelectCalibrationRegion` but still referenced, causing it to be undefined when accessed later in the `region.js` code. A potential solution could be to avoid `wavesurfer.clearRegions()` and instead handle removing regions one at a time from `wavesurfer.regions.list` to prevent premature updates or removal mishaps, ensuring all regions are fully defined before use.",
      "created_at": "2025-03-23T15:57:22.599343",
      "sequence_order": 15,
      "parent_id": "9d68ea36-ed54-431c-933a-5b8317653a3f",
      "metadata": {
        "status": "finished_successfully",
        "weight": 0,
        "end_turn": null
      }
    },
    {
      "id": "4b2ea4af-2398-44c9-a13e-80833eb3c8d0",
      "role": "assistant",
      "content": "The error message\n\n```\nUncaught (in promise) TypeError: Cannot read properties of undefined (reading 'start')\n```\n\nindicates that somewhere (typically in the Wavesurfer Regions plugin code) a region object is being accessed even though it’s undefined or its properties (like `start`) are missing.\n\nIn our case, the culprit is the event handler for region updates. For example, the handler:\n\n```js\nwavesurfer.on('region-update-end', function(region) {\n  log(`Region updated: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n});\n```\n\nassumes that the region object is valid. However, if the region has been removed (or not yet fully defined), then accessing `region.start` causes the error.\n\nTo fix this, you should add a safety check (a “guard”) before using the region’s properties. For example:\n\n```js\nwavesurfer.on('region-update-end', function(region) {\n  if (!region || typeof region.start === 'undefined' || typeof region.end === 'undefined') {\n    return;\n  }\n  log(`Region updated: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n});\n```\n\nThis way, if the region is undefined or its properties are missing, the handler simply exits without throwing an error.\n\n---\n\n### **Why It Happens**\n\n- **Fast or Tiny Regions:** Sometimes a very short or quickly created/removed region (e.g. from an accidental drag or quick click) might be removed or not fully defined when the update event fires.\n- **Region Removal:** In your calibration flow, you call `region.remove()` for the original region once you’ve created a calibration region. That removed region may still trigger an update event in the plugin, causing the error.\n\n---\n\n### **How to Fix It**\n\n1. **Add Null Checks in Event Handlers:** Update your event handlers (like for `region-update-end`) to verify that the region object is valid before accessing its properties.\n\n2. **(Optional) Validate Regions in Other Parts:** You might also want to add similar checks in your functions (such as in `createTemplate` or `extractRegionAudio`) where you assume that a region is valid.\n\nBelow is a snippet that shows the fix in the region-update-end event:\n\n---\n\n#### **Fixed Region-Update Handler (Snippet)**\n\n```js\nwavesurfer.on('region-update-end', function(region) {\n  // Check if region is valid\n  if (!region || typeof region.start === 'undefined' || typeof region.end === 'undefined') {\n    return;\n  }\n  log(`Region updated: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n});\n```\n\n---\n\n### **Next Steps**\n\n- Make sure you add similar guards in any place where you access `region.start` or `region.end` (for example, in your `createTemplate` function you already check for validity).\n- Test your workflow (template extraction, calibration region selection, etc.) to confirm that the error no longer appears.\n\nBy adding these guards, you prevent the code from trying to read properties from an undefined region, thereby stopping the error.",
      "created_at": "2025-03-23T15:57:15.545865",
      "sequence_order": 16,
      "parent_id": "2c58815f-e74d-466d-a8cf-de5c0a69a514",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "8a756e69-5fde-4bf1-a3fa-9c261ab6ec5e",
      "role": "user",
      "content": "still have this issue, find a new fix, we can change process if needed: (index):2470 \n Error in createTemplate: TypeError: Cannot read properties of undefined (reading 'start')\n    at e.value (region.js:94:20)\n    at HTMLButtonElement.createTemplate ((index):2419:20)\ncreateTemplate\t@\t(index):2470\n\n[[[<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Thikr Counter - Visual Pattern Recognition</title>\n  <script src=\"https://unpkg.com/wavesurfer.js@6.6.3\"></script>\n  <script src=\"https://unpkg.com/wavesurfer.js@6.6.3/dist/plugin/wavesurfer.regions.min.js\"></script>\n  <script src=\"https://unpkg.com/wavesurfer.js@6.6.3/dist/plugin/wavesurfer.timeline.min.js\"></script>\n  <script src=\"https://unpkg.com/meyda@5.6.1/dist/web/meyda.min.js\"></script>\n  <style>\n    body {\n      font-family: system-ui, sans-serif;\n      max-width: 1000px;\n      margin: 0 auto;\n      padding: 20px;\n      background-color: #f5f5f5;\n    }\n    \n    .panel {\n      background: white;\n      border-radius: 8px;\n      padding: 20px;\n      margin-bottom: 20px;\n      box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n    }\n    \n    button {\n      background-color: #4c6ef5;\n      color: white;\n      border: none;\n      padding: 8px 16px;\n      margin: 5px;\n      border-radius: 4px;\n      cursor: pointer;\n      font-weight: 500;\n      transition: all 0.2s ease;\n    }\n    \n    button:hover:not(:disabled) {\n      background-color: #364fc7;\n      transform: translateY(-1px);\n    }\n    \n    button:disabled {\n      background-color: #a5b4fc;\n      cursor: not-allowed;\n    }\n    \n    .waveform {\n      border: 1px solid #e9ecef;\n      border-radius: 4px;\n      overflow: hidden;\n      margin: 10px 0;\n      height: 128px; /* Explicitly set height */\n      width: 100%;\n      background-color: #f8f9fa;\n      position: relative;\n    }\n    \n    #waveform-timeline {\n      height: 30px;\n      border-bottom: 1px solid #e9ecef;\n      margin-bottom: 10px;\n    }\n    \n    #counter {\n      font-size: 64px;\n      font-weight: bold;\n      text-align: center;\n      color: #4c6ef5;\n      padding: 20px;\n    }\n    \n    #confidenceDisplay {\n      height: 100px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      margin: 10px 0;\n      position: relative;\n    }\n    \n    .progress-bar {\n      position: absolute;\n      bottom: 0;\n      left: 0;\n      width: 100%;\n      background-color: #4c6ef5;\n      transition: height 0.1s;\n      height: 0%;\n    }\n    \n    .threshold-line {\n      position: absolute;\n      width: 100%;\n      height: 2px;\n      background-color: #fa5252;\n      z-index: 2;\n      bottom: 75%; /* Default position */\n    }\n    \n    #tokenContainer {\n      margin-top: 20px;\n    }\n    \n    #tokenSequence {\n      display: flex;\n      flex-wrap: wrap;\n      padding: 20px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      min-height: 80px;\n      margin: 10px 0;\n      position: relative;\n    }\n    \n    .token {\n      display: inline-flex;\n      align-items: center;\n      justify-content: center;\n      width: 50px;\n      height: 50px;\n      margin: 5px;\n      border-radius: 4px;\n      font-weight: bold;\n      font-size: 20px;\n      transition: all 0.3s ease;\n      position: relative;\n      box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n    }\n    \n    .token-label {\n      position: absolute;\n      top: -15px;\n      font-size: 10px;\n      color: #495057;\n    }\n    \n    #legend {\n      display: flex;\n      flex-wrap: wrap;\n      gap: 10px;\n      padding: 10px;\n      margin-top: 10px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .legend-item {\n      display: flex;\n      align-items: center;\n      margin-right: 15px;\n    }\n    \n    .legend-color {\n      width: 20px;\n      height: 20px;\n      border-radius: 3px;\n      margin-right: 5px;\n    }\n    \n    #liveActivity {\n      margin-top: 10px;\n      padding: 10px;\n      background-color: #e9ecef;\n      border-radius: 4px;\n      font-family: monospace;\n      font-size: 12px;\n      min-height: 60px;\n      overflow-y: auto;\n    }\n    \n    #diagnostics {\n      height: 200px;\n      overflow-y: auto;\n      font-family: monospace;\n      font-size: 12px;\n      background-color: #212529;\n      color: #f8f9fa;\n      padding: 10px;\n      border-radius: 4px;\n      white-space: pre-wrap;\n    }\n    \n    #calibrationInfo {\n      margin-top: 10px;\n      padding: 10px;\n      background-color: #e9ecef;\n      border-radius: 4px;\n      font-size: 14px;\n    }\n    \n    .detection-flash {\n      position: absolute;\n      width: 100%;\n      height: 100%;\n      background-color: rgba(76, 175, 80, 0.3);\n      top: 0;\n      left: 0;\n      z-index: 10;\n      animation: flash-animation 1.5s forwards;\n      pointer-events: none;\n    }\n    \n    .confidence-marker {\n      position: absolute;\n      height: 10px;\n      width: 10px;\n      border-radius: 50%;\n      background-color: green;\n      transform: translate(-50%, -50%);\n      z-index: 3;\n    }\n    \n    @keyframes flash-animation {\n      0% { opacity: 0.8; }\n      100% { opacity: 0; }\n    }\n    \n    @keyframes wave-animation {\n      0% { transform: scale(1); opacity: 0.7; }\n      50% { transform: scale(1.4); opacity: 1; }\n      100% { transform: scale(1); opacity: 0.7; }\n    }\n    \n    @keyframes pulse-animation {\n      0% { box-shadow: 0 0 0 0 rgba(76, 110, 245, 0.7); }\n      70% { box-shadow: 0 0 0 15px rgba(76, 110, 245, 0); }\n      100% { box-shadow: 0 0 0 0 rgba(76, 110, 245, 0); }\n    }\n    \n    .wave-effect {\n      animation: wave-animation 0.5s ease;\n    }\n    \n    .pulse-effect {\n      animation: pulse-animation 1.5s infinite;\n    }\n    \n    .control-group {\n      display: flex;\n      flex-wrap: wrap;\n      gap: 5px;\n      margin-bottom: 10px;\n    }\n    \n    h2 {\n      margin-top: 0;\n      color: #343a40;\n    }\n    \n    label {\n      font-weight: bold;\n      display: block;\n      margin-bottom: 5px;\n    }\n    \n    .instruction {\n      font-style: italic;\n      color: #6c757d;\n      margin-bottom: 10px;\n    }\n    \n    .region-count {\n      display: inline-block;\n      background-color: #4c6ef5;\n      color: white;\n      border-radius: 50%;\n      width: 24px;\n      height: 24px;\n      text-align: center;\n      line-height: 24px;\n      font-size: 14px;\n      margin-left: 10px;\n    }\n    \n    /* Enhanced Calibration Styles */\n    .calibration-panel {\n      margin-top: 20px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      padding: 15px;\n    }\n    \n    .region-list {\n      max-height: 300px;\n      overflow-y: auto;\n      margin: 10px 0;\n    }\n    \n    .region-item {\n      display: flex;\n      justify-content: space-between;\n      align-items: center;\n      padding: 10px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      margin-bottom: 8px;\n      cursor: pointer;\n      transition: all 0.2s ease;\n    }\n    \n    .region-item:hover {\n      background-color: #e9ecef;\n      transform: translateY(-1px);\n    }\n    \n    .region-item.selected {\n      background-color: #cfe8ff;\n      border-color: #4c6ef5;\n      box-shadow: 0 0 0 2px rgba(76, 110, 245, 0.5);\n    }\n    \n    .region-item .region-info {\n      flex-grow: 1;\n    }\n    \n    .region-item .region-actions {\n      display: flex;\n      gap: 5px;\n    }\n    \n    .region-item .similarity-score {\n      display: inline-block;\n      margin-left: 10px;\n      padding: 2px 8px;\n      background-color: #4c6ef5;\n      color: white;\n      border-radius: 10px;\n      font-size: 12px;\n      font-weight: bold;\n    }\n    \n    .region-item .region-color-indicator {\n      width: 12px;\n      height: 30px;\n      border-radius: 3px;\n      margin-right: 10px;\n    }\n    \n    /* Comparison visualization styles */\n    .comparison-container {\n      margin-top: 20px;\n      padding: 15px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .comparison-row {\n      display: flex;\n      align-items: center;\n      margin-bottom: 15px;\n      padding-bottom: 10px;\n      border-bottom: 1px solid #e9ecef;\n    }\n    \n    .comparison-label {\n      width: 120px;\n      font-weight: bold;\n      margin-right: 10px;\n    }\n    \n    .comparison-waveform {\n      flex-grow: 1;\n      height: 60px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      position: relative;\n      overflow: hidden;\n    }\n    \n    .comparison-tokens {\n      display: flex;\n      padding: 10px;\n      overflow-x: auto;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      margin-top: 5px;\n    }\n    \n    .mini-token {\n      display: inline-flex;\n      align-items: center;\n      justify-content: center;\n      min-width: 30px;\n      height: 30px;\n      margin-right: 3px;\n      border-radius: 3px;\n      font-weight: bold;\n      font-size: 12px;\n      box-shadow: 0 1px 2px rgba(0,0,0,0.1);\n    }\n    \n    /* Feature comparison visualization */\n    .feature-comparison {\n      margin-top: 15px;\n      padding: 10px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .comparison-chart {\n      height: 200px;\n      position: relative;\n      margin-top: 10px;\n      border-bottom: 1px solid #dee2e6;\n      border-left: 1px solid #dee2e6;\n    }\n    \n    .feature-series {\n      position: absolute;\n      bottom: 0;\n      left: 0;\n      display: flex;\n      align-items: flex-end;\n      height: 100%;\n      width: 100%;\n    }\n    \n    .feature-point {\n      flex: 1;\n      margin: 0 1px;\n      position: relative;\n    }\n    \n    .feature-bar {\n      width: 100%;\n      background-color: #4c6ef5;\n      position: absolute;\n      bottom: 0;\n    }\n    \n    .template-bar {\n      background-color: rgba(255, 86, 0, 0.6);\n    }\n    \n    .calibration-bar {\n      background-color: rgba(0, 200, 83, 0.6);\n    }\n    \n    .selected-region-bar {\n      background-color: rgba(76, 110, 245, 0.8);\n    }\n    \n    .feature-type-selector {\n      display: flex;\n      gap: 10px;\n      margin-bottom: 10px;\n    }\n    \n    .feature-type-selector label {\n      margin-bottom: 0;\n      font-weight: normal;\n    }\n    \n    .calibration-summary {\n      display: flex;\n      flex-wrap: wrap;\n      gap: 10px;\n      margin-top: 15px;\n    }\n    \n    .summary-card {\n      flex: 1;\n      min-width: 120px;\n      padding: 10px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      text-align: center;\n    }\n    \n    .summary-value {\n      font-size: 24px;\n      font-weight: bold;\n      margin: 5px 0;\n    }\n    \n    .summary-label {\n      font-size: 12px;\n      color: #6c757d;\n    }\n    \n    /* Threshold adjustment sliders */\n    .threshold-adjustment {\n      margin-top: 15px;\n      padding: 15px;\n      background-color: white;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .slider-container {\n      display: flex;\n      align-items: center;\n      margin-bottom: 10px;\n    }\n    \n    .slider-container label {\n      width: 150px;\n      margin-bottom: 0;\n    }\n    \n    .slider-container input[type=\"range\"] {\n      flex-grow: 1;\n      margin-right: 10px;\n    }\n    \n    .slider-value {\n      width: 40px;\n      text-align: right;\n    }\n    \n    /* Enhanced region visualization */\n    .region-color-palette {\n      display: flex;\n      margin: 10px 0;\n      gap: 10px;\n    }\n    \n    .color-item {\n      display: flex;\n      align-items: center;\n    }\n    \n    .color-swatch {\n      width: 20px;\n      height: 20px;\n      border-radius: 3px;\n      margin-right: 5px;\n    }\n    \n    /* Enhanced diagnostics styles */\n    .token-debug-info {\n      position: absolute;\n      bottom: -25px;\n      font-size: 9px;\n      color: #6c757d;\n      left: 0;\n      right: 0;\n      text-align: center;\n      white-space: nowrap;\n      overflow: hidden;\n      text-overflow: ellipsis;\n    }\n    \n    .diagnostic-controls {\n      margin-bottom: 10px;\n      display: flex;\n      gap: 10px;\n      align-items: center;\n    }\n    \n    .copy-diagnostics {\n      background-color: #212529;\n      color: white;\n      border: 1px solid #495057;\n      padding: 5px 10px;\n      border-radius: 4px;\n      cursor: pointer;\n      font-size: 12px;\n    }\n    \n    .diagnostics-options label {\n      display: inline-flex;\n      align-items: center;\n      margin-right: 10px;\n      font-weight: normal;\n      font-size: 12px;\n    }\n    \n    .diagnostic-section {\n      margin-top: 10px;\n      padding: 10px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      font-family: monospace;\n      font-size: 12px;\n    }\n    \n    #detectionData {\n      max-height: 150px;\n      overflow-y: auto;\n    }\n    \n    #debugOutput {\n      font-family: monospace;\n      white-space: pre;\n      font-size: 12px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      padding: 10px;\n      margin-top: 10px;\n      overflow-x: auto;\n    }\n    \n    .debug-help {\n      font-size: 12px;\n      color: #6c757d;\n      margin-top: 5px;\n      margin-bottom: 10px;\n      font-style: italic;\n    }\n    \n    /* Status indicator */\n    .status-indicator {\n      display: inline-flex;\n      align-items: center;\n      margin-left: 10px;\n      padding: 3px 8px;\n      border-radius: 12px;\n      font-size: 12px;\n      font-weight: bold;\n    }\n    \n    .status-ready {\n      background-color: #d3f9d8;\n      color: #2b8a3e;\n    }\n    \n    .status-pending {\n      background-color: #fff3bf;\n      color: #e67700;\n    }\n    \n    .status-error {\n      background-color: #ffe3e3;\n      color: #c92a2a;\n    }\n    \n    /* Tooltip styles */\n    .tooltip {\n      position: relative;\n      display: inline-block;\n      cursor: help;\n    }\n    \n    .tooltip .tooltip-text {\n      visibility: hidden;\n      width: 200px;\n      background-color: #212529;\n      color: #fff;\n      text-align: center;\n      border-radius: 6px;\n      padding: 5px;\n      position: absolute;\n      z-index: 1;\n      bottom: 125%;\n      left: 50%;\n      transform: translateX(-50%);\n      opacity: 0;\n      transition: opacity 0.3s;\n    }\n    \n    .tooltip:hover .tooltip-text {\n      visibility: visible;\n      opacity: 1;\n    }\n  </style>\n</head>\n<body>\n  <h1>Thikr Counter - Visual Pattern Recognition</h1>\n  \n  <div class=\"panel\">\n    <h2>1. Record & Extract Template</h2>\n    <div class=\"instruction\">Record your thikr, then use your mouse to drag-select the region containing a single complete thikr recitation.</div>\n    <div class=\"control-group\">\n      <button id=\"recordBtn\">Record Audio</button>\n      <button id=\"stopBtn\" disabled>Stop Recording</button>\n      <button id=\"playBtn\" disabled>Play Audio</button>\n      <button id=\"resetBtn\">Reset</button>\n    </div>\n    \n    <div id=\"counter\">0</div>\n    \n    <div id=\"waveformContainer\">\n      <label>Waveform Display</label>\n      <div id=\"waveform-timeline\"></div>\n      <div id=\"waveform\" class=\"waveform\"></div>\n      <div class=\"control-group\">\n        <button id=\"createTemplateBtn\" disabled>Extract Template Tokens</button>\n        <div id=\"calibrationControls\" style=\"display: none;\">\n          <button id=\"selectCalibrationBtn\">Add Calibration Region</button>\n          <span id=\"regionCount\" class=\"region-count\">0</span>\n          <button id=\"calibrateBtn\" disabled>Run Calibration</button>\n          <span id=\"calibrationStatus\" class=\"status-indicator status-pending\">Pending</span>\n        </div>\n      </div>\n    </div>\n    \n    <div id=\"calibrationInfo\">\n      Record audio, then select a template region by dragging on the waveform.\n    </div>\n    \n    <!-- Color legend for regions -->\n    <div id=\"regionColorLegend\" class=\"region-color-palette\" style=\"display: none;\">\n      <div class=\"color-item\">\n        <div class=\"color-swatch\" style=\"background-color: rgba(255, 86, 0, 0.6);\"></div>\n        <span>Template</span>\n      </div>\n      <div class=\"color-item\">\n        <div class=\"color-swatch\" style=\"background-color: rgba(0, 200, 83, 0.6);\"></div>\n        <span>Calibration Region</span>\n      </div>\n      <div class=\"color-item\">\n        <div class=\"color-swatch\" style=\"background-color: rgba(76, 110, 245, 0.8);\"></div>\n        <span>Selected Region</span>\n      </div>\n    </div>\n    \n    <!-- New Calibration Management UI -->\n    <div id=\"calibrationPanel\" class=\"calibration-panel\" style=\"display: none;\">\n      <h3>Calibration Regions</h3>\n      <p class=\"instruction\">Manage your calibration regions. Click on a region to select and view its features.</p>\n      \n      <!-- Region List -->\n      <div id=\"regionList\" class=\"region-list\">\n        <!-- Region items will be added here dynamically -->\n      </div>\n      \n      <!-- Calibration Comparison View -->\n      <div class=\"comparison-container\" id=\"comparisonContainer\">\n        <h3>Thikr Comparison View</h3>\n        <p class=\"instruction\">Visual comparison of all calibration regions against the template.</p>\n        <div id=\"comparisonRows\">\n          <!-- Comparison rows will be added here dynamically -->\n        </div>\n      </div>\n      \n      <!-- Feature Comparison Visualization -->\n      <div class=\"feature-comparison\">\n        <h3>Feature Analysis</h3>\n        <div class=\"feature-type-selector\">\n          <label><input type=\"radio\" name=\"featureType\" value=\"energy\" checked> Energy (RMS)</label>\n          <label><input type=\"radio\" name=\"featureType\" value=\"centroid\"> Spectral Centroid</label>\n          <label><input type=\"radio\" name=\"featureType\" value=\"zcr\"> Zero Crossing Rate</label>\n          <label><input type=\"radio\" name=\"featureType\" value=\"tokens\"> Token Types</label>\n        </div>\n        \n        <div id=\"comparisonChart\" class=\"comparison-chart\">\n          <!-- Feature visualization will be generated here -->\n        </div>\n      </div>\n      \n      <!-- Calibration Summary -->\n      <div class=\"calibration-summary\">\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"avgSimilarity\">-</div>\n          <div class=\"summary-label\">Average Similarity</div>\n        </div>\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"minSimilarity\">-</div>\n          <div class=\"summary-label\">Min Similarity</div>\n        </div>\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"maxSimilarity\">-</div>\n          <div class=\"summary-label\">Max Similarity</div>\n        </div>\n        <div class=\"summary-card\">\n          <div class=\"summary-value\" id=\"stdDevSimilarity\">-</div>\n          <div class=\"summary-label\">Std Deviation</div>\n        </div>\n      </div>\n      \n      <!-- Threshold Adjustment -->\n      <div class=\"threshold-adjustment\">\n        <h4>Threshold Adjustments</h4>\n        <div class=\"slider-container\">\n          <label for=\"matchThresholdSlider\">Match Threshold:</label>\n          <input type=\"range\" id=\"matchThresholdSlider\" min=\"0\" max=\"100\" value=\"75\">\n          <span class=\"slider-value\" id=\"matchThresholdValue\">75%</span>\n        </div>\n        <div class=\"slider-container\">\n          <label for=\"minConfidenceSlider\">Min Confidence:</label>\n          <input type=\"range\" id=\"minConfidenceSlider\" min=\"0\" max=\"100\" value=\"30\">\n          <span class=\"slider-value\" id=\"minConfidenceValue\">30%</span>\n        </div>\n      </div>\n    </div>\n  </div>\n  \n  <div class=\"panel\" id=\"tokenContainer\" style=\"display: none;\">\n    <h2>2. Token Visualization</h2>\n    <div class=\"instruction\">These tokens represent the distinctive audio patterns in your thikr. During detection, they will grow and change color as matches are found.</div>\n    \n    <div id=\"legend\">\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #4dabf7;\"></div>\n        <span>A: Energy Rise (vowel onset)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #f783ac;\"></div>\n        <span>B: Energy Fall (syllable end)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #8ce99a;\"></div>\n        <span>C: High Frequency (consonants)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #ffd43b;\"></div>\n        <span>D: Low Frequency (low vowels)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #a5d8ff;\"></div>\n        <span>E: Transition</span>\n      </div>\n    </div>\n    \n    <div id=\"tokenSequence\"></div>\n  </div>\n  \n  <div class=\"panel\">\n    <h2>3. Live Pattern Detection</h2>\n    <div class=\"instruction\">Start analysis and recite your thikr. The system will detect patterns and show confidence levels in real-time.</div>\n    \n    <div class=\"control-group\">\n      <button id=\"startAnalysisBtn\" disabled>Start Analysis</button>\n      <button id=\"stopAnalysisBtn\" disabled>Stop Analysis</button>\n    </div>\n    \n    <label>Pattern Match Confidence</label>\n    <div id=\"confidenceDisplay\">\n      <div class=\"threshold-line\"></div>\n      <div class=\"progress-bar\"></div>\n    </div>\n    \n    <label>Live Activity</label>\n    <div id=\"liveActivity\">Waiting to start analysis...</div>\n  </div>\n  \n  <!-- Enhanced Diagnostics Panel -->\n  <div class=\"panel\">\n    <h2>Diagnostics</h2>\n    <div class=\"debug-help\">\n      This panel provides detailed information for debugging. All data can be copied and pasted to share with developers.\n    </div>\n    \n    <div class=\"diagnostic-controls\">\n      <button class=\"copy-diagnostics\" id=\"copyDiagnosticsBtn\">Copy All Diagnostics</button>\n      <div class=\"diagnostics-options\">\n        <label><input type=\"checkbox\" id=\"verboseLogging\" checked> Verbose Logging</label>\n        <label><input type=\"checkbox\" id=\"showFeatureValues\" checked> Show Feature Values</label>\n      </div>\n    </div>\n    \n    <div id=\"diagnostics\"></div>\n    \n    <!-- Pattern Detection Data -->\n    <h3>Pattern Detection Data</h3>\n    <div class=\"debug-help\">\n      The most recent pattern detection events with detailed metrics. This data is useful for troubleshooting false positives/negatives.\n    </div>\n    <div id=\"detectionData\" class=\"diagnostic-section\"></div>\n    \n    <!-- Debug Output for Copy/Paste -->\n    <h3>Recognition Debug Data</h3>\n    <div class=\"debug-help\">\n      This formatted data can be copied and shared to help debug the recognition process.\n    </div>\n    <pre id=\"debugOutput\"></pre>\n  </div>\n\n  <script>\n    // Global variables\n    let audioContext;\n    let wavesurfer;\n    let recorder;\n    let recordedChunks = [];\n    let isRecording = false;\n    let meydaAnalyzer = null;\n    let calibrationMode = false;\n    \n    // Audio processing configuration\n    const frameSize = 2048;\n    const hopSize = 1024;\n    \n    // Token types and colors\n    const tokenTypes = ['A', 'B', 'C', 'D', 'E']; // Different audio characteristics\n    const tokenColors = {\n      'A': '#4dabf7', // Blue - Energy rise\n      'B': '#f783ac', // Pink - Energy fall\n      'C': '#8ce99a', // Green - Spectral high\n      'D': '#ffd43b', // Yellow - Spectral low\n      'E': '#a5d8ff'  // Light blue - Background\n    };\n    \n    // Token type descriptions\n    const tokenDescriptions = {\n      'A': 'Energy Rise (vowel onset)',\n      'B': 'Energy Fall (syllable end)',\n      'C': 'High Frequency (consonants)',\n      'D': 'Low Frequency (low vowels)',\n      'E': 'Transition'\n    };\n    \n    // Region colors - enhanced palette\n    const regionColors = [\n      'rgba(255, 86, 0, 0.6)',   // Template (orange)\n      'rgba(0, 200, 83, 0.6)',   // Default calibration (green)\n      'rgba(76, 110, 245, 0.8)', // Selected (blue) \n      'rgba(142, 36, 170, 0.6)', // Alternative 1 (purple)\n      'rgba(225, 83, 97, 0.6)',  // Alternative 2 (rose)\n      'rgba(0, 150, 136, 0.6)',  // Alternative 3 (teal)\n      'rgba(255, 152, 0, 0.6)',  // Alternative 4 (amber)\n      'rgba(121, 85, 72, 0.6)'   // Alternative 5 (brown)\n    ];\n    \n    // Pattern recognition parameters (will be auto-calibrated)\n    let matchThreshold = 0.75;\n    let minConfidence = 0.3;\n    \n    // Template data\n    let templateRegion = null;\n    let calibrationRegions = [];\n    let templateTokens = [];\n    let templateBuffer = null;\n    \n    // Detection state\n    let detectionCount = 0;\n    let isAnalyzing = false;\n    let currentTokens = [];\n    let liveTokenBuffer = [];\n    let confidenceHistory = [];\n    let lastDetectionTime = 0;\n    let lastTokenTime = 0;\n    let activeTokenTypes = new Set();\n    \n    // Enhanced calibration variables\n    let calibrationResults = [];\n    let selectedRegionId = null;\n    let regionFeatures = {};\n    let selectedFeatureType = 'energy';\n    \n    // Diagnostic logging\n    let detectionEvents = [];\n    let verboseLogging = true;\n    let showFeatureValues = true;\n    \n    // DOM elements\n    const recordBtn = document.getElementById('recordBtn');\n    const stopBtn = document.getElementById('stopBtn');\n    const playBtn = document.getElementById('playBtn');\n    const resetBtn = document.getElementById('resetBtn');\n    const createTemplateBtn = document.getElementById('createTemplateBtn');\n    const selectCalibrationBtn = document.getElementById('selectCalibrationBtn');\n    const calibrateBtn = document.getElementById('calibrateBtn');\n    const startAnalysisBtn = document.getElementById('startAnalysisBtn');\n    const stopAnalysisBtn = document.getElementById('stopAnalysisBtn');\n    const progressBar = document.querySelector('.progress-bar');\n    const thresholdLine = document.querySelector('.threshold-line');\n    const diagnosticsLog = document.getElementById('diagnostics');\n    const calibrationInfo = document.getElementById('calibrationInfo');\n    const counterDisplay = document.getElementById('counter');\n    const tokenSequence = document.getElementById('tokenSequence');\n    const liveActivity = document.getElementById('liveActivity');\n    const regionCount = document.getElementById('regionCount');\n    const calibrationControls = document.getElementById('calibrationControls');\n    const tokenContainer = document.getElementById('tokenContainer');\n    const detectionData = document.getElementById('detectionData');\n    const debugOutput = document.getElementById('debugOutput');\n    const copyDiagnosticsBtn = document.getElementById('copyDiagnosticsBtn');\n    const verboseLoggingCheckbox = document.getElementById('verboseLogging');\n    const showFeatureValuesCheckbox = document.getElementById('showFeatureValues');\n    const regionColorLegend = document.getElementById('regionColorLegend');\n    const calibrationStatus = document.getElementById('calibrationStatus');\n    \n    // Initialize the app\n    function init() {\n      initWavesurfer();\n      initAudioContext();\n      \n      // Setup event listeners\n      recordBtn.addEventListener('click', startRecording);\n      stopBtn.addEventListener('click', stopRecording);\n      playBtn.addEventListener('click', () => wavesurfer.playPause());\n      resetBtn.addEventListener('click', resetApp);\n      createTemplateBtn.addEventListener('click', createTemplate);\n      selectCalibrationBtn.addEventListener('click', enhancedSelectCalibrationRegion);\n      calibrateBtn.addEventListener('click', enhancedCalibrate);\n      startAnalysisBtn.addEventListener('click', startAnalysis);\n      stopAnalysisBtn.addEventListener('click', stopAnalysis);\n      \n      // Set threshold line position\n      updateThresholdLine();\n      \n      // Setup diagnostic controls\n      copyDiagnosticsBtn.addEventListener('click', copyAllDiagnostics);\n      verboseLoggingCheckbox.addEventListener('change', (e) => {\n        verboseLogging = e.target.checked;\n      });\n      showFeatureValuesCheckbox.addEventListener('change', (e) => {\n        showFeatureValues = e.target.checked;\n      });\n      \n      // Initialize enhanced calibration\n      initEnhancedCalibration();\n      \n      log('App initialized. Click \"Record Audio\" to begin.');\n    }\n    \n    // Initialize WaveSurfer\n    function initWavesurfer() {\n      wavesurfer = WaveSurfer.create({\n        container: '#waveform',\n        waveColor: '#4c6ef5',\n        progressColor: '#364fc7',\n        cursorColor: '#fa5252',\n        height: 128,\n        normalize: true,\n        plugins: [\n          WaveSurfer.regions.create({\n            dragSelection: true,\n            color: 'rgba(255, 86, 0, 0.2)',\n          }),\n          WaveSurfer.timeline.create({\n            container: '#waveform-timeline',\n            primaryFontColor: '#666',\n            secondaryFontColor: '#999',\n            primaryColor: '#333',\n            secondaryColor: '#999'\n          })\n        ]\n      });\n      \n      wavesurfer.on('ready', function() {\n        playBtn.disabled = false;\n        createTemplateBtn.disabled = false;\n        log('Waveform ready - audio loaded successfully');\n      });\n      \n      wavesurfer.on('error', function(err) {\n        log('WaveSurfer error: ' + err);\n      });\n      \n      // Handle region creation - simplified\n      wavesurfer.on('region-created', function(region) {\n        // Only handle initial region creation here\n        if (!calibrationMode && !templateRegion) {\n          region.id = 'template-' + Date.now();\n          log(`Template region created: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n        }\n      });\n      \n      // Handle region updates\n      wavesurfer.on('region-update-end', function(region) {\n        log(`Region updated: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n      });\n      \n      // Handle region click\n      wavesurfer.on('region-click', function(region, e) {\n        e.stopPropagation(); // Prevent creating a new region\n        if (region !== templateRegion) {\n          selectRegion(region.id);\n        }\n      });\n    }\n    \n    // Enhanced calibration process\n    async function enhancedCalibrate() {\n      if (templateTokens.length === 0 || calibrationRegions.length === 0) {\n        log('Error: Need template tokens and at least one calibration region');\n        return;\n      }\n      \n      // Update status indicator\n      updateCalibrationStatus('processing');\n      \n      log(`Starting calibration with ${calibrationRegions.length} regions...`);\n      \n      calibrationResults = [];\n      regionFeatures = {};\n      \n      // Process all calibration regions\n      for (let i = 0; i < calibrationRegions.length; i++) {\n        const region = calibrationRegions[i];\n        log(`Processing region ${i+1}: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`);\n        \n        // Extract audio from region\n        const audioBuffer = await extractRegionAudio(region);\n        \n        if (!audioBuffer) {\n          log(`Error extracting audio from region ${i+1}`);\n          continue;\n        }\n        \n        // Extract tokens from audio\n        const tokens = await extractTokensFromBuffer(audioBuffer);\n        \n        // Extract raw feature frames for visualization\n        const frames = await extractFeatureFrames(audioBuffer);\n        \n        // Store tokens and frames with the region for later comparison\n        region.data.tokens = tokens;\n        region.data.features = frames;\n        \n        // Compare with template\n        const similarity = compareTokenSequences(templateTokens, tokens);\n        region.data.similarity = similarity;\n        \n        // Store calibration result\n        calibrationResults.push({\n          regionId: region.id,\n          similarity: similarity,\n          tokens: tokens,\n          features: frames\n        });\n        \n        // Update the similarity display in the UI\n        const similarityEl = document.querySelector(`#region-item-${region.id} .similarity-score`);\n        if (similarityEl) {\n          similarityEl.textContent = `${(similarity * 100).toFixed(0)}%`;\n          \n          // Update color based on similarity\n          if (similarity >= 0.8) {\n            similarityEl.style.backgroundColor = '#40c057';\n          } else if (similarity >= 0.6) {\n            similarityEl.style.backgroundColor = '#fab005';\n          } else {\n            similarityEl.style.backgroundColor = '#fa5252';\n          }\n        }\n        \n        log(`Region ${i+1}: ${tokens.length} tokens, similarity: ${(similarity * 100).toFixed(1)}%`);\n        \n        // Verbose logging of token comparison if enabled\n        if (verboseLogging) {\n          const tokenComparison = compareTokenSequencesDetailed(templateTokens, tokens);\n          log(`Token comparison: ${JSON.stringify(tokenComparison)}`);\n        }\n      }\n      \n      // Calculate statistics\n      if (calibrationResults.length > 0) {\n        const similarities = calibrationResults.map(r => r.similarity);\n        const avgSimilarity = similarities.reduce((a, b) => a + b, 0) / similarities.length;\n        const minSimilarity = Math.min(...similarities);\n        const maxSimilarity = Math.max(...similarities);\n        \n        // Calculate standard deviation\n        const stdDev = Math.sqrt(\n          similarities.reduce((sum, val) => sum + Math.pow(val - avgSimilarity, 2), 0) / similarities.length\n        );\n        \n        // Update summary display\n        document.getElementById('avgSimilarity').textContent = `${(avgSimilarity * 100).toFixed(1)}%`;\n        document.getElementById('minSimilarity').textContent = `${(minSimilarity * 100).toFixed(1)}%`;\n        document.getElementById('maxSimilarity').textContent = `${(maxSimilarity * 100).toFixed(1)}%`;\n        document.getElementById('stdDevSimilarity').textContent = `${(stdDev * 100).toFixed(1)}%`;\n        \n        // Set match threshold to 85% of the average similarity to allow for variations\n        const recommendedThreshold = Math.max(0.5, minSimilarity * 0.9);\n        matchThreshold = recommendedThreshold;\n        minConfidence = recommendedThreshold * 0.4;\n        \n        // Update threshold sliders\n        document.getElementById('matchThresholdSlider').value = Math.round(matchThreshold * 100);\n        document.getElementById('matchThresholdValue').textContent = `${Math.round(matchThreshold * 100)}%`;\n        \n        document.getElementById('minConfidenceSlider').value = Math.round(minConfidence * 100);\n        document.getElementById('minConfidenceValue').textContent = `${Math.round(minConfidence * 100)}%`;\n        \n        // Update UI\n        updateThresholdLine();\n        updateFeatureComparison();\n        \n        // Create comparison visualization\n        createThikrComparisonView();\n        \n        calibrationInfo.innerHTML = `\n          <strong>Calibration complete:</strong> \n          Match threshold: ${(matchThreshold * 100).toFixed(1)}% | \n          Average similarity: ${(avgSimilarity * 100).toFixed(1)}% |\n          Regions analyzed: ${calibrationRegions.length}\n        `;\n        \n        // Update status\n        updateCalibrationStatus('ready');\n        \n        log(`Calibration complete. Match threshold set to ${(matchThreshold * 100).toFixed(1)}%`);\n        \n        // Update debug output\n        updateDebugOutput();\n        \n        // Enable analysis\n        startAnalysisBtn.disabled = false;\n      } else {\n        // Update status to error\n        updateCalibrationStatus('error');\n        log('Calibration failed - no valid regions processed');\n      }\n    }\n    \n    // Create thikr comparison visualization\n    function createThikrComparisonView() {\n      const comparisonRows = document.getElementById('comparisonRows');\n      comparisonRows.innerHTML = '';\n      \n      // Create template row first\n      if (templateRegion && templateTokens) {\n        const templateRow = createComparisonRow('Template', templateRegion, templateTokens, regionColors[0]);\n        comparisonRows.appendChild(templateRow);\n      }\n      \n      // Create rows for each calibration region\n      calibrationRegions.forEach((region, index) => {\n        if (region.data && region.data.tokens) {\n          // Use a color from our palette\n          const colorIndex = (index % (regionColors.length - 2)) + 2; // Skip first two colors (template and selected)\n          const row = createComparisonRow(\n            `Region ${index + 1}`, \n            region, \n            region.data.tokens, \n            region.id === selectedRegionId ? regionColors[2] : regionColors[colorIndex]\n          );\n          comparisonRows.appendChild(row);\n        }\n      });\n    }\n    \n    // Create a comparison row for thikr visualization\n    function createComparisonRow(label, region, tokens, color) {\n      const row = document.createElement('div');\n      row.className = 'comparison-row';\n      row.dataset.regionId = region.id;\n      \n      // Label with similarity if available\n      const labelDiv = document.createElement('div');\n      labelDiv.className = 'comparison-label';\n      \n      if (region.data && region.data.similarity !== undefined && region.id !== templateRegion.id) {\n        labelDiv.innerHTML = `${label}<br><span style=\"font-size:11px;\">${(region.data.similarity * 100).toFixed(1)}% match</span>`;\n      } else {\n        labelDiv.textContent = label;\n      }\n      \n      // Waveform visualization (simplified)\n      const waveformDiv = document.createElement('div');\n      waveformDiv.className = 'comparison-waveform';\n      waveformDiv.style.backgroundColor = color.replace('0.6', '0.2'); // Lighter background\n      waveformDiv.style.borderColor = color.replace('0.6', '1.0'); // Darker border\n      \n      // Add play button\n      const playBtn = document.createElement('button');\n      playBtn.textContent = '▶';\n      playBtn.style.position = 'absolute';\n      playBtn.style.left = '5px';\n      playBtn.style.top = '5px';\n      playBtn.style.padding = '2px 8px';\n      playBtn.style.fontSize = '12px';\n      playBtn.addEventListener('click', () => playRegion(region));\n      waveformDiv.appendChild(playBtn);\n      \n      // Add region duration\n      const durationSpan = document.createElement('span');\n      durationSpan.textContent = `${(region.end - region.start).toFixed(2)}s`;\n      durationSpan.style.position = 'absolute';\n      durationSpan.style.right = '10px';\n      durationSpan.style.top = '10px';\n      durationSpan.style.fontSize = '12px';\n      durationSpan.style.color = '#495057';\n      waveformDiv.appendChild(durationSpan);\n      \n      // Token visualization\n      const tokensDiv = document.createElement('div');\n      tokensDiv.className = 'comparison-tokens';\n      \n      // Create token elements\n      tokens.forEach(token => {\n        const tokenEl = document.createElement('div');\n        tokenEl.className = 'mini-token';\n        tokenEl.textContent = token.type;\n        tokenEl.style.backgroundColor = tokenColors[token.type];\n        tokensDiv.appendChild(tokenEl);\n      });\n      \n      // Add select button if not template\n      if (region.id !== templateRegion.id) {\n        const selectBtn = document.createElement('button');\n        selectBtn.textContent = 'Select';\n        selectBtn.style.position = 'absolute';\n        selectBtn.style.bottom = '5px';\n        selectBtn.style.right = '5px';\n        selectBtn.style.padding = '2px 8px';\n        selectBtn.style.fontSize = '12px';\n        selectBtn.addEventListener('click', () => selectRegion(region.id));\n        waveformDiv.appendChild(selectBtn);\n      }\n      \n      // Assemble row\n      row.appendChild(labelDiv);\n      row.appendChild(waveformDiv);\n      row.appendChild(tokensDiv);\n      \n      return row;\n    }\n    \n    // Update calibration status indicator\n    function updateCalibrationStatus(status) {\n      const statusEl = document.getElementById('calibrationStatus');\n      \n      switch(status) {\n        case 'ready':\n          statusEl.textContent = 'Ready';\n          statusEl.className = 'status-indicator status-ready';\n          break;\n        case 'processing':\n          statusEl.textContent = 'Processing...';\n          statusEl.className = 'status-indicator status-pending';\n          break;\n        case 'error':\n          statusEl.textContent = 'Error';\n          statusEl.className = 'status-indicator status-error';\n          break;\n        default:\n          statusEl.textContent = 'Pending';\n          statusEl.className = 'status-indicator status-pending';\n      }\n    }\n    \n    // Compare two token sequences and return similarity (0-1)\n    function compareTokenSequences(template, sequence) {\n      if (!template.length || !sequence.length) return 0;\n      \n      // Simple sliding window approach - find best match within sequence\n      let bestSimilarity = 0;\n      let bestOffset = 0;\n      \n      // Try different alignments to find best match\n      for (let startIdx = 0; startIdx <= sequence.length - Math.min(template.length, 3); startIdx++) {\n        const endIdx = Math.min(startIdx + template.length, sequence.length);\n        const window = sequence.slice(startIdx, endIdx);\n        \n        // Calculate how many tokens match by type\n        let matches = 0;\n        const minLength = Math.min(template.length, window.length);\n        \n        for (let i = 0; i < minLength; i++) {\n          // Compare token features with some tolerance\n          const templateToken = template[i];\n          const windowToken = window[i];\n          \n          // Base similarity on token type\n          const typeMatch = templateToken.type === windowToken.type ? 1 : 0;\n          \n          // Energy similarity\n          const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - windowToken.rms) / 0.2);\n          \n          // Spectral similarity\n          const spectralSimilarity = 1 - Math.min(1, Math.abs(templateToken.spectralCentroid - windowToken.spectralCentroid) / 5000);\n          \n          // Combined similarity for this token\n          const tokenSimilarity = typeMatch * 0.6 + energySimilarity * 0.3 + spectralSimilarity * 0.1;\n          \n          matches += tokenSimilarity;\n        }\n        \n        // Normalize by template length\n        const similarity = matches / template.length;\n        \n        if (similarity > bestSimilarity) {\n          bestSimilarity = similarity;\n          bestOffset = startIdx;\n        }\n      }\n      \n      return bestSimilarity;\n    }\n    \n    // Compare token sequences with detailed reporting for debugging\n    function compareTokenSequencesDetailed(template, sequence) {\n      if (!template.length || !sequence.length) return { similarity: 0, details: [] };\n      \n      // Simple sliding window approach - find best match within sequence\n      let bestSimilarity = 0;\n      let bestOffset = 0;\n      let bestDetails = [];\n      \n      // Try different alignments to find best match\n      for (let startIdx = 0; startIdx <= sequence.length - Math.min(template.length, 3); startIdx++) {\n        const endIdx = Math.min(startIdx + template.length, sequence.length);\n        const window = sequence.slice(startIdx, endIdx);\n        \n        // Calculate how many tokens match by type\n        let matches = 0;\n        const details = [];\n        const minLength = Math.min(template.length, window.length);\n        \n        for (let i = 0; i < minLength; i++) {\n          // Compare token features with some tolerance\n          const templateToken = template[i];\n          const windowToken = window[i];\n          \n          // Base similarity on token type\n          const typeMatch = templateToken.type === windowToken.type ? 1 : 0;\n          \n          // Energy similarity\n          const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - windowToken.rms) / 0.2);\n          \n          // Spectral similarity\n          const spectralSimilarity = 1 - Math.min(1, Math.abs(templateToken.spectralCentroid - windowToken.spectralCentroid) / 5000);\n          \n          // Combined similarity for this token\n          const tokenSimilarity = typeMatch * 0.6 + energySimilarity * 0.3 + spectralSimilarity * 0.1;\n          \n          matches += tokenSimilarity;\n          \n          details.push({\n            template: {\n              type: templateToken.type,\n              rms: templateToken.rms,\n              spectralCentroid: templateToken.spectralCentroid\n            },\n            window: {\n              type: windowToken.type,\n              rms: windowToken.rms, \n              spectralCentroid: windowToken.spectralCentroid\n            },\n            typeMatch: typeMatch,\n            energySimilarity: energySimilarity,\n            spectralSimilarity: spectralSimilarity,\n            tokenSimilarity: tokenSimilarity\n          });\n        }\n        \n        // Normalize by template length\n        const similarity = matches / template.length;\n        \n        if (similarity > bestSimilarity) {\n          bestSimilarity = similarity;\n          bestOffset = startIdx;\n          bestDetails = details;\n        }\n      }\n      \n      return {\n        similarity: bestSimilarity,\n        offset: bestOffset,\n        details: bestDetails\n      };\n    }\n    \n    // Update the feature comparison visualization\n    function updateFeatureComparison() {\n      const comparisonChart = document.getElementById('comparisonChart');\n      comparisonChart.innerHTML = '';\n      \n      // If no template or no selection, show a message\n      if (!templateTokens.length && !templateRegion) {\n        comparisonChart.innerHTML = '<div style=\"text-align: center; padding: 20px;\">No template available for comparison</div>';\n        return;\n      }\n      \n      if (selectedFeatureType === 'tokens') {\n        // Special visualization for token types\n        renderTokenTypeComparison(comparisonChart);\n      } else {\n        // Render time-series data for other feature types\n        renderFeatureTimeSeries(comparisonChart);\n      }\n    }\n    \n    // Render feature time series comparison\n    function renderFeatureTimeSeries(container) {\n      // Get template features\n      let templateFeatures = [];\n      if (templateRegion && templateRegion.data && templateRegion.data.features) {\n        templateFeatures = templateRegion.data.features;\n      } else if (templateBuffer) {\n        // If template features not stored, extract them\n        log('Template features not available, visualization may be incomplete');\n      }\n      \n      // Get selected region features\n      let selectedFeatures = [];\n      if (selectedRegionId) {\n        const selectedRegion = calibrationRegions.find(r => r.id === selectedRegionId);\n        if (selectedRegion && selectedRegion.data && selectedRegion.data.features) {\n          selectedFeatures = selectedRegion.data.features;\n        }\n      }\n      \n      // Create template series container\n      const templateSeries = document.createElement('div');\n      templateSeries.className = 'feature-series';\n      \n      // Get feature property based on selected type\n      const getFeatureValue = (frame) => {\n        switch (selectedFeatureType) {\n          case 'energy': return frame.rms;\n          case 'centroid': return frame.spectralCentroid / 10000; // Normalize\n          case 'zcr': return frame.zcr;\n          default: return frame.rms;\n        }\n      };\n      \n      // Render template features\n      if (templateFeatures.length > 0) {\n        renderFeatureSeries(templateSeries, templateFeatures, getFeatureValue, 'template-bar');\n      }\n      \n      // Render selected region features if available\n      if (selectedFeatures.length > 0) {\n        const selectedSeries = document.createElement('div');\n        selectedSeries.className = 'feature-series';\n        renderFeatureSeries(selectedSeries, selectedFeatures, getFeatureValue, 'selected-region-bar');\n        \n        // Add both to container\n        container.appendChild(templateSeries);\n        container.appendChild(selectedSeries);\n      } else {\n        // Just add template\n        container.appendChild(templateSeries);\n      }\n    }\n    \n    // Render a feature series\n    function renderFeatureSeries(container, features, valueAccessor, barClass) {\n      // Find max value for scaling\n      const maxValue = Math.max(...features.map(valueAccessor));\n      \n      // Only display a reasonable number of points (max 100)\n      const step = Math.max(1, Math.ceil(features.length / 100));\n      \n      // Create visible points\n      for (let i = 0; i < features.length; i += step) {\n        const feature = features[i];\n        const value = valueAccessor(feature);\n        \n        // Create feature point element\n        const pointEl = document.createElement('div');\n        pointEl.className = 'feature-point';\n        \n        // Create feature bar element (height represents value)\n        const barEl = document.createElement('div');\n        barEl.className = `feature-bar ${barClass}`;\n        \n        // Set height as percentage of max value\n        const heightPercent = (value / maxValue) * 100;\n        barEl.style.height = `${heightPercent}%`;\n        \n        // Add tooltip\n        barEl.title = `${selectedFeatureType}: ${value.toFixed(4)} at ${feature.time.toFixed(3)}s`;\n        \n        // Add to DOM\n        pointEl.appendChild(barEl);\n        container.appendChild(pointEl);\n      }\n    }\n    \n    // Render token type comparison\n    function renderTokenTypeComparison(container) {\n      // Create a chart showing the proportion of each token type\n      \n      // Get template tokens\n      const templateTokens = this.templateTokens || [];\n      \n      // Get selected region tokens\n      let selectedTokens = [];\n      if (selectedRegionId) {\n        const selectedRegion = calibrationRegions.find(r => r.id === selectedRegionId);\n        if (selectedRegion && selectedRegion.data && selectedRegion.data.tokens) {\n          selectedTokens = selectedRegion.data.tokens;\n        }\n      }\n      \n      // Count token types\n      const templateCounts = countTokenTypes(templateTokens);\n      const selectedCounts = countTokenTypes(selectedTokens);\n      \n      // Create container for the grouped bars\n      const barsContainer = document.createElement('div');\n      barsContainer.style.display = 'flex';\n      barsContainer.style.height = '100%';\n      barsContainer.style.alignItems = 'flex-end';\n      barsContainer.style.padding = '10px';\n      \n      // Create bars for each token type\n      for (const type of tokenTypes) {\n        // Create group for this token type\n        const groupEl = document.createElement('div');\n        groupEl.style.display = 'flex';\n        groupEl.style.flexDirection = 'column';\n        groupEl.style.alignItems = 'center';\n        groupEl.style.flex = '1';\n        groupEl.style.marginBottom = '25px';\n        \n        // Add token type label\n        const labelEl = document.createElement('div');\n        labelEl.textContent = `Type ${type}`;\n        labelEl.style.position = 'absolute';\n        labelEl.style.bottom = '-20px';\n        labelEl.style.fontSize = '12px';\n        \n        // Create container for the two bars\n        const barGroupEl = document.createElement('div');\n        barGroupEl.style.display = 'flex';\n        barGroupEl.style.width = '100%';\n        barGroupEl.style.height = '100%';\n        barGroupEl.style.position = 'relative';\n        \n        // Template bar\n        const templateBar = document.createElement('div');\n        templateBar.className = 'feature-bar template-bar';\n        templateBar.style.width = '45%';\n        templateBar.style.marginRight = '10%';\n        templateBar.style.height = `${templateCounts[type] || 0}%`;\n        templateBar.title = `Template: ${templateCounts[type] || 0}%`;\n        \n        // Selected region bar\n        const selectedBar = document.createElement('div');\n        selectedBar.className = 'feature-bar selected-region-bar';\n        selectedBar.style.width = '45%';\n        selectedBar.style.height = `${selectedCounts[type] || 0}%`;\n        selectedBar.title = `Selected: ${selectedCounts[type] || 0}%`;\n        \n        // Add bars to bar group\n        barGroupEl.appendChild(templateBar);\n        barGroupEl.appendChild(selectedBar);\n        barGroupEl.appendChild(labelEl);\n        \n        // Add to group element\n        groupEl.appendChild(barGroupEl);\n        \n        // Add to container\n        barsContainer.appendChild(groupEl);\n      }\n      \n      // Add legend\n      const legendEl = document.createElement('div');\n      legendEl.style.display = 'flex';\n      legendEl.style.justifyContent = 'center';\n      legendEl.style.marginTop = '30px';\n      legendEl.style.gap = '20px';\n      \n      const templateLegend = document.createElement('div');\n      templateLegend.innerHTML = '<span style=\"display:inline-block;width:12px;height:12px;background-color:rgba(255,86,0,0.6);margin-right:5px;\"></span> Template';\n      \n      const selectedLegend = document.createElement('div');\n      selectedLegend.innerHTML = '<span style=\"display:inline-block;width:12px;height:12px;background-color:rgba(76,110,245,0.8);margin-right:5px;\"></span> Selected Region';\n      \n      legendEl.appendChild(templateLegend);\n      legendEl.appendChild(selectedLegend);\n      \n      // Add all to main container\n      container.appendChild(barsContainer);\n      container.appendChild(legendEl);\n    }\n    \n    // Count token types as percentages\n    function countTokenTypes(tokens) {\n      const counts = {};\n      if (!tokens || tokens.length === 0) return counts;\n      \n      // Count occurrences of each type\n      for (const token of tokens) {\n        counts[token.type] = (counts[token.type] || 0) + 1;\n      }\n      \n      // Convert to percentages\n      for (const type in counts) {\n        counts[type] = (counts[type] / tokens.length) * 100;\n      }\n      \n      return counts;\n    }\n    \n    // Start real-time analysis\n    async function startAnalysis() {\n      if (templateTokens.length === 0) {\n        log('Error: Template tokens not available');\n        return;\n      }\n      \n      // Reset state\n      resetAnalysisState();\n      \n      try {\n        // Access microphone\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        const source = audioContext.createMediaStreamSource(stream);\n        \n        // Create Meyda analyzer\n        meydaAnalyzer = Meyda.createMeydaAnalyzer({\n          audioContext: audioContext,\n          source: source,\n          bufferSize: frameSize,\n          hopSize: hopSize,\n          featureExtractors: ['rms', 'mfcc', 'spectralCentroid', 'spectralFlatness', 'zcr'],\n          callback: processFrame\n        });\n        \n        meydaAnalyzer.start();\n        isAnalyzing = true;\n        \n        // Update UI\n        startAnalysisBtn.disabled = true;\n        stopAnalysisBtn.disabled = false;\n        liveActivity.innerHTML = 'Listening for thikr patterns...';\n        \n        log('Real-time analysis started. Recite thikr...');\n        \n      } catch (err) {\n        console.error('Error accessing microphone:', err);\n        log('Error: ' + err.message);\n      }\n    }\n    \n    // Stop real-time analysis\n    function stopAnalysis() {\n      if (meydaAnalyzer) {\n        meydaAnalyzer.stop();\n      }\n      \n      isAnalyzing = false;\n      \n      // Update UI\n      startAnalysisBtn.disabled = false;\n      stopAnalysisBtn.disabled = true;\n      liveActivity.innerHTML = 'Analysis stopped.';\n      \n      log('Analysis stopped.');\n    }\n    \n    // Process a frame from the real-time analyzer\n    let prevFrames = [];\n    \n    function processFrame(features) {\n      if (!isAnalyzing) return;\n      \n      const currentTime = audioContext.currentTime;\n      \n      // Create frame object\n      const frame = {\n        time: currentTime,\n        rms: features.rms || 0,\n        mfcc: features.mfcc || [],\n        spectralCentroid: features.spectralCentroid || 0,\n        spectralFlatness: features.spectralFlatness || 0,\n        zcr: features.zcr || 0\n      };\n      \n      // Add to frames buffer\n      prevFrames.push(frame);\n      if (prevFrames.length > 5) {\n        prevFrames.shift();\n      }\n      \n      // Need at least 3 frames to detect features\n      if (prevFrames.length < 3) return;\n      \n      // Get frames for context\n      const currentIdx = prevFrames.length - 1;\n      const prevFrame2 = prevFrames[Math.max(0, currentIdx - 2)];\n      const prevFrame = prevFrames[Math.max(0, currentIdx - 1)];\n      const currentFrame = prevFrames[currentIdx];\n      const nextFrame = null; // We don't have future frames in real-time\n      const nextFrame2 = null;\n      \n      // Check if this frame is a significant point AND enough time has passed since last token\n      if (isSignificantPoint(currentFrame, prevFrame, nextFrame, prevFrame2, nextFrame2) && \n          currentTime - lastTokenTime > 0.05) { // Minimum 50ms between tokens\n        \n        // Determine token type\n        const tokenType = determineTokenType(currentFrame, prevFrame, nextFrame);\n        \n        // Create token\n        const token = {\n          type: tokenType,\n          time: currentTime,\n          rms: currentFrame.rms,\n          spectralCentroid: currentFrame.spectralCentroid,\n          mfcc: currentFrame.mfcc.slice(0, 5),\n          spectralFlux: calculateSpectralFlux(currentFrame, prevFrame),\n          zcr: currentFrame.zcr\n        };\n        \n        // Add to token buffer\n        liveTokenBuffer.push(token);\n        lastTokenTime = currentTime;\n        \n        // Limit token buffer size (keep enough to match template)\n        const maxBuffer = Math.max(30, templateTokens.length * 2);\n        if (liveTokenBuffer.length > maxBuffer) {\n          liveTokenBuffer.shift();\n        }\n        \n        // Update activity display with more detailed token info\n        if (verboseLogging) {\n          updateLiveActivity(`Token ${tokenType} detected (RMS: ${token.rms.toFixed(3)}, SC: ${(token.spectralCentroid/1000).toFixed(1)}k Hz, ZCR: ${token.zcr.toFixed(3)})`);\n        } else {\n          updateLiveActivity(`Token ${tokenType} detected (${token.rms.toFixed(2)} energy)`);\n        }\n        \n        // Process for pattern matching\n        processTokenMatching();\n      }\n    }\n    \n    // Process token matching\n    function processTokenMatching() {\n      // Need a minimum number of tokens to start matching\n      if (liveTokenBuffer.length < Math.max(3, templateTokens.length / 2)) {\n        return;\n      }\n      \n      // Calculate similarity with template\n      const similarity = compareTokenSequences(templateTokens, liveTokenBuffer);\n      \n      // Add confidence marker\n      addConfidenceMarker(similarity);\n      \n      // Update confidence history\n      confidenceHistory.push(similarity);\n      if (confidenceHistory.length > 50) {\n        confidenceHistory.shift();\n      }\n      \n      // Update UI\n      updateProgressBar(similarity);\n      updateTokenVisualization(similarity);\n      \n      // Update activity display with confidence\n      updateLiveActivity(`Pattern match: ${(similarity * 100).toFixed(1)}% confidence`);\n      \n      if (verboseLogging) {\n        log(`Pattern match: ${(similarity * 100).toFixed(1)}% confidence`);\n      }\n      \n      // Check for detection\n      if (similarity >= matchThreshold && \n          audioContext.currentTime - lastDetectionTime > 2.0) { // Cooldown period\n        \n        // Register detection\n        detectionCount++;\n        counterDisplay.textContent = detectionCount;\n        lastDetectionTime = audioContext.currentTime;\n        \n        // Add to detection events log\n        const detectionEvent = {\n          id: detectionCount,\n          time: new Date().toISOString(),\n          similarity: similarity,\n          thresholdUsed: matchThreshold,\n          tokenCount: liveTokenBuffer.length,\n          tokenTypes: tokenTypeCounts(liveTokenBuffer)\n        };\n        detectionEvents.push(detectionEvent);\n        \n        // Update detection data display\n        updateDetectionData(detectionEvent);\n        \n        // Add detection flash\n        addDetectionFlash();\n        \n        // Apply wave animation\n        applyWaveAnimation();\n        \n        // Update activity display with detection\n        updateLiveActivity(`THIKR DETECTED (#${detectionCount}) with ${(similarity * 100).toFixed(1)}% confidence!`);\n        \n        log(`THIKR DETECTED (#${detectionCount}) with ${(similarity * 100).toFixed(1)}% confidence`);\n        \n        // Clear token buffer to look for next pattern\n        liveTokenBuffer = [];\n      }\n    }\n    \n    // Update detection data display\n    function updateDetectionData(event) {\n      // Format the detection data\n      const formattedData = `\n        <div style=\"border-bottom: 1px solid #dee2e6; padding-bottom: 10px; margin-bottom: 10px;\">\n          <strong>Detection #${event.id}</strong> (${new Date(event.time).toLocaleTimeString()})\n          <br>Confidence: ${(event.similarity * 100).toFixed(1)}% (threshold: ${(event.thresholdUsed * 100).toFixed(1)}%)\n          <br>Tokens: ${event.tokenCount} (${formatTokenTypeCounts(event.tokenTypes)})\n        </div>\n      `;\n      \n      // Add to detection data display\n      detectionData.innerHTML = formattedData + detectionData.innerHTML;\n      \n      // Keep only the last 10 events in the display\n      const items = detectionData.querySelectorAll('div');\n      if (items.length > 10) {\n        for (let i = 10; i < items.length; i++) {\n          items[i].remove();\n        }\n      }\n      \n      // Update debug output\n      updateDebugOutput();\n    }\n    \n    // Format token type counts\n    function formatTokenTypeCounts(counts) {\n      return Object.entries(counts)\n        .map(([type, count]) => `${type}:${count}`)\n        .join(', ');\n    }\n    \n    // Count token types\n    function tokenTypeCounts(tokens) {\n      const counts = {};\n      tokens.forEach(token => {\n        counts[token.type] = (counts[token.type] || 0) + 1;\n      });\n      return counts;\n    }\n    \n    // Update live activity display\n    function updateLiveActivity(message) {\n      const time = new Date().toLocaleTimeString();\n      const activityMessage = `[${time}] ${message}`;\n      \n      // Add new message at top\n      liveActivity.innerHTML = activityMessage + \"<br>\" + liveActivity.innerHTML;\n      \n      // Limit number of messages\n      const messages = liveActivity.innerHTML.split(\"<br>\");\n      if (messages.length > 10) {\n        liveActivity.innerHTML = messages.slice(0, 10).join(\"<br>\");\n      }\n    }\n    \n    // Add confidence marker to visualization\n    function addConfidenceMarker(confidence) {\n      // Create a marker\n      const marker = document.createElement('div');\n      marker.className = 'confidence-marker';\n      \n      // Position at the right edge, height based on confidence\n      const bottom = confidence * 100;\n      marker.style.bottom = `${bottom}%`;\n      marker.style.right = '0px';\n      \n      // Color based on threshold\n      if (confidence >= matchThreshold) {\n        marker.style.backgroundColor = 'green';\n      } else if (confidence >= minConfidence) {\n        marker.style.backgroundColor = 'yellow';\n      } else {\n        marker.style.backgroundColor = 'red';\n      }\n      \n      confidenceDisplay.appendChild(marker);\n      \n      // Animate movement\n      let position = 0;\n      const maxPosition = confidenceDisplay.offsetWidth;\n      const moveMarker = () => {\n        position += 2;\n        marker.style.right = `${position}px`;\n        \n        if (position <= maxPosition) {\n          requestAnimationFrame(moveMarker);\n        } else {\n          // Remove marker when it's off-screen\n          marker.remove();\n        }\n      };\n      \n      requestAnimationFrame(moveMarker);\n    }\n    \n    // Update token visualization\n    function updateTokenVisualization(overallConfidence) {\n      // Get all token elements\n      const tokenElements = tokenSequence.querySelectorAll('.token');\n      if (tokenElements.length === 0) return;\n      \n      // Calculate individual token matches\n      for (let i = 0; i < templateTokens.length && i < tokenElements.length; i++) {\n        const templateToken = templateTokens[i];\n        \n        // Find best matching token in live buffer\n        let bestMatch = 0;\n        for (let j = 0; j < liveTokenBuffer.length; j++) {\n          const liveToken = liveTokenBuffer[j];\n          if (templateToken.type === liveToken.type) {\n            const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - liveToken.rms) / 0.2);\n            bestMatch = Math.max(bestMatch, energySimilarity);\n          }\n        }\n        \n        // Reset animation\n        tokenElements[i].classList.remove('wave-effect');\n        void tokenElements[i].offsetWidth; // Force reflow to restart animation\n        \n        // Adjust token appearance based on match confidence\n        if (bestMatch > 0.7) {\n          // High confidence match\n          tokenElements[i].style.transform = `scale(${1 + bestMatch * 0.4})`;\n          \n          // Calculate color (yellow to green)\n          const r = Math.floor(255 * (1 - bestMatch));\n          const g = Math.floor(200);\n          const b = 0;\n          tokenElements[i].style.backgroundColor = `rgb(${r}, ${g}, ${b})`;\n          tokenElements[i].style.color = bestMatch > 0.8 ? 'white' : 'black';\n          tokenElements[i].style.boxShadow = `0 0 10px rgba(0, 255, 0, ${bestMatch * 0.8})`;\n          \n          // Add wave effect if high confidence\n          if (bestMatch > 0.85) {\n            tokenElements[i].classList.add('wave-effect');\n          }\n        } else if (bestMatch > 0.4) {\n          // Medium confidence match\n          tokenElements[i].style.transform = `scale(${1 + bestMatch * 0.2})`;\n          \n          // Yellow color\n          tokenElements[i].style.backgroundColor = `rgb(255, 204, 0)`;\n          tokenElements[i].style.color = 'black';\n          tokenElements[i].style.boxShadow = `0 0 5px rgba(255, 204, 0, ${bestMatch * 0.5})`;\n        } else {\n          // Low confidence or no match - reset to original\n          tokenElements[i].style.transform = 'scale(1)';\n          tokenElements[i].style.backgroundColor = tokenColors[templateToken.type];\n          tokenElements[i].style.color = 'black';\n          tokenElements[i].style.boxShadow = '0 2px 4px rgba(0,0,0,0.1)';\n        }\n        \n        // Update debug info on token\n        if (showFeatureValues) {\n          const debugInfo = tokenElements[i].querySelector('.token-debug-info');\n          if (debugInfo) {\n            debugInfo.textContent = `Match: ${(bestMatch * 100).toFixed(0)}%`;\n          }\n        }\n      }\n      \n      // If very high confidence, produce wave effect\n      if (overallConfidence > matchThreshold * 0.9) {\n        applyWaveAnimation();\n      }\n    }\n    \n    // Apply wave animation sequence to tokens\n    function applyWaveAnimation() {\n      const tokenElements = tokenSequence.querySelectorAll('.token');\n      \n      tokenElements.forEach((el, i) => {\n        setTimeout(() => {\n          el.classList.remove('wave-effect');\n          void el.offsetWidth; // Force reflow to restart animation\n          el.classList.add('wave-effect');\n        }, i * 100); // Stagger animation\n      });\n    }\n    \n    // Add detection flash\n    function addDetectionFlash() {\n      const flash = document.createElement('div');\n      flash.className = 'detection-flash';\n      tokenSequence.appendChild(flash);\n      \n      // Remove after animation completes\n      setTimeout(() => {\n        if (flash.parentNode) {\n          flash.parentNode.removeChild(flash);\n        }\n      }, 1500);\n    }\n    \n    // Update progress bar\n    function updateProgressBar(confidence) {\n      progressBar.style.height = `${confidence * 100}%`;\n    }\n    \n    // Update threshold line position\n    function updateThresholdLine() {\n      thresholdLine.style.bottom = `${matchThreshold * 100}%`;\n    }\n    \n    // Reset analysis state\n    function resetAnalysisState() {\n      liveTokenBuffer = [];\n      currentTokens = [];\n      confidenceHistory = [];\n      prevFrames = [];\n      lastTokenTime = 0;\n      lastDetectionTime = 0;\n      detectionCount = 0;\n      counterDisplay.textContent = detectionCount;\n      updateProgressBar(0);\n      liveActivity.innerHTML = 'Waiting to start analysis...';\n      \n      // Clear detection events\n      detectionEvents = [];\n      detectionData.innerHTML = '';\n      \n      // Reset token visualization\n      const tokenElements = tokenSequence.querySelectorAll('.token');\n      tokenElements.forEach((el, i) => {\n        if (i < templateTokens.length) {\n          const templateToken = templateTokens[i];\n          el.style.transform = 'scale(1)';\n          el.style.backgroundColor = tokenColors[templateToken.type];\n          el.style.color = 'black';\n          el.style.boxShadow = '0 2px 4px rgba(0,0,0,0.1)';\n        }\n      });\n      \n      // Clear confidence markers\n      document.querySelectorAll('.confidence-marker').forEach(el => el.remove());\n    }\n    \n    // Reset the app\n    function resetApp() {\n      // Stop recording if in progress\n      if (isRecording && recorder) {\n        recorder.stop();\n        isRecording = false;\n      }\n      \n      // Stop analysis if in progress\n      if (isAnalyzing) {\n        stopAnalysis();\n      }\n      \n      // Clear wavesurfer\n      wavesurfer.clearRegions();\n      wavesurfer.empty();\n      \n      // Reset variables\n      templateRegion = null;\n      calibrationRegions = [];\n      templateTokens = [];\n      templateBuffer = null;\n      calibrationMode = false;\n      \n      // Reset analysis state\n      resetAnalysisState();\n      \n      // Clear token display\n      tokenSequence.innerHTML = '';\n      \n      // Reset UI\n      recordBtn.disabled = false;\n      stopBtn.disabled = true;\n      playBtn.disabled = true;\n      createTemplateBtn.disabled = true;\n      calibrateBtn.disabled = true;\n      startAnalysisBtn.disabled = true;\n      stopAnalysisBtn.disabled = true;\n      \n      // Hide panels and reset counts\n      tokenContainer.style.display = 'none';\n      calibrationControls.style.display = 'none';\n      document.getElementById('calibrationPanel').style.display = 'none';\n      regionColorLegend.style.display = 'none';\n      regionCount.textContent = '0';\n      \n      // Reset calibration status\n      updateCalibrationStatus('pending');\n      \n      calibrationInfo.textContent = 'Record audio, then select a template region by dragging on the waveform.';\n      liveActivity.innerHTML = 'Waiting to start analysis...';\n      \n      // Clear diagnostics\n      diagnosticsLog.innerHTML = '';\n      detectionData.innerHTML = '';\n      debugOutput.innerHTML = '';\n      \n      log('App reset');\n    }\n    \n    // Update the debug output \n    function updateDebugOutput() {\n      // Create a formatted summary of the current state for easy copy/paste debugging\n      let output = \"=== THIKR COUNTER DEBUG DATA ===\\n\\n\";\n      \n      // Template info\n      output += \"TEMPLATE INFO:\\n\";\n      output += `--------------\\n`;\n      if (templateTokens.length > 0) {\n        output += `Token count: ${templateTokens.length}\\n`;\n        output += `Token sequence: ${templateTokens.map(t => t.type).join('')}\\n`;\n        \n        // Token type counts\n        const counts = {};\n        templateTokens.forEach(token => {\n          counts[token.type] = (counts[token.type] || 0) + 1;\n        });\n        \n        output += `Token distribution: ${Object.entries(counts)\n          .map(([type, count]) => `${type}:${count} (${Math.round(count/templateTokens.length*100)}%)`)\n          .join(', ')}\\n\\n`;\n          \n        // Detailed token data (first 5 tokens)\n        output += \"FIRST 5 TEMPLATE TOKENS:\\n\";\n        templateTokens.slice(0, 5).forEach((token, i) => {\n          output += `[${i}] Type:${token.type} | RMS:${token.rms.toFixed(3)} | SC:${token.spectralCentroid.toFixed(0)} | ZCR:${token.zcr ? token.zcr.toFixed(3) : 'N/A'}\\n`;\n        });\n      } else {\n        output += \"No template tokens available\\n\";\n      }\n      \n      // Calibration info\n      output += \"\\nCALIBRATION INFO:\\n\";\n      output += `-----------------\\n`;\n      output += `Regions: ${calibrationRegions.length}\\n`;\n      output += `Match threshold: ${(matchThreshold * 100).toFixed(1)}%\\n`;\n      output += `Min confidence: ${(minConfidence * 100).toFixed(1)}%\\n\\n`;\n      \n      // Calibration regions\n      if (calibrationRegions.length > 0) {\n        output += \"CALIBRATION REGIONS:\\n\";\n        calibrationRegions.forEach((region, i) => {\n          const similarity = region.data && region.data.similarity ? \n            (region.data.similarity * 100).toFixed(1) + '%' : 'Not calculated';\n            \n          output += `[${i}] Time: ${region.start.toFixed(2)}s-${region.end.toFixed(2)}s | Duration: ${(region.end - region.start).toFixed(2)}s | Similarity: ${similarity}\\n`;\n          \n          // Add token details if available\n          if (region.data && region.data.tokens && region.data.tokens.length > 0) {\n            const tokens = region.data.tokens;\n            output += `    Tokens: ${tokens.length} | Types: ${tokens.map(t => t.type).join('')}\\n`;\n          }\n        });\n      }\n      \n      // Detection history\n      output += \"\\nDETECTION HISTORY:\\n\";\n      output += `----------------\\n`;\n      if (detectionEvents.length > 0) {\n        detectionEvents.slice(-5).reverse().forEach(event => {\n          output += `[#${event.id}] Time: ${new Date(event.time).toLocaleTimeString()} | Confidence: ${(event.similarity * 100).toFixed(1)}%\\n`;\n          output += `    Tokens: ${event.tokenCount} | Types: ${formatTokenTypeCounts(event.tokenTypes)}\\n`;\n        });\n      } else {\n        output += \"No detections recorded\\n\";\n      }\n      \n      // Update the debug output element\n      debugOutput.textContent = output;\n    }\n    \n    // Copy all diagnostics to clipboard\n    function copyAllDiagnostics() {\n      // Combine all diagnostic data\n      const allData = debugOutput.textContent + \n        \"\\n\\n=== LOG MESSAGES ===\\n\" + \n        diagnosticsLog.textContent;\n      \n      // Copy to clipboard\n      navigator.clipboard.writeText(allData)\n        .then(() => {\n          alert(\"Diagnostic data copied to clipboard!\");\n        })\n        .catch(err => {\n          console.error('Error copying text: ', err);\n          alert(\"Failed to copy. Please select and copy the text manually.\");\n        });\n    }\n    \n    // Utility: Log message to diagnostics box\n    function log(message) {\n      const time = new Date().toLocaleTimeString();\n      diagnosticsLog.innerHTML += `[${time}] ${message}\\n`;\n      diagnosticsLog.scrollTop = diagnosticsLog.scrollHeight;\n      console.log(message); // Also log to console for debugging\n    }\n    \n    // Initialize the app when the page loads\n    window.addEventListener('load', init);\n    \n    // Initialize Audio Context\n    function initAudioContext() {\n      audioContext = new (window.AudioContext || window.webkitAudioContext)();\n    }\n    \n    // Initialize enhanced calibration\n    function initEnhancedCalibration() {\n      // Add event listeners for the feature type selector\n      document.querySelectorAll('input[name=\"featureType\"]').forEach(radio => {\n        radio.addEventListener('change', event => {\n          selectedFeatureType = event.target.value;\n          updateFeatureComparison();\n        });\n      });\n      \n      // Add event listeners for threshold sliders\n      const matchThresholdSlider = document.getElementById('matchThresholdSlider');\n      const minConfidenceSlider = document.getElementById('minConfidenceSlider');\n      \n      matchThresholdSlider.addEventListener('input', function() {\n        const value = this.value / 100;\n        document.getElementById('matchThresholdValue').textContent = `${this.value}%`;\n        matchThreshold = value;\n        updateThresholdLine();\n      });\n      \n      minConfidenceSlider.addEventListener('input', function() {\n        const value = this.value / 100;\n        document.getElementById('minConfidenceValue').textContent = `${this.value}%`;\n        minConfidence = value;\n      });\n    }\n    \n    // Start recording audio\n    async function startRecording() {\n      if (isRecording) return;\n      \n      try {\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        recorder = new MediaRecorder(stream);\n        \n        recordedChunks = [];\n        isRecording = true;\n        \n        recordBtn.disabled = true;\n        stopBtn.disabled = false;\n        \n        // Handle data available\n        recorder.ondataavailable = function(e) {\n          recordedChunks.push(e.data);\n        };\n        \n        // Handle recording stop\n        recorder.onstop = function() {\n          isRecording = false;\n          \n          // Create audio blob and load into wavesurfer\n          const blob = new Blob(recordedChunks, { type: 'audio/webm' });\n          const url = URL.createObjectURL(blob);\n          wavesurfer.load(url);\n          \n          // Clean up\n          stream.getTracks().forEach(track => track.stop());\n          \n          log('Recording loaded into waveform display - drag to select a region');\n        };\n        \n        // Start recording\n        recorder.start();\n        log('Recording started...');\n        \n      } catch (err) {\n        console.error('Error accessing microphone:', err);\n        log('Error: ' + err.message);\n      }\n    }\n    \n    // Stop recording\n    function stopRecording() {\n      if (recorder && isRecording) {\n        recorder.stop();\n        recordBtn.disabled = false;\n        stopBtn.disabled = true;\n        log('Recording stopped');\n      }\n    }\n    \n// Create template from selected region\nasync function createTemplate() {\n  try {\n    // First ensure WaveSurfer is loaded\n    if (!wavesurfer || !wavesurfer.backend || !wavesurfer.backend.buffer) {\n      log('Error: WaveSurfer not fully loaded or no audio present');\n      return;\n    }\n    \n    // Make sure regions plugin is initialized\n    if (!wavesurfer.regions || typeof wavesurfer.regions.list !== 'object') {\n      log('Error: Regions plugin not properly initialized');\n      return;\n    }\n    \n    // Get available regions and verify we have at least one\n    const regions = Object.values(wavesurfer.regions.list || {});\n    if (!regions || regions.length === 0) {\n      log('Please select a region first by dragging on the waveform');\n      return;\n    }\n    \n    // Get first region and verify it has start/end properties\n    const region = regions[0];\n    if (!region || region.start === undefined || region.end === undefined) {\n      log('Error: Invalid region selected. Please try again with a new selection');\n      return;\n    }\n    \n    // Validate region boundaries\n    if (typeof region.start !== 'number' || typeof region.end !== 'number' || \n        region.start >= region.end || region.start < 0) {\n      log('Error: Region has invalid boundaries. Please select a valid region');\n      return;\n    }\n    \n    // Now it's safe to set the template region\n    templateRegion = region;\n    \n    // Continue with the rest of the function...\n    log(`Creating template from region: ${templateRegion.start.toFixed(2)}s - ${templateRegion.end.toFixed(2)}s`);\n    \n    // Clear other regions\n    Object.values(wavesurfer.regions.list).forEach(r => {\n      if (r !== templateRegion) {\n        r.remove();\n      }\n    });\n    \n    // Update appearance and set data\n    templateRegion.id = 'template-' + Date.now();\n    templateRegion.color = regionColors[0];\n    templateRegion.drag = false;\n    templateRegion.resize = false;\n    templateRegion.update();\n    \n    templateRegion.data = {\n      tokens: [],\n      features: null\n    };\n    \n      \n      log(`Creating template from region: ${templateRegion.start.toFixed(2)}s - ${templateRegion.end.toFixed(2)}s`);\n      \n      // Extract audio from region\n      const audioBuffer = await extractRegionAudio(templateRegion);\n      templateBuffer = audioBuffer;\n      \n      if (!audioBuffer) {\n        log('Failed to extract audio from region');\n        return;\n      }\n      \n      // Extract frames for visualization\n      const frames = await extractFeatureFrames(audioBuffer);\n      templateRegion.data.features = frames;\n      \n      // Extract tokens from audio\n      const tokens = await extractTokensFromBuffer(audioBuffer);\n      templateTokens = tokens;\n      templateRegion.data.tokens = tokens;\n      \n      log(`Extracted ${tokens.length} tokens from template`);\n      \n      // Generate debug output\n      updateDebugOutput();\n      \n      // Display template tokens\n      displayTemplateTokens();\n      \n      // Show calibration controls and color legend\n      calibrationControls.style.display = 'inline-block';\n      regionColorLegend.style.display = 'flex';\n      \n      // Update UI\n      createTemplateBtn.disabled = true;\n      calibrationInfo.innerHTML = `\n        <strong>Template extracted:</strong> ${templateTokens.length} tokens from region ${templateRegion.start.toFixed(2)}s - ${templateRegion.end.toFixed(2)}s. \n        <br>Now add calibration regions by clicking \"Select Calibration Region\" and selecting other instances of the same thikr.\n      `;\n      \n      // Show token container\n      tokenContainer.style.display = 'block';\n} catch (error) {\n    // Add a global error handler to catch any unexpected issues\n    console.error('Error in createTemplate:', error);\n    log(`Error creating template: ${error.message || 'Unknown error'}`);\n  }\n}    \n    // Select calibration region\n    function enhancedSelectCalibrationRegion() {\n      calibrationMode = true;\n      log('Click and drag on the waveform to select another instance of the same thikr pattern.');\n      \n      // Add a one-time event handler for the next region event\n      const handleNextRegionEvent = function(region) {\n        // Only handle this once\n        wavesurfer.un('region-update-end', handleNextRegionEvent);\n        wavesurfer.un('region-created', handleNextRegionEvent);\n        \n        // Skip if this is the template region\n        if (templateRegion && region.id === templateRegion.id) {\n          calibrationMode = false;\n          return;\n        }\n        \n        // Determine color index for this region\n        const colorIndex = (calibrationRegions.length % (regionColors.length - 2)) + 3; // Skip template and selected colors\n        \n        // Create a new calibration region\n        const calibRegion = wavesurfer.addRegion({\n          id: 'calibration-' + Date.now(),\n          start: region.start,\n          end: region.end,\n          color: regionColors[colorIndex], // Use color from palette\n          drag: true,\n          resize: true\n        });\n        \n        // Store metadata with the region\n        calibRegion.data = {\n          tokens: [],\n          similarity: null,\n          features: null,\n          colorIndex: colorIndex // Store color index for reference\n        };\n        \n        // Add to the calibration regions array\n        calibrationRegions.push(calibRegion);\n        updateRegionCount();\n        \n        log(`Calibration region created: ${calibRegion.start.toFixed(2)}s - ${calibRegion.end.toFixed(2)}s`);\n        \n        // Add to UI list with matching color\n        addRegionToList(calibRegion, regionColors[colorIndex]);\n        \n        // Enable calibration button\n        if (calibrationRegions.length > 0) {\n          calibrateBtn.disabled = false;\n        }\n        \n        // Show calibration panel\n        document.getElementById('calibrationPanel').style.display = 'block';\n        \n        // Turn off calibration mode\n        calibrationMode = false;\n        \n        // Remove the original region if it's not the template\n        if (region !== templateRegion) {\n          region.remove();\n        }\n      };\n      \n      // Listen for either region creation or update\n      wavesurfer.on('region-created', handleNextRegionEvent);\n      wavesurfer.on('region-update-end', handleNextRegionEvent);\n    }\n    \n    // Add a region to the UI list\n    function addRegionToList(region, color) {\n      const regionList = document.getElementById('regionList');\n      \n      // Create region item element\n      const regionItem = document.createElement('div');\n      regionItem.className = 'region-item';\n      regionItem.id = `region-item-${region.id}`;\n      regionItem.dataset.regionId = region.id;\n      \n      // Create color indicator\n      const colorIndicator = document.createElement('div');\n      colorIndicator.className = 'region-color-indicator';\n      colorIndicator.style.backgroundColor = color;\n      \n      // Create region info\n      const regionInfo = document.createElement('div');\n      regionInfo.className = 'region-info';\n      regionInfo.textContent = `Region ${calibrationRegions.length}: ${region.start.toFixed(2)}s - ${region.end.toFixed(2)}s`;\n      \n      // Create similarity score display (initially empty)\n      const similarityScore = document.createElement('div');\n      similarityScore.className = 'similarity-score';\n      similarityScore.textContent = '...';\n      \n      // Create region actions\n      const regionActions = document.createElement('div');\n      regionActions.className = 'region-actions';\n      \n      const playButton = document.createElement('button');\n      playButton.className = 'play-region';\n      playButton.innerHTML = '&#9658;'; // Play icon\n      playButton.title = 'Play this region';\n      playButton.addEventListener('click', (e) => {\n        e.stopPropagation();\n        playRegion(region);\n      });\n      \n      const removeButton = document.createElement('button');\n      removeButton.className = 'remove-region';\n      removeButton.innerHTML = '&#10005;'; // X icon\n      removeButton.title = 'Remove this region';\n      removeButton.addEventListener('click', (e) => {\n        e.stopPropagation();\n        removeCalibrationRegion(region.id);\n      });\n      \n      // Add pulse effect to indicate it's newly created\n      regionItem.classList.add('pulse-effect');\n      setTimeout(() => {\n        regionItem.classList.remove('pulse-effect');\n      }, 3000);\n      \n      // Assemble the region item\n      regionActions.appendChild(playButton);\n      regionActions.appendChild(removeButton);\n      regionItem.appendChild(colorIndicator);\n      regionItem.appendChild(regionInfo);\n      regionItem.appendChild(similarityScore);\n      regionItem.appendChild(regionActions);\n      \n      // Add click event to select this region\n      regionItem.addEventListener('click', () => {\n        selectRegion(region.id);\n      });\n      \n      // Add to the list\n      regionList.appendChild(regionItem);\n    }\n    \n    // Play a specific region\n    function playRegion(region) {\n      // Set playback to start at region start\n      wavesurfer.setCurrentTime(region.start);\n      \n      // Play for the duration of the region\n      wavesurfer.play(region.start, region.end);\n      \n      // Add visual feedback by highlighting the region temporarily\n      const originalColor = region.color;\n      region.color = 'rgba(252, 196, 25, 0.5)'; // Bright yellow for playing\n      region.update();\n      \n      // Reset color after playback\n      setTimeout(() => {\n        region.color = originalColor;\n        region.update();\n      }, (region.end - region.start) * 1000 + 100); // Convert to ms and add a small buffer\n      \n      log(`Playing region: ${region.start.toFixed(2)}s to ${region.end.toFixed(2)}s`);\n    }\n    \n    // Remove a calibration region\n    function removeCalibrationRegion(regionId) {\n      // Find the region in the list\n      const regionIndex = calibrationRegions.findIndex(r => r.id === regionId);\n      \n      if (regionIndex !== -1) {\n        // Remove the region from WaveSurfer\n        calibrationRegions[regionIndex].remove();\n        \n        // Remove from our array\n        calibrationRegions.splice(regionIndex, 1);\n        \n        // Remove from UI\n        const regionItem = document.getElementById(`region-item-${regionId}`);\n        if (regionItem) {\n          regionItem.remove();\n        }\n        \n        // Update region count\n        updateRegionCount();\n        \n        // Update calibrate button state\n        calibrateBtn.disabled = calibrationRegions.length === 0;\n        \n        // If selected region was removed, clear selection\n        if (selectedRegionId === regionId) {\n          selectedRegionId = null;\n          updateFeatureComparison();\n        }\n        \n        // Update comparison view\n        if (document.getElementById('comparisonRows').children.length > 0) {\n          createThikrComparisonView();\n        }\n        \n        log(`Calibration region removed (${calibrationRegions.length} remaining)`);\n      }\n    }\n    \n    // Update the region counter display\n    function updateRegionCount() {\n      regionCount.textContent = calibrationRegions.length;\n    }\n    \n    // Select a region for inspection\n    function selectRegion(regionId) {\n      // Deselect previous region in UI\n      if (selectedRegionId) {\n        const prevSelected = document.getElementById(`region-item-${selectedRegionId}`);\n        if (prevSelected) {\n          prevSelected.classList.remove('selected');\n        }\n        \n        // Reset color of previously selected region\n        const prevRegion = calibrationRegions.find(r => r.id === selectedRegionId);\n        if (prevRegion) {\n          // Restore original color\n          const colorIndex = prevRegion.data.colorIndex || 1;\n          prevRegion.color = regionColors[colorIndex];\n          prevRegion.update();\n        }\n      }\n      \n      // Update selection\n      selectedRegionId = regionId;\n      \n      // Update UI selection\n      const selectedItem = document.getElementById(`region-item-${regionId}`);\n      if (selectedItem) {\n        selectedItem.classList.add('selected');\n      }\n      \n      // Update the feature comparison visualization\n      updateFeatureComparison();\n      \n      // Also update comparison view to highlight the selected region\n      const comparisonRows = document.getElementById('comparisonRows').querySelectorAll('.comparison-row');\n      comparisonRows.forEach(row => {\n        if (row.dataset.regionId === regionId) {\n          row.style.backgroundColor = 'rgba(230, 245, 255, 0.5)';\n          row.style.borderLeft = '3px solid ' + regionColors[2];\n        } else {\n          row.style.backgroundColor = '';\n          row.style.borderLeft = '';\n        }\n      });\n      \n      // Highlight the region in the waveform\n      calibrationRegions.forEach(region => {\n        if (region.id === regionId) {\n          // Apply selected color\n          region.color = regionColors[2]; // Selected region color\n          region.update();\n          \n          // Scroll to region in wavesurfer\n          wavesurfer.setCurrentTime(region.start);\n        } else {\n          // Restore original color\n          const colorIndex = region.data.colorIndex || 1;\n          region.color = regionColors[colorIndex];\n          region.update();\n        }\n      });\n      \n      log(`Selected calibration region: ${regionId}`);\n    }\n    \n    // Extract audio buffer from a region\n    async function extractRegionAudio(region) {\n      if (!region || !wavesurfer || !wavesurfer.backend.buffer) {\n        log('Error: Missing region or audio data');\n        return null;\n      }\n      \n      const sourceBuffer = wavesurfer.backend.buffer;\n      const startSample = Math.floor(region.start * sourceBuffer.sampleRate);\n      const endSample = Math.floor(region.end * sourceBuffer.sampleRate);\n      \n      if (startSample >= endSample || startSample < 0 || endSample > sourceBuffer.length) {\n        log('Error: Invalid region boundaries');\n        return null;\n      }\n      \n      // Create a new buffer for the region\n      const regionBuffer = audioContext.createBuffer(\n        sourceBuffer.numberOfChannels,\n        endSample - startSample,\n        sourceBuffer.sampleRate\n      );\n      \n      // Copy audio data to region buffer\n      for (let channel = 0; channel < sourceBuffer.numberOfChannels; channel++) {\n        const sourceData = sourceBuffer.getChannelData(channel);\n        const regionData = regionBuffer.getChannelData(channel);\n        for (let i = 0; i < regionBuffer.length; i++) {\n          regionData[i] = sourceData[startSample + i];\n        }\n      }\n      \n      return regionBuffer;\n    }\n    \n    // Extract feature frames from audio buffer\n    async function extractFeatureFrames(buffer) {\n      return new Promise((resolve) => {\n        const frames = [];\n        const offlineCtx = new OfflineAudioContext(\n          buffer.numberOfChannels,\n          buffer.length,\n          buffer.sampleRate\n        );\n        \n        const source = offlineCtx.createBufferSource();\n        source.buffer = buffer;\n        \n        // Create Meyda analyzer\n        const analyzer = Meyda.createMeydaAnalyzer({\n          audioContext: offlineCtx,\n          source: source,\n          bufferSize: frameSize,\n          hopSize: hopSize,\n          featureExtractors: ['rms', 'mfcc', 'spectralCentroid', 'spectralFlatness', 'zcr'],\n          callback: (features) => {\n            frames.push({\n              time: frames.length * (hopSize / offlineCtx.sampleRate),\n              rms: features.rms,\n              mfcc: features.mfcc,\n              spectralCentroid: features.spectralCentroid,\n              spectralFlatness: features.spectralFlatness,\n              zcr: features.zcr\n            });\n          }\n        });\n        \n        analyzer.start();\n        source.connect(offlineCtx.destination);\n        source.start();\n        \n        // When rendering is complete, return frames\n        offlineCtx.startRendering().then(() => {\n          log(`Extracted ${frames.length} frames from buffer`);\n          resolve(frames);\n        }).catch(err => {\n          console.error('Feature extraction error:', err);\n          log(`Feature extraction error: ${err.message}`);\n          resolve([]);\n        });\n      });\n    }\n    \n    // Extract tokens from audio buffer\n    async function extractTokensFromBuffer(buffer) {\n      const tokens = [];\n      \n      // Track frame features\n      const frames = await extractFeatureFrames(buffer);\n      \n      // Find key points in the audio (peaks, valleys, transitions)\n      for (let i = 2; i < frames.length - 2; i++) {\n        const prevFrame2 = frames[i-2];\n        const prevFrame = frames[i-1];\n        const frame = frames[i];\n        const nextFrame = frames[i+1];\n        const nextFrame2 = frames[i+2];\n        \n        // Skip frames with very low energy\n        if (frame.rms < 0.01) continue;\n        \n        // Determine token type based on audio characteristics\n        let tokenType = determineTokenType(frame, prevFrame, nextFrame);\n        \n        // Only add if it's a significant point in the audio\n        if (isSignificantPoint(frame, prevFrame, nextFrame, prevFrame2, nextFrame2)) {\n          tokens.push({\n            type: tokenType,\n            time: frame.time,\n            rms: frame.rms,\n            spectralCentroid: frame.spectralCentroid,\n            mfcc: frame.mfcc.slice(0, 5), // Only keep first 5 coefficients\n            spectralFlux: calculateSpectralFlux(frame, prevFrame),\n            zcr: frame.zcr\n          });\n        }\n      }\n      \n      // Simplify to avoid too many tokens\n      return simplifyTokenSequence(tokens);\n    }\n    \n    // Calculate spectral flux (difference from previous frame)\n    function calculateSpectralFlux(frame, prevFrame) {\n      if (!prevFrame) return 0;\n      \n      // Use spectral centroid difference as a simple flux measure\n      return Math.abs(frame.spectralCentroid - prevFrame.spectralCentroid);\n    }\n    \n    // Determine if this is a significant point in the audio\n    function isSignificantPoint(frame, prevFrame, nextFrame, prevFrame2, nextFrame2) {\n      if (!prevFrame || !nextFrame) return false;\n      \n      // Energy peak (local maximum)\n      const isEnergyPeak = frame.rms > prevFrame.rms && \n                          frame.rms > nextFrame.rms && \n                          frame.rms > 0.02;\n      \n      // Energy valley (local minimum)\n      const isEnergyValley = frame.rms < prevFrame.rms && \n                            frame.rms < nextFrame.rms && \n                            prevFrame.rms > 0.02 && \n                            nextFrame.rms > 0.02;\n      \n      // Spectral centroid peak (local maximum - bright sounds)\n      const isSpectralPeak = frame.spectralCentroid > prevFrame.spectralCentroid && \n                            frame.spectralCentroid > nextFrame.spectralCentroid &&\n                            frame.spectralCentroid > 3000;\n      \n      // Sharp rising edge in energy\n      const isRisingEdge = prevFrame2 && \n                          (frame.rms - prevFrame2.rms) > 0.03;\n      \n      // Sharp falling edge in energy\n      const isFallingEdge = nextFrame2 && \n                           (frame.rms - nextFrame2.rms) > 0.03;\n      \n      // Zero crossing rate peak (consonant sounds)\n      const isZcrPeak = frame.zcr > prevFrame.zcr && \n                        frame.zcr > nextFrame.zcr && \n                        frame.zcr > 0.3;\n      \n      return isEnergyPeak || isEnergyValley || isSpectralPeak || isZcrPeak || isRisingEdge || isFallingEdge;\n    }\n    \n    // Determine token type based on audio characteristics\n    function determineTokenType(frame, prevFrame, nextFrame) {\n      if (!prevFrame || !nextFrame) return 'E';\n      \n      // Energy rising\n      if (frame.rms > prevFrame.rms * 1.2 && frame.rms > 0.02) {\n        return 'A';\n      }\n      \n      // Energy falling\n      if (frame.rms < prevFrame.rms * 0.8 && prevFrame.rms > 0.02) {\n        return 'B';\n      }\n      \n      // High spectral content (bright/sharp sounds)\n      if (frame.spectralCentroid > 5000 && frame.rms > 0.02) {\n        return 'C';\n      }\n      \n      // Low spectral content (dull/muffled sounds)\n      if (frame.spectralCentroid < 2000 && frame.rms > 0.02) {\n        return 'D';\n      }\n      \n      // Default token type for background/silence\n      return 'E';\n    }\n    \n    // Simplify token sequence to avoid too many tokens\n    function simplifyTokenSequence(tokens) {\n      if (tokens.length <= 10) return tokens;\n      \n      // Group tokens by type and proximity\n      const simplified = [];\n      let lastTokenType = null;\n      let lastTokenTime = -1;\n      \n      for (let i = 0; i < tokens.length; i++) {\n        // Keep token if:\n        // 1. It's a different type than the last one\n        // 2. It's sufficiently separated in time\n        // 3. It's one of the first or last tokens\n        // 4. It's evenly spaced throughout (keep ~15 tokens total)\n        const timeDiff = lastTokenTime >= 0 ? tokens[i].time - lastTokenTime : 999;\n        \n        if (tokens[i].type !== lastTokenType || \n            timeDiff > 0.1 || \n            i === 0 || \n            i === tokens.length - 1 ||\n            i % Math.ceil(tokens.length / 15) === 0) {\n          simplified.push(tokens[i]);\n          lastTokenType = tokens[i].type;\n          lastTokenTime = tokens[i].time;\n        }\n      }\n      \n      return simplified;\n    }\n    \n    // Display template tokens\n    function displayTemplateTokens() {\n      // Clear previous display\n      tokenSequence.innerHTML = '';\n      activeTokenTypes.clear();\n      \n      // Display each token\n      templateTokens.forEach((token, index) => {\n        const tokenEl = document.createElement('div');\n        tokenEl.className = 'token';\n        tokenEl.style.backgroundColor = tokenColors[token.type];\n        \n        // Use letters A-Z for first 26, then numbers\n        const letter = index < 26 ? String.fromCharCode(65 + index) : (index - 25);\n        tokenEl.textContent = letter;\n        \n        // Add tooltip with more info\n        tokenEl.title = `Token ${letter}: Type ${token.type} (${tokenDescriptions[token.type]})\nRMS: ${token.rms.toFixed(3)}\nSpectral Centroid: ${(token.spectralCentroid/1000).toFixed(1)}kHz`;\n        \n        // Store token type for legend highlight\n        activeTokenTypes.add(token.type);\n        \n        // Add token type label\n        const labelEl = document.createElement('div');\n        labelEl.className = 'token-label';\n        labelEl.textContent = token.type;\n        tokenEl.appendChild(labelEl);\n        \n        // Add debug info tooltip\n        if (showFeatureValues) {\n          const debugInfo = document.createElement('div');\n          debugInfo.className = 'token-debug-info';\n          debugInfo.textContent = `RMS: ${token.rms.toFixed(3)}, SC: ${(token.spectralCentroid/1000).toFixed(1)}k`;\n          tokenEl.appendChild(debugInfo);\n        }\n        \n        tokenSequence.appendChild(tokenEl);\n      });\n      \n      // Update legend to highlight active token types\n      updateLegend();\n    }\n    \n    // Update legend to highlight active token types\n    function updateLegend() {\n      const legendItems = document.querySelectorAll('.legend-item');\n      \n      legendItems.forEach(item => {\n        const typeText = item.querySelector('span').textContent;\n        const type = typeText.charAt(0); // Get the letter (A, B, C, etc.)\n        \n        if (activeTokenTypes.has(type)) {\n          item.style.opacity = '1';\n          item.style.fontWeight = 'bold';\n        } else {\n          item.style.opacity = '0.5';\n          item.style.fontWeight = 'normal';\n        }\n      });\n    }\n\n// Start real-time analysis\nasync function startAnalysis() {\n  if (templateTokens.length === 0) {\n    log('Error: Template tokens not available');\n    return;\n  }\n  \n  // Reset state\n  resetAnalysisState();\n  \n  try {\n    // Access microphone\n    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n    const source = audioContext.createMediaStreamSource(stream);\n    \n    // Create Meyda analyzer\n    meydaAnalyzer = Meyda.createMeydaAnalyzer({\n      audioContext: audioContext,\n      source: source,\n      bufferSize: frameSize,\n      hopSize: hopSize,\n      featureExtractors: ['rms', 'mfcc', 'spectralCentroid', 'spectralFlatness', 'zcr'],\n      callback: processFrame\n    });\n    \n    meydaAnalyzer.start();\n    isAnalyzing = true;\n    \n    // Update UI\n    startAnalysisBtn.disabled = true;\n    stopAnalysisBtn.disabled = false;\n    liveActivity.innerHTML = 'Listening for thikr patterns...';\n    \n    log('Real-time analysis started. Recite thikr...');\n    \n  } catch (err) {\n    console.error('Error accessing microphone:', err);\n    log('Error: ' + err.message);\n  }\n}\n\n// Stop real-time analysis\nfunction stopAnalysis() {\n  if (meydaAnalyzer) {\n    meydaAnalyzer.stop();\n  }\n  \n  isAnalyzing = false;\n  \n  // Update UI\n  startAnalysisBtn.disabled = false;\n  stopAnalysisBtn.disabled = true;\n  liveActivity.innerHTML = 'Analysis stopped.';\n  \n  log('Analysis stopped.');\n}\n\n\nfunction processFrame(features) {\n  if (!isAnalyzing) return;\n  \n  const currentTime = audioContext.currentTime;\n  \n  // Create frame object\n  const frame = {\n    time: currentTime,\n    rms: features.rms || 0,\n    mfcc: features.mfcc || [],\n    spectralCentroid: features.spectralCentroid || 0,\n    spectralFlatness: features.spectralFlatness || 0,\n    zcr: features.zcr || 0\n  };\n  \n  // Add to frames buffer\n  prevFrames.push(frame);\n  if (prevFrames.length > 5) {\n    prevFrames.shift();\n  }\n  \n  // Need at least 3 frames to detect features\n  if (prevFrames.length < 3) return;\n  \n  // Get frames for context\n  const currentIdx = prevFrames.length - 1;\n  const prevFrame2 = prevFrames[Math.max(0, currentIdx - 2)];\n  const prevFrame = prevFrames[Math.max(0, currentIdx - 1)];\n  const currentFrame = prevFrames[currentIdx];\n  const nextFrame = null; // We don't have future frames in real-time\n  const nextFrame2 = null;\n  \n  // Check if this frame is a significant point AND enough time has passed since last token\n  if (isSignificantPoint(currentFrame, prevFrame, nextFrame, prevFrame2, nextFrame2) && \n      currentTime - lastTokenTime > 0.05) { // Minimum 50ms between tokens\n    \n    // Determine token type\n    const tokenType = determineTokenType(currentFrame, prevFrame, nextFrame);\n    \n    // Create token\n    const token = {\n      type: tokenType,\n      time: currentTime,\n      rms: currentFrame.rms,\n      spectralCentroid: currentFrame.spectralCentroid,\n      mfcc: currentFrame.mfcc.slice(0, 5),\n      spectralFlux: calculateSpectralFlux(currentFrame, prevFrame),\n      zcr: currentFrame.zcr\n    };\n    \n    // Add to token buffer\n    liveTokenBuffer.push(token);\n    lastTokenTime = currentTime;\n    \n    // Limit token buffer size (keep enough to match template)\n    const maxBuffer = Math.max(30, templateTokens.length * 2);\n    if (liveTokenBuffer.length > maxBuffer) {\n      liveTokenBuffer.shift();\n    }\n    \n    // Update activity display with more detailed token info\n    if (verboseLogging) {\n      updateLiveActivity(`Token ${tokenType} detected (RMS: ${token.rms.toFixed(3)}, SC: ${(token.spectralCentroid/1000).toFixed(1)}k Hz, ZCR: ${token.zcr.toFixed(3)})`);\n    } else {\n      updateLiveActivity(`Token ${tokenType} detected (${token.rms.toFixed(2)} energy)`);\n    }\n    \n    // Process for pattern matching\n    processTokenMatching();\n  }\n}\n\n// Process token matching\nfunction processTokenMatching() {\n  // Need a minimum number of tokens to start matching\n  if (liveTokenBuffer.length < Math.max(3, templateTokens.length / 2)) {\n    return;\n  }\n  \n  // Calculate similarity with template\n  const similarity = compareTokenSequences(templateTokens, liveTokenBuffer);\n  \n  // Add confidence marker\n  addConfidenceMarker(similarity);\n  \n  // Update confidence history\n  confidenceHistory.push(similarity);\n  if (confidenceHistory.length > 50) {\n    confidenceHistory.shift();\n  }\n  \n  // Update UI\n  updateProgressBar(similarity);\n  updateTokenVisualization(similarity);\n  \n  // Update activity display with confidence\n  updateLiveActivity(`Pattern match: ${(similarity * 100).toFixed(1)}% confidence`);\n  \n  if (verboseLogging) {\n    log(`Pattern match: ${(similarity * 100).toFixed(1)}% confidence`);\n  }\n  \n  // Check for detection\n  if (similarity >= matchThreshold && \n      audioContext.currentTime - lastDetectionTime > 2.0) { // Cooldown period\n    \n    // Register detection\n    detectionCount++;\n    counterDisplay.textContent = detectionCount;\n    lastDetectionTime = audioContext.currentTime;\n    \n    // Add to detection events log\n    const detectionEvent = {\n      id: detectionCount,\n      time: new Date().toISOString(),\n      similarity: similarity,\n      thresholdUsed: matchThreshold,\n      tokenCount: liveTokenBuffer.length,\n      tokenTypes: tokenTypeCounts(liveTokenBuffer)\n    };\n    detectionEvents.push(detectionEvent);\n    \n    // Update detection data display\n    updateDetectionData(detectionEvent);\n    \n    // Add detection flash\n    addDetectionFlash();\n    \n    // Apply wave animation\n    applyWaveAnimation();\n    \n    // Update activity display with detection\n    updateLiveActivity(`THIKR DETECTED (#${detectionCount}) with ${(similarity * 100).toFixed(1)}% confidence!`);\n    \n    log(`THIKR DETECTED (#${detectionCount}) with ${(similarity * 100).toFixed(1)}% confidence`);\n    \n    // Clear token buffer to look for next pattern\n    liveTokenBuffer = [];\n  }\n}\n\n// Update detection data display\nfunction updateDetectionData(event) {\n  // Format the detection data\n  const formattedData = `\n    <div style=\"border-bottom: 1px solid #dee2e6; padding-bottom: 10px; margin-bottom: 10px;\">\n      <strong>Detection #${event.id}</strong> (${new Date(event.time).toLocaleTimeString()})\n      <br>Confidence: ${(event.similarity * 100).toFixed(1)}% (threshold: ${(event.thresholdUsed * 100).toFixed(1)}%)\n      <br>Tokens: ${event.tokenCount} (${formatTokenTypeCounts(event.tokenTypes)})\n    </div>\n  `;\n  \n  // Add to detection data display\n  detectionData.innerHTML = formattedData + detectionData.innerHTML;\n  \n  // Keep only the last 10 events in the display\n  const items = detectionData.querySelectorAll('div');\n  if (items.length > 10) {\n    for (let i = 10; i < items.length; i++) {\n      items[i].remove();\n    }\n  }\n  \n  // Update debug output\n  updateDebugOutput();\n}\n\n// Format token type counts\nfunction formatTokenTypeCounts(counts) {\n  return Object.entries(counts)\n    .map(([type, count]) => `${type}:${count}`)\n    .join(', ');\n}\n\n// Count token types\nfunction tokenTypeCounts(tokens) {\n  const counts = {};\n  tokens.forEach(token => {\n    counts[token.type] = (counts[token.type] || 0) + 1;\n  });\n  return counts;\n}\n\n// Update live activity display\nfunction updateLiveActivity(message) {\n  const time = new Date().toLocaleTimeString();\n  const activityMessage = `[${time}] ${message}`;\n  \n  // Add new message at top\n  liveActivity.innerHTML = activityMessage + \"<br>\" + liveActivity.innerHTML;\n  \n  // Limit number of messages\n  const messages = liveActivity.innerHTML.split(\"<br>\");\n  if (messages.length > 10) {\n    liveActivity.innerHTML = messages.slice(0, 10).join(\"<br>\");\n  }\n}\n\n// Add confidence marker to visualization\nfunction addConfidenceMarker(confidence) {\n  // Create a marker\n  const marker = document.createElement('div');\n  marker.className = 'confidence-marker';\n  \n  // Position at the right edge, height based on confidence\n  const bottom = confidence * 100;\n  marker.style.bottom = `${bottom}%`;\n  marker.style.right = '0px';\n  \n  // Color based on threshold\n  if (confidence >= matchThreshold) {\n    marker.style.backgroundColor = 'green';\n  } else if (confidence >= minConfidence) {\n    marker.style.backgroundColor = 'yellow';\n  } else {\n    marker.style.backgroundColor = 'red';\n  }\n  \n  confidenceDisplay.appendChild(marker);\n  \n  // Animate movement\n  let position = 0;\n  const maxPosition = confidenceDisplay.offsetWidth;\n  const moveMarker = () => {\n    position += 2;\n    marker.style.right = `${position}px`;\n    \n    if (position <= maxPosition) {\n      requestAnimationFrame(moveMarker);\n    } else {\n      // Remove marker when it's off-screen\n      marker.remove();\n    }\n  };\n  \n  requestAnimationFrame(moveMarker);\n}\n\n// Update token visualization\nfunction updateTokenVisualization(overallConfidence) {\n  // Get all token elements\n  const tokenElements = tokenSequence.querySelectorAll('.token');\n  if (tokenElements.length === 0) return;\n  \n  // Calculate individual token matches\n  for (let i = 0; i < templateTokens.length && i < tokenElements.length; i++) {\n    const templateToken = templateTokens[i];\n    \n    // Find best matching token in live buffer\n    let bestMatch = 0;\n    for (let j = 0; j < liveTokenBuffer.length; j++) {\n      const liveToken = liveTokenBuffer[j];\n      if (templateToken.type === liveToken.type) {\n        const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - liveToken.rms) / 0.2);\n        bestMatch = Math.max(bestMatch, energySimilarity);\n      }\n    }\n    \n    // Reset animation\n    tokenElements[i].classList.remove('wave-effect');\n    void tokenElements[i].offsetWidth; // Force reflow to restart animation\n    \n    // Adjust token appearance based on match confidence\n    if (bestMatch > 0.7) {\n      // High confidence match\n      tokenElements[i].style.transform = `scale(${1 + bestMatch * 0.4})`;\n      \n      // Calculate color (yellow to green)\n      const r = Math.floor(255 * (1 - bestMatch));\n      const g = Math.floor(200);\n      const b = 0;\n      tokenElements[i].style.backgroundColor = `rgb(${r}, ${g}, ${b})`;\n      tokenElements[i].style.color = bestMatch > 0.8 ? 'white' : 'black';\n      tokenElements[i].style.boxShadow = `0 0 10px rgba(0, 255, 0, ${bestMatch * 0.8})`;\n      \n      // Add wave effect if high confidence\n      if (bestMatch > 0.85) {\n        tokenElements[i].classList.add('wave-effect');\n      }\n    } else if (bestMatch > 0.4) {\n      // Medium confidence match\n      tokenElements[i].style.transform = `scale(${1 + bestMatch * 0.2})`;\n      \n      // Yellow color\n      tokenElements[i].style.backgroundColor = `rgb(255, 204, 0)`;\n      tokenElements[i].style.color = 'black';\n      tokenElements[i].style.boxShadow = `0 0 5px rgba(255, 204, 0, ${bestMatch * 0.5})`;\n    } else {\n      // Low confidence or no match - reset to original\n      tokenElements[i].style.transform = 'scale(1)';\n      tokenElements[i].style.backgroundColor = tokenColors[templateToken.type];\n      tokenElements[i].style.color = 'black';\n      tokenElements[i].style.boxShadow = '0 2px 4px rgba(0,0,0,0.1)';\n    }\n    \n    // Update debug info on token\n    if (showFeatureValues) {\n      const debugInfo = tokenElements[i].querySelector('.token-debug-info');\n      if (debugInfo) {\n        debugInfo.textContent = `Match: ${(bestMatch * 100).toFixed(0)}%`;\n      }\n    }\n  }\n  \n  // If very high confidence, produce wave effect\n  if (overallConfidence > matchThreshold * 0.9) {\n    applyWaveAnimation();\n  }\n}\n\n// Apply wave animation sequence to tokens\nfunction applyWaveAnimation() {\n  const tokenElements = tokenSequence.querySelectorAll('.token');\n  \n  tokenElements.forEach((el, i) => {\n    setTimeout(() => {\n      el.classList.remove('wave-effect');\n      void el.offsetWidth; // Force reflow to restart animation\n      el.classList.add('wave-effect');\n    }, i * 100); // Stagger animation\n  });\n}\n\n// Add detection flash\nfunction addDetectionFlash() {\n  const flash = document.createElement('div');\n  flash.className = 'detection-flash';\n  tokenSequence.appendChild(flash);\n  \n  // Remove after animation completes\n  setTimeout(() => {\n    if (flash.parentNode) {\n      flash.parentNode.removeChild(flash);\n    }\n  }, 1500);\n}\n\n// Update progress bar\nfunction updateProgressBar(confidence) {\n  progressBar.style.height = `${confidence * 100}%`;\n}\n\n// Update threshold line position\nfunction updateThresholdLine() {\n  thresholdLine.style.bottom = `${matchThreshold * 100}%`;\n}\n\n// Reset analysis state\nfunction resetAnalysisState() {\n  liveTokenBuffer = [];\n  currentTokens = [];\n  confidenceHistory = [];\n  prevFrames = [];\n  lastTokenTime = 0;\n  lastDetectionTime = 0;\n  detectionCount = 0;\n  counterDisplay.textContent = detectionCount;\n  updateProgressBar(0);\n  liveActivity.innerHTML = 'Waiting to start analysis...';\n  \n  // Clear detection events\n  detectionEvents = [];\n  detectionData.innerHTML = '';\n  \n  // Reset token visualization\n  const tokenElements = tokenSequence.querySelectorAll('.token');\n  tokenElements.forEach((el, i) => {\n    if (i < templateTokens.length) {\n      const templateToken = templateTokens[i];\n      el.style.transform = 'scale(1)';\n      el.style.backgroundColor = tokenColors[templateToken.type];\n      el.style.color = 'black';\n      el.style.boxShadow = '0 2px 4px rgba(0,0,0,0.1)';\n    }\n  });\n  \n  // Clear confidence markers\n  document.querySelectorAll('.confidence-marker').forEach(el => el.remove());\n}\n\n// Reset the app\nfunction resetApp() {\n  // Stop recording if in progress\n  if (isRecording && recorder) {\n    recorder.stop();\n    isRecording = false;\n  }\n  \n  // Stop analysis if in progress\n  if (isAnalyzing) {\n    stopAnalysis();\n  }\n  \n  // Clear wavesurfer\n  wavesurfer.clearRegions();\n  wavesurfer.empty();\n  \n  // Reset variables\n  templateRegion = null;\n  calibrationRegions = [];\n  templateTokens = [];\n  templateBuffer = null;\n  calibrationMode = false;\n  \n  // Reset analysis state\n  resetAnalysisState();\n  \n  // Clear token display\n  tokenSequence.innerHTML = '';\n  \n  // Reset UI\n  recordBtn.disabled = false;\n  stopBtn.disabled = true;\n  playBtn.disabled = true;\n  createTemplateBtn.disabled = true;\n  calibrateBtn.disabled = true;\n  startAnalysisBtn.disabled = true;\n  stopAnalysisBtn.disabled = true;\n  \n  // Hide panels and reset counts\n  tokenContainer.style.display = 'none';\n  calibrationControls.style.display = 'none';\n  document.getElementById('calibrationPanel').style.display = 'none';\n  regionColorLegend.style.display = 'none';\n  regionCount.textContent = '0';\n  \n  // Reset calibration status\n  updateCalibrationStatus('pending');\n  \n  calibrationInfo.textContent = 'Record audio, then select a template region by dragging on the waveform.';\n  liveActivity.innerHTML = 'Waiting to start analysis...';\n  \n  // Clear diagnostics\n  diagnosticsLog.innerHTML = '';\n  detectionData.innerHTML = '';\n  debugOutput.innerHTML = '';\n  \n  log('App reset');\n}\n\n// Update the debug output \nfunction updateDebugOutput() {\n  // Create a formatted summary of the current state for easy copy/paste debugging\n  let output = \"=== THIKR COUNTER DEBUG DATA ===\\n\\n\";\n  \n  // Template info\n  output += \"TEMPLATE INFO:\\n\";\n  output += `--------------\\n`;\n  if (templateTokens.length > 0) {\n    output += `Token count: ${templateTokens.length}\\n`;\n    output += `Token sequence: ${templateTokens.map(t => t.type).join('')}\\n`;\n    \n    // Token type counts\n    const counts = {};\n    templateTokens.forEach(token => {\n      counts[token.type] = (counts[token.type] || 0) + 1;\n    });\n    \n    output += `Token distribution: ${Object.entries(counts)\n      .map(([type, count]) => `${type}:${count} (${Math.round(count/templateTokens.length*100)}%)`)\n      .join(', ')}\\n\\n`;\n      \n    // Detailed token data (first 5 tokens)\n    output += \"FIRST 5 TEMPLATE TOKENS:\\n\";\n    templateTokens.slice(0, 5).forEach((token, i) => {\n      output += `[${i}] Type:${token.type} | RMS:${token.rms.toFixed(3)} | SC:${token.spectralCentroid.toFixed(0)} | ZCR:${token.zcr ? token.zcr.toFixed(3) : 'N/A'}\\n`;\n    });\n  } else {\n    output += \"No template tokens available\\n\";\n  }\n  \n  // Calibration info\n  output += \"\\nCALIBRATION INFO:\\n\";\n  output += `-----------------\\n`;\n  output += `Regions: ${calibrationRegions.length}\\n`;\n  output += `Match threshold: ${(matchThreshold * 100).toFixed(1)}%\\n`;\n  output += `Min confidence: ${(minConfidence * 100).toFixed(1)}%\\n\\n`;\n  \n  // Calibration regions\n  if (calibrationRegions.length > 0) {\n    output += \"CALIBRATION REGIONS:\\n\";\n    calibrationRegions.forEach((region, i) => {\n      const similarity = region.data && region.data.similarity ? \n        (region.data.similarity * 100).toFixed(1) + '%' : 'Not calculated';\n        \n      output += `[${i}] Time: ${region.start.toFixed(2)}s-${region.end.toFixed(2)}s | Duration: ${(region.end - region.start).toFixed(2)}s | Similarity: ${similarity}\\n`;\n      \n      // Add token details if available\n      if (region.data && region.data.tokens && region.data.tokens.length > 0) {\n        const tokens = region.data.tokens;\n        output += `    Tokens: ${tokens.length} | Types: ${tokens.map(t => t.type).join('')}\\n`;\n      }\n    });\n  }\n  \n  // Detection history\n  output += \"\\nDETECTION HISTORY:\\n\";\n  output += `----------------\\n`;\n  if (detectionEvents.length > 0) {\n    detectionEvents.slice(-5).reverse().forEach(event => {\n      output += `[#${event.id}] Time: ${new Date(event.time).toLocaleTimeString()} | Confidence: ${(event.similarity * 100).toFixed(1)}%\\n`;\n      output += `    Tokens: ${event.tokenCount} | Types: ${formatTokenTypeCounts(event.tokenTypes)}\\n`;\n    });\n  } else {\n    output += \"No detections recorded\\n\";\n  }\n  \n  // Update the debug output element\n  debugOutput.textContent = output;\n}\n\n// Copy all diagnostics to clipboard\nfunction copyAllDiagnostics() {\n  // Combine all diagnostic data\n  const allData = debugOutput.textContent + \n    \"\\n\\n=== LOG MESSAGES ===\\n\" + \n    diagnosticsLog.textContent;\n  \n  // Copy to clipboard\n  navigator.clipboard.writeText(allData)\n    .then(() => {\n      alert(\"Diagnostic data copied to clipboard!\");\n    })\n    .catch(err => {\n      console.error('Error copying text: ', err);\n      alert(\"Failed to copy. Please select and copy the text manually.\");\n    });\n}\n\n// Utility: Log message to diagnostics box\nfunction log(message) {\n  const time = new Date().toLocaleTimeString();\n  diagnosticsLog.innerHTML += `[${time}] ${message}\\n`;\n  diagnosticsLog.scrollTop = diagnosticsLog.scrollHeight;\n  console.log(message); // Also log to console for debugging\n}\n\n// Initialize the app when the page loads\nwindow.addEventListener('load', init);\n\n// Initialize Audio Context\nfunction initAudioContext() {\n  audioContext = new (window.AudioContext || window.webkitAudioContext)();\n}\n\n// Initialize enhanced calibration\nfunction initEnhancedCalibration() {\n  // Add event listeners for the feature type selector\n  document.querySelectorAll('input[name=\"featureType\"]').forEach(radio => {\n    radio.addEventListener('change', event => {\n      selectedFeatureType = event.target.value;\n      updateFeatureComparison();\n    });\n  });\n  \n  // Add event listeners for threshold sliders\n  const matchThresholdSlider = document.getElementById('matchThresholdSlider');\n  const minConfidenceSlider = document.getElementById('minConfidenceSlider');\n  \n  matchThresholdSlider.addEventListener('input', function() {\n    const value = this.value / 100;\n    document.getElementById('matchThresholdValue').textContent = `${this.value}%`;\n    matchThreshold = value;\n    updateThresholdLine();\n  });\n  \n  minConfidenceSlider.addEventListener('input', function() {\n    const value = this.value / 100;\n    document.getElementById('minConfidenceValue').textContent = `${this.value}%`;\n    minConfidence = value;\n  });\n}\n</script>\n</body>\n</html>\n\n]]]",
      "created_at": "2025-03-23T16:05:48.010000",
      "sequence_order": 17,
      "parent_id": "4b2ea4af-2398-44c9-a13e-80833eb3c8d0",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "77e9ce19-6a32-45cf-9656-b70d1dbf6c14",
      "role": "tool",
      "content": "**Troubleshooting error in createTemplate**\n\nOkay, user has an error in the `createTemplate` function where it's trying to read the `start` property of an undefined object. This likely happens when Wavesurfer's Regions plugin is involved, pointing to a missing `region.start` in `region.js:94`. It seems like `region` could be removed unexpectedly, maybe by another process, before `createTemplate` is called. I'll focus on why the region might be undefined when it's accessed and whether adjusting the process flow or dependencies can fix this.\n\n**Investigating region removal issue**\n\nIn the `createTemplate` function, when we call `wavesurfer.regions.list`, we check if any regions exist. But sometimes the region object isn't fully defined, leading to the error in `region.js:94` where it tries to read `start`. This happens likely because the Wavesurfer Regions plugin might remove or alter the region before `createTemplate` finishes. A potential fix could be to wait for region creation to finish, isolate `start` and `end` properties before calling `clearRegions()`, or ensure there's a minimum duration before proceeding.\n\n**Proposing a fix for region handling**\n\nThe error seems to occur when `createTemplate` reads the `start` property of a region after clearing all other regions. Instead of using `wavesurfer.regions.list`, a fix could be to temporarily store the region's `start` and `end` variables locally before clearing all regions. Then, after clearing, we re-add the region with the same boundaries. This would prevent attempting to access the original region after it's been removed. Moving forward, using a globally stored region from the creation event could help avoid this problem.",
      "created_at": "2025-03-23T16:06:00.245933",
      "sequence_order": 18,
      "parent_id": "8a756e69-5fde-4bf1-a3fa-9c261ab6ec5e",
      "metadata": {
        "status": "finished_successfully",
        "weight": 0,
        "end_turn": null
      }
    },
    {
      "id": "55921ca9-b339-4cc2-80d2-36afb5675978",
      "role": "assistant",
      "content": "One robust solution is to “freeze” the region’s boundaries as soon as the user makes a selection and then re‐create a new template region using those saved start/end values. In other words, rather than keeping a reference to the region that Wavesurfer later “clears” (or that becomes undefined), you can extract the region’s start and end times, then clear the regions and add a new region with those values.\n\nBelow is a revised version of your createTemplate function that does this:\n\n---\n\n```js\nasync function createTemplate() {\n  try {\n    // Ensure audio is loaded\n    if (!wavesurfer || !wavesurfer.backend || !wavesurfer.backend.buffer) {\n      log('Error: WaveSurfer not fully loaded or no audio present');\n      return;\n    }\n    \n    // Get available regions\n    const regions = Object.values(wavesurfer.regions.list || {});\n    if (!regions.length) {\n      log('Please select a region first by dragging on the waveform');\n      return;\n    }\n    \n    // Extract boundaries from the first region\n    const firstRegion = regions[0];\n    const start = firstRegion.start;\n    const end = firstRegion.end;\n    \n    if (typeof start !== 'number' || typeof end !== 'number' || start >= end) {\n      log('Error: Selected region has invalid boundaries.');\n      return;\n    }\n    \n    log(`Template region selected: ${start.toFixed(2)}s - ${end.toFixed(2)}s`);\n    \n    // Clear all regions so the old region (which might be unstable) is removed\n    wavesurfer.clearRegions();\n    \n    // Create a new template region using the saved boundaries\n    templateRegion = wavesurfer.addRegion({\n      id: 'template-' + Date.now(),\n      start: start,\n      end: end,\n      color: 'rgba(255, 86, 0, 0.4)', // Orange for template\n      drag: false,\n      resize: false\n    });\n    \n    // Attach a data object to the template region\n    templateRegion.data = { tokens: [], features: null };\n    \n    log(`New template region created: ${templateRegion.start.toFixed(2)}s - ${templateRegion.end.toFixed(2)}s`);\n    \n    // Proceed to extract audio, features, and tokens from the new template region\n    const audioBuffer = await extractRegionAudio(templateRegion);\n    if (!audioBuffer) {\n      log('Failed to extract audio from the template region');\n      return;\n    }\n    templateBuffer = audioBuffer;\n    \n    const frames = await extractFeatureFrames(audioBuffer);\n    templateRegion.data.features = frames;\n    \n    const tokens = await extractTokensFromBuffer(audioBuffer);\n    templateTokens = tokens;\n    templateRegion.data.tokens = tokens;\n    \n    log(`Extracted ${tokens.length} tokens from the template`);\n    updateDebugOutput();\n    displayTemplateTokens();\n    \n    // Update UI controls\n    calibrationControls.style.display = 'inline-block';\n    regionColorLegend.style.display = 'flex';\n    createTemplateBtn.disabled = true;\n    calibrationInfo.innerHTML = `\n      <strong>Template extracted:</strong> ${tokens.length} tokens from region ${start.toFixed(2)}s - ${end.toFixed(2)}s.\n      <br>Now add calibration regions by clicking \"Select Calibration Region\" and selecting other instances of the same thikr.\n    `;\n    tokenContainer.style.display = 'block';\n  } catch (error) {\n    console.error('Error in createTemplate:', error);\n    log(`Error creating template: ${error.message || 'Unknown error'}`);\n  }\n}\n```\n\n---\n\n### How This Fix Works\n\n1. **Save Boundaries Immediately:**  \n   The code reads the start and end times from the first region (when the user selects a region) and stores them in local variables.\n\n2. **Clear Regions:**  \n   It then calls `wavesurfer.clearRegions()`. This avoids relying on a region object that might later become undefined.\n\n3. **Recreate Template Region:**  \n   A new region is created using `wavesurfer.addRegion()` with the saved boundaries. This region is guaranteed to have valid start/end properties.\n\n4. **Proceed with Processing:**  \n   The function continues to extract audio, feature frames, and tokens from the newly created template region.\n\nBy re-creating the template region using stored values, you decouple the process from any potential issues (such as asynchronous region removal or updates) that occur with the original region object.\n\nTry this updated process and see if the error no longer occurs.",
      "created_at": "2025-03-23T16:05:56.676067",
      "sequence_order": 19,
      "parent_id": "77e9ce19-6a32-45cf-9656-b70d1dbf6c14",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "36f27344-8b36-4071-9ef4-844c553ede55",
      "role": "user",
      "content": "lockdown-install.js:1 Removing unpermitted intrinsics\n(index):3590 App initialized. Click \"Record Audio\" to begin.\n(index):3590 Recording started...\n(index):3590 Recording stopped\n(index):3590 Recording loaded into waveform display - drag to select a region\n(index):3590 Waveform ready - audio loaded successfully\n(index):3590 Template region created: 0.00s - 0.05s\n(index):3590 Region updated: 0.63s - 3.41s\n(index):3590 Template region selected: 0.63s - 3.41s\n(index):3590 Template region created: 0.63s - 3.41s\n(index):3590 New template region created: 0.63s - 3.41s\n7[Deprecation] The ScriptProcessorNode is deprecated. Use AudioWorkletNode instead. (<URL>)\n[NEW] Explain Console errors by using Copilot in Edge: click\n         \n         to explain an error. \n        Learn more\n        Don't show again\n2(index):3590 Extracted 129 frames from buffer\n(index):3590 Extracted 28 tokens from the template\n(index):3590 Region updated: 4.97s - 7.31s\n(index):3590 Click and drag on the waveform to select another instance of the same thikr pattern.\n(index):3590 Region updated: 8.13s - 10.47s\n(index):3590 Calibration region created: 8.13s - 10.47s\n(index):3590 Region updated: 4.96s - 7.42s\n(index):3590 Click and drag on the waveform to select another instance of the same thikr pattern.\n(index):3590 Calibration region created: 0.00s - 0.05s\n(index):3590 Region updated: 4.79s - 7.24s\n(index):3590 Region updated: 0.00s - 7.44s\n(index):3590 Region updated: 4.93s - 7.44s\n(index):3590 Starting calibration with 2 regions...\n(index):3590 Processing region 1: 8.13s - 10.47s\n2(index):3590 Extracted 107 frames from buffer\n(index):3590 Region 1: 14 tokens, similarity: 28.5%\n(index):3590 Token comparison: {\"similarity\":0.2845854543818844,\"offset\":0,\"details\":[{\"template\":{\"type\":\"A\",\"rms\":0.031979611870628574,\"spectralCentroid\":68.2363848008862},\"window\":{\"type\":\"A\",\"rms\":0.08366429339005357,\"spectralCentroid\":49.43805323390933},\"typeMatch\":1,\"energySimilarity\":0.741576592402875,\"spectralSimilarity\":0.9962403336866046,\"tokenSimilarity\":0.9220970110895229},{\"template\":{\"type\":\"D\",\"rms\":0.030945232103529844,\"spectralCentroid\":51.7496245452731},\"window\":{\"type\":\"D\",\"rms\":0.09905790723939649,\"spectralCentroid\":49.273324291062764},\"typeMatch\":1,\"energySimilarity\":0.6594366243206669,\"spectralSimilarity\":0.9995047399491579,\"tokenSimilarity\":0.8977814612911159},{\"template\":{\"type\":\"A\",\"rms\":0.028262437530616108,\"spectralCentroid\":37.4786515881797},\"window\":{\"type\":\"B\",\"rms\":0.07098331318082567,\"spectralCentroid\":107.11814786045312},\"typeMatch\":0,\"energySimilarity\":0.7863956217489523,\"spectralSimilarity\":0.9860721007455453,\"tokenSimilarity\":0.3345258965992402},{\"template\":{\"type\":\"D\",\"rms\":0.02528779474669335,\"spectralCentroid\":21.058748413892108},\"window\":{\"type\":\"D\",\"rms\":0.07768535132825952,\"spectralCentroid\":82.19810780732851},\"typeMatch\":1,\"energySimilarity\":0.7380122170921692,\"spectralSimilarity\":0.9877721281213128,\"tokenSimilarity\":0.920180877939782},{\"template\":{\"type\":\"A\",\"rms\":0.04331392081967737,\"spectralCentroid\":134.2688622022525},\"window\":{\"type\":\"B\",\"rms\":0.0383546792443569,\"spectralCentroid\":172.7449621486853},\"typeMatch\":0,\"energySimilarity\":0.9752037921233976,\"spectralSimilarity\":0.9923047800107134,\"tokenSimilarity\":0.3917916156380906},{\"template\":{\"type\":\"D\",\"rms\":0.04088861427019256,\"spectralCentroid\":18.718331480549452},\"window\":{\"type\":\"B\",\"rms\":0.02247594749499793,\"spectralCentroid\":186.30197325074155},\"typeMatch\":0,\"energySimilarity\":0.9079366661240269,\"spectralSimilarity\":0.9664832716459616,\"tokenSimilarity\":0.3690293270018042},{\"template\":{\"type\":\"B\",\"rms\":0.03791237994586898,\"spectralCentroid\":148.2451195064873},\"window\":{\"type\":\"D\",\"rms\":0.021163885655294434,\"spectralCentroid\":120.0756070307228},\"typeMatch\":0,\"energySimilarity\":0.9162575285471273,\"spectralSimilarity\":0.9943660975048471,\"tokenSimilarity\":0.3743138683146229},{\"template\":{\"type\":\"D\",\"rms\":0.03792766131782951,\"spectralCentroid\":21.315812509353503},\"window\":{\"type\":\"E\",\"rms\":0.019222007191103375,\"spectralCentroid\":30.272980311745936},\"typeMatch\":0,\"energySimilarity\":0.9064717293663693,\"spectralSimilarity\":0.9982085664395215,\"tokenSimilarity\":0.3717623754538629},{\"template\":{\"type\":\"D\",\"rms\":0.02944675541513324,\"spectralCentroid\":25.38565765629282},\"window\":{\"type\":\"D\",\"rms\":0.020246227907569567,\"spectralCentroid\":155.25616254386335},\"typeMatch\":1,\"energySimilarity\":0.9539973624621816,\"spectralSimilarity\":0.9740258990224859,\"tokenSimilarity\":0.983601798640903},{\"template\":{\"type\":\"D\",\"rms\":0.041628611903653835,\"spectralCentroid\":26.70122065609794},\"window\":{\"type\":\"D\",\"rms\":0.022111526833294315,\"spectralCentroid\":27.127922749637396},\"typeMatch\":1,\"energySimilarity\":0.9024145746482024,\"spectralSimilarity\":0.9999146595812921,\"tokenSimilarity\":0.9707158383525899},{\"template\":{\"type\":\"D\",\"rms\":0.047252843314248866,\"spectralCentroid\":146.00178740469568},\"window\":{\"type\":\"E\",\"rms\":0.015448148015115406,\"spectralCentroid\":69.3018151921251},\"typeMatch\":0,\"energySimilarity\":0.8409765235043327,\"spectralSimilarity\":0.9846600055574859,\"tokenSimilarity\":0.3507589576070484},{\"template\":{\"type\":\"D\",\"rms\":0.045668816214375844,\"spectralCentroid\":18.411092753784246},\"window\":{\"type\":\"A\",\"rms\":0.020850852773883623,\"spectralCentroid\":100.05015243080639},\"typeMatch\":0,\"energySimilarity\":0.8759101827975388,\"spectralSimilarity\":0.9836721880645956,\"tokenSimilarity\":0.3611402736457212},{\"template\":{\"type\":\"D\",\"rms\":0.05132555297464262,\"spectralCentroid\":15.325989274260046},\"window\":{\"type\":\"E\",\"rms\":0.013260754885478863,\"spectralCentroid\":75.8620720149864},\"typeMatch\":0,\"energySimilarity\":0.8096760095541813,\"spectralSimilarity\":0.9878927834518547,\"tokenSimilarity\":0.34169208121143985},{\"template\":{\"type\":\"A\",\"rms\":0.02760623545089081,\"spectralCentroid\":77.30798112355221},\"window\":{\"type\":\"E\",\"rms\":0.013722880565564541,\"spectralCentroid\":68.62659287394622},\"typeMatch\":0,\"energySimilarity\":0.9305832255733687,\"spectralSimilarity\":0.9982637223500788,\"tokenSimilarity\":0.3790013399070185}]}\n(index):3590 Processing region 2: 4.93s - 7.44s\n2(index):3590 Extracted 115 frames from buffer\n(index):3590 Region 2: 27 tokens, similarity: 66.3%\n(index):3590 Token comparison: {\"similarity\":0.6629401819848252,\"offset\":0,\"details\":[{\"template\":{\"type\":\"A\",\"rms\":0.031979611870628574,\"spectralCentroid\":68.2363848008862},\"window\":{\"type\":\"A\",\"rms\":0.04472048900233692,\"spectralCentroid\":55.22026903738945},\"typeMatch\":1,\"energySimilarity\":0.9362956143414582,\"spectralSimilarity\":0.9973967768473007,\"tokenSimilarity\":0.9806283619871676},{\"template\":{\"type\":\"D\",\"rms\":0.030945232103529844,\"spectralCentroid\":51.7496245452731},\"window\":{\"type\":\"D\",\"rms\":0.09064480162652853,\"spectralCentroid\":41.28223107318438},\"typeMatch\":1,\"energySimilarity\":0.7015021523850066,\"spectralSimilarity\":0.9979065213055822,\"tokenSimilarity\":0.9102412978460602},{\"template\":{\"type\":\"A\",\"rms\":0.028262437530616108,\"spectralCentroid\":37.4786515881797},\"window\":{\"type\":\"D\",\"rms\":0.09759160188802704,\"spectralCentroid\":85.84778999619516},\"typeMatch\":0,\"energySimilarity\":0.6533541782129453,\"spectralSimilarity\":0.9903261723183969,\"tokenSimilarity\":0.2950388706957233},{\"template\":{\"type\":\"D\",\"rms\":0.02528779474669335,\"spectralCentroid\":21.058748413892108},\"window\":{\"type\":\"D\",\"rms\":0.031319343715362394,\"spectralCentroid\":24.719681312252188},\"typeMatch\":1,\"energySimilarity\":0.9698422551566548,\"spectralSimilarity\":0.999267813420328,\"tokenSimilarity\":0.9908794578890292},{\"template\":{\"type\":\"A\",\"rms\":0.04331392081967737,\"spectralCentroid\":134.2688622022525},\"window\":{\"type\":\"B\",\"rms\":0.024622506460074974,\"spectralCentroid\":155.00786790310624},\"typeMatch\":0,\"energySimilarity\":0.906542928201988,\"spectralSimilarity\":0.9958521988598292,\"tokenSimilarity\":0.3715480983465793},{\"template\":{\"type\":\"D\",\"rms\":0.04088861427019256,\"spectralCentroid\":18.718331480549452},\"window\":{\"type\":\"D\",\"rms\":0.025939897047927235,\"spectralCentroid\":23.495787506136555},\"typeMatch\":1,\"energySimilarity\":0.9252564138886734,\"spectralSimilarity\":0.9990445087948826,\"tokenSimilarity\":0.9774813750460903},{\"template\":{\"type\":\"B\",\"rms\":0.03791237994586898,\"spectralCentroid\":148.2451195064873},\"window\":{\"type\":\"E\",\"rms\":0.01398313168189743,\"spectralCentroid\":37.824444023310036},\"typeMatch\":0,\"energySimilarity\":0.8803537586801422,\"spectralSimilarity\":0.9779158649033646,\"tokenSimilarity\":0.36189771409437915},{\"template\":{\"type\":\"D\",\"rms\":0.03792766131782951,\"spectralCentroid\":21.315812509353503},\"window\":{\"type\":\"E\",\"rms\":0.014633000718407011,\"spectralCentroid\":149.51581732457564},\"typeMatch\":0,\"energySimilarity\":0.8835266970028876,\"spectralSimilarity\":0.9743599990369556,\"tokenSimilarity\":0.3624940090045618},{\"template\":{\"type\":\"D\",\"rms\":0.02944675541513324,\"spectralCentroid\":25.38565765629282},\"window\":{\"type\":\"E\",\"rms\":0.01677099881732157,\"spectralCentroid\":76.84945587166585},\"typeMatch\":0,\"energySimilarity\":0.9366212170109417,\"spectralSimilarity\":0.9897072403569254,\"tokenSimilarity\":0.3799570891389751},{\"template\":{\"type\":\"D\",\"rms\":0.041628611903653835,\"spectralCentroid\":26.70122065609794},\"window\":{\"type\":\"A\",\"rms\":0.036837413429982584,\"spectralCentroid\":147.28887166410465},\"typeMatch\":0,\"energySimilarity\":0.9760440076316438,\"spectralSimilarity\":0.9758824697983987,\"tokenSimilarity\":0.390401449269333},{\"template\":{\"type\":\"D\",\"rms\":0.047252843314248866,\"spectralCentroid\":146.00178740469568},\"window\":{\"type\":\"D\",\"rms\":0.030298246028880964,\"spectralCentroid\":66.56387161885227},\"typeMatch\":1,\"energySimilarity\":0.9152270135731605,\"spectralSimilarity\":0.9841124168428314,\"tokenSimilarity\":0.9729793457562314},{\"template\":{\"type\":\"D\",\"rms\":0.045668816214375844,\"spectralCentroid\":18.411092753784246},\"window\":{\"type\":\"B\",\"rms\":0.03340405563437273,\"spectralCentroid\":141.74244508113367},\"typeMatch\":0,\"energySimilarity\":0.9386761970999844,\"spectralSimilarity\":0.9753337295345301,\"tokenSimilarity\":0.3791362320834484},{\"template\":{\"type\":\"D\",\"rms\":0.05132555297464262,\"spectralCentroid\":15.325989274260046},\"window\":{\"type\":\"D\",\"rms\":0.036736565832345504,\"spectralCentroid\":17.876485580606897},\"typeMatch\":1,\"energySimilarity\":0.9270550642885145,\"spectralSimilarity\":0.9994899007387307,\"tokenSimilarity\":0.9780655093604274},{\"template\":{\"type\":\"A\",\"rms\":0.02760623545089081,\"spectralCentroid\":77.30798112355221},\"window\":{\"type\":\"A\",\"rms\":0.035049704668226066,\"spectralCentroid\":70.27570855093492},\"typeMatch\":1,\"energySimilarity\":0.9627826539133237,\"spectralSimilarity\":0.9985935454854765,\"tokenSimilarity\":0.9886941507225447},{\"template\":{\"type\":\"D\",\"rms\":0.032878369024050204,\"spectralCentroid\":21.36517239635587},\"window\":{\"type\":\"D\",\"rms\":0.035529713342266706,\"spectralCentroid\":16.951513749565184},\"typeMatch\":1,\"energySimilarity\":0.9867432784089175,\"spectralSimilarity\":0.9991172682706418,\"tokenSimilarity\":0.9959347103497393},{\"template\":{\"type\":\"B\",\"rms\":0.023621433609624244,\"spectralCentroid\":92.49630818115529},\"window\":{\"type\":\"B\",\"rms\":0.027669919248401405,\"spectralCentroid\":59.21318223834553},\"typeMatch\":1,\"energySimilarity\":0.9797575718061142,\"spectralSimilarity\":0.9933433748114381,\"tokenSimilarity\":0.9932616090229781},{\"template\":{\"type\":\"A\",\"rms\":0.021450978495999744,\"spectralCentroid\":128.44015303544248},\"window\":{\"type\":\"D\",\"rms\":0.02818628817909982,\"spectralCentroid\":18.68340667113547},\"typeMatch\":0,\"energySimilarity\":0.9663234515844996,\"spectralSimilarity\":0.9780486507271386,\"tokenSimilarity\":0.38770190054806375},{\"template\":{\"type\":\"D\",\"rms\":0.02098547953908521,\"spectralCentroid\":15.822188319113991},\"window\":{\"type\":\"E\",\"rms\":0.013512398065550558,\"spectralCentroid\":149.83186739782602},\"typeMatch\":0,\"energySimilarity\":0.9626345926323268,\"spectralSimilarity\":0.9731980641842576,\"tokenSimilarity\":0.38611018420812376},{\"template\":{\"type\":\"A\",\"rms\":0.032588864218549785,\"spectralCentroid\":91.84680925595876},\"window\":{\"type\":\"A\",\"rms\":0.03902889308698527,\"spectralCentroid\":143.0708204453695},\"typeMatch\":1,\"energySimilarity\":0.9677998556578226,\"spectralSimilarity\":0.9897551977621178,\"tokenSimilarity\":0.9893154764735584},{\"template\":{\"type\":\"D\",\"rms\":0.03237320667614019,\"spectralCentroid\":14.591384561208216},\"window\":{\"type\":\"D\",\"rms\":0.04337084479474289,\"spectralCentroid\":28.638607146805963},\"typeMatch\":1,\"energySimilarity\":0.9450118094069865,\"spectralSimilarity\":0.9971905554828805,\"tokenSimilarity\":0.983222598370384},{\"template\":{\"type\":\"D\",\"rms\":0.04422894561202236,\"spectralCentroid\":63.73097526411642},\"window\":{\"type\":\"B\",\"rms\":0.036230983063038014,\"spectralCentroid\":76.1703275849427},\"typeMatch\":0,\"energySimilarity\":0.9600101872550783,\"spectralSimilarity\":0.9975121295358348,\"tokenSimilarity\":0.3877542691301069},{\"template\":{\"type\":\"D\",\"rms\":0.04395716292043586,\"spectralCentroid\":12.88556452193183},\"window\":{\"type\":\"D\",\"rms\":0.03649315167373812,\"spectralCentroid\":38.43744431011939},\"typeMatch\":1,\"energySimilarity\":0.9626799437665113,\"spectralSimilarity\":0.9948896240423625,\"tokenSimilarity\":0.9882929455341896},{\"template\":{\"type\":\"D\",\"rms\":0.04932087111086217,\"spectralCentroid\":14.737999600149163},\"window\":{\"type\":\"B\",\"rms\":0.027840174112472416,\"spectralCentroid\":129.51952146944612},\"typeMatch\":0,\"energySimilarity\":0.8925965150080513,\"spectralSimilarity\":0.9770436956261406,\"tokenSimilarity\":0.3654833240650294},{\"template\":{\"type\":\"B\",\"rms\":0.03314502043984523,\"spectralCentroid\":94.69384125839301},\"window\":{\"type\":\"D\",\"rms\":0.023177107669926863,\"spectralCentroid\":81.0716625354853},\"typeMatch\":0,\"energySimilarity\":0.9501604361504081,\"spectralSimilarity\":0.9972755642554184,\"tokenSimilarity\":0.38477568727066425},{\"template\":{\"type\":\"D\",\"rms\":0.03333101695597534,\"spectralCentroid\":14.810131841025566},\"window\":{\"type\":\"D\",\"rms\":0.02042465932764763,\"spectralCentroid\":91.16758388708521},\"typeMatch\":1,\"energySimilarity\":0.9354682118583615,\"spectralSimilarity\":0.9847285095907881,\"tokenSimilarity\":0.9791133145165873},{\"template\":{\"type\":\"B\",\"rms\":0.020080380766298693,\"spectralCentroid\":151.65221691707495},\"window\":{\"type\":\"D\",\"rms\":0.024592828357111733,\"spectralCentroid\":182.2821007555928},\"typeMatch\":0,\"energySimilarity\":0.9774377620459348,\"spectralSimilarity\":0.9938740232322965,\"tokenSimilarity\":0.39261873093701005},{\"template\":{\"type\":\"E\",\"rms\":0.011964728678717725,\"spectralCentroid\":124.47987274409817},\"window\":{\"type\":\"E\",\"rms\":0.018764970746423377,\"spectralCentroid\":149.59252226038473},\"typeMatch\":1,\"energySimilarity\":0.9659987896614718,\"spectralSimilarity\":0.9949774700967426,\"tokenSimilarity\":0.9892973839081158}]}\n(index):3590 Calibration complete. Match threshold set to 50.0%\n2region.js:94  Uncaught TypeError: Cannot read properties of undefined (reading 'start')\n    at e.value (region.js:94:20)\n    at playRegion ((index):2592:14)\n    at HTMLButtonElement.<anonymous> ((index):2546:9)\nvalue @ region.js:94\nplayRegion @ (index):2592\n(anonymous) @ (index):2546\nregion.js:94  Uncaught TypeError: Cannot read properties of undefined (reading 'start')\n    at e.value (region.js:94:20)\n    at (index):2695:18\n    at Array.forEach (<anonymous>)\n    at selectRegion ((index):2691:26)\n    at HTMLButtonElement.<anonymous> ((index):1296:51)\nvalue @ region.js:94\n(anonymous) @ (index):2695\nselectRegion @ (index):2691\n(anonymous) @ (index):1296\nregion.js:94  Uncaught TypeError: Cannot read properties of undefined (reading 'start')\n    at e.value (region.js:94:20)\n    at playRegion ((index):2592:14)\n    at HTMLButtonElement.<anonymous> ((index):1261:47)\nvalue @ region.js:94\nplayRegion @ (index):2592\n(anonymous) @ (index):1261\n(index):3590 Real-time analysis started. Recite thikr...\n(index):3590 Analysis stopped.",
      "created_at": "2025-03-23T16:12:40.783000",
      "sequence_order": 20,
      "parent_id": "55921ca9-b339-4cc2-80d2-36afb5675978",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "ecce7cb0-e25f-4815-bc53-a5e84969239b",
      "role": "tool",
      "content": "**Investigating region errors**\n\nThe user is having errors with a missing 'start' property in region.js:94 and issues with playRegion when the region is undefined. The logs show timestamps like \"Template region created: 0.00s - 0.05s\" and \"Region updated: 0.63s - 3.41s.\" It seems the error is related to the wavesurfer regions plugin, possibly caused by a region being removed or replaced. I'll need to ensure that all calls to playRegion or selectRegion check if the region exists. Maybe the UI is holding a reference to a removed region?\n\n**Revisiting region handling**\n\nIn the addRegionToList function, region.id is used, but in playRegion, we call `wavesurfer.setCurrentTime(region.start)` — and if the region is removed, it might be undefined. A solution could be to re-fetch the region by id from `wavesurfer.regions.list`. If region is missing or invalid, we log an error. I’ll also check that regions exist in selectRegion, especially for calibration regions. The error in region.js:94 seems to be when trying to access `region.start` on an undefined region. Using the region id might prevent this, ensuring stability in both `playRegion` and `selectRegion`.\n\n**Fixing region errors**\n\nInstead of removing the original region in `enhancedSelectCalibrationRegion`, we can modify its properties (like color or id) and add it to `calibrationRegions`. This keeps the region valid for use in `playRegion`. My idea is to refresh `calibrationRegions` from `wavesurfer.regions.list` to avoid stale references. I propose updating the `playRegion` function to check if the region exists in `wavesurfer.regions.list`. This should prevent the \"reading 'start' of undefined\" error.",
      "created_at": "2025-03-23T17:42:53.992277",
      "sequence_order": 21,
      "parent_id": "d6484b6b-b232-4d01-aac2-be40c4bf1b45",
      "metadata": {
        "status": "finished_successfully",
        "weight": 0,
        "end_turn": null
      }
    },
    {
      "id": "36ca42fe-fd4a-443d-bb5d-861f012acd87",
      "role": "assistant",
      "content": "One effective workaround is to stop relying on a saved (and possibly stale) region object. Instead, whenever you need to play (or select) a region, look it up fresh from Wavesurfer’s region list. This way, if a region was removed or updated, you’ll catch that and avoid trying to read its properties.\n\nFor example, change your **playRegion** function to re‐look up the region by its id before using it. Replace your current playRegion with something like this:\n\n---\n\n```js\nfunction playRegion(region) {\n  // Look up the current region object from wavesurfer.regions.list using its id.\n  const currentRegion = wavesurfer.regions.list[region.id];\n  if (!currentRegion || typeof currentRegion.start !== 'number' || typeof currentRegion.end !== 'number') {\n    log(`Region with id ${region.id} is not available for playback.`);\n    return;\n  }\n  // Now safely use currentRegion\n  wavesurfer.setCurrentTime(currentRegion.start);\n  wavesurfer.play(currentRegion.start, currentRegion.end);\n  log(`Playing region: ${currentRegion.start.toFixed(2)}s to ${currentRegion.end.toFixed(2)}s`);\n}\n```\n\n---\n\nLikewise, update your **selectRegion** function to retrieve the region from Wavesurfer’s list rather than using a potentially outdated reference:\n\n---\n\n```js\nfunction selectRegion(regionId) {\n  // Look up the region using its id\n  const region = wavesurfer.regions.list[regionId];\n  if (!region || typeof region.start !== 'number') {\n    log(`Selected region ${regionId} not found.`);\n    return;\n  }\n  \n  // Deselect previous region in UI\n  if (selectedRegionId) {\n    const prevSelected = document.getElementById(`region-item-${selectedRegionId}`);\n    if (prevSelected) {\n      prevSelected.classList.remove('selected');\n    }\n  }\n  \n  selectedRegionId = regionId;\n  \n  // Update UI selection\n  const selectedItem = document.getElementById(`region-item-${regionId}`);\n  if (selectedItem) {\n    selectedItem.classList.add('selected');\n  }\n  \n  // Update the feature comparison visualization, etc.\n  updateFeatureComparison();\n  \n  // Optionally, scroll to the region's start time\n  wavesurfer.setCurrentTime(region.start);\n  \n  log(`Selected calibration region: ${regionId}`);\n}\n```\n\n---\n\n### Why This Works\n\n- **Fresh Lookup:** By always fetching the current region from `wavesurfer.regions.list` using its id, you avoid relying on a stale reference that might have been removed or updated.\n- **Guarding Against Undefined:** You check whether the retrieved region exists and has valid properties before proceeding. If it doesn’t, you log a message and abort the action.\n\nTry these changes and then retest your workflow. This approach should prevent errors like “Cannot read properties of undefined (reading 'start')” that occur when playing or selecting a region.",
      "created_at": "2025-03-23T17:42:49.254211",
      "sequence_order": 22,
      "parent_id": "ecce7cb0-e25f-4815-bc53-a5e84969239b",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "81c00839-01bc-4159-b8cc-cb78bf1b42ba",
      "role": "user",
      "content": "{'content_type': 'image_asset_pointer', 'asset_pointer': 'file-service://file-WfQLrQHb8hoDxbVhtsLpja', 'size_bytes': 4937539, 'width': 2048, 'height': 1358, 'fovea': None, 'metadata': {'dalle': None, 'gizmo': None, 'generation': None, 'container_pixel_height': None, 'container_pixel_width': None, 'emu_omit_glimpse_image': None, 'emu_patches_override': None, 'lpe_keep_patch_ijhw': None, 'sanitized': True, 'asset_pointer_link': None, 'watermarked_asset_pointer': None}}\nExtracted 255 features\n(index):1819 Audio loaded: 5.46 seconds\n(index):1819 App reset\n(index):715  Uncaught TypeError: Cannot read properties of null (reading 'startTime')\n    at updatePlaybackTime ((index):715:65)\nupdatePlaybackTime @ (index):715\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\nrequestAnimationFrame\nupdatePlaybackTime @ (index):729\n(index):1819 Recording started...\n(index):1819 Recording stopped.<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Thikr Counter - Simplified Version</title>\n  <script src=\"https://unpkg.com/meyda@5.6.1/dist/web/meyda.min.js\"></script>\n  <style>\n    body {\n      font-family: system-ui, sans-serif;\n      max-width: 1000px;\n      margin: 0 auto;\n      padding: 20px;\n      background-color: #f5f5f5;\n    }\n    \n    .panel {\n      background: white;\n      border-radius: 8px;\n      padding: 20px;\n      margin-bottom: 20px;\n      box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n    }\n    \n    button {\n      background-color: #4c6ef5;\n      color: white;\n      border: none;\n      padding: 8px 16px;\n      margin: 5px;\n      border-radius: 4px;\n      cursor: pointer;\n      font-weight: 500;\n      transition: all 0.2s ease;\n    }\n    \n    button:hover:not(:disabled) {\n      background-color: #364fc7;\n      transform: translateY(-1px);\n    }\n    \n    button:disabled {\n      background-color: #a5b4fc;\n      cursor: not-allowed;\n    }\n    \n    #counter {\n      font-size: 64px;\n      font-weight: bold;\n      text-align: center;\n      color: #4c6ef5;\n      padding: 20px;\n    }\n    \n    #waveform-display {\n      height: 128px;\n      width: 100%;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      position: relative;\n      margin: 10px 0;\n    }\n    \n    .waveform-canvas {\n      width: 100%;\n      height: 100%;\n    }\n    \n    .selection-marker {\n      position: absolute;\n      height: 100%;\n      background-color: rgba(76, 110, 245, 0.2);\n      border-left: 2px solid rgba(76, 110, 245, 0.7);\n      border-right: 2px solid rgba(76, 110, 245, 0.7);\n      pointer-events: none;\n    }\n    \n    .time-marker {\n      position: absolute;\n      top: 0;\n      height: 100%;\n      width: 2px;\n      background-color: #fa5252;\n      pointer-events: none;\n    }\n    \n    #time-display {\n      text-align: center;\n      font-family: monospace;\n    }\n    \n    .selection-controls {\n      display: flex;\n      align-items: center;\n      margin: 10px 0;\n    }\n    \n    .selection-controls input {\n      margin: 0 10px;\n      width: 80px;\n    }\n    \n    #token-container {\n      margin-top: 20px;\n    }\n    \n    #token-sequence {\n      display: flex;\n      flex-wrap: wrap;\n      padding: 20px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      min-height: 80px;\n      margin: 10px 0;\n      position: relative;\n    }\n    \n    .token {\n      display: inline-flex;\n      align-items: center;\n      justify-content: center;\n      width: 50px;\n      height: 50px;\n      margin: 5px;\n      border-radius: 4px;\n      font-weight: bold;\n      font-size: 20px;\n      transition: all 0.3s ease;\n      position: relative;\n      box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n    }\n    \n    .token-label {\n      position: absolute;\n      top: -15px;\n      font-size: 10px;\n      color: #495057;\n    }\n    \n    #legend {\n      display: flex;\n      flex-wrap: wrap;\n      gap: 10px;\n      padding: 10px;\n      margin-top: 10px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .legend-item {\n      display: flex;\n      align-items: center;\n      margin-right: 15px;\n    }\n    \n    .legend-color {\n      width: 20px;\n      height: 20px;\n      border-radius: 3px;\n      margin-right: 5px;\n    }\n    \n    #analysis-display {\n      height: 100px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      margin: 10px 0;\n      position: relative;\n    }\n    \n    .progress-bar {\n      position: absolute;\n      bottom: 0;\n      left: 0;\n      width: 100%;\n      background-color: #4c6ef5;\n      transition: height 0.1s;\n      height: 0%;\n    }\n    \n    .threshold-line {\n      position: absolute;\n      width: 100%;\n      height: 2px;\n      background-color: #fa5252;\n      z-index: 2;\n      bottom: 75%;\n    }\n    \n    #live-activity {\n      margin-top: 10px;\n      padding: 10px;\n      background-color: #e9ecef;\n      border-radius: 4px;\n      font-family: monospace;\n      font-size: 12px;\n      min-height: 60px;\n      max-height: 120px;\n      overflow-y: auto;\n    }\n    \n    #diagnostics {\n      height: 200px;\n      overflow-y: auto;\n      font-family: monospace;\n      font-size: 12px;\n      background-color: #212529;\n      color: #f8f9fa;\n      padding: 10px;\n      border-radius: 4px;\n      white-space: pre-wrap;\n    }\n    \n    #feature-view {\n      height: 150px;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      margin: 10px 0;\n      position: relative;\n      background-color: #f8f9fa;\n      overflow: hidden;\n    }\n    \n    .feature-bar {\n      position: absolute;\n      bottom: 0;\n      width: 2px;\n      background-color: #4c6ef5;\n    }\n    \n    .template-feature {\n      background-color: #fd7e14;\n    }\n    \n    .calibration-feature {\n      background-color: #20c997;\n    }\n    \n    .detection-feature {\n      background-color: #ff6b6b;\n    }\n    \n    .section-highlight {\n      background-color: rgba(76, 110, 245, 0.1);\n      border-left: 2px solid rgba(76, 110, 245, 0.7);\n      padding: 10px;\n      margin: 10px 0;\n    }\n    \n    .flex-container {\n      display: flex;\n      gap: 10px;\n    }\n    \n    .flex-item {\n      flex: 1;\n    }\n    \n    .sample-section {\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n      padding: 10px;\n      margin: 5px 0;\n      cursor: pointer;\n      transition: background-color 0.2s;\n    }\n    \n    .sample-section:hover {\n      background-color: #e7f5ff;\n    }\n    \n    .sample-selected {\n      background-color: #e7f5ff;\n      border-color: #4c6ef5;\n    }\n    \n    .comparison-container {\n      margin-top: 15px;\n      padding: 10px;\n      background-color: #f8f9fa;\n      border: 1px solid #dee2e6;\n      border-radius: 4px;\n    }\n    \n    .comparison-row {\n      display: flex;\n      margin-bottom: 10px;\n    }\n    \n    .comparison-label {\n      width: 100px;\n      font-weight: bold;\n    }\n    \n    .comparison-tokens {\n      display: flex;\n      flex-wrap: wrap;\n      flex-grow: 1;\n    }\n    \n    .mini-token {\n      display: inline-flex;\n      align-items: center;\n      justify-content: center;\n      width: 30px;\n      height: 30px;\n      margin: 2px;\n      border-radius: 3px;\n      font-weight: bold;\n      font-size: 12px;\n    }\n  </style>\n</head>\n<body>\n  <h1>Thikr Counter - Simplified</h1>\n  \n  <div class=\"panel\">\n    <h2>1. Record Audio & Select Template</h2>\n    <div class=\"control-group\">\n      <button id=\"record-btn\">Record Audio</button>\n      <button id=\"stop-btn\" disabled>Stop Recording</button>\n      <button id=\"play-btn\" disabled>Play Audio</button>\n      <button id=\"reset-btn\">Reset</button>\n    </div>\n    \n    <div id=\"waveform-display\">\n      <canvas id=\"waveform-canvas\" class=\"waveform-canvas\"></canvas>\n      <div id=\"selection-marker\" class=\"selection-marker\" style=\"display: none;\"></div>\n      <div id=\"time-marker\" class=\"time-marker\" style=\"display: none;\"></div>\n    </div>\n    \n    <div id=\"time-display\">0:00 / 0:00</div>\n    \n    <div class=\"selection-controls\">\n      <button id=\"select-start-btn\" disabled>Set Start</button>\n      <input type=\"number\" id=\"start-time\" min=\"0\" step=\"0.1\" value=\"0\" disabled>\n      <button id=\"select-end-btn\" disabled>Set End</button>\n      <input type=\"number\" id=\"end-time\" min=\"0\" step=\"0.1\" value=\"0\" disabled>\n      <button id=\"extract-btn\" disabled>Extract Template</button>\n    </div>\n    \n    <div id=\"section-list\"></div>\n  </div>\n  \n  <div id=\"token-container\" class=\"panel\" style=\"display: none;\">\n    <h2>2. Token Visualization</h2>\n    \n    <div id=\"legend\">\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #4dabf7;\"></div>\n        <span>A: Energy Rise (vowel onset)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #f783ac;\"></div>\n        <span>B: Energy Fall (syllable end)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #8ce99a;\"></div>\n        <span>C: High Frequency (consonants)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #ffd43b;\"></div>\n        <span>D: Low Frequency (low vowels)</span>\n      </div>\n      <div class=\"legend-item\">\n        <div class=\"legend-color\" style=\"background-color: #a5d8ff;\"></div>\n        <span>E: Transition</span>\n      </div>\n    </div>\n    \n    <div id=\"token-sequence\"></div>\n    \n    <h3>Feature Analysis</h3>\n    <div class=\"flex-container\">\n      <div class=\"flex-item\">\n        <select id=\"feature-select\">\n          <option value=\"energy\">Energy (RMS)</option>\n          <option value=\"spectral\">Spectral Centroid</option>\n          <option value=\"zcr\">Zero Crossing Rate</option>\n        </select>\n        <div id=\"feature-view\"></div>\n      </div>\n    </div>\n    \n    <div class=\"comparison-container\" id=\"comparison-container\" style=\"display: none;\">\n      <h3>Pattern Comparison</h3>\n      <div id=\"comparison-content\"></div>\n    </div>\n    \n    <div class=\"section-highlight\">\n      <div>Template section: <span id=\"template-time\">0:00 - 0:00</span></div>\n      <div>Tokens identified: <span id=\"token-count\">0</span></div>\n      <div id=\"calibration-info\"></div>\n      <button id=\"calibrate-btn\" disabled>Calibrate & Analyze</button>\n    </div>\n  </div>\n  \n  <div class=\"panel\">\n    <h2>3. Pattern Detection</h2>\n    \n    <div id=\"counter\">0</div>\n    \n    <div class=\"control-group\">\n      <button id=\"start-analysis-btn\" disabled>Start Analysis</button>\n      <button id=\"stop-analysis-btn\" disabled>Stop Analysis</button>\n    </div>\n    \n    <div id=\"analysis-display\">\n      <div class=\"threshold-line\"></div>\n      <div class=\"progress-bar\"></div>\n    </div>\n    \n    <h3>Activity Log</h3>\n    <div id=\"live-activity\">Waiting to start...</div>\n  </div>\n  \n  <div class=\"panel\">\n    <h3>Diagnostics</h3>\n    <div id=\"diagnostics\"></div>\n  </div>\n\n  <script>\n    // Global variables\n    let audioContext;\n    let audioBuffer = null;\n    let audioSource = null;\n    let recorder = null;\n    let recordedChunks = [];\n    let isRecording = false;\n    let isPlaying = false;\n    let meydaAnalyzer = null;\n    let isAnalyzing = false;\n    \n    // Canvas for waveform visualization\n    let canvas;\n    let canvasCtx;\n    \n    // Audio visualization\n    let currentTime = 0;\n    let startTime = 0;\n    let endTime = 0;\n    \n    // Pattern recognition\n    const tokenTypes = ['A', 'B', 'C', 'D', 'E'];\n    const tokenColors = {\n      'A': '#4dabf7', // Blue - Energy rise\n      'B': '#f783ac', // Pink - Energy fall\n      'C': '#8ce99a', // Green - Spectral high\n      'D': '#ffd43b', // Yellow - Spectral low\n      'E': '#a5d8ff'  // Light blue - Background\n    };\n    \n    // Audio processing\n    const frameSize = 2048;\n    const hopSize = 1024;\n    \n    // Template and sections\n    let templateSection = null;\n    let calibrationSections = [];\n    let templateTokens = [];\n    let detectionCount = 0;\n    let matchThreshold = 0.75;\n    \n    // Runtime variables\n    let animationId = null;\n    let liveTokenBuffer = [];\n    let lastTokenTime = 0;\n    let lastDetectionTime = 0;\n    let selectedFeature = 'energy';\n    let audioFeatures = [];\n    let prevFrames = [];\n    \n    // DOM Elements\n    const recordBtn = document.getElementById('record-btn');\n    const stopBtn = document.getElementById('stop-btn');\n    const playBtn = document.getElementById('play-btn');\n    const resetBtn = document.getElementById('reset-btn');\n    const selectStartBtn = document.getElementById('select-start-btn');\n    const selectEndBtn = document.getElementById('select-end-btn');\n    const startTimeInput = document.getElementById('start-time');\n    const endTimeInput = document.getElementById('end-time');\n    const extractBtn = document.getElementById('extract-btn');\n    const waveformCanvas = document.getElementById('waveform-canvas');\n    const selectionMarker = document.getElementById('selection-marker');\n    const timeMarker = document.getElementById('time-marker');\n    const timeDisplay = document.getElementById('time-display');\n    const sectionList = document.getElementById('section-list');\n    const tokenContainer = document.getElementById('token-container');\n    const tokenSequence = document.getElementById('token-sequence');\n    const templateTime = document.getElementById('template-time');\n    const tokenCount = document.getElementById('token-count');\n    const calibrationInfo = document.getElementById('calibration-info');\n    const calibrateBtn = document.getElementById('calibrate-btn');\n    const featureSelect = document.getElementById('feature-select');\n    const featureView = document.getElementById('feature-view');\n    const comparisonContainer = document.getElementById('comparison-container');\n    const comparisonContent = document.getElementById('comparison-content');\n    const startAnalysisBtn = document.getElementById('start-analysis-btn');\n    const stopAnalysisBtn = document.getElementById('stop-analysis-btn');\n    const progressBar = document.querySelector('.progress-bar');\n    const thresholdLine = document.querySelector('.threshold-line');\n    const liveActivity = document.getElementById('live-activity');\n    const diagnostics = document.getElementById('diagnostics');\n    const counterDisplay = document.getElementById('counter');\n    \n    // Initialize the application\n    function init() {\n      // Set up canvas context\n      canvas = waveformCanvas;\n      canvasCtx = canvas.getContext('2d');\n      \n      // Initialize audio context\n      audioContext = new (window.AudioContext || window.webkitAudioContext)();\n      \n      // Set up event listeners\n      recordBtn.addEventListener('click', startRecording);\n      stopBtn.addEventListener('click', stopRecording);\n      playBtn.addEventListener('click', togglePlayback);\n      resetBtn.addEventListener('click', resetApp);\n      selectStartBtn.addEventListener('click', setSelectionStart);\n      selectEndBtn.addEventListener('click', setSelectionEnd);\n      extractBtn.addEventListener('click', extractTemplate);\n      calibrateBtn.addEventListener('click', calibrateAndAnalyze);\n      startAnalysisBtn.addEventListener('click', startAnalysis);\n      stopAnalysisBtn.addEventListener('click', stopAnalysis);\n      \n      // Feature selection change\n      featureSelect.addEventListener('change', function() {\n        selectedFeature = this.value;\n        updateFeatureVisualization();\n      });\n      \n      // Waveform canvas interactions\n      waveformCanvas.addEventListener('click', function(e) {\n        if (!audioBuffer) return;\n        \n        const rect = this.getBoundingClientRect();\n        const x = e.clientX - rect.left;\n        const percentage = x / rect.width;\n        const time = percentage * audioBuffer.duration;\n        \n        // Update time marker\n        updateTimeMarker(time);\n        \n        // If we're in playback, seek to this time\n        if (isPlaying) {\n          seekToTime(time);\n        }\n      });\n      \n      // Time inputs change\n      startTimeInput.addEventListener('change', updateSelectionMarker);\n      endTimeInput.addEventListener('change', updateSelectionMarker);\n      \n      // Set threshold line\n      updateThresholdLine();\n      \n      log('App initialized. Click \"Record Audio\" to begin.');\n    }\n    \n    // Start recording\n    async function startRecording() {\n      if (isRecording) return;\n      \n      try {\n        // Reset previous audio\n        resetAudio();\n        \n        // Get user media and set up recorder\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        recorder = new MediaRecorder(stream);\n        \n        // Prepare for recording\n        recordedChunks = [];\n        isRecording = true;\n        \n        // Update UI\n        recordBtn.disabled = true;\n        stopBtn.disabled = false;\n        \n        // Handle data available\n        recorder.ondataavailable = function(e) {\n          recordedChunks.push(e.data);\n        };\n        \n        // Handle recording stop\n        recorder.onstop = async function() {\n          isRecording = false;\n          \n          // Create audio blob and load it\n          const blob = new Blob(recordedChunks, { type: 'audio/webm' });\n          await loadAudioFromBlob(blob);\n          \n          // Clean up stream\n          stream.getTracks().forEach(track => track.stop());\n        };\n        \n        // Start recording\n        recorder.start();\n        log('Recording started...');\n        \n      } catch (err) {\n        console.error('Microphone error:', err);\n        log('Error: ' + err.message);\n      }\n    }\n    \n    // Stop recording\n    function stopRecording() {\n      if (recorder && isRecording) {\n        recorder.stop();\n        \n        // Update UI\n        recordBtn.disabled = false;\n        stopBtn.disabled = true;\n        \n        log('Recording stopped.');\n      }\n    }\n    \n    // Load audio from blob\n    async function loadAudioFromBlob(blob) {\n      try {\n        // Create URL for the blob\n        const url = URL.createObjectURL(blob);\n        \n        // Load audio file\n        const response = await fetch(url);\n        const arrayBuffer = await response.arrayBuffer();\n        \n        // Decode audio\n        audioBuffer = await audioContext.decodeAudioData(arrayBuffer);\n        \n        // Extract features for visualization\n        audioFeatures = await extractFeatures(audioBuffer);\n        \n        // Enable controls\n        playBtn.disabled = false;\n        selectStartBtn.disabled = false;\n        selectEndBtn.disabled = false;\n        startTimeInput.disabled = false;\n        endTimeInput.disabled = false;\n        \n        // Update UI\n        endTimeInput.value = audioBuffer.duration.toFixed(1);\n        endTimeInput.max = audioBuffer.duration;\n        startTimeInput.max = audioBuffer.duration;\n        \n        // Draw waveform\n        drawWaveform();\n        \n        log(`Audio loaded: ${audioBuffer.duration.toFixed(2)} seconds`);\n        \n      } catch (err) {\n        console.error('Error loading audio:', err);\n        log('Error loading audio: ' + err.message);\n      }\n    }\n    \n    // Toggle audio playback\n    function togglePlayback() {\n      if (!audioBuffer) return;\n      \n      if (isPlaying) {\n        // Stop playback\n        if (audioSource) {\n          audioSource.stop();\n          audioSource = null;\n        }\n        isPlaying = false;\n        \n        // Update UI\n        playBtn.textContent = 'Play Audio';\n        \n        // Stop animation\n        cancelAnimationFrame(animationId);\n        \n      } else {\n        // Start playback\n        startPlayback();\n        \n        // Update UI\n        playBtn.textContent = 'Pause';\n      }\n    }\n    \n    // Start audio playback\n    function startPlayback(startPosition = 0) {\n      if (!audioBuffer) return;\n      \n      // Create source and start playback\n      audioSource = audioContext.createBufferSource();\n      audioSource.buffer = audioBuffer;\n      audioSource.connect(audioContext.destination);\n      \n      // Create start time based on selection\n      const playbackStart = Math.max(0, startPosition);\n      \n      // Start playback\n      audioSource.start(0, playbackStart);\n      isPlaying = true;\n      \n      // Store start time for progress tracking\n      currentTime = playbackStart;\n      \n      // Animate playback progress\n      function updatePlaybackTime() {\n        if (!isPlaying) return;\n        \n        // Calculate current time\n        const elapsed = (audioContext.currentTime - audioSource.startTime) + playbackStart;\n        currentTime = Math.min(elapsed, audioBuffer.duration);\n        \n        // Update time marker\n        updateTimeMarker(currentTime);\n        \n        // Check if playback has reached the end\n        if (currentTime >= audioBuffer.duration) {\n          isPlaying = false;\n          playBtn.textContent = 'Play Audio';\n          return;\n        }\n        \n        // Continue animation\n        animationId = requestAnimationFrame(updatePlaybackTime);\n      }\n      \n      // Start animation\n      animationId = requestAnimationFrame(updatePlaybackTime);\n      \n      // Handle playback end\n      audioSource.onended = function() {\n        isPlaying = false;\n        playBtn.textContent = 'Play Audio';\n        cancelAnimationFrame(animationId);\n      };\n    }\n    \n    // Seek to specific time\n    function seekToTime(time) {\n      if (!audioBuffer) return;\n      \n      // Stop current playback\n      if (audioSource) {\n        audioSource.stop();\n      }\n      \n      // Start new playback from the specified time\n      startPlayback(time);\n    }\n    \n    // Set selection start time\n    function setSelectionStart() {\n      if (!audioBuffer) return;\n      \n      startTime = currentTime;\n      startTimeInput.value = startTime.toFixed(1);\n      \n      // Update selection\n      updateSelectionMarker();\n      \n      // Check if we can extract a template\n      checkExtractReady();\n      \n      log(`Selection start set to ${startTime.toFixed(2)}s`);\n    }\n    \n    // Set selection end time\n    function setSelectionEnd() {\n      if (!audioBuffer) return;\n      \n      endTime = currentTime;\n      endTimeInput.value = endTime.toFixed(1);\n      \n      // Update selection\n      updateSelectionMarker();\n      \n      // Check if we can extract a template\n      checkExtractReady();\n      \n      log(`Selection end set to ${endTime.toFixed(2)}s`);\n    }\n    \n    // Check if template can be extracted\n    function checkExtractReady() {\n      if (startTime >= 0 && endTime > startTime) {\n        extractBtn.disabled = false;\n      } else {\n        extractBtn.disabled = true;\n      }\n    }\n    \n    // Update selection marker\n    function updateSelectionMarker() {\n      // Get values from inputs (allows manual entry)\n      startTime = parseFloat(startTimeInput.value);\n      endTime = parseFloat(endTimeInput.value);\n      \n      // Validate values\n      if (isNaN(startTime)) startTime = 0;\n      if (isNaN(endTime)) endTime = audioBuffer ? audioBuffer.duration : 0;\n      \n      // Make sure start comes before end\n      if (startTime > endTime) {\n        const temp = startTime;\n        startTime = endTime;\n        endTime = temp;\n        \n        // Update inputs\n        startTimeInput.value = startTime.toFixed(1);\n        endTimeInput.value = endTime.toFixed(1);\n      }\n      \n      // Update marker position\n      if (audioBuffer) {\n        const width = canvas.width;\n        const startPx = (startTime / audioBuffer.duration) * width;\n        const endPx = (endTime / audioBuffer.duration) * width;\n        \n        selectionMarker.style.left = startPx + 'px';\n        selectionMarker.style.width = (endPx - startPx) + 'px';\n        selectionMarker.style.display = 'block';\n        \n        // Check if we can extract a template\n        checkExtractReady();\n      }\n    }\n    \n    // Update time marker\n    function updateTimeMarker(time) {\n      if (!audioBuffer) return;\n      \n      // Update current time\n      currentTime = time;\n      \n      // Update time display\n      const duration = audioBuffer.duration;\n      timeDisplay.textContent = `${formatTime(currentTime)} / ${formatTime(duration)}`;\n      \n      // Position marker\n      const width = canvas.width;\n      const position = (currentTime / duration) * width;\n      \n      timeMarker.style.left = position + 'px';\n      timeMarker.style.display = 'block';\n    }\n    \n    // Format time as mm:ss\n    function formatTime(seconds) {\n      const mins = Math.floor(seconds / 60);\n      const secs = Math.floor(seconds % 60);\n      return `${mins}:${secs.toString().padStart(2, '0')}`;\n    }\n    \n    // Extract template from selection\n    async function extractTemplate() {\n      if (!audioBuffer || startTime >= endTime) {\n        log('Invalid selection');\n        return;\n      }\n      \n      try {\n        // Create template section\n        templateSection = {\n          id: 'template',\n          start: startTime,\n          end: endTime,\n          tokens: [],\n          features: []\n        };\n        \n        // Extract selected audio\n        const sectionBuffer = extractAudioSection(audioBuffer, startTime, endTime);\n        \n        // Extract features for visualization\n        const features = await extractFeatures(sectionBuffer);\n        \n        // Extract tokens\n        const tokens = await extractTokens(sectionBuffer);\n        \n        // Update template section\n        templateSection.tokens = tokens;\n        templateSection.features = features;\n        \n        // Update UI\n        templateTime.textContent = `${startTime.toFixed(1)}s - ${endTime.toFixed(1)}s`;\n        tokenCount.textContent = tokens.length;\n        \n        // Display tokens\n        displayTokens(tokens);\n        \n        // Show token container\n        tokenContainer.style.display = 'block';\n        \n        // Update feature visualization\n        updateFeatureVisualization();\n        \n        // Add to section list\n        addSectionToList(templateSection, true);\n        \n        log(`Template extracted: ${tokens.length} tokens from ${startTime.toFixed(2)}s - ${endTime.toFixed(2)}s`);\n        \n      } catch (err) {\n        console.error('Error extracting template:', err);\n        log('Error: ' + err.message);\n      }\n    }\n    \n    // Add section to the list\n    function addSectionToList(section, isTemplate = false) {\n      // Create section element\n      const sectionEl = document.createElement('div');\n      sectionEl.className = 'sample-section';\n      sectionEl.dataset.id = section.id;\n      \n      if (isTemplate) {\n        sectionEl.classList.add('sample-selected');\n        sectionEl.innerHTML = `\n          <strong>Template:</strong> ${section.start.toFixed(1)}s - ${section.end.toFixed(1)}s \n          (${section.tokens.length} tokens)\n        `;\n      } else {\n        sectionEl.innerHTML = `\n          <strong>Calibration ${calibrationSections.length}:</strong> ${section.start.toFixed(1)}s - ${section.end.toFixed(1)}s\n          (${section.tokens.length} tokens)\n        `;\n        \n        // Add similarity if available\n        if (section.similarity !== undefined) {\n          sectionEl.innerHTML += ` - Similarity: ${(section.similarity * 100).toFixed(0)}%`;\n        }\n        \n        // Add to calibration sections\n        calibrationSections.push(section);\n        \n        // Enable calibration button\n        calibrateBtn.disabled = false;\n      }\n      \n      // Add play button\n      const playBtn = document.createElement('button');\n      playBtn.textContent = 'Play';\n      playBtn.addEventListener('click', function(e) {\n        e.stopPropagation();\n        \n        // Stop current playback\n        if (isPlaying && audioSource) {\n          audioSource.stop();\n        }\n        \n        // Start playback from section start\n        startPlayback(section.start);\n      });\n      \n      sectionEl.appendChild(playBtn);\n      \n      // Section click selects the section\n      sectionEl.addEventListener('click', function() {\n        if (!isTemplate) {\n          // Select this calibration section\n          document.querySelectorAll('.sample-section').forEach(el => {\n            if (el.dataset.id !== 'template') {\n              el.classList.remove('sample-selected');\n            }\n          });\n          \n          sectionEl.classList.add('sample-selected');\n          \n          // Update feature visualization with comparison\n          updateFeatureVisualization(section);\n        }\n      });\n      \n      // Add to section list\n      sectionList.appendChild(sectionEl);\n    }\n    \n    // Extract audio section\n    function extractAudioSection(buffer, start, end) {\n      // Calculate samples\n      const startSample = Math.floor(start * buffer.sampleRate);\n      const endSample = Math.floor(end * buffer.sampleRate);\n      const length = endSample - startSample;\n      \n      // Create new buffer\n      const sectionBuffer = audioContext.createBuffer(\n        buffer.numberOfChannels,\n        length,\n        buffer.sampleRate\n      );\n      \n      // Copy audio data\n      for (let channel = 0; channel < buffer.numberOfChannels; channel++) {\n        const channelData = buffer.getChannelData(channel);\n        const sectionData = sectionBuffer.getChannelData(channel);\n        \n        for (let i = 0; i < length; i++) {\n          sectionData[i] = channelData[startSample + i];\n        }\n      }\n      \n      return sectionBuffer;\n    }\n    \n    // Extract features from audio buffer\n    async function extractFeatures(buffer) {\n      return new Promise((resolve) => {\n        const features = [];\n        \n        try {\n          // Create offline context\n          const offlineCtx = new OfflineAudioContext(\n            buffer.numberOfChannels,\n            buffer.length,\n            buffer.sampleRate\n          );\n          \n          // Create source\n          const source = offlineCtx.createBufferSource();\n          source.buffer = buffer;\n          \n          // Create analyzer\n          const analyzer = Meyda.createMeydaAnalyzer({\n            audioContext: offlineCtx,\n            source: source,\n            bufferSize: frameSize,\n            hopSize: hopSize,\n            featureExtractors: ['rms', 'spectralCentroid', 'zcr'],\n            callback: (data) => {\n              features.push({\n                time: features.length * (hopSize / buffer.sampleRate),\n                rms: data.rms,\n                spectralCentroid: data.spectralCentroid,\n                zcr: data.zcr\n              });\n            }\n          });\n          \n          // Start analysis\n          analyzer.start();\n          source.connect(offlineCtx.destination);\n          source.start();\n          \n          // Complete rendering\n          offlineCtx.startRendering().then(() => {\n            log(`Extracted ${features.length} features`);\n            resolve(features);\n          }).catch(err => {\n            console.error('Feature extraction error:', err);\n            resolve([]);\n          });\n        } catch (err) {\n          console.error('Error setting up feature extraction:', err);\n          resolve([]);\n        }\n      });\n    }\n    \n    // Extract tokens from audio buffer\n    async function extractTokens(buffer) {\n      // Get features\n      const features = await extractFeatures(buffer);\n      \n      // Find key points in audio\n      const tokens = [];\n      \n      for (let i = 2; i < features.length - 2; i++) {\n        const prevFeature = features[i-1];\n        const feature = features[i];\n        const nextFeature = features[i+1];\n        \n        // Skip low energy frames\n        if (feature.rms < 0.01) continue;\n        \n        // Check if this is a significant point\n        if (isSignificantPoint(feature, prevFeature, nextFeature)) {\n          // Determine token type\n          const type = determineTokenType(feature, prevFeature);\n          \n          // Add token\n          tokens.push({\n            type: type,\n            time: feature.time,\n            rms: feature.rms,\n            spectralCentroid: feature.spectralCentroid,\n            zcr: feature.zcr\n          });\n        }\n      }\n      \n      // If not enough tokens were found, add some based on energy peaks\n      if (tokens.length < 5) {\n        // Sort features by energy\n        const sortedFeatures = [...features].sort((a, b) => b.rms - a.rms);\n        \n        // Take top 10 energy peaks\n        const topFeatures = sortedFeatures.slice(0, 10);\n        \n        for (const feature of topFeatures) {\n          if (!tokens.some(t => Math.abs(t.time - feature.time) < 0.05)) {\n            // Determine type based on spectral content\n            let type;\n            if (feature.spectralCentroid > 5000) {\n              type = 'C'; // High frequency\n            } else if (feature.spectralCentroid < 2000) {\n              type = 'D'; // Low frequency\n            } else if (feature.rms > 0.1) {\n              type = 'A'; // Energy rise\n            } else {\n              type = 'E'; // Default\n            }\n            \n            // Add token\n            tokens.push({\n              type: type,\n              time: feature.time,\n              rms: feature.rms,\n              spectralCentroid: feature.spectralCentroid,\n              zcr: feature.zcr\n            });\n          }\n        }\n      }\n      \n      // Sort by time\n      return tokens.sort((a, b) => a.time - b.time);\n    }\n    \n    // Check if a point is significant\n    function isSignificantPoint(feature, prevFeature, nextFeature) {\n      // Energy peak (local maximum)\n      const isEnergyPeak = feature.rms > prevFeature.rms && \n                           feature.rms > nextFeature.rms && \n                           feature.rms > 0.02;\n      \n      // Spectral centroid peak (local maximum - bright sounds)\n      const isSpectralPeak = feature.spectralCentroid > prevFeature.spectralCentroid && \n                             feature.spectralCentroid > nextFeature.spectralCentroid &&\n                             feature.spectralCentroid > 3000;\n      \n      // Zero crossing rate peak (consonant sounds)\n      const isZcrPeak = feature.zcr > prevFeature.zcr && \n                        feature.zcr > nextFeature.zcr && \n                        feature.zcr > 0.3;\n      \n      // Sharp energy change\n      const isEnergyChange = Math.abs(feature.rms - prevFeature.rms) > 0.03;\n      \n      return isEnergyPeak || isSpectralPeak || isZcrPeak || isEnergyChange;\n    }\n    \n    // Determine token type\n    function determineTokenType(feature, prevFeature) {\n      // Energy rising\n      if (feature.rms > prevFeature.rms * 1.2 && feature.rms > 0.02) {\n        return 'A';\n      }\n      \n      // Energy falling\n      if (feature.rms < prevFeature.rms * 0.8 && prevFeature.rms > 0.02) {\n        return 'B';\n      }\n      \n      // High spectral content\n      if (feature.spectralCentroid > 5000 && feature.rms > 0.02) {\n        return 'C';\n      }\n      \n      // Low spectral content\n      if (feature.spectralCentroid < 2000 && feature.rms > 0.02) {\n        return 'D';\n      }\n      \n      // Default type\n      return 'E';\n    }\n    \n    // Display tokens\n    function displayTokens(tokens) {\n      // Clear token display\n      tokenSequence.innerHTML = '';\n      \n      // Display each token\n      tokens.forEach((token, index) => {\n        const tokenEl = document.createElement('div');\n        tokenEl.className = 'token';\n        tokenEl.style.backgroundColor = tokenColors[token.type];\n        \n        // Use letter index\n        const letter = index < 26 ? String.fromCharCode(65 + index) : (index - 25);\n        tokenEl.textContent = letter;\n        \n        // Add tooltip\n        tokenEl.title = `Token ${token.type} - RMS: ${token.rms.toFixed(3)}, Centroid: ${(token.spectralCentroid/1000).toFixed(1)}kHz`;\n        \n        // Add token type label\n        const labelEl = document.createElement('div');\n        labelEl.className = 'token-label';\n        labelEl.textContent = token.type;\n        tokenEl.appendChild(labelEl);\n        \n        tokenSequence.appendChild(tokenEl);\n      });\n    }\n    \n    // Update feature visualization\n    function updateFeatureVisualization(comparisonSection = null) {\n      // Clear previous visualization\n      featureView.innerHTML = '';\n      \n      // Check if we have template features\n      if (!templateSection || !templateSection.features || !templateSection.features.length) {\n        featureView.innerHTML = '<div style=\"text-align:center;padding:20px;\">No template features available</div>';\n        return;\n      }\n      \n      // Get template features\n      const templateFeatures = templateSection.features;\n      \n      // Get comparison features if available\n      let comparisonFeatures = null;\n      if (comparisonSection && comparisonSection.features) {\n        comparisonFeatures = comparisonSection.features;\n      }\n      \n      // Get feature accessor based on selection\n      const getFeatureValue = (feature) => {\n        switch (selectedFeature) {\n          case 'energy': return feature.rms;\n          case 'spectral': return feature.spectralCentroid / 10000; // Normalize\n          case 'zcr': return feature.zcr;\n          default: return feature.rms;\n        }\n      };\n      \n      // Find max value for scaling\n      const templateMax = Math.max(...templateFeatures.map(getFeatureValue));\n      let comparisonMax = 0;\n      if (comparisonFeatures) {\n        comparisonMax = Math.max(...comparisonFeatures.map(getFeatureValue));\n      }\n      \n      const maxValue = Math.max(templateMax, comparisonMax, 0.001); // Avoid division by zero\n      \n      // Draw template features\n      const templateStep = Math.max(1, Math.floor(templateFeatures.length / 100));\n      for (let i = 0; i < templateFeatures.length; i += templateStep) {\n        const feature = templateFeatures[i];\n        const value = getFeatureValue(feature);\n        \n        const bar = document.createElement('div');\n        bar.className = 'feature-bar template-feature';\n        bar.style.left = `${(i / templateFeatures.length) * 100}%`;\n        bar.style.height = `${(value / maxValue) * 100}%`;\n        \n        // Add token markers\n        const tokenAtTime = templateSection.tokens.find(\n          t => Math.abs(t.time - feature.time) < 0.05\n        );\n        \n        if (tokenAtTime) {\n          bar.style.backgroundColor = tokenColors[tokenAtTime.type];\n          bar.style.width = '3px';\n        }\n        \n        featureView.appendChild(bar);\n      }\n      \n      // Draw comparison features if available\n      if (comparisonFeatures) {\n        const comparisonStep = Math.max(1, Math.floor(comparisonFeatures.length / 100));\n        for (let i = 0; i < comparisonFeatures.length; i += comparisonStep) {\n          const feature = comparisonFeatures[i];\n          const value = getFeatureValue(feature);\n          \n          const bar = document.createElement('div');\n          bar.className = 'feature-bar calibration-feature';\n          bar.style.left = `${(i / comparisonFeatures.length) * 100}%`;\n          bar.style.height = `${(value / maxValue) * 100}%`;\n          bar.style.opacity = '0.6';\n          \n          featureView.appendChild(bar);\n        }\n      }\n    }\n    \n    // Calibrate and analyze\n    async function calibrateAndAnalyze() {\n      if (!templateSection || !templateSection.tokens.length || !calibrationSections.length) {\n        log('Template or calibration sections missing');\n        return;\n      }\n      \n      // Process all calibration sections\n      for (const section of calibrationSections) {\n        // Calculate similarity\n        const similarity = compareTokenSequences(templateSection.tokens, section.tokens);\n        section.similarity = similarity;\n        \n        log(`Calibration section: ${section.start.toFixed(2)}s - ${section.end.toFixed(2)}s, similarity: ${(similarity * 100).toFixed(1)}%`);\n      }\n      \n      // Update section list with similarities\n      updateSectionList();\n      \n      // Create token comparison view\n      createComparisonView();\n      \n      // Calculate threshold based on calibration\n      const similarities = calibrationSections.map(s => s.similarity);\n      const avgSimilarity = similarities.reduce((a, b) => a + b, 0) / similarities.length;\n      const minSimilarity = Math.min(...similarities);\n      \n      // Set threshold slightly below minimum similarity\n      matchThreshold = Math.max(0.5, minSimilarity * 0.95);\n      \n      // Update UI\n      updateThresholdLine();\n      \n      calibrationInfo.innerHTML = `\n        <div>Calibration complete!</div>\n        <div>Average similarity: ${(avgSimilarity * 100).toFixed(1)}%</div>\n        <div>Match threshold: ${(matchThreshold * 100).toFixed(1)}%</div>\n      `;\n      \n      // Enable analysis\n      startAnalysisBtn.disabled = false;\n      \n      log(`Calibration complete. Match threshold set to ${(matchThreshold * 100).toFixed(1)}%`);\n    }\n    \n    // Update section list\n    function updateSectionList() {\n      // Update section entries with similarity\n      calibrationSections.forEach(section => {\n        const sectionEl = document.querySelector(`.sample-section[data-id=\"${section.id}\"]`);\n        if (sectionEl) {\n          const similarity = section.similarity !== undefined ? \n            `Similarity: ${(section.similarity * 100).toFixed(1)}%` : '';\n          \n          sectionEl.innerHTML = `\n            <strong>Calibration:</strong> ${section.start.toFixed(1)}s - ${section.end.toFixed(1)}s\n            (${section.tokens.length} tokens) - ${similarity}\n          `;\n          \n          // Add play button\n          const playBtn = document.createElement('button');\n          playBtn.textContent = 'Play';\n          playBtn.addEventListener('click', function(e) {\n            e.stopPropagation();\n            startPlayback(section.start);\n          });\n          \n          sectionEl.appendChild(playBtn);\n          \n          // Color code by similarity\n          if (section.similarity !== undefined) {\n            if (section.similarity > 0.8) {\n              sectionEl.style.borderLeft = '4px solid #40c057';\n            } else if (section.similarity > 0.6) {\n              sectionEl.style.borderLeft = '4px solid #fab005';\n            } else {\n              sectionEl.style.borderLeft = '4px solid #fa5252';\n            }\n          }\n        }\n      });\n    }\n    \n    // Create comparison view\n    function createComparisonView() {\n      // Show comparison container\n      comparisonContainer.style.display = 'block';\n      \n      // Clear previous content\n      comparisonContent.innerHTML = '';\n      \n      // Create template row\n      const templateRow = document.createElement('div');\n      templateRow.className = 'comparison-row';\n      \n      const templateLabel = document.createElement('div');\n      templateLabel.className = 'comparison-label';\n      templateLabel.textContent = 'Template';\n      \n      const templateTokensContainer = document.createElement('div');\n      templateTokensContainer.className = 'comparison-tokens';\n      \n      // Add template tokens\n      templateSection.tokens.forEach(token => {\n        const tokenEl = document.createElement('div');\n        tokenEl.className = 'mini-token';\n        tokenEl.textContent = token.type;\n        tokenEl.style.backgroundColor = tokenColors[token.type];\n        templateTokensContainer.appendChild(tokenEl);\n      });\n      \n      templateRow.appendChild(templateLabel);\n      templateRow.appendChild(templateTokensContainer);\n      comparisonContent.appendChild(templateRow);\n      \n      // Create row for each calibration section\n      calibrationSections.forEach((section, index) => {\n        const row = document.createElement('div');\n        row.className = 'comparison-row';\n        \n        const label = document.createElement('div');\n        label.className = 'comparison-label';\n        label.textContent = `Region ${index + 1}`;\n        \n        const tokensContainer = document.createElement('div');\n        tokensContainer.className = 'comparison-tokens';\n        \n        // Add calibration tokens\n        section.tokens.forEach(token => {\n          const tokenEl = document.createElement('div');\n          tokenEl.className = 'mini-token';\n          tokenEl.textContent = token.type;\n          tokenEl.style.backgroundColor = tokenColors[token.type];\n          tokensContainer.appendChild(tokenEl);\n        });\n        \n        row.appendChild(label);\n        row.appendChild(tokensContainer);\n        \n        // Add similarity if available\n        if (section.similarity !== undefined) {\n          const similarityLabel = document.createElement('div');\n          similarityLabel.style.marginLeft = '10px';\n          similarityLabel.textContent = `${(section.similarity * 100).toFixed(1)}%`;\n          row.appendChild(similarityLabel);\n        }\n        \n        comparisonContent.appendChild(row);\n      });\n    }\n    \n    // Compare token sequences\n    function compareTokenSequences(template, sequence) {\n      if (!template.length || !sequence.length) return 0;\n      \n      // Sliding window approach to find best match\n      let bestSimilarity = 0;\n      \n      for (let startIdx = 0; startIdx <= sequence.length - Math.min(template.length, 3); startIdx++) {\n        const endIdx = Math.min(startIdx + template.length, sequence.length);\n        const window = sequence.slice(startIdx, endIdx);\n        \n        // Calculate token matches\n        let matches = 0;\n        const minLength = Math.min(template.length, window.length);\n        \n        for (let i = 0; i < minLength; i++) {\n          const templateToken = template[i];\n          const windowToken = window[i];\n          \n          // Type match\n          const typeMatch = templateToken.type === windowToken.type ? 1 : 0;\n          \n          // Energy similarity\n          const energySimilarity = 1 - Math.min(1, Math.abs(templateToken.rms - windowToken.rms) / 0.2);\n          \n          // Combined similarity\n          const tokenSimilarity = typeMatch * 0.7 + energySimilarity * 0.3;\n          \n          matches += tokenSimilarity;\n        }\n        \n        // Normalize by template length\n        const similarity = matches / template.length;\n        \n        if (similarity > bestSimilarity) {\n          bestSimilarity = similarity;\n        }\n      }\n      \n      return bestSimilarity;\n    }\n    \n    // Start real-time analysis\n    async function startAnalysis() {\n      if (!templateSection || !templateSection.tokens.length) {\n        log('Template not available');\n        return;\n      }\n      \n      // Reset state\n      liveTokenBuffer = [];\n      prevFrames = [];\n      lastTokenTime = 0;\n      lastDetectionTime = 0;\n      \n      try {\n        // Access microphone\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        const source = audioContext.createMediaStreamSource(stream);\n        \n        // Create Meyda analyzer\n        meydaAnalyzer = Meyda.createMeydaAnalyzer({\n          audioContext: audioContext,\n          source: source,\n          bufferSize: frameSize,\n          hopSize: hopSize,\n          featureExtractors: ['rms', 'spectralCentroid', 'zcr'],\n          callback: processFrame\n        });\n        \n        meydaAnalyzer.start();\n        isAnalyzing = true;\n        \n        // Update UI\n        startAnalysisBtn.disabled = true;\n        stopAnalysisBtn.disabled = false;\n        \n        log('Analysis started. Recite thikr...');\n        updateLiveActivity('Listening for thikr patterns...');\n        \n      } catch (err) {\n        console.error('Error accessing microphone:', err);\n        log('Error: ' + err.message);\n      }\n    }\n    \n    // Stop real-time analysis\n    function stopAnalysis() {\n      if (meydaAnalyzer) {\n        meydaAnalyzer.stop();\n      }\n      \n      isAnalyzing = false;\n      \n      // Update UI\n      startAnalysisBtn.disabled = false;\n      stopAnalysisBtn.disabled = true;\n      \n      log('Analysis stopped.');\n      updateLiveActivity('Analysis stopped.');\n    }\n    \n    // Process a frame from the analyzer\n    function processFrame(features) {\n      if (!isAnalyzing) return;\n      \n      const currentTime = audioContext.currentTime;\n      \n      // Create frame object\n      const frame = {\n        time: currentTime,\n        rms: features.rms || 0,\n        spectralCentroid: features.spectralCentroid || 0,\n        zcr: features.zcr || 0\n      };\n      \n      // Add to frames buffer\n      prevFrames.push(frame);\n      if (prevFrames.length > 5) {\n        prevFrames.shift();\n      }\n      \n      // Need at least 2 frames to detect features\n      if (prevFrames.length < 2) return;\n      \n      // Get frames for context\n      const prevFrame = prevFrames[prevFrames.length - 2];\n      const currFrame = prevFrames[prevFrames.length - 1];\n      \n      // Check if this is a significant point AND enough time since last token\n      if (isSignificantPoint(currFrame, prevFrame, null) && \n          currentTime - lastTokenTime > 0.05) { // Min 50ms between tokens\n        \n        // Determine token type\n        const tokenType = determineTokenType(currFrame, prevFrame);\n        \n        // Create token\n        const token = {\n          type: tokenType,\n          time: currentTime,\n          rms: currFrame.rms,\n          spectralCentroid: currFrame.spectralCentroid,\n          zcr: currFrame.zcr\n        };\n        \n        // Add to token buffer\n        liveTokenBuffer.push(token);\n        lastTokenTime = currentTime;\n        \n        // Limit buffer size\n        if (liveTokenBuffer.length > Math.max(30, templateSection.tokens.length * 2)) {\n          liveTokenBuffer.shift();\n        }\n        \n        // Log token\n        updateLiveActivity(`Token ${tokenType} detected (${token.rms.toFixed(2)} energy)`);\n        \n        // Check for pattern match\n        if (liveTokenBuffer.length >= Math.min(3, templateSection.tokens.length)) {\n          // Calculate similarity\n          const similarity = compareTokenSequences(templateSection.tokens, liveTokenBuffer);\n          \n          // Update progress bar\n          updateProgressBar(similarity);\n          \n          // Log similarity\n          updateLiveActivity(`Pattern match: ${(similarity * 100).toFixed(1)}% confidence`);\n          \n          // Check for detection\n          if (similarity >= matchThreshold && \n              currentTime - lastDetectionTime > 2.0) { // Cooldown period\n            \n            // Register detection\n            detectionCount++;\n            counterDisplay.textContent = detectionCount;\n            lastDetectionTime = currentTime;\n            \n            // Update UI\n            updateLiveActivity(`THIKR DETECTED (#${detectionCount}) with ${(similarity * 100).toFixed(1)}% confidence!`);\n            \n            log(`THIKR DETECTED (#${detectionCount}) with ${(similarity * 100).toFixed(1)}% confidence`);\n            \n            // Clear token buffer after detection\n            liveTokenBuffer = [];\n          }\n        }\n      }\n    }\n    \n    // Update progress bar\n    function updateProgressBar(confidence) {\n      progressBar.style.height = `${confidence * 100}%`;\n    }\n    \n    // Update threshold line\n    function updateThresholdLine() {\n      thresholdLine.style.bottom = `${matchThreshold * 100}%`;\n    }\n    \n    // Update live activity display\n    function updateLiveActivity(message) {\n      const time = new Date().toLocaleTimeString();\n      const activityMessage = `[${time}] ${message}`;\n      \n      // Add message at top\n      liveActivity.innerHTML = activityMessage + '<br>' + liveActivity.innerHTML;\n      \n      // Limit number of messages\n      const messages = liveActivity.innerHTML.split('<br>');\n      if (messages.length > 10) {\n        liveActivity.innerHTML = messages.slice(0, 10).join('<br>');\n      }\n    }\n    \n    // Draw waveform\n    function drawWaveform() {\n      if (!audioBuffer) return;\n      \n      // Set canvas dimensions\n      canvas.width = canvas.clientWidth;\n      canvas.height = canvas.clientHeight;\n      \n      // Clear canvas\n      canvasCtx.clearRect(0, 0, canvas.width, canvas.height);\n      \n      // Draw background\n      canvasCtx.fillStyle = '#f8f9fa';\n      canvasCtx.fillRect(0, 0, canvas.width, canvas.height);\n      \n      // Get audio data (use first channel)\n      const data = audioBuffer.getChannelData(0);\n      \n      // Draw waveform\n      canvasCtx.strokeStyle = '#4c6ef5';\n      canvasCtx.lineWidth = 1;\n      canvasCtx.beginPath();\n      \n      // Calculate step to avoid drawing too many points\n      const step = Math.ceil(data.length / canvas.width);\n      const amp = canvas.height / 2;\n      \n      for (let i = 0; i < canvas.width; i++) {\n        // Get max value for this pixel\n        let min = 1.0;\n        let max = -1.0;\n        \n        for (let j = 0; j < step; j++) {\n          const datum = data[(i * step) + j];\n          if (datum < min) min = datum;\n          if (datum > max) max = datum;\n        }\n        \n        // Draw line\n        canvasCtx.moveTo(i, (1 + min) * amp);\n        canvasCtx.lineTo(i, (1 + max) * amp);\n      }\n      \n      canvasCtx.stroke();\n      \n      // Draw time markers\n      drawTimeMarkers();\n    }\n    \n    // Draw time markers on waveform\n    function drawTimeMarkers() {\n      if (!audioBuffer) return;\n      \n      const duration = audioBuffer.duration;\n      const width = canvas.width;\n      \n      // Determine appropriate interval (every 1s, 5s, or 10s)\n      let interval = 1;\n      if (duration > 30) interval = 5;\n      if (duration > 60) interval = 10;\n      \n      // Draw markers\n      canvasCtx.fillStyle = '#adb5bd';\n      canvasCtx.font = '10px sans-serif';\n      canvasCtx.textAlign = 'center';\n      \n      for (let i = 0; i <= duration; i += interval) {\n        const x = (i / duration) * width;\n        \n        // Draw marker line\n        canvasCtx.beginPath();\n        canvasCtx.moveTo(x, 0);\n        canvasCtx.lineTo(x, 5);\n        canvasCtx.stroke();\n        \n        // Draw time\n        canvasCtx.fillText(i + 's', x, 15);\n      }\n    }\n    \n    // Reset audio state\n    function resetAudio() {\n      // Stop playback\n      if (isPlaying && audioSource) {\n        audioSource.stop();\n        audioSource = null;\n      }\n      \n      // Clear audio buffer\n      audioBuffer = null;\n      \n      // Reset time\n      currentTime = 0;\n      startTime = 0;\n      endTime = 0;\n      \n      // Clear canvas\n      if (canvas && canvasCtx) {\n        canvasCtx.clearRect(0, 0, canvas.width, canvas.height);\n      }\n      \n      // Reset UI\n      timeDisplay.textContent = '0:00 / 0:00';\n      selectionMarker.style.display = 'none';\n      timeMarker.style.display = 'none';\n      startTimeInput.value = '0';\n      endTimeInput.value = '0';\n      \n      // Disable controls\n      playBtn.disabled = true;\n      selectStartBtn.disabled = true;\n      selectEndBtn.disabled = true;\n      startTimeInput.disabled = true;\n      endTimeInput.disabled = true;\n      extractBtn.disabled = true;\n    }\n    \n    // Reset app\n    function resetApp() {\n      // Reset audio\n      resetAudio();\n      \n      // Stop analysis\n      if (isAnalyzing) {\n        stopAnalysis();\n      }\n      \n      // Reset template and sections\n      templateSection = null;\n      calibrationSections = [];\n      templateTokens = [];\n      \n      // Reset detection\n      detectionCount = 0;\n      counterDisplay.textContent = '0';\n      \n      // Clear UI\n      tokenSequence.innerHTML = '';\n      sectionList.innerHTML = '';\n      featureView.innerHTML = '';\n      comparisonContent.innerHTML = '';\n      \n      // Hide panels\n      tokenContainer.style.display = 'none';\n      comparisonContainer.style.display = 'none';\n      \n      // Reset UI state\n      calibrateBtn.disabled = true;\n      startAnalysisBtn.disabled = true;\n      progressBar.style.height = '0%';\n      \n      // Clear info\n      calibrationInfo.innerHTML = '';\n      liveActivity.innerHTML = 'Waiting to start...';\n      \n      log('App reset');\n    }\n    \n    // Utility: Log to diagnostics\n    function log(message) {\n      const time = new Date().toLocaleTimeString();\n      diagnostics.innerHTML += `[${time}] ${message}\\n`;\n      diagnostics.scrollTop = diagnostics.scrollHeight;\n      console.log(message);\n    }\n    \n    // Initialize on page load\n    window.addEventListener('load', init);\n  </script>\n</body>\n</html>",
      "created_at": "2025-03-23T17:45:01.901000",
      "sequence_order": 23,
      "parent_id": "36ca42fe-fd4a-443d-bb5d-861f012acd87",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "5ccc8405-9251-424a-9127-87f511709782",
      "role": "tool",
      "content": "",
      "created_at": "2025-03-23T17:45:17.605722",
      "sequence_order": 24,
      "parent_id": "51dcfbea-bc44-4f52-be47-6b71493a1af5",
      "metadata": {
        "status": "finished_successfully",
        "weight": 0,
        "end_turn": null
      }
    },
    {
      "id": "577fa13c-82dc-44a0-9d5f-6fdd3cf540af",
      "role": "assistant",
      "content": "That error happens because your **`updatePlaybackTime()`** function is trying to read **`audioSource.startTime`** (or some other property on a null/undefined `audioSource`) even after `audioSource` has been set to null (for example, when you stop or reset the app). \n\nIn short:\n- **Some browsers don’t populate `audioSource.startTime`** automatically. If you rely on it, you may get `undefined`.  \n- **Even if you store it yourself, once `audioSource` is `null`, referencing `audioSource.startTime` will throw.**  \n\nBelow are two common ways to fix it.\n\n---\n\n## 1) **Store Your Own Start Time** & Guard in `updatePlaybackTime()`\n\n### **(A) Store a custom property** in `startPlayback()`\n\nRight now, your code does something like:\n```js\naudioSource.start(0, playbackStart);\n// ...\nfunction updatePlaybackTime() {\n  const elapsed = (audioContext.currentTime - audioSource.startTime) + playbackStart;\n  // ...\n}\n```\nBut `audioSource.startTime` isn’t standard in all browsers. Instead, **create a custom property**. For example:\n```js\nfunction startPlayback(startPosition = 0) {\n  if (!audioBuffer) return;\n  \n  audioSource = audioContext.createBufferSource();\n  audioSource.buffer = audioBuffer;\n  audioSource.connect(audioContext.destination);\n  \n  const playbackStart = Math.max(0, startPosition);\n\n  // 1) Store your own property for the start time\n  audioSource._startTime = audioContext.currentTime;\n  audioSource._offset = playbackStart; // store offset if needed\n  \n  audioSource.start(0, playbackStart);\n  isPlaying = true;\n\n  function updatePlaybackTime() {\n    // 2) Guard if audioSource is null or we aren’t playing\n    if (!isPlaying || !audioSource) return;\n\n    // 3) Use your custom property\n    const elapsed = (audioContext.currentTime - audioSource._startTime) + audioSource._offset;\n    currentTime = Math.min(elapsed, audioBuffer.duration);\n\n    if (currentTime >= audioBuffer.duration) {\n      isPlaying = false;\n      // ...\n    }\n    animationId = requestAnimationFrame(updatePlaybackTime);\n  }\n  animationId = requestAnimationFrame(updatePlaybackTime);\n\n  // 4) On ended\n  audioSource.onended = () => {\n    isPlaying = false;\n    cancelAnimationFrame(animationId);\n  };\n}\n```\n\n### **(B) Cancel the animation** and null checks\n\nIf you call **`resetApp()`** or **stop** the audio, you likely do:\n```js\nif (audioSource) {\n  audioSource.stop();\n  audioSource = null;\n}\nisPlaying = false;\n```\nBut `requestAnimationFrame(updatePlaybackTime)` might still be running. So also call:\n```js\ncancelAnimationFrame(animationId);\n```\nand in `updatePlaybackTime()`, always do:\n```js\nif (!isPlaying || !audioSource) return;\n```\nThis prevents the function from trying to read `.startTime` (or `_startTime`) on a null object.\n\n---\n\n## 2) **Simply Use `audioContext.currentTime`** Instead of `audioSource.startTime`\n\nAn even simpler approach is to **store a global “playbackStartTime”** in your code. For instance:\n\n```js\nlet playbackStartTime = 0;\nfunction startPlayback(startPosition = 0) {\n  audioSource = audioContext.createBufferSource();\n  audioSource.buffer = audioBuffer;\n  audioSource.connect(audioContext.destination);\n\n  playbackStartTime = audioContext.currentTime;\n  audioSource.start(0, startPosition);\n\n  // Now in updatePlaybackTime, use playbackStartTime\n  function updatePlaybackTime() {\n    if (!isPlaying || !audioSource) return;\n    const elapsed = audioContext.currentTime - playbackStartTime + startPosition;\n    // ...\n  }\n}\n```\n\nThat way, you never rely on `audioSource.startTime`. You keep track of the time you manually started the source.\n\n---\n\n### **Summary of the Fix**\n\n1. **Do not rely on `audioSource.startTime`**—most browsers don’t set that property. Store your own `_startTime` or keep a global `playbackStartTime`.\n2. **Always guard** in your animation function with `if (!isPlaying || !audioSource) return;` so you don’t read from a null object.\n3. **Cancel any ongoing `requestAnimationFrame`** calls when you stop or reset the app.  \n\nWith these steps, you’ll avoid the **“Cannot read properties of null (reading 'startTime')”** error.",
      "created_at": "2025-03-23T17:45:04.558488",
      "sequence_order": 25,
      "parent_id": "5ccc8405-9251-424a-9127-87f511709782",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    }
  ]
}