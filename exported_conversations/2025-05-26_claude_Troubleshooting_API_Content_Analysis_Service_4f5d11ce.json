{
  "id": "4f5d11ce-b82f-4db9-8a5a-9acd76ed10c6",
  "source": "claude",
  "title": "Troubleshooting API Content Analysis Service",
  "created_at": "2025-05-26T16:41:47.533027Z",
  "updated_at": "2025-05-26T16:42:41.651503Z",
  "summary": "",
  "message_count": 2,
  "messages": [
    {
      "id": "8f71bc69-c4f7-4a9c-aa78-39cdefa0da43",
      "role": "human",
      "content": "I'm having some issues # api/makeslides/domain/services/content_analysis_service.py\n\"\"\"\nDomain service interface for content analysis.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any\nfrom ..entities.presentation import Presentation\n\n\nclass ContentAnalysisService(ABC):\n    \"\"\"\n    Domain service for analyzing content and generating presentation structures.\n    \n    This is a core domain service that encapsulates the business logic\n    for transforming raw content into structured presentations.\n    \"\"\"\n    \n    @abstractmethod\n    async def analyze(self, content: str) -> Presentation:\n        \"\"\"\n        Analyze content and generate a presentation structure.\n        \n        Args:\n            content: Raw content to analyze\n            \n        Returns:\n            Presentation entity with structured content\n            \n        Raises:\n            DomainException: If content cannot be analyzed\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def analyze_for_modification(\n        self, \n        original_presentation: Presentation,\n        modification_request: str\n    ) -> Presentation:\n        \"\"\"\n        Analyze a modification request for an existing presentation.\n        \n        Args:\n            original_presentation: The presentation to modify\n            modification_request: Description of requested changes\n            \n        Returns:\n            Modified presentation entity\n        \"\"\"\n        pass# api/makeslides/domain/services/presentation_builder_service.py\n# makeslides/domain/services/presentation_builder_service.py\nfrom abc import ABC, abstractmethod\nfrom typing import Optional, Dict, Any\nfrom ..entities.presentation import Presentation\nfrom ..value_objects.theme import Theme\n\n\nclass PresentationBuilderService:\n    \"\"\"Domain service for building presentations from analyzed content\"\"\"\n    \n    def build_from_analyzed_content(\n        self,\n        analyzed_content: 'AnalyzedContent',\n        options: Optional[Dict[str, Any]] = None\n    ) -> Presentation:\n        \"\"\"Build presentation from analyzed content\"\"\"\n        # The analyzed_content is actually already a Presentation entity\n        # from the ContentAnalysisService, so we just return it as-is\n        # In the future, this could apply additional domain business logic\n        return analyzed_content\n    \n    def build_from_voice_content(\n        self,\n        analyzed_content: 'AnalyzedContent',\n        theme: Theme,\n        preferences: Dict[str, Any]\n    ) -> Presentation:\n        \"\"\"Build presentation optimized for voice content\"\"\"\n        # Implementation would go here\n        pass\n\n\n# makeslides/domain/services/speech_to_text_service.py\nfrom abc import ABC, abstractmethod\nfrom ..entities.voice_note import VoiceNote\nfrom ..entities.transcription import Transcription\n\n\nclass SpeechToTextService(ABC):\n    \"\"\"Domain service interface for speech-to-text conversion\"\"\"\n    \n    @abstractmethod\n    async def transcribe(self, voice_note: VoiceNote) -> Transcription:\n        \"\"\"Transcribe a voice note to text\"\"\"\n        pass\n    \n    @abstractmethod\n    async def get_supported_languages(self) -> list[str]:\n        \"\"\"Get list of supported languages\"\"\"\n        pass\n    \n    @abstractmethod\n    async def health_check(self) -> bool:\n        \"\"\"Check if service is available\"\"\"\n        pass\n\n\n# makeslides/domain/services/voice_enhancement_service.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any\nfrom ..entities.presentation import Presentation\nfrom ..entities.transcription import Transcription\n\n\nclass VoiceEnhancementService(ABC):\n    \"\"\"Domain service interface for enhancing voice-based presentations\"\"\"\n    \n    @abstractmethod\n    async def enhance_voice_presentation(\n        self,\n        presentation: Presentation,\n        original_transcription: Transcription,\n        preferences: Dict[str, Any]\n    ) -> 'VoiceEnhancements':\n        \"\"\"Enhance a presentation created from voice content\"\"\"\n        pass\n\n\nclass VoiceEnhancements:\n    \"\"\"Value object containing voice-specific enhancements\"\"\"\n    \n    def __init__(\n        self,\n        speaker_notes: Dict[int, str],\n        visual_suggestions: Dict[int, list[str]],\n        pacing_recommendations: Dict[int, float]\n    ):\n        self._speaker_notes = speaker_notes\n        self._visual_suggestions = visual_suggestions\n        self._pacing_recommendations = pacing_recommendations\n    \n    def apply_speaker_notes(self, presentation: Presentation) -> Presentation:\n        \"\"\"Apply speaker notes to presentation\"\"\"\n        # Implementation would modify slides with speaker notes\n        return presentation\n    \n    def apply_visual_suggestions(self, presentation: Presentation) -> Presentation:\n        \"\"\"Apply visual suggestions to presentation\"\"\"\n        # Implementation would add visual elements based on suggestions\n        return presentation",
      "created_at": "2025-05-26T16:41:49.384972Z",
      "sequence_order": 0,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-26T16:41:49.357379Z",
            "stop_timestamp": "2025-05-26T16:41:49.357379Z",
            "flags": null,
            "type": "text",
            "text": "I'm having some issues # api/makeslides/domain/services/content_analysis_service.py\n\"\"\"\nDomain service interface for content analysis.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any\nfrom ..entities.presentation import Presentation\n\n\nclass ContentAnalysisService(ABC):\n    \"\"\"\n    Domain service for analyzing content and generating presentation structures.\n    \n    This is a core domain service that encapsulates the business logic\n    for transforming raw content into structured presentations.\n    \"\"\"\n    \n    @abstractmethod\n    async def analyze(self, content: str) -> Presentation:\n        \"\"\"\n        Analyze content and generate a presentation structure.\n        \n        Args:\n            content: Raw content to analyze\n            \n        Returns:\n            Presentation entity with structured content\n            \n        Raises:\n            DomainException: If content cannot be analyzed\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def analyze_for_modification(\n        self, \n        original_presentation: Presentation,\n        modification_request: str\n    ) -> Presentation:\n        \"\"\"\n        Analyze a modification request for an existing presentation.\n        \n        Args:\n            original_presentation: The presentation to modify\n            modification_request: Description of requested changes\n            \n        Returns:\n            Modified presentation entity\n        \"\"\"\n        pass# api/makeslides/domain/services/presentation_builder_service.py\n# makeslides/domain/services/presentation_builder_service.py\nfrom abc import ABC, abstractmethod\nfrom typing import Optional, Dict, Any\nfrom ..entities.presentation import Presentation\nfrom ..value_objects.theme import Theme\n\n\nclass PresentationBuilderService:\n    \"\"\"Domain service for building presentations from analyzed content\"\"\"\n    \n    def build_from_analyzed_content(\n        self,\n        analyzed_content: 'AnalyzedContent',\n        options: Optional[Dict[str, Any]] = None\n    ) -> Presentation:\n        \"\"\"Build presentation from analyzed content\"\"\"\n        # The analyzed_content is actually already a Presentation entity\n        # from the ContentAnalysisService, so we just return it as-is\n        # In the future, this could apply additional domain business logic\n        return analyzed_content\n    \n    def build_from_voice_content(\n        self,\n        analyzed_content: 'AnalyzedContent',\n        theme: Theme,\n        preferences: Dict[str, Any]\n    ) -> Presentation:\n        \"\"\"Build presentation optimized for voice content\"\"\"\n        # Implementation would go here\n        pass\n\n\n# makeslides/domain/services/speech_to_text_service.py\nfrom abc import ABC, abstractmethod\nfrom ..entities.voice_note import VoiceNote\nfrom ..entities.transcription import Transcription\n\n\nclass SpeechToTextService(ABC):\n    \"\"\"Domain service interface for speech-to-text conversion\"\"\"\n    \n    @abstractmethod\n    async def transcribe(self, voice_note: VoiceNote) -> Transcription:\n        \"\"\"Transcribe a voice note to text\"\"\"\n        pass\n    \n    @abstractmethod\n    async def get_supported_languages(self) -> list[str]:\n        \"\"\"Get list of supported languages\"\"\"\n        pass\n    \n    @abstractmethod\n    async def health_check(self) -> bool:\n        \"\"\"Check if service is available\"\"\"\n        pass\n\n\n# makeslides/domain/services/voice_enhancement_service.py\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any\nfrom ..entities.presentation import Presentation\nfrom ..entities.transcription import Transcription\n\n\nclass VoiceEnhancementService(ABC):\n    \"\"\"Domain service interface for enhancing voice-based presentations\"\"\"\n    \n    @abstractmethod\n    async def enhance_voice_presentation(\n        self,\n        presentation: Presentation,\n        original_transcription: Transcription,\n        preferences: Dict[str, Any]\n    ) -> 'VoiceEnhancements':\n        \"\"\"Enhance a presentation created from voice content\"\"\"\n        pass\n\n\nclass VoiceEnhancements:\n    \"\"\"Value object containing voice-specific enhancements\"\"\"\n    \n    def __init__(\n        self,\n        speaker_notes: Dict[int, str],\n        visual_suggestions: Dict[int, list[str]],\n        pacing_recommendations: Dict[int, float]\n    ):\n        self._speaker_notes = speaker_notes\n        self._visual_suggestions = visual_suggestions\n        self._pacing_recommendations = pacing_recommendations\n    \n    def apply_speaker_notes(self, presentation: Presentation) -> Presentation:\n        \"\"\"Apply speaker notes to presentation\"\"\"\n        # Implementation would modify slides with speaker notes\n        return presentation\n    \n    def apply_visual_suggestions(self, presentation: Presentation) -> Presentation:\n        \"\"\"Apply visual suggestions to presentation\"\"\"\n        # Implementation would add visual elements based on suggestions\n        return presentation",
            "citations": []
          }
        ],
        "updated_at": "2025-05-26T16:41:49.384972Z",
        "attachments": [
          {
            "file_name": "paste.txt",
            "file_size": 104467,
            "file_type": "txt",
            "extracted_content": "# api/makeslides/api/controllers/presentation_controller.py\n\nimport logging\nimport os\nimport re\nimport time\nimport uuid\nfrom typing import Optional\nfrom fastapi import APIRouter, HTTPException, Depends, UploadFile, File, Form, Request\nfrom fastapi.responses import JSONResponse, FileResponse\n\nfrom ..schemas.presentation_schema import (\n    CreatePresentationSchema,\n    PresentationResponseSchema,\n    ProcessVoiceNoteSchema,\n    VoiceProcessingResponseSchema\n)\nfrom ..dependencies import (\n    get_current_user,\n    get_current_user_optional,\n    get_create_presentation_use_case,\n    get_process_voice_note_use_case,\n    get_render_presentation_use_case,\n    check_google_permissions\n)\nfrom ..middleware.correlation_middleware import get_correlation_id\nfrom ...application.use_cases.create_presentation import CreatePresentationUseCase\nfrom ...application.use_cases.process_voice_note import ProcessVoiceNoteUseCase\nfrom ...application.use_cases.render_presentation import RenderPresentationUseCase\nfrom ...application.dto.create_presentation_request import CreatePresentationRequest\nfrom ...application.dto.process_voice_note_request import ProcessVoiceNoteRequest\nfrom ...application.dto.render_presentation_request import RenderPresentationRequest\nfrom ...application.exceptions import ApplicationException, ValidationException\nfrom ...domain.exceptions import DomainException\nfrom ...domain.value_objects.output_format import OutputFormat\nfrom ...domain.value_objects.theme import ThemeType\nfrom ...domain.value_objects.audio_format import AudioFormat\nfrom ...domain.entities.user import User\n\n\nrouter = APIRouter(prefix=\"/presentations\", tags=[\"presentations\"])\nlogger = logging.getLogger(__name__)\n\n\n@router.get(\"/debug/auth-check\", tags=[\"Debug\"])\nasync def debug_auth_check(\n    request: Request,\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Debug endpoint to check authentication flow step by step.\"\"\"\n    debug_info = {\n        \"correlation_id\": correlation_id,\n        \"headers\": {},\n        \"auth_steps\": [],\n        \"errors\": []\n    }\n    \n    # Step 1: Check headers\n    auth_header = request.headers.get(\"Authorization\")\n    debug_info[\"headers\"][\"authorization\"] = auth_header[:50] + \"...\" if auth_header and len(auth_header) > 50 else auth_header\n    debug_info[\"headers\"][\"content_type\"] = request.headers.get(\"content-type\")\n    \n    if not auth_header:\n        debug_info[\"errors\"].append(\"No Authorization header found\")\n        return JSONResponse(status_code=200, content=debug_info)\n    \n    if not auth_header.startswith(\"Bearer \"):\n        debug_info[\"errors\"].append(\"Authorization header doesn't start with 'Bearer '\")\n        return JSONResponse(status_code=200, content=debug_info)\n    \n    token = auth_header[7:]\n    debug_info[\"auth_steps\"].append(f\"Token extracted: {token[:20]}...\")\n    \n    # Step 2: Try to validate with Supabase\n    try:\n        from ...infrastructure.di_container import DIContainerManager\n        from ...domain.services.interfaces.authentication_service import AuthenticationService\n        \n        auth_service = DIContainerManager.get_service(AuthenticationService)\n        debug_info[\"auth_steps\"].append(\"Got auth service from DI container\")\n        \n        # Get Supabase client\n        from supabase import Client\n        supabase_client = DIContainerManager.get_service(Client)\n        debug_info[\"auth_steps\"].append(\"Got Supabase client\")\n        \n        # Try to get user from Supabase\n        try:\n            user_response = supabase_client.auth.get_user(token)\n            if user_response and user_response.user:\n                debug_info[\"auth_steps\"].append(f\"Supabase returned user: {user_response.user.email}\")\n                debug_info[\"supabase_user\"] = {\n                    \"id\": user_response.user.id,\n                    \"email\": user_response.user.email,\n                    \"created_at\": str(user_response.user.created_at) if hasattr(user_response.user, 'created_at') else None\n                }\n            else:\n                debug_info[\"errors\"].append(\"Supabase returned no user for token\")\n        except Exception as e:\n            debug_info[\"errors\"].append(f\"Supabase get_user error: {str(e)}\")\n        \n        # Step 3: Check if user exists in our users table\n        from ...domain.repositories.user_repository import UserRepository\n        user_repo = DIContainerManager.get_service(UserRepository)\n        debug_info[\"auth_steps\"].append(\"Got user repository\")\n        \n        if \"supabase_user\" in debug_info:\n            try:\n                db_user = await user_repo.find_by_id(debug_info[\"supabase_user\"][\"id\"])\n                if db_user:\n                    debug_info[\"auth_steps\"].append(f\"User found in database: {db_user.email}\")\n                    debug_info[\"db_user_exists\"] = True\n                else:\n                    debug_info[\"auth_steps\"].append(\"User NOT found in database\")\n                    debug_info[\"db_user_exists\"] = False\n            except Exception as e:\n                debug_info[\"errors\"].append(f\"Database lookup error: {str(e)}\")\n        \n        # Step 4: Check RLS policies\n        try:\n            # Try a direct query to check RLS\n            result = supabase_client.table('users').select('id').execute()\n            debug_info[\"auth_steps\"].append(f\"RLS test query returned {len(result.data)} rows\")\n        except Exception as e:\n            debug_info[\"errors\"].append(f\"RLS test query failed: {str(e)}\")\n        \n    except Exception as e:\n        debug_info[\"errors\"].append(f\"General error: {str(e)}\")\n        logger.error(f\"Auth debug error: {e}\", exc_info=True)\n    \n    return JSONResponse(status_code=200, content=debug_info)\n\n\n@router.get(\"/{presentation_id}/content\")\nasync def get_presentation_content(\n    presentation_id: str,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Get complete presentation content for display/modification\"\"\"\n    try:\n        from ...infrastructure.repositories.presentation_storage_repository import (\n            PresentationStorageRepository\n        )\n        from pathlib import Path\n        \n        # Load presentation\n        storage_repo = PresentationStorageRepository(\n            storage_path=Path(\"data/presentations\"),\n            logger=logger\n        )\n        \n        metadata = await storage_repo.load_presentation(presentation_id)\n        if not metadata:\n            raise HTTPException(status_code=404, detail=\"Presentation not found\")\n        \n        # For now, skip user ownership check since we have RLS issues\n        # In production, uncomment this:\n        # if metadata.user_id != current_user.id and metadata.user_id != \"anonymous\":\n        #     raise HTTPException(status_code=403, detail=\"Access denied\")\n        \n        # Check if PPTX file exists and generate download URL\n        pptx_download_url = metadata.pptx_download_url\n        if not pptx_download_url:\n            # Try to find existing PPTX file\n            base_dir = Path(\"data/presentations\")\n            possible_files = [\n                base_dir / f\"{metadata.presentation_id}.pptx\",\n                base_dir / f\"presentation_{metadata.presentation_id}.pptx\",\n                base_dir / f\"test_{metadata.presentation_id}.pptx\",\n                base_dir / f\"regenerated_{metadata.presentation_id}.pptx\"\n            ]\n            \n            # Also check for files with timestamps or stream prefixes\n            for file in base_dir.glob(\"*.pptx\"):\n                if metadata.presentation_id in str(file):\n                    possible_files.append(file)\n            \n            for file_path in possible_files:\n                if file_path.exists():\n                    # Generate download URL using the direct download endpoint (relative URL)\n                    pptx_download_url = f\"/presentations/{metadata.presentation_id}/download\"\n                    break\n        \n        # Return structured content for frontend\n        content_data = {\n            \"presentation_id\": metadata.presentation_id,\n            \"title\": metadata.title,\n            \"status\": metadata.status.value,\n            \"original_content\": metadata.original_content,\n            \"theme\": metadata.theme,\n            \"slide_count\": metadata.slide_count,\n            \"estimated_duration_minutes\": metadata.estimated_duration_minutes,\n            \"slides\": [\n                {\n                    \"slide_number\": slide.slide_number,\n                    \"title\": slide.title,\n                    \"content\": slide.content,\n                    \"layout\": slide.layout,\n                    \"speaker_notes\": slide.speaker_notes,\n                    \"notes\": slide.speaker_notes,  # Add both for compatibility\n                    \"facilitator_notes\": slide.speaker_notes,  # Add facilitator notes\n                    \"assets\": [\n                        {\n                            \"asset_id\": asset.asset_id,\n                            \"asset_type\": asset.asset_type,\n                            \"cloud_url\": asset.cloud_url\n                        } for asset in slide.assets\n                    ]\n                } for slide in metadata.slides\n            ],\n            \"google_slides_url\": metadata.google_slides_url,\n            \"pptx_download_url\": pptx_download_url,\n            \"modification_history\": metadata.modification_history,\n            \"generation_timestamp\": metadata.generation_timestamp.isoformat(),\n            \"is_modifiable\": metadata.is_modifiable\n        }\n        \n        return JSONResponse(content=content_data)\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Failed to get presentation content: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n\n\n@router.get(\"/{presentation_id}/download\")\nasync def download_presentation(\n    presentation_id: str,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Download presentation file directly.\"\"\"\n    try:\n        from pathlib import Path\n        from fastapi.responses import FileResponse\n        \n        # Look for PPTX file in the presentations directory\n        # Use absolute path to ensure we find the files regardless of working directory\n        base_dir = Path(\"data/presentations\").resolve()\n        if not base_dir.exists():\n            # Fallback: try relative to API directory\n            api_dir = Path(__file__).parent.parent.parent.parent\n            base_dir = api_dir / \"data\" / \"presentations\"\n        \n        # Try different possible filenames\n        possible_files = [\n            base_dir / f\"{presentation_id}.pptx\",\n            base_dir / f\"presentation_{presentation_id}.pptx\",\n            base_dir / f\"test_{presentation_id}.pptx\",\n            base_dir / f\"test_stream_{presentation_id}.pptx\",\n            base_dir / f\"regenerated_{presentation_id}.pptx\"\n        ]\n        \n        # Also check for files with timestamps\n        for file in base_dir.glob(\"*.pptx\"):\n            if presentation_id in str(file):\n                possible_files.append(file)\n        \n        for file_path in possible_files:\n            if file_path.exists():\n                return FileResponse(\n                    path=str(file_path),\n                    filename=f\"presentation_{presentation_id[:8]}.pptx\",\n                    media_type=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\"\n                )\n        \n        raise HTTPException(status_code=404, detail=\"Presentation file not found\")\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Download failed for {presentation_id}: {e}\")\n        raise HTTPException(status_code=500, detail=\"Failed to download presentation\")\n\n\n@router.get(\"/{presentation_id}/download/json\")\nasync def download_presentation_json(\n    presentation_id: str,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Download presentation as JSON file.\"\"\"\n    try:\n        from pathlib import Path\n        from fastapi.responses import Response\n        import json\n        from ...domain.repositories.presentation_repository import PresentationRepository\n        from ...infrastructure.di_container import DIContainerManager\n        from ...domain.adapters.presentation_adapter import PresentationAdapter\n        \n        # Get presentation repository\n        presentation_repo = DIContainerManager.get_service(PresentationRepository)\n        \n        # Retrieve the presentation\n        presentation = await presentation_repo.get_by_id(presentation_id)\n        if not presentation:\n            raise HTTPException(status_code=404, detail=\"Presentation not found\")\n        \n        # Convert to dict format\n        presentation_dict = PresentationAdapter.to_dict(presentation)\n        \n        # Convert to JSON with proper formatting\n        json_content = json.dumps(presentation_dict, indent=2, ensure_ascii=False)\n        \n        # Return as downloadable JSON file\n        return Response(\n            content=json_content,\n            media_type=\"application/json\",\n            headers={\n                \"Content-Disposition\": f\"attachment; filename=presentation_{presentation_id[:8]}.json\"\n            }\n        )\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"JSON download failed for {presentation_id}: {e}\")\n        raise HTTPException(status_code=500, detail=\"Failed to download presentation JSON\")\n\n\n@router.get(\"/google-permissions\")\nasync def check_google_permissions_status(\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Check user's Google OAuth permissions for creating slides\"\"\"\n    try:\n        # Get authentication status from domain logic\n        auth_status = current_user.get_google_authentication_status()\n        \n        response_data = {\n            \"user_id\": current_user.id,\n            \"email\": current_user.email,\n            \"google_connected\": current_user.google_connected,\n            \"has_google_auth\": current_user.has_google_credentials(),\n            \"can_create_slides\": auth_status[\"can_create_slides\"],\n            \"needs_refresh\": auth_status[\"needs_refresh\"],\n            \"can_refresh\": auth_status[\"can_refresh\"],\n            \"reason\": auth_status[\"reason\"],\n            \"scopes\": auth_status.get(\"scopes\", []),\n            \"required_scopes\": auth_status.get(\"required_scopes\", []),\n            \"debug_info\": auth_status\n        }\n        \n        logger.info(f\"Google permissions check for user {current_user.email}: {auth_status.get('reason', 'OK')}\")\n        \n        return JSONResponse(content=response_data)\n        \n    except Exception as e:\n        logger.error(f\"Failed to check Google permissions: {e}\", exc_info=True)\n        \n        # Return a more detailed error response\n        return JSONResponse(\n            status_code=500,\n            content={\n                \"error\": \"Failed to check Google permissions\",\n                \"message\": str(e),\n                \"google_connected\": False,\n                \"has_google_auth\": False,\n                \"can_create_slides\": False,\n                \"needs_reauth\": True\n            }\n        )\n\n\n@router.post(\"/create\", response_model=PresentationResponseSchema)\nasync def create_presentation(\n    request: CreatePresentationSchema,\n    correlation_id: str = Depends(get_correlation_id)\n) -> PresentationResponseSchema:\n    \"\"\"\n    Create a new presentation from content.\n    \n    This endpoint accepts text content and creates a structured presentation\n    with AI-powered content analysis and professional formatting.\n    \"\"\"\n    logger.info(\n        \"Creating presentation via API\",\n        extra={\n            \"correlation_id\": correlation_id,\n            \"content_length\": len(request.content),\n            \"format\": request.format\n        }\n    )\n    \n    try:\n        # For now, return a mock response to test the API flow\n        from datetime import datetime\n        \n        mock_response = PresentationResponseSchema(\n            id=str(uuid.uuid4()),\n            title=\"Mock Presentation\",\n            slide_count=5,\n            theme=request.theme,\n            estimated_duration_minutes=10,\n            status=\"completed\",\n            created_at=datetime.now(),\n            validation_issues=[],\n            processing_time_seconds=2.5\n        )\n        \n        logger.info(\n            \"Mock presentation created successfully\",\n            extra={\"correlation_id\": correlation_id, \"presentation_id\": mock_response.id}\n        )\n        \n        return mock_response\n        \n    except ValidationException as e:\n        logger.warning(\n            \"Presentation creation validation error\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n        )\n        raise HTTPException(status_code=400, detail=str(e))\n        \n    except DomainException as e:\n        logger.warning(\n            \"Presentation creation domain error\", \n            extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n        )\n        raise HTTPException(status_code=422, detail=f\"Business rule violation: {str(e)}\")\n        \n    except ApplicationException as e:\n        logger.error(\n            \"Presentation creation application error\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n        )\n        raise HTTPException(status_code=500, detail=\"Failed to create presentation\")\n        \n    except Exception as e:\n        logger.error(\n            \"Unexpected error creating presentation\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)},\n            exc_info=True\n        )\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n\n\n@router.get(\"/\", response_model=list[PresentationResponseSchema])\nasync def get_presentations(\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n) -> list[PresentationResponseSchema]:\n    \"\"\"\n    Get all presentations for the current user.\n    \"\"\"\n    try:\n        logger.info(\n            f\"Getting presentations for user: {current_user.email}\",\n            extra={\"correlation_id\": correlation_id, \"user_id\": current_user.id}\n        )\n        \n        # Load presentations from storage\n        from ...infrastructure.repositories.presentation_storage_repository import (\n            PresentationStorageRepository\n        )\n        from pathlib import Path\n        \n        storage_repo = PresentationStorageRepository(\n            storage_path=Path(\"data/presentations\"),\n            logger=logger\n        )\n        \n        # Get all presentations for this user (including anonymous ones for now)\n        presentations = await storage_repo.list_user_presentations(current_user.id)\n        \n        # Also get anonymous presentations (temporary fix until we link them properly)\n        anonymous_presentations = await storage_repo.list_user_presentations(\"anonymous\")\n        presentations.extend(anonymous_presentations)\n        \n        # Convert to response format\n        presentation_responses = []\n        for presentation in presentations:\n            response = PresentationResponseSchema(\n                id=presentation.presentation_id,\n                title=presentation.title,\n                status=presentation.status.value,\n                download_url=presentation.pptx_download_url,\n                google_slides_url=presentation.google_slides_url,\n                created_at=presentation.generation_timestamp.isoformat(),\n                slide_count=presentation.slide_count,\n                theme=presentation.theme,\n                estimated_duration_minutes=max(1, presentation.slide_count * 2),  # Rough estimate\n                processing_time_seconds=0.0,\n                validation_issues=None,\n                url=presentation.google_slides_url  # For backwards compatibility\n            )\n            presentation_responses.append(response)\n        \n        logger.info(f\"Found {len(presentation_responses)} presentations for user {current_user.email}\")\n        return presentation_responses\n        \n    except Exception as e:\n        logger.error(\n            \"Unexpected error getting presentations\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)},\n            exc_info=True\n        )\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n\n\n@router.post(\"/create-stream\")\nasync def create_presentation_stream(\n    request: CreatePresentationSchema,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id),\n    use_case: CreatePresentationUseCase = Depends(get_create_presentation_use_case)\n):\n    \"\"\"Create presentation using modern DDD architecture with asset processing and streaming updates.\"\"\"\n    from fastapi.responses import StreamingResponse\n    import json\n    import asyncio\n    \n    logger.info(\n        \"Creating presentation with modern CreatePresentationUseCase\",\n        extra={\n            \"correlation_id\": correlation_id,\n            \"content_length\": len(request.content),\n            \"format\": request.format,\n            \"process_assets\": request.process_assets,\n            \"user_id\": current_user.id if current_user else None\n        }\n    )\n    \n    async def generate_sse():\n        \"\"\"Generate Server-Sent Events using modern CreatePresentationUseCase with asset processing.\"\"\"\n        try:\n            # Send initial status\n            yield f\"data: {json.dumps({'type': 'status', 'message': 'Initializing modern presentation creation...'})}\\n\\n\"\n            await asyncio.sleep(0.1)\n            \n            # Transform API request to use case request\n            yield f\"data: {json.dumps({'type': 'status', 'message': 'Preparing request with asset processing enabled...'})}\\n\\n\"\n            \n            use_case_request = CreatePresentationRequest(\n                content=request.content,\n                output_format=OutputFormat.from_string(request.format),\n                theme=ThemeType.PROFESSIONAL,  # Use theme from request if needed\n                google_credentials=None,  # Add Google creds if available\n                options=_create_presentation_options(request),\n                user_id=current_user.id if current_user else \"anonymous\",\n                title=request.title if hasattr(request, 'title') else None\n            )\n            \n            # Show asset processing status\n            if use_case_request.options.process_assets:\n                yield f\"data: {json.dumps({'type': 'status', 'message': 'üé® Asset processing enabled - will generate diagrams, charts, and images'})}\\n\\n\"\n            else:\n                yield f\"data: {json.dumps({'type': 'warning', 'message': 'Asset processing disabled'})}\\n\\n\"\n            \n            await asyncio.sleep(0.1)\n            \n            # Execute the modern use case\n            yield f\"data: {json.dumps({'type': 'status', 'message': 'üß† Analyzing content with Claude AI...'})}\\n\\n\"\n            await asyncio.sleep(0.5)\n            \n            yield f\"data: {json.dumps({'type': 'status', 'message': 'üèóÔ∏è Building presentation structure...'})}\\n\\n\"\n            await asyncio.sleep(0.3)\n            \n            if use_case_request.options.process_assets:\n                yield f\"data: {json.dumps({'type': 'status', 'message': 'üé® Detecting and generating assets...'})}\\n\\n\"\n                await asyncio.sleep(0.5)\n            \n            yield f\"data: {json.dumps({'type': 'status', 'message': 'üíæ Saving presentation...'})}\\n\\n\"\n            \n            # Execute use case\n            response = await use_case.execute(use_case_request)\n            \n            if response.success:\n                yield f\"data: {json.dumps({'type': 'status', 'message': f'‚úÖ Presentation created successfully with {response.slide_count} slides'})}\\n\\n\"\n                \n                # Send final result\n                final_result = {\n                    \"type\": \"result\",\n                    \"presentation_id\": response.presentation_id,\n                    \"slide_count\": response.slide_count,\n                    \"title\": response.metadata.get(\"title\", \"Untitled\") if response.metadata else \"Untitled\",\n                    \"pptx_filename\": f\"{response.presentation_id}.pptx\",\n                    \"google_slides_url\": None,  # TODO: Add when Google Slides is implemented\n                    \"warnings\": response.warnings or []\n                }\n                \n                yield f\"data: {json.dumps(final_result)}\\n\\n\"\n                \n                # Final completion status\n                yield f\"data: {json.dumps({'type': 'final_result', **final_result})}\\n\\n\"\n                \n            else:\n                error_msg = response.error_message or \"Unknown error occurred\"\n                yield f\"data: {json.dumps({'type': 'error', 'message': f'‚ùå Failed to create presentation: {error_msg}'})}\\n\\n\"\n                \n        except Exception as e:\n            logger.error(f\"Modern streaming generation failed: {e}\", exc_info=True)\n            yield f\"data: {json.dumps({'type': 'error', 'message': f'Generation failed: {str(e)}'})}\\n\\n\"\n        \n        # Send completion event\n        yield f\"data: {json.dumps({'type': 'complete'})}\\n\\n\"\n    \n    return StreamingResponse(\n        generate_sse(),\n        media_type=\"text/event-stream\",\n        headers={\n            \"Cache-Control\": \"no-cache\",\n            \"Connection\": \"keep-alive\",\n            \"Access-Control-Allow-Origin\": \"*\",\n            \"Access-Control-Allow-Headers\": \"*\",\n        }\n    )\n\n    \n    \n# ==================== MOCK/BACKUP ENDPOINT ====================\n\n@router.post(\"/create-stream-mock\")\nasync def create_presentation_stream_mock(\n    request: CreatePresentationSchema,\n    current_user: User = Depends(get_current_user_optional),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Backup endpoint with mock data for testing when Claude AI is unavailable.\"\"\"\n    from fastapi.responses import StreamingResponse\n    import json\n    import asyncio\n    \n    async def generate_sse():\n        \"\"\"Generate Server-Sent Events with mock data.\"\"\"\n        try:\n            # Send initial status\n            yield f\"data: {json.dumps({'type': 'status', 'message': 'Starting AI analysis...', 'progress': 0})}\\n\\n\"\n            await asyncio.sleep(0.5)\n            \n            # Simulate Claude thinking process\n            thinking_steps = [\n                {\"message\": \"üß† Analyzing content structure...\", \"progress\": 10},\n                {\"message\": \"üìã Identifying key topics and themes...\", \"progress\": 20},\n                {\"message\": \"üéØ Planning slide organization...\", \"progress\": 30},\n                {\"message\": \"üí≠ Claude thinking: This content covers ML fundamentals. I should structure it with an intro, core concepts, practical applications, and conclusion.\", \"progress\": 40},\n                {\"message\": \"üé® Applying theme and visual design...\", \"progress\": 50},\n                {\"message\": \"üìä Generating diagrams and visual elements...\", \"progress\": 60},\n                {\"message\": \"üí≠ Claude thinking: A flowchart showing the ML pipeline would be helpful here. Also considering a comparison table for supervised vs unsupervised learning.\", \"progress\": 70},\n                {\"message\": \"‚ú® Finalizing slide content and formatting...\", \"progress\": 80},\n                {\"message\": \"üîç Running quality checks and validation...\", \"progress\": 90},\n                {\"message\": \"‚úÖ Presentation generation complete!\", \"progress\": 100}\n            ]\n            \n            for step in thinking_steps:\n                yield f\"data: {json.dumps({'type': 'progress', **step})}\\n\\n\"\n                await asyncio.sleep(1.0)  # Simulate processing time\n            \n            # Send final result\n            from datetime import datetime\n            \n            presentation_id = str(uuid.uuid4())\n            \n            # Determine the actual output format (prioritize Google Slides)\n            output_format = request.format\n            google_slides_url = None\n            \n            # Try to create real Google Slides if user has Google credentials\n            if output_format == \"google_slides\" and current_user and current_user.can_create_google_slides():\n                try:\n                    # Create real Google Slides presentation\n                    from ...renderers.google_slides_renderer import GoogleSlidesRenderer\n                    from ...infrastructure.external_services.google_slides_client import GoogleSlidesClient\n                    \n                    # Mock presentation data for now\n                    presentation_data = {\n                        'title': f\"Generated: {request.content[:50]}...\",\n                        'slides': [\n                            {\n                                'title': 'Title Slide',\n                                'content': request.content[:200] + '...',\n                                'layout': 'TITLE_SLIDE'\n                            },\n                            {\n                                'title': 'Main Content',\n                                'content': request.content,\n                                'layout': 'TITLE_AND_CONTENT'\n                            }\n                        ]\n                    }\n                    \n                    # Create Google Slides renderer\n                    slides_client = GoogleSlidesClient(\n                        credentials_path=\"\", \n                        scopes=[\n                            \"https://www.googleapis.com/auth/presentations\",\n                            \"https://www.googleapis.com/auth/drive.file\"\n                        ],\n                        logger=logger\n                    )\n                    renderer = GoogleSlidesRenderer(slides_client, debug=True)\n                    \n                    # Render to Google Slides using the user's OAuth tokens\n                    result = renderer.render(\n                        presentation_data, \n                        access_token=current_user.google_credentials.access_token\n                    )\n                    \n                    if result.get('success'):\n                        google_slides_url = result.get('url')\n                        logger.info(f\"Successfully created Google Slides: {google_slides_url}\")\n                    else:\n                        logger.error(f\"Failed to create Google Slides: {result.get('error')}\")\n                        # Fall back to mock URL\n                        slides_id = f\"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms_{presentation_id[-8:]}\"\n                        google_slides_url = f\"https://docs.google.com/presentation/d/{slides_id}/edit\"\n                        \n                except Exception as e:\n                    logger.error(f\"Error creating Google Slides: {e}\")\n                    # Fall back to mock URL\n                    slides_id = f\"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms_{presentation_id[-8:]}\"\n                    google_slides_url = f\"https://docs.google.com/presentation/d/{slides_id}/edit\"\n            \n            elif output_format == \"google_slides\":\n                # User doesn't have Google credentials, use mock URL\n                slides_id = f\"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms_{presentation_id[-8:]}\"\n                google_slides_url = f\"https://docs.google.com/presentation/d/{slides_id}/edit\"\n            \n            download_request_url = f\"/presentations/{presentation_id}/request-download\"\n            \n            result = {\n                \"type\": \"result\",\n                \"presentation\": {\n                    \"id\": presentation_id,\n                    \"title\": f\"Generated: {request.content[:50]}...\",\n                    \"slide_count\": 7,\n                    \"theme\": request.theme,\n                    \"estimated_duration_minutes\": 12,\n                    \"status\": \"completed\",\n                    \"created_at\": datetime.now().isoformat(),\n                    \"download_request_url\": download_request_url,\n                    \"download_url\": download_request_url,  # Add for frontend compatibility\n                    \"google_slides_url\": google_slides_url,\n                    \"output_format\": output_format\n                }\n            }\n            \n            # Save complete presentation JSON for future reference and modifications\n            try:\n                from ...domain.value_objects.complete_presentation_metadata import (\n                    CompletePresentationMetadata, PresentationStatus, SlideContent, AssetInfo\n                )\n                from ...infrastructure.repositories.presentation_storage_repository import (\n                    PresentationStorageRepository\n                )\n                from pathlib import Path\n                \n                # Create mock slide content (in real implementation, this would come from AI analysis)\n                mock_slides = [\n                    SlideContent(\n                        slide_number=1,\n                        title=\"Title Slide\",\n                        content=request.content[:200] + \"...\",\n                        layout=\"TITLE_SLIDE\",\n                        speaker_notes=\"Introduction to the presentation\",\n                        assets=[],\n                        style_metadata={\"theme\": request.theme}\n                    ),\n                    SlideContent(\n                        slide_number=2,\n                        title=\"Main Content\",\n                        content=request.content,\n                        layout=\"TITLE_AND_CONTENT\",\n                        speaker_notes=\"Main content of the presentation\",\n                        assets=[],\n                        style_metadata={\"theme\": request.theme}\n                    )\n                ]\n                \n                # Create complete metadata\n                complete_metadata = CompletePresentationMetadata(\n                    presentation_id=presentation_id,\n                    title=result[\"presentation\"][\"title\"],\n                    user_id=current_user.id,\n                    status=PresentationStatus.GENERATED,\n                    original_content=request.content,\n                    original_prompt=None,\n                    theme=request.theme,\n                    output_format=output_format,\n                    processing_options={\n                        \"format\": request.format,\n                        \"theme\": request.theme\n                    },\n                    slides=mock_slides,\n                    assets=[],\n                    ai_analysis={\n                        \"content_type\": \"text\",\n                        \"detected_topics\": [\"AI\", \"presentation\"],\n                        \"suggested_layouts\": [\"TITLE_SLIDE\", \"TITLE_AND_CONTENT\"]\n                    },\n                    generation_timestamp=datetime.now(),\n                    modification_history=[],\n                    google_slides_url=google_slides_url,\n                    pptx_download_url=download_request_url,\n                    slide_count=result[\"presentation\"][\"slide_count\"],\n                    estimated_duration_minutes=result[\"presentation\"][\"estimated_duration_minutes\"],\n                    processing_time_seconds=2.5\n                )\n                \n                # Save to storage\n                storage_repo = PresentationStorageRepository(\n                    storage_path=Path(\"data/presentations\"),\n                    logger=logger\n                )\n                await storage_repo.save_presentation(complete_metadata)\n                \n                logger.info(f\"Saved complete presentation metadata for {presentation_id}\")\n                \n            except Exception as e:\n                logger.error(f\"Failed to save presentation metadata: {e}\")\n                # Don't fail the whole request if storage fails\n            \n            yield f\"data: {json.dumps(result)}\\n\\n\"\n            \n        except Exception as e:\n            logger.error(f\"Streaming error: {e}\", exc_info=True)\n            yield f\"data: {json.dumps({'type': 'error', 'message': str(e)})}\\n\\n\"\n    \n    return StreamingResponse(\n        generate_sse(),\n        media_type=\"text/plain\",\n        headers={\n            \"Cache-Control\": \"no-cache\",\n            \"Connection\": \"keep-alive\",\n            \"Access-Control-Allow-Origin\": \"*\",\n            \"Access-Control-Allow-Headers\": \"*\",\n        }\n    )\n\n\n@router.post(\"/{presentation_id}/modify\")\nasync def modify_presentation(\n    presentation_id: str,\n    modification_request: str = Form(..., description=\"Description of changes to make\"),\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Modify an existing presentation based on user feedback\"\"\"\n    logger.info(\n        \"Modifying presentation\",\n        extra={\n            \"correlation_id\": correlation_id,\n            \"presentation_id\": presentation_id,\n            \"modification_length\": len(modification_request)\n        }\n    )\n    \n    try:\n        from ...infrastructure.repositories.presentation_storage_repository import (\n            PresentationStorageRepository\n        )\n        from ...services.presentation_modification_service import (\n            PresentationModificationService\n        )\n        from ...domain.value_objects.complete_presentation_metadata import (\n            CompletePresentationMetadata\n        )\n        from pathlib import Path\n        import json\n        \n        # Load original presentation\n        storage_repo = PresentationStorageRepository(\n            storage_path=Path(\"data/presentations\"),\n            logger=logger\n        )\n        \n        original_metadata = await storage_repo.load_presentation(presentation_id)\n        if not original_metadata:\n            raise HTTPException(status_code=404, detail=\"Presentation not found\")\n        \n        # Temporarily disable user ownership check for debugging\n        # TODO: Re-enable in production\n        # if original_metadata.user_id != current_user.id:\n        #     raise HTTPException(status_code=403, detail=\"Access denied\")\n        \n        # Check if presentation is modifiable\n        if not original_metadata.is_modifiable:\n            raise HTTPException(status_code=400, detail=\"Presentation cannot be modified\")\n        \n        # Generate modification prompt\n        modification_service = PresentationModificationService(logger)\n        \n        # Select best prompt version\n        prompt_version = modification_service.select_best_prompt_version(\n            modification_request, original_metadata\n        )\n        \n        modification_prompt = modification_service.generate_modification_prompt(\n            original_metadata, modification_request, prompt_version\n        )\n        \n        logger.info(f\"Using prompt version {prompt_version} for modification\")\n        \n        # For now, return the prompt and metadata for testing\n        # In production, this would call Claude API\n        response_data = {\n            \"presentation_id\": presentation_id,\n            \"modification_request\": modification_request,\n            \"prompt_version_used\": prompt_version,\n            \"original_slide_count\": original_metadata.slide_count,\n            \"original_title\": original_metadata.title,\n            \"modification_prompt\": modification_prompt[:500] + \"...\" if len(modification_prompt) > 500 else modification_prompt,\n            \"status\": \"ready_for_processing\"\n        }\n        \n        logger.info(\n            \"Modification request prepared\",\n            extra={\n                \"correlation_id\": correlation_id,\n                \"presentation_id\": presentation_id,\n                \"prompt_version\": prompt_version\n            }\n        )\n        \n        return JSONResponse(content=response_data)\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Modification failed: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n\n\n@router.get(\"/{presentation_id}/content\")\nasync def get_presentation_content(\n    presentation_id: str,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Get complete presentation content for display/modification\"\"\"\n    try:\n        from ...infrastructure.repositories.presentation_storage_repository import (\n            PresentationStorageRepository\n        )\n        from pathlib import Path\n        \n        # Load presentation\n        storage_repo = PresentationStorageRepository(\n            storage_path=Path(\"data/presentations\"),\n            logger=logger\n        )\n        \n        metadata = await storage_repo.load_presentation(presentation_id)\n        if not metadata:\n            raise HTTPException(status_code=404, detail=\"Presentation not found\")\n        \n        # Temporarily disable user ownership check for debugging\n        # TODO: Re-enable in production\n        # if metadata.user_id != current_user.id:\n        #     raise HTTPException(status_code=403, detail=\"Access denied\")\n        \n        # Return structured content for frontend\n        content_data = {\n            \"presentation_id\": metadata.presentation_id,\n            \"title\": metadata.title,\n            \"status\": metadata.status.value,\n            \"original_content\": metadata.original_content,\n            \"theme\": metadata.theme,\n            \"slide_count\": metadata.slide_count,\n            \"slides\": [\n                {\n                    \"slide_number\": slide.slide_number,\n                    \"title\": slide.title,\n                    \"content\": slide.content,\n                    \"layout\": slide.layout,\n                    \"speaker_notes\": slide.speaker_notes,\n                    \"assets\": [\n                        {\n                            \"asset_id\": asset.asset_id,\n                            \"asset_type\": asset.asset_type,\n                            \"cloud_url\": asset.cloud_url\n                        } for asset in slide.assets\n                    ]\n                } for slide in metadata.slides\n            ],\n            \"google_slides_url\": metadata.google_slides_url,\n            \"modification_history\": metadata.modification_history,\n            \"generation_timestamp\": metadata.generation_timestamp.isoformat(),\n            \"is_modifiable\": metadata.is_modifiable\n        }\n        \n        return JSONResponse(content=content_data)\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Failed to get presentation content: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n\n\n@router.put(\"/{presentation_id}\")\nasync def update_presentation(\n    presentation_id: str,\n    request: dict,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Update presentation content without regenerating files\"\"\"\n    try:\n        from ...infrastructure.repositories.presentation_storage_repository import (\n            PresentationStorageRepository\n        )\n        from ...domain.value_objects.complete_presentation_metadata import (\n            CompletePresentationMetadata, PresentationStatus, SlideContent\n        )\n        from pathlib import Path\n        from datetime import datetime\n        \n        # Load existing presentation\n        storage_repo = PresentationStorageRepository(\n            storage_path=Path(\"data/presentations\"),\n            logger=logger\n        )\n        \n        metadata = await storage_repo.load_presentation(presentation_id)\n        if not metadata:\n            raise HTTPException(status_code=404, detail=\"Presentation not found\")\n        \n        # Temporarily disable user ownership check for debugging\n        # TODO: Re-enable in production\n        # if metadata.user_id != current_user.id:\n        #     raise HTTPException(status_code=403, detail=\"Access denied\")\n        \n        # Update slides from request\n        updated_slides = []\n        for slide_data in request.get('slides', []):\n            slide = SlideContent(\n                slide_number=slide_data.get('slide_number', 1),\n                title=slide_data.get('title', ''),\n                content=slide_data.get('content', ''),\n                layout=slide_data.get('layout', 'TITLE_AND_CONTENT'),\n                speaker_notes=slide_data.get('notes', ''),\n                assets=[],\n                style_metadata=slide_data.get('style_metadata', {})\n            )\n            updated_slides.append(slide)\n        \n        # Create updated metadata\n        updated_metadata = CompletePresentationMetadata(\n            presentation_id=metadata.presentation_id,\n            title=request.get('title', metadata.title),\n            user_id=metadata.user_id,\n            status=PresentationStatus.MODIFIED,\n            original_content=metadata.original_content,\n            original_prompt=metadata.original_prompt,\n            theme=request.get('theme', metadata.theme),\n            output_format=metadata.output_format,\n            processing_options=metadata.processing_options,\n            slides=updated_slides,\n            assets=metadata.assets,\n            ai_analysis=metadata.ai_analysis,\n            generation_timestamp=metadata.generation_timestamp,\n            modification_history=metadata.modification_history + [{\n                'timestamp': datetime.now().isoformat(),\n                'action': 'manual_edit',\n                'changes': f'Updated {len(updated_slides)} slides'\n            }],\n            google_slides_url=metadata.google_slides_url,\n            pptx_download_url=metadata.pptx_download_url,\n            slide_count=len(updated_slides),\n            estimated_duration_minutes=metadata.estimated_duration_minutes,\n            processing_time_seconds=metadata.processing_time_seconds\n        )\n        \n        # Save updated presentation\n        await storage_repo.save_presentation(updated_metadata)\n        \n        logger.info(f\"Updated presentation {presentation_id} with {len(updated_slides)} slides\")\n        \n        return JSONResponse(content={\n            \"message\": \"Presentation updated successfully\",\n            \"presentation\": {\n                \"id\": updated_metadata.presentation_id,\n                \"title\": updated_metadata.title,\n                \"slide_count\": updated_metadata.slide_count,\n                \"theme\": updated_metadata.theme,\n                \"status\": updated_metadata.status.value,\n                \"modified_at\": datetime.now().isoformat()\n            }\n        })\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Failed to update presentation {presentation_id}: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=f\"Failed to update presentation: {str(e)}\")\n\n\n@router.post(\"/{presentation_id}/versions\")\nasync def create_presentation_version(\n    presentation_id: str,\n    request: dict,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Create a new version of the presentation with changes\"\"\"\n    try:\n        from ...infrastructure.repositories.presentation_storage_repository import (\n            PresentationStorageRepository\n        )\n        from ...domain.value_objects.complete_presentation_metadata import (\n            CompletePresentationMetadata, PresentationStatus, SlideContent\n        )\n        from pathlib import Path\n        from datetime import datetime\n        import uuid\n        \n        # Load original presentation\n        storage_repo = PresentationStorageRepository(\n            storage_path=Path(\"data/presentations\"),\n            logger=logger\n        )\n        \n        original_metadata = await storage_repo.load_presentation(presentation_id)\n        if not original_metadata:\n            raise HTTPException(status_code=404, detail=\"Original presentation not found\")\n        \n        # Temporarily disable user ownership check for debugging\n        # TODO: Re-enable in production\n        # if original_metadata.user_id != current_user.id:\n        #     raise HTTPException(status_code=403, detail=\"Access denied\")\n        \n        # Create new version ID\n        version_id = str(uuid.uuid4())\n        \n        # Update slides from request\n        updated_slides = []\n        for slide_data in request.get('slides', []):\n            slide = SlideContent(\n                slide_number=slide_data.get('slide_number', 1),\n                title=slide_data.get('title', ''),\n                content=slide_data.get('content', ''),\n                layout=slide_data.get('layout', 'TITLE_AND_CONTENT'),\n                speaker_notes=slide_data.get('notes', ''),\n                assets=[],\n                style_metadata=slide_data.get('style_metadata', {})\n            )\n            updated_slides.append(slide)\n        \n        # Create new version metadata\n        version_metadata = CompletePresentationMetadata(\n            presentation_id=version_id,\n            title=f\"{original_metadata.title} (Version {len(original_metadata.modification_history) + 2})\",\n            user_id=original_metadata.user_id,\n            status=PresentationStatus.GENERATED,\n            original_content=original_metadata.original_content,\n            original_prompt=original_metadata.original_prompt,\n            theme=request.get('theme', original_metadata.theme),\n            output_format=request.get('format', original_metadata.output_format),\n            processing_options=original_metadata.processing_options,\n            slides=updated_slides,\n            assets=original_metadata.assets,\n            ai_analysis=original_metadata.ai_analysis,\n            generation_timestamp=datetime.now(),\n            modification_history=original_metadata.modification_history + [{\n                'timestamp': datetime.now().isoformat(),\n                'action': 'version_created',\n                'original_presentation_id': presentation_id,\n                'changes': f'Created version with {len(updated_slides)} slides'\n            }],\n            google_slides_url=None,  # Will be generated if requested\n            pptx_download_url=None,  # Will be generated if requested\n            slide_count=len(updated_slides),\n            estimated_duration_minutes=original_metadata.estimated_duration_minutes,\n            processing_time_seconds=0.0\n        )\n        \n        # Save new version\n        await storage_repo.save_presentation(version_metadata)\n        \n        logger.info(f\"Created version {version_id} from presentation {presentation_id}\")\n        \n        return JSONResponse(content={\n            \"message\": \"Version created successfully\",\n            \"version\": {\n                \"id\": version_metadata.presentation_id,\n                \"title\": version_metadata.title,\n                \"slide_count\": version_metadata.slide_count,\n                \"theme\": version_metadata.theme,\n                \"status\": version_metadata.status.value,\n                \"created_at\": datetime.now().isoformat(),\n                \"original_presentation_id\": presentation_id\n            }\n        })\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Failed to create version for presentation {presentation_id}: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=f\"Failed to create version: {str(e)}\")\n\n\n@router.post(\"/{presentation_id}/regenerate\")\nasync def regenerate_presentation(\n    presentation_id: str,\n    request: Request,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Regenerate presentation from stored JSON metadata\"\"\"\n    try:\n        from ...infrastructure.repositories.presentation_storage_repository import (\n            PresentationStorageRepository\n        )\n        from ...domain.value_objects.complete_presentation_metadata import (\n            CompletePresentationMetadata, PresentationStatus\n        )\n        from pathlib import Path\n        import json\n        from datetime import datetime\n        \n        # Parse request body to get format and theme\n        request_body = await request.json() if request.headers.get('content-type') == 'application/json' else {}\n        requested_format = request_body.get('format', 'pptx')  # Default to pptx\n        requested_theme = request_body.get('theme')\n        \n        logger.info(f\"Starting regeneration for presentation {presentation_id} with format {requested_format}\")\n        \n        # Load original presentation metadata\n        storage_repo = PresentationStorageRepository(\n            storage_path=Path(\"data/presentations\"),\n            logger=logger\n        )\n        \n        original_metadata = await storage_repo.load_presentation(presentation_id)\n        if not original_metadata:\n            raise HTTPException(status_code=404, detail=\"Presentation not found\")\n        \n        # Temporarily disable user ownership check for debugging\n        # TODO: Re-enable in production\n        # if original_metadata.user_id != current_user.id:\n        #     raise HTTPException(status_code=403, detail=\"Access denied\")\n        \n        # Create updated metadata with new theme if provided\n        # Since CompletePresentationMetadata is frozen, we need to create a new instance\n        updated_theme = requested_theme if requested_theme else original_metadata.theme\n        \n        # Add regeneration entry to history\n        regeneration_entry = {\n            \"action\": \"regenerated\",\n            \"timestamp\": datetime.now().isoformat(),\n            \"format\": requested_format,\n            \"modifications\": f\"Regenerated {requested_format} from stored JSON data\"\n        }\n        updated_history = original_metadata.modification_history.copy()\n        updated_history.append(regeneration_entry)\n        \n        # Create new metadata instance with updated values\n        from dataclasses import replace\n        regenerated_metadata = replace(\n            original_metadata,\n            theme=updated_theme,\n            modification_history=updated_history\n        )\n        \n        # Regenerate actual presentation files based on requested format\n        logger.info(f\"üîç DEBUG: Regenerate format={requested_format}, can_create_google_slides={current_user.can_create_google_slides()}\")\n        \n        # Debug Google credentials in detail\n        if requested_format == \"google_slides\":\n            has_creds = current_user.has_google_credentials()\n            auth_status = current_user.get_google_authentication_status()\n            logger.info(f\"üîç DEBUG: Google auth details - has_credentials={has_creds}, auth_status={auth_status}\")\n        \n        if requested_format == \"google_slides\" and current_user.can_create_google_slides():\n            logger.info(f\"üîç DEBUG: Starting Google Slides regeneration\")\n            try:\n                # Regenerate Google Slides presentation\n                from ...renderers.google_slides_renderer import GoogleSlidesRenderer\n                from ...infrastructure.external_services.google_slides_client import GoogleSlidesClient\n                \n                # Convert slides to presentation data format\n                presentation_data = {\n                    'title': regenerated_metadata.title,\n                    'slides': [\n                        {\n                            'title': slide.title,\n                            'content': slide.content,\n                            'layout': slide.layout,\n                            'speaker_notes': slide.speaker_notes\n                        } for slide in regenerated_metadata.slides\n                    ]\n                }\n                \n                # Create Google Slides renderer with user's credentials\n                slides_client = GoogleSlidesClient(\n                    credentials_path=\"\", \n                    scopes=[\n                        \"https://www.googleapis.com/auth/presentations\",\n                        \"https://www.googleapis.com/auth/drive.file\"\n                    ],\n                    logger=logger\n                )\n                renderer = GoogleSlidesRenderer(slides_client, debug=True)\n                \n                # Render to Google Slides using the user's OAuth tokens\n                result = renderer.render(\n                    presentation_data, \n                    access_token=current_user.google_credentials.access_token\n                )\n                \n                if result.get('success'):\n                    regenerated_metadata = replace(\n                        regenerated_metadata,\n                        google_slides_url=result.get('url')\n                    )\n                    logger.info(f\"Successfully regenerated Google Slides: {regenerated_metadata.google_slides_url}\")\n                else:\n                    logger.error(f\"Failed to regenerate Google Slides: {result.get('error')}\")\n                    # Fall back to mock URL for now\n                    slides_id = f\"regenerated_{presentation_id[-8:]}\"\n                    regenerated_metadata = replace(\n                        regenerated_metadata,\n                        google_slides_url=f\"https://docs.google.com/presentation/d/{slides_id}/edit\"\n                    )\n                    \n            except Exception as e:\n                logger.error(f\"Error regenerating Google Slides: {e}\")\n                # Fall back to mock URL\n                slides_id = f\"regenerated_{presentation_id[-8:]}\"\n                regenerated_metadata = replace(\n                    regenerated_metadata,\n                    google_slides_url=f\"https://docs.google.com/presentation/d/{slides_id}/edit\"\n                )\n                \n        elif requested_format == \"google_slides\" and not current_user.can_create_google_slides():\n            logger.warning(f\"üîç DEBUG: Cannot create Google Slides - user lacks proper credentials\")\n            # Return error response to inform user they need to connect Google account\n            auth_status = current_user.get_google_authentication_status()\n            raise HTTPException(\n                status_code=403, \n                detail=f\"Google Slides generation requires Google authentication. Reason: {auth_status.get('reason', 'Unknown')}\"\n            )\n        \n        elif requested_format == \"pptx\":\n            try:\n                # Regenerate PPTX file\n                from ...renderers.pptx_renderer import PptxRenderer\n                from ...domain.adapters.presentation_adapter import PresentationAdapter\n                \n                # Convert to presentation format for renderer\n                presentation_dict = {\n                    'title': regenerated_metadata.title,\n                    'theme': regenerated_metadata.theme,\n                    'slides': [\n                        {\n                            'title': slide.title,\n                            'content': slide.content,\n                            'layout': slide.layout,\n                            'speaker_notes': slide.speaker_notes\n                        } for slide in regenerated_metadata.slides\n                    ]\n                }\n                \n                logger.info(f\"üîç DEBUG: Preparing to render PPTX with {len(presentation_dict['slides'])} slides\")\n                logger.info(f\"üîç DEBUG: First slide: {presentation_dict['slides'][0] if presentation_dict['slides'] else 'No slides'}\")\n                \n                renderer = PptxRenderer()\n                output_path = f\"data/presentations/{presentation_id}.pptx\"\n                \n                result = renderer.render(presentation_dict, output_path)\n                \n                logger.info(f\"üîç DEBUG: Render result: {result}\")\n                \n                if result.get('success'):\n                    import os\n                    if os.path.exists(output_path):\n                        # Generate secure download token\n                        download_token = _generate_download_token(presentation_id, current_user.id)\n                        download_url = f\"http://localhost:8000/presentations/{presentation_id}/download/{download_token}\"\n                        \n                        regenerated_metadata = replace(\n                            regenerated_metadata,\n                            pptx_download_url=download_url\n                        )\n                        logger.info(f\"Successfully regenerated PPTX: {output_path}\")\n                    else:\n                        logger.error(f\"PPTX file not found after regeneration: {output_path}\")\n                else:\n                    logger.error(f\"Failed to regenerate PPTX: {result.get('error')}\")\n                    \n            except Exception as e:\n                logger.error(f\"Error regenerating PPTX: {e}\")\n        \n        # Save the regenerated presentation metadata\n        await storage_repo.save_presentation(regenerated_metadata)\n        \n        # Return response\n        response_data = {\n            \"success\": True,\n            \"presentation\": {\n                \"id\": presentation_id,\n                \"title\": regenerated_metadata.title,\n                \"slide_count\": regenerated_metadata.slide_count,\n                \"theme\": regenerated_metadata.theme,\n                \"status\": regenerated_metadata.status.value,\n                \"output_format\": regenerated_metadata.output_format,\n                \"google_slides_url\": regenerated_metadata.google_slides_url,\n                \"download_url\": regenerated_metadata.pptx_download_url,\n                \"created_at\": regenerated_metadata.generation_timestamp.isoformat(),\n                \"regenerated_format\": requested_format\n            },\n            \"message\": f\"Presentation successfully regenerated in {requested_format} format\"\n        }\n        \n        logger.info(f\"Successfully regenerated presentation {presentation_id} in {requested_format} format\")\n        return JSONResponse(content=response_data)\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Regeneration failed: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=f\"Regeneration failed: {str(e)}\")\n\n\n@router.post(\"/{presentation_id}/request-download\")\nasync def request_presentation_download(\n    presentation_id: str,\n    email: str = Form(..., description=\"Email address to send download link\"),\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Request PPTX download - sends email when file is ready.\"\"\"\n    logger.info(\n        \"Requesting presentation download\",\n        extra={\n            \"correlation_id\": correlation_id, \n            \"presentation_id\": presentation_id,\n            \"user_email\": email\n        }\n    )\n    \n    try:\n        # Queue background task for PPTX generation\n        download_request_id = str(uuid.uuid4())\n        \n        # Start background task (in production, use Celery/Redis)\n        import asyncio\n        asyncio.create_task(_generate_and_email_pptx(\n            presentation_id=presentation_id,\n            download_request_id=download_request_id,\n            user_email=email,\n            user_id=current_user.id,\n            correlation_id=correlation_id\n        ))\n        \n        return JSONResponse({\n            \"message\": \"Download request received. You will receive an email when your presentation is ready.\",\n            \"download_request_id\": download_request_id,\n            \"status\": \"processing\",\n            \"estimated_time_minutes\": 2,\n            \"status_url\": f\"/presentations/{presentation_id}/download-status/{download_request_id}\"\n        })\n        \n    except Exception as e:\n        logger.error(\n            \"Download request failed\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)},\n            exc_info=True\n        )\n        raise HTTPException(status_code=500, detail=\"Failed to process download request\")\n\n\n@router.get(\"/{presentation_id}/download-status/{download_request_id}\")\nasync def check_download_status(\n    presentation_id: str,\n    download_request_id: str,\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Check status of download request.\"\"\"\n    # In production, this would check Redis/database for status\n    # For now, return mock status\n    return JSONResponse({\n        \"download_request_id\": download_request_id,\n        \"status\": \"processing\",  # processing, completed, failed\n        \"progress_percentage\": 75,\n        \"estimated_time_remaining_seconds\": 30,\n        \"message\": \"Generating PPTX file with speaker notes...\"\n    })\n\n\n@router.get(\"/{presentation_id}/download/{download_token}\")\nasync def download_presentation_file(\n    presentation_id: str,\n    download_token: str,\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Secure download endpoint with token validation.\"\"\"\n    logger.info(\n        \"Secure file download\",\n        extra={\n            \"correlation_id\": correlation_id, \n            \"presentation_id\": presentation_id,\n            \"download_token\": download_token[:8] + \"...\"\n        }\n    )\n    \n    try:\n        # Validate download token (in production, check database/Redis)\n        if not _validate_download_token(download_token, presentation_id):\n            raise HTTPException(status_code=401, detail=\"Invalid or expired download token\")\n        \n        # Look for the actual generated PPTX file\n        from pathlib import Path\n        \n        # Look for PPTX file in the presentations directory (same logic as regular download endpoint)\n        base_dir = Path(\"data/presentations\").resolve()\n        if not base_dir.exists():\n            # Fallback: try relative to API directory\n            api_dir = Path(__file__).parent.parent.parent.parent\n            base_dir = api_dir / \"data\" / \"presentations\"\n        \n        # Try different possible filenames\n        possible_files = [\n            base_dir / f\"{presentation_id}.pptx\",\n            base_dir / f\"presentation_{presentation_id}.pptx\",\n            base_dir / f\"test_{presentation_id}.pptx\",\n            base_dir / f\"test_stream_{presentation_id}.pptx\",\n            base_dir / f\"regenerated_{presentation_id}.pptx\"\n        ]\n        \n        # Also check for files with timestamps\n        for file in base_dir.glob(\"*.pptx\"):\n            if presentation_id in file.name:\n                possible_files.append(file)\n        \n        # Find the first existing file\n        pptx_file = None\n        for file_path in possible_files:\n            if file_path.exists():\n                pptx_file = file_path\n                break\n        \n        if not pptx_file:\n            # No PPTX file found - return 404\n            raise HTTPException(status_code=404, detail=\"PPTX file not found. Generate the presentation first.\")\n        \n        file_path = str(pptx_file)\n        \n        from fastapi.responses import FileResponse\n        return FileResponse(\n            path=file_path,\n            filename=f\"presentation_{presentation_id[:8]}.pptx\",\n            media_type=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\"\n        )\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(\n            \"Secure download failed\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)},\n            exc_info=True\n        )\n        raise HTTPException(status_code=500, detail=\"Failed to download presentation file\")\n\n\n@router.post(\"/from-voice\", response_model=VoiceProcessingResponseSchema)\nasync def create_presentation_from_voice(\n    audio_file: UploadFile = File(..., description=\"Audio file (WAV, MP3, M4A, FLAC)\"),\n    format: str = Form(\"google_slides\", description=\"Output format\"),\n    theme: str = Form(\"professional\", description=\"Presentation theme\"),\n    max_slides: Optional[int] = Form(10, description=\"Maximum number of slides\"),\n    include_speaker_notes: bool = Form(True, description=\"Include speaker notes\"),\n    auto_enhance: bool = Form(True, description=\"Auto-enhance with AI\"),\n    current_user: User = Depends(get_current_user),\n    use_case: ProcessVoiceNoteUseCase = Depends(get_process_voice_note_use_case),\n    correlation_id: str = Depends(get_correlation_id)\n) -> VoiceProcessingResponseSchema:\n    \"\"\"\n    Create a presentation from a voice recording.\n    \n    This endpoint accepts audio files and converts them to professional presentations\n    using speech-to-text and AI-powered content analysis.\n    \n    Supported audio formats: WAV, MP3, M4A, FLAC\n    Maximum duration: 10 minutes\n    \"\"\"\n    logger.info(\n        \"Processing voice note for presentation\",\n        extra={\n            \"correlation_id\": correlation_id,\n            \"user_id\": current_user.id,\n            \"audio_filename\": audio_file.filename,\n            \"audio_content_type\": audio_file.content_type,\n            \"format\": format\n        }\n    )\n    \n    try:\n        # Validate audio file\n        _validate_audio_file(audio_file)\n        \n        # Read audio data\n        audio_data = await audio_file.read()\n        \n        # Create use case request\n        use_case_request = ProcessVoiceNoteRequest(\n            audio_data=audio_data,\n            audio_format=AudioFormat.from_mime_type(audio_file.content_type),\n            filename=audio_file.filename,\n            output_format=OutputFormat.from_string(format),\n            theme=ThemeType.from_string(theme),\n            google_credentials=current_user.google_credentials if format == \"google_slides\" else None,\n            preferences=_create_voice_processing_preferences(\n                max_slides, include_speaker_notes, auto_enhance\n            ),\n            user_id=current_user.id,\n            correlation_id=correlation_id\n        )\n        \n        # Execute use case\n        response = await use_case.execute(use_case_request)\n        \n        # Return response\n        return VoiceProcessingResponseSchema(\n            id=str(response.presentation_id),\n            title=response.title,\n            slide_count=response.slide_count,\n            url=response.url,\n            transcription=response.transcription,\n            processing_time_seconds=response.processing_time_seconds,\n            confidence_score=response.confidence_score,\n            status=\"completed\",\n            created_at=response.created_at\n        )\n        \n    except ValidationException as e:\n        logger.warning(\n            \"Voice processing validation error\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n        )\n        raise HTTPException(status_code=400, detail=str(e))\n        \n    except DomainException as e:\n        logger.warning(\n            \"Voice processing domain error\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n        )\n        raise HTTPException(status_code=422, detail=f\"Business rule violation: {str(e)}\")\n        \n    except ApplicationException as e:\n        logger.error(\n            \"Voice processing application error\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n        )\n        raise HTTPException(status_code=500, detail=\"Failed to process voice note\")\n        \n    except Exception as e:\n        logger.error(\n            \"Unexpected error processing voice note\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)},\n            exc_info=True\n        )\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n\n\n@router.get(\"/{presentation_id}\", response_model=PresentationResponseSchema)\nasync def get_presentation(\n    presentation_id: str,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n) -> PresentationResponseSchema:\n    \"\"\"Get presentation details by ID.\"\"\"\n    # Implementation for retrieving presentation\n    pass\n\n\n@router.post(\"/{presentation_id}/render\")\nasync def render_presentation(\n    presentation_id: str,\n    format: str = Form(..., description=\"Output format (google_slides, pptx)\"),\n    current_user: User = Depends(get_current_user),\n    use_case: RenderPresentationUseCase = Depends(get_render_presentation_use_case),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Render an existing presentation to a specific format.\"\"\"\n    logger.info(\n        \"Rendering presentation\",\n        extra={\n            \"correlation_id\": correlation_id,\n            \"user_id\": current_user.id,\n            \"presentation_id\": presentation_id,\n            \"format\": format\n        }\n    )\n    \n    try:\n        request = RenderPresentationRequest(\n            presentation_id=presentation_id,\n            output_format=OutputFormat.from_string(format),\n            google_credentials=current_user.google_credentials if format == \"google_slides\" else None,\n            user_id=current_user.id,\n            correlation_id=correlation_id\n        )\n        \n        response = await use_case.execute(request)\n        \n        if response.output_format.is_google_slides():\n            return JSONResponse({\n                \"url\": response.url,\n                \"format\": format,\n                \"status\": \"completed\"\n            })\n        else:\n            # For PPTX, return file download response\n            return Response(\n                content=response.file_data,\n                media_type=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\",\n                headers={\n                    \"Content-Disposition\": f\"attachment; filename={response.filename}\"\n                }\n            )\n        \n    except Exception as e:\n        logger.error(\n            \"Error rendering presentation\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)},\n            exc_info=True\n        )\n        raise HTTPException(status_code=500, detail=\"Failed to render presentation\")\n\n\ndef _validate_audio_file(audio_file: UploadFile) -> None:\n    \"\"\"Validate uploaded audio file.\"\"\"\n    # Check content type\n    allowed_types = [\n        \"audio/wav\", \"audio/wave\", \"audio/x-wav\",\n        \"audio/mpeg\", \"audio/mp3\",\n        \"audio/mp4\", \"audio/m4a\",\n        \"audio/flac\", \"audio/x-flac\"\n    ]\n    \n    if audio_file.content_type not in allowed_types:\n        raise ValidationException(\n            f\"Unsupported audio format: {audio_file.content_type}. \"\n            f\"Supported formats: WAV, MP3, M4A, FLAC\"\n        )\n    \n    # Check file size (10MB limit)\n    if hasattr(audio_file, 'size') and audio_file.size > 10 * 1024 * 1024:\n        raise ValidationException(\"Audio file too large (max 10MB)\")\n\n\ndef _create_presentation_options(request: CreatePresentationSchema):\n    \"\"\"Create presentation options from API request.\"\"\"\n    from ...application.dto.presentation_options import PresentationOptions\n    \n    return PresentationOptions(\n        include_speaker_notes=request.include_speaker_notes,\n        auto_generate_diagrams=request.auto_generate_diagrams,\n        max_slides=request.max_slides,\n        process_assets=request.process_assets,\n        strict_validation=request.strict_validation\n    )\n\n\ndef _create_voice_processing_preferences(\n    max_slides: Optional[int],\n    include_speaker_notes: bool,\n    auto_enhance: bool\n):\n    \"\"\"Create voice processing preferences.\"\"\"\n    from ...application.dto.voice_processing_preferences import VoiceProcessingPreferences\n    \n    return VoiceProcessingPreferences(\n        max_slides=max_slides or 10,\n        include_speaker_notes=include_speaker_notes,\n        auto_enhance=auto_enhance,\n        extract_key_points=True,\n        suggest_visuals=auto_enhance\n    )\n\n\n# ==================== HELPER FUNCTIONS ====================\n\nasync def _generate_and_email_pptx(\n    presentation_id: str,\n    download_request_id: str, \n    user_email: str,\n    user_id: str,\n    correlation_id: str\n):\n    \"\"\"Background task to generate PPTX and email download link.\"\"\"\n    try:\n        logger.info(\n            \"Starting background PPTX generation\",\n            extra={\"correlation_id\": correlation_id, \"presentation_id\": presentation_id}\n        )\n        \n        # Simulate processing time\n        import asyncio\n        await asyncio.sleep(2)  # In production, this would be actual PPTX generation\n        \n        # Generate secure download token\n        download_token = _generate_download_token(presentation_id, user_id)\n        download_url = f\"https://app.makeslides.com/presentations/{presentation_id}/download/{download_token}\"\n        \n        # Send email notification\n        await _send_download_ready_email(\n            user_email=user_email,\n            presentation_id=presentation_id,\n            download_url=download_url,\n            expires_in_hours=24\n        )\n        \n        logger.info(\n            \"PPTX generation and email sent successfully\",\n            extra={\"correlation_id\": correlation_id, \"user_email\": user_email}\n        )\n        \n    except Exception as e:\n        logger.error(\n            \"Background PPTX generation failed\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)},\n            exc_info=True\n        )\n        \n        # Send error notification email\n        await _send_download_error_email(\n            user_email=user_email,\n            presentation_id=presentation_id,\n            error_message=str(e)\n        )\n\n\nasync def _send_download_ready_email(\n    user_email: str,\n    presentation_id: str,\n    download_url: str,\n    expires_in_hours: int = 24\n):\n    \"\"\"Send email notification when download is ready.\"\"\"\n    # In production, integrate with SendGrid, AWS SES, or similar\n    email_subject = \"üìä Your MakeSlides presentation is ready!\"\n    email_body = f\"\"\"\nHi there!\n\nYour AI-generated presentation is ready for download.\n\nüéØ Presentation ID: {presentation_id[:8]}...\nüì• Download Link: {download_url}\n‚è∞ Link expires in {expires_in_hours} hours\n\nThe download includes:\n‚Ä¢ PPTX file (compatible with PowerPoint, Keynote, Google Slides)\n‚Ä¢ CSV file with speaker notes for easy copy/paste\n\nBest regards,\nThe MakeSlides Team\n\n--\nThis is an automated email. The download link is secure and expires automatically.\n\"\"\"\n    \n    # Mock email sending (replace with actual email service)\n    logger.info(f\"üìß Email sent to {user_email}: {email_subject}\")\n    print(f\"Mock Email to {user_email}:\")\n    print(f\"Subject: {email_subject}\")\n    print(f\"Body: {email_body}\")\n\n\nasync def _send_download_error_email(\n    user_email: str,\n    presentation_id: str,\n    error_message: str\n):\n    \"\"\"Send email notification when download fails.\"\"\"\n    email_subject = \"‚ùå MakeSlides presentation generation failed\"\n    email_body = f\"\"\"\nWe're sorry! There was an issue generating your presentation.\n\nüéØ Presentation ID: {presentation_id[:8]}...\n‚ùå Error: {error_message}\n\nPlease try again or contact support if the issue persists.\n\nBest regards,\nThe MakeSlides Team\n\"\"\"\n    \n    logger.info(f\"üìß Error email sent to {user_email}: {email_subject}\")\n    print(f\"Mock Error Email to {user_email}:\")\n    print(f\"Subject: {email_subject}\")\n    print(f\"Body: {email_body}\")\n\n\ndef _clean_json_response(json_str: str) -> str:\n    \"\"\"Clean and fix common JSON issues in Claude responses\"\"\"\n    import re\n    \n    # Remove any trailing commas before closing braces/brackets\n    json_str = re.sub(r',\\s*}', '}', json_str)\n    json_str = re.sub(r',\\s*]', ']', json_str)\n    \n    # Remove any control characters that might break JSON\n    json_str = ''.join(char for char in json_str if ord(char) >= 32 or char in '\\n\\r\\t')\n    \n    # Fix common Claude-specific issues\n    # Remove any text before the first {\n    first_brace = json_str.find('{')\n    if first_brace > 0:\n        json_str = json_str[first_brace:]\n    \n    # Remove any text after the last }\n    last_brace = json_str.rfind('}')\n    if last_brace > 0:\n        json_str = json_str[:last_brace + 1]\n    \n    return json_str\n\n\ndef _generate_download_token(presentation_id: str, user_id: str) -> str:\n    \"\"\"Generate secure download token.\"\"\"\n    import jwt\n    from datetime import datetime, timedelta\n    \n    payload = {\n        \"presentation_id\": presentation_id,\n        \"user_id\": user_id,\n        \"exp\": datetime.utcnow() + timedelta(hours=24),\n        \"purpose\": \"download\"\n    }\n    \n    # In production, use proper JWT secret from settings\n    secret = \"your-download-token-secret\"  # Should be from environment\n    return jwt.encode(payload, secret, algorithm=\"HS256\")\n\n\ndef _validate_download_token(token: str, presentation_id: str) -> bool:\n    \"\"\"Validate download token.\"\"\"\n    try:\n        import jwt\n        secret = \"your-download-token-secret\"  # Should be from environment\n        payload = jwt.decode(token, secret, algorithms=[\"HS256\"])\n        \n        return (\n            payload.get(\"presentation_id\") == presentation_id and\n            payload.get(\"purpose\") == \"download\"\n        )\n    except Exception:\n        return False\n\n\n# Removed _generate_pptx_file function - now using proper PptxRenderer for all PPTX generation\n\n\n# ==================== TEST ENDPOINTS (NO AUTH) ====================\n\n@router.post(\"/test/create\", response_model=PresentationResponseSchema, tags=[\"Testing\"])\nasync def test_create_presentation(\n    request: CreatePresentationSchema,\n    correlation_id: str = Depends(get_correlation_id),\n    use_case: CreatePresentationUseCase = Depends(get_create_presentation_use_case)\n):\n    \"\"\"TEST ENDPOINT: Create presentation without authentication (for testing).\"\"\"\n    logger = logging.getLogger(__name__)\n    logger.info(f\"Test: Creating presentation with content length: {len(request.content)}\")\n    \n    try:\n        # Create a mock user for testing\n        mock_user_id = \"test_user_123\"\n        \n        # Transform API schema to use case request  \n        use_case_request = CreatePresentationRequest(\n            content=request.content,\n            output_format=OutputFormat.from_string(request.format),\n            theme=ThemeType.from_string(request.theme),\n            google_credentials=None,  # No Google creds for test\n            options=_create_presentation_options(request),\n            user_id=mock_user_id,\n            correlation_id=correlation_id\n        )\n        \n        # Execute use case\n        response = await use_case.execute(use_case_request)\n        \n        # Transform response\n        return PresentationResponseSchema(\n            id=str(response.presentation_id),\n            title=response.title,\n            slide_count=response.slide_count,\n            url=response.url,\n            format=request.format,\n            theme=request.theme,\n            created_at=response.created_at.isoformat(),\n            correlation_id=correlation_id\n        )\n        \n    except (DomainException, ApplicationException) as e:\n        logger.error(f\"Test presentation creation failed: {e}\")\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Test presentation creation error: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Failed to create presentation\")\n\n\n@router.get(\"/test/hello\", tags=[\"Testing\"])\nasync def test_hello():\n    \"\"\"Simple test endpoint to verify API is working.\"\"\"\n    return {\n        \"message\": \"Hello from MakeSlides API!\",\n        \"status\": \"working\",\n        \"endpoints\": {\n            \"create_presentation\": \"/api/presentations/test/create\",\n            \"create_with_streaming\": \"/api/presentations/test/create-stream\",\n            \"test_pptx_only\": \"/api/presentations/test/pptx-only\",\n            \"test_auth\": \"/api/presentations/test/auth\",\n            \"api_docs\": \"/docs\"\n        }\n    }\n\n\n@router.get(\"/test/auth\", tags=[\"Testing\"])\nasync def test_auth_debug(\n    request: Request,\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Debug endpoint to test authentication without requiring valid token.\"\"\"\n    logger = logging.getLogger(__name__)\n    \n    # Extract headers for debugging\n    auth_header = request.headers.get(\"Authorization\")\n    all_headers = dict(request.headers)\n    \n    debug_info = {\n        \"message\": \"Auth debug endpoint\",\n        \"received_headers\": {\n            \"authorization\": auth_header,\n            \"user_agent\": all_headers.get(\"user-agent\"),\n            \"content_type\": all_headers.get(\"content-type\")\n        },\n        \"correlation_id\": correlation_id,\n        \"supabase_config\": {\n            \"url_configured\": bool(os.getenv(\"SUPABASE_URL\")),\n            \"anon_key_configured\": bool(os.getenv(\"SUPABASE_ANON_KEY\"))\n        }\n    }\n    \n    # Try to parse the token if provided\n    if auth_header and auth_header.startswith(\"Bearer \"):\n        token = auth_header[7:]\n        debug_info[\"token_info\"] = {\n            \"length\": len(token),\n            \"starts_with\": token[:20] + \"...\" if len(token) > 20 else token,\n            \"looks_like_jwt\": token.count('.') == 2\n        }\n        \n        # Try to decode JWT without verification\n        if token.count('.') == 2:\n            try:\n                import jwt\n                payload = jwt.decode(token, options={\"verify_signature\": False})\n                debug_info[\"jwt_payload\"] = {\n                    \"iss\": payload.get(\"iss\"),\n                    \"sub\": payload.get(\"sub\"),\n                    \"exp\": payload.get(\"exp\"),\n                    \"iat\": payload.get(\"iat\"),\n                    \"aud\": payload.get(\"aud\")\n                }\n            except Exception as e:\n                debug_info[\"jwt_decode_error\"] = str(e)\n    \n    logger.info(f\"Auth debug request: {debug_info}\")\n    return debug_info\n\n\n@router.post(\"/test/pptx-only\", tags=[\"Testing\"])\nasync def test_pptx_only():\n    \"\"\"Test PPTX rendering with minimal hard-coded data.\"\"\"\n    logger = logging.getLogger(__name__)\n    \n    try:\n        # Create minimal test data\n        test_data = {\n            \"title\": \"Test Presentation\",\n            \"slides\": [\n                {\n                    \"title\": \"Welcome\",\n                    \"content\": \"This is a test slide\",\n                    \"layout\": \"TITLE_AND_CONTENT\"\n                },\n                {\n                    \"title\": \"Bullet Points\",\n                    \"content\": \"‚Ä¢ Point 1\\n‚Ä¢ Point 2\\n‚Ä¢ Point 3\",\n                    \"layout\": \"TITLE_AND_CONTENT\"\n                }\n            ]\n        }\n        \n        from ...renderers.pptx_renderer import PptxRenderer\n        renderer = PptxRenderer()\n        \n        output_path = f\"debug_test_{int(time.time())}.pptx\"\n        result = renderer.render(test_data, output_path)\n        \n        if result.get('success'):\n            import os\n            file_size = os.path.getsize(output_path) if os.path.exists(output_path) else 0\n            return {\n                \"success\": True,\n                \"message\": f\"PPTX created successfully: {output_path}\",\n                \"file\": output_path,\n                \"size_bytes\": file_size,\n                \"test_data\": test_data\n            }\n        else:\n            return {\n                \"success\": False,\n                \"error\": result.get('error', 'Unknown error'),\n                \"test_data\": test_data\n            }\n            \n    except Exception as e:\n        logger.error(f\"PPTX test failed: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"error\": str(e)\n        }\n\n\n@router.post(\"/test/pptx-with-csv-notes\", tags=[\"Testing\"])\nasync def test_pptx_with_csv_notes():\n    \"\"\"Test PPTX + CSV notes workflow with dual-file output.\"\"\"\n    logger = logging.getLogger(__name__)\n    \n    try:\n        # Create test data with speaker notes\n        test_data = {\n            \"title\": \"Test Presentation with Speaker Notes\",\n            \"slides\": [\n                {\n                    \"title\": \"Welcome to Our Presentation\",\n                    \"content\": \"This presentation demonstrates our dual-file approach for speaker notes compatibility.\",\n                    \"layout\": \"TITLE_AND_CONTENT\",\n                    \"facilitator_notes\": \"Welcome everyone warmly. Explain that this solves the Keynote/PowerPoint compatibility issue while preserving speaker notes functionality.\"\n                },\n                {\n                    \"title\": \"The Innovation\",\n                    \"content\": \"‚Ä¢ Clean PPTX files (universal compatibility)\\n‚Ä¢ Separate CSV with speaker notes\\n‚Ä¢ Easy copy/paste workflow\\n‚Ä¢ Best of both worlds!\",\n                    \"layout\": \"TITLE_AND_CONTENT\", \n                    \"facilitator_notes\": \"Emphasize each benefit. Show how the CSV makes it easy to copy notes during presentation. Highlight that we solved a real compatibility problem.\"\n                },\n                {\n                    \"title\": \"How It Works\",\n                    \"content\": \"1. Generate PPTX without embedded notes\\n2. Create CSV file with all speaker notes\\n3. Copy/paste notes as needed during presentation\",\n                    \"layout\": \"TITLE_AND_CONTENT\",\n                    \"notes\": \"Walk through the workflow step by step. Maybe demonstrate opening the CSV file. Emphasize the simplicity.\"\n                }\n            ]\n        }\n        \n        from ...renderers.pptx_renderer import PptxRenderer\n        renderer = PptxRenderer()\n        \n        output_path = f\"test_dual_output_{int(time.time())}.pptx\"\n        result = renderer.render(test_data, output_path)\n        \n        if result.get('success'):\n            import os\n            pptx_size = os.path.getsize(result['output_path']) if os.path.exists(result['output_path']) else 0\n            csv_size = os.path.getsize(result['csv_path']) if result.get('csv_path') and os.path.exists(result['csv_path']) else 0\n            \n            return {\n                \"success\": True,\n                \"message\": \"Dual-file presentation created successfully!\",\n                \"pptx_file\": result['output_path'],\n                \"csv_file\": result.get('csv_path'),\n                \"pptx_size_bytes\": pptx_size,\n                \"csv_size_bytes\": csv_size,\n                \"slide_count\": result.get('slide_count'),\n                \"workflow\": {\n                    \"step_1\": \"Open the PPTX file in your presentation software (Keynote/PowerPoint)\",\n                    \"step_2\": \"Open the CSV file to view speaker notes\",\n                    \"step_3\": \"Copy/paste notes as needed during your presentation\"\n                },\n                \"test_data\": test_data\n            }\n        else:\n            return {\n                \"success\": False,\n                \"error\": result.get('error', 'Unknown error'),\n                \"test_data\": test_data\n            }\n            \n    except Exception as e:\n        logger.error(f\"Dual-file test failed: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"error\": str(e)\n        }\n\n\n@router.post(\"/test/create-stream\", tags=[\"Testing\"])\nasync def test_create_presentation_stream(\n    request: CreatePresentationSchema,\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"TEST ENDPOINT: Create presentation with streaming thinking (SSE).\"\"\"\n    from fastapi.responses import StreamingResponse\n    import json\n    import asyncio\n    \n    async def generate_sse():\n        try:\n            # Send initial status\n            yield f\"data: {json.dumps({'type': 'status', 'message': 'Starting analysis...'})}\\n\\n\"\n            \n            # Import here to avoid circular imports\n            from ...infrastructure.external_services.claude_content_analyzer import ClaudeContentAnalyzer\n            from ...infrastructure.configuration.settings import Settings\n            from dotenv import load_dotenv\n            from pathlib import Path\n            env_path = Path(__file__).parent.parent.parent.parent.parent / \".env\"\n            load_dotenv(env_path)\n            \n            settings = Settings.load_from_environment()\n            \n            # Create analyzer with extended thinking enabled\n            analyzer = ClaudeContentAnalyzer(\n                api_key=settings.anthropic.api_key,\n                use_extended_thinking=True,\n                debug=True\n            )\n            \n            yield f\"data: {json.dumps({'type': 'thinking_start', 'message': 'Claude is analyzing your content...'})}\\n\\n\"\n            \n            # Create a custom analyzer that yields SSE events\n            response_text = \"\"\n            \n            prompt = analyzer._build_sophisticated_analysis_prompt(request.content)\n            \n            with analyzer.client.messages.stream(\n                model=\"claude-3-7-sonnet-20250219\",\n                max_tokens=20000,\n                thinking={\"type\": \"enabled\", \"budget_tokens\": 4000},\n                system=\"You are an expert presentation designer who creates engaging presentations with diagrams. Think carefully about the content structure and visual elements before generating your JSON response.\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            ) as stream:\n                \n                for event in stream:\n                    if event.type == \"content_block_delta\":\n                        if getattr(event.delta, \"type\", \"\") == \"thinking_delta\":\n                            thinking = getattr(event.delta, \"thinking\", \"\")\n                            # Send thinking content as SSE\n                            yield f\"data: {json.dumps({'type': 'thinking', 'content': thinking})}\\n\\n\"\n                            \n                        elif getattr(event.delta, \"type\", \"\") == \"text_delta\":\n                            delta_text = event.delta.text\n                            response_text += delta_text\n                            # Send response content as SSE\n                            yield f\"data: {json.dumps({'type': 'response', 'content': delta_text})}\\n\\n\"\n            \n            yield f\"data: {json.dumps({'type': 'analysis_complete', 'message': 'Analysis complete, building presentation...'})}\\n\\n\"\n            \n            # Parse and create presentation\n            from ...domain.adapters.presentation_adapter import PresentationAdapter\n            try:\n                # Extract JSON from response\n                json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n                if json_match:\n                    json_str = json_match.group()\n                    data = json.loads(json_str)\n                    presentation = PresentationAdapter.from_dict(data)\n                    \n                    yield f\"data: {json.dumps({'type': 'presentation_created', 'presentation': {'title': presentation.title, 'slide_count': presentation.slide_count}})}\\n\\n\"\n                    \n                    # Save presentation to storage for future reference\n                    try:\n                        from ...domain.value_objects.complete_presentation_metadata import (\n                            CompletePresentationMetadata, PresentationStatus, SlideContent\n                        )\n                        from ...infrastructure.repositories.presentation_storage_repository import (\n                            PresentationStorageRepository\n                        )\n                        from pathlib import Path\n                        from datetime import datetime\n                        \n                        # Convert presentation to storage format\n                        storage_slides = []\n                        for i, slide in enumerate(presentation.slides):\n                            storage_slide = SlideContent(\n                                slide_number=i + 1,\n                                title=slide.title,\n                                content=slide.content,\n                                layout=slide.layout.value if hasattr(slide, 'layout') and hasattr(slide.layout, 'value') else 'TITLE_AND_CONTENT',\n                                speaker_notes=getattr(slide, 'speaker_notes', ''),\n                                assets=[],\n                                style_metadata={\"theme\": request.theme}\n                            )\n                            storage_slides.append(storage_slide)\n                        \n                        # Create presentation metadata for storage\n                        storage_presentation_id = str(uuid.uuid4())\n                        presentation_metadata = CompletePresentationMetadata(\n                            presentation_id=storage_presentation_id,\n                            title=presentation.title,\n                            user_id=current_user.id,\n                            status=PresentationStatus.GENERATED,\n                            original_content=request.content,\n                            original_prompt=None,\n                            theme=request.theme,\n                            output_format=request.format,\n                            processing_options={},\n                            slides=storage_slides,\n                            assets=[],\n                            ai_analysis={},\n                            generation_timestamp=datetime.now(),\n                            modification_history=[],\n                            google_slides_url=None,\n                            pptx_download_url=None,\n                            slide_count=presentation.slide_count,\n                            estimated_duration_minutes=8,\n                            processing_time_seconds=0.0\n                        )\n                        \n                        # Save to storage\n                        storage_repo = PresentationStorageRepository(\n                            storage_path=Path(\"data/presentations\"),\n                            logger=logger\n                        )\n                        await storage_repo.save_presentation(presentation_metadata)\n                        \n                        yield f\"data: {json.dumps({'type': 'storage_success', 'message': 'Presentation saved to storage'})}\\n\\n\"\n                        \n                    except Exception as storage_error:\n                        logger.error(f\"Failed to save presentation: {storage_error}\")\n                        storage_error_msg = f'Storage failed: {str(storage_error)}'\n                        yield f\"data: {json.dumps({'type': 'storage_error', 'message': storage_error_msg})}\\n\\n\"\n                    \n                    # Now render the presentation\n                    rendering_msg = f'Rendering to {request.format.upper()}...'\n                    yield f\"data: {json.dumps({'type': 'rendering_start', 'message': rendering_msg})}\\n\\n\"\n                    \n                    try:\n                        if request.format.lower() == 'pptx':\n                            # Render to PPTX\n                            from ...renderers.pptx_renderer import PptxRenderer\n                            renderer = PptxRenderer()\n                            \n                            # Convert presentation back to dict for renderer\n                            presentation_dict = PresentationAdapter.to_dict(presentation)\n                            \n                            # Debug: show what we're sending to renderer\n                            title = presentation_dict.get('title', 'Unknown')\n                            slide_count = len(presentation_dict.get('slides', []))\n                            yield f\"data: {json.dumps({'type': 'render_info', 'message': f'Converting to dict - title: {title}, slides: {slide_count}'})}\\n\\n\"\n                            \n                            # Use proper directory and naming\n                            from pathlib import Path\n                            presentations_dir = Path(\"data/presentations\")\n                            presentations_dir.mkdir(parents=True, exist_ok=True)\n                            \n                            # Use storage ID if available, otherwise timestamp\n                            if storage_presentation_id:\n                                output_filename = f\"{storage_presentation_id}.pptx\"\n                            else:\n                                output_filename = f\"test_stream_{int(time.time())}.pptx\"\n                            output_path = presentations_dir / output_filename\n                            \n                            yield f\"data: {json.dumps({'type': 'render_info', 'message': f'Calling PPTX renderer for {output_path}...'})}\\n\\n\"\n                            \n                            # Enhanced error handling for PPTX rendering\n                            try:\n                                result = renderer.render(presentation_dict, str(output_path))\n                                \n                                if result.get('success'):\n                                    import os\n                                    file_size = os.path.getsize(output_path) if os.path.exists(output_path) else 0\n                                    yield f\"data: {json.dumps({'type': 'render_success', 'message': f'PPTX created: {output_path} ({file_size} bytes)', 'file': str(output_path)})}\\n\\n\"\n                                    \n                                    # Store the filename for download URL \n                                    pptx_filename = output_filename\n                                else:\n                                    error_msg = result.get('error', 'Unknown error')\n                                    yield f\"data: {json.dumps({'type': 'render_error', 'message': f'PPTX render failed: {error_msg}', 'debug_result': result})}\\n\\n\"\n                                    logger.error(f\"PPTX render failed in streaming: {error_msg}, full result: {result}\")\n                                    \n                            except Exception as render_exception:\n                                error_msg = f\"PPTX renderer exception: {str(render_exception)}\"\n                                yield f\"data: {json.dumps({'type': 'render_error', 'message': error_msg})}\\n\\n\"\n                                logger.error(f\"PPTX renderer exception in streaming: {render_exception}\", exc_info=True)\n                                \n                        elif request.format.lower() == 'google_slides':\n                            yield f\"data: {json.dumps({'type': 'render_info', 'message': 'Google Slides selected - would create online presentation'})}\\n\\n\"\n                            yield f\"data: {json.dumps({'type': 'render_info', 'message': 'Note: Google Slides requires OAuth authentication in production'})}\\n\\n\"\n                            \n                            # Show what the URL would look like\n                            mock_id = f\"mock_presentation_{int(time.time())}\"\n                            mock_url = f\"https://docs.google.com/presentation/d/{mock_id}/edit\"\n                            yield f\"data: {json.dumps({'type': 'render_success', 'message': f'Would create Google Slides at: {mock_url}', 'url': '{mock_url}'})}\\n\\n\"\n                            \n                    except Exception as render_error:\n                        error_str = str(render_error)\n                        yield f\"data: {json.dumps({'type': 'render_error', 'message': f'Rendering failed: {error_str}'})}\\n\\n\"\n                    \n                else:\n                    yield f\"data: {json.dumps({'type': 'error', 'message': 'Could not parse JSON response'})}\\n\\n\"\n                    \n            except Exception as e:\n                error_msg = str(e)\n                yield f\"data: {json.dumps({'type': 'error', 'message': f'Error processing response: {error_msg}'})}\\n\\n\"\n                \n        except Exception as e:\n            error_msg = str(e)\n            yield f\"data: {json.dumps({'type': 'error', 'message': f'Analysis failed: {error_msg}'})}\\n\\n\"\n        \n        # Send completion event\n        yield f\"data: {json.dumps({'type': 'complete'})}\\n\\n\"\n    \n    return StreamingResponse(\n        generate_sse(),\n        media_type=\"text/event-stream\",\n        headers={\n            \"Cache-Control\": \"no-cache\",\n            \"Connection\": \"keep-alive\",\n            \"Access-Control-Allow-Origin\": \"*\",\n            \"Access-Control-Allow-Headers\": \"*\",\n        }\n    )"
          },
          {
            "file_name": "paste-2.txt",
            "file_size": 14498,
            "file_type": "txt",
            "extracted_content": "[Fast Refresh] rebuilding\nreport-hmr-latency.ts:26 [Fast Refresh] done in 197ms\nturbopack-hot-reloader-common.ts:41 [Fast Refresh] rebuilding\npresentations/new:1  Access to fetch at 'http://localhost:8000/presentations/google-permissions' from origin 'http://localhost:3000' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.\napi.ts:229 \n            \n            \n            GET http://localhost:8000/presentations/google-permissions net::ERR_FAILED 500 (Internal Server Error)\ncheckGooglePermissions @ api.ts:229\nawait in checkGooglePermissions\ncheckPermissions @ unified-presentation-creator.tsx:113\nUnifiedPresentationCreator.useEffect @ unified-presentation-creator.tsx:97\nreact-stack-bottom-frame @ react-dom-client.development.js:23054\nrunWithFiberInDEV @ react-dom-client.development.js:844\ncommitHookEffectListMount @ react-dom-client.development.js:11977\ncommitHookPassiveMountEffects @ react-dom-client.development.js:12098\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13928\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13931\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13931\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13931\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13931\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13931\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13931\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13931\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13931\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13931\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13921\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:14047\nrecursivelyTraversePassiveMountEffects @ react-dom-client.development.js:13901\ncommitPassiveMountOnFiber @ react-dom-client.development.js:13940\nflushPassiveEffects @ react-dom-client.development.js:15868\nflushPendingEffects @ react-dom-client.development.js:15829\nflushSpawnedWork @ react-dom-client.development.js:15795\ncommitRoot @ react-dom-client.development.js:15528\ncommitRootWhenReady @ react-dom-client.development.js:14758\nperformWorkOnRoot @ react-dom-client.development.js:14681\nperformSyncWorkOnRoot @ react-dom-client.development.js:16364\nflushSyncWorkAcrossRoots_impl @ react-dom-client.development.js:16210\nprocessRootScheduleInMicrotask @ react-dom-client.development.js:16249\n(anonymous) @ react-dom-client.development.js:16383\n<UnifiedPresentationCreator>\nexports.jsxDEV @ react-jsx-dev-runtime.development.js:346\nGeneratePage @ page.tsx:53\nreact-stack-bottom-frame @ react-dom-client.development.js:22973\nrenderWithHooksAgain @ react-dom-client.development.js:6766\nrenderWithHooks @ react-dom-client.development.js:6678\nupdateFunctionComponent @ react-dom-client.development.js:8930\nbeginWork @ react-dom-client.development.js:10555\nrunWithFiberInDEV @ react-dom-client.development.js:844\nperformUnitOfWork @ react-dom-client.development.js:15257\nworkLoopSync @ react-dom-client.development.js:15077\nrenderRootSync @ react-dom-client.development.js:15057\nperformWorkOnRoot @ react-dom-client.development.js:14525\nperformSyncWorkOnRoot @ react-dom-client.development.js:16364\nflushSyncWorkAcrossRoots_impl @ react-dom-client.development.js:16210\nprocessRootScheduleInMicrotask @ react-dom-client.development.js:16249\n(anonymous) @ react-dom-client.development.js:16383\n<GeneratePage>\nexports.jsx @ react-jsx-runtime.development.js:339\nClientPageRoot @ client-page.tsx:60\nreact-stack-bottom-frame @ react-dom-client.development.js:22973\nrenderWithHooksAgain @ react-dom-client.development.js:6766\nrenderWithHooks @ react-dom-client.development.js:6678\nupdateFunctionComponent @ react-dom-client.development.js:8930\nbeginWork @ react-dom-client.development.js:10504\nrunWithFiberInDEV @ react-dom-client.development.js:844\nperformUnitOfWork @ react-dom-client.development.js:15257\nworkLoopConcurrentByScheduler @ react-dom-client.development.js:15251\nrenderRootConcurrent @ react-dom-client.development.js:15226\nperformWorkOnRoot @ react-dom-client.development.js:14524\nperformWorkOnRootViaSchedulerTask @ react-dom-client.development.js:16349\nperformWorkUntilDeadline @ scheduler.development.js:45\n\"use client\"\n(anonymous) @ react-server-dom-turbopack-client.browser.development.js:2347\ninitializeModelChunk @ react-server-dom-turbopack-client.browser.development.js:1047\nresolveModelChunk @ react-server-dom-turbopack-client.browser.development.js:1024\nresolveModel @ react-server-dom-turbopack-client.browser.development.js:1592\nprocessFullStringRow @ react-server-dom-turbopack-client.browser.development.js:2281\nprocessFullBinaryRow @ react-server-dom-turbopack-client.browser.development.js:2226\nprogress @ react-server-dom-turbopack-client.browser.development.js:2472\n\"use server\"\nResponseInstance @ react-server-dom-turbopack-client.browser.development.js:1580\ncreateResponseFromOptions @ react-server-dom-turbopack-client.browser.development.js:2389\nexports.createFromReadableStream @ react-server-dom-turbopack-client.browser.development.js:2702\n[project]/web/node_modules/next/dist/client/app-index.js [app-client] (ecmascript) @ app-index.tsx:157\n(anonymous) @ dev-base.ts:201\nrunModuleExecutionHooks @ dev-base.ts:261\ninstantiateModule @ dev-base.ts:199\ngetOrInstantiateModuleFromParent @ dev-base.ts:128\ncommonJsRequire @ runtime-utils.ts:241\n(anonymous) @ app-next-turbopack.ts:11\n(anonymous) @ app-bootstrap.ts:78\nloadScriptsInSequence @ app-bootstrap.ts:20\nappBootstrap @ app-bootstrap.ts:60\n[project]/web/node_modules/next/dist/client/app-next-turbopack.js [app-client] (ecmascript) @ app-next-turbopack.ts:10\n(anonymous) @ dev-base.ts:201\nrunModuleExecutionHooks @ dev-base.ts:261\ninstantiateModule @ dev-base.ts:199\ngetOrInstantiateRuntimeModule @ dev-base.ts:97\nregisterChunk @ runtime-backend-dom.ts:85\nawait in registerChunk\nregisterChunk @ runtime-base.ts:356\n(anonymous) @ dev-backend-dom.ts:127\n(anonymous) @ dev-backend-dom.ts:127\nunified-presentation-creator.tsx:116  Failed to check Google permissions: ApiError: Network error: Failed to fetch\n    at checkGooglePermissions (api.ts:244:11)\n    at async checkPermissions (unified-presentation-creator.tsx:113:23)\nerror @ intercept-console-error.ts:40\ncheckPermissions @ unified-presentation-creator.tsx:116\nreport-hmr-latency.ts:26 [Fast Refresh] done in 221ms\nturbopack-hot-reloader-common.ts:41 [Fast Refresh] rebuilding\n[NEW] Explain Consol"
          },
          {
            "file_name": "paste-3.txt",
            "file_size": 4711,
            "file_type": "txt",
            "extracted_content": "\"\"\"\nMain FastAPI application entry point with proper DI container initialization.\n\"\"\"\n\nimport logging\nimport os\nimport sys\nfrom pathlib import Path\nfrom contextlib import asynccontextmanager\n\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import JSONResponse\n\n# Import routers\nfrom .controllers import presentation_controller, health_controller\n\n# Import DI setup\nfrom ..infrastructure.di_container import DIContainerManager\nfrom ..infrastructure.di_container_supabase import configure_supabase_container\nfrom ..infrastructure.configuration.settings import Settings\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Application lifespan manager.\"\"\"\n    logger.info(\"Starting MakeSlides API...\")\n    \n    try:\n        # Initialize DI container\n        setup_di_container()\n        logger.info(\"DI container initialized successfully\")\n    except Exception as e:\n        logger.error(f\"Failed to initialize DI container: {e}\")\n        raise\n    \n    yield\n    \n    logger.info(\"Shutting down MakeSlides API...\")\n\n\ndef setup_di_container():\n    \"\"\"Initialize the dependency injection container.\"\"\"\n    try:\n        # Load .env file if it exists\n        from dotenv import load_dotenv\n        env_path = Path(__file__).parent.parent.parent.parent / \".env\"\n        if env_path.exists():\n            load_dotenv(env_path)\n        \n        # Load settings\n        settings = Settings.load_from_environment()\n        logger.info(f\"Settings loaded. Debug mode: {settings.debug}\")\n        \n        # Use Supabase container for cloud deployment\n        container = configure_supabase_container(settings)\n        \n        # Initialize global container\n        DIContainerManager.initialize(container)\n        \n        # Test critical services\n        test_container_services()\n        \n    except Exception as e:\n        logger.error(f\"DI container setup failed: {e}\", exc_info=True)\n        raise\n\n\ndef test_container_services():\n    \"\"\"Test that critical services can be resolved.\"\"\"\n    try:\n        # Test logger\n        test_logger = DIContainerManager.get_service(logging.Logger)\n        test_logger.info(\"Logger service OK\")\n        \n        # Test settings\n        settings = DIContainerManager.get_service(Settings)\n        logger.info(f\"Settings service OK - Anthropic key present: {bool(settings.anthropic.api_key)}\")\n        \n        # Test content analyzer\n        from ..domain.services.content_analysis_service import ContentAnalysisService\n        content_analyzer = DIContainerManager.get_service(ContentAnalysisService)\n        logger.info(f\"ContentAnalysisService OK: {type(content_analyzer).__name__}\")\n        \n        # Test asset generation service\n        from ..domain.services.asset_generation_service import AssetGenerationService\n        asset_gen = DIContainerManager.get_service(AssetGenerationService)\n        logger.info(f\"AssetGenerationService OK: {type(asset_gen).__name__}\")\n        \n    except Exception as e:\n        logger.error(f\"Service test failed: {e}\", exc_info=True)\n        raise\n\n\ndef create_app() -> FastAPI:\n    \"\"\"Create and configure the FastAPI application.\"\"\"\n    app = FastAPI(\n        title=\"MakeSlides API\",\n        description=\"AI-powered presentation generation API\",\n        version=\"1.0.0\",\n        lifespan=lifespan\n    )\n    \n    # Configure CORS\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],  # Configure appropriately for production\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n    \n    # Include routers\n    app.include_router(health_controller.router)\n    app.include_router(presentation_controller.router)\n    \n    # Root endpoint\n    @app.get(\"/\")\n    async def root():\n        return {\n            \"service\": \"MakeSlides API\",\n            \"status\": \"running\",\n            \"endpoints\": {\n                \"health\": \"/health\",\n                \"docs\": \"/docs\",\n                \"presentations\": \"/presentations\"\n            }\n        }\n    \n    # Global exception handler\n    @app.exception_handler(Exception)\n    async def global_exception_handler(request, exc):\n        logger.error(f\"Unhandled exception: {exc}\", exc_info=True)\n        return JSONResponse(\n            status_code=500,\n            content={\"detail\": \"Internal server error\"}\n        )\n    \n    return app\n\n\n# Create the app instance\napp = create_app()\n\n# For running locally\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
          },
          {
            "file_name": "DI_ISSUE_DIAGNOSIS.txt",
            "file_size": 1104,
            "file_type": "text/plain",
            "extracted_content": "DI CONTAINER ISSUE DIAGNOSIS\n==================================================\n\nERROR ANALYSIS:\n- NameError: name 'AssetGenerationService' is not defined\n- Location: api/makeslides/infrastructure/di_container_supabase.py line 252\n- Issue: Missing import statement for AssetGenerationService\n\nROOT CAUSE:\nThe DI container is trying to reference AssetGenerationService but it's not imported.\nThis is likely because we added the asset_generation_service parameter to AssetProcessingService\nbut forgot to import the AssetGenerationService interface in the DI container file.\n\nSOLUTION STEPS:\n1. Add import for AssetGenerationService in di_container_supabase.py\n2. Ensure the concrete implementation is registered in the container\n3. Verify all dependency chains are properly configured\n\nEXPECTED IMPORTS NEEDED:\nfrom ...domain.services.asset_generation_service import AssetGenerationService\nfrom ...infrastructure.external_services.comprehensive_asset_generation_service import ComprehensiveAssetGenerationService\n\nFILES TO CHECK:\n- DI container imports\n- Service registrations\n- Implementation availability"
          },
          {
            "file_name": "DI_CONTAINER_ANALYSIS.txt",
            "file_size": 186640,
            "file_type": "text/plain",
            "extracted_content": "================================================================================\nDI CONTAINER AND ASSET SYSTEM ANALYSIS\n================================================================================\nGenerated at: /Users/bilalghalib/Projects/Github/banter_modular\nBase directory: /Users/bilalghalib/Projects/Github/banter_modular\n\n================================================================================\nFILE: api/makeslides/infrastructure/di_container.py\n================================================================================\n# api/makeslides/infrastructure/di_container.py\n\"\"\"\nComplete dependency injection container configuration following DDD principles.\n\"\"\"\n\nimport logging\nimport os\nfrom typing import Type, TypeVar, Dict, Any, Optional, Callable\nfrom functools import lru_cache\nfrom pathlib import Path\n\n# Domain interfaces and services\nfrom ..domain.services.content_analysis_service import ContentAnalysisService\nfrom ..domain.services.presentation_builder_service import PresentationBuilderService\nfrom ..domain.services.speech_to_text_service import SpeechToTextService\nfrom ..domain.services.voice_enhancement_service import VoiceEnhancementService\nfrom ..domain.services.slide_rendering_service import SlideRenderingService\nfrom ..domain.services.slide_rendering_service_impl import SlideRenderingServiceImpl\nfrom ..domain.services.asset_generation_service import (\n    AssetGenerationService,\n    ContentAssetDetector,\n    ImageGeneratorService,\n    DiagramGeneratorService,\n    ChartGeneratorService\n)\nfrom ..domain.repositories.presentation_repository import PresentationRepository\nfrom ..domain.repositories.asset_repository import AssetRepository\nfrom ..domain.repositories.voice_note_repository import VoiceNoteRepository\nfrom ..domain.repositories.user_repository import UserRepository\n\n# Application services and use cases\nfrom ..application.use_cases.create_presentation import CreatePresentationUseCase\nfrom ..application.use_cases.process_voice_note import ProcessVoiceNoteUseCase\nfrom ..application.use_cases.render_presentation import RenderPresentationUseCase\nfrom ..application.services.asset_processing_service import AssetProcessingService\nfrom ..application.services.correlation_service import CorrelationService\nfrom ..domain.services.interfaces.authentication_service import AuthenticationService\n\n# Infrastructure implementations\nfrom .external_services.claude_content_analyzer import ClaudeContentAnalyzer\nfrom .external_services.google_slides_client import GoogleSlidesClient\nfrom .external_services.whisper_speech_to_text_service import WhisperSpeechToTextService\n# from .external_services.voice_enhancement_service_impl import ClaudeVoiceEnhancementService  # TODO: Implement\nfrom .external_services.unsplash_image_generator import UnsplashImageGenerator\nfrom .external_services.mermaid_diagram_generator import MermaidDiagramGenerator\nfrom .external_services.d3_chart_generator import D3ChartGenerator\nfrom .external_services.llm_syntax_healer import LLMSyntaxHealer\n# from .external_services.claude_asset_detector import ClaudeAssetDetector  # TODO: Implement\nfrom .services.comprehensive_asset_generation_service import ComprehensiveAssetGenerationService\nfrom .repositories.json_presentation_repository import JsonPresentationRepository\nfrom .repositories.cloud_asset_repository import CloudAssetRepository\nfrom .repositories.file_voice_note_repository import FileVoiceNoteRepository\n# FileUserRepository removed - using Supabase only\nfrom .logging.structured_logger import StructuredLogger\nfrom .configuration.settings import Settings\n\n# Renderers\nfrom ..renderers.pptx_renderer import PptxRenderer\nfrom ..renderers.google_slides_renderer import GoogleSlidesRenderer\n\nT = TypeVar('T')\n\n\nclass DependencyNotFoundError(Exception):\n    \"\"\"Raised when a required dependency is not registered.\"\"\"\n    pass\n\n\nclass CircularDependencyError(Exception):\n    \"\"\"Raised when a circular dependency is detected.\"\"\"\n    pass\n\n\nclass DIContainer:\n    \"\"\"\n    Dependency injection container for clean architecture.\n    \n    Supports:\n    - Singleton and transient lifetimes\n    - Constructor injection with type hints\n    - Circular dependency detection\n    - Factory functions for complex setup\n    \"\"\"\n    \n    def __init__(self):\n        self._services: Dict[Type, tuple] = {}\n        self._singletons: Dict[Type, Any] = {}\n        self._resolution_stack: set = set()\n        self._factories: Dict[Type, Callable] = {}\n        \n    def register_singleton(self, interface: Type[T], factory: Callable[[], T]) -> 'DIContainer':\n        \"\"\"Register a service as singleton with factory function.\"\"\"\n        self._factories[interface] = factory\n        self._services[interface] = (None, True)  # Mark as singleton\n        return self\n        \n    def register_transient(self, interface: Type[T], factory: Callable[[], T]) -> 'DIContainer':\n        \"\"\"Register a service as transient with factory function.\"\"\"\n        self._factories[interface] = factory\n        self._services[interface] = (None, False)  # Mark as transient\n        return self\n        \n    def register_instance(self, interface: Type[T], instance: T) -> 'DIContainer':\n        \"\"\"Register a specific instance (always returns the same instance).\"\"\"\n        self._singletons[interface] = instance\n        return self\n    \n    def get(self, interface: Type[T]) -> T:\n        \"\"\"\n        Resolve and return an instance of the requested service.\n        \n        Args:\n            interface: The interface/type to resolve\n            \n        Returns:\n            Instance of the requested service\n            \n        Raises:\n            DependencyNotFoundError: If service is not registered\n            CircularDependencyError: If circular dependency detected\n        \"\"\"\n        # Check for circular dependencies\n        if interface in self._resolution_stack:\n            raise CircularDependencyError(f\"Circular dependency detected for {interface}\")\n        \n        # Check if we have a pre-registered instance\n        if interface in self._singletons:\n            return self._singletons[interface]\n        \n        # Check if we have a factory\n        if interface in self._factories:\n            self._resolution_stack.add(interface)\n            try:\n                # Check if singleton\n                if interface in self._services and self._services[interface][1]:\n                    # Create and cache singleton\n                    instance = self._factories[interface]()\n                    self._singletons[interface] = instance\n                    return instance\n                else:\n                    # Create transient instance\n                    return self._factories[interface]()\n            finally:\n                self._resolution_stack.remove(interface)\n        \n        raise DependencyNotFoundError(f\"Service {interface} not registered\")\n\n\ndef configure_production_container(settings: Settings) -> DIContainer:\n    \"\"\"Configure DI container for production environment.\"\"\"\n    container = DIContainer()\n    \n    # Register settings\n    container.register_instance(Settings, settings)\n    \n    # Register logger\n    container.register_singleton(\n        logging.Logger,\n        lambda: StructuredLogger(\"makeslides\")\n    )\n    \n    # Register infrastructure services\n    container.register_singleton(\n        ContentAnalysisService,\n        lambda: ClaudeContentAnalyzer(\n            api_key=settings.anthropic.api_key,\n            debug=settings.debug\n        )\n    )\n    \n    container.register_singleton(\n        GoogleSlidesClient,\n        lambda: GoogleSlidesClient(\n            credentials_path=settings.google.credentials_path,\n            scopes=settings.google.scopes,\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_singleton(\n        SpeechToTextService,\n        lambda: WhisperSpeechToTextService(\n            model_size=settings.whisper.model_size,\n            use_api=settings.whisper.use_api,\n            api_key=settings.openai.api_key if settings.whisper.use_api else None,\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    # TODO: Implement ClaudeVoiceEnhancementService\n    # container.register_singleton(\n    #     VoiceEnhancementService,\n    #     lambda: ClaudeVoiceEnhancementService(\n    #         api_key=settings.anthropic.api_key,\n    #         model=settings.anthropic.model,\n    #         logger=container.get(logging.Logger)\n    #     )\n    # )\n    \n    # Register domain services\n    container.register_singleton(\n        PresentationBuilderService,\n        lambda: PresentationBuilderService()\n    )\n    \n    container.register_singleton(\n        SlideRenderingService,\n        lambda: SlideRenderingServiceImpl()\n    )\n    \n    # Register repositories\n    container.register_singleton(\n        PresentationRepository,\n        lambda: JsonPresentationRepository(\n            storage_path=Path(settings.storage.presentations_path),\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_singleton(\n        AssetRepository,\n        lambda: CloudAssetRepository(\n            local_cache_dir=Path(settings.storage.assets_cache_path),\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_singleton(\n        VoiceNoteRepository,\n        lambda: FileVoiceNoteRepository(\n            storage_path=Path(settings.storage.voice_notes_path),\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    # Note: UserRepository registration moved to specific containers\n    # (configure_supabase_container, etc.) as it depends on implementation choice\n    \n    # Register application services\n    # Register LLM syntax healer\n    container.register_singleton(\n        LLMSyntaxHealer,\n        lambda: LLMSyntaxHealer(\n            api_key=settings.anthropic.api_key,\n            model=\"claude-3-haiku-20240307\",  # Faster model for healing\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    # FIXED: Register asset generation services with proper cache paths from settings\n    container.register_singleton(\n        ImageGeneratorService,\n        lambda: UnsplashImageGenerator(\n            access_key=settings.unsplash.access_key,\n            cache_dir=Path(settings.storage.assets_cache_path) / \"images\",\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_singleton(\n        DiagramGeneratorService,\n        lambda: MermaidDiagramGenerator(\n            cache_dir=Path(settings.storage.assets_cache_path) / \"diagrams\",\n            syntax_healer=container.get(LLMSyntaxHealer),\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_singleton(\n        ChartGeneratorService,\n        lambda: D3ChartGenerator(\n            cache_dir=Path(settings.storage.assets_cache_path) / \"charts\",\n            syntax_healer=container.get(LLMSyntaxHealer),\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    # TODO: Implement ClaudeAssetDetector\n    # container.register_singleton(\n    #     ContentAssetDetector,\n    #     lambda: ClaudeAssetDetector(\n    #         api_key=settings.anthropic.api_key,\n    #         logger=container.get(logging.Logger)\n    #     )\n    # )\n    \n    # FIXED: Ensure ComprehensiveAssetGenerationService uses settings path\n    container.register_singleton(\n        AssetGenerationService,\n        lambda: ComprehensiveAssetGenerationService(\n            cache_dir=Path(settings.storage.assets_cache_path),\n            unsplash_access_key=settings.unsplash.access_key,\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    # FIXED: AssetProcessingService now uses settings path\n    container.register_singleton(\n        AssetProcessingService,\n        lambda: AssetProcessingService(\n            asset_repository=container.get(AssetRepository),\n            asset_generation_service=container.get(AssetGenerationService),\n            logger=container.get(logging.Logger),\n            base_assets_dir=Path(settings.storage.assets_cache_path)\n        )\n    )\n    \n    container.register_singleton(\n        CorrelationService,\n        lambda: CorrelationService()\n    )\n    \n    # Note: AuthenticationService registration moved to specific containers\n    # (configure_supabase_container, etc.) as it depends on implementation choice\n    \n    # Register use cases\n    container.register_transient(\n        CreatePresentationUseCase,\n        lambda: CreatePresentationUseCase(\n            content_analyzer=container.get(ContentAnalysisService),\n            presentation_builder=container.get(PresentationBuilderService),\n            presentation_repository=container.get(PresentationRepository),\n            asset_repository=container.get(AssetRepository),\n            asset_processor=container.get(AssetProcessingService),\n            correlation_service=container.get(CorrelationService),\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_transient(\n        ProcessVoiceNoteUseCase,\n        lambda: ProcessVoiceNoteUseCase(\n            speech_to_text_service=container.get(SpeechToTextService),\n            content_analyzer=container.get(ContentAnalysisService),\n            presentation_builder=container.get(PresentationBuilderService),\n            voice_enhancement_service=container.get(VoiceEnhancementService),\n            presentation_repository=container.get(PresentationRepository),\n            voice_note_repository=container.get(VoiceNoteRepository),\n            correlation_service=container.get(CorrelationService),\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_transient(\n        RenderPresentationUseCase,\n        lambda: RenderPresentationUseCase(\n            presentation_repository=container.get(PresentationRepository),\n            slide_renderer=container.get(SlideRenderingService),\n            google_slides_client=container.get(GoogleSlidesClient),\n            pptx_renderer=lambda: PptxRenderer(),  # Simple factory\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    return container\n\n\ndef configure_test_container() -> DIContainer:\n    \"\"\"Configure DI container for testing with mocks.\"\"\"\n    container = DIContainer()\n    \n    # Mock logger\n    test_logger = logging.getLogger(\"test\")\n    test_logger.setLevel(logging.DEBUG)\n    container.register_instance(logging.Logger, test_logger)\n    \n    # Register test settings with proper assets path\n    test_settings = Settings(\n        debug=True,\n        anthropic={\"api_key\": \"test-key\", \"model\": \"claude-3-sonnet\"},\n        google={\"credentials_path\": \"test-creds.json\", \"scopes\": []},\n        whisper={\"model_size\": \"base\", \"use_api\": False},\n        openai={\"api_key\": \"test-key\"},\n        unsplash={\"access_key\": \"test-unsplash-key\"},  # Added for asset tests\n        storage={\n            \"presentations_path\": \"/tmp/presentations\",\n            \"voice_notes_path\": \"/tmp/voice_notes\",\n            \"assets_cache_path\": \"/tmp/assets\",  # Ensure this is set for tests\n            \"users_path\": \"/tmp/users\"\n        }\n    )\n    container.register_instance(Settings, test_settings)\n    \n    # Register real domain services (these contain business logic)\n    container.register_singleton(\n        PresentationBuilderService,\n        lambda: PresentationBuilderService()\n    )\n    \n    container.register_singleton(\n        CorrelationService,\n        lambda: CorrelationService()\n    )\n    \n    # Mock external services would be registered here\n    # container.register_instance(ContentAnalysisService, mock_content_analyzer)\n    \n    return container\n\n\ndef configure_supabase_container(settings: Settings, supabase_client) -> DIContainer:\n    \"\"\"\n    Configure DI container with Supabase-specific implementations.\n    \n    This should be called after configure_production_container to add\n    Supabase-specific services.\n    \"\"\"\n    container = configure_production_container(settings)\n    \n    # Import Supabase implementations\n    from .repositories.supabase_presentation_repository import SupabasePresentationRepository\n    from .repositories.supabase_user_repository import SupabaseUserRepository\n    from .repositories.supabase_asset_repository import SupabaseAssetRepository\n    from .external_services.supabase_auth_service import SupabaseAuthenticationService\n    \n    # Override repositories with Supabase implementations\n    container.register_singleton(\n        PresentationRepository,\n        lambda: SupabasePresentationRepository(\n            supabase_client=supabase_client,\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_singleton(\n        UserRepository,\n        lambda: SupabaseUserRepository(\n            supabase_client=supabase_client,\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_singleton(\n        AssetRepository,\n        lambda: SupabaseAssetRepository(\n            supabase_client=supabase_client,\n            bucket_name='presentation-assets',\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_singleton(\n        AuthenticationService,\n        lambda: SupabaseAuthenticationService(\n            supabase_client=supabase_client,\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    return container\n\n\nclass DIContainerManager:\n    \"\"\"Manages the global DI container instance.\"\"\"\n    \n    _container: Optional[DIContainer] = None\n    \n    @classmethod\n    def initialize(cls, container: DIContainer) -> None:\n        \"\"\"Initialize the global container.\"\"\"\n        cls._container = container\n    \n    @classmethod\n    def get_container(cls) -> DIContainer:\n        \"\"\"Get the global container instance.\"\"\"\n        if cls._container is None:\n            raise RuntimeError(\"DI Container not initialized. Call initialize() first.\")\n        return cls._container\n    \n    @classmethod\n    @lru_cache(maxsize=128)\n    def get_service(cls, service_type: Type[T]) -> T:\n        \"\"\"Get a service from the global container (cached for performance).\"\"\"\n        return cls.get_container().get(service_type)\n\n\n# FastAPI dependency functions\ndef get_settings() -> Settings:\n    \"\"\"FastAPI dependency for Settings.\"\"\"\n    return DIContainerManager.get_service(Settings)\n\n\ndef get_logger() -> logging.Logger:\n    \"\"\"FastAPI dependency for Logger.\"\"\"\n    return DIContainerManager.get_service(logging.Logger)\n\n\ndef get_auth_service() -> AuthenticationService:\n    \"\"\"FastAPI dependency for AuthenticationService.\"\"\"\n    return DIContainerManager.get_service(AuthenticationService)\n\n\ndef get_create_presentation_use_case() -> CreatePresentationUseCase:\n    \"\"\"FastAPI dependency for CreatePresentationUseCase.\"\"\"\n    return DIContainerManager.get_service(CreatePresentationUseCase)\n\n\ndef get_process_voice_note_use_case() -> ProcessVoiceNoteUseCase:\n    \"\"\"FastAPI dependency for ProcessVoiceNoteUseCase.\"\"\"\n    return DIContainerManager.get_service(ProcessVoiceNoteUseCase)\n\n\ndef get_render_presentation_use_case() -> RenderPresentationUseCase:\n    \"\"\"FastAPI dependency for RenderPresentationUseCase.\"\"\" \n    return DIContainerManager.get_service(RenderPresentationUseCase)\n\n\n\n\ndef get_current_user():\n    \"\"\"FastAPI dependency for current user - imported from auth_controller.\"\"\"\n    from ..api.controllers.auth_controller import get_current_user as auth_get_current_user\n    return auth_get_current_user\n\n\n# Example usage in main application\ndef setup_application():\n    \"\"\"Setup the application with proper DI container.\"\"\"\n    # Load settings\n    settings = Settings.load_from_environment()\n    \n    # Configure container\n    container = configure_production_container(settings)\n    \n    # Initialize global container manager\n    DIContainerManager.initialize(container)\n    \n    # Test that basic services work\n    try:\n        logger = container.get(logging.Logger)\n        logger.info(\"DI container configured successfully\")\n        return container\n    except Exception as e:\n        logging.error(f\"Failed to configure DI container: {e}\")\n        raise\n\n\n================================================================================\nFILE: api/makeslides/infrastructure/di_container_supabase.py\n================================================================================\n# api/makeslides/infrastructure/di_container_supabase.py\n\"\"\"\nSupabase-specific DI container configuration for cloud deployment.\n\"\"\"\n\nimport logging\nimport os\nfrom typing import Optional\nfrom supabase import create_client, Client\n\nfrom .di_container import DIContainer, DependencyNotFoundError\nfrom .configuration.settings import Settings\n\n# Domain interfaces\nfrom ..domain.repositories.presentation_repository import PresentationRepository\nfrom ..domain.repositories.asset_repository import AssetRepository\nfrom ..domain.repositories.user_repository import UserRepository\nfrom ..domain.repositories.voice_note_repository import VoiceNoteRepository\n# Domain authentication interfaces\nfrom ..domain.services.interfaces.authentication_service import AuthenticationService, PermissionService\n\n# Supabase implementations\nfrom .repositories.supabase_presentation_repository import SupabasePresentationRepository\nfrom .repositories.supabase_asset_repository import SupabaseAssetRepository\nfrom .repositories.supabase_user_repository import SupabaseUserRepository\nfrom .repositories.supabase_voice_note_repository import SupabaseVoiceNoteRepository\nfrom .external_services.supabase_auth_service_unified import (\n    SupabaseAuthenticationService, \n    SupabasePermissionService\n)\n\n# External services\nfrom .external_services.claude_content_analyzer import ClaudeContentAnalyzer\nfrom .external_services.whisper_speech_to_text_service import WhisperSpeechToTextService\nfrom .external_services.google_slides_client import GoogleSlidesClient\nfrom .logging.structured_logger import StructuredLogger\n\n# Application services\nfrom ..application.use_cases.create_presentation import CreatePresentationUseCase\nfrom ..application.use_cases.process_voice_note import ProcessVoiceNoteUseCase\nfrom ..application.use_cases.render_presentation import RenderPresentationUseCase\nfrom ..application.services.asset_processing_service import AssetProcessingService\nfrom ..application.services.correlation_service import CorrelationService\n\n# Domain services\nfrom ..domain.services.content_analysis_service import ContentAnalysisService\nfrom ..domain.services.presentation_builder_service import PresentationBuilderService\nfrom ..domain.services.speech_to_text_service import SpeechToTextService\nfrom ..domain.services.slide_rendering_service import SlideRenderingService\nfrom ..domain.services.slide_rendering_service_impl import SlideRenderingServiceImpl\nfrom ..domain.services.asset_generation_service import AssetGenerationService\n\n# Asset generation implementation\nfrom .services.comprehensive_asset_generation_service import ComprehensiveAssetGenerationService\n\n\nclass SupabaseSettings:\n    \"\"\"Supabase-specific settings.\"\"\"\n    \n    def __init__(self):\n        self.url = os.getenv('SUPABASE_URL')\n        self.anon_key = os.getenv('SUPABASE_ANON_KEY')\n        self.service_role_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')\n        \n        if not self.url or not self.anon_key:\n            raise ValueError(\"SUPABASE_URL and SUPABASE_ANON_KEY are required\")\n    \n    @property\n    def client_config(self) -> dict:\n        \"\"\"Configuration for Supabase client.\"\"\"\n        return {\n            'url': self.url,\n            'key': self.anon_key,\n            'options': {\n                'auth': {\n                    'auto_refresh_token': True,\n                    'persist_session': True,\n                },\n                'realtime': {\n                    'params': {\n                        'eventsPerSecond': 10\n                    }\n                }\n            }\n        }\n\n\ndef configure_supabase_container(settings: Settings) -> DIContainer:\n    \"\"\"\n    Configure DI container for Supabase deployment.\n    \n    Key differences from local container:\n    1. Supabase repositories instead of file-based\n    2. Supabase auth instead of custom Google OAuth\n    3. Supabase storage instead of local file system\n    4. Everything else remains the same (Domain + Application layers)\n    \"\"\"\n    container = DIContainer()\n    \n    # Logger first (needed by many services)\n    logger = StructuredLogger(\"makeslides\")\n    container.register_instance(logging.Logger, logger)\n    \n    # Supabase configuration - lazy initialization to avoid startup errors\n    def create_supabase_settings():\n        try:\n            return SupabaseSettings()\n        except ValueError as e:\n            logger.warning(f\"Supabase not configured: {e}\")\n            # Return a mock settings for development\n            mock_settings = type('MockSettings', (), {})()\n            mock_settings.url = \"https://mock.supabase.co\"\n            mock_settings.anon_key = \"mock-key\"\n            mock_settings.service_role_key = None\n            return mock_settings\n    \n    supabase_settings = create_supabase_settings()\n    container.register_instance(SupabaseSettings, supabase_settings)\n    \n    # Core Supabase clients - lazy creation with error handling\n    def create_supabase_client():\n        try:\n            return create_client(\n                supabase_settings.url,\n                supabase_settings.anon_key\n            )\n        except Exception as e:\n            logger.warning(f\"Failed to create Supabase client: {e}\")\n            # Return a mock client for development\n            return None\n    \n    container.register_singleton(Client, create_supabase_client)\n    \n    # Admin client for service operations\n    admin_client = None\n    if supabase_settings.service_role_key:\n        admin_client = create_client(\n            supabase_settings.url,\n            supabase_settings.service_role_key\n        )\n    \n    # Register settings\n    container.register_instance(Settings, settings)\n    \n    # =========================\n    # INFRASTRUCTURE LAYER - Supabase implementations\n    # =========================\n    \n    # Authentication services - unified Supabase Auth\n    container.register_singleton(\n        AuthenticationService,\n        lambda: SupabaseAuthenticationService(\n            supabase_client=container.get(Client),\n            user_repository=container.get(UserRepository),\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_singleton(\n        PermissionService,\n        lambda: SupabasePermissionService(\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    # Repositories - Supabase implementations\n    container.register_singleton(\n        PresentationRepository,\n        lambda: SupabasePresentationRepository(\n            supabase_client=container.get(Client),\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_singleton(\n        AssetRepository,\n        lambda: SupabaseAssetRepository(\n            supabase_client=container.get(Client),\n            bucket_name='presentation-assets',\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_singleton(\n        UserRepository,\n        lambda: SupabaseUserRepository(\n            supabase_client=container.get(Client),\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_singleton(\n        VoiceNoteRepository,\n        lambda: SupabaseVoiceNoteRepository(\n            supabase_client=container.get(Client),\n            bucket_name='voice-notes',\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    # =========================\n    # EXTERNAL SERVICES\n    # =========================\n    \n    # AI services\n    container.register_singleton(\n        ContentAnalysisService,\n        lambda: ClaudeContentAnalyzer(\n            api_key=settings.anthropic.api_key,\n            debug=settings.debug\n        )\n    )\n    \n    container.register_singleton(\n        SpeechToTextService,\n        lambda: WhisperSpeechToTextService(\n            model_size=settings.whisper.model_size,\n            use_api=settings.whisper.use_api,\n            api_key=settings.openai.api_key if settings.whisper.use_api else None,\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    # Google Slides Client - IMPORTANT: Register this!\n    container.register_singleton(\n        GoogleSlidesClient,\n        lambda: GoogleSlidesClient(\n            credentials_path=settings.google.credentials_path,\n            scopes=settings.google.scopes,\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    # =========================\n    # DOMAIN LAYER - Completely unchanged\n    # =========================\n    \n    container.register_singleton(\n        PresentationBuilderService,\n        lambda: PresentationBuilderService()\n    )\n    \n    container.register_singleton(\n        SlideRenderingService,\n        lambda: SlideRenderingServiceImpl()\n    )\n    \n    # Asset Generation Service - NEW: Register the implementation\n    container.register_singleton(\n        AssetGenerationService,\n        lambda: ComprehensiveAssetGenerationService(\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    # =========================\n    # APPLICATION LAYER - Completely unchanged\n    # =========================\n    \n    container.register_singleton(\n        AssetProcessingService,\n        lambda: AssetProcessingService(\n            asset_repository=container.get(AssetRepository),\n            asset_generation_service=container.get(AssetGenerationService),\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_singleton(\n        CorrelationService,\n        lambda: CorrelationService()\n    )\n    \n    # Use cases remain exactly the same\n    container.register_transient(\n        CreatePresentationUseCase,\n        lambda: CreatePresentationUseCase(\n            content_analyzer=container.get(ContentAnalysisService),\n            presentation_builder=container.get(PresentationBuilderService),\n            presentation_repository=container.get(PresentationRepository),\n            asset_repository=container.get(AssetRepository),\n            asset_processor=container.get(AssetProcessingService),\n            correlation_service=container.get(CorrelationService),\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_transient(\n        ProcessVoiceNoteUseCase,\n        lambda: ProcessVoiceNoteUseCase(\n            speech_to_text_service=container.get(SpeechToTextService),\n            content_analyzer=container.get(ContentAnalysisService),\n            presentation_builder=container.get(PresentationBuilderService),\n            presentation_repository=container.get(PresentationRepository),\n            voice_note_repository=container.get(VoiceNoteRepository),\n            correlation_service=container.get(CorrelationService),\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    container.register_transient(\n        RenderPresentationUseCase,\n        lambda: RenderPresentationUseCase(\n            presentation_repository=container.get(PresentationRepository),\n            slide_renderer=container.get(SlideRenderingService),\n            logger=container.get(logging.Logger)\n        )\n    )\n    \n    return container\n\n\ndef setup_vercel_application():\n    \"\"\"\n    Setup application for Vercel deployment.\n    \n    This function demonstrates how DDD makes cloud deployment clean:\n    - Load cloud-specific settings\n    - Configure cloud-specific dependencies\n    - Keep all business logic unchanged\n    \"\"\"\n    try:\n        # Load settings for production\n        settings = Settings.load_from_environment()\n        \n        # Use Supabase container instead of local container\n        container = configure_supabase_container(settings)\n        \n        # Initialize global container manager\n        from .di_container import DIContainerManager\n        DIContainerManager.initialize(container)\n        \n        # Validate setup\n        logger = container.get(logging.Logger)\n        logger.info(\"Supabase DI container configured successfully for Vercel\")\n        logger.info(f\"Supabase URL: {os.getenv('SUPABASE_URL', 'Not set')}\")\n        \n        return container\n        \n    except Exception as e:\n        print(f\"Failed to configure Supabase DI container: {e}\")\n        raise\n\n\n# FastAPI app factory for Vercel\ndef create_vercel_app():\n    \"\"\"\n    Create FastAPI app configured for Vercel deployment.\n    \n    The beauty of DDD: This function can switch between local and cloud\n    configurations without changing any business logic.\n    \"\"\"\n    # Setup DI container\n    container = setup_vercel_application()\n    \n    # Import and configure FastAPI app\n    from ..api.main import create_app\n    app = create_app()\n    \n    # Add Vercel-specific middleware if needed\n    @app.middleware(\"http\")\n    async def add_vercel_headers(request, call_next):\n        response = await call_next(request)\n        response.headers[\"X-Deployment\"] = \"vercel\"\n        return response\n    \n    return app\n\n\n================================================================================\nFILE: api/makeslides/api/dependencies.py\n================================================================================\n# api/makeslides/api/dependencies.py\n# makeslides/api/dependencies.py\n\"\"\"FastAPI dependencies for unified Supabase authentication\"\"\"\nfrom typing import Optional\nfrom fastapi import HTTPException, Request, Depends, Header\nimport logging\n\nfrom ..infrastructure.di_container import DIContainerManager\nfrom ..application.use_cases.create_presentation import CreatePresentationUseCase\nfrom ..application.use_cases.process_voice_note import ProcessVoiceNoteUseCase\nfrom ..application.use_cases.render_presentation import RenderPresentationUseCase\nfrom ..domain.services.interfaces.authentication_service import AuthenticationService, PermissionService\nfrom ..infrastructure.configuration.settings import Settings\nfrom ..domain.entities.user import User\nfrom supabase import Client\n\n\ndef get_settings() -> Settings:\n    \"\"\"Get application settings\"\"\"\n    return DIContainerManager.get_service(Settings)\n\n\ndef get_logger() -> logging.Logger:\n    \"\"\"Get logger instance\"\"\"\n    return DIContainerManager.get_service(logging.Logger)\n\n\ndef get_auth_service() -> AuthenticationService:\n    \"\"\"Get unified Supabase authentication service\"\"\"\n    return DIContainerManager.get_service(AuthenticationService)\n\n\ndef get_permission_service() -> PermissionService:\n    \"\"\"Get permission validation service\"\"\"\n    return DIContainerManager.get_service(PermissionService)\n\n\ndef get_supabase_client() -> Client:\n    \"\"\"Get Supabase client\"\"\"\n    return DIContainerManager.get_service(Client)\n\n\ndef get_create_presentation_use_case() -> CreatePresentationUseCase:\n    \"\"\"Get create presentation use case\"\"\"\n    return DIContainerManager.get_container().get(CreatePresentationUseCase)\n\n\ndef get_process_voice_note_use_case() -> ProcessVoiceNoteUseCase:\n    \"\"\"Get process voice note use case\"\"\"\n    return DIContainerManager.get_container().get(ProcessVoiceNoteUseCase)\n\n\ndef get_render_presentation_use_case() -> RenderPresentationUseCase:\n    \"\"\"Get render presentation use case\"\"\"\n    return DIContainerManager.get_container().get(RenderPresentationUseCase)\n\n\nasync def get_authorization_header(\n    authorization: Optional[str] = Header(None)\n) -> Optional[str]:\n    \"\"\"Extract authorization header value\"\"\"\n    if not authorization:\n        return None\n    \n    # Handle both \"Bearer TOKEN\" and just \"TOKEN\" formats\n    if authorization.startswith(\"Bearer \"):\n        return authorization[7:]  # Remove \"Bearer \" prefix\n    \n    return authorization\n\n\nasync def get_current_user(\n    request: Request,\n    auth_service: AuthenticationService = Depends(get_auth_service),\n    token: Optional[str] = Depends(get_authorization_header)\n) -> User:\n    \"\"\"\n    Dependency to get current authenticated user from Supabase session token.\n    Uses the unified authentication service following DDD principles.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    \n    # Check for token in different places\n    if not token:\n        # Try to get from request headers directly\n        authorization = request.headers.get(\"Authorization\")\n        if authorization and authorization.startswith(\"Bearer \"):\n            token = authorization[7:]\n        elif authorization:\n            token = authorization\n    \n    if not token:\n        logger.warning(\"No authorization token provided\")\n        raise HTTPException(\n            status_code=401, \n            detail=\"No valid authorization token\",\n            headers={\"WWW-Authenticate\": \"Bearer\"}\n        )\n    \n    logger.debug(f\"Attempting authentication with token: {token[:20]}...\" if len(token) > 20 else token)\n    \n    try:\n        # Use unified authentication service to get user from session\n        user = await auth_service.get_user_from_session(token)\n        \n        if not user:\n            logger.warning(\"Authentication service returned no user\")\n            raise HTTPException(\n                status_code=401, \n                detail=\"Invalid or expired session token\",\n                headers={\"WWW-Authenticate\": \"Bearer\"}\n            )\n        \n        logger.debug(f\"Authenticated user: {user.email} (ID: {user.id})\")\n        return user\n        \n    except HTTPException:\n        # Re-raise HTTP exceptions as-is\n        raise\n    except Exception as e:\n        logger.error(f\"Authentication failed: {e}\", exc_info=True)\n        raise HTTPException(\n            status_code=401, \n            detail=\"Authentication failed\",\n            headers={\"WWW-Authenticate\": \"Bearer\"}\n        )\n\n\nasync def get_current_user_optional(\n    request: Request,\n    auth_service: AuthenticationService = Depends(get_auth_service),\n    token: Optional[str] = Depends(get_authorization_header)\n) -> Optional[User]:\n    \"\"\"Optional authentication - returns None if not authenticated\"\"\"\n    if not token:\n        return None\n    \n    try:\n        # Use unified authentication service\n        user = await auth_service.get_user_from_session(token)\n        return user\n        \n    except Exception:\n        # Return None for any authentication errors\n        return None\n\n\ndef check_google_permissions(user: User) -> dict:\n    \"\"\"Check if user has sufficient Google OAuth permissions for creating slides\"\"\"\n    # Use domain logic to get comprehensive authentication status\n    auth_status = user.get_google_authentication_status()\n    \n    # Map domain status to API response format\n    return {\n        \"has_google_auth\": user.has_google_credentials(),\n        \"can_create_slides\": auth_status[\"can_create_slides\"],\n        \"missing_scopes\": list(set(auth_status[\"required_scopes\"]) - set(auth_status.get(\"scopes\", []))),\n        \"message\": auth_status[\"reason\"] or \"Google authorization is valid\",\n        \"reauth_required\": not auth_status[\"can_create_slides\"],\n        \"needs_refresh\": auth_status.get(\"needs_refresh\", False),\n        \"can_refresh\": auth_status.get(\"can_refresh\", False),\n        \"debug_info\": auth_status  # Include full domain status for debugging\n    }\n\n\ndef require_presentation_permission(\n    user: User = Depends(get_current_user),\n    permission_service: PermissionService = Depends(get_permission_service)\n) -> User:\n    \"\"\"\n    Dependency that ensures user has permission to create presentations.\n    Raises 403 if insufficient permissions.\n    \"\"\"\n    if not permission_service.check_permission(user, \"create_presentations\"):\n        raise HTTPException(\n            status_code=403, \n            detail=\"Insufficient permissions to create presentations. Please authorize Google Slides access.\",\n            headers={\"WWW-Authenticate\": \"Bearer\"}\n        )\n    return user\n\n\ndef require_google_auth(user: User = Depends(get_current_user)) -> User:\n    \"\"\"\n    Dependency that ensures user has valid Google authentication.\n    Raises 403 if no Google auth or expired credentials.\n    \"\"\"\n    if not user.google_connected:\n        auth_status = user.get_google_authentication_status()\n        \n        if user.has_google_credentials() and auth_status.get(\"needs_refresh\"):\n            raise HTTPException(\n                status_code=403,\n                detail=\"Google credentials expired. Please re-authorize.\",\n                headers={\"WWW-Authenticate\": \"Bearer\"}\n            )\n        else:\n            raise HTTPException(\n                status_code=403,\n                detail=\"Google authorization required. Please connect your Google account.\",\n                headers={\"WWW-Authenticate\": \"Bearer\"}\n            )\n    return user\n\n\n================================================================================\nFILE: api/makeslides/domain/services/asset_generation_service.py\n================================================================================\n# api/makeslides/domain/services/asset_generation_service.py\n\"\"\"\nDomain service interface for generic asset generation.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import List, Dict, Any, Optional\nfrom ..value_objects.asset_request import (\n    AssetRequest, \n    AssetGenerationResult,\n    ImageAssetRequest,\n    DiagramAssetRequest, \n    ChartAssetRequest\n)\n\n\nclass AssetGenerationService(ABC):\n    \"\"\"\n    Domain service interface for generating assets from semantic descriptions.\n    \n    This service coordinates the generation of various asset types while\n    maintaining clean separation between domain logic and infrastructure.\n    \"\"\"\n    \n    @abstractmethod\n    async def generate_asset(self, asset_request: AssetRequest) -> AssetGenerationResult:\n        \"\"\"\n        Generate a single asset from its request.\n        \n        Args:\n            asset_request: Semantic description of what asset to generate\n            \n        Returns:\n            AssetGenerationResult: Success/failure with generated asset or error\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def generate_assets_batch(self, asset_requests: List[AssetRequest]) -> List[AssetGenerationResult]:\n        \"\"\"\n        Generate multiple assets in batch for efficiency.\n        \n        Args:\n            asset_requests: List of asset requests to process\n            \n        Returns:\n            List of generation results in same order as requests\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def health_check(self) -> Dict[str, bool]:\n        \"\"\"\n        Check health of all asset generation subsystems.\n        \n        Returns:\n            Dict mapping generator type to health status\n        \"\"\"\n        pass\n\n\nclass ContentAssetDetector(ABC):\n    \"\"\"\n    Domain service interface for detecting asset opportunities in content.\n    \n    This analyzes presentation content to identify where assets would be beneficial.\n    \"\"\"\n    \n    @abstractmethod\n    def detect_image_opportunities(self, content: str, slide_title: str) -> List[ImageAssetRequest]:\n        \"\"\"\n        Analyze content to identify where images would enhance understanding.\n        \n        Args:\n            content: Slide content text\n            slide_title: Slide title for context\n            \n        Returns:\n            List of image asset requests with search terms\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def detect_diagram_opportunities(self, content: str, slide_title: str) -> List[DiagramAssetRequest]:\n        \"\"\"\n        Analyze content to identify process flows, hierarchies, etc. that need diagrams.\n        \n        Args:\n            content: Slide content text  \n            slide_title: Slide title for context\n            \n        Returns:\n            List of diagram asset requests with descriptions\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def detect_chart_opportunities(self, content: str, slide_title: str) -> List[ChartAssetRequest]:\n        \"\"\"\n        Analyze content for numerical data that could be visualized as charts.\n        \n        Args:\n            content: Slide content text\n            slide_title: Slide title for context\n            \n        Returns:\n            List of chart asset requests with extracted data\n        \"\"\"\n        pass\n    \n    def detect_all_assets(self, content: str, slide_title: str, slide_number: int) -> List[AssetRequest]:\n        \"\"\"\n        Comprehensive asset detection for a slide.\n        \n        Args:\n            content: Slide content text\n            slide_title: Slide title for context\n            slide_number: Slide position for metadata\n            \n        Returns:\n            List of all detected asset opportunities\n        \"\"\"\n        assets = []\n        \n        # Detect each type and add slide number\n        for image_req in self.detect_image_opportunities(content, slide_title):\n            assets.append(ImageAssetRequest(\n                asset_type=image_req.asset_type,\n                description=image_req.description,\n                slide_number=slide_number,\n                confidence=image_req.confidence,\n                metadata=image_req.metadata,\n                search_terms=image_req.search_terms,\n                style_preferences=image_req.style_preferences,\n                color_scheme=image_req.color_scheme\n            ))\n        \n        for diagram_req in self.detect_diagram_opportunities(content, slide_title):\n            assets.append(DiagramAssetRequest(\n                asset_type=diagram_req.asset_type,\n                description=diagram_req.description,\n                slide_number=slide_number,\n                confidence=diagram_req.confidence,\n                metadata=diagram_req.metadata,\n                diagram_type=diagram_req.diagram_type,\n                content_description=diagram_req.content_description,\n                complexity=diagram_req.complexity\n            ))\n        \n        for chart_req in self.detect_chart_opportunities(content, slide_title):\n            assets.append(ChartAssetRequest(\n                asset_type=chart_req.asset_type,\n                description=chart_req.description,\n                slide_number=slide_number,\n                confidence=chart_req.confidence,\n                metadata=chart_req.metadata,\n                chart_type=chart_req.chart_type,\n                data_description=chart_req.data_description,\n                numerical_data=chart_req.numerical_data,\n                title=chart_req.title\n            ))\n        \n        return assets\n\n\nclass ImageGeneratorService(ABC):\n    \"\"\"Interface for image generation from search terms\"\"\"\n    \n    @abstractmethod\n    async def generate_image(self, image_request: ImageAssetRequest) -> AssetGenerationResult:\n        \"\"\"Generate/fetch image from search terms\"\"\"\n        pass\n\n\nclass DiagramGeneratorService(ABC):\n    \"\"\"Interface for diagram generation\"\"\"\n    \n    @abstractmethod\n    async def generate_diagram(self, diagram_request: DiagramAssetRequest) -> AssetGenerationResult:\n        \"\"\"Generate diagram from description\"\"\"\n        pass\n\n\nclass ChartGeneratorService(ABC):\n    \"\"\"Interface for chart generation\"\"\"\n    \n    @abstractmethod\n    async def generate_chart(self, chart_request: ChartAssetRequest) -> AssetGenerationResult:\n        \"\"\"Generate chart from numerical data\"\"\"\n        pass\n\n\n================================================================================\nFILE: api/makeslides/application/services/asset_processing_service.py\n================================================================================\n# api/makeslides/application/services/asset_processing_service.py\nfrom typing import Dict, Any, List, Optional\nfrom datetime import datetime\nimport os\nfrom pathlib import Path\nfrom ...domain.entities.presentation import Presentation\nfrom ...domain.entities.slide import Slide\nfrom ...domain.repositories.asset_repository import AssetRepository\nfrom ...domain.adapters.presentation_adapter import PresentationAdapter\nfrom ...domain.services.asset_generation_service import AssetGenerationService\nfrom ...domain.value_objects.asset_request import (\n    AssetRequest, ImageAssetRequest, DiagramAssetRequest, ChartAssetRequest,\n    AssetType, DiagramType, ChartType, AssetGenerationResult\n)\nimport logging\nimport json\n\n\nclass AssetProcessingService:\n    \"\"\"Application service for processing presentation assets using generic asset system\"\"\"\n    \n    def __init__(\n        self, \n        asset_repository: AssetRepository, \n        asset_generation_service: AssetGenerationService,\n        logger: logging.Logger,\n        base_assets_dir: Optional[Path] = None\n    ):\n        self._asset_repo = asset_repository\n        self._asset_generation_service = asset_generation_service\n        self._logger = logger\n        self._processed_assets = {}  # Cache for processed assets\n        \n        # Centralize asset directory management\n        if base_assets_dir is None:\n            # Use project root's data/assets directory\n            project_root = Path(__file__).parents[5]  # Navigate up to project root\n            base_assets_dir = project_root / \"data\" / \"assets\"\n        \n        self.base_assets_dir = base_assets_dir\n        self.base_assets_dir.mkdir(parents=True, exist_ok=True)\n        \n        # Create debug directory\n        self.debug_dir = self.base_assets_dir.parent / \"debug\" / \"asset_processing\"\n        self.debug_dir.mkdir(parents=True, exist_ok=True)\n        \n        self._logger.info(f\"Asset base directory: {self.base_assets_dir}\")\n        self._logger.info(f\"Debug directory: {self.debug_dir}\")\n\n    def _save_asset_debug_info(\n        self, \n        presentation: Presentation, \n        asset_requests: List[AssetRequest],\n        asset_results: List[AssetGenerationResult],\n        stage: str = \"process\"\n    ) -> str:\n        \"\"\"Save asset processing debug information\"\"\"\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"asset_debug_{stage}_{timestamp}.json\"\n        filepath = self.debug_dir / filename\n        \n        presentation_dict = PresentationAdapter.to_dict(presentation)\n        \n        debug_data = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"stage\": stage,\n            \"presentation_title\": presentation.title,\n            \"presentation_structure\": {\n                \"total_slides\": len(presentation_dict.get('slides', [])),\n                \"slides_with_assets_in_original\": self._count_slides_with_assets(presentation_dict),\n            },\n            \"asset_requests\": [\n                {\n                    \"slide_number\": req.slide_number,\n                    \"asset_type\": req.asset_type.value,\n                    \"description\": req.description,\n                    \"confidence\": req.confidence,\n                    \"metadata\": getattr(req, 'metadata', {}),\n                    # Include specific fields for debugging\n                    \"search_terms\": getattr(req, 'search_terms', None) if isinstance(req, ImageAssetRequest) else None,\n                    \"numerical_data\": getattr(req, 'numerical_data', None) if isinstance(req, ChartAssetRequest) else None,\n                    \"content_description\": getattr(req, 'content_description', None) if isinstance(req, DiagramAssetRequest) else None,\n                } for req in asset_requests\n            ],\n            \"asset_results\": [\n                {\n                    \"success\": result.success,\n                    \"error_message\": result.error_message,\n                    \"fallback_used\": result.fallback_used,\n                    \"generated_asset_path\": result.generated_asset.local_path if result.generated_asset else None,\n                    \"generated_asset_remote_url\": result.generated_asset.remote_url if result.generated_asset else None\n                } for result in asset_results\n            ] if asset_results else [],\n            \"processing_summary\": {\n                \"total_asset_requests\": len(asset_requests),\n                \"successful_generations\": sum(1 for r in asset_results if r.success) if asset_results else 0,\n                \"failed_generations\": sum(1 for r in asset_results if not r.success) if asset_results else 0,\n                \"fallbacks_used\": sum(1 for r in asset_results if r.fallback_used) if asset_results else 0\n            }\n        }\n        \n        try:\n            with open(filepath, 'w', encoding='utf-8') as f:\n                json.dump(debug_data, f, indent=2, ensure_ascii=False)\n            \n            self._logger.info(f\"Asset debug info saved to: {filepath}\")\n            return str(filepath)\n        except Exception as e:\n            self._logger.error(f\"Failed to save asset debug info: {e}\")\n            return \"\"\n\n    def _count_slides_with_assets(self, presentation_dict: Dict[str, Any]) -> int:\n        \"\"\"Count slides that have assets array from Claude\"\"\"\n        count = 0\n        for slide in presentation_dict.get('slides', []):\n            if slide.get('assets') and len(slide['assets']) > 0:\n                count += 1\n        return count\n    \n    async def process_presentation_assets(\n        self, \n        presentation: Presentation\n    ) -> Presentation:\n        \"\"\"Process all assets in a presentation using the generic asset generation system\"\"\"\n        self._logger.info(f\"Processing assets for presentation: {presentation.title}\")\n        \n        try:\n            # Step 1: Extract asset requests from Claude's semantic descriptions\n            asset_requests = await self._extract_asset_requests_from_presentation(presentation)\n            \n            # Save initial state for debugging\n            self._save_asset_debug_info(presentation, asset_requests, [], \"initial\")\n            \n            if not asset_requests:\n                self._logger.info(\"No asset requests found in presentation\")\n                return presentation\n            \n            self._logger.info(f\"Found {len(asset_requests)} asset requests to process\")\n            \n            # Step 2: Generate assets using the comprehensive asset generation service\n            asset_results = await self._asset_generation_service.generate_assets_batch(asset_requests)\n            \n            # Save post-generation debug info\n            self._save_asset_debug_info(presentation, asset_requests, asset_results, \"post_generation\")\n            \n            # Step 3: Apply generated assets back to presentation\n            updated_presentation = await self._apply_generated_assets_to_presentation(\n                presentation, asset_requests, asset_results\n            )\n            \n            # Save final debug info\n            self._save_asset_debug_info(updated_presentation, asset_requests, asset_results, \"final\")\n            \n            # Count successful assets\n            success_count = sum(1 for result in asset_results if result.success)\n            fallback_count = sum(1 for result in asset_results if result.fallback_used)\n            \n            self._logger.info(\n                f\"Asset processing completed: {success_count}/{len(asset_requests)} successful, \"\n                f\"{fallback_count} fallbacks used\"\n            )\n            \n            return updated_presentation\n            \n        except Exception as e:\n            self._logger.error(f\"Asset processing failed: {e}\", exc_info=True)\n            \n            # Save error debug info\n            self._save_asset_debug_info(presentation, [], [], \"error\")\n            \n            # Return original presentation\n            return presentation\n    \n    async def _extract_asset_requests_from_presentation(self, presentation: Presentation) -> List[AssetRequest]:\n        \"\"\"Extract asset requests from Claude's semantic descriptions AND content patterns in slides\"\"\"\n        asset_requests = []\n        \n        try:\n            # Convert to dict to access assets array and slide content\n            presentation_dict = PresentationAdapter.to_dict(presentation)\n            \n            for slide_idx, slide_data in enumerate(presentation_dict.get('slides', [])):\n                slide_number = slide_data.get('slide_number', slide_idx + 1)\n                \n                # Method 1: Extract from Claude's assets array (preferred)\n                assets = slide_data.get('assets', [])\n                self._logger.debug(f\"Slide {slide_number} has {len(assets)} Claude-detected assets\")\n                \n                for asset_data in assets:\n                    asset_request = self._parse_asset_from_dict(asset_data, slide_number)\n                    if asset_request:\n                        asset_requests.append(asset_request)\n                        self._logger.debug(\n                            f\"Extracted {asset_request.asset_type.value} asset for slide {slide_number}\"\n                        )\n                    else:\n                        self._logger.warning(f\"Failed to parse asset on slide {slide_number}: {asset_data}\")\n                \n                # Method 2: Content pattern detection (fallback for manual content)\n                content_assets = self._extract_assets_from_content(slide_data.get('content', ''), slide_number)\n                asset_requests.extend(content_assets)\n                if content_assets:\n                    self._logger.debug(f\"Extracted {len(content_assets)} assets from content patterns on slide {slide_number}\")\n            \n            self._logger.info(f\"Total asset requests extracted: {len(asset_requests)}\")\n            return asset_requests\n            \n        except Exception as e:\n            self._logger.error(f\"Failed to extract asset requests: {e}\", exc_info=True)\n            return []\n    \n    def _extract_assets_from_content(self, content: str, slide_number: int) -> List[AssetRequest]:\n        \"\"\"Extract asset requests from content patterns like [DIAGRAM:flowchart], [IMAGE], [CHART:bar]\"\"\"\n        import re\n        asset_requests = []\n        \n        # Pattern for [DIAGRAM:type] description\n        diagram_pattern = r'\\[DIAGRAM:([^\\]]+)\\]\\s*([^\\n]*)'\n        for match in re.finditer(diagram_pattern, content, re.IGNORECASE):\n            diagram_type_str = match.group(1).strip().lower()\n            description = match.group(2).strip()\n            \n            try:\n                diagram_type = DiagramType(diagram_type_str)\n            except ValueError:\n                diagram_type = DiagramType.FLOWCHART  # Default fallback\n            \n            asset_requests.append(DiagramAssetRequest(\n                asset_type=AssetType.DIAGRAM,\n                description=description or f\"Generate {diagram_type_str} diagram\",\n                slide_number=slide_number,\n                diagram_type=diagram_type,\n                content_description=description,\n                confidence=0.9\n            ))\n        \n        # Pattern for [CHART:type] description\n        chart_pattern = r'\\[CHART:([^\\]]+)\\]\\s*([^\\n]*)'\n        for match in re.finditer(chart_pattern, content, re.IGNORECASE):\n            chart_type_str = match.group(1).strip().lower()\n            description = match.group(2).strip()\n            \n            try:\n                chart_type = ChartType(chart_type_str)\n            except ValueError:\n                chart_type = ChartType.BAR  # Default fallback\n            \n            # Extract numerical data from description or provide defaults\n            numerical_data = self._extract_numerical_data_from_description(description)\n            \n            asset_requests.append(ChartAssetRequest(\n                asset_type=AssetType.CHART,\n                description=description or f\"Generate {chart_type_str} chart\",\n                slide_number=slide_number,\n                chart_type=chart_type,\n                data_description=description or f\"Sample {chart_type_str} chart data\",\n                numerical_data=numerical_data,\n                confidence=0.9\n            ))\n        \n        # Pattern for [IMAGE] description\n        image_pattern = r'\\[IMAGE\\]\\s*([^\\n]*)'\n        for match in re.finditer(image_pattern, content, re.IGNORECASE):\n            description = match.group(1).strip()\n            \n            # Extract search terms from description\n            search_terms = description.split()[:5] if description else ['business', 'professional']\n            \n            asset_requests.append(ImageAssetRequest(\n                asset_type=AssetType.IMAGE,\n                description=description or \"Professional business image\",\n                slide_number=slide_number,\n                search_terms=search_terms,\n                style_preferences=\"professional\",\n                confidence=0.8\n            ))\n        \n        return asset_requests\n    \n    def _extract_numerical_data_from_description(self, description: str) -> List[Dict[str, Any]]:\n        \"\"\"Extract numerical data from description text or provide defaults\"\"\"\n        import re\n        \n        # Try to extract data like \"Epoch 1: 65%, Epoch 5: 78%, Epoch 10: 85%\"\n        data_pattern = r'([^:]+):\\s*(\\d+(?:\\.\\d+)?)\\s*%?'\n        matches = re.findall(data_pattern, description)\n        \n        if matches:\n            return [{\"label\": label.strip(), \"value\": float(value)} for label, value in matches]\n        \n        # Try to extract simple numbers like \"65%, 78%, 85%, 90%\"\n        number_pattern = r'(\\d+(?:\\.\\d+)?)\\s*%?'\n        numbers = re.findall(number_pattern, description)\n        \n        if numbers:\n            return [{\"label\": f\"Item {i+1}\", \"value\": float(num)} for i, num in enumerate(numbers)]\n        \n        # Default fallback data\n        return [\n            {\"label\": \"Category A\", \"value\": 30},\n            {\"label\": \"Category B\", \"value\": 45},\n            {\"label\": \"Category C\", \"value\": 25}\n        ]\n    \n    def _parse_asset_from_dict(self, asset_data: Dict[str, Any], slide_number: int) -> Optional[AssetRequest]:\n        \"\"\"Parse asset request from Claude's semantic description\"\"\"\n        try:\n            asset_type_str = asset_data.get('type', '').lower()\n            description = asset_data.get('description', '')\n            \n            if asset_type_str == 'image':\n                # Extract search terms - Claude provides them in the asset data\n                search_terms = asset_data.get('search_terms', [])\n                if not search_terms:\n                    # Extract from description if search_terms missing\n                    search_terms = description.split()[:5]\n                \n                return ImageAssetRequest(\n                    asset_type=AssetType.IMAGE,\n                    description=description,\n                    slide_number=slide_number,\n                    search_terms=search_terms,\n                    style_preferences=asset_data.get('style_preference'),\n                    color_scheme=asset_data.get('color_scheme'),\n                    confidence=0.8\n                )\n                \n            elif asset_type_str == 'diagram':\n                diagram_type_str = asset_data.get('diagram_type', 'flowchart')\n                try:\n                    diagram_type = DiagramType(diagram_type_str.lower())\n                except ValueError:\n                    diagram_type = DiagramType.FLOWCHART  # Default fallback\n                \n                content_description = asset_data.get('content_description', description)\n                \n                return DiagramAssetRequest(\n                    asset_type=AssetType.DIAGRAM,\n                    description=description,\n                    slide_number=slide_number,\n                    diagram_type=diagram_type,\n                    content_description=content_description,\n                    complexity=\"medium\",\n                    confidence=0.9\n                )\n                \n            elif asset_type_str == 'chart':\n                chart_type_str = asset_data.get('chart_type', 'bar')\n                try:\n                    chart_type = ChartType(chart_type_str.lower())\n                except ValueError:\n                    chart_type = ChartType.BAR  # Default fallback\n                \n                # CRITICAL FIX: Extract the actual data from the asset\n                numerical_data = asset_data.get('data', [])\n                if not numerical_data:\n                    # Skip charts without data\n                    self._logger.warning(f\"Chart asset on slide {slide_number} has no data\")\n                    return None\n                \n                # Ensure data has correct structure\n                validated_data = []\n                for item in numerical_data:\n                    if isinstance(item, dict) and 'label' in item and 'value' in item:\n                        validated_data.append({\n                            'label': str(item['label']),\n                            'value': float(item['value'])\n                        })\n                \n                if not validated_data:\n                    self._logger.warning(f\"Chart asset on slide {slide_number} has invalid data structure\")\n                    return None\n                \n                return ChartAssetRequest(\n                    asset_type=AssetType.CHART,\n                    description=description,\n                    slide_number=slide_number,\n                    chart_type=chart_type,\n                    data_description=asset_data.get('data_description', description),\n                    numerical_data=validated_data,\n                    title=asset_data.get('title'),\n                    confidence=0.95\n                )\n            \n            else:\n                self._logger.warning(f\"Unknown asset type: {asset_type_str}\")\n                return None\n                \n        except Exception as e:\n            self._logger.error(f\"Failed to parse asset from dict: {e}\", exc_info=True)\n            return None\n    \n    async def _apply_generated_assets_to_presentation(\n        self, \n        presentation: Presentation, \n        asset_requests: List[AssetRequest],\n        asset_results: List[AssetGenerationResult]\n    ) -> Presentation:\n        \"\"\"Apply successfully generated assets back to the presentation\"\"\"\n        try:\n            # Convert to dict for easier manipulation\n            presentation_dict = PresentationAdapter.to_dict(presentation)\n            \n            # Create mapping of slide number to generated assets\n            slide_assets = {}\n            for request, result in zip(asset_requests, asset_results):\n                slide_num = request.slide_number\n                if slide_num not in slide_assets:\n                    slide_assets[slide_num] = []\n                \n                if result.success and result.generated_asset:\n                    slide_assets[slide_num].append((request, result.generated_asset))\n                    self._logger.debug(f\"Asset generated for slide {slide_num}: {result.generated_asset.local_path}\")\n            \n            # Apply assets to slides\n            for slide_idx, slide_data in enumerate(presentation_dict.get('slides', [])):\n                slide_number = slide_data.get('slide_number', slide_idx + 1)\n                \n                if slide_number in slide_assets:\n                    self._apply_assets_to_slide_dict(slide_data, slide_assets[slide_number])\n            \n            # Convert back to domain entity\n            return PresentationAdapter.from_dict(presentation_dict)\n            \n        except Exception as e:\n            self._logger.error(f\"Failed to apply generated assets: {e}\", exc_info=True)\n            return presentation\n    \n    def _apply_assets_to_slide_dict(self, slide_data: Dict[str, Any], generated_assets: List[tuple]) -> None:\n        \"\"\"Apply generated assets to a slide dictionary\"\"\"\n        for asset_request, generated_asset in generated_assets:\n            \n            # Use remote URL if available, otherwise local path\n            asset_url = generated_asset.remote_url or generated_asset.local_path\n            \n            if asset_request.asset_type == AssetType.IMAGE:\n                slide_data['image_url'] = asset_url\n                slide_data['local_image_path'] = generated_asset.local_path\n                slide_data['image_description'] = asset_request.description\n                \n            elif asset_request.asset_type == AssetType.DIAGRAM:\n                slide_data['diagram_type'] = asset_request.diagram_type.value\n                slide_data['diagram_content'] = asset_request.content_description\n                slide_data['local_diagram_path'] = generated_asset.local_path\n                slide_data['image_url'] = asset_url  # For display\n                \n            elif asset_request.asset_type == AssetType.CHART:\n                slide_data['chart_type'] = asset_request.chart_type.value\n                slide_data['chart_data'] = asset_request.numerical_data\n                slide_data['local_chart_path'] = generated_asset.local_path\n                slide_data['image_url'] = asset_url  # For display\n\n\n================================================================================\nFILE: api/makeslides/infrastructure/external_services/comprehensive_asset_generation_service.py\n================================================================================\nFILE NOT FOUND: /Users/bilalghalib/Projects/Github/banter_modular/api/makeslides/infrastructure/external_services/comprehensive_asset_generation_service.py\n\n\n================================================================================\nFILE: api/makeslides/application/use_cases/create_presentation.py\n================================================================================\n# api/makeslides/application/use_cases/create_presentation.py\n# makeslides/application/use_cases/create_presentation.py\n\nimport logging\nfrom typing import Optional\nfrom datetime import datetime\nfrom dataclasses import dataclass\n\nfrom ...domain.entities.presentation import Presentation\nfrom ...domain.services.content_analysis_service import ContentAnalysisService\nfrom ...domain.services.presentation_builder_service import PresentationBuilderService\nfrom ...domain.repositories.presentation_repository import PresentationRepository\nfrom ...domain.repositories.asset_repository import AssetRepository\nfrom ...domain.value_objects.theme import Theme, ThemeType\nfrom ...domain.value_objects.presentation_id import PresentationId\nfrom ...domain.exceptions import DomainException\nfrom ..dto.create_presentation_request import CreatePresentationRequest\nfrom ..dto.create_presentation_response import CreatePresentationResponse\nfrom ..exceptions import ApplicationException, ExternalServiceUnavailableError\nfrom ..services.asset_processing_service import AssetProcessingService\nfrom ..services.correlation_service import CorrelationService\n\n\nclass CreatePresentationUseCase:\n    \"\"\"\n    Use case for creating presentations from content.\n    \n    This orchestrates the entire presentation creation workflow:\n    1. Content analysis and structure detection\n    2. Presentation building with business rules\n    3. Asset processing and optimization\n    4. Theme application and validation\n    5. Persistence and result generation\n    \"\"\"\n    \n    def __init__(\n        self,\n        content_analyzer: ContentAnalysisService,\n        presentation_builder: PresentationBuilderService,\n        presentation_repository: PresentationRepository,\n        asset_repository: AssetRepository,\n        asset_processor: AssetProcessingService,\n        correlation_service: CorrelationService,\n        logger: logging.Logger\n    ):\n        self._content_analyzer = content_analyzer\n        self._presentation_builder = presentation_builder\n        self._presentation_repo = presentation_repository\n        self._asset_repo = asset_repository\n        self._asset_processor = asset_processor\n        self._correlation_service = correlation_service\n        self._logger = logger\n    \n    async def execute(self, request: CreatePresentationRequest) -> CreatePresentationResponse:\n        \"\"\"\n        Execute the presentation creation workflow.\n        \n        Args:\n            request: The presentation creation request with content and options\n            \n        Returns:\n            CreatePresentationResponse: Success response with presentation details\n            \n        Raises:\n            ApplicationException: For application-level errors\n            DomainException: For business rule violations\n        \"\"\"\n        correlation_id = self._correlation_service.generate_id()\n        start_time = datetime.utcnow()\n        \n        self._logger.info(\n            \"Starting presentation creation\",\n            extra={\n                \"correlation_id\": correlation_id,\n                \"content_length\": len(request.content),\n                \"output_format\": getattr(request.output_format, 'value', str(request.output_format)),\n                \"theme\": getattr(request.theme, 'name', str(request.theme))\n            }\n        )\n        \n        try:\n            # Step 1: Validate request\n            self._validate_request(request)\n            \n            # Step 2: Analyze content structure and extract key information\n            self._logger.info(\"Analyzing content structure\", extra={\"correlation_id\": correlation_id})\n            analyzed_content = await self._analyze_content(request.content, correlation_id)\n            \n            # Step 3: Build presentation using domain logic\n            self._logger.info(\"Building presentation structure\", extra={\"correlation_id\": correlation_id})\n            presentation = await self._build_presentation(analyzed_content, request, correlation_id)\n            \n            # Step 4: Process and optimize assets (images, diagrams)\n            self._logger.info(f\"ASSET DEBUG: request.options = {request.options}\", extra={\"correlation_id\": correlation_id})\n            if request.options:\n                self._logger.info(f\"ASSET DEBUG: process_assets = {request.options.process_assets}\", extra={\"correlation_id\": correlation_id})\n            \n            if request.options and request.options.process_assets:\n                self._logger.info(\"ASSET DEBUG: Starting asset processing\", extra={\"correlation_id\": correlation_id})\n                presentation = await self._process_assets(presentation, correlation_id)\n                self._logger.info(\"ASSET DEBUG: Asset processing completed\", extra={\"correlation_id\": correlation_id})\n            else:\n                self._logger.warning(\"ASSET DEBUG: Asset processing skipped - options missing or process_assets=False\", extra={\"correlation_id\": correlation_id})\n            \n            # Step 5: Apply theme and validate compatibility\n            self._logger.info(\"Applying theme\", extra={\"correlation_id\": correlation_id})\n            theme = self._resolve_theme(request.theme)\n            presentation.apply_theme(theme)\n            \n            # Step 6: Validate final presentation structure\n            validation_issues = presentation.validate_structure()\n            if validation_issues and request.options and request.options.strict_validation:\n                raise ApplicationException(f\"Presentation validation failed: {validation_issues}\")\n            elif validation_issues:\n                self._logger.warning(\n                    \"Presentation has validation issues\", \n                    extra={\"correlation_id\": correlation_id, \"issues\": validation_issues}\n                )\n            \n            # Step 7: Save presentation\n            self._logger.info(\"Saving presentation\", extra={\"correlation_id\": correlation_id})\n            presentation_id = await self._presentation_repo.save(presentation)\n            \n            # Step 8: Generate response\n            duration = (datetime.utcnow() - start_time).total_seconds()\n            \n            self._logger.info(\n                \"Presentation created successfully\",\n                extra={\n                    \"correlation_id\": correlation_id,\n                    \"presentation_id\": str(presentation_id),\n                    \"slide_count\": presentation.slide_count,\n                    \"duration_seconds\": duration\n                }\n            )\n            \n            return CreatePresentationResponse.success_response(\n                presentation_id=str(presentation_id),\n                slide_count=presentation.slide_count,\n                warnings=validation_issues,\n                metadata={\n                    \"title\": presentation.title,\n                    \"theme_name\": theme.name,\n                    \"estimated_duration_minutes\": presentation.estimate_duration_minutes(),\n                    \"processing_time_seconds\": duration,\n                    \"created_at\": presentation.created_at.isoformat(),\n                    \"correlation_id\": correlation_id\n                }\n            )\n            \n        except DomainException as e:\n            duration = (datetime.utcnow() - start_time).total_seconds()\n            self._logger.error(\n                \"Domain error during presentation creation\",\n                extra={\n                    \"correlation_id\": correlation_id,\n                    \"error_type\": type(e).__name__,\n                    \"error_message\": str(e),\n                    \"duration_seconds\": duration\n                }\n            )\n            raise  # Re-raise domain exceptions as-is\n            \n        except ExternalServiceUnavailableError as e:\n            duration = (datetime.utcnow() - start_time).total_seconds()\n            self._logger.error(\n                \"External service unavailable\",\n                extra={\n                    \"correlation_id\": correlation_id,\n                    \"service\": e.service_name,\n                    \"error_message\": str(e),\n                    \"duration_seconds\": duration\n                }\n            )\n            raise ApplicationException(f\"Service temporarily unavailable: {e.service_name}\") from e\n            \n        except Exception as e:\n            duration = (datetime.utcnow() - start_time).total_seconds()\n            self._logger.error(\n                \"Unexpected error during presentation creation\",\n                extra={\n                    \"correlation_id\": correlation_id,\n                    \"error_type\": type(e).__name__,\n                    \"error_message\": str(e),\n                    \"duration_seconds\": duration\n                },\n                exc_info=True\n            )\n            raise ApplicationException(\"Failed to create presentation due to unexpected error\") from e\n    \n    def _validate_request(self, request: CreatePresentationRequest) -> None:\n        \"\"\"Validate the incoming request\"\"\"\n        if not request.content or len(request.content.strip()) == 0:\n            raise ApplicationException(\"Content cannot be empty\")\n        \n        if len(request.content) > 100_000:  # 100KB limit\n            raise ApplicationException(\"Content too large (max 100KB)\")\n        \n        # Validate Google credentials if Google Slides output requested\n        if (request.output_format.is_google_slides() and \n            not request.google_credentials):\n            raise ApplicationException(\"Google credentials required for Google Slides output\")\n    \n    async def _analyze_content(self, content: str, correlation_id: str) -> 'AnalyzedContent':\n        \"\"\"Analyze content structure using AI service\"\"\"\n        try:\n            return await self._content_analyzer.analyze(content)\n        except Exception as e:\n            self._logger.error(\n                \"Content analysis failed\",\n                extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n            )\n            raise ExternalServiceUnavailableError(\"Content analysis service\", str(e)) from e\n    \n    async def _build_presentation(\n        self, \n        analyzed_content: 'AnalyzedContent', \n        request: CreatePresentationRequest,\n        correlation_id: str\n    ) -> Presentation:\n        \"\"\"Build presentation using domain business logic\"\"\"\n        try:\n            return self._presentation_builder.build_from_analyzed_content(\n                analyzed_content=analyzed_content,\n                options=request.options\n            )\n        except Exception as e:\n            self._logger.error(\n                \"Presentation building failed\",\n                extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n            )\n            raise ApplicationException(\"Failed to build presentation structure\") from e\n    \n    async def _process_assets(self, presentation: Presentation, correlation_id: str) -> Presentation:\n        \"\"\"Process and optimize presentation assets\"\"\"\n        try:\n            return await self._asset_processor.process_presentation_assets(presentation)\n        except Exception as e:\n            self._logger.warning(\n                \"Asset processing failed, continuing without assets\",\n                extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n            )\n            # Asset processing is non-critical, so we continue without it\n            return presentation\n    \n    def _resolve_theme(self, theme_type: ThemeType) -> Theme:\n        \"\"\"Resolve theme type to concrete theme object\"\"\"\n        theme_mapping = {\n            ThemeType.PROFESSIONAL: Theme.professional(),\n            ThemeType.MINIMALIST: Theme.minimalist(),\n            ThemeType.VIBRANT: Theme.vibrant(),\n            ThemeType.DARK: Theme.dark()\n        }\n        \n        return theme_mapping.get(theme_type, Theme.professional())\n\n\n@dataclass(frozen=True)\nclass PresentationCreationMetrics:\n    \"\"\"Metrics for presentation creation process\"\"\"\n    content_analysis_time_seconds: float\n    presentation_building_time_seconds: float\n    asset_processing_time_seconds: float\n    theme_application_time_seconds: float\n    persistence_time_seconds: float\n    total_time_seconds: float\n    slide_count: int\n    asset_count: int\n    validation_issues_count: int\n\n\n================================================================================\nFILE: api/makeslides/api/controllers/presentation_controller.py\n================================================================================\n# api/makeslides/api/controllers/presentation_controller.py\n\nimport logging\nimport os\nimport re\nimport time\nimport uuid\nfrom typing import Optional\nfrom fastapi import APIRouter, HTTPException, Depends, UploadFile, File, Form, Request\nfrom fastapi.responses import JSONResponse, FileResponse\n\nfrom ..schemas.presentation_schema import (\n    CreatePresentationSchema,\n    PresentationResponseSchema,\n    ProcessVoiceNoteSchema,\n    VoiceProcessingResponseSchema\n)\nfrom ..dependencies import (\n    get_current_user,\n    get_current_user_optional,\n    get_create_presentation_use_case,\n    get_process_voice_note_use_case,\n    get_render_presentation_use_case,\n    check_google_permissions\n)\nfrom ..middleware.correlation_middleware import get_correlation_id\nfrom ...application.use_cases.create_presentation import CreatePresentationUseCase\nfrom ...application.use_cases.process_voice_note import ProcessVoiceNoteUseCase\nfrom ...application.use_cases.render_presentation import RenderPresentationUseCase\nfrom ...application.dto.create_presentation_request import CreatePresentationRequest\nfrom ...application.dto.process_voice_note_request import ProcessVoiceNoteRequest\nfrom ...application.dto.render_presentation_request import RenderPresentationRequest\nfrom ...application.exceptions import ApplicationException, ValidationException\nfrom ...domain.exceptions import DomainException\nfrom ...domain.value_objects.output_format import OutputFormat\nfrom ...domain.value_objects.theme import ThemeType\nfrom ...domain.value_objects.audio_format import AudioFormat\nfrom ...domain.entities.user import User\n\n\nrouter = APIRouter(prefix=\"/presentations\", tags=[\"presentations\"])\nlogger = logging.getLogger(__name__)\n\n\n@router.get(\"/debug/auth-check\", tags=[\"Debug\"])\nasync def debug_auth_check(\n    request: Request,\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Debug endpoint to check authentication flow step by step.\"\"\"\n    debug_info = {\n        \"correlation_id\": correlation_id,\n        \"headers\": {},\n        \"auth_steps\": [],\n        \"errors\": []\n    }\n    \n    # Step 1: Check headers\n    auth_header = request.headers.get(\"Authorization\")\n    debug_info[\"headers\"][\"authorization\"] = auth_header[:50] + \"...\" if auth_header and len(auth_header) > 50 else auth_header\n    debug_info[\"headers\"][\"content_type\"] = request.headers.get(\"content-type\")\n    \n    if not auth_header:\n        debug_info[\"errors\"].append(\"No Authorization header found\")\n        return JSONResponse(status_code=200, content=debug_info)\n    \n    if not auth_header.startswith(\"Bearer \"):\n        debug_info[\"errors\"].append(\"Authorization header doesn't start with 'Bearer '\")\n        return JSONResponse(status_code=200, content=debug_info)\n    \n    token = auth_header[7:]\n    debug_info[\"auth_steps\"].append(f\"Token extracted: {token[:20]}...\")\n    \n    # Step 2: Try to validate with Supabase\n    try:\n        from ...infrastructure.di_container import DIContainerManager\n        from ...domain.services.interfaces.authentication_service import AuthenticationService\n        \n        auth_service = DIContainerManager.get_service(AuthenticationService)\n        debug_info[\"auth_steps\"].append(\"Got auth service from DI container\")\n        \n        # Get Supabase client\n        from supabase import Client\n        supabase_client = DIContainerManager.get_service(Client)\n        debug_info[\"auth_steps\"].append(\"Got Supabase client\")\n        \n        # Try to get user from Supabase\n        try:\n            user_response = supabase_client.auth.get_user(token)\n            if user_response and user_response.user:\n                debug_info[\"auth_steps\"].append(f\"Supabase returned user: {user_response.user.email}\")\n                debug_info[\"supabase_user\"] = {\n                    \"id\": user_response.user.id,\n                    \"email\": user_response.user.email,\n                    \"created_at\": str(user_response.user.created_at) if hasattr(user_response.user, 'created_at') else None\n                }\n            else:\n                debug_info[\"errors\"].append(\"Supabase returned no user for token\")\n        except Exception as e:\n            debug_info[\"errors\"].append(f\"Supabase get_user error: {str(e)}\")\n        \n        # Step 3: Check if user exists in our users table\n        from ...domain.repositories.user_repository import UserRepository\n        user_repo = DIContainerManager.get_service(UserRepository)\n        debug_info[\"auth_steps\"].append(\"Got user repository\")\n        \n        if \"supabase_user\" in debug_info:\n            try:\n                db_user = await user_repo.find_by_id(debug_info[\"supabase_user\"][\"id\"])\n                if db_user:\n                    debug_info[\"auth_steps\"].append(f\"User found in database: {db_user.email}\")\n                    debug_info[\"db_user_exists\"] = True\n                else:\n                    debug_info[\"auth_steps\"].append(\"User NOT found in database\")\n                    debug_info[\"db_user_exists\"] = False\n            except Exception as e:\n                debug_info[\"errors\"].append(f\"Database lookup error: {str(e)}\")\n        \n        # Step 4: Check RLS policies\n        try:\n            # Try a direct query to check RLS\n            result = supabase_client.table('users').select('id').execute()\n            debug_info[\"auth_steps\"].append(f\"RLS test query returned {len(result.data)} rows\")\n        except Exception as e:\n            debug_info[\"errors\"].append(f\"RLS test query failed: {str(e)}\")\n        \n    except Exception as e:\n        debug_info[\"errors\"].append(f\"General error: {str(e)}\")\n        logger.error(f\"Auth debug error: {e}\", exc_info=True)\n    \n    return JSONResponse(status_code=200, content=debug_info)\n\n\n@router.get(\"/{presentation_id}/content\")\nasync def get_presentation_content(\n    presentation_id: str,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Get complete presentation content for display/modification\"\"\"\n    try:\n        from ...infrastructure.repositories.presentation_storage_repository import (\n            PresentationStorageRepository\n        )\n        from pathlib import Path\n        \n        # Load presentation\n        storage_repo = PresentationStorageRepository(\n            storage_path=Path(\"data/presentations\"),\n            logger=logger\n        )\n        \n        metadata = await storage_repo.load_presentation(presentation_id)\n        if not metadata:\n            raise HTTPException(status_code=404, detail=\"Presentation not found\")\n        \n        # For now, skip user ownership check since we have RLS issues\n        # In production, uncomment this:\n        # if metadata.user_id != current_user.id and metadata.user_id != \"anonymous\":\n        #     raise HTTPException(status_code=403, detail=\"Access denied\")\n        \n        # Check if PPTX file exists and generate download URL\n        pptx_download_url = metadata.pptx_download_url\n        if not pptx_download_url:\n            # Try to find existing PPTX file\n            base_dir = Path(\"data/presentations\")\n            possible_files = [\n                base_dir / f\"{metadata.presentation_id}.pptx\",\n                base_dir / f\"presentation_{metadata.presentation_id}.pptx\",\n                base_dir / f\"test_{metadata.presentation_id}.pptx\",\n                base_dir / f\"regenerated_{metadata.presentation_id}.pptx\"\n            ]\n            \n            # Also check for files with timestamps or stream prefixes\n            for file in base_dir.glob(\"*.pptx\"):\n                if metadata.presentation_id in str(file):\n                    possible_files.append(file)\n            \n            for file_path in possible_files:\n                if file_path.exists():\n                    # Generate download URL using the direct download endpoint (relative URL)\n                    pptx_download_url = f\"/presentations/{metadata.presentation_id}/download\"\n                    break\n        \n        # Return structured content for frontend\n        content_data = {\n            \"presentation_id\": metadata.presentation_id,\n            \"title\": metadata.title,\n            \"status\": metadata.status.value,\n            \"original_content\": metadata.original_content,\n            \"theme\": metadata.theme,\n            \"slide_count\": metadata.slide_count,\n            \"estimated_duration_minutes\": metadata.estimated_duration_minutes,\n            \"slides\": [\n                {\n                    \"slide_number\": slide.slide_number,\n                    \"title\": slide.title,\n                    \"content\": slide.content,\n                    \"layout\": slide.layout,\n                    \"speaker_notes\": slide.speaker_notes,\n                    \"notes\": slide.speaker_notes,  # Add both for compatibility\n                    \"facilitator_notes\": slide.speaker_notes,  # Add facilitator notes\n                    \"assets\": [\n                        {\n                            \"asset_id\": asset.asset_id,\n                            \"asset_type\": asset.asset_type,\n                            \"cloud_url\": asset.cloud_url\n                        } for asset in slide.assets\n                    ]\n                } for slide in metadata.slides\n            ],\n            \"google_slides_url\": metadata.google_slides_url,\n            \"pptx_download_url\": pptx_download_url,\n            \"modification_history\": metadata.modification_history,\n            \"generation_timestamp\": metadata.generation_timestamp.isoformat(),\n            \"is_modifiable\": metadata.is_modifiable\n        }\n        \n        return JSONResponse(content=content_data)\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Failed to get presentation content: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n\n\n@router.get(\"/{presentation_id}/download\")\nasync def download_presentation(\n    presentation_id: str,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Download presentation file directly.\"\"\"\n    try:\n        from pathlib import Path\n        from fastapi.responses import FileResponse\n        \n        # Look for PPTX file in the presentations directory\n        # Use absolute path to ensure we find the files regardless of working directory\n        base_dir = Path(\"data/presentations\").resolve()\n        if not base_dir.exists():\n            # Fallback: try relative to API directory\n            api_dir = Path(__file__).parent.parent.parent.parent\n            base_dir = api_dir / \"data\" / \"presentations\"\n        \n        # Try different possible filenames\n        possible_files = [\n            base_dir / f\"{presentation_id}.pptx\",\n            base_dir / f\"presentation_{presentation_id}.pptx\",\n            base_dir / f\"test_{presentation_id}.pptx\",\n            base_dir / f\"test_stream_{presentation_id}.pptx\",\n            base_dir / f\"regenerated_{presentation_id}.pptx\"\n        ]\n        \n        # Also check for files with timestamps\n        for file in base_dir.glob(\"*.pptx\"):\n            if presentation_id in str(file):\n                possible_files.append(file)\n        \n        for file_path in possible_files:\n            if file_path.exists():\n                return FileResponse(\n                    path=str(file_path),\n                    filename=f\"presentation_{presentation_id[:8]}.pptx\",\n                    media_type=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\"\n                )\n        \n        raise HTTPException(status_code=404, detail=\"Presentation file not found\")\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Download failed for {presentation_id}: {e}\")\n        raise HTTPException(status_code=500, detail=\"Failed to download presentation\")\n\n\n@router.get(\"/{presentation_id}/download/json\")\nasync def download_presentation_json(\n    presentation_id: str,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Download presentation as JSON file.\"\"\"\n    try:\n        from pathlib import Path\n        from fastapi.responses import Response\n        import json\n        from ...domain.repositories.presentation_repository import PresentationRepository\n        from ...infrastructure.di_container import DIContainerManager\n        from ...domain.adapters.presentation_adapter import PresentationAdapter\n        \n        # Get presentation repository\n        presentation_repo = DIContainerManager.get_service(PresentationRepository)\n        \n        # Retrieve the presentation\n        presentation = await presentation_repo.get_by_id(presentation_id)\n        if not presentation:\n            raise HTTPException(status_code=404, detail=\"Presentation not found\")\n        \n        # Convert to dict format\n        presentation_dict = PresentationAdapter.to_dict(presentation)\n        \n        # Convert to JSON with proper formatting\n        json_content = json.dumps(presentation_dict, indent=2, ensure_ascii=False)\n        \n        # Return as downloadable JSON file\n        return Response(\n            content=json_content,\n            media_type=\"application/json\",\n            headers={\n                \"Content-Disposition\": f\"attachment; filename=presentation_{presentation_id[:8]}.json\"\n            }\n        )\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"JSON download failed for {presentation_id}: {e}\")\n        raise HTTPException(status_code=500, detail=\"Failed to download presentation JSON\")\n\n\n@router.get(\"/google-permissions\")\nasync def check_google_permissions_status(\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Check user's Google OAuth permissions for creating slides\"\"\"\n    try:\n        # Get authentication status from domain logic\n        auth_status = current_user.get_google_authentication_status()\n        \n        response_data = {\n            \"user_id\": current_user.id,\n            \"email\": current_user.email,\n            \"google_connected\": current_user.google_connected,\n            \"has_google_auth\": current_user.has_google_credentials(),\n            \"can_create_slides\": auth_status[\"can_create_slides\"],\n            \"needs_refresh\": auth_status[\"needs_refresh\"],\n            \"can_refresh\": auth_status[\"can_refresh\"],\n            \"reason\": auth_status[\"reason\"],\n            \"scopes\": auth_status.get(\"scopes\", []),\n            \"required_scopes\": auth_status.get(\"required_scopes\", []),\n            \"debug_info\": auth_status\n        }\n        \n        logger.info(f\"Google permissions check for user {current_user.email}: {auth_status.get('reason', 'OK')}\")\n        \n        return JSONResponse(content=response_data)\n        \n    except Exception as e:\n        logger.error(f\"Failed to check Google permissions: {e}\", exc_info=True)\n        \n        # Return a more detailed error response\n        return JSONResponse(\n            status_code=500,\n            content={\n                \"error\": \"Failed to check Google permissions\",\n                \"message\": str(e),\n                \"google_connected\": False,\n                \"has_google_auth\": False,\n                \"can_create_slides\": False,\n                \"needs_reauth\": True\n            }\n        )\n\n\n@router.post(\"/create\", response_model=PresentationResponseSchema)\nasync def create_presentation(\n    request: CreatePresentationSchema,\n    correlation_id: str = Depends(get_correlation_id)\n) -> PresentationResponseSchema:\n    \"\"\"\n    Create a new presentation from content.\n    \n    This endpoint accepts text content and creates a structured presentation\n    with AI-powered content analysis and professional formatting.\n    \"\"\"\n    logger.info(\n        \"Creating presentation via API\",\n        extra={\n            \"correlation_id\": correlation_id,\n            \"content_length\": len(request.content),\n            \"format\": request.format\n        }\n    )\n    \n    try:\n        # For now, return a mock response to test the API flow\n        from datetime import datetime\n        \n        mock_response = PresentationResponseSchema(\n            id=str(uuid.uuid4()),\n            title=\"Mock Presentation\",\n            slide_count=5,\n            theme=request.theme,\n            estimated_duration_minutes=10,\n            status=\"completed\",\n            created_at=datetime.now(),\n            validation_issues=[],\n            processing_time_seconds=2.5\n        )\n        \n        logger.info(\n            \"Mock presentation created successfully\",\n            extra={\"correlation_id\": correlation_id, \"presentation_id\": mock_response.id}\n        )\n        \n        return mock_response\n        \n    except ValidationException as e:\n        logger.warning(\n            \"Presentation creation validation error\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n        )\n        raise HTTPException(status_code=400, detail=str(e))\n        \n    except DomainException as e:\n        logger.warning(\n            \"Presentation creation domain error\", \n            extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n        )\n        raise HTTPException(status_code=422, detail=f\"Business rule violation: {str(e)}\")\n        \n    except ApplicationException as e:\n        logger.error(\n            \"Presentation creation application error\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n        )\n        raise HTTPException(status_code=500, detail=\"Failed to create presentation\")\n        \n    except Exception as e:\n        logger.error(\n            \"Unexpected error creating presentation\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)},\n            exc_info=True\n        )\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n\n\n@router.get(\"/\", response_model=list[PresentationResponseSchema])\nasync def get_presentations(\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n) -> list[PresentationResponseSchema]:\n    \"\"\"\n    Get all presentations for the current user.\n    \"\"\"\n    try:\n        logger.info(\n            f\"Getting presentations for user: {current_user.email}\",\n            extra={\"correlation_id\": correlation_id, \"user_id\": current_user.id}\n        )\n        \n        # Load presentations from storage\n        from ...infrastructure.repositories.presentation_storage_repository import (\n            PresentationStorageRepository\n        )\n        from pathlib import Path\n        \n        storage_repo = PresentationStorageRepository(\n            storage_path=Path(\"data/presentations\"),\n            logger=logger\n        )\n        \n        # Get all presentations for this user (including anonymous ones for now)\n        presentations = await storage_repo.list_user_presentations(current_user.id)\n        \n        # Also get anonymous presentations (temporary fix until we link them properly)\n        anonymous_presentations = await storage_repo.list_user_presentations(\"anonymous\")\n        presentations.extend(anonymous_presentations)\n        \n        # Convert to response format\n        presentation_responses = []\n        for presentation in presentations:\n            response = PresentationResponseSchema(\n                id=presentation.presentation_id,\n                title=presentation.title,\n                status=presentation.status.value,\n                download_url=presentation.pptx_download_url,\n                google_slides_url=presentation.google_slides_url,\n                created_at=presentation.generation_timestamp.isoformat(),\n                slide_count=presentation.slide_count,\n                theme=presentation.theme,\n                estimated_duration_minutes=max(1, presentation.slide_count * 2),  # Rough estimate\n                processing_time_seconds=0.0,\n                validation_issues=None,\n                url=presentation.google_slides_url  # For backwards compatibility\n            )\n            presentation_responses.append(response)\n        \n        logger.info(f\"Found {len(presentation_responses)} presentations for user {current_user.email}\")\n        return presentation_responses\n        \n    except Exception as e:\n        logger.error(\n            \"Unexpected error getting presentations\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)},\n            exc_info=True\n        )\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n\n\n@router.post(\"/create-stream\")\nasync def create_presentation_stream(\n    request: CreatePresentationSchema,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id),\n    use_case: CreatePresentationUseCase = Depends(get_create_presentation_use_case)\n):\n    \"\"\"Create presentation using modern DDD architecture with asset processing and streaming updates.\"\"\"\n    from fastapi.responses import StreamingResponse\n    import json\n    import asyncio\n    \n    logger.info(\n        \"Creating presentation with modern CreatePresentationUseCase\",\n        extra={\n            \"correlation_id\": correlation_id,\n            \"content_length\": len(request.content),\n            \"format\": request.format,\n            \"process_assets\": request.process_assets,\n            \"user_id\": current_user.id if current_user else None\n        }\n    )\n    \n    async def generate_sse():\n        \"\"\"Generate Server-Sent Events using modern CreatePresentationUseCase with asset processing.\"\"\"\n        try:\n            # Send initial status\n            yield f\"data: {json.dumps({'type': 'status', 'message': 'Initializing modern presentation creation...'})}\\n\\n\"\n            await asyncio.sleep(0.1)\n            \n            # Transform API request to use case request\n            yield f\"data: {json.dumps({'type': 'status', 'message': 'Preparing request with asset processing enabled...'})}\\n\\n\"\n            \n            use_case_request = CreatePresentationRequest(\n                content=request.content,\n                output_format=OutputFormat.from_string(request.format),\n                theme=ThemeType.PROFESSIONAL,  # Use theme from request if needed\n                google_credentials=None,  # Add Google creds if available\n                options=_create_presentation_options(request),\n                user_id=current_user.id if current_user else \"anonymous\",\n                title=request.title if hasattr(request, 'title') else None\n            )\n            \n            # Show asset processing status\n            if use_case_request.options.process_assets:\n                yield f\"data: {json.dumps({'type': 'status', 'message': 'üé® Asset processing enabled - will generate diagrams, charts, and images'})}\\n\\n\"\n            else:\n                yield f\"data: {json.dumps({'type': 'warning', 'message': 'Asset processing disabled'})}\\n\\n\"\n            \n            await asyncio.sleep(0.1)\n            \n            # Execute the modern use case\n            yield f\"data: {json.dumps({'type': 'status', 'message': 'üß† Analyzing content with Claude AI...'})}\\n\\n\"\n            await asyncio.sleep(0.5)\n            \n            yield f\"data: {json.dumps({'type': 'status', 'message': 'üèóÔ∏è Building presentation structure...'})}\\n\\n\"\n            await asyncio.sleep(0.3)\n            \n            if use_case_request.options.process_assets:\n                yield f\"data: {json.dumps({'type': 'status', 'message': 'üé® Detecting and generating assets...'})}\\n\\n\"\n                await asyncio.sleep(0.5)\n            \n            yield f\"data: {json.dumps({'type': 'status', 'message': 'üíæ Saving presentation...'})}\\n\\n\"\n            \n            # Execute use case\n            response = await use_case.execute(use_case_request)\n            \n            if response.success:\n                yield f\"data: {json.dumps({'type': 'status', 'message': f'‚úÖ Presentation created successfully with {response.slide_count} slides'})}\\n\\n\"\n                \n                # Send final result\n                final_result = {\n                    \"type\": \"result\",\n                    \"presentation_id\": response.presentation_id,\n                    \"slide_count\": response.slide_count,\n                    \"title\": response.metadata.get(\"title\", \"Untitled\") if response.metadata else \"Untitled\",\n                    \"pptx_filename\": f\"{response.presentation_id}.pptx\",\n                    \"google_slides_url\": None,  # TODO: Add when Google Slides is implemented\n                    \"warnings\": response.warnings or []\n                }\n                \n                yield f\"data: {json.dumps(final_result)}\\n\\n\"\n                \n                # Final completion status\n                yield f\"data: {json.dumps({'type': 'final_result', **final_result})}\\n\\n\"\n                \n            else:\n                error_msg = response.error_message or \"Unknown error occurred\"\n                yield f\"data: {json.dumps({'type': 'error', 'message': f'‚ùå Failed to create presentation: {error_msg}'})}\\n\\n\"\n                \n        except Exception as e:\n            logger.error(f\"Modern streaming generation failed: {e}\", exc_info=True)\n            yield f\"data: {json.dumps({'type': 'error', 'message': f'Generation failed: {str(e)}'})}\\n\\n\"\n        \n        # Send completion event\n        yield f\"data: {json.dumps({'type': 'complete'})}\\n\\n\"\n    \n    return StreamingResponse(\n        generate_sse(),\n        media_type=\"text/event-stream\",\n        headers={\n            \"Cache-Control\": \"no-cache\",\n            \"Connection\": \"keep-alive\",\n            \"Access-Control-Allow-Origin\": \"*\",\n            \"Access-Control-Allow-Headers\": \"*\",\n        }\n    )\n\n    \n    \n# ==================== MOCK/BACKUP ENDPOINT ====================\n\n@router.post(\"/create-stream-mock\")\nasync def create_presentation_stream_mock(\n    request: CreatePresentationSchema,\n    current_user: User = Depends(get_current_user_optional),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Backup endpoint with mock data for testing when Claude AI is unavailable.\"\"\"\n    from fastapi.responses import StreamingResponse\n    import json\n    import asyncio\n    \n    async def generate_sse():\n        \"\"\"Generate Server-Sent Events with mock data.\"\"\"\n        try:\n            # Send initial status\n            yield f\"data: {json.dumps({'type': 'status', 'message': 'Starting AI analysis...', 'progress': 0})}\\n\\n\"\n            await asyncio.sleep(0.5)\n            \n            # Simulate Claude thinking process\n            thinking_steps = [\n                {\"message\": \"üß† Analyzing content structure...\", \"progress\": 10},\n                {\"message\": \"üìã Identifying key topics and themes...\", \"progress\": 20},\n                {\"message\": \"üéØ Planning slide organization...\", \"progress\": 30},\n                {\"message\": \"üí≠ Claude thinking: This content covers ML fundamentals. I should structure it with an intro, core concepts, practical applications, and conclusion.\", \"progress\": 40},\n                {\"message\": \"üé® Applying theme and visual design...\", \"progress\": 50},\n                {\"message\": \"üìä Generating diagrams and visual elements...\", \"progress\": 60},\n                {\"message\": \"üí≠ Claude thinking: A flowchart showing the ML pipeline would be helpful here. Also considering a comparison table for supervised vs unsupervised learning.\", \"progress\": 70},\n                {\"message\": \"‚ú® Finalizing slide content and formatting...\", \"progress\": 80},\n                {\"message\": \"üîç Running quality checks and validation...\", \"progress\": 90},\n                {\"message\": \"‚úÖ Presentation generation complete!\", \"progress\": 100}\n            ]\n            \n            for step in thinking_steps:\n                yield f\"data: {json.dumps({'type': 'progress', **step})}\\n\\n\"\n                await asyncio.sleep(1.0)  # Simulate processing time\n            \n            # Send final result\n            from datetime import datetime\n            \n            presentation_id = str(uuid.uuid4())\n            \n            # Determine the actual output format (prioritize Google Slides)\n            output_format = request.format\n            google_slides_url = None\n            \n            # Try to create real Google Slides if user has Google credentials\n            if output_format == \"google_slides\" and current_user and current_user.can_create_google_slides():\n                try:\n                    # Create real Google Slides presentation\n                    from ...renderers.google_slides_renderer import GoogleSlidesRenderer\n                    from ...infrastructure.external_services.google_slides_client import GoogleSlidesClient\n                    \n                    # Mock presentation data for now\n                    presentation_data = {\n                        'title': f\"Generated: {request.content[:50]}...\",\n                        'slides': [\n                            {\n                                'title': 'Title Slide',\n                                'content': request.content[:200] + '...',\n                                'layout': 'TITLE_SLIDE'\n                            },\n                            {\n                                'title': 'Main Content',\n                                'content': request.content,\n                                'layout': 'TITLE_AND_CONTENT'\n                            }\n                        ]\n                    }\n                    \n                    # Create Google Slides renderer\n                    slides_client = GoogleSlidesClient(\n                        credentials_path=\"\", \n                        scopes=[\n                            \"https://www.googleapis.com/auth/presentations\",\n                            \"https://www.googleapis.com/auth/drive.file\"\n                        ],\n                        logger=logger\n                    )\n                    renderer = GoogleSlidesRenderer(slides_client, debug=True)\n                    \n                    # Render to Google Slides using the user's OAuth tokens\n                    result = renderer.render(\n                        presentation_data, \n                        access_token=current_user.google_credentials.access_token\n                    )\n                    \n                    if result.get('success'):\n                        google_slides_url = result.get('url')\n                        logger.info(f\"Successfully created Google Slides: {google_slides_url}\")\n                    else:\n                        logger.error(f\"Failed to create Google Slides: {result.get('error')}\")\n                        # Fall back to mock URL\n                        slides_id = f\"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms_{presentation_id[-8:]}\"\n                        google_slides_url = f\"https://docs.google.com/presentation/d/{slides_id}/edit\"\n                        \n                except Exception as e:\n                    logger.error(f\"Error creating Google Slides: {e}\")\n                    # Fall back to mock URL\n                    slides_id = f\"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms_{presentation_id[-8:]}\"\n                    google_slides_url = f\"https://docs.google.com/presentation/d/{slides_id}/edit\"\n            \n            elif output_format == \"google_slides\":\n                # User doesn't have Google credentials, use mock URL\n                slides_id = f\"1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms_{presentation_id[-8:]}\"\n                google_slides_url = f\"https://docs.google.com/presentation/d/{slides_id}/edit\"\n            \n            download_request_url = f\"/presentations/{presentation_id}/request-download\"\n            \n            result = {\n                \"type\": \"result\",\n                \"presentation\": {\n                    \"id\": presentation_id,\n                    \"title\": f\"Generated: {request.content[:50]}...\",\n                    \"slide_count\": 7,\n                    \"theme\": request.theme,\n                    \"estimated_duration_minutes\": 12,\n                    \"status\": \"completed\",\n                    \"created_at\": datetime.now().isoformat(),\n                    \"download_request_url\": download_request_url,\n                    \"download_url\": download_request_url,  # Add for frontend compatibility\n                    \"google_slides_url\": google_slides_url,\n                    \"output_format\": output_format\n                }\n            }\n            \n            # Save complete presentation JSON for future reference and modifications\n            try:\n                from ...domain.value_objects.complete_presentation_metadata import (\n                    CompletePresentationMetadata, PresentationStatus, SlideContent, AssetInfo\n                )\n                from ...infrastructure.repositories.presentation_storage_repository import (\n                    PresentationStorageRepository\n                )\n                from pathlib import Path\n                \n                # Create mock slide content (in real implementation, this would come from AI analysis)\n                mock_slides = [\n                    SlideContent(\n                        slide_number=1,\n                        title=\"Title Slide\",\n                        content=request.content[:200] + \"...\",\n                        layout=\"TITLE_SLIDE\",\n                        speaker_notes=\"Introduction to the presentation\",\n                        assets=[],\n                        style_metadata={\"theme\": request.theme}\n                    ),\n                    SlideContent(\n                        slide_number=2,\n                        title=\"Main Content\",\n                        content=request.content,\n                        layout=\"TITLE_AND_CONTENT\",\n                        speaker_notes=\"Main content of the presentation\",\n                        assets=[],\n                        style_metadata={\"theme\": request.theme}\n                    )\n                ]\n                \n                # Create complete metadata\n                complete_metadata = CompletePresentationMetadata(\n                    presentation_id=presentation_id,\n                    title=result[\"presentation\"][\"title\"],\n                    user_id=current_user.id,\n                    status=PresentationStatus.GENERATED,\n                    original_content=request.content,\n                    original_prompt=None,\n                    theme=request.theme,\n                    output_format=output_format,\n                    processing_options={\n                        \"format\": request.format,\n                        \"theme\": request.theme\n                    },\n                    slides=mock_slides,\n                    assets=[],\n                    ai_analysis={\n                        \"content_type\": \"text\",\n                        \"detected_topics\": [\"AI\", \"presentation\"],\n                        \"suggested_layouts\": [\"TITLE_SLIDE\", \"TITLE_AND_CONTENT\"]\n                    },\n                    generation_timestamp=datetime.now(),\n                    modification_history=[],\n                    google_slides_url=google_slides_url,\n                    pptx_download_url=download_request_url,\n                    slide_count=result[\"presentation\"][\"slide_count\"],\n                    estimated_duration_minutes=result[\"presentation\"][\"estimated_duration_minutes\"],\n                    processing_time_seconds=2.5\n                )\n                \n                # Save to storage\n                storage_repo = PresentationStorageRepository(\n                    storage_path=Path(\"data/presentations\"),\n                    logger=logger\n                )\n                await storage_repo.save_presentation(complete_metadata)\n                \n                logger.info(f\"Saved complete presentation metadata for {presentation_id}\")\n                \n            except Exception as e:\n                logger.error(f\"Failed to save presentation metadata: {e}\")\n                # Don't fail the whole request if storage fails\n            \n            yield f\"data: {json.dumps(result)}\\n\\n\"\n            \n        except Exception as e:\n            logger.error(f\"Streaming error: {e}\", exc_info=True)\n            yield f\"data: {json.dumps({'type': 'error', 'message': str(e)})}\\n\\n\"\n    \n    return StreamingResponse(\n        generate_sse(),\n        media_type=\"text/plain\",\n        headers={\n            \"Cache-Control\": \"no-cache\",\n            \"Connection\": \"keep-alive\",\n            \"Access-Control-Allow-Origin\": \"*\",\n            \"Access-Control-Allow-Headers\": \"*\",\n        }\n    )\n\n\n@router.post(\"/{presentation_id}/modify\")\nasync def modify_presentation(\n    presentation_id: str,\n    modification_request: str = Form(..., description=\"Description of changes to make\"),\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Modify an existing presentation based on user feedback\"\"\"\n    logger.info(\n        \"Modifying presentation\",\n        extra={\n            \"correlation_id\": correlation_id,\n            \"presentation_id\": presentation_id,\n            \"modification_length\": len(modification_request)\n        }\n    )\n    \n    try:\n        from ...infrastructure.repositories.presentation_storage_repository import (\n            PresentationStorageRepository\n        )\n        from ...services.presentation_modification_service import (\n            PresentationModificationService\n        )\n        from ...domain.value_objects.complete_presentation_metadata import (\n            CompletePresentationMetadata\n        )\n        from pathlib import Path\n        import json\n        \n        # Load original presentation\n        storage_repo = PresentationStorageRepository(\n            storage_path=Path(\"data/presentations\"),\n            logger=logger\n        )\n        \n        original_metadata = await storage_repo.load_presentation(presentation_id)\n        if not original_metadata:\n            raise HTTPException(status_code=404, detail=\"Presentation not found\")\n        \n        # Temporarily disable user ownership check for debugging\n        # TODO: Re-enable in production\n        # if original_metadata.user_id != current_user.id:\n        #     raise HTTPException(status_code=403, detail=\"Access denied\")\n        \n        # Check if presentation is modifiable\n        if not original_metadata.is_modifiable:\n            raise HTTPException(status_code=400, detail=\"Presentation cannot be modified\")\n        \n        # Generate modification prompt\n        modification_service = PresentationModificationService(logger)\n        \n        # Select best prompt version\n        prompt_version = modification_service.select_best_prompt_version(\n            modification_request, original_metadata\n        )\n        \n        modification_prompt = modification_service.generate_modification_prompt(\n            original_metadata, modification_request, prompt_version\n        )\n        \n        logger.info(f\"Using prompt version {prompt_version} for modification\")\n        \n        # For now, return the prompt and metadata for testing\n        # In production, this would call Claude API\n        response_data = {\n            \"presentation_id\": presentation_id,\n            \"modification_request\": modification_request,\n            \"prompt_version_used\": prompt_version,\n            \"original_slide_count\": original_metadata.slide_count,\n            \"original_title\": original_metadata.title,\n            \"modification_prompt\": modification_prompt[:500] + \"...\" if len(modification_prompt) > 500 else modification_prompt,\n            \"status\": \"ready_for_processing\"\n        }\n        \n        logger.info(\n            \"Modification request prepared\",\n            extra={\n                \"correlation_id\": correlation_id,\n                \"presentation_id\": presentation_id,\n                \"prompt_version\": prompt_version\n            }\n        )\n        \n        return JSONResponse(content=response_data)\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Modification failed: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n\n\n@router.get(\"/{presentation_id}/content\")\nasync def get_presentation_content(\n    presentation_id: str,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Get complete presentation content for display/modification\"\"\"\n    try:\n        from ...infrastructure.repositories.presentation_storage_repository import (\n            PresentationStorageRepository\n        )\n        from pathlib import Path\n        \n        # Load presentation\n        storage_repo = PresentationStorageRepository(\n            storage_path=Path(\"data/presentations\"),\n            logger=logger\n        )\n        \n        metadata = await storage_repo.load_presentation(presentation_id)\n        if not metadata:\n            raise HTTPException(status_code=404, detail=\"Presentation not found\")\n        \n        # Temporarily disable user ownership check for debugging\n        # TODO: Re-enable in production\n        # if metadata.user_id != current_user.id:\n        #     raise HTTPException(status_code=403, detail=\"Access denied\")\n        \n        # Return structured content for frontend\n        content_data = {\n            \"presentation_id\": metadata.presentation_id,\n            \"title\": metadata.title,\n            \"status\": metadata.status.value,\n            \"original_content\": metadata.original_content,\n            \"theme\": metadata.theme,\n            \"slide_count\": metadata.slide_count,\n            \"slides\": [\n                {\n                    \"slide_number\": slide.slide_number,\n                    \"title\": slide.title,\n                    \"content\": slide.content,\n                    \"layout\": slide.layout,\n                    \"speaker_notes\": slide.speaker_notes,\n                    \"assets\": [\n                        {\n                            \"asset_id\": asset.asset_id,\n                            \"asset_type\": asset.asset_type,\n                            \"cloud_url\": asset.cloud_url\n                        } for asset in slide.assets\n                    ]\n                } for slide in metadata.slides\n            ],\n            \"google_slides_url\": metadata.google_slides_url,\n            \"modification_history\": metadata.modification_history,\n            \"generation_timestamp\": metadata.generation_timestamp.isoformat(),\n            \"is_modifiable\": metadata.is_modifiable\n        }\n        \n        return JSONResponse(content=content_data)\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Failed to get presentation content: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n\n\n@router.put(\"/{presentation_id}\")\nasync def update_presentation(\n    presentation_id: str,\n    request: dict,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Update presentation content without regenerating files\"\"\"\n    try:\n        from ...infrastructure.repositories.presentation_storage_repository import (\n            PresentationStorageRepository\n        )\n        from ...domain.value_objects.complete_presentation_metadata import (\n            CompletePresentationMetadata, PresentationStatus, SlideContent\n        )\n        from pathlib import Path\n        from datetime import datetime\n        \n        # Load existing presentation\n        storage_repo = PresentationStorageRepository(\n            storage_path=Path(\"data/presentations\"),\n            logger=logger\n        )\n        \n        metadata = await storage_repo.load_presentation(presentation_id)\n        if not metadata:\n            raise HTTPException(status_code=404, detail=\"Presentation not found\")\n        \n        # Temporarily disable user ownership check for debugging\n        # TODO: Re-enable in production\n        # if metadata.user_id != current_user.id:\n        #     raise HTTPException(status_code=403, detail=\"Access denied\")\n        \n        # Update slides from request\n        updated_slides = []\n        for slide_data in request.get('slides', []):\n            slide = SlideContent(\n                slide_number=slide_data.get('slide_number', 1),\n                title=slide_data.get('title', ''),\n                content=slide_data.get('content', ''),\n                layout=slide_data.get('layout', 'TITLE_AND_CONTENT'),\n                speaker_notes=slide_data.get('notes', ''),\n                assets=[],\n                style_metadata=slide_data.get('style_metadata', {})\n            )\n            updated_slides.append(slide)\n        \n        # Create updated metadata\n        updated_metadata = CompletePresentationMetadata(\n            presentation_id=metadata.presentation_id,\n            title=request.get('title', metadata.title),\n            user_id=metadata.user_id,\n            status=PresentationStatus.MODIFIED,\n            original_content=metadata.original_content,\n            original_prompt=metadata.original_prompt,\n            theme=request.get('theme', metadata.theme),\n            output_format=metadata.output_format,\n            processing_options=metadata.processing_options,\n            slides=updated_slides,\n            assets=metadata.assets,\n            ai_analysis=metadata.ai_analysis,\n            generation_timestamp=metadata.generation_timestamp,\n            modification_history=metadata.modification_history + [{\n                'timestamp': datetime.now().isoformat(),\n                'action': 'manual_edit',\n                'changes': f'Updated {len(updated_slides)} slides'\n            }],\n            google_slides_url=metadata.google_slides_url,\n            pptx_download_url=metadata.pptx_download_url,\n            slide_count=len(updated_slides),\n            estimated_duration_minutes=metadata.estimated_duration_minutes,\n            processing_time_seconds=metadata.processing_time_seconds\n        )\n        \n        # Save updated presentation\n        await storage_repo.save_presentation(updated_metadata)\n        \n        logger.info(f\"Updated presentation {presentation_id} with {len(updated_slides)} slides\")\n        \n        return JSONResponse(content={\n            \"message\": \"Presentation updated successfully\",\n            \"presentation\": {\n                \"id\": updated_metadata.presentation_id,\n                \"title\": updated_metadata.title,\n                \"slide_count\": updated_metadata.slide_count,\n                \"theme\": updated_metadata.theme,\n                \"status\": updated_metadata.status.value,\n                \"modified_at\": datetime.now().isoformat()\n            }\n        })\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Failed to update presentation {presentation_id}: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=f\"Failed to update presentation: {str(e)}\")\n\n\n@router.post(\"/{presentation_id}/versions\")\nasync def create_presentation_version(\n    presentation_id: str,\n    request: dict,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Create a new version of the presentation with changes\"\"\"\n    try:\n        from ...infrastructure.repositories.presentation_storage_repository import (\n            PresentationStorageRepository\n        )\n        from ...domain.value_objects.complete_presentation_metadata import (\n            CompletePresentationMetadata, PresentationStatus, SlideContent\n        )\n        from pathlib import Path\n        from datetime import datetime\n        import uuid\n        \n        # Load original presentation\n        storage_repo = PresentationStorageRepository(\n            storage_path=Path(\"data/presentations\"),\n            logger=logger\n        )\n        \n        original_metadata = await storage_repo.load_presentation(presentation_id)\n        if not original_metadata:\n            raise HTTPException(status_code=404, detail=\"Original presentation not found\")\n        \n        # Temporarily disable user ownership check for debugging\n        # TODO: Re-enable in production\n        # if original_metadata.user_id != current_user.id:\n        #     raise HTTPException(status_code=403, detail=\"Access denied\")\n        \n        # Create new version ID\n        version_id = str(uuid.uuid4())\n        \n        # Update slides from request\n        updated_slides = []\n        for slide_data in request.get('slides', []):\n            slide = SlideContent(\n                slide_number=slide_data.get('slide_number', 1),\n                title=slide_data.get('title', ''),\n                content=slide_data.get('content', ''),\n                layout=slide_data.get('layout', 'TITLE_AND_CONTENT'),\n                speaker_notes=slide_data.get('notes', ''),\n                assets=[],\n                style_metadata=slide_data.get('style_metadata', {})\n            )\n            updated_slides.append(slide)\n        \n        # Create new version metadata\n        version_metadata = CompletePresentationMetadata(\n            presentation_id=version_id,\n            title=f\"{original_metadata.title} (Version {len(original_metadata.modification_history) + 2})\",\n            user_id=original_metadata.user_id,\n            status=PresentationStatus.GENERATED,\n            original_content=original_metadata.original_content,\n            original_prompt=original_metadata.original_prompt,\n            theme=request.get('theme', original_metadata.theme),\n            output_format=request.get('format', original_metadata.output_format),\n            processing_options=original_metadata.processing_options,\n            slides=updated_slides,\n            assets=original_metadata.assets,\n            ai_analysis=original_metadata.ai_analysis,\n            generation_timestamp=datetime.now(),\n            modification_history=original_metadata.modification_history + [{\n                'timestamp': datetime.now().isoformat(),\n                'action': 'version_created',\n                'original_presentation_id': presentation_id,\n                'changes': f'Created version with {len(updated_slides)} slides'\n            }],\n            google_slides_url=None,  # Will be generated if requested\n            pptx_download_url=None,  # Will be generated if requested\n            slide_count=len(updated_slides),\n            estimated_duration_minutes=original_metadata.estimated_duration_minutes,\n            processing_time_seconds=0.0\n        )\n        \n        # Save new version\n        await storage_repo.save_presentation(version_metadata)\n        \n        logger.info(f\"Created version {version_id} from presentation {presentation_id}\")\n        \n        return JSONResponse(content={\n            \"message\": \"Version created successfully\",\n            \"version\": {\n                \"id\": version_metadata.presentation_id,\n                \"title\": version_metadata.title,\n                \"slide_count\": version_metadata.slide_count,\n                \"theme\": version_metadata.theme,\n                \"status\": version_metadata.status.value,\n                \"created_at\": datetime.now().isoformat(),\n                \"original_presentation_id\": presentation_id\n            }\n        })\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Failed to create version for presentation {presentation_id}: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=f\"Failed to create version: {str(e)}\")\n\n\n@router.post(\"/{presentation_id}/regenerate\")\nasync def regenerate_presentation(\n    presentation_id: str,\n    request: Request,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Regenerate presentation from stored JSON metadata\"\"\"\n    try:\n        from ...infrastructure.repositories.presentation_storage_repository import (\n            PresentationStorageRepository\n        )\n        from ...domain.value_objects.complete_presentation_metadata import (\n            CompletePresentationMetadata, PresentationStatus\n        )\n        from pathlib import Path\n        import json\n        from datetime import datetime\n        \n        # Parse request body to get format and theme\n        request_body = await request.json() if request.headers.get('content-type') == 'application/json' else {}\n        requested_format = request_body.get('format', 'pptx')  # Default to pptx\n        requested_theme = request_body.get('theme')\n        \n        logger.info(f\"Starting regeneration for presentation {presentation_id} with format {requested_format}\")\n        \n        # Load original presentation metadata\n        storage_repo = PresentationStorageRepository(\n            storage_path=Path(\"data/presentations\"),\n            logger=logger\n        )\n        \n        original_metadata = await storage_repo.load_presentation(presentation_id)\n        if not original_metadata:\n            raise HTTPException(status_code=404, detail=\"Presentation not found\")\n        \n        # Temporarily disable user ownership check for debugging\n        # TODO: Re-enable in production\n        # if original_metadata.user_id != current_user.id:\n        #     raise HTTPException(status_code=403, detail=\"Access denied\")\n        \n        # Create updated metadata with new theme if provided\n        # Since CompletePresentationMetadata is frozen, we need to create a new instance\n        updated_theme = requested_theme if requested_theme else original_metadata.theme\n        \n        # Add regeneration entry to history\n        regeneration_entry = {\n            \"action\": \"regenerated\",\n            \"timestamp\": datetime.now().isoformat(),\n            \"format\": requested_format,\n            \"modifications\": f\"Regenerated {requested_format} from stored JSON data\"\n        }\n        updated_history = original_metadata.modification_history.copy()\n        updated_history.append(regeneration_entry)\n        \n        # Create new metadata instance with updated values\n        from dataclasses import replace\n        regenerated_metadata = replace(\n            original_metadata,\n            theme=updated_theme,\n            modification_history=updated_history\n        )\n        \n        # Regenerate actual presentation files based on requested format\n        logger.info(f\"üîç DEBUG: Regenerate format={requested_format}, can_create_google_slides={current_user.can_create_google_slides()}\")\n        \n        # Debug Google credentials in detail\n        if requested_format == \"google_slides\":\n            has_creds = current_user.has_google_credentials()\n            auth_status = current_user.get_google_authentication_status()\n            logger.info(f\"üîç DEBUG: Google auth details - has_credentials={has_creds}, auth_status={auth_status}\")\n        \n        if requested_format == \"google_slides\" and current_user.can_create_google_slides():\n            logger.info(f\"üîç DEBUG: Starting Google Slides regeneration\")\n            try:\n                # Regenerate Google Slides presentation\n                from ...renderers.google_slides_renderer import GoogleSlidesRenderer\n                from ...infrastructure.external_services.google_slides_client import GoogleSlidesClient\n                \n                # Convert slides to presentation data format\n                presentation_data = {\n                    'title': regenerated_metadata.title,\n                    'slides': [\n                        {\n                            'title': slide.title,\n                            'content': slide.content,\n                            'layout': slide.layout,\n                            'speaker_notes': slide.speaker_notes\n                        } for slide in regenerated_metadata.slides\n                    ]\n                }\n                \n                # Create Google Slides renderer with user's credentials\n                slides_client = GoogleSlidesClient(\n                    credentials_path=\"\", \n                    scopes=[\n                        \"https://www.googleapis.com/auth/presentations\",\n                        \"https://www.googleapis.com/auth/drive.file\"\n                    ],\n                    logger=logger\n                )\n                renderer = GoogleSlidesRenderer(slides_client, debug=True)\n                \n                # Render to Google Slides using the user's OAuth tokens\n                result = renderer.render(\n                    presentation_data, \n                    access_token=current_user.google_credentials.access_token\n                )\n                \n                if result.get('success'):\n                    regenerated_metadata = replace(\n                        regenerated_metadata,\n                        google_slides_url=result.get('url')\n                    )\n                    logger.info(f\"Successfully regenerated Google Slides: {regenerated_metadata.google_slides_url}\")\n                else:\n                    logger.error(f\"Failed to regenerate Google Slides: {result.get('error')}\")\n                    # Fall back to mock URL for now\n                    slides_id = f\"regenerated_{presentation_id[-8:]}\"\n                    regenerated_metadata = replace(\n                        regenerated_metadata,\n                        google_slides_url=f\"https://docs.google.com/presentation/d/{slides_id}/edit\"\n                    )\n                    \n            except Exception as e:\n                logger.error(f\"Error regenerating Google Slides: {e}\")\n                # Fall back to mock URL\n                slides_id = f\"regenerated_{presentation_id[-8:]}\"\n                regenerated_metadata = replace(\n                    regenerated_metadata,\n                    google_slides_url=f\"https://docs.google.com/presentation/d/{slides_id}/edit\"\n                )\n                \n        elif requested_format == \"google_slides\" and not current_user.can_create_google_slides():\n            logger.warning(f\"üîç DEBUG: Cannot create Google Slides - user lacks proper credentials\")\n            # Return error response to inform user they need to connect Google account\n            auth_status = current_user.get_google_authentication_status()\n            raise HTTPException(\n                status_code=403, \n                detail=f\"Google Slides generation requires Google authentication. Reason: {auth_status.get('reason', 'Unknown')}\"\n            )\n        \n        elif requested_format == \"pptx\":\n            try:\n                # Regenerate PPTX file\n                from ...renderers.pptx_renderer import PptxRenderer\n                from ...domain.adapters.presentation_adapter import PresentationAdapter\n                \n                # Convert to presentation format for renderer\n                presentation_dict = {\n                    'title': regenerated_metadata.title,\n                    'theme': regenerated_metadata.theme,\n                    'slides': [\n                        {\n                            'title': slide.title,\n                            'content': slide.content,\n                            'layout': slide.layout,\n                            'speaker_notes': slide.speaker_notes\n                        } for slide in regenerated_metadata.slides\n                    ]\n                }\n                \n                logger.info(f\"üîç DEBUG: Preparing to render PPTX with {len(presentation_dict['slides'])} slides\")\n                logger.info(f\"üîç DEBUG: First slide: {presentation_dict['slides'][0] if presentation_dict['slides'] else 'No slides'}\")\n                \n                renderer = PptxRenderer()\n                output_path = f\"data/presentations/{presentation_id}.pptx\"\n                \n                result = renderer.render(presentation_dict, output_path)\n                \n                logger.info(f\"üîç DEBUG: Render result: {result}\")\n                \n                if result.get('success'):\n                    import os\n                    if os.path.exists(output_path):\n                        # Generate secure download token\n                        download_token = _generate_download_token(presentation_id, current_user.id)\n                        download_url = f\"http://localhost:8000/presentations/{presentation_id}/download/{download_token}\"\n                        \n                        regenerated_metadata = replace(\n                            regenerated_metadata,\n                            pptx_download_url=download_url\n                        )\n                        logger.info(f\"Successfully regenerated PPTX: {output_path}\")\n                    else:\n                        logger.error(f\"PPTX file not found after regeneration: {output_path}\")\n                else:\n                    logger.error(f\"Failed to regenerate PPTX: {result.get('error')}\")\n                    \n            except Exception as e:\n                logger.error(f\"Error regenerating PPTX: {e}\")\n        \n        # Save the regenerated presentation metadata\n        await storage_repo.save_presentation(regenerated_metadata)\n        \n        # Return response\n        response_data = {\n            \"success\": True,\n            \"presentation\": {\n                \"id\": presentation_id,\n                \"title\": regenerated_metadata.title,\n                \"slide_count\": regenerated_metadata.slide_count,\n                \"theme\": regenerated_metadata.theme,\n                \"status\": regenerated_metadata.status.value,\n                \"output_format\": regenerated_metadata.output_format,\n                \"google_slides_url\": regenerated_metadata.google_slides_url,\n                \"download_url\": regenerated_metadata.pptx_download_url,\n                \"created_at\": regenerated_metadata.generation_timestamp.isoformat(),\n                \"regenerated_format\": requested_format\n            },\n            \"message\": f\"Presentation successfully regenerated in {requested_format} format\"\n        }\n        \n        logger.info(f\"Successfully regenerated presentation {presentation_id} in {requested_format} format\")\n        return JSONResponse(content=response_data)\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Regeneration failed: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=f\"Regeneration failed: {str(e)}\")\n\n\n@router.post(\"/{presentation_id}/request-download\")\nasync def request_presentation_download(\n    presentation_id: str,\n    email: str = Form(..., description=\"Email address to send download link\"),\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Request PPTX download - sends email when file is ready.\"\"\"\n    logger.info(\n        \"Requesting presentation download\",\n        extra={\n            \"correlation_id\": correlation_id, \n            \"presentation_id\": presentation_id,\n            \"user_email\": email\n        }\n    )\n    \n    try:\n        # Queue background task for PPTX generation\n        download_request_id = str(uuid.uuid4())\n        \n        # Start background task (in production, use Celery/Redis)\n        import asyncio\n        asyncio.create_task(_generate_and_email_pptx(\n            presentation_id=presentation_id,\n            download_request_id=download_request_id,\n            user_email=email,\n            user_id=current_user.id,\n            correlation_id=correlation_id\n        ))\n        \n        return JSONResponse({\n            \"message\": \"Download request received. You will receive an email when your presentation is ready.\",\n            \"download_request_id\": download_request_id,\n            \"status\": \"processing\",\n            \"estimated_time_minutes\": 2,\n            \"status_url\": f\"/presentations/{presentation_id}/download-status/{download_request_id}\"\n        })\n        \n    except Exception as e:\n        logger.error(\n            \"Download request failed\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)},\n            exc_info=True\n        )\n        raise HTTPException(status_code=500, detail=\"Failed to process download request\")\n\n\n@router.get(\"/{presentation_id}/download-status/{download_request_id}\")\nasync def check_download_status(\n    presentation_id: str,\n    download_request_id: str,\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Check status of download request.\"\"\"\n    # In production, this would check Redis/database for status\n    # For now, return mock status\n    return JSONResponse({\n        \"download_request_id\": download_request_id,\n        \"status\": \"processing\",  # processing, completed, failed\n        \"progress_percentage\": 75,\n        \"estimated_time_remaining_seconds\": 30,\n        \"message\": \"Generating PPTX file with speaker notes...\"\n    })\n\n\n@router.get(\"/{presentation_id}/download/{download_token}\")\nasync def download_presentation_file(\n    presentation_id: str,\n    download_token: str,\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Secure download endpoint with token validation.\"\"\"\n    logger.info(\n        \"Secure file download\",\n        extra={\n            \"correlation_id\": correlation_id, \n            \"presentation_id\": presentation_id,\n            \"download_token\": download_token[:8] + \"...\"\n        }\n    )\n    \n    try:\n        # Validate download token (in production, check database/Redis)\n        if not _validate_download_token(download_token, presentation_id):\n            raise HTTPException(status_code=401, detail=\"Invalid or expired download token\")\n        \n        # Look for the actual generated PPTX file\n        from pathlib import Path\n        \n        # Look for PPTX file in the presentations directory (same logic as regular download endpoint)\n        base_dir = Path(\"data/presentations\").resolve()\n        if not base_dir.exists():\n            # Fallback: try relative to API directory\n            api_dir = Path(__file__).parent.parent.parent.parent\n            base_dir = api_dir / \"data\" / \"presentations\"\n        \n        # Try different possible filenames\n        possible_files = [\n            base_dir / f\"{presentation_id}.pptx\",\n            base_dir / f\"presentation_{presentation_id}.pptx\",\n            base_dir / f\"test_{presentation_id}.pptx\",\n            base_dir / f\"test_stream_{presentation_id}.pptx\",\n            base_dir / f\"regenerated_{presentation_id}.pptx\"\n        ]\n        \n        # Also check for files with timestamps\n        for file in base_dir.glob(\"*.pptx\"):\n            if presentation_id in file.name:\n                possible_files.append(file)\n        \n        # Find the first existing file\n        pptx_file = None\n        for file_path in possible_files:\n            if file_path.exists():\n                pptx_file = file_path\n                break\n        \n        if not pptx_file:\n            # No PPTX file found - return 404\n            raise HTTPException(status_code=404, detail=\"PPTX file not found. Generate the presentation first.\")\n        \n        file_path = str(pptx_file)\n        \n        from fastapi.responses import FileResponse\n        return FileResponse(\n            path=file_path,\n            filename=f\"presentation_{presentation_id[:8]}.pptx\",\n            media_type=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\"\n        )\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(\n            \"Secure download failed\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)},\n            exc_info=True\n        )\n        raise HTTPException(status_code=500, detail=\"Failed to download presentation file\")\n\n\n@router.post(\"/from-voice\", response_model=VoiceProcessingResponseSchema)\nasync def create_presentation_from_voice(\n    audio_file: UploadFile = File(..., description=\"Audio file (WAV, MP3, M4A, FLAC)\"),\n    format: str = Form(\"google_slides\", description=\"Output format\"),\n    theme: str = Form(\"professional\", description=\"Presentation theme\"),\n    max_slides: Optional[int] = Form(10, description=\"Maximum number of slides\"),\n    include_speaker_notes: bool = Form(True, description=\"Include speaker notes\"),\n    auto_enhance: bool = Form(True, description=\"Auto-enhance with AI\"),\n    current_user: User = Depends(get_current_user),\n    use_case: ProcessVoiceNoteUseCase = Depends(get_process_voice_note_use_case),\n    correlation_id: str = Depends(get_correlation_id)\n) -> VoiceProcessingResponseSchema:\n    \"\"\"\n    Create a presentation from a voice recording.\n    \n    This endpoint accepts audio files and converts them to professional presentations\n    using speech-to-text and AI-powered content analysis.\n    \n    Supported audio formats: WAV, MP3, M4A, FLAC\n    Maximum duration: 10 minutes\n    \"\"\"\n    logger.info(\n        \"Processing voice note for presentation\",\n        extra={\n            \"correlation_id\": correlation_id,\n            \"user_id\": current_user.id,\n            \"audio_filename\": audio_file.filename,\n            \"audio_content_type\": audio_file.content_type,\n            \"format\": format\n        }\n    )\n    \n    try:\n        # Validate audio file\n        _validate_audio_file(audio_file)\n        \n        # Read audio data\n        audio_data = await audio_file.read()\n        \n        # Create use case request\n        use_case_request = ProcessVoiceNoteRequest(\n            audio_data=audio_data,\n            audio_format=AudioFormat.from_mime_type(audio_file.content_type),\n            filename=audio_file.filename,\n            output_format=OutputFormat.from_string(format),\n            theme=ThemeType.from_string(theme),\n            google_credentials=current_user.google_credentials if format == \"google_slides\" else None,\n            preferences=_create_voice_processing_preferences(\n                max_slides, include_speaker_notes, auto_enhance\n            ),\n            user_id=current_user.id,\n            correlation_id=correlation_id\n        )\n        \n        # Execute use case\n        response = await use_case.execute(use_case_request)\n        \n        # Return response\n        return VoiceProcessingResponseSchema(\n            id=str(response.presentation_id),\n            title=response.title,\n            slide_count=response.slide_count,\n            url=response.url,\n            transcription=response.transcription,\n            processing_time_seconds=response.processing_time_seconds,\n            confidence_score=response.confidence_score,\n            status=\"completed\",\n            created_at=response.created_at\n        )\n        \n    except ValidationException as e:\n        logger.warning(\n            \"Voice processing validation error\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n        )\n        raise HTTPException(status_code=400, detail=str(e))\n        \n    except DomainException as e:\n        logger.warning(\n            \"Voice processing domain error\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n        )\n        raise HTTPException(status_code=422, detail=f\"Business rule violation: {str(e)}\")\n        \n    except ApplicationException as e:\n        logger.error(\n            \"Voice processing application error\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)}\n        )\n        raise HTTPException(status_code=500, detail=\"Failed to process voice note\")\n        \n    except Exception as e:\n        logger.error(\n            \"Unexpected error processing voice note\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)},\n            exc_info=True\n        )\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n\n\n@router.get(\"/{presentation_id}\", response_model=PresentationResponseSchema)\nasync def get_presentation(\n    presentation_id: str,\n    current_user: User = Depends(get_current_user),\n    correlation_id: str = Depends(get_correlation_id)\n) -> PresentationResponseSchema:\n    \"\"\"Get presentation details by ID.\"\"\"\n    # Implementation for retrieving presentation\n    pass\n\n\n@router.post(\"/{presentation_id}/render\")\nasync def render_presentation(\n    presentation_id: str,\n    format: str = Form(..., description=\"Output format (google_slides, pptx)\"),\n    current_user: User = Depends(get_current_user),\n    use_case: RenderPresentationUseCase = Depends(get_render_presentation_use_case),\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Render an existing presentation to a specific format.\"\"\"\n    logger.info(\n        \"Rendering presentation\",\n        extra={\n            \"correlation_id\": correlation_id,\n            \"user_id\": current_user.id,\n            \"presentation_id\": presentation_id,\n            \"format\": format\n        }\n    )\n    \n    try:\n        request = RenderPresentationRequest(\n            presentation_id=presentation_id,\n            output_format=OutputFormat.from_string(format),\n            google_credentials=current_user.google_credentials if format == \"google_slides\" else None,\n            user_id=current_user.id,\n            correlation_id=correlation_id\n        )\n        \n        response = await use_case.execute(request)\n        \n        if response.output_format.is_google_slides():\n            return JSONResponse({\n                \"url\": response.url,\n                \"format\": format,\n                \"status\": \"completed\"\n            })\n        else:\n            # For PPTX, return file download response\n            return Response(\n                content=response.file_data,\n                media_type=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\",\n                headers={\n                    \"Content-Disposition\": f\"attachment; filename={response.filename}\"\n                }\n            )\n        \n    except Exception as e:\n        logger.error(\n            \"Error rendering presentation\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)},\n            exc_info=True\n        )\n        raise HTTPException(status_code=500, detail=\"Failed to render presentation\")\n\n\ndef _validate_audio_file(audio_file: UploadFile) -> None:\n    \"\"\"Validate uploaded audio file.\"\"\"\n    # Check content type\n    allowed_types = [\n        \"audio/wav\", \"audio/wave\", \"audio/x-wav\",\n        \"audio/mpeg\", \"audio/mp3\",\n        \"audio/mp4\", \"audio/m4a\",\n        \"audio/flac\", \"audio/x-flac\"\n    ]\n    \n    if audio_file.content_type not in allowed_types:\n        raise ValidationException(\n            f\"Unsupported audio format: {audio_file.content_type}. \"\n            f\"Supported formats: WAV, MP3, M4A, FLAC\"\n        )\n    \n    # Check file size (10MB limit)\n    if hasattr(audio_file, 'size') and audio_file.size > 10 * 1024 * 1024:\n        raise ValidationException(\"Audio file too large (max 10MB)\")\n\n\ndef _create_presentation_options(request: CreatePresentationSchema):\n    \"\"\"Create presentation options from API request.\"\"\"\n    from ...application.dto.presentation_options import PresentationOptions\n    \n    return PresentationOptions(\n        include_speaker_notes=request.include_speaker_notes,\n        auto_generate_diagrams=request.auto_generate_diagrams,\n        max_slides=request.max_slides,\n        process_assets=request.process_assets,\n        strict_validation=request.strict_validation\n    )\n\n\ndef _create_voice_processing_preferences(\n    max_slides: Optional[int],\n    include_speaker_notes: bool,\n    auto_enhance: bool\n):\n    \"\"\"Create voice processing preferences.\"\"\"\n    from ...application.dto.voice_processing_preferences import VoiceProcessingPreferences\n    \n    return VoiceProcessingPreferences(\n        max_slides=max_slides or 10,\n        include_speaker_notes=include_speaker_notes,\n        auto_enhance=auto_enhance,\n        extract_key_points=True,\n        suggest_visuals=auto_enhance\n    )\n\n\n# ==================== HELPER FUNCTIONS ====================\n\nasync def _generate_and_email_pptx(\n    presentation_id: str,\n    download_request_id: str, \n    user_email: str,\n    user_id: str,\n    correlation_id: str\n):\n    \"\"\"Background task to generate PPTX and email download link.\"\"\"\n    try:\n        logger.info(\n            \"Starting background PPTX generation\",\n            extra={\"correlation_id\": correlation_id, \"presentation_id\": presentation_id}\n        )\n        \n        # Simulate processing time\n        import asyncio\n        await asyncio.sleep(2)  # In production, this would be actual PPTX generation\n        \n        # Generate secure download token\n        download_token = _generate_download_token(presentation_id, user_id)\n        download_url = f\"https://app.makeslides.com/presentations/{presentation_id}/download/{download_token}\"\n        \n        # Send email notification\n        await _send_download_ready_email(\n            user_email=user_email,\n            presentation_id=presentation_id,\n            download_url=download_url,\n            expires_in_hours=24\n        )\n        \n        logger.info(\n            \"PPTX generation and email sent successfully\",\n            extra={\"correlation_id\": correlation_id, \"user_email\": user_email}\n        )\n        \n    except Exception as e:\n        logger.error(\n            \"Background PPTX generation failed\",\n            extra={\"correlation_id\": correlation_id, \"error\": str(e)},\n            exc_info=True\n        )\n        \n        # Send error notification email\n        await _send_download_error_email(\n            user_email=user_email,\n            presentation_id=presentation_id,\n            error_message=str(e)\n        )\n\n\nasync def _send_download_ready_email(\n    user_email: str,\n    presentation_id: str,\n    download_url: str,\n    expires_in_hours: int = 24\n):\n    \"\"\"Send email notification when download is ready.\"\"\"\n    # In production, integrate with SendGrid, AWS SES, or similar\n    email_subject = \"üìä Your MakeSlides presentation is ready!\"\n    email_body = f\"\"\"\nHi there!\n\nYour AI-generated presentation is ready for download.\n\nüéØ Presentation ID: {presentation_id[:8]}...\nüì• Download Link: {download_url}\n‚è∞ Link expires in {expires_in_hours} hours\n\nThe download includes:\n‚Ä¢ PPTX file (compatible with PowerPoint, Keynote, Google Slides)\n‚Ä¢ CSV file with speaker notes for easy copy/paste\n\nBest regards,\nThe MakeSlides Team\n\n--\nThis is an automated email. The download link is secure and expires automatically.\n\"\"\"\n    \n    # Mock email sending (replace with actual email service)\n    logger.info(f\"üìß Email sent to {user_email}: {email_subject}\")\n    print(f\"Mock Email to {user_email}:\")\n    print(f\"Subject: {email_subject}\")\n    print(f\"Body: {email_body}\")\n\n\nasync def _send_download_error_email(\n    user_email: str,\n    presentation_id: str,\n    error_message: str\n):\n    \"\"\"Send email notification when download fails.\"\"\"\n    email_subject = \"‚ùå MakeSlides presentation generation failed\"\n    email_body = f\"\"\"\nWe're sorry! There was an issue generating your presentation.\n\nüéØ Presentation ID: {presentation_id[:8]}...\n‚ùå Error: {error_message}\n\nPlease try again or contact support if the issue persists.\n\nBest regards,\nThe MakeSlides Team\n\"\"\"\n    \n    logger.info(f\"üìß Error email sent to {user_email}: {email_subject}\")\n    print(f\"Mock Error Email to {user_email}:\")\n    print(f\"Subject: {email_subject}\")\n    print(f\"Body: {email_body}\")\n\n\ndef _clean_json_response(json_str: str) -> str:\n    \"\"\"Clean and fix common JSON issues in Claude responses\"\"\"\n    import re\n    \n    # Remove any trailing commas before closing braces/brackets\n    json_str = re.sub(r',\\s*}', '}', json_str)\n    json_str = re.sub(r',\\s*]', ']', json_str)\n    \n    # Remove any control characters that might break JSON\n    json_str = ''.join(char for char in json_str if ord(char) >= 32 or char in '\\n\\r\\t')\n    \n    # Fix common Claude-specific issues\n    # Remove any text before the first {\n    first_brace = json_str.find('{')\n    if first_brace > 0:\n        json_str = json_str[first_brace:]\n    \n    # Remove any text after the last }\n    last_brace = json_str.rfind('}')\n    if last_brace > 0:\n        json_str = json_str[:last_brace + 1]\n    \n    return json_str\n\n\ndef _generate_download_token(presentation_id: str, user_id: str) -> str:\n    \"\"\"Generate secure download token.\"\"\"\n    import jwt\n    from datetime import datetime, timedelta\n    \n    payload = {\n        \"presentation_id\": presentation_id,\n        \"user_id\": user_id,\n        \"exp\": datetime.utcnow() + timedelta(hours=24),\n        \"purpose\": \"download\"\n    }\n    \n    # In production, use proper JWT secret from settings\n    secret = \"your-download-token-secret\"  # Should be from environment\n    return jwt.encode(payload, secret, algorithm=\"HS256\")\n\n\ndef _validate_download_token(token: str, presentation_id: str) -> bool:\n    \"\"\"Validate download token.\"\"\"\n    try:\n        import jwt\n        secret = \"your-download-token-secret\"  # Should be from environment\n        payload = jwt.decode(token, secret, algorithms=[\"HS256\"])\n        \n        return (\n            payload.get(\"presentation_id\") == presentation_id and\n            payload.get(\"purpose\") == \"download\"\n        )\n    except Exception:\n        return False\n\n\n# Removed _generate_pptx_file function - now using proper PptxRenderer for all PPTX generation\n\n\n# ==================== TEST ENDPOINTS (NO AUTH) ====================\n\n@router.post(\"/test/create\", response_model=PresentationResponseSchema, tags=[\"Testing\"])\nasync def test_create_presentation(\n    request: CreatePresentationSchema,\n    correlation_id: str = Depends(get_correlation_id),\n    use_case: CreatePresentationUseCase = Depends(get_create_presentation_use_case)\n):\n    \"\"\"TEST ENDPOINT: Create presentation without authentication (for testing).\"\"\"\n    logger = logging.getLogger(__name__)\n    logger.info(f\"Test: Creating presentation with content length: {len(request.content)}\")\n    \n    try:\n        # Create a mock user for testing\n        mock_user_id = \"test_user_123\"\n        \n        # Transform API schema to use case request  \n        use_case_request = CreatePresentationRequest(\n            content=request.content,\n            output_format=OutputFormat.from_string(request.format),\n            theme=ThemeType.from_string(request.theme),\n            google_credentials=None,  # No Google creds for test\n            options=_create_presentation_options(request),\n            user_id=mock_user_id,\n            correlation_id=correlation_id\n        )\n        \n        # Execute use case\n        response = await use_case.execute(use_case_request)\n        \n        # Transform response\n        return PresentationResponseSchema(\n            id=str(response.presentation_id),\n            title=response.title,\n            slide_count=response.slide_count,\n            url=response.url,\n            format=request.format,\n            theme=request.theme,\n            created_at=response.created_at.isoformat(),\n            correlation_id=correlation_id\n        )\n        \n    except (DomainException, ApplicationException) as e:\n        logger.error(f\"Test presentation creation failed: {e}\")\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Test presentation creation error: {e}\", exc_info=True)\n        raise HTTPException(status_code=500, detail=\"Failed to create presentation\")\n\n\n@router.get(\"/test/hello\", tags=[\"Testing\"])\nasync def test_hello():\n    \"\"\"Simple test endpoint to verify API is working.\"\"\"\n    return {\n        \"message\": \"Hello from MakeSlides API!\",\n        \"status\": \"working\",\n        \"endpoints\": {\n            \"create_presentation\": \"/api/presentations/test/create\",\n            \"create_with_streaming\": \"/api/presentations/test/create-stream\",\n            \"test_pptx_only\": \"/api/presentations/test/pptx-only\",\n            \"test_auth\": \"/api/presentations/test/auth\",\n            \"api_docs\": \"/docs\"\n        }\n    }\n\n\n@router.get(\"/test/auth\", tags=[\"Testing\"])\nasync def test_auth_debug(\n    request: Request,\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"Debug endpoint to test authentication without requiring valid token.\"\"\"\n    logger = logging.getLogger(__name__)\n    \n    # Extract headers for debugging\n    auth_header = request.headers.get(\"Authorization\")\n    all_headers = dict(request.headers)\n    \n    debug_info = {\n        \"message\": \"Auth debug endpoint\",\n        \"received_headers\": {\n            \"authorization\": auth_header,\n            \"user_agent\": all_headers.get(\"user-agent\"),\n            \"content_type\": all_headers.get(\"content-type\")\n        },\n        \"correlation_id\": correlation_id,\n        \"supabase_config\": {\n            \"url_configured\": bool(os.getenv(\"SUPABASE_URL\")),\n            \"anon_key_configured\": bool(os.getenv(\"SUPABASE_ANON_KEY\"))\n        }\n    }\n    \n    # Try to parse the token if provided\n    if auth_header and auth_header.startswith(\"Bearer \"):\n        token = auth_header[7:]\n        debug_info[\"token_info\"] = {\n            \"length\": len(token),\n            \"starts_with\": token[:20] + \"...\" if len(token) > 20 else token,\n            \"looks_like_jwt\": token.count('.') == 2\n        }\n        \n        # Try to decode JWT without verification\n        if token.count('.') == 2:\n            try:\n                import jwt\n                payload = jwt.decode(token, options={\"verify_signature\": False})\n                debug_info[\"jwt_payload\"] = {\n                    \"iss\": payload.get(\"iss\"),\n                    \"sub\": payload.get(\"sub\"),\n                    \"exp\": payload.get(\"exp\"),\n                    \"iat\": payload.get(\"iat\"),\n                    \"aud\": payload.get(\"aud\")\n                }\n            except Exception as e:\n                debug_info[\"jwt_decode_error\"] = str(e)\n    \n    logger.info(f\"Auth debug request: {debug_info}\")\n    return debug_info\n\n\n@router.post(\"/test/pptx-only\", tags=[\"Testing\"])\nasync def test_pptx_only():\n    \"\"\"Test PPTX rendering with minimal hard-coded data.\"\"\"\n    logger = logging.getLogger(__name__)\n    \n    try:\n        # Create minimal test data\n        test_data = {\n            \"title\": \"Test Presentation\",\n            \"slides\": [\n                {\n                    \"title\": \"Welcome\",\n                    \"content\": \"This is a test slide\",\n                    \"layout\": \"TITLE_AND_CONTENT\"\n                },\n                {\n                    \"title\": \"Bullet Points\",\n                    \"content\": \"‚Ä¢ Point 1\\n‚Ä¢ Point 2\\n‚Ä¢ Point 3\",\n                    \"layout\": \"TITLE_AND_CONTENT\"\n                }\n            ]\n        }\n        \n        from ...renderers.pptx_renderer import PptxRenderer\n        renderer = PptxRenderer()\n        \n        output_path = f\"debug_test_{int(time.time())}.pptx\"\n        result = renderer.render(test_data, output_path)\n        \n        if result.get('success'):\n            import os\n            file_size = os.path.getsize(output_path) if os.path.exists(output_path) else 0\n            return {\n                \"success\": True,\n                \"message\": f\"PPTX created successfully: {output_path}\",\n                \"file\": output_path,\n                \"size_bytes\": file_size,\n                \"test_data\": test_data\n            }\n        else:\n            return {\n                \"success\": False,\n                \"error\": result.get('error', 'Unknown error'),\n                \"test_data\": test_data\n            }\n            \n    except Exception as e:\n        logger.error(f\"PPTX test failed: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"error\": str(e)\n        }\n\n\n@router.post(\"/test/pptx-with-csv-notes\", tags=[\"Testing\"])\nasync def test_pptx_with_csv_notes():\n    \"\"\"Test PPTX + CSV notes workflow with dual-file output.\"\"\"\n    logger = logging.getLogger(__name__)\n    \n    try:\n        # Create test data with speaker notes\n        test_data = {\n            \"title\": \"Test Presentation with Speaker Notes\",\n            \"slides\": [\n                {\n                    \"title\": \"Welcome to Our Presentation\",\n                    \"content\": \"This presentation demonstrates our dual-file approach for speaker notes compatibility.\",\n                    \"layout\": \"TITLE_AND_CONTENT\",\n                    \"facilitator_notes\": \"Welcome everyone warmly. Explain that this solves the Keynote/PowerPoint compatibility issue while preserving speaker notes functionality.\"\n                },\n                {\n                    \"title\": \"The Innovation\",\n                    \"content\": \"‚Ä¢ Clean PPTX files (universal compatibility)\\n‚Ä¢ Separate CSV with speaker notes\\n‚Ä¢ Easy copy/paste workflow\\n‚Ä¢ Best of both worlds!\",\n                    \"layout\": \"TITLE_AND_CONTENT\", \n                    \"facilitator_notes\": \"Emphasize each benefit. Show how the CSV makes it easy to copy notes during presentation. Highlight that we solved a real compatibility problem.\"\n                },\n                {\n                    \"title\": \"How It Works\",\n                    \"content\": \"1. Generate PPTX without embedded notes\\n2. Create CSV file with all speaker notes\\n3. Copy/paste notes as needed during presentation\",\n                    \"layout\": \"TITLE_AND_CONTENT\",\n                    \"notes\": \"Walk through the workflow step by step. Maybe demonstrate opening the CSV file. Emphasize the simplicity.\"\n                }\n            ]\n        }\n        \n        from ...renderers.pptx_renderer import PptxRenderer\n        renderer = PptxRenderer()\n        \n        output_path = f\"test_dual_output_{int(time.time())}.pptx\"\n        result = renderer.render(test_data, output_path)\n        \n        if result.get('success'):\n            import os\n            pptx_size = os.path.getsize(result['output_path']) if os.path.exists(result['output_path']) else 0\n            csv_size = os.path.getsize(result['csv_path']) if result.get('csv_path') and os.path.exists(result['csv_path']) else 0\n            \n            return {\n                \"success\": True,\n                \"message\": \"Dual-file presentation created successfully!\",\n                \"pptx_file\": result['output_path'],\n                \"csv_file\": result.get('csv_path'),\n                \"pptx_size_bytes\": pptx_size,\n                \"csv_size_bytes\": csv_size,\n                \"slide_count\": result.get('slide_count'),\n                \"workflow\": {\n                    \"step_1\": \"Open the PPTX file in your presentation software (Keynote/PowerPoint)\",\n                    \"step_2\": \"Open the CSV file to view speaker notes\",\n                    \"step_3\": \"Copy/paste notes as needed during your presentation\"\n                },\n                \"test_data\": test_data\n            }\n        else:\n            return {\n                \"success\": False,\n                \"error\": result.get('error', 'Unknown error'),\n                \"test_data\": test_data\n            }\n            \n    except Exception as e:\n        logger.error(f\"Dual-file test failed: {e}\", exc_info=True)\n        return {\n            \"success\": False,\n            \"error\": str(e)\n        }\n\n\n@router.post(\"/test/create-stream\", tags=[\"Testing\"])\nasync def test_create_presentation_stream(\n    request: CreatePresentationSchema,\n    correlation_id: str = Depends(get_correlation_id)\n):\n    \"\"\"TEST ENDPOINT: Create presentation with streaming thinking (SSE).\"\"\"\n    from fastapi.responses import StreamingResponse\n    import json\n    import asyncio\n    \n    async def generate_sse():\n        try:\n            # Send initial status\n            yield f\"data: {json.dumps({'type': 'status', 'message': 'Starting analysis...'})}\\n\\n\"\n            \n            # Import here to avoid circular imports\n            from ...infrastructure.external_services.claude_content_analyzer import ClaudeContentAnalyzer\n            from ...infrastructure.configuration.settings import Settings\n            from dotenv import load_dotenv\n            from pathlib import Path\n            env_path = Path(__file__).parent.parent.parent.parent.parent / \".env\"\n            load_dotenv(env_path)\n            \n            settings = Settings.load_from_environment()\n            \n            # Create analyzer with extended thinking enabled\n            analyzer = ClaudeContentAnalyzer(\n                api_key=settings.anthropic.api_key,\n                use_extended_thinking=True,\n                debug=True\n            )\n            \n            yield f\"data: {json.dumps({'type': 'thinking_start', 'message': 'Claude is analyzing your content...'})}\\n\\n\"\n            \n            # Create a custom analyzer that yields SSE events\n            response_text = \"\"\n            \n            prompt = analyzer._build_sophisticated_analysis_prompt(request.content)\n            \n            with analyzer.client.messages.stream(\n                model=\"claude-3-7-sonnet-20250219\",\n                max_tokens=20000,\n                thinking={\"type\": \"enabled\", \"budget_tokens\": 4000},\n                system=\"You are an expert presentation designer who creates engaging presentations with diagrams. Think carefully about the content structure and visual elements before generating your JSON response.\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            ) as stream:\n                \n                for event in stream:\n                    if event.type == \"content_block_delta\":\n                        if getattr(event.delta, \"type\", \"\") == \"thinking_delta\":\n                            thinking = getattr(event.delta, \"thinking\", \"\")\n                            # Send thinking content as SSE\n                            yield f\"data: {json.dumps({'type': 'thinking', 'content': thinking})}\\n\\n\"\n                            \n                        elif getattr(event.delta, \"type\", \"\") == \"text_delta\":\n                            delta_text = event.delta.text\n                            response_text += delta_text\n                            # Send response content as SSE\n                            yield f\"data: {json.dumps({'type': 'response', 'content': delta_text})}\\n\\n\"\n            \n            yield f\"data: {json.dumps({'type': 'analysis_complete', 'message': 'Analysis complete, building presentation...'})}\\n\\n\"\n            \n            # Parse and create presentation\n            from ...domain.adapters.presentation_adapter import PresentationAdapter\n            try:\n                # Extract JSON from response\n                json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n                if json_match:\n                    json_str = json_match.group()\n                    data = json.loads(json_str)\n                    presentation = PresentationAdapter.from_dict(data)\n                    \n                    yield f\"data: {json.dumps({'type': 'presentation_created', 'presentation': {'title': presentation.title, 'slide_count': presentation.slide_count}})}\\n\\n\"\n                    \n                    # Save presentation to storage for future reference\n                    try:\n                        from ...domain.value_objects.complete_presentation_metadata import (\n                            CompletePresentationMetadata, PresentationStatus, SlideContent\n                        )\n                        from ...infrastructure.repositories.presentation_storage_repository import (\n                            PresentationStorageRepository\n                        )\n                        from pathlib import Path\n                        from datetime import datetime\n                        \n                        # Convert presentation to storage format\n                        storage_slides = []\n                        for i, slide in enumerate(presentation.slides):\n                            storage_slide = SlideContent(\n                                slide_number=i + 1,\n                                title=slide.title,\n                                content=slide.content,\n                                layout=slide.layout.value if hasattr(slide, 'layout') and hasattr(slide.layout, 'value') else 'TITLE_AND_CONTENT',\n                                speaker_notes=getattr(slide, 'speaker_notes', ''),\n                                assets=[],\n                                style_metadata={\"theme\": request.theme}\n                            )\n                            storage_slides.append(storage_slide)\n                        \n                        # Create presentation metadata for storage\n                        storage_presentation_id = str(uuid.uuid4())\n                        presentation_metadata = CompletePresentationMetadata(\n                            presentation_id=storage_presentation_id,\n                            title=presentation.title,\n                            user_id=current_user.id,\n                            status=PresentationStatus.GENERATED,\n                            original_content=request.content,\n                            original_prompt=None,\n                            theme=request.theme,\n                            output_format=request.format,\n                            processing_options={},\n                            slides=storage_slides,\n                            assets=[],\n                            ai_analysis={},\n                            generation_timestamp=datetime.now(),\n                            modification_history=[],\n                            google_slides_url=None,\n                            pptx_download_url=None,\n                            slide_count=presentation.slide_count,\n                            estimated_duration_minutes=8,\n                            processing_time_seconds=0.0\n                        )\n                        \n                        # Save to storage\n                        storage_repo = PresentationStorageRepository(\n                            storage_path=Path(\"data/presentations\"),\n                            logger=logger\n                        )\n                        await storage_repo.save_presentation(presentation_metadata)\n                        \n                        yield f\"data: {json.dumps({'type': 'storage_success', 'message': 'Presentation saved to storage'})}\\n\\n\"\n                        \n                    except Exception as storage_error:\n                        logger.error(f\"Failed to save presentation: {storage_error}\")\n                        storage_error_msg = f'Storage failed: {str(storage_error)}'\n                        yield f\"data: {json.dumps({'type': 'storage_error', 'message': storage_error_msg})}\\n\\n\"\n                    \n                    # Now render the presentation\n                    rendering_msg = f'Rendering to {request.format.upper()}...'\n                    yield f\"data: {json.dumps({'type': 'rendering_start', 'message': rendering_msg})}\\n\\n\"\n                    \n                    try:\n                        if request.format.lower() == 'pptx':\n                            # Render to PPTX\n                            from ...renderers.pptx_renderer import PptxRenderer\n                            renderer = PptxRenderer()\n                            \n                            # Convert presentation back to dict for renderer\n                            presentation_dict = PresentationAdapter.to_dict(presentation)\n                            \n                            # Debug: show what we're sending to renderer\n                            title = presentation_dict.get('title', 'Unknown')\n                            slide_count = len(presentation_dict.get('slides', []))\n                            yield f\"data: {json.dumps({'type': 'render_info', 'message': f'Converting to dict - title: {title}, slides: {slide_count}'})}\\n\\n\"\n                            \n                            # Use proper directory and naming\n                            from pathlib import Path\n                            presentations_dir = Path(\"data/presentations\")\n                            presentations_dir.mkdir(parents=True, exist_ok=True)\n                            \n                            # Use storage ID if available, otherwise timestamp\n                            if storage_presentation_id:\n                                output_filename = f\"{storage_presentation_id}.pptx\"\n                            else:\n                                output_filename = f\"test_stream_{int(time.time())}.pptx\"\n                            output_path = presentations_dir / output_filename\n                            \n                            yield f\"data: {json.dumps({'type': 'render_info', 'message': f'Calling PPTX renderer for {output_path}...'})}\\n\\n\"\n                            \n                            # Enhanced error handling for PPTX rendering\n                            try:\n                                result = renderer.render(presentation_dict, str(output_path))\n                                \n                                if result.get('success'):\n                                    import os\n                                    file_size = os.path.getsize(output_path) if os.path.exists(output_path) else 0\n                                    yield f\"data: {json.dumps({'type': 'render_success', 'message': f'PPTX created: {output_path} ({file_size} bytes)', 'file': str(output_path)})}\\n\\n\"\n                                    \n                                    # Store the filename for download URL \n                                    pptx_filename = output_filename\n                                else:\n                                    error_msg = result.get('error', 'Unknown error')\n                                    yield f\"data: {json.dumps({'type': 'render_error', 'message': f'PPTX render failed: {error_msg}', 'debug_result': result})}\\n\\n\"\n                                    logger.error(f\"PPTX render failed in streaming: {error_msg}, full result: {result}\")\n                                    \n                            except Exception as render_exception:\n                                error_msg = f\"PPTX renderer exception: {str(render_exception)}\"\n                                yield f\"data: {json.dumps({'type': 'render_error', 'message': error_msg})}\\n\\n\"\n                                logger.error(f\"PPTX renderer exception in streaming: {render_exception}\", exc_info=True)\n                                \n                        elif request.format.lower() == 'google_slides':\n                            yield f\"data: {json.dumps({'type': 'render_info', 'message': 'Google Slides selected - would create online presentation'})}\\n\\n\"\n                            yield f\"data: {json.dumps({'type': 'render_info', 'message': 'Note: Google Slides requires OAuth authentication in production'})}\\n\\n\"\n                            \n                            # Show what the URL would look like\n                            mock_id = f\"mock_presentation_{int(time.time())}\"\n                            mock_url = f\"https://docs.google.com/presentation/d/{mock_id}/edit\"\n                            yield f\"data: {json.dumps({'type': 'render_success', 'message': f'Would create Google Slides at: {mock_url}', 'url': '{mock_url}'})}\\n\\n\"\n                            \n                    except Exception as render_error:\n                        error_str = str(render_error)\n                        yield f\"data: {json.dumps({'type': 'render_error', 'message': f'Rendering failed: {error_str}'})}\\n\\n\"\n                    \n                else:\n                    yield f\"data: {json.dumps({'type': 'error', 'message': 'Could not parse JSON response'})}\\n\\n\"\n                    \n            except Exception as e:\n                error_msg = str(e)\n                yield f\"data: {json.dumps({'type': 'error', 'message': f'Error processing response: {error_msg}'})}\\n\\n\"\n                \n        except Exception as e:\n            error_msg = str(e)\n            yield f\"data: {json.dumps({'type': 'error', 'message': f'Analysis failed: {error_msg}'})}\\n\\n\"\n        \n        # Send completion event\n        yield f\"data: {json.dumps({'type': 'complete'})}\\n\\n\"\n    \n    return StreamingResponse(\n        generate_sse(),\n        media_type=\"text/event-stream\",\n        headers={\n            \"Cache-Control\": \"no-cache\",\n            \"Connection\": \"keep-alive\",\n            \"Access-Control-Allow-Origin\": \"*\",\n            \"Access-Control-Allow-Headers\": \"*\",\n        }\n    )\n\n"
          },
          {
            "file_name": "paste-4.txt",
            "file_size": 9441,
            "file_type": "txt",
            "extracted_content": "# api/makeslides/api/middleware/rate_limiting_middleware.py\n\"\"\"\nRate limiting middleware to prevent 429 errors and improve API stability.\n\"\"\"\n\nimport time\nimport logging\nfrom typing import Dict, Optional, Tuple\nfrom collections import defaultdict, deque\nfrom datetime import datetime, timedelta\nfrom starlette.middleware.base import BaseHTTPMiddleware\nfrom starlette.requests import Request\nfrom starlette.responses import Response, JSONResponse\nfrom fastapi import status\n\nlogger = logging.getLogger(__name__)\n\n\nclass RateLimiter:\n    \"\"\"Token bucket rate limiter implementation\"\"\"\n    \n    def __init__(self, rate: int = 10, per: int = 60):\n        \"\"\"\n        Initialize rate limiter.\n        \n        Args:\n            rate: Number of requests allowed\n            per: Time period in seconds\n        \"\"\"\n        self.rate = rate\n        self.per = per\n        self.allowance = defaultdict(lambda: float(rate))\n        self.last_check = defaultdict(float)\n    \n    def is_allowed(self, key: str) -> Tuple[bool, Optional[int]]:\n        \"\"\"\n        Check if request is allowed.\n        \n        Returns:\n            Tuple of (is_allowed, retry_after_seconds)\n        \"\"\"\n        current = time.time()\n        time_passed = current - self.last_check[key]\n        self.last_check[key] = current\n        \n        # Add tokens based on time passed\n        self.allowance[key] += time_passed * (self.rate / self.per)\n        \n        # Cap at maximum rate\n        if self.allowance[key] > self.rate:\n            self.allowance[key] = float(self.rate)\n        \n        # Check if request is allowed\n        if self.allowance[key] < 1.0:\n            # Calculate retry after\n            retry_after = int((1.0 - self.allowance[key]) * (self.per / self.rate))\n            return False, retry_after\n        \n        # Consume one token\n        self.allowance[key] -= 1.0\n        return True, None\n\n\nclass SlidingWindowRateLimiter:\n    \"\"\"Sliding window rate limiter for more accurate rate limiting\"\"\"\n    \n    def __init__(self, rate: int = 60, window: int = 60):\n        \"\"\"\n        Initialize sliding window rate limiter.\n        \n        Args:\n            rate: Number of requests allowed\n            window: Window size in seconds\n        \"\"\"\n        self.rate = rate\n        self.window = window\n        self.requests = defaultdict(deque)\n    \n    def is_allowed(self, key: str) -> Tuple[bool, Optional[int]]:\n        \"\"\"Check if request is allowed\"\"\"\n        now = time.time()\n        \n        # Remove old requests outside the window\n        while self.requests[key] and self.requests[key][0] < now - self.window:\n            self.requests[key].popleft()\n        \n        # Check if under rate limit\n        if len(self.requests[key]) < self.rate:\n            self.requests[key].append(now)\n            return True, None\n        \n        # Calculate retry after\n        oldest_request = self.requests[key][0]\n        retry_after = int(oldest_request + self.window - now) + 1\n        return False, retry_after\n\n\nclass RateLimitMiddleware(BaseHTTPMiddleware):\n    \"\"\"Rate limiting middleware with multiple strategies\"\"\"\n    \n    def __init__(\n        self,\n        app,\n        default_rate: int = 120,  # Increased from 60 to 120\n        default_window: int = 60,\n        burst_rate: int = 20,\n        burst_window: int = 1,\n        auth_multiplier: float = 2.0,\n        path_limits: Optional[Dict[str, Tuple[int, int]]] = None\n    ):\n        \"\"\"\n        Initialize rate limit middleware.\n        \n        Args:\n            app: FastAPI application\n            default_rate: Default requests per window\n            default_window: Default window in seconds\n            burst_rate: Burst requests allowed\n            burst_window: Burst window in seconds\n            auth_multiplier: Multiplier for authenticated users\n            path_limits: Custom limits per path pattern\n        \"\"\"\n        super().__init__(app)\n        \n        # Default rate limiter\n        self.default_limiter = SlidingWindowRateLimiter(default_rate, default_window)\n        \n        # Burst rate limiter\n        self.burst_limiter = RateLimiter(burst_rate, burst_window)\n        \n        # Configuration\n        self.auth_multiplier = auth_multiplier\n        self.path_limits = path_limits or {\n            # More reasonable limits for expensive operations\n            \"/presentations/create-stream\": (30, 60),  # 30 per minute (was 5)\n            \"/presentations/*/regenerate\": (20, 60),   # 20 per minute (was 10)\n            \"/presentations/*/content\": (60, 60),      # 60 per minute (prevent flickering)\n        }\n        \n        # Cache for request deduplication\n        self.request_cache: Dict[str, Tuple[float, Response]] = {}\n        self.cache_ttl = 5.0  # 5 seconds cache\n    \n    def get_client_key(self, request: Request) -> str:\n        \"\"\"Get client identifier for rate limiting\"\"\"\n        # Try to get user ID from authorization\n        auth_header = request.headers.get(\"authorization\", \"\")\n        if auth_header.startswith(\"Bearer \"):\n            # Use a hash of the token for consistency\n            import hashlib\n            token_hash = hashlib.sha256(auth_header.encode()).hexdigest()[:16]\n            return f\"auth:{token_hash}\"\n        \n        # Fall back to IP address\n        forwarded_for = request.headers.get(\"x-forwarded-for\")\n        if forwarded_for:\n            client_ip = forwarded_for.split(\",\")[0].strip()\n        else:\n            client_ip = request.client.host if request.client else \"unknown\"\n        \n        return f\"ip:{client_ip}\"\n    \n    def get_cache_key(self, request: Request) -> str:\n        \"\"\"Get cache key for request deduplication\"\"\"\n        return f\"{request.method}:{request.url.path}:{self.get_client_key(request)}\"\n    \n    def match_path_pattern(self, path: str, pattern: str) -> bool:\n        \"\"\"Check if path matches pattern (supports * wildcard)\"\"\"\n        import re\n        pattern_regex = pattern.replace(\"*\", \"[^/]+\")\n        return bool(re.match(f\"^{pattern_regex}$\", path))\n    \n    def get_rate_limit_for_path(self, path: str) -> Tuple[int, int]:\n        \"\"\"Get rate limit for specific path\"\"\"\n        for pattern, (rate, window) in self.path_limits.items():\n            if self.match_path_pattern(path, pattern):\n                return rate, window\n        return self.default_limiter.rate, self.default_limiter.window\n    \n    async def dispatch(self, request: Request, call_next):\n        # Skip rate limiting for health checks and docs\n        if request.url.path in [\"/health\", \"/docs\", \"/openapi.json\", \"/redoc\"]:\n            return await call_next(request)\n        \n        client_key = self.get_client_key(request)\n        \n        # Apply burst limiting first\n        burst_allowed, burst_retry = self.burst_limiter.is_allowed(f\"burst:{client_key}\")\n        if not burst_allowed:\n            logger.warning(f\"Burst limit exceeded for {client_key} on {request.url.path}\")\n            return JSONResponse(\n                status_code=status.HTTP_429_TOO_MANY_REQUESTS,\n                content={\n                    \"error\": \"Too many requests in a short time\",\n                    \"retry_after\": burst_retry\n                },\n                headers={\n                    \"Retry-After\": str(burst_retry),\n                    \"X-RateLimit-Type\": \"burst\"\n                }\n            )\n        \n        # Get path-specific rate limit\n        rate, window = self.get_rate_limit_for_path(request.url.path)\n        \n        # Apply auth multiplier if authenticated\n        if client_key.startswith(\"auth:\"):\n            rate = int(rate * self.auth_multiplier)\n        \n        # Create path-specific limiter\n        path_limiter = SlidingWindowRateLimiter(rate, window)\n        path_limiter.requests = self.default_limiter.requests  # Share request history\n        \n        # Check rate limit\n        allowed, retry_after = path_limiter.is_allowed(client_key)\n        \n        if not allowed:\n            logger.warning(f\"Rate limit exceeded for {client_key} on {request.url.path}\")\n            return JSONResponse(\n                status_code=status.HTTP_429_TOO_MANY_REQUESTS,\n                content={\n                    \"error\": \"Rate limit exceeded\",\n                    \"retry_after\": retry_after,\n                    \"limit\": rate,\n                    \"window\": window\n                },\n                headers={\n                    \"Retry-After\": str(retry_after),\n                    \"X-RateLimit-Limit\": str(rate),\n                    \"X-RateLimit-Window\": str(window),\n                    \"X-RateLimit-Type\": \"sliding-window\"\n                }\n            )\n        \n        # Process request\n        response = await call_next(request)\n        \n        # Add rate limit headers\n        remaining = rate - len(path_limiter.requests[client_key])\n        response.headers[\"X-RateLimit-Limit\"] = str(rate)\n        response.headers[\"X-RateLimit-Remaining\"] = str(max(0, remaining))\n        response.headers[\"X-RateLimit-Window\"] = str(window)\n        \n        return response\n    \n    def _clean_cache(self):\n        \"\"\"Remove expired cache entries\"\"\"\n        now = time.time()\n        expired_keys = [\n            key for key, (timestamp, _) in self.request_cache.items()\n            if now - timestamp > self.cache_ttl\n        ]\n        for key in expired_keys:\n            del self.request_cache[key]\n\n\n# Backwards compatibility alias\nRateLimitingMiddleware = RateLimitMiddleware"
          },
          {
            "file_name": "paste-5.txt",
            "file_size": 12784,
            "file_type": "txt",
            "extracted_content": "# api/makeslides/infrastructure/external_services/llm_syntax_healer.py\n\"\"\"\nLLM-based syntax healing service for Mermaid diagrams and D3 charts.\nProvides intelligent error recovery with context-aware fixes.\n\"\"\"\n\nimport logging\nimport re\nfrom typing import Optional, Dict, Any, Tuple\nfrom dataclasses import dataclass\nimport anthropic\nimport json\n\n\n@dataclass\nclass SyntaxHealingResult:\n    \"\"\"Result of syntax healing attempt\"\"\"\n    success: bool\n    healed_code: Optional[str] = None\n    original_error: Optional[str] = None\n    healing_error: Optional[str] = None\n    attempts: int = 0\n    healing_strategy: Optional[str] = None\n\n\nclass LLMSyntaxHealer:\n    \"\"\"\n    LLM-powered syntax healing for diagram and chart code generation.\n    \n    Uses Claude to fix syntax errors with contextual examples and best practices.\n    \"\"\"\n    \n    def __init__(\n        self,\n        api_key: str,\n        model: str = \"claude-3-haiku-20240307\",  # Faster model for healing\n        max_healing_attempts: int = 2,\n        logger: Optional[logging.Logger] = None\n    ):\n        self.client = anthropic.Anthropic(api_key=api_key)\n        self.model = model\n        self.max_healing_attempts = max_healing_attempts\n        self.logger = logger or logging.getLogger(__name__)\n        \n        # Cache successful patterns for faster healing\n        self._healing_cache: Dict[str, str] = {}\n    \n    async def heal_mermaid_syntax(\n        self,\n        broken_code: str,\n        error_message: str,\n        content_description: str,\n        diagram_type: str = \"flowchart\"\n    ) -> SyntaxHealingResult:\n        \"\"\"\n        Heal broken Mermaid diagram syntax using LLM.\n        \n        Args:\n            broken_code: The Mermaid code that failed\n            error_message: Error message from Mermaid CLI\n            content_description: Natural language description of intended diagram\n            diagram_type: Type of diagram (flowchart, mindmap, etc.)\n            \n        Returns:\n            SyntaxHealingResult with healed code or failure details\n        \"\"\"\n        cache_key = f\"mermaid:{hash(broken_code + error_message)}\"\n        if cache_key in self._healing_cache:\n            self.logger.debug(\"Using cached Mermaid healing result\")\n            return SyntaxHealingResult(\n                success=True,\n                healed_code=self._healing_cache[cache_key],\n                healing_strategy=\"cache\"\n            )\n        \n        for attempt in range(1, self.max_healing_attempts + 1):\n            try:\n                self.logger.info(f\"Healing Mermaid syntax attempt {attempt}/{self.max_healing_attempts}\")\n                \n                prompt = self._build_mermaid_healing_prompt(\n                    broken_code, error_message, content_description, diagram_type\n                )\n                \n                response = self.client.messages.create(\n                    model=self.model,\n                    max_tokens=1000,\n                    temperature=0.1,  # Low temperature for consistent syntax\n                    messages=[{\"role\": \"user\", \"content\": prompt}]\n                )\n                \n                healed_code = self._extract_mermaid_code(response.content[0].text)\n                \n                if healed_code:\n                    # Cache successful healing\n                    self._healing_cache[cache_key] = healed_code\n                    \n                    return SyntaxHealingResult(\n                        success=True,\n                        healed_code=healed_code,\n                        original_error=error_message,\n                        attempts=attempt,\n                        healing_strategy=\"llm_healing\"\n                    )\n                \n            except Exception as e:\n                self.logger.warning(f\"Mermaid healing attempt {attempt} failed: {e}\")\n                if attempt == self.max_healing_attempts:\n                    return SyntaxHealingResult(\n                        success=False,\n                        original_error=error_message,\n                        healing_error=str(e),\n                        attempts=attempt\n                    )\n        \n        return SyntaxHealingResult(success=False, original_error=error_message, attempts=self.max_healing_attempts)\n    \n    async def generate_d3_chart_code(\n        self,\n        chart_description: str,\n        chart_type: str,\n        data: list,\n        chart_title: str = \"\",\n        width: int = 400,\n        height: int = 300\n    ) -> SyntaxHealingResult:\n        \"\"\"\n        Generate complete D3 chart code using LLM.\n        \n        Args:\n            chart_description: Natural language description\n            chart_type: pie_chart, bar_chart, line_chart, etc.\n            data: Chart data as list of dicts\n            chart_title: Optional chart title\n            width, height: Chart dimensions\n            \n        Returns:\n            SyntaxHealingResult with D3 code or failure details\n        \"\"\"\n        try:\n            self.logger.info(f\"Generating D3 {chart_type} code via LLM\")\n            \n            prompt = self._build_d3_generation_prompt(\n                chart_description, chart_type, data, chart_title, width, height\n            )\n            \n            response = self.client.messages.create(\n                model=self.model,\n                max_tokens=2000,\n                temperature=0.2,  # Low temperature for consistent D3 syntax\n                messages=[{\"role\": \"user\", \"content\": prompt}]\n            )\n            \n            d3_code = self._extract_d3_code(response.content[0].text)\n            \n            if d3_code:\n                return SyntaxHealingResult(\n                    success=True,\n                    healed_code=d3_code,\n                    attempts=1,\n                    healing_strategy=\"llm_generation\"\n                )\n            else:\n                return SyntaxHealingResult(\n                    success=False,\n                    healing_error=\"Failed to extract valid D3 code from LLM response\",\n                    attempts=1\n                )\n                \n        except Exception as e:\n            self.logger.error(f\"D3 code generation failed: {e}\")\n            return SyntaxHealingResult(\n                success=False,\n                healing_error=str(e),\n                attempts=1\n            )\n    \n    def _build_mermaid_healing_prompt(\n        self,\n        broken_code: str,\n        error_message: str,\n        content_description: str,\n        diagram_type: str\n    ) -> str:\n        \"\"\"Build a healing prompt for Mermaid syntax errors\"\"\"\n        \n        mermaid_examples = {\n            \"flowchart\": \"\"\"\nflowchart TD\n    A[Start] --> B{Decision}\n    B -->|Yes| C[Process]\n    B -->|No| D[Alternative]\n    C --> E[End]\n    D --> E\n\"\"\",\n            \"mindmap\": \"\"\"\nmindmap\n  root((Mind Map))\n    Topic1\n      Subtopic A\n      Subtopic B\n        Detail 1\n        Detail 2\n    Topic2\n      Subtopic C\n      Subtopic D\n\"\"\",\n            \"graph\": \"\"\"\ngraph TD\n    A[Node A] --> B[Node B]\n    A --> C[Node C]\n    B --> D[Node D]\n    C --> D\n\"\"\"\n        }\n        \n        example = mermaid_examples.get(diagram_type, mermaid_examples[\"flowchart\"])\n        \n        return f\"\"\"You are a Mermaid diagram syntax expert. I have broken Mermaid code that needs to be fixed.\n\n**Content Description:** {content_description}\n**Diagram Type:** {diagram_type}\n**Error Message:** {error_message}\n\n**Broken Code:**\n```mermaid\n{broken_code}\n```\n\n**Valid {diagram_type.title()} Example:**\n```mermaid\n{example.strip()}\n```\n\n**Common Mermaid Syntax Rules:**\n1. Node IDs must be alphanumeric (no spaces, special chars except underscores)\n2. Labels can be in brackets [Label] or quotes \"Label\"\n3. Arrows use --> for flowcharts, no spaces around operators\n4. No trailing commas or semicolons\n5. Consistent indentation (2 spaces recommended)\n6. No duplicate node IDs\n\nPlease fix the broken Mermaid code to be syntactically valid while preserving the intended meaning. Return ONLY the corrected Mermaid code wrapped in ```mermaid``` tags.\n\nFixed code:\"\"\"\n    \n    def _build_d3_generation_prompt(\n        self,\n        chart_description: str,\n        chart_type: str,\n        data: list,\n        chart_title: str,\n        width: int,\n        height: int\n    ) -> str:\n        \"\"\"Build a prompt for generating D3 chart code\"\"\"\n        \n        data_json = json.dumps(data, indent=2)\n        \n        d3_examples = {\n            \"pie_chart\": \"\"\"\n// D3 Pie Chart Example\nconst width = 400;\nconst height = 300;\nconst radius = Math.min(width, height) / 2;\n\nconst svg = d3.select(\"body\").append(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height);\n\nconst g = svg.append(\"g\")\n    .attr(\"transform\", `translate(${width/2},${height/2})`);\n\nconst color = d3.scaleOrdinal(d3.schemeCategory10);\n\nconst pie = d3.pie()\n    .value(d => d.value);\n\nconst arc = d3.arc()\n    .innerRadius(0)\n    .outerRadius(radius - 10);\n\nconst arcs = g.selectAll(\".arc\")\n    .data(pie(data))\n    .enter().append(\"g\")\n    .attr(\"class\", \"arc\");\n\narcs.append(\"path\")\n    .attr(\"d\", arc)\n    .attr(\"fill\", d => color(d.data.label));\n\narcs.append(\"text\")\n    .attr(\"transform\", d => `translate(${arc.centroid(d)})`)\n    .attr(\"dy\", \"0.35em\")\n    .style(\"text-anchor\", \"middle\")\n    .text(d => d.data.label);\n\"\"\",\n            \"bar_chart\": \"\"\"\n// D3 Bar Chart Example\nconst margin = {top: 20, right: 30, bottom: 40, left: 40};\nconst width = 400 - margin.left - margin.right;\nconst height = 300 - margin.top - margin.bottom;\n\nconst svg = d3.select(\"body\").append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom);\n\nconst g = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left},${margin.top})`);\n\nconst x = d3.scaleBand()\n    .rangeRound([0, width])\n    .padding(0.1)\n    .domain(data.map(d => d.label));\n\nconst y = d3.scaleLinear()\n    .rangeRound([height, 0])\n    .domain([0, d3.max(data, d => d.value)]);\n\ng.selectAll(\".bar\")\n    .data(data)\n    .enter().append(\"rect\")\n    .attr(\"class\", \"bar\")\n    .attr(\"x\", d => x(d.label))\n    .attr(\"y\", d => y(d.value))\n    .attr(\"width\", x.bandwidth())\n    .attr(\"height\", d => height - y(d.value))\n    .attr(\"fill\", \"steelblue\");\n\ng.append(\"g\")\n    .attr(\"transform\", `translate(0,${height})`)\n    .call(d3.axisBottom(x));\n\ng.append(\"g\")\n    .call(d3.axisLeft(y));\n\"\"\"\n        }\n        \n        example = d3_examples.get(chart_type, d3_examples[\"bar_chart\"])\n        \n        return f\"\"\"You are a D3.js expert. Generate complete, functional D3 code for a {chart_type}.\n\n**Chart Description:** {chart_description}\n**Chart Type:** {chart_type}\n**Chart Title:** {chart_title}\n**Dimensions:** {width}x{height}\n\n**Data:**\n```json\n{data_json}\n```\n\n**Example {chart_type.replace('_', ' ').title()}:**\n```javascript\n{example.strip()}\n```\n\n**Requirements:**\n1. Generate complete, executable D3.js code\n2. Use the provided data structure exactly\n3. Include proper scales, axes (if applicable), and labels\n4. Use modern D3 v7 syntax\n5. Include proper margins and responsive design\n6. Add a title if provided\n7. Use appropriate colors and styling\n8. Handle edge cases (empty data, etc.)\n\nGenerate the complete D3 code wrapped in ```javascript``` tags:\n\n```javascript\"\"\"\n    \n    def _extract_mermaid_code(self, llm_response: str) -> Optional[str]:\n        \"\"\"Extract Mermaid code from LLM response\"\"\"\n        # Look for code blocks with mermaid\n        mermaid_pattern = r'```mermaid\\s*\\n(.*?)\\n```'\n        match = re.search(mermaid_pattern, llm_response, re.DOTALL)\n        if match:\n            return match.group(1).strip()\n        \n        # Fallback: look for any code block\n        code_pattern = r'```\\s*\\n(.*?)\\n```'\n        match = re.search(code_pattern, llm_response, re.DOTALL)\n        if match:\n            code = match.group(1).strip()\n            # Basic validation: should contain flowchart, graph, or mindmap\n            if any(keyword in code.lower() for keyword in ['flowchart', 'graph', 'mindmap']):\n                return code\n        \n        return None\n    \n    def _extract_d3_code(self, llm_response: str) -> Optional[str]:\n        \"\"\"Extract D3 JavaScript code from LLM response\"\"\"\n        # Look for JavaScript code blocks\n        js_pattern = r'```javascript\\s*\\n(.*?)\\n```'\n        match = re.search(js_pattern, llm_response, re.DOTALL)\n        if match:\n            return match.group(1).strip()\n        \n        # Look for general code blocks\n        code_pattern = r'```\\s*\\n(.*?)\\n```'\n        match = re.search(code_pattern, llm_response, re.DOTALL)\n        if match:\n            code = match.group(1).strip()\n            # Basic validation: should contain d3\n            if 'd3.' in code.lower():\n                return code\n        \n        return None"
          },
          {
            "file_name": "paste-6.txt",
            "file_size": 26530,
            "file_type": "txt",
            "extracted_content": "# api/makeslides/infrastructure/external_services/claude_content_analyzer.py\n# makeslides/infrastructure/external_services/claude_content_analyzer.py\n# Infrastructure implementation of ClaudeContentAnalyzer using DDD patterns\n\nimport logging\nimport json\nimport re\nimport os\nimport time\nfrom datetime import datetime\nfrom typing import Dict, Any, Optional, List\nfrom colorama import init, Fore, Style\nimport anthropic\n# from anthropic.types import ContentBlockDeltaEvent  # Not needed for basic usage\n\nfrom ...domain.interfaces import ContentAnalyzerInterface\nfrom ...domain.entities.presentation import Presentation\nfrom ...domain.adapters.presentation_adapter import PresentationAdapter\n\ninit()\nlogger = logging.getLogger(__name__)\n\n\nclass ClaudeContentAnalyzer(ContentAnalyzerInterface):\n    \"\"\"Infrastructure implementation of content analysis using Claude\"\"\"\n    \n    def __init__(\n        self,\n        api_key: Optional[str] = None,\n        use_extended_thinking: bool = False,\n        debug: bool = False,\n    ):\n        self.api_key = api_key or os.environ.get(\"ANTHROPIC_API_KEY\")\n        if not self.api_key:\n            raise ValueError(\n                \"Anthropic API key not provided and ANTHROPIC_API_KEY environment variable not set\"\n            )\n        self.client = anthropic.Anthropic(api_key=self.api_key)\n        self.use_extended_thinking = use_extended_thinking\n        self.debug = debug\n\n        # Create debug directory for saving initial responses (absolute path)\n        project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))\n        self.debug_dir = os.path.join(project_root, \"data\", \"debug\", \"claude_responses\")\n        os.makedirs(self.debug_dir, exist_ok=True)\n        logger.info(f\"Claude debug directory created at: {self.debug_dir}\")\n\n        if self.debug:\n            logger.setLevel(logging.DEBUG)\n            logger.debug(\"Debug mode enabled for content analyzer\")\n\n    async def health_check(self) -> bool:\n        \"\"\"Check if Claude API is accessible and working.\"\"\"\n        try:\n            # Simple test with minimal content to verify API connectivity\n            response = self.client.messages.create(\n                model=\"claude-3-haiku-20240307\",  # Use fastest model for health check\n                max_tokens=10,\n                messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n            )\n            return bool(response and response.content)\n        except Exception as e:\n            logger.warning(f\"Claude API health check failed: {e}\")\n            return False\n\n    def _save_initial_claude_response(self, response_data: Dict[str, Any], content_preview: str) -> str:\n        \"\"\"Save initial Claude JSON response for debugging and recreation purposes\"\"\"\n        logger.info(\"Starting to save Claude response debug info\")\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"claude_response_{timestamp}.json\"\n        filepath = os.path.join(self.debug_dir, filename)\n        \n        debug_data = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"content_preview\": content_preview[:500] + \"...\" if len(content_preview) > 500 else content_preview,\n            \"claude_response\": response_data,\n            \"has_assets\": self._analyze_assets_in_response(response_data),\n            \"asset_summary\": self._summarize_assets(response_data)\n        }\n        \n        try:\n            with open(filepath, 'w', encoding='utf-8') as f:\n                json.dump(debug_data, f, indent=2, ensure_ascii=False)\n            \n            logger.info(f\"Saved initial Claude response to: {filepath}\")\n            return filepath\n        except Exception as e:\n            logger.error(f\"Failed to save Claude response debug file: {e}\")\n            return \"\"\n\n    def _analyze_assets_in_response(self, response_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Analyze what assets were detected in the Claude response\"\"\"\n        asset_analysis = {\n            \"total_slides\": 0,\n            \"slides_with_assets\": 0,\n            \"asset_types\": {\"diagram\": 0, \"image\": 0, \"chart\": 0},\n            \"slides_with_assets_details\": []\n        }\n        \n        if \"slides\" in response_data:\n            asset_analysis[\"total_slides\"] = len(response_data[\"slides\"])\n            \n            for i, slide in enumerate(response_data[\"slides\"]):\n                if \"assets\" in slide and slide[\"assets\"]:\n                    asset_analysis[\"slides_with_assets\"] += 1\n                    slide_assets = []\n                    \n                    for asset in slide[\"assets\"]:\n                        asset_type = asset.get(\"type\", \"unknown\")\n                        if asset_type in asset_analysis[\"asset_types\"]:\n                            asset_analysis[\"asset_types\"][asset_type] += 1\n                        slide_assets.append({\n                            \"type\": asset_type,\n                            \"description\": asset.get(\"description\", \"\"),\n                            \"has_diagram_content\": \"content_description\" in asset,\n                            \"has_search_terms\": \"search_terms\" in asset,\n                            \"has_chart_data\": \"data\" in asset\n                        })\n                    \n                    asset_analysis[\"slides_with_assets_details\"].append({\n                        \"slide_number\": i + 1,\n                        \"slide_title\": slide.get(\"title\", \"\"),\n                        \"assets\": slide_assets\n                    })\n        \n        return asset_analysis\n\n    def _summarize_assets(self, response_data: Dict[str, Any]) -> List[str]:\n        \"\"\"Create a human-readable summary of assets found\"\"\"\n        summary = []\n        asset_analysis = self._analyze_assets_in_response(response_data)\n        \n        total_assets = sum(asset_analysis[\"asset_types\"].values())\n        if total_assets > 0:\n            summary.append(f\"Found {total_assets} assets across {asset_analysis['slides_with_assets']} slides\")\n            for asset_type, count in asset_analysis[\"asset_types\"].items():\n                if count > 0:\n                    summary.append(f\"- {count} {asset_type}(s)\")\n        else:\n            summary.append(\"No assets detected in Claude response\")\n        \n        return summary\n\n    def analyze(self, content: str) -> Presentation:\n        print(f\"\\n{Fore.CYAN}üìä ANALYZING CONTENT FOR PRESENTATION{Style.RESET_ALL}\")\n        print(\n            f\"{Fore.YELLOW}Content length: {len(content)} characters{Style.RESET_ALL}\"\n        )\n\n        if self.debug:\n            logger.debug(f\"Input content preview: {content[:200]}...\")\n\n        start_time = time.time()\n        prompt = self._build_sophisticated_analysis_prompt(content)\n\n        if self.debug:\n            logger.debug(f\"Generated prompt length: {len(prompt)} characters\")\n            logger.debug(f\"Prompt preview: {prompt[:500]}...\")\n\n        try:\n            result = (\n                self._analyze_with_streaming_thinking(prompt)\n                if self.use_extended_thinking\n                else self._analyze_with_tools(prompt)\n            )\n            elapsed = time.time() - start_time\n            print(\n                f\"\\n{Fore.GREEN}‚úÖ Analysis completed in {elapsed:.2f} seconds{Style.RESET_ALL}\"\n            )\n            print(\n                f\"{Fore.CYAN}Generated {len(result.slides)} slides for '{result.title}'{Style.RESET_ALL}\"\n            )\n\n            if self.debug:\n                self._debug_presentation_structure(result)\n\n            return result\n        except Exception as e:\n            elapsed = time.time() - start_time\n            print(\n                f\"\\n{Fore.RED}‚ùå Analysis failed after {elapsed:.2f} seconds: {str(e)}{Style.RESET_ALL}\"\n            )\n            logger.error(f\"Error analyzing content: {e}\")\n            if self.debug:\n                logger.debug(\"Full error traceback:\", exc_info=True)\n            raise\n\n    def _debug_presentation_structure(self, presentation: Presentation):\n        \"\"\"Debug logging to show what was generated\"\"\"\n        logger.debug(\"=== PRESENTATION STRUCTURE DEBUG ===\")\n        logger.debug(f\"Title: {presentation.title}\")\n        logger.debug(f\"Total slides: {len(presentation.slides)}\")\n\n        diagram_count = 0\n        image_count = 0\n        layouts = {}\n\n        for i, slide in enumerate(presentation.slides):\n            layout = slide.layout\n            layout_name = layout.value if hasattr(layout, 'value') else str(layout)\n            layouts[layout_name] = layouts.get(layout_name, 0) + 1\n\n            # Check for diagrams\n            if slide.has_diagrams():\n                diagram_count += 1\n                logger.debug(\n                    f\"  Slide {i+1}: HAS DIAGRAM ({slide.diagram_type})\"\n                )\n\n            # Check for images\n            if slide.has_images():\n                image_count += 1\n                logger.debug(f\"  Slide {i+1}: HAS IMAGE ({slide.image_url})\")\n\n            logger.debug(f\"  Slide {i+1}: '{slide.title}' [{layout_name}]\")\n\n        logger.debug(f\"Layout distribution: {layouts}\")\n        logger.debug(f\"Slides with diagrams: {diagram_count}\")\n        logger.debug(f\"Slides with images: {image_count}\")\n        logger.debug(\"=== END STRUCTURE DEBUG ===\")\n\n    def _analyze_with_tools(self, prompt: str) -> Presentation:\n        \"\"\"Analyze using tools API for better JSON extraction\"\"\"\n        print(\n            f\"{Fore.YELLOW}Sending request to Claude with tools API...{Style.RESET_ALL}\"\n        )\n\n        tools = [\n            {\n                \"name\": \"generate_presentation\",\n                \"description\": \"Generate a structured presentation with slides that may include visual assets (diagrams, images, charts)\",\n                \"input_schema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"title\": {\"type\": \"string\"},\n                        \"author\": {\"type\": [\"string\", \"null\"]},\n                        \"slides\": {\n                            \"type\": \"array\",\n                            \"items\": {\n                                \"type\": \"object\",\n                                \"properties\": {\n                                    \"title\": {\"type\": \"string\"},\n                                    \"content\": {\"type\": \"string\"},\n                                    \"layout\": {\"type\": \"string\"},\n                                    \"diagram_type\": {\"type\": [\"string\", \"null\"]},\n                                    \"diagram_content\": {\"type\": [\"string\", \"null\"]},\n                                    \"image_url\": {\"type\": [\"string\", \"null\"]},\n                                    \"image_description\": {\"type\": [\"string\", \"null\"]},\n                                    \"notes\": {\"type\": [\"string\", \"null\"]},\n                                    \"facilitator_notes\": {\"type\": [\"string\", \"null\"]},\n                                    \"assets\": {\n                                        \"type\": \"array\",\n                                        \"items\": {\n                                            \"type\": \"object\",\n                                            \"properties\": {\n                                                \"type\": {\"type\": \"string\"},\n                                                \"description\": {\"type\": \"string\"},\n                                                \"diagram_type\": {\"type\": [\"string\", \"null\"]},\n                                                \"content_description\": {\"type\": [\"string\", \"null\"]},\n                                                \"search_terms\": {\n                                                    \"type\": \"array\",\n                                                    \"items\": {\"type\": \"string\"}\n                                                },\n                                                \"style_preference\": {\"type\": [\"string\", \"null\"]},\n                                                \"chart_type\": {\"type\": [\"string\", \"null\"]},\n                                                \"data\": {\n                                                    \"type\": \"array\",\n                                                    \"items\": {\n                                                        \"type\": \"object\",\n                                                        \"properties\": {\n                                                            \"label\": {\"type\": \"string\"},\n                                                            \"value\": {\"type\": \"number\"}\n                                                        }\n                                                    }\n                                                }\n                                            },\n                                            \"required\": [\"type\", \"description\"]\n                                        }\n                                    },\n                                },\n                                \"required\": [\"title\", \"content\", \"layout\"],\n                            },\n                        },\n                    },\n                    \"required\": [\"title\", \"slides\"],\n                },\n            }\n        ]\n\n        try:\n            response = self.client.messages.create(\n                model=\"claude-3-7-sonnet-20250219\",\n                max_tokens=8192,\n                system=\"You are an expert presentation designer who creates structured presentations with diagrams. Use the generate_presentation tool to return your response.\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                tools=tools,\n            )\n\n            # Extract from tool use\n            for content in response.content:\n                if (\n                    hasattr(content, \"type\")\n                    and content.type == \"tool_use\"\n                    and content.name == \"generate_presentation\"\n                ):\n                    data = content.input\n                    \n                    # Save initial Claude response for debugging\n                    logger.info(\"ASSET DEBUG: About to save Claude response\")\n                    debug_filepath = self._save_initial_claude_response(data, prompt[:500])\n                    if debug_filepath:\n                        logger.info(f\"ASSET DEBUG: Initial Claude response saved to: {debug_filepath}\")\n                    else:\n                        logger.error(\"ASSET DEBUG: Failed to save Claude response\")\n                    \n                    # Always log asset summary regardless of debug mode\n                    asset_summary = self._summarize_assets(data)\n                    logger.info(f\"ASSET DEBUG: Claude generated assets summary: {asset_summary}\")\n                    \n                    if self.debug:\n                        logger.debug(f\"Tool response received: {json.dumps(data, indent=2)}\")\n                        for summary_line in asset_summary:\n                            logger.debug(f\"Asset Summary: {summary_line}\")\n                    \n                    return PresentationAdapter.from_dict(data)\n\n            # Fallback if no tool use found\n            raise ValueError(\"No tool use response found in Claude response\")\n\n        except Exception as e:\n            logger.warning(f\"Tools API failed: {e}, falling back to standard approach\")\n            if self.debug:\n                logger.debug(\"Tools API error details:\", exc_info=True)\n            return self._analyze_standard(prompt)\n\n    def _analyze_standard(self, prompt: str) -> Presentation:\n        \"\"\"Standard analysis without tools\"\"\"\n        print(f\"{Fore.YELLOW}Sending request to Claude...{Style.RESET_ALL}\")\n        response = self.client.messages.create(\n            model=\"claude-3-7-sonnet-20250219\",\n            max_tokens=8192,\n            system=\"You are an expert presentation designer. Return only valid JSON that matches the expected presentation structure.\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n        )\n        response_text = self._extract_text(response.content)\n\n        if self.debug:\n            logger.debug(f\"Raw response length: {len(response_text)}\")\n            logger.debug(f\"Raw response preview: {response_text[:500]}...\")\n\n        print(f\"{Fore.YELLOW}Parsing presentation data...{Style.RESET_ALL}\")\n        return self._parse_presentation(response_text, prompt[:500])\n\n    def _analyze_with_streaming_thinking(self, prompt: str) -> Presentation:\n        \"\"\"Analysis with streaming thinking enabled\"\"\"\n        thinking_log_path = \"thinking.log\"\n        print(\n            f\"{Fore.YELLOW}Starting streaming session with Claude...{Style.RESET_ALL}\"\n        )\n        print(\n            f\"{Fore.BLUE}Thinking logs will be saved to: {thinking_log_path}{Style.RESET_ALL}\"\n        )\n        response_text = \"\"\n        thinking_chars = 0\n        response_chars = 0\n\n        with open(thinking_log_path, \"w\") as log_file:\n            with self.client.messages.stream(\n                model=\"claude-3-7-sonnet-20250219\",\n                max_tokens=20000,\n                thinking={\"type\": \"enabled\", \"budget_tokens\": 2048},\n                system=\"You are an expert presentation designer who creates engaging presentations with diagrams. Think carefully about the content structure and visual elements before generating your JSON response.\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            ) as stream:\n                print(f\"\\n{Fore.CYAN}üîÑ Claude is thinking...{Style.RESET_ALL}\\n\")\n                for event in stream:\n                    if event.type == \"content_block_delta\" and isinstance(\n                        event, ContentBlockDeltaEvent\n                    ):\n                        if getattr(event.delta, \"type\", \"\") == \"thinking_delta\":\n                            thinking = getattr(event.delta, \"thinking\", \"\")\n                            thinking_chars += len(thinking)\n                            if self.debug:\n                                print(\n                                    f\"{Fore.YELLOW}üß† {thinking}{Style.RESET_ALL}\",\n                                    end=\"\",\n                                    flush=True,\n                                )\n                            log_file.write(thinking)\n                        elif getattr(event.delta, \"type\", \"\") == \"text_delta\":\n                            delta_text = event.delta.text\n                            response_chars += len(delta_text)\n                            print(\n                                f\"{Fore.GREEN}{delta_text}{Style.RESET_ALL}\",\n                                end=\"\",\n                                flush=True,\n                            )\n                            response_text += delta_text\n\n        print(\n            f\"\\n{Fore.YELLOW}Received {response_chars} chars of output and {thinking_chars} chars of thinking{Style.RESET_ALL}\"\n        )\n\n        if self.debug:\n            logger.debug(f\"Thinking file created: {thinking_log_path}\")\n            logger.debug(f\"Final response length: {len(response_text)}\")\n\n        print(f\"{Fore.YELLOW}Parsing presentation data...{Style.RESET_ALL}\")\n        return self._parse_presentation(response_text, prompt[:500])\n\n    def _parse_presentation(self, text: str, content_preview: str = \"\") -> Presentation:\n        \"\"\"Parse presentation from Claude's response\"\"\"\n        try:\n            data = self._extract_json(text)\n            \n            # Save initial Claude response for debugging\n            debug_filepath = self._save_initial_claude_response(data, content_preview)\n            if debug_filepath:\n                logger.info(f\"Initial Claude response saved to: {debug_filepath}\")\n            \n            if self.debug:\n                logger.debug(f\"Extracted JSON keys: {list(data.keys())}\")\n                if \"slides\" in data:\n                    logger.debug(f\"Number of slides in JSON: {len(data['slides'])}\")\n                \n                asset_summary = self._summarize_assets(data)\n                for summary_line in asset_summary:\n                    logger.debug(f\"Asset Summary: {summary_line}\")\n            \n            return PresentationAdapter.from_dict(data)\n        except Exception as e:\n            print(f\"{Fore.RED}‚ùå Error parsing presentation: {str(e)}{Style.RESET_ALL}\")\n            if self.debug:\n                logger.debug(f\"Failed to parse JSON from text: {text[:1000]}...\")\n                logger.debug(\"Parse error details:\", exc_info=True)\n            raise\n\n    def _extract_text(self, content: list) -> str:\n        \"\"\"Extract text from Claude response content\"\"\"\n        for block in content:\n            if hasattr(block, 'type') and block.type == \"text\":\n                return block.text\n        raise ValueError(\"No text block found in response.\")\n\n    def _extract_json(self, text: str) -> Dict[str, Any]:\n        \"\"\"Extract JSON from text with multiple fallback strategies\"\"\"\n        # Try multiple extraction methods\n        patterns = [\n            r\"```(?:json)?\\s*([\\s\\S]*?)\\s*```\",  # Code blocks\n            r\"\\{[\\s\\S]*\\}\",  # Any JSON object\n        ]\n\n        for pattern in patterns:\n            match = re.search(pattern, text, re.DOTALL)\n            if match:\n                try:\n                    json_str = match.group(1) if \"```\" in pattern else match.group(0)\n                    # Clean up common issues\n                    json_str = json_str.strip()\n                    data = json.loads(json_str)\n                    # Validate it has required structure\n                    if isinstance(data, dict) and (\"slides\" in data or \"title\" in data):\n                        return data\n                except json.JSONDecodeError:\n                    continue\n\n        # Last resort: try the entire text\n        try:\n            data = json.loads(text.strip())\n            if isinstance(data, dict):\n                return data\n        except json.JSONDecodeError:\n            pass\n\n        if self.debug:\n            logger.debug(f\"All JSON extraction methods failed for text: {text[:500]}...\")\n        \n        # Create minimal fallback presentation\n        return {\n            \"title\": \"Error Processing Content\",\n            \"author\": None,\n            \"slides\": [\n                {\n                    \"title\": \"Content Analysis Error\",\n                    \"content\": \"Failed to parse Claude's response into a valid presentation structure.\",\n                    \"layout\": \"TITLE_AND_CONTENT\",\n                    \"notes\": f\"Original response preview: {text[:200]}...\"\n                }\n            ]\n        }\n\n    def refine(self, presentation: Presentation) -> Presentation:\n        \"\"\"Refine an existing presentation (placeholder implementation)\"\"\"\n        return presentation\n\n    def _build_sophisticated_analysis_prompt(self, content: str) -> str:\n        \"\"\"Build a sophisticated prompt that explicitly requests diagrams\"\"\"\n        # Use string concatenation instead of f-string to avoid format specifier issues\n        prompt_template = \"\"\"You are an expert presentation designer creating engaging presentations with visual elements. Analyze the content and create a comprehensive presentation structure with diagrams where appropriate.\n\n## CRITICAL: Asset Detection System\nFor slides that would benefit from visual assets, include an \"assets\" array with semantic descriptions:\n\n### Diagram Assets\nFor processes, workflows, hierarchies, relationships:\n- \"type\": \"diagram\"\n- \"diagram_type\": \"flowchart\", \"mindmap\", \"timeline\", \"classDiagram\", etc.\n- \"description\": Clear description of what the diagram should show\n- \"content_description\": Detailed explanation for diagram generation\n\n### Image Assets  \nFor slides needing visual context or emotional connection:\n- \"type\": \"image\" \n- \"search_terms\": [\"keyword1\", \"keyword2\", \"keyword3\"] (3-5 relevant search terms)\n- \"description\": Why this image enhances the slide\n- \"style_preference\": \"professional\", \"modern\", \"warm\", \"technical\", etc.\n\n### Chart Assets\nFor numerical data that should be visualized:\n- \"type\": \"chart\"\n- \"chart_type\": \"pie\", \"bar\", \"line\", \"scatter\", etc.\n- \"data\": [{\"label\": \"Category\", \"value\": 42}, ...] (extract from content)\n- \"description\": What the chart represents\n\n## Asset Detection Guidelines:\n- Look for percentages, statistics, comparisons (‚Üí charts)\n- Look for processes, workflows, hierarchies (‚Üí diagrams) \n- Look for concepts needing visual context (‚Üí images)\n- Aim for 30-40% of slides having assets\n- Prioritize assets that enhance understanding, not decoration\n\n## Layout Variety\nUse varied layouts for visual interest:\n- TITLE_SLIDE: For opening slides\n- SECTION_HEADER: For section dividers  \n- TITLE_AND_CONTENT: For regular content\n- TWO_COLUMNS: For comparisons, lists >4 items\n- BIG_NUMBER: For statistics/metrics\n- QUOTE: For notable quotes\n- IMAGE_WITH_CAPTION: For visual-focused slides\n\n\nCONTENT TO ANALYZE:\n\"\"\" + content + \"\"\"\n\nReturn JSON in this exact format:\n{\n  \"title\": \"Presentation Title\",\n  \"author\": \"Author Name\", \n  \"slides\": [\n    {\n      \"title\": \"Slide Title\",\n      \"content\": \"Main content with bullet points\",\n      \"layout\": \"TITLE_AND_CONTENT\",\n      \"notes\": \"Speaker notes\",\n      \"facilitator_notes\": \"Additional facilitator guidance\",\n      \"assets\": [\n        {\n          \"type\": \"diagram\",\n          \"diagram_type\": \"flowchart\",\n          \"description\": \"Process flow showing the main workflow\",\n          \"content_description\": \"Start ‚Üí Planning ‚Üí Execution ‚Üí Review ‚Üí End\"\n        },\n        {\n          \"type\": \"image\", \n          \"search_terms\": [\"business\", \"teamwork\", \"collaboration\", \"office\"],\n          \"description\": \"Professional team collaborating on strategy\",\n          \"style_preference\": \"modern\"\n        },\n        {\n          \"type\": \"chart\",\n          \"chart_type\": \"pie\",\n          \"description\": \"Market share distribution\", \n          \"data\": [{\"label\": \"Company A\", \"value\": 45}, {\"label\": \"Company B\", \"value\": 30}, {\"label\": \"Others\", \"value\": 25}]\n        }\n      ]\n    }\n  ]\n}\n\nREQUIREMENTS:\n1. Each slide MUST have title, content, and layout\n2. Include \"assets\" array for slides that benefit from visual enhancement (30-40% of slides)\n3. For diagrams: provide clear \"content_description\" for generation\n4. For images: provide 3-5 relevant \"search_terms\" and \"style_preference\"\n5. For charts: extract numerical data from content into \"data\" array\n6. Use varied layouts - no more than 30% should be TITLE_AND_CONTENT\n7. Include facilitator_notes with presentation guidance\n8. Keep content concise but informative\"\"\"\n        \n        return prompt_template"
          }
        ],
        "files": [
          {
            "file_name": "paste.txt"
          },
          {
            "file_name": "paste-2.txt"
          },
          {
            "file_name": "paste-3.txt"
          },
          {
            "file_name": "DI_ISSUE_DIAGNOSIS.txt"
          },
          {
            "file_name": "DI_CONTAINER_ANALYSIS.txt"
          },
          {
            "file_name": "paste-4.txt"
          },
          {
            "file_name": "paste-5.txt"
          },
          {
            "file_name": "paste-6.txt"
          }
        ]
      }
    },
    {
      "id": "63dab450-10c3-425b-8cea-23622b23600b",
      "role": "assistant",
      "content": "The user is asking about issues with their MakeSlides presentation generation system. Looking at the code, I can see this is a comprehensive FastAPI application with Domain-Driven Design (DDD) architecture for generating presentations using Claude AI.\n\nFrom the code provided, I can see several components:\n\n1. **Presentation Controller** - The main API endpoints for creating, modifying, and managing presentations\n2. **DI Container Configuration** - Dependency injection setup with multiple services\n3. **Content Analysis Service** - Claude AI integration for analyzing content\n4. **Asset Processing Service** - Handling images, diagrams, and charts\n5. **Rate Limiting Middleware** - To prevent API throttling\n6. **Authentication System** - Supabase-based authentication\n\nLooking at the errors in the console output:\n- CORS policy error when trying to access `/presentations/google-permissions`\n- 500 Internal Server Error for the same endpoint\n- Network error: Failed to fetch\n\nAnd from the DI container diagnosis document, there's a specific issue:\n- `NameError: name 'AssetGenerationService' is not defined`\n- Location: `api/makeslides/infrastructure/di_container_supabase.py` line 252\n- Missing import statement for `AssetGenerationService`\n\nThe issue is that the `AssetGenerationService` is being used in the DI container but it's not imported. Looking at the imports in `di_container_supabase.py`, I can see it imports from domain services but not the specific asset generation service.\n\nLet me provide a solution to fix this issue and also address the CORS error.Looking at your code and the error messages, I can identify several issues:\n\n## 1. Missing Import in DI Container (Primary Issue)\n\nFrom your `DI_ISSUE_DIAGNOSIS.txt`, the main issue is that `AssetGenerationService` is not imported in `di_container_supabase.py`. \n\n**Fix**: Add this import at the top of `api/makeslides/infrastructure/di_container_supabase.py`:\n\n```python\n# Add this import with the other domain service imports\nfrom ..domain.services.asset_generation_service import AssetGenerationService\n```\n\n## 2. CORS Configuration Issue\n\nThe browser console shows CORS errors when trying to access `/presentations/google-permissions`. Your FastAPI app needs proper CORS configuration.\n\n**Fix**: In your `api/makeslides/api/main.py`, ensure CORS is configured correctly:\n\n```python\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:3000\", \"http://localhost:8000\"],  # Add your frontend URL\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n    expose_headers=[\"*\"]  # This allows custom headers in responses\n)\n```\n\n## 3. Missing Implementation File\n\nThe file `comprehensive_asset_generation_service.py` is not found:\n```\nFILE NOT FOUND: /Users/bilalghalib/Projects/Github/banter_modular/api/makeslides/infrastructure/external_services/comprehensive_asset_generation_service.py\n```\n\nBut it's imported in `di_container_supabase.py`:\n```python\nfrom .services.comprehensive_asset_generation_service import ComprehensiveAssetGenerationService\n```\n\nThis suggests the file is in a different location. It should be at:\n`api/makeslides/infrastructure/services/comprehensive_asset_generation_service.py`\n\n## 4. Complete Fix for DI Container\n\nHere's the corrected import section for `di_container_supabase.py`:\n\n```python\n# Domain services - Add the missing import\nfrom ..domain.services.content_analysis_service import ContentAnalysisService\nfrom ..domain.services.presentation_builder_service import PresentationBuilderService\nfrom ..domain.services.speech_to_text_service import SpeechToTextService\nfrom ..domain.services.slide_rendering_service import SlideRenderingService\nfrom ..domain.services.slide_rendering_service_impl import SlideRenderingServiceImpl\nfrom ..domain.services.asset_generation_service import AssetGenerationService  # ADD THIS\n\n# Asset generation implementation - Fix the path\nfrom .services.comprehensive_asset_generation_service import ComprehensiveAssetGenerationService  # Note: .services not .external_services\n```\n\n## 5. Quick Debugging Steps\n\n1. **Check if comprehensive_asset_generation_service.py exists**:\n   ```bash\n   find . -name \"comprehensive_asset_generation_service.py\"\n   ```\n\n2. **Verify all imports**:\n   ```python\n   # Add this temporary debug code in your main.py after container setup\n   try:\n       asset_gen = DIContainerManager.get_service(AssetGenerationService)\n       logger.info(f\"AssetGenerationService resolved: {type(asset_gen)}\")\n   except Exception as e:\n       logger.error(f\"Failed to resolve AssetGenerationService: {e}\")\n   ```\n\n3. **Test the specific endpoint**:\n   ```bash\n   curl -X GET http://localhost:8000/presentations/google-permissions \\\n        -H \"Authorization: Bearer YOUR_TOKEN\" \\\n        -H \"Content-Type: application/json\"\n   ```\n\n## Summary\n\nThe main issues are:\n1. Missing import of `AssetGenerationService` in the DI container\n2. CORS configuration blocking frontend requests\n3. Incorrect file path for `ComprehensiveAssetGenerationService`\n\nAfter fixing these imports and ensuring the service implementation file exists in the correct location, your DI container should initialize properly and the API endpoints should work.",
      "created_at": "2025-05-26T16:42:37.797842Z",
      "sequence_order": 1,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-26T16:41:56.170111Z",
            "stop_timestamp": "2025-05-26T16:42:10.637983Z",
            "flags": null,
            "type": "thinking",
            "thinking": "The user is asking about issues with their MakeSlides presentation generation system. Looking at the code, I can see this is a comprehensive FastAPI application with Domain-Driven Design (DDD) architecture for generating presentations using Claude AI.\n\nFrom the code provided, I can see several components:\n\n1. **Presentation Controller** - The main API endpoints for creating, modifying, and managing presentations\n2. **DI Container Configuration** - Dependency injection setup with multiple services\n3. **Content Analysis Service** - Claude AI integration for analyzing content\n4. **Asset Processing Service** - Handling images, diagrams, and charts\n5. **Rate Limiting Middleware** - To prevent API throttling\n6. **Authentication System** - Supabase-based authentication\n\nLooking at the errors in the console output:\n- CORS policy error when trying to access `/presentations/google-permissions`\n- 500 Internal Server Error for the same endpoint\n- Network error: Failed to fetch\n\nAnd from the DI container diagnosis document, there's a specific issue:\n- `NameError: name 'AssetGenerationService' is not defined`\n- Location: `api/makeslides/infrastructure/di_container_supabase.py` line 252\n- Missing import statement for `AssetGenerationService`\n\nThe issue is that the `AssetGenerationService` is being used in the DI container but it's not imported. Looking at the imports in `di_container_supabase.py`, I can see it imports from domain services but not the specific asset generation service.\n\nLet me provide a solution to fix this issue and also address the CORS error.",
            "summaries": [
              {
                "summary": "Thinking about analyzing domain service interfaces for presentation generation"
              },
              {
                "summary": "Investigating MakeSlides presentation generation system architecture"
              },
              {
                "summary": "Diagnosed MakeSlides API issues and proposed targeted fixes."
              }
            ],
            "cut_off": false
          },
          {
            "start_timestamp": "2025-05-26T16:42:10.957239Z",
            "stop_timestamp": "2025-05-26T16:42:37.131401Z",
            "flags": null,
            "type": "text",
            "text": "Looking at your code and the error messages, I can identify several issues:\n\n## 1. Missing Import in DI Container (Primary Issue)\n\nFrom your `DI_ISSUE_DIAGNOSIS.txt`, the main issue is that `AssetGenerationService` is not imported in `di_container_supabase.py`. \n\n**Fix**: Add this import at the top of `api/makeslides/infrastructure/di_container_supabase.py`:\n\n```python\n# Add this import with the other domain service imports\nfrom ..domain.services.asset_generation_service import AssetGenerationService\n```\n\n## 2. CORS Configuration Issue\n\nThe browser console shows CORS errors when trying to access `/presentations/google-permissions`. Your FastAPI app needs proper CORS configuration.\n\n**Fix**: In your `api/makeslides/api/main.py`, ensure CORS is configured correctly:\n\n```python\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:3000\", \"http://localhost:8000\"],  # Add your frontend URL\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n    expose_headers=[\"*\"]  # This allows custom headers in responses\n)\n```\n\n## 3. Missing Implementation File\n\nThe file `comprehensive_asset_generation_service.py` is not found:\n```\nFILE NOT FOUND: /Users/bilalghalib/Projects/Github/banter_modular/api/makeslides/infrastructure/external_services/comprehensive_asset_generation_service.py\n```\n\nBut it's imported in `di_container_supabase.py`:\n```python\nfrom .services.comprehensive_asset_generation_service import ComprehensiveAssetGenerationService\n```\n\nThis suggests the file is in a different location. It should be at:\n`api/makeslides/infrastructure/services/comprehensive_asset_generation_service.py`\n\n## 4. Complete Fix for DI Container\n\nHere's the corrected import section for `di_container_supabase.py`:\n\n```python\n# Domain services - Add the missing import\nfrom ..domain.services.content_analysis_service import ContentAnalysisService\nfrom ..domain.services.presentation_builder_service import PresentationBuilderService\nfrom ..domain.services.speech_to_text_service import SpeechToTextService\nfrom ..domain.services.slide_rendering_service import SlideRenderingService\nfrom ..domain.services.slide_rendering_service_impl import SlideRenderingServiceImpl\nfrom ..domain.services.asset_generation_service import AssetGenerationService  # ADD THIS\n\n# Asset generation implementation - Fix the path\nfrom .services.comprehensive_asset_generation_service import ComprehensiveAssetGenerationService  # Note: .services not .external_services\n```\n\n## 5. Quick Debugging Steps\n\n1. **Check if comprehensive_asset_generation_service.py exists**:\n   ```bash\n   find . -name \"comprehensive_asset_generation_service.py\"\n   ```\n\n2. **Verify all imports**:\n   ```python\n   # Add this temporary debug code in your main.py after container setup\n   try:\n       asset_gen = DIContainerManager.get_service(AssetGenerationService)\n       logger.info(f\"AssetGenerationService resolved: {type(asset_gen)}\")\n   except Exception as e:\n       logger.error(f\"Failed to resolve AssetGenerationService: {e}\")\n   ```\n\n3. **Test the specific endpoint**:\n   ```bash\n   curl -X GET http://localhost:8000/presentations/google-permissions \\\n        -H \"Authorization: Bearer YOUR_TOKEN\" \\\n        -H \"Content-Type: application/json\"\n   ```\n\n## Summary\n\nThe main issues are:\n1. Missing import of `AssetGenerationService` in the DI container\n2. CORS configuration blocking frontend requests\n3. Incorrect file path for `ComprehensiveAssetGenerationService`\n\nAfter fixing these imports and ensuring the service implementation file exists in the correct location, your DI container should initialize properly and the API endpoints should work.",
            "citations": []
          }
        ],
        "updated_at": "2025-05-26T16:42:37.797842Z",
        "attachments": [],
        "files": []
      }
    }
  ]
}