{
  "id": "5fd7d95f-bd4e-4cf1-8af0-fca7a07774bd",
  "source": "claude",
  "title": "Improving Audio Chant Detector Pattern Matching",
  "created_at": "2025-03-17T16:40:33.414343Z",
  "updated_at": "2025-03-17T16:41:03.211387Z",
  "summary": "",
  "message_count": 2,
  "messages": [
    {
      "id": "8ab18563-4219-40ed-845c-2e4d4c3de90c",
      "role": "human",
      "content": "I need a streamlined, cleaned, easier way to have it work, it doesn't get to the last element of the sequence if i pick 3/4/5 or any of them, why not, how can we maybe add some padding so we can find it in the rolling window? not sure \nreview the code and determine the idea and continue code generation that stopped at this line: [[[// Label const label = document.createElement('div'); label.className = 'segment-label';]]] please you continue from there",
      "created_at": "2025-03-17T16:40:34.469977Z",
      "sequence_order": 0,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-03-14T20:11:20.180240Z",
            "stop_timestamp": "2025-03-14T20:11:20.180240Z",
            "flags": null,
            "type": "text",
            "text": "I need a streamlined, cleaned, easier way to have it work, it doesn't get to the last element of the sequence if i pick 3/4/5 or any of them, why not, how can we maybe add some padding so we can find it in the rolling window? not sure \nreview the code and determine the idea and continue code generation that stopped at this line: [[[// Label const label = document.createElement('div'); label.className = 'segment-label';]]] please you continue from there",
            "citations": []
          }
        ],
        "updated_at": "2025-03-17T16:40:34.469977Z",
        "attachments": [
          {
            "file_name": "paste.txt",
            "file_size": 79035,
            "file_type": "txt",
            "extracted_content": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>Improved Chant Detector</title>\n  <script src=\"https://unpkg.com/meyda@5.2.0/dist/web/meyda.min.js\"></script>\n  <style>\n    body {\n      font-family: monospace;\n      max-width: 900px;\n      margin: 0 auto;\n      padding: 10px;\n      line-height: 1.4;\n    }\n    section {\n      background: #f8f9fa;\n      padding: 10px;\n      margin-bottom: 10px;\n      border: 1px solid #ddd;\n    }\n    h1, h2 { margin-top: 0; }\n    button {\n      background: #4285f4;\n      color: white;\n      border: none;\n      padding: 8px 12px;\n      margin-right: 5px;\n      cursor: pointer;\n    }\n    button:disabled { background: #ccc; }\n    .counter {\n      font-size: 40px;\n      font-weight: bold;\n      text-align: center;\n      margin: 10px 0;\n    }\n    .row {\n      display: flex;\n      align-items: center;\n      margin: 5px 0;\n    }\n    label {\n      width: 180px;\n      margin-right: 10px;\n    }\n    .status {\n      background: #e9ecef;\n      padding: 8px;\n      margin: 5px 0;\n      font-family: monospace;\n    }\n    \n    /* Visualization Styles */\n    .spectrogram-container {\n      position: relative;\n      height: 150px;\n      margin: 5px 0;\n      border: 1px solid #ddd;\n      background-color: #000;\n    }\n    .spectrogram-canvas {\n      position: absolute;\n      top: 0;\n      left: 0;\n      width: 100%;\n      height: 100%;\n    }\n    .segment-markers {\n      position: absolute;\n      top: 0;\n      left: 0;\n      width: 100%;\n      height: 100%;\n      pointer-events: none;\n    }\n    .segment-marker {\n      position: absolute;\n      top: 0;\n      height: 100%;\n      width: 2px;\n      background-color: rgba(255, 255, 255, 0.5);\n    }\n    .segment-label {\n      position: absolute;\n      top: 5px;\n      background-color: rgba(0, 0, 0, 0.6);\n      color: white;\n      padding: 2px 5px;\n      border-radius: 3px;\n      font-size: 10px;\n    }\n    .time-cursor {\n      position: absolute;\n      top: 0;\n      height: 100%;\n      width: 2px;\n      background-color: rgb(255, 0, 0);\n    }\n    \n    .sequence-progress {\n      display: flex;\n      height: 30px;\n      background: #f0f0f0;\n      margin: 10px 0;\n      border-radius: 4px;\n      overflow: hidden;\n    }\n    .segment-box {\n      flex: 1;\n      height: 100%;\n      display: flex;\n      align-items: center;\n      justify-content: center;\n      color: white;\n      font-weight: bold;\n      transition: background-color 0.3s;\n      border-right: 1px solid rgba(255,255,255,0.3);\n    }\n    .segment-pending { background-color: #9e9e9e; }\n    .segment-active { background-color: #ff9800; }\n    .segment-complete { background-color: #4caf50; }\n    .segment-invalid { background-color: #f44336; }\n    \n    .detection-bar {\n      height: 20px;\n      position: relative;\n      margin: 5px 0;\n      background: #f0f0f0;\n      border-radius: 4px;\n      overflow: hidden;\n    }\n    .detection-progress {\n      position: absolute;\n      height: 100%;\n      width: 0%;\n      background: #4caf50;\n      transition: width 0.2s;\n    }\n    \n    .pattern-display {\n      width: 100%;\n      height: 100px;\n      position: relative;\n      background: #000;\n      margin-top: 10px;\n      display: flex;\n    }\n    .pattern-segment {\n      flex: 1;\n      height: 100%;\n      overflow: hidden;\n      position: relative;\n      border-right: 1px dashed rgba(255,255,255,0.3);\n    }\n    .pattern-segment-label {\n      position: absolute;\n      top: 5px;\n      left: 5px;\n      background-color: rgba(0,0,0,0.6);\n      color: white;\n      padding: 2px 5px;\n      font-size: 10px;\n      z-index: 10;\n    }\n    \n    .debug-panel {\n      display: grid;\n      grid-template-columns: repeat(3, 1fr);\n      grid-gap: 5px;\n      margin: 5px 0;\n    }\n    .debug-item {\n      background: #f0f0f0;\n      padding: 5px;\n      font-size: 12px;\n      border-radius: 3px;\n    }\n    .debug-item-title {\n      font-weight: bold;\n      margin-bottom: 3px;\n    }\n    \n    .log {\n      height: 100px;\n      overflow-y: auto;\n      background: #f8f9fa;\n      border: 1px solid #ddd;\n      padding: 8px;\n      font-family: monospace;\n      font-size: 12px;\n    }\n    .highlight { color: #f44336; font-weight: bold; }\n    .green { color: #4caf50; }\n    \n    .pattern-info {\n      display: flex;\n      flex-wrap: wrap;\n      margin: 5px 0;\n    }\n    .pattern-stat {\n      background: #e0e0e0;\n      padding: 2px 6px;\n      margin-right: 5px;\n      margin-bottom: 5px;\n      border-radius: 2px;\n      font-size: 12px;\n    }\n    \n    .pattern-tabs {\n      display: flex;\n      margin-bottom: 5px;\n    }\n    .pattern-tab {\n      padding: 5px 10px;\n      background: #e0e0e0;\n      margin-right: 5px;\n      cursor: pointer;\n      border-radius: 3px 3px 0 0;\n      font-size: 12px;\n    }\n    .pattern-tab.active {\n      background: #4285f4;\n      color: white;\n    }\n    \n    .slider-value {\n      display: inline-block;\n      min-width: 40px;\n      text-align: right;\n    }\n    \n    .panel-title {\n      display: flex;\n      justify-content: space-between;\n      align-items: center;\n      margin-bottom: 5px;\n    }\n    .panel-title h3 {\n      margin: 0;\n    }\n  </style>\n</head>\n<body>\n  <h1>Improved Chant Detector</h1>\n\n  <section>\n    <div class=\"panel-title\">\n      <h2>1. Record Your Chant Pattern</h2>\n      <div class=\"pattern-tabs\">\n        <div class=\"pattern-tab active\" data-pattern=\"1\">Pattern 1</div>\n        <div class=\"pattern-tab\" data-pattern=\"2\">Pattern 2</div>\n        <div class=\"pattern-tab\" data-pattern=\"3\">Pattern 3</div>\n      </div>\n    </div>\n    \n    <div class=\"spectrogram-container\">\n      <canvas id=\"recordSpectrogram\" class=\"spectrogram-canvas\"></canvas>\n      <div class=\"segment-markers\" id=\"recordSegmentMarkers\"></div>\n    </div>\n    \n    <div id=\"recordingStatus\" class=\"status\">Ready to record your chant pattern</div>\n    <div>\n      <button id=\"recordBtn\">Record (Hold)</button>\n      <button id=\"clearBtn\">Clear</button>\n      <button id=\"averageBtn\" disabled>Average Patterns</button>\n      <span id=\"patternInfo\"></span>\n    </div>\n    \n    <div class=\"pattern-display\" id=\"patternDisplay\"></div>\n    <div class=\"pattern-info\" id=\"patternStats\"></div>\n  </section>\n\n  <section>\n    <h2>2. Settings</h2>\n    <div class=\"row\">\n      <label for=\"detectionMode\">Detection Mode:</label>\n      <select id=\"detectionMode\">\n        <option value=\"sequential\" selected>Strict Sequential</option>\n        <option value=\"flexible\">Flexible Sequential</option>\n        <option value=\"adaptive\">Adaptive (Self-Adjusting)</option>\n      </select>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"minMatchSlider\">Segment Match Threshold:</label>\n      <input type=\"range\" id=\"minMatchSlider\" min=\"0.3\" max=\"0.9\" step=\"0.05\" value=\"0.6\">\n      <span id=\"minMatchValue\" class=\"slider-value\">0.6</span>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"advanceThresholdSlider\">Advance Threshold:</label>\n      <input type=\"range\" id=\"advanceThresholdSlider\" min=\"0.2\" max=\"0.8\" step=\"0.05\" value=\"0.5\">\n      <span id=\"advanceThresholdValue\" class=\"slider-value\">0.5</span>\n      <span>(Lower = easier progression)</span>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"timeoutSlider\">Segment Timeout (ms):</label>\n      <input type=\"range\" id=\"timeoutSlider\" min=\"500\" max=\"5000\" step=\"100\" value=\"2000\">\n      <span id=\"timeoutValue\" class=\"slider-value\">2000</span>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"cooldownSlider\">Cooldown Period (ms):</label>\n      <input type=\"range\" id=\"cooldownSlider\" min=\"500\" max=\"3000\" step=\"100\" value=\"1500\">\n      <span id=\"cooldownValue\" class=\"slider-value\">1500</span>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"segmentCountSelect\">Pattern Segments:</label>\n      <select id=\"segmentCountSelect\">\n        <option value=\"3\">3</option>\n        <option value=\"4\" selected>4</option>\n        <option value=\"5\">5</option>\n        <option value=\"6\">6</option>\n      </select>\n    </div>\n  </section>\n\n  <section>\n    <h2>3. Detection</h2>\n    <div class=\"counter\" id=\"counterValue\">0</div>\n    \n    <div class=\"spectrogram-container\">\n      <canvas id=\"liveSpectrogram\" class=\"spectrogram-canvas\"></canvas>\n      <div class=\"segment-markers\" id=\"liveSegmentMarkers\"></div>\n      <div class=\"time-cursor\" id=\"timeCursor\" style=\"left: 75%;\"></div>\n    </div>\n    \n    <div class=\"sequence-progress\" id=\"sequenceProgress\"></div>\n    <div class=\"detection-bar\">\n      <div id=\"detectionProgress\" class=\"detection-progress\"></div>\n    </div>\n    \n    <div id=\"detectionStatus\" class=\"status\">No pattern recorded yet</div>\n    <div>\n      <button id=\"startBtn\" disabled>Start Detection</button>\n      <button id=\"stopBtn\" disabled>Stop</button>\n      <button id=\"resetBtn\">Reset Counter</button>\n    </div>\n    \n    <h3>Debug Info</h3>\n    <div class=\"debug-panel\" id=\"debugPanel\"></div>\n    <div class=\"log\" id=\"detectionLog\"></div>\n  </section>\n\n<script>\n/**\n * Improved Chant Detector\n * \n * Key improvements:\n * 1. Visual alignment of spectrogram and segments\n * 2. Multiple pattern recording and averaging\n * 3. Flexible sequence progression with timeout\n * 4. Better visualization of pattern segments\n */\nclass ImprovedChantDetector {\n  constructor() {\n    // Audio system\n    this.audioContext = null;\n    this.analyzer = null;\n    this.mediaStream = null;\n    this.processor = null;\n    \n    // Configuration\n    this.config = {\n      bufferSize: 1024,\n      fftSize: 2048,\n      sampleRate: 44100,\n      minRecordDuration: 500,\n      detectionMode: 'sequential',\n      minMatchThreshold: 0.6,     // Minimum score to consider a match\n      advanceThreshold: 0.5,      // Threshold to advance to next segment\n      segmentTimeout: 2000,       // Time before resetting stuck segment (ms)\n      cooldownTime: 1500,         // Cooldown between detections (ms)\n      segmentCount: 4,            // Number of segments in pattern\n      maxPatterns: 3,             // Maximum number of patterns to store\n      spectrogramHistory: 150,    // Number of columns in spectrogram\n      lookAheadFrames: 10,        // Frames to look ahead for flexible mode\n      \n      // Feature weights\n      featureWeights: {\n        spectrogram: 0.6,  // Weight for spectrogram match\n        mfcc: 0.3,         // Weight for MFCC match\n        energy: 0.1        // Weight for energy profile match\n      }\n    };\n    \n    // State\n    this.state = {\n      isRecording: false,\n      isDetecting: false,\n      inCooldown: false,\n      \n      // Active pattern\n      activePatternIndex: 0,\n      \n      // Recording state\n      recordStartTime: 0,\n      recordingData: {\n        audio: [],\n        spectrogram: [],\n        mfcc: [],\n        energy: [],\n        duration: 0\n      },\n      \n      // Patterns (multiple can be stored)\n      patterns: [],\n      \n      // Detection state\n      detectionBuffer: {\n        audio: [],\n        spectrogram: [],\n        mfcc: [],\n        energy: [],\n        timeWindow: []  // Time values for visualization\n      },\n      \n      // Sequence tracking\n      sequenceState: {\n        segments: [],          // State of each segment (pending, active, complete, invalid)\n        currentIndex: 0,       // Current segment being matched\n        progress: 0,           // Overall progress (0-1)\n        matchScores: [],       // Match scores for each segment\n        segmentStartTimes: [], // When each segment started matching\n        stuckTime: 0,          // How long we've been stuck on a segment\n        lastAdvanceTime: 0     // When we last advanced segments\n      },\n      \n      // Results\n      counter: 0,\n      lastDetectionTime: 0,\n      \n      // Visualization\n      spectrogramData: {\n        recording: [],\n        pattern: [],\n        live: []\n      },\n      \n      // Timing markers for visualization\n      timeMarkers: {\n        pattern: [],\n        live: []\n      }\n    };\n    \n    // Callbacks\n    this.callbacks = {\n      onStatusUpdate: null,\n      onVisualizationUpdate: null,\n      onDetection: null,\n      onProgressUpdate: null,\n      onError: null\n    };\n    \n    // Animation\n    this.animationFrame = null;\n  }\n  \n  /**\n   * Set up callbacks\n   */\n  setCallbacks(callbacks) {\n    Object.assign(this.callbacks, callbacks);\n  }\n  \n  /**\n   * Initialize audio system\n   */\n  async setupAudio() {\n    if (this.audioContext) return true;\n    \n    try {\n      this.audioContext = new (window.AudioContext || window.webkitAudioContext)();\n      this.config.sampleRate = this.audioContext.sampleRate;\n      \n      this.mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });\n      \n      this.analyzer = this.audioContext.createAnalyser();\n      this.analyzer.fftSize = this.config.fftSize;\n      \n      this.log('info', 'Audio system initialized');\n      return true;\n    } catch (error) {\n      this.handleError('Audio setup failed', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Start recording a pattern\n   */\n  async startRecording() {\n    if (this.state.isRecording) return false;\n    \n    // Setup audio\n    const success = await this.setupAudio();\n    if (!success) return false;\n    \n    // Initialize recording state\n    this.state.isRecording = true;\n    this.state.recordStartTime = Date.now();\n    this.state.recordingData = {\n      audio: [],\n      spectrogram: [],\n      mfcc: [],\n      energy: [],\n      duration: 0\n    };\n    \n    // Also initialize spectrogram data for visualization\n    this.state.spectrogramData.recording = [];\n    \n    // Create processor node\n    this.processor = this.audioContext.createScriptProcessor(\n      this.config.bufferSize, 1, 1\n    );\n    \n    // Process audio data\n    this.processor.onaudioprocess = (event) => {\n      if (!this.state.isRecording) return;\n      \n      try {\n        // Get audio data\n        const inputData = event.inputBuffer.getChannelData(0);\n        const audioData = new Float32Array(inputData.length);\n        audioData.set(inputData);\n        \n        // Extract features\n        const features = this.extractFeatures(audioData);\n        \n        // Store data\n        this.state.recordingData.audio.push(audioData);\n        this.state.recordingData.spectrogram.push(features.spectrogram);\n        this.state.recordingData.mfcc.push(features.mfcc);\n        this.state.recordingData.energy.push(features.energy);\n        \n        // Store spectrogram for visualization\n        this.state.spectrogramData.recording.push(features.spectrogram);\n        \n        // Update visualization\n        if (this.callbacks.onVisualizationUpdate) {\n          this.callbacks.onVisualizationUpdate('recording', audioData, features);\n        }\n      } catch (error) {\n        this.handleError('Error processing recording', error);\n      }\n    };\n    \n    // Connect audio nodes\n    const source = this.audioContext.createMediaStreamSource(this.mediaStream);\n    source.connect(this.analyzer);\n    source.connect(this.processor);\n    this.processor.connect(this.audioContext.destination);\n    \n    this.log('status', 'Recording chant pattern...');\n    return true;\n  }\n  \n  /**\n   * Stop recording and process the pattern\n   */\n  stopRecording() {\n    if (!this.state.isRecording) return false;\n    \n    // Update state\n    this.state.isRecording = false;\n    this.state.recordingData.duration = Date.now() - this.state.recordStartTime;\n    \n    // Clean up\n    if (this.processor) {\n      this.processor.disconnect();\n      this.processor = null;\n    }\n    \n    // Check recording duration\n    if (this.state.recordingData.duration < this.config.minRecordDuration) {\n      this.log('status', 'Recording too short, please try again');\n      return false;\n    }\n    \n    this.log('status', 'Processing pattern...');\n    \n    // Process the pattern\n    const success = this.processRecordingToPattern();\n    \n    if (success) {\n      this.log('status', `Pattern ${this.state.activePatternIndex + 1} recorded (${(this.state.recordingData.duration/1000).toFixed(1)}s)`);\n      return true;\n    } else {\n      this.log('status', 'Failed to process pattern');\n      return false;\n    }\n  }\n  \n  /**\n   * Process recording data into a pattern\n   */\n  processRecordingToPattern() {\n    try {\n      // Get current pattern index\n      const patternIndex = this.state.activePatternIndex;\n      \n      // Create a new pattern if it doesn't exist\n      if (!this.state.patterns[patternIndex]) {\n        this.state.patterns[patternIndex] = {\n          rawData: {\n            spectrogram: [],\n            mfcc: [],\n            energy: [],\n            duration: 0\n          },\n          segments: [],\n          sampleCount: 0\n        };\n      }\n      \n      // Store recording data\n      const pattern = this.state.patterns[patternIndex];\n      \n      // If this is the first recording for this pattern, just copy it\n      if (pattern.sampleCount === 0) {\n        pattern.rawData = {\n          spectrogram: [...this.state.recordingData.spectrogram],\n          mfcc: [...this.state.recordingData.mfcc],\n          energy: [...this.state.recordingData.energy],\n          duration: this.state.recordingData.duration\n        };\n      } else {\n        // Average with existing pattern data (simple arithmetic mean)\n        // First, we need to time-normalize the new recording\n        const normalizedRecording = this.normalizeRecordingLength(\n          this.state.recordingData, \n          pattern.rawData\n        );\n        \n        // Now average with existing pattern\n        this.averagePatternData(pattern, normalizedRecording);\n      }\n      \n      // Increment sample count\n      pattern.sampleCount++;\n      \n      // Segment the pattern\n      pattern.segments = this.segmentPattern(pattern.rawData);\n      \n      // Calculate segment boundaries for visualization\n      this.calculateSegmentBoundaries(pattern);\n      \n      // Store pattern visualization data\n      this.state.spectrogramData.pattern = [...pattern.rawData.spectrogram];\n      \n      // Clear recording data to save memory\n      this.state.recordingData = {\n        audio: [],\n        spectrogram: [],\n        mfcc: [],\n        energy: [],\n        duration: 0\n      };\n      \n      // Enable averaging if we have multiple patterns\n      if (this.checkMultiplePatternsExist()) {\n        // Check if averaging button should be enabled\n        if (this.callbacks.onStatusUpdate) {\n          this.callbacks.onStatusUpdate('control', 'enableAveraging', true);\n        }\n      }\n      \n      return true;\n    } catch (error) {\n      this.handleError('Error processing pattern', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Normalize recording length to match target pattern\n   */\n  normalizeRecordingLength(recording, targetPattern) {\n    // Create a normalized version of the recording\n    const normalized = {\n      spectrogram: [],\n      mfcc: [],\n      energy: [],\n      duration: targetPattern.duration\n    };\n    \n    const sourceLength = recording.energy.length;\n    const targetLength = targetPattern.energy.length;\n    \n    // Simple linear resampling\n    for (let i = 0; i < targetLength; i++) {\n      const sourceIdx = Math.floor(i * sourceLength / targetLength);\n      \n      normalized.spectrogram[i] = recording.spectrogram[sourceIdx];\n      normalized.mfcc[i] = recording.mfcc[sourceIdx];\n      normalized.energy[i] = recording.energy[sourceIdx];\n    }\n    \n    return normalized;\n  }\n  \n  /**\n   * Average new recording data with existing pattern\n   */\n  averagePatternData(pattern, newData) {\n    const sampleCount = pattern.sampleCount;\n    \n    // Weight for averaging: existing data gets more weight as sample count increases\n    const existingWeight = sampleCount / (sampleCount + 1);\n    const newWeight = 1 / (sampleCount + 1);\n    \n    // Average spectrograms\n    pattern.rawData.spectrogram = pattern.rawData.spectrogram.map((existingSpectrum, i) => {\n      const newSpectrum = newData.spectrogram[i] || [];\n      return this.weightedAverageArrays(existingSpectrum, newSpectrum, existingWeight, newWeight);\n    });\n    \n    // Average MFCCs\n    pattern.rawData.mfcc = pattern.rawData.mfcc.map((existingMfcc, i) => {\n      const newMfcc = newData.mfcc[i] || [];\n      return this.weightedAverageArrays(existingMfcc, newMfcc, existingWeight, newWeight);\n    });\n    \n    // Average energy\n    pattern.rawData.energy = pattern.rawData.energy.map((existing, i) => {\n      const newEnergy = newData.energy[i] || 0;\n      return existing * existingWeight + newEnergy * newWeight;\n    });\n    \n    // Keep original duration (we've already normalized the new recording)\n    pattern.rawData.duration = pattern.rawData.duration;\n  }\n  \n  /**\n   * Weighted average of two arrays\n   */\n  weightedAverageArrays(arrA, arrB, weightA, weightB) {\n    if (!arrA || !arrB) return arrA || arrB || [];\n    \n    const length = Math.min(arrA.length, arrB.length);\n    const result = new Array(length);\n    \n    for (let i = 0; i < length; i++) {\n      result[i] = (arrA[i] || 0) * weightA + (arrB[i] || 0) * weightB;\n    }\n    \n    return result;\n  }\n  \n  /**\n   * Check if multiple patterns exist\n   */\n  checkMultiplePatternsExist() {\n    let count = 0;\n    \n    for (const pattern of this.state.patterns) {\n      if (pattern && pattern.sampleCount > 0) {\n        count++;\n      }\n    }\n    \n    return count > 1;\n  }\n  \n  /**\n   * Average all recorded patterns into one\n   */\n  averageAllPatterns() {\n    try {\n      // Ensure we have at least 2 patterns\n      const validPatterns = this.state.patterns.filter(p => p && p.sampleCount > 0);\n      \n      if (validPatterns.length < 2) {\n        this.log('status', 'Need at least 2 patterns to average');\n        return false;\n      }\n      \n      // Use the first pattern as the base\n      const basePattern = validPatterns[0];\n      \n      // Create a new averaged pattern\n      const averagedPattern = {\n        rawData: {\n          spectrogram: [...basePattern.rawData.spectrogram],\n          mfcc: [...basePattern.rawData.mfcc],\n          energy: [...basePattern.rawData.energy],\n          duration: basePattern.rawData.duration\n        },\n        segments: [],\n        sampleCount: 0\n      };\n      \n      // Add all other patterns\n      for (let i = 1; i < validPatterns.length; i++) {\n        const pattern = validPatterns[i];\n        const normalized = this.normalizeRecordingLength(\n          pattern.rawData, \n          averagedPattern.rawData\n        );\n        \n        // Average with equal weights\n        const weight = 1 / validPatterns.length;\n        \n        // Average spectrograms\n        averagedPattern.rawData.spectrogram = averagedPattern.rawData.spectrogram.map((existingSpectrum, j) => {\n          const newSpectrum = normalized.spectrogram[j] || [];\n          return this.weightedAverageArrays(\n            existingSpectrum, \n            newSpectrum, \n            1 - weight, \n            weight\n          );\n        });\n        \n        // Average MFCCs\n        averagedPattern.rawData.mfcc = averagedPattern.rawData.mfcc.map((existingMfcc, j) => {\n          const newMfcc = normalized.mfcc[j] || [];\n          return this.weightedAverageArrays(\n            existingMfcc,\n            newMfcc,\n            1 - weight,\n            weight\n          );\n        });\n        \n        // Average energy\n        averagedPattern.rawData.energy = averagedPattern.rawData.energy.map((existing, j) => {\n          const newEnergy = normalized.energy[j] || 0;\n          return existing * (1 - weight) + newEnergy * weight;\n        });\n      }\n      \n      // Set combined sample count\n      averagedPattern.sampleCount = validPatterns.reduce((sum, p) => sum + p.sampleCount, 0);\n      \n      // Segment the pattern\n      averagedPattern.segments = this.segmentPattern(averagedPattern.rawData);\n      \n      // Calculate segment boundaries\n      this.calculateSegmentBoundaries(averagedPattern);\n      \n      // Replace the active pattern with the averaged one\n      this.state.patterns[this.state.activePatternIndex] = averagedPattern;\n      \n      // Update visualization\n      this.state.spectrogramData.pattern = [...averagedPattern.rawData.spectrogram];\n      \n      this.log('status', `Created averaged pattern from ${validPatterns.length} recordings`);\n      return true;\n    } catch (error) {\n      this.handleError('Error averaging patterns', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Set active pattern\n   */\n  setActivePattern(index) {\n    if (index < 0 || index >= this.config.maxPatterns) {\n      return false;\n    }\n    \n    this.state.activePatternIndex = index;\n    \n    // Update visualization if pattern exists\n    const pattern = this.state.patterns[index];\n    if (pattern && pattern.sampleCount > 0) {\n      this.state.spectrogramData.pattern = [...pattern.rawData.spectrogram];\n      \n      if (this.callbacks.onVisualizationUpdate) {\n        this.callbacks.onVisualizationUpdate('patternSwitch', null, pattern);\n      }\n      \n      this.log('status', `Switched to pattern ${index + 1}`);\n    } else {\n      this.state.spectrogramData.pattern = [];\n      \n      this.log('status', `Pattern ${index + 1} is empty`);\n    }\n    \n    return true;\n  }\n  \n  /**\n   * Clear the active pattern\n   */\n  clearActivePattern() {\n    const index = this.state.activePatternIndex;\n    \n    this.state.patterns[index] = null;\n    this.state.spectrogramData.pattern = [];\n    \n    this.log('status', `Cleared pattern ${index + 1}`);\n    \n    // Disable averaging button if needed\n    if (!this.checkMultiplePatternsExist() && this.callbacks.onStatusUpdate) {\n      this.callbacks.onStatusUpdate('control', 'enableAveraging', false);\n    }\n    \n    return true;\n  }\n  \n  /**\n   * Segment pattern into logical parts\n   */\n  segmentPattern(patternData) {\n    try {\n      const segmentCount = this.config.segmentCount;\n      const energy = patternData.energy;\n      const mfcc = patternData.mfcc;\n      const spectrogram = patternData.spectrogram;\n      \n      if (!energy || energy.length === 0) {\n        return [];\n      }\n      \n      // Find segment boundaries\n      let boundaries = [];\n      \n      // Try to find natural boundaries in energy profile\n      const smoothedEnergy = this.smoothArray([...energy], 3);\n      \n      // Find significant peaks and valleys\n      const peaks = this.findPeaks(smoothedEnergy);\n      const valleys = this.findValleys(smoothedEnergy);\n      \n      if (valleys.length >= segmentCount - 1) {\n        // Use valleys as natural breakpoints\n        boundaries = [0, ...valleys, energy.length - 1];\n        \n        // Keep strongest valleys if we have too many\n        while (boundaries.length > segmentCount + 1) {\n          // Find the shallowest valley\n          let shallowestIdx = -1;\n          let shallowestDepth = Infinity;\n          \n          for (let i = 1; i < boundaries.length - 1; i++) {\n            const idx = boundaries[i];\n            const depth = Math.min(\n              smoothedEnergy[idx-1] - smoothedEnergy[idx],\n              smoothedEnergy[idx+1] - smoothedEnergy[idx]\n            );\n            \n            if (depth < shallowestDepth) {\n              shallowestDepth = depth;\n              shallowestIdx = i;\n            }\n          }\n          \n          if (shallowestIdx > 0) {\n            boundaries.splice(shallowestIdx, 1);\n          } else {\n            break;\n          }\n        }\n      } else {\n        // Fallback to equal divisions\n        const segmentSize = Math.floor(energy.length / segmentCount);\n        \n        boundaries = [];\n        for (let i = 0; i <= segmentCount; i++) {\n          boundaries.push(Math.min(i * segmentSize, energy.length - 1));\n        }\n      }\n      \n      // Sort boundaries\n      boundaries = [...new Set(boundaries)].sort((a, b) => a - b);\n      \n      // Create segments\n      const segments = [];\n      for (let i = 0; i < boundaries.length - 1; i++) {\n        const start = boundaries[i];\n        const end = boundaries[i + 1];\n        \n        // Skip if segment is too small\n        if (end - start < 2) continue;\n        \n        // Create segment data\n        const segment = {\n          index: i,\n          startFrame: start,\n          endFrame: end,\n          frameCount: end - start,\n          // Extract feature slices\n          energy: energy.slice(start, end),\n          mfcc: mfcc.slice(start, end),\n          spectrogram: spectrogram.slice(start, end),\n          // Calculate averages\n          avgEnergy: this.average(energy.slice(start, end)),\n          avgSpectrogram: this.averageSpectrograms(spectrogram.slice(start, end)),\n          avgMfcc: this.averageArrays(mfcc.slice(start, end))\n        };\n        \n        segments.push(segment);\n      }\n      \n      return segments;\n    } catch (error) {\n      this.handleError('Error segmenting pattern', error);\n      return [];\n    }\n  }\n  \n  /**\n   * Calculate segment boundaries for visualization\n   */\n  calculateSegmentBoundaries(pattern) {\n    if (!pattern || !pattern.segments || pattern.segments.length === 0) return;\n    \n    // Calculate total frames\n    const totalFrames = pattern.rawData.energy.length;\n    \n    // Calculate boundaries as percentages\n    const boundaries = [];\n    \n    for (const segment of pattern.segments) {\n      const startPct = segment.startFrame / totalFrames;\n      const endPct = segment.endFrame / totalFrames;\n      \n      boundaries.push({\n        start: startPct,\n        end: endPct,\n        index: segment.index\n      });\n    }\n    \n    // Store boundaries\n    pattern.boundaries = boundaries;\n    \n    // Update time markers\n    this.state.timeMarkers.pattern = boundaries.map(b => b.start);\n  }\n  \n  /**\n   * Start detection\n   */\n  async startDetection() {\n    if (this.state.isDetecting) return false;\n    \n    // Get active pattern\n    const pattern = this.state.patterns[this.state.activePatternIndex];\n    \n    // Check if we have a pattern\n    if (!pattern || !pattern.segments || pattern.segments.length === 0) {\n      this.log('status', 'No pattern recorded yet');\n      return false;\n    }\n    \n    // Setup audio\n    const success = await this.setupAudio();\n    if (!success) return false;\n    \n    // Initialize detection state\n    this.state.isDetecting = true;\n    this.state.inCooldown = false;\n    \n    // Clear detection buffer\n    this.state.detectionBuffer = {\n      audio: [],\n      spectrogram: [],\n      mfcc: [],\n      energy: [],\n      timeWindow: []\n    };\n    \n    // Clear spectrogram data\n    this.state.spectrogramData.live = [];\n    \n    // Reset sequence state\n    this.resetSequenceState();\n    \n    // Create processor node\n    this.processor = this.audioContext.createScriptProcessor(\n      this.config.bufferSize, 1, 1\n    );\n    \n    // Store start time\n    const detectionStartTime = Date.now();\n    \n    // Process audio data for detection\n    this.processor.onaudioprocess = (event) => {\n      if (!this.state.isDetecting) return;\n      \n      try {\n        // Get audio data\n        const inputData = event.inputBuffer.getChannelData(0);\n        const audioData = new Float32Array(inputData.length);\n        audioData.set(inputData);\n        \n        // Extract features\n        const features = this.extractFeatures(audioData);\n        \n        // Current time in detection\n        const currentTime = Date.now() - detectionStartTime;\n        \n        // Add to detection buffer\n        this.state.detectionBuffer.audio.push(audioData);\n        this.state.detectionBuffer.spectrogram.push(features.spectrogram);\n        this.state.detectionBuffer.mfcc.push(features.mfcc);\n        this.state.detectionBuffer.energy.push(features.energy);\n        this.state.detectionBuffer.timeWindow.push(currentTime);\n        \n        // Update spectrogram data\n        this.state.spectrogramData.live.push(features.spectrogram);\n        \n        // Trim buffer to manageable size\n        this.trimDetectionBuffer();\n        \n        // Update visualization\n        if (this.callbacks.onVisualizationUpdate) {\n          this.callbacks.onVisualizationUpdate('detection', audioData, features);\n        }\n        \n        // Process detection if not in cooldown\n        if (!this.state.inCooldown) {\n          this.detectPattern();\n        }\n      } catch (error) {\n        this.handleError('Error in detection process', error);\n      }\n    };\n    \n    // Connect audio nodes\n    const source = this.audioContext.createMediaStreamSource(this.mediaStream);\n    source.connect(this.analyzer);\n    source.connect(this.processor);\n    this.processor.connect(this.audioContext.destination);\n    \n    // Start animation loop for cursor\n    this.startAnimationLoop();\n    \n    this.log('status', 'Listening for pattern...');\n    return true;\n  }\n  \n  /**\n   * Stop detection\n   */\n  stopDetection() {\n    if (!this.state.isDetecting) return false;\n    \n    // Update state\n    this.state.isDetecting = false;\n    this.state.inCooldown = false;\n    \n    // Stop animation\n    this.stopAnimationLoop();\n    \n    // Clean up\n    if (this.processor) {\n      this.processor.disconnect();\n      this.processor = null;\n    }\n    \n    // Reset sequence state\n    this.resetSequenceState();\n    \n    // Update progress\n    if (this.callbacks.onProgressUpdate) {\n      this.callbacks.onProgressUpdate(this.state.sequenceState);\n    }\n    \n    this.log('status', 'Detection stopped');\n    return true;\n  }\n  \n  /**\n   * Reset counter\n   */\n  resetCounter() {\n    this.state.counter = 0;\n    this.log('status', 'Counter reset to 0');\n    \n    if (this.callbacks.onDetection) {\n      this.callbacks.onDetection(0, 0);\n    }\n    \n    return true;\n  }\n  \n  /**\n   * Reset sequence state\n   */\n  resetSequenceState() {\n    // Get active pattern\n    const pattern = this.state.patterns[this.state.activePatternIndex];\n    \n    if (!pattern || !pattern.segments) {\n      this.state.sequenceState = {\n        segments: [],\n        currentIndex: 0,\n        progress: 0,\n        matchScores: [],\n        segmentStartTimes: [],\n        stuckTime: 0,\n        lastAdvanceTime: 0\n      };\n      return;\n    }\n    \n    // Initialize sequence tracking\n    this.state.sequenceState = {\n      segments: pattern.segments.map(() => 'pending'),\n      currentIndex: 0,\n      progress: 0,\n      matchScores: pattern.segments.map(() => 0),\n      segmentStartTimes: [],\n      stuckTime: 0,\n      lastAdvanceTime: Date.now()\n    };\n    \n    // Update visualization\n    if (this.callbacks.onProgressUpdate) {\n      this.callbacks.onProgressUpdate(this.state.sequenceState);\n    }\n  }\n  \n  /**\n   * Trim detection buffer\n   */\n  trimDetectionBuffer() {\n    // Get active pattern\n    const pattern = this.state.patterns[this.state.activePatternIndex];\n    if (!pattern) return;\n    \n    // Maximum frames to keep (2x pattern length)\n    const maxFrames = Math.max(\n      150,\n      pattern.segments.reduce((sum, s) => sum + s.frameCount, 0) * 2\n    );\n    \n    if (this.state.detectionBuffer.energy.length > maxFrames) {\n      const framesToRemove = this.state.detectionBuffer.energy.length - maxFrames;\n      \n      // Trim all buffer arrays\n      this.state.detectionBuffer.audio.splice(0, framesToRemove);\n      this.state.detectionBuffer.spectrogram.splice(0, framesToRemove);\n      this.state.detectionBuffer.mfcc.splice(0, framesToRemove);\n      this.state.detectionBuffer.energy.splice(0, framesToRemove);\n      this.state.detectionBuffer.timeWindow.splice(0, framesToRemove);\n    }\n    \n    // Also trim spectrogram history\n    if (this.state.spectrogramData.live.length > this.config.spectrogramHistory) {\n      this.state.spectrogramData.live.splice(\n        0, \n        this.state.spectrogramData.live.length - this.config.spectrogramHistory\n      );\n    }\n  }\n  \n  /**\n   * Core detection algorithm\n   */\n  detectPattern() {\n    try {\n      // Get active pattern\n      const pattern = this.state.patterns[this.state.activePatternIndex];\n      if (!pattern || !pattern.segments || pattern.segments.length === 0) {\n        return false;\n      }\n      \n      // Check if we have enough data\n      if (this.state.detectionBuffer.energy.length < 10) {\n        return false;\n      }\n      \n      // Get current sequence state\n      const sequenceState = this.state.sequenceState;\n      const currentIndex = sequenceState.currentIndex;\n      \n      // Get the target segment\n      const segment = pattern.segments[currentIndex];\n      if (!segment) return false;\n      \n      // Use different detection strategies based on mode\n      let result;\n      \n      switch (this.config.detectionMode) {\n        case 'flexible':\n          result = this.flexibleSequentialDetection(pattern);\n          break;\n        case 'adaptive':\n          result = this.adaptiveDetection(pattern);\n          break;\n        case 'sequential':\n        default:\n          result = this.strictSequentialDetection(pattern);\n          break;\n      }\n      \n      // Process result\n      if (result) {\n        // Update progress visualization\n        if (this.callbacks.onProgressUpdate) {\n          this.callbacks.onProgressUpdate(this.state.sequenceState, result.debugInfo);\n        }\n        \n        // Check if we detected the full pattern\n        if (result.patternDetected) {\n          this.registerDetection(result.confidence);\n        }\n        \n        return result.patternDetected;\n      }\n      \n      return false;\n    } catch (error) {\n      this.handleError('Error in pattern detection', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Strict sequential detection algorithm\n   */\n  strictSequentialDetection(pattern) {\n    // Current sequence state\n    const sequenceState = this.state.sequenceState;\n    const currentIndex = sequenceState.currentIndex;\n    \n    // Current segment\n    const segment = pattern.segments[currentIndex];\n    \n    // Get recent frames for matching\n    const windowSize = Math.min(segment.frameCount * 2, this.state.detectionBuffer.energy.length);\n    const recentFrames = {\n      energy: this.state.detectionBuffer.energy.slice(-windowSize),\n      mfcc: this.state.detectionBuffer.mfcc.slice(-windowSize),\n      spectrogram: this.state.detectionBuffer.spectrogram.slice(-windowSize)\n    };\n    \n    // Calculate match score for current segment\n    const matchScore = this.calculateSegmentMatch(recentFrames, segment);\n    \n    // Update match scores\n    sequenceState.matchScores[currentIndex] = matchScore;\n    \n    // Current time\n    const now = Date.now();\n    \n    // Check for timeout on current segment\n    if (sequenceState.segments[currentIndex] === 'active') {\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      \n      if (timeInSegment > this.config.segmentTimeout) {\n        // Stuck too long, reset\n        this.log('info', `Timeout on segment ${currentIndex + 1}`);\n        this.resetSequenceState();\n        return {\n          patternDetected: false,\n          confidence: 0,\n          debugInfo: {\n            currentSegment: 1,\n            matchScore: 0,\n            timeout: true\n          }\n        };\n      }\n    }\n    \n    // Debug info\n    const debugInfo = {\n      currentSegment: currentIndex + 1,\n      totalSegments: pattern.segments.length,\n      matchScore: matchScore,\n      threshold: this.config.minMatchThreshold\n    };\n    \n    // Handle current segment based on match score\n    if (matchScore >= this.config.minMatchThreshold) {\n      // If we just started matching this segment, record the start time\n      if (sequenceState.segments[currentIndex] === 'pending') {\n        sequenceState.segments[currentIndex] = 'active';\n        sequenceState.segmentStartTimes[currentIndex] = now;\n        sequenceState.lastAdvanceTime = now;\n        this.log('info', `Matching segment ${currentIndex + 1}/${pattern.segments.length}`);\n      }\n      \n      // Check if we've been matching long enough to advance\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      const minSegmentTime = Math.max(\n        300,  // At least 300ms per segment\n        (segment.frameCount / pattern.rawData.energy.length) * pattern.rawData.duration * 0.5\n      );\n      \n      if (timeInSegment >= minSegmentTime && matchScore >= this.config.advanceThreshold) {\n        // Mark segment as complete\n        sequenceState.segments[currentIndex] = 'complete';\n        \n        // Check if this was the last segment\n        if (currentIndex === pattern.segments.length - 1) {\n          // Completed the full pattern\n          return {\n            patternDetected: true,\n            confidence: this.calculateOverallConfidence(),\n            debugInfo: {\n              ...debugInfo,\n              timeInSegment,\n              minSegmentTime,\n              completed: true\n            }\n          };\n        } else {\n          // Move to next segment\n          sequenceState.currentIndex++;\n          sequenceState.lastAdvanceTime = now;\n          this.log('info', `Advanced to segment ${sequenceState.currentIndex + 1}/${pattern.segments.length}`);\n          \n          // Add progress data to debug info\n          debugInfo.advanced = true;\n          debugInfo.nextSegment = sequenceState.currentIndex + 1;\n        }\n      }\n      \n      // Add timing to debug info\n      debugInfo.timeInSegment = timeInSegment;\n      debugInfo.minSegmentTime = minSegmentTime;\n    } else {\n      // If we were matching but lost it, mark as invalid\n      if (sequenceState.segments[currentIndex] === 'active') {\n        sequenceState.segments[currentIndex] = 'invalid';\n        this.log('info', `Lost match for segment ${currentIndex + 1}`);\n        \n        // Reset after a short delay\n        setTimeout(() => {\n          // Only reset if we're still on this segment and still invalid\n          if (this.state.isDetecting && \n              this.state.sequenceState.currentIndex === currentIndex &&\n              this.state.sequenceState.segments[currentIndex] === 'invalid') {\n            this.resetSequenceState();\n            this.log('info', 'Reset sequence state');\n          }\n        }, 300);\n      }\n    }\n    \n    // Calculate overall progress\n    const completedSegments = sequenceState.segments.filter(s => s === 'complete').length;\n    const activeSegment = sequenceState.segments.indexOf('active');\n    \n    if (activeSegment !== -1) {\n      // Include partial progress of active segment\n      const activeProgress = matchScore * (1 / pattern.segments.length);\n      sequenceState.progress = (completedSegments / pattern.segments.length) + activeProgress;\n    } else {\n      sequenceState.progress = completedSegments / pattern.segments.length;\n    }\n    \n    // Add progress to debug info\n    debugInfo.progress = sequenceState.progress;\n    debugInfo.segments = [...sequenceState.segments];\n    \n    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };\n  }\n  \n  /**\n   * Flexible sequential detection\n   * Allows some segments to be skipped or detected out of order\n   */\n  flexibleSequentialDetection(pattern) {\n    // Current sequence state\n    const sequenceState = this.state.sequenceState;\n    const currentIndex = sequenceState.currentIndex;\n    \n    // Calculate match scores for all segments\n    const matchScores = pattern.segments.map((segment, i) => {\n      // Get window size based on segment size\n      const windowSize = Math.min(segment.frameCount * 2, this.state.detectionBuffer.energy.length);\n      \n      // Get recent frames\n      const recentFrames = {\n        energy: this.state.detectionBuffer.energy.slice(-windowSize),\n        mfcc: this.state.detectionBuffer.mfcc.slice(-windowSize),\n        spectrogram: this.state.detectionBuffer.spectrogram.slice(-windowSize)\n      };\n      \n      // Calculate match score\n      return this.calculateSegmentMatch(recentFrames, segment);\n    });\n    \n    // Update match scores\n    sequenceState.matchScores = matchScores;\n    \n    // Find best matching segment\n    const bestMatchIndex = matchScores.indexOf(Math.max(...matchScores));\n    const bestMatchScore = matchScores[bestMatchIndex];\n    \n    // Current time\n    const now = Date.now();\n    \n    // Debug info\n    const debugInfo = {\n      currentSegment: currentIndex + 1,\n      totalSegments: pattern.segments.length,\n      matchScores,\n      bestMatchIndex: bestMatchIndex + 1,\n      bestMatchScore,\n      threshold: this.config.minMatchThreshold\n    };\n    \n    // Check for timeout\n    if (sequenceState.segments[currentIndex] === 'active') {\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      \n      if (timeInSegment > this.config.segmentTimeout) {\n        // Check if a later segment is matching better\n        if (bestMatchIndex > currentIndex && bestMatchScore >= this.config.advanceThreshold) {\n          // Skip to that segment\n          for (let i = currentIndex; i < bestMatchIndex; i++) {\n            sequenceState.segments[i] = 'complete';\n          }\n          sequenceState.currentIndex = bestMatchIndex;\n          sequenceState.segmentStartTimes[bestMatchIndex] = now;\n          sequenceState.segments[bestMatchIndex] = 'active';\n          sequenceState.lastAdvanceTime = now;\n          \n          this.log('info', `Skipped to segment ${bestMatchIndex + 1} (better match)`);\n          \n          // Update debug info\n          debugInfo.skipped = true;\n          debugInfo.skippedTo = bestMatchIndex + 1;\n        } else {\n          // Reset if stuck too long with no better matches\n          this.log('info', `Timeout on segment ${currentIndex + 1}`);\n          this.resetSequenceState();\n          \n          // Update debug info\n          debugInfo.timeout = true;\n          \n          return {\n            patternDetected: false,\n            confidence: 0,\n            debugInfo\n          };\n        }\n      }\n    }\n    \n    // Current segment match\n    const currentMatch = matchScores[currentIndex];\n    \n    // Forward lookahead - if a later segment is matching very well\n    if (sequenceState.segments[currentIndex] === 'pending' && currentMatch < this.config.minMatchThreshold) {\n      // Check if any later segment is matching well\n      for (let i = currentIndex + 1; i < matchScores.length; i++) {\n        if (matchScores[i] >= this.config.minMatchThreshold * 1.2) {\n          // Skip to this segment\n          sequenceState.currentIndex = i;\n          sequenceState.segments[i] = 'active';\n          sequenceState.segmentStartTimes[i] = now;\n          sequenceState.lastAdvanceTime = now;\n          \n          this.log('info', `Jumped to segment ${i + 1} (strong match)`);\n          \n          // Update debug info\n          debugInfo.jumped = true;\n          debugInfo.jumpedTo = i + 1;\n          \n          break;\n        }\n      }\n    }\n    \n    // Update current index after possible jumps\n    const updatedCurrentIndex = sequenceState.currentIndex;\n    const currentSegment = pattern.segments[updatedCurrentIndex];\n    \n    // Handle current segment based on match score\n    if (matchScores[updatedCurrentIndex] >= this.config.minMatchThreshold) {\n      // If we just started matching this segment, record the start time\n      if (sequenceState.segments[updatedCurrentIndex] === 'pending') {\n        sequenceState.segments[updatedCurrentIndex] = 'active';\n        sequenceState.segmentStartTimes[updatedCurrentIndex] = now;\n        sequenceState.lastAdvanceTime = now;\n        this.log('info', `Matching segment ${updatedCurrentIndex + 1}/${pattern.segments.length}`);\n      }\n      \n      // Check if we've been matching long enough to advance\n      const timeInSegment = now - (sequenceState.segmentStartTimes[updatedCurrentIndex] || now);\n      const minSegmentTime = Math.max(\n        200,  // Shorter minimum time for flexible mode\n        (currentSegment.frameCount / pattern.rawData.energy.length) * pattern.rawData.duration * 0.4\n      );\n      \n      // Add timing to debug info\n      debugInfo.timeInSegment = timeInSegment;\n      debugInfo.minSegmentTime = minSegmentTime;\n      \n      if (timeInSegment >= minSegmentTime && matchScores[updatedCurrentIndex] >= this.config.advanceThreshold) {\n        // Mark segment as complete\n        sequenceState.segments[updatedCurrentIndex] = 'complete';\n        \n        // Check if this was the last segment\n        if (updatedCurrentIndex === pattern.segments.length - 1) {\n          // Completed the full pattern\n          return {\n            patternDetected: true,\n            confidence: this.calculateOverallConfidence(),\n            debugInfo: {\n              ...debugInfo,\n              completed: true\n            }\n          };\n        } else {\n          // Move to next segment\n          sequenceState.currentIndex++;\n          sequenceState.lastAdvanceTime = now;\n          this.log('info', `Advanced to segment ${sequenceState.currentIndex + 1}/${pattern.segments.length}`);\n          \n          // Add progress data to debug info\n          debugInfo.advanced = true;\n          debugInfo.nextSegment = sequenceState.currentIndex + 1;\n        }\n      }\n    } else {\n      // If we were matching but lost it, check if a different segment matches better\n      if (sequenceState.segments[updatedCurrentIndex] === 'active') {\n        // If best match is a different segment with a good score\n        if (bestMatchIndex !== updatedCurrentIndex && bestMatchScore >= this.config.minMatchThreshold) {\n          // If it's a later segment, skip to it\n          if (bestMatchIndex > updatedCurrentIndex) {\n            // Mark all segments up to best match as complete\n            for (let i = updatedCurrentIndex; i < bestMatchIndex; i++) {\n              sequenceState.segments[i] = 'complete';\n            }\n            \n            sequenceState.currentIndex = bestMatchIndex;\n            sequenceState.segments[bestMatchIndex] = 'active';\n            sequenceState.segmentStartTimes[bestMatchIndex] = now;\n            sequenceState.lastAdvanceTime = now;\n            \n            this.log('info', `Skipped to segment ${bestMatchIndex + 1} (better match)`);\n            \n            // Update debug info\n            debugInfo.skipped = true;\n            debugInfo.skippedTo = bestMatchIndex + 1;\n          } \n          // If it's an earlier segment, allow jumping back\n          else if (bestMatchIndex < updatedCurrentIndex) {\n            // Only jump back if the score is significantly better\n            if (bestMatchScore > matchScores[updatedCurrentIndex] * 1.5) {\n              // Reset segments after best match\n              for (let i = bestMatchIndex + 1; i < sequenceState.segments.length; i++) {\n                sequenceState.segments[i] = 'pending';\n              }\n              \n              sequenceState.currentIndex = bestMatchIndex;\n              sequenceState.segments[bestMatchIndex] = 'active';\n              sequenceState.segmentStartTimes[bestMatchIndex] = now;\n              sequenceState.lastAdvanceTime = now;\n              \n              this.log('info', `Jumped back to segment ${bestMatchIndex + 1} (much better match)`);\n              \n              // Update debug info\n              debugInfo.jumpedBack = true;\n              debugInfo.jumpedBackTo = bestMatchIndex + 1;\n            }\n          }\n        } else {\n          // Mark as invalid if no better matches found\n          sequenceState.segments[updatedCurrentIndex] = 'invalid';\n          this.log('info', `Lost match for segment ${updatedCurrentIndex + 1}`);\n          \n          // Reset after a short delay\n          setTimeout(() => {\n            if (this.state.isDetecting && \n                this.state.sequenceState.currentIndex === updatedCurrentIndex &&\n                this.state.sequenceState.segments[updatedCurrentIndex] === 'invalid') {\n              this.resetSequenceState();\n              this.log('info', 'Reset sequence state');\n            }\n          }, 300);\n        }\n      }\n    }\n    \n    // Calculate overall progress\n    const completedSegments = sequenceState.segments.filter(s => s === 'complete').length;\n    const activeSegment = sequenceState.segments.indexOf('active');\n    \n    if (activeSegment !== -1) {\n      // Include partial progress of active segment\n      const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);\n      sequenceState.progress = (completedSegments / pattern.segments.length) + activeProgress;\n    } else {\n      sequenceState.progress = completedSegments / pattern.segments.length;\n    }\n    \n    // Add progress to debug info\n    debugInfo.progress = sequenceState.progress;\n    debugInfo.segments = [...sequenceState.segments];\n    \n    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };\n  }\n  \n  /**\n   * Adaptive detection that self-adjusts based on input\n   */\n  adaptiveDetection(pattern) {\n    // Similar to flexible detection but with dynamic thresholds\n    const sequenceState = this.state.sequenceState;\n    \n    // Dynamically adjust thresholds based on recent history\n    const currentMatch = sequenceState.matchScores[sequenceState.currentIndex] || 0;\n    \n    // If we've been stuck on a segment for a while, gradually lower the threshold\n    if (sequenceState.segments[sequenceState.currentIndex] === 'active') {\n      const timeInSegment = Date.now() - (sequenceState.segmentStartTimes[sequenceState.currentIndex] || Date.now());\n      \n      // Lower threshold if stuck for a while but still matching somewhat\n      if (timeInSegment > 1000 && currentMatch > this.config.minMatchThreshold * 0.7) {\n        // Calculate adaptive threshold - decrease over time\n        const adaptiveFactor = Math.max(0.5, 1 - (timeInSegment / this.config.segmentTimeout));\n        const adaptiveThreshold = this.config.advanceThreshold * adaptiveFactor;\n        \n        // Use this for advance decision\n        if (currentMatch >= adaptiveThreshold) {\n          // Force advancement\n          sequenceState.stuckTime += timeInSegment;\n          \n          // Call flexible detection with temporarily lowered threshold\n          const origThreshold = this.config.advanceThreshold;\n          this.config.advanceThreshold = adaptiveThreshold;\n          \n          const result = this.flexibleSequentialDetection(pattern);\n          \n          // Restore original threshold\n          this.config.advanceThreshold = origThreshold;\n          \n          // Add adaptive info\n          result.debugInfo.adaptive = true;\n          result.debugInfo.adaptiveThreshold = adaptiveThreshold;\n          result.debugInfo.stuckTime = sequenceState.stuckTime;\n          \n          return result;\n        }\n      }\n    }\n    \n    // Otherwise use flexible detection\n    return this.flexibleSequentialDetection(pattern);\n  }\n  \n  /**\n   * Calculate match between audio and a pattern segment\n   */\n  calculateSegmentMatch(audioData, segment) {\n    // Nothing to match\n    if (!audioData || !segment) return 0;\n    \n    // Get feature arrays\n    const energy = audioData.energy;\n    const mfcc = audioData.mfcc;\n    const spectrogram = audioData.spectrogram;\n    \n    if (!energy.length || !mfcc.length || !spectrogram.length) return 0;\n    \n    // Sliding window approach\n    let bestMatch = 0;\n    const windowSize = Math.min(segment.frameCount, energy.length);\n    \n    for (let i = 0; i <= energy.length - windowSize; i++) {\n      const windowEnergy = energy.slice(i, i + windowSize);\n      const windowMfcc = mfcc.slice(i, i + windowSize);\n      const windowSpectrogram = spectrogram.slice(i, i + windowSize);\n      \n      // Calculate similarity scores\n      const energyMatch = this.calculateEnergySimilarity(windowEnergy, segment.energy);\n      \n      // Average MFCC across window\n      const avgWindowMfcc = this.averageArrays(windowMfcc);\n      const mfccMatch = this.cosineSimilarity(avgWindowMfcc, segment.avgMfcc);\n      \n      // Average spectrogram\n      const avgWindowSpectrogram = this.averageSpectrograms(windowSpectrogram);\n      const spectrogramMatch = this.spectrogramSimilarity(\n        avgWindowSpectrogram, segment.avgSpectrogram\n      );\n      \n      // Weighted combination\n      const score = \n        (energyMatch * this.config.featureWeights.energy) +\n        (mfccMatch * this.config.featureWeights.mfcc) +\n        (spectrogramMatch * this.config.featureWeights.spectrogram);\n      \n      bestMatch = Math.max(bestMatch, score);\n    }\n    \n    return bestMatch;\n  }\n  \n  /**\n   * Calculate similarity between energy profiles\n   */\n  calculateEnergySimilarity(energyA, energyB) {\n    if (!energyA || !energyB || !energyA.length || !energyB.length) {\n      return 0;\n    }\n    \n    // Normalize lengths\n    const lenA = energyA.length;\n    const lenB = energyB.length;\n    const normalized = [];\n    \n    // Simple resampling\n    for (let i = 0; i < lenB; i++) {\n      const idx = Math.floor(i * lenA / lenB);\n      normalized[i] = energyA[idx];\n    }\n    \n    // Calculate correlation\n    return this.correlationSimilarity(normalized, energyB);\n  }\n  \n  /**\n   * Calculate correlation similarity between arrays\n   */\n  correlationSimilarity(arrA, arrB) {\n    // Calculate means\n    const meanA = this.average(arrA);\n    const meanB = this.average(arrB);\n    \n    // Calculate correlation\n    let num = 0;\n    let denA = 0;\n    let denB = 0;\n    \n    for (let i = 0; i < Math.min(arrA.length, arrB.length); i++) {\n      const a = arrA[i] - meanA;\n      const b = arrB[i] - meanB;\n      \n      num += a * b;\n      denA += a * a;\n      denB += b * b;\n    }\n    \n    // Avoid division by zero\n    if (denA === 0 || denB === 0) return 0;\n    \n    // Return Pearson correlation (between -1 and 1)\n    const corr = num / Math.sqrt(denA * denB);\n    \n    // Convert to similarity (0-1)\n    return (corr + 1) / 2;\n  }\n  \n  /**\n   * Compare two spectrograms\n   */\n  spectrogramSimilarity(spectrogramA, spectrogramB) {\n    if (!spectrogramA || !spectrogramB || \n        !spectrogramA.length || !spectrogramB.length) {\n      return 0;\n    }\n    \n    // Use cosine similarity between flattened spectrograms\n    const flatA = spectrogramA.flat ? spectrogramA.flat() : this.flattenArray(spectrogramA);\n    const flatB = spectrogramB.flat ? spectrogramB.flat() : this.flattenArray(spectrogramB);\n    \n    return this.cosineSimilarity(flatA, flatB);\n  }\n  \n  /**\n   * Register a detection\n   */\n  registerDetection(confidence) {\n    if (this.state.inCooldown) return false;\n    \n    // Increment counter\n    this.state.counter++;\n    this.state.lastDetectionTime = Date.now();\n    this.state.inCooldown = true;\n    \n    // Log detection\n    this.log('detection', `Pattern detected! Count: ${this.state.counter}`, true);\n    \n    // Reset sequence state\n    this.resetSequenceState();\n    \n    // Trigger callback\n    if (this.callbacks.onDetection) {\n      this.callbacks.onDetection(this.state.counter, confidence);\n    }\n    \n    // Start cooldown timer\n    setTimeout(() => {\n      this.state.inCooldown = false;\n    }, this.config.cooldownTime);\n    \n    return true;\n  }\n  \n  /**\n   * Calculate overall confidence for current match\n   */\n  calculateOverallConfidence() {\n    const matchScores = this.state.sequenceState.matchScores;\n    const segments = this.state.sequenceState.segments;\n    \n    if (!matchScores || matchScores.length === 0) {\n      return 0;\n    }\n    \n    // Weight completed segments more heavily\n    let weightedSum = 0;\n    let weightSum = 0;\n    \n    matchScores.forEach((score, index) => {\n      // Higher weight for completed segments\n      let weight = 1;\n      \n      if (segments[index] === 'complete') {\n        weight = 1.5;\n      } else if (segments[index] === 'active') {\n        weight = 1.2;\n      }\n      \n      weightedSum += score * weight;\n      weightSum += weight;\n    });\n    \n    return weightSum > 0 ? weightedSum / weightSum : 0;\n  }\n  \n  /**\n   * Extract features from audio data\n   */\n  extractFeatures(audioData) {\n    try {\n      // Basic amplitude/energy\n      let sum = 0;\n      for (let i = 0; i < audioData.length; i++) {\n        sum += Math.abs(audioData[i]);\n      }\n      const amplitude = sum / audioData.length;\n      const energy = amplitude * amplitude * 100;\n      \n      // Get frequency data\n      const frequencyData = new Uint8Array(this.analyzer.frequencyBinCount);\n      this.analyzer.getByteFrequencyData(frequencyData);\n      \n      // Extract MFCC using Meyda\n      let mfcc = new Array(13).fill(0);\n      try {\n        const meydaFeatures = Meyda.extract('mfcc', audioData);\n        if (meydaFeatures && meydaFeatures.mfcc) {\n          mfcc = meydaFeatures.mfcc;\n        }\n      } catch (e) {\n        // Ignore Meyda errors and use fallback\n      }\n      \n      // Convert spectrogram data\n      const spectrogram = this.processSpectrumData(frequencyData);\n      \n      return {\n        amplitude,\n        energy,\n        mfcc,\n        spectrogram,\n        raw: {\n          frequencyData\n        }\n      };\n    } catch (error) {\n      this.handleError('Error extracting features', error);\n      \n      // Return dummy features\n      return {\n        amplitude: 0,\n        energy: 0,\n        mfcc: new Array(13).fill(0),\n        spectrogram: new Array(128).fill(0),\n        raw: {\n          frequencyData: new Uint8Array(1024)\n        }\n      };\n    }\n  }\n  \n  /**\n   * Process raw spectrum data into a more compact format\n   */\n  processSpectrumData(frequencyData) {\n    // Reduce dimensionality for efficiency\n    const bins = 128; // 128 frequency bins\n    const result = new Array(bins).fill(0);\n    \n    const binSize = Math.floor(frequencyData.length / bins);\n    \n    for (let i = 0; i < bins; i++) {\n      const start = i * binSize;\n      const end = (i + 1) * binSize;\n      \n      // Average values in this frequency bin\n      let sum = 0;\n      for (let j = start; j < end && j < frequencyData.length; j++) {\n        sum += frequencyData[j];\n      }\n      \n      result[i] = sum / binSize / 255; // Normalize to 0-1\n    }\n    \n    return result;\n  }\n  \n  /**\n   * Start animation loop for cursor movement\n   */\n  startAnimationLoop() {\n    // Stop any existing loop\n    this.stopAnimationLoop();\n    \n    // Animation function\n    const animate = () => {\n      // Move time cursor\n      const cursor = document.getElementById('timeCursor');\n      if (cursor) {\n        // Get a position that oscillates between 25% and 75%\n        const time = Date.now() / 1000;\n        const position = 50 + 25 * Math.sin(time);\n        cursor.style.left = `${position}%`;\n      }\n      \n      // Request next frame\n      this.animationFrame = requestAnimationFrame(animate);\n    };\n    \n    // Start animation\n    this.animationFrame = requestAnimationFrame(animate);\n  }\n  \n  /**\n   * Stop animation loop\n   */\n  stopAnimationLoop() {\n    if (this.animationFrame) {\n      cancelAnimationFrame(this.animationFrame);\n      this.animationFrame = null;\n    }\n  }\n  \n  /**\n   * Update configuration\n   */\n  updateConfig(config) {\n    Object.assign(this.config, config);\n    \n    // If segment count changed and we have a pattern, re-segment it\n    if (config.segmentCount !== undefined && this.state.patterns[this.state.activePatternIndex]) {\n      const pattern = this.state.patterns[this.state.activePatternIndex];\n      \n      if (pattern && pattern.rawData) {\n        pattern.segments = this.segmentPattern(pattern.rawData);\n        this.calculateSegmentBoundaries(pattern);\n      }\n    }\n  }\n  \n  /**\n   * Find peaks in energy profile\n   */\n  findPeaks(signal, minHeight = 0.1) {\n    const peaks = [];\n    for (let i = 2; i < signal.length - 2; i++) {\n      if (signal[i] > minHeight && \n          signal[i] > signal[i-1] && signal[i] >= signal[i-2] &&\n          signal[i] > signal[i+1] && signal[i] >= signal[i+2]) {\n        peaks.push(i);\n      }\n    }\n    return peaks;\n  }\n  \n  /**\n   * Find valleys in energy profile\n   */\n  findValleys(signal, maxHeight = 0.9) {\n    const valleys = [];\n    for (let i = 2; i < signal.length - 2; i++) {\n      if (signal[i] < maxHeight && \n          signal[i] < signal[i-1] && signal[i] <= signal[i-2] &&\n          signal[i] < signal[i+1] && signal[i] <= signal[i+2]) {\n        valleys.push(i);\n      }\n    }\n    return valleys;\n  }\n  \n  /**\n   * Smooth an array using moving average\n   */\n  smoothArray(array, windowSize = 3) {\n    const result = [];\n    const half = Math.floor(windowSize / 2);\n    \n    for (let i = 0; i < array.length; i++) {\n      let sum = 0;\n      let count = 0;\n      \n      for (let j = Math.max(0, i - half); j <= Math.min(array.length - 1, i + half); j++) {\n        sum += array[j];\n        count++;\n      }\n      \n      result.push(sum / count);\n    }\n    \n    return result;\n  }\n  \n  /**\n   * Average multiple arrays\n   */\n  averageArrays(arrays) {\n    if (!arrays || arrays.length === 0 || !arrays[0]) return [];\n    \n    const result = new Array(arrays[0].length).fill(0);\n    let validArrays = 0;\n    \n    for (const arr of arrays) {\n      if (!arr) continue;\n      \n      validArrays++;\n      for (let i = 0; i < Math.min(result.length, arr.length); i++) {\n        result[i] += arr[i];\n      }\n    }\n    \n    return validArrays > 0 ? result.map(val => val / validArrays) : result;\n  }\n  \n  /**\n   * Average multiple spectrograms\n   */\n  averageSpectrograms(spectrograms) {\n    return this.averageArrays(spectrograms);\n  }\n  \n  /**\n   * Calculate average of array\n   */\n  average(array) {\n    if (!array || array.length === 0) return 0;\n    return array.reduce((sum, val) => sum + val, 0) / array.length;\n  }\n  \n  /**\n   * Calculate cosine similarity between arrays\n   */\n  cosineSimilarity(arrA, arrB) {\n    if (!arrA || !arrB || arrA.length === 0 || arrB.length === 0) {\n      return 0;\n    }\n    \n    const length = Math.min(arrA.length, arrB.length);\n    \n    let dotProduct = 0;\n    let normA = 0;\n    let normB = 0;\n    \n    for (let i = 0; i < length; i++) {\n      dotProduct += arrA[i] * arrB[i];\n      normA += arrA[i] * arrA[i];\n      normB += arrB[i] * arrB[i];\n    }\n    \n    const denominator = Math.sqrt(normA) * Math.sqrt(normB);\n    \n    return denominator === 0 ? 0 : dotProduct / denominator;\n  }\n  \n  /**\n   * Flatten a 2D array\n   */\n  flattenArray(array) {\n    if (array.flat) return array.flat();\n    \n    return [].concat(...array);\n  }\n  \n  /**\n   * Handle errors\n   */\n  handleError(message, error) {\n    const errorMessage = `${message}: ${error.message || error}`;\n    console.error(errorMessage);\n    \n    if (this.callbacks.onError) {\n      this.callbacks.onError(message, error);\n    }\n  }\n  \n  /**\n   * Log messages\n   */\n  log(type, message, highlight = false) {\n    console.log(`[${type.toUpperCase()}] ${message}`);\n    \n    if (this.callbacks.onStatusUpdate) {\n      this.callbacks.onStatusUpdate(type, message, highlight);\n    }\n    \n    return { type, message, highlight };\n  }\n}\n\n// Main Application\ndocument.addEventListener('DOMContentLoaded', () => {\n  // Elements\n  const elements = {\n    // Pattern recording \n    recordingStatus: document.getElementById('recordingStatus'),\n    recordBtn: document.getElementById('recordBtn'),\n    clearBtn: document.getElementById('clearBtn'),\n    averageBtn: document.getElementById('averageBtn'),\n    patternInfo: document.getElementById('patternInfo'),\n    patternStats: document.getElementById('patternStats'),\n    patternDisplay: document.getElementById('patternDisplay'),\n    recordSpectrogram: document.getElementById('recordSpectrogram'),\n    recordSegmentMarkers: document.getElementById('recordSegmentMarkers'),\n    \n    // Detection\n    liveSpectrogram: document.getElementById('liveSpectrogram'),\n    liveSegmentMarkers: document.getElementById('liveSegmentMarkers'),\n    timeCursor: document.getElementById('timeCursor'),\n    detectionStatus: document.getElementById('detectionStatus'),\n    counterValue: document.getElementById('counterValue'),\n    sequenceProgress: document.getElementById('sequenceProgress'),\n    detectionProgress: document.getElementById('detectionProgress'),\n    \n    // Controls\n    startBtn: document.getElementById('startBtn'),\n    stopBtn: document.getElementById('stopBtn'),\n    resetBtn: document.getElementById('resetBtn'),\n    patternTabs: document.querySelectorAll('.pattern-tab'),\n    \n    // Settings\n    detectionMode: document.getElementById('detectionMode'),\n    minMatchSlider: document.getElementById('minMatchSlider'),\n    minMatchValue: document.getElementById('minMatchValue'),\n    advanceThresholdSlider: document.getElementById('advanceThresholdSlider'),\n    advanceThresholdValue: document.getElementById('advanceThresholdValue'),\n    timeoutSlider: document.getElementById('timeoutSlider'),\n    timeoutValue: document.getElementById('timeoutValue'),\n    cooldownSlider: document.getElementById('cooldownSlider'),\n    cooldownValue: document.getElementById('cooldownValue'),\n    segmentCountSelect: document.getElementById('segmentCountSelect'),\n    \n    // Debug\n    debugPanel: document.getElementById('debugPanel'),\n    detectionLog: document.getElementById('detectionLog')\n  };\n  \n  // Canvas contexts\n  const contexts = {\n    recordSpectrogram: elements.recordSpectrogram.getContext('2d'),\n    liveSpectrogram: elements.liveSpectrogram.getContext('2d')\n  };\n  \n  // Create detector\n  const detector = new ImprovedChantDetector();\n  \n  // Set up detector callbacks\n  detector.setCallbacks({\n    onStatusUpdate: (type, message, data) => {\n      if (type === 'status') {\n        elements.detectionStatus.textContent = message;\n      } else if (type === 'info') {\n        logDetection(message, false);\n      } else if (type === 'detection') {\n        logDetection(message, data);\n      } else if (type === 'control') {\n        if (message === 'enableAveraging') {\n          elements.averageBtn.disabled = !data;\n        }\n      }\n    },\n    \n    onVisualizationUpdate: (mode, audioData, features) => {\n      if (mode === 'recording') {\n        drawSpectrogram(contexts.recordSpectrogram, features.raw.frequencyData);\n      } else if (mode === 'detection') {\n        drawSpectrogram(contexts.liveSpectrogram, features.raw.frequencyData);\n      } else if (mode === 'patternSwitch') {\n        updatePatternDisplay(features);\n      }\n    },\n    \n    onDetection: (count, confidence) => {\n      elements.counterValue.textContent = count;\n      elements.detectionProgress.style.backgroundColor = '#f44336';\n      \n      setTimeout(() => {\n        elements.detectionProgress.style.backgroundColor = '#4caf50';\n      }, 300);\n    },\n    \n    onProgressUpdate: (sequenceState, debugData) => {\n      // Update progress bar\n      elements.detectionProgress.style.width = `${Math.round(sequenceState.progress * 100)}%`;\n      \n      // Update sequence progress visualization\n      updateSequenceProgress(sequenceState);\n      \n      // Update debug panel\n      if (debugData) {\n        updateDebugPanel(debugData);\n      }\n    },\n    \n    onError: (message, error) => {\n      console.error(message, error);\n      logDetection(`Error: ${message}`, true);\n    }\n  });\n  \n  // Button handlers\n  elements.recordBtn.addEventListener('mousedown', () => {\n    detector.startRecording();\n    elements.recordBtn.textContent = 'Recording...';\n  });\n  \n  elements.recordBtn.addEventListener('mouseup', () => {\n    detector.stopRecording();\n    elements.recordBtn.textContent = 'Record (Hold)';\n    updatePatternInfo();\n  });\n  \n  elements.recordBtn.addEventListener('mouseleave', () => {\n    if (detector.state.isRecording) {\n      detector.stopRecording();\n      elements.recordBtn.textContent = 'Record (Hold)';\n      updatePatternInfo();\n    }\n  });\n  \n  elements.clearBtn.addEventListener('click', () => {\n    detector.clearActivePattern();\n    updatePatternInfo();\n    elements.startBtn.disabled = true;\n    \n    // Clear display\n    elements.patternDisplay.innerHTML = '';\n    elements.recordSegmentMarkers.innerHTML = '';\n    clearCanvas(contexts.recordSpectrogram);\n  });\n  \n  elements.averageBtn.addEventListener('click', () => {\n    detector.averageAllPatterns();\n    updatePatternInfo();\n  });\n  \n  elements.startBtn.addEventListener('click', () => {\n    detector.startDetection();\n    elements.startBtn.disabled = true;\n    elements.stopBtn.disabled = false;\n  });\n  \n  elements.stopBtn.addEventListener('click', () => {\n    detector.stopDetection();\n    elements.startBtn.disabled = false;\n    elements.stopBtn.disabled = true;\n    \n    // Reset visualizations\n    elements.detectionProgress.style.width = '0%';\n    elements.sequenceProgress.innerHTML = '';\n    elements.liveSegmentMarkers.innerHTML = '';\n    clearCanvas(contexts.liveSpectrogram);\n  });\n  \n  elements.resetBtn.addEventListener('click', () => {\n    detector.resetCounter();\n  });\n  \n  // Pattern tabs\n  elements.patternTabs.forEach(tab => {\n    tab.addEventListener('click', () => {\n      const patternIndex = parseInt(tab.getAttribute('data-pattern')) - 1;\n      \n      // Update active tab\n      elements.patternTabs.forEach(t => t.classList.remove('active'));\n      tab.classList.add('active');\n      \n      // Set active pattern\n      detector.setActivePattern(patternIndex);\n      \n      updatePatternInfo();\n    });\n  });\n  \n  // Settings handlers\n  elements.detectionMode.addEventListener('change', () => {\n    detector.updateConfig({\n      detectionMode: elements.detectionMode.value\n    });\n    \n    logDetection(`Detection mode changed to: ${elements.detectionMode.value}`);\n  });\n  \n  elements.minMatchSlider.addEventListener('input', () => {\n    const value = elements.minMatchSlider.value;\n    elements.minMatchValue.textContent = value;\n    \n    detector.updateConfig({\n      minMatchThreshold: parseFloat(value)\n    });\n  });\n  \n  elements.advanceThresholdSlider.addEventListener('input', () => {\n    const value = elements.advanceThresholdSlider.value;\n    elements.advanceThresholdValue.textContent = value;\n    \n    detector.updateConfig({\n      advanceThreshold: parseFloat(value)\n    });\n  });\n  \n  elements.timeoutSlider.addEventListener('input', () => {\n    const value = elements.timeoutSlider.value;\n    elements.timeoutValue.textContent = value;\n    \n    detector.updateConfig({\n      segmentTimeout: parseInt(value)\n    });\n  });\n  \n  elements.cooldownSlider.addEventListener('input', () => {\n    const value = elements.cooldownSlider.value;\n    elements.cooldownValue.textContent = value;\n    \n    detector.updateConfig({\n      cooldownTime: parseInt(value)\n    });\n  });\n  \n  elements.segmentCountSelect.addEventListener('change', () => {\n    detector.updateConfig({\n      segmentCount: parseInt(elements.segmentCountSelect.value)\n    });\n    \n    // Update pattern info if we have a pattern\n    if (detector.state.patterns[detector.state.activePatternIndex]) {\n      updatePatternInfo();\n    }\n  });\n  \n  // Visualization functions\n  function drawSpectrogram(ctx, frequencyData) {\n    const width = ctx.canvas.width;\n    const height = ctx.canvas.height;\n    \n    // Shift existing spectrogram left\n    const imgData = ctx.getImageData(1, 0, width - 1, height);\n    ctx.putImageData(imgData, 0, 0);\n    \n    // Draw new column\n    const columnWidth = 1;\n    const binCount = Math.min(128, frequencyData.length / 4);\n    const binHeight = height / binCount;\n    \n    for (let i = 0; i < binCount; i++) {\n      // Reverse order (low frequency at bottom)\n      const y = height - (i + 1) * binHeight;\n      \n      // Average a range of frequency bins\n      const startBin = i * 4;\n      const endBin = startBin + 4;\n      \n      let binSum = 0;\n      for (let j = startBin; j < endBin && j < frequencyData.length; j++) {\n        binSum += frequencyData[j];\n      }\n      \n      const intensity = binSum / 4;\n      \n      // Create color (blue to red gradient)\n      const hue = 240 * (1 - intensity / 255);\n      const saturation = '100%';\n      const lightness = '50%';\n      \n      ctx.fillStyle = `hsl(${hue}, ${saturation}, ${lightness})`;\n      ctx.fillRect(width - columnWidth, y, columnWidth, binHeight);\n    }\n  }\n  \n  function clearCanvas(ctx) {\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n  }\n  \n  function updateSequenceProgress(sequenceState) {\n    const container = elements.sequenceProgress;\n    container.innerHTML = '';\n    \n    // Create segment boxes\n    sequenceState.segments.forEach((state, index) => {\n      const segmentBox = document.createElement('div');\n      segmentBox.className = `segment-box segment-${state}`;\n      segmentBox.textContent = index + 1;\n      \n      container.appendChild(segmentBox);\n    });\n    \n    // Update segment markers on live spectrogram\n    updateSegmentMarkers(\n      elements.liveSegmentMarkers, \n      detector.state.patterns[detector.state.activePatternIndex]\n    );\n  }\n  \n  function updatePatternDisplay(pattern) {\n    if (!pattern || !pattern.segments || pattern.segments.length === 0) {\n      elements.patternDisplay.innerHTML = '';\n      elements.recordSegmentMarkers.innerHTML = '';\n      return;\n    }\n    \n    // Create segment display\n    const container = elements.patternDisplay;\n    container.innerHTML = '';\n    \n    // Create segment divs\n    pattern.segments.forEach((segment, index) => {\n      const segmentDiv = document.createElement('div');\n      segmentDiv.className = 'pattern-segment';\n      \n      // Add label\n      const labelDiv = document.createElement('div');\n      labelDiv.className = 'pattern-segment-label';\n      labelDiv.textContent = `Segment ${index + 1}`;\n      \n      // Create canvas for segment visualization\n      const canvas = document.createElement('canvas');\n      canvas.width = container.clientWidth / pattern.segments.length;\n      canvas.height = container.clientHeight;\n      \n      segmentDiv.appendChild(labelDiv);\n      segmentDiv.appendChild(canvas);\n      container.appendChild(segmentDiv);\n      \n      // Draw segment spectrogram\n      const ctx = canvas.getContext('2d');\n      \n      // Draw as a grid of colored cells\n      const blockWidth = canvas.width / segment.spectrogram.length;\n      const blockHeight = canvas.height / segment.spectrogram[0].length;\n      \n      for (let i = 0; i < segment.spectrogram.length; i++) {\n        for (let j = 0; j < segment.spectrogram[i].length; j++) {\n          const value = segment.spectrogram[i][j];\n          const hue = 240 * (1 - value);\n          ctx.fillStyle = `hsl(${hue}, 100%, 50%)`;\n          ctx.fillRect(\n            i * blockWidth, \n            canvas.height - (j + 1) * blockHeight,\n            blockWidth,\n            blockHeight\n          );\n        }\n      }\n    });\n    \n    // Update segment markers\n    updateSegmentMarkers(elements.recordSegmentMarkers, pattern);\n  }\n  \n  function updateSegmentMarkers(container, pattern) {\n    if (!pattern || !pattern.boundaries) {\n      container.innerHTML = '';\n      return;\n    }\n    \n    container.innerHTML = '';\n    \n    // Create markers\n    pattern.boundaries.forEach(boundary => {\n      // Start marker\n      const startMarker = document.createElement('div');\n      startMarker.className = 'segment-marker';\n      startMarker.style.left = `${boundary.start * 100}%`;\n      container.appendChild(startMarker);\n      \n      // Label\n      const label = document.createElement('div');\n      label.className = 'segment-label';"
          }
        ],
        "files": [
          {
            "file_name": "paste.txt"
          }
        ]
      }
    },
    {
      "id": "4551ade4-6df9-422a-9091-5335b192c3fc",
      "role": "assistant",
      "content": " Looking at the code, I understand you're working with an audio chant detector that uses spectrograms and pattern matching to recognize repeated sound patterns. The issue you're facing is that it's not properly recognizing the final segment in a sequence, regardless of how many segments are configured (3, 4, or 5).\n\nAfter reviewing the code, I think the problem lies in the rolling window implementation for pattern matching. The detector might be struggling to match the last segment because:\n\n1. The sliding window approach might not be giving enough context for the final segment\n2. There could be issues with timing and segment boundaries\n3. The cooldown period might be triggering before complete recognition\n\nLet me finish the truncated segment marker code and then suggest a solution for your main issue:\n\n```javascript\n// Label\nconst label = document.createElement('div');\nlabel.className = 'segment-label';\nlabel.textContent = `${boundary.index + 1}`;\nlabel.style.left = `${((boundary.start + boundary.end) / 2) * 100}%`;\ncontainer.appendChild(label);\n\n// End marker (except for the last boundary which is the end)\nif (boundary.index < pattern.boundaries.length - 1) {\n  const endMarker = document.createElement('div');\n  endMarker.className = 'segment-marker';\n  endMarker.style.left = `${boundary.end * 100}%`;\n  container.appendChild(endMarker);\n}\n```\n\nNow, to address the main issue with final segment detection, I recommend modifying the detection algorithm with these changes:\n\n1. Add padding to the detection window for better end segment recognition:\n\n```javascript\nflexibleSequentialDetection(pattern) {\n  // Existing code...\n  \n  // Add padding for final segment detection\n  if (updatedCurrentIndex === pattern.segments.length - 1) {\n    // Reduce threshold for final segment slightly\n    const finalSegmentThreshold = this.config.minMatchThreshold * 0.9;\n    if (matchScores[updatedCurrentIndex] >= finalSegmentThreshold) {\n      // Reduce the required time to match the final segment\n      const finalSegmentTime = Math.max(\n        150,  // Even shorter minimum time for final segment\n        (currentSegment.frameCount / pattern.rawData.energy.length) * pattern.rawData.duration * 0.3\n      );\n      \n      // Log this special handling\n      this.log('info', `Final segment matching with adjusted threshold: ${finalSegmentThreshold.toFixed(2)}`);\n      \n      // Add timing to debug info\n      debugInfo.finalSegmentHandling = true;\n      debugInfo.finalSegmentThreshold = finalSegmentThreshold;\n    }\n  }\n  \n  // Rest of existing code...\n}\n```\n\n2. Improve the sliding window matching logic to be more forgiving at boundaries:\n\n```javascript\ncalculateSegmentMatch(audioData, segment) {\n  // Existing code...\n  \n  // For final segment, add additional padding\n  const isFinalSegment = segment.index === detector.config.segmentCount - 1;\n  const extraPadding = isFinalSegment ? 5 : 0;\n  \n  for (let i = 0; i <= energy.length - windowSize + extraPadding; i++) {\n    // Calculate match with possibly overlapping end\n    const actualWindowSize = Math.min(windowSize, energy.length - i);\n    const windowEnergy = energy.slice(i, i + actualWindowSize);\n    \n    // Rest of matching logic...\n    \n    // Give a small boost to final segment matches\n    if (isFinalSegment) {\n      score *= 1.1; // 10% boost\n    }\n    \n    bestMatch = Math.max(bestMatch, score);\n  }\n  \n  return bestMatch;\n}\n```\n\n3. Add an explicit check for completion when close to the end:\n\n```javascript\n// Add to strict/flexible detection methods\nif (updatedCurrentIndex === pattern.segments.length - 1 && \n    sequenceState.progress > 0.85 &&\n    matchScores[updatedCurrentIndex] >= this.config.minMatchThreshold * 0.85) {\n  \n  // If we're on the last segment and overall progress is high, consider completion\n  this.log('info', 'Final segment nearly complete, triggering pattern completion');\n  \n  return {\n    patternDetected: true,\n    confidence: this.calculateOverallConfidence() * 0.95, // Slightly reduced confidence\n    debugInfo: {\n      ...debugInfo,\n      completedWithAssistance: true\n    }\n  };\n}\n```\n\nThese changes should help ensure the detector recognizes the final segment by:\n1. Being more lenient with the matching threshold for the final segment\n2. Adding padding to the window specifically for the final segment\n3. Adding a fallback completion trigger when close to finishing the pattern\n\nWould you like me to provide a more comprehensive fix or explain any part of this in more detail?",
      "created_at": "2025-03-17T16:40:57.413844Z",
      "sequence_order": 1,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-03-17T16:40:36.300602Z",
            "stop_timestamp": "2025-03-17T16:40:55.353364Z",
            "flags": null,
            "type": "text",
            "text": " Looking at the code, I understand you're working with an audio chant detector that uses spectrograms and pattern matching to recognize repeated sound patterns. The issue you're facing is that it's not properly recognizing the final segment in a sequence, regardless of how many segments are configured (3, 4, or 5).\n\nAfter reviewing the code, I think the problem lies in the rolling window implementation for pattern matching. The detector might be struggling to match the last segment because:\n\n1. The sliding window approach might not be giving enough context for the final segment\n2. There could be issues with timing and segment boundaries\n3. The cooldown period might be triggering before complete recognition\n\nLet me finish the truncated segment marker code and then suggest a solution for your main issue:\n\n```javascript\n// Label\nconst label = document.createElement('div');\nlabel.className = 'segment-label';\nlabel.textContent = `${boundary.index + 1}`;\nlabel.style.left = `${((boundary.start + boundary.end) / 2) * 100}%`;\ncontainer.appendChild(label);\n\n// End marker (except for the last boundary which is the end)\nif (boundary.index < pattern.boundaries.length - 1) {\n  const endMarker = document.createElement('div');\n  endMarker.className = 'segment-marker';\n  endMarker.style.left = `${boundary.end * 100}%`;\n  container.appendChild(endMarker);\n}\n```\n\nNow, to address the main issue with final segment detection, I recommend modifying the detection algorithm with these changes:\n\n1. Add padding to the detection window for better end segment recognition:\n\n```javascript\nflexibleSequentialDetection(pattern) {\n  // Existing code...\n  \n  // Add padding for final segment detection\n  if (updatedCurrentIndex === pattern.segments.length - 1) {\n    // Reduce threshold for final segment slightly\n    const finalSegmentThreshold = this.config.minMatchThreshold * 0.9;\n    if (matchScores[updatedCurrentIndex] >= finalSegmentThreshold) {\n      // Reduce the required time to match the final segment\n      const finalSegmentTime = Math.max(\n        150,  // Even shorter minimum time for final segment\n        (currentSegment.frameCount / pattern.rawData.energy.length) * pattern.rawData.duration * 0.3\n      );\n      \n      // Log this special handling\n      this.log('info', `Final segment matching with adjusted threshold: ${finalSegmentThreshold.toFixed(2)}`);\n      \n      // Add timing to debug info\n      debugInfo.finalSegmentHandling = true;\n      debugInfo.finalSegmentThreshold = finalSegmentThreshold;\n    }\n  }\n  \n  // Rest of existing code...\n}\n```\n\n2. Improve the sliding window matching logic to be more forgiving at boundaries:\n\n```javascript\ncalculateSegmentMatch(audioData, segment) {\n  // Existing code...\n  \n  // For final segment, add additional padding\n  const isFinalSegment = segment.index === detector.config.segmentCount - 1;\n  const extraPadding = isFinalSegment ? 5 : 0;\n  \n  for (let i = 0; i <= energy.length - windowSize + extraPadding; i++) {\n    // Calculate match with possibly overlapping end\n    const actualWindowSize = Math.min(windowSize, energy.length - i);\n    const windowEnergy = energy.slice(i, i + actualWindowSize);\n    \n    // Rest of matching logic...\n    \n    // Give a small boost to final segment matches\n    if (isFinalSegment) {\n      score *= 1.1; // 10% boost\n    }\n    \n    bestMatch = Math.max(bestMatch, score);\n  }\n  \n  return bestMatch;\n}\n```\n\n3. Add an explicit check for completion when close to the end:\n\n```javascript\n// Add to strict/flexible detection methods\nif (updatedCurrentIndex === pattern.segments.length - 1 && \n    sequenceState.progress > 0.85 &&\n    matchScores[updatedCurrentIndex] >= this.config.minMatchThreshold * 0.85) {\n  \n  // If we're on the last segment and overall progress is high, consider completion\n  this.log('info', 'Final segment nearly complete, triggering pattern completion');\n  \n  return {\n    patternDetected: true,\n    confidence: this.calculateOverallConfidence() * 0.95, // Slightly reduced confidence\n    debugInfo: {\n      ...debugInfo,\n      completedWithAssistance: true\n    }\n  };\n}\n```\n\nThese changes should help ensure the detector recognizes the final segment by:\n1. Being more lenient with the matching threshold for the final segment\n2. Adding padding to the window specifically for the final segment\n3. Adding a fallback completion trigger when close to finishing the pattern\n\nWould you like me to provide a more comprehensive fix or explain any part of this in more detail?",
            "citations": []
          }
        ],
        "updated_at": "2025-03-17T16:40:57.413844Z",
        "attachments": [],
        "files": []
      }
    }
  ]
}