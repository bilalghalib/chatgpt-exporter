{
  "id": "7411ab55-56b4-4178-b840-234baabaf08f",
  "source": "chatgpt",
  "title": "\"Relevancy Score Validation Code\"",
  "created_at": "2023-05-13T12:02:31.911367",
  "updated_at": "2023-05-14T03:59:52",
  "summary": null,
  "message_count": 66,
  "messages": [
    {
      "id": "aaa2283c-1ef6-41c6-9ebf-58c096ea5dcb",
      "role": "user",
      "content": "Can you modify this code so that after it asks the first prompt, it will then send another prompt that says: \"please respond with a number from 0 to 100 only\"\nAnd if it doesn't after 3 times it should return the relevancy as 0\n\n    def calculate_relevancy(self, chat_context: str) -> int:\n        print(\"Calculating relevancy...\")\n        prompt = f\"Return the result as a number. How relevant, from 0-100 is this context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n\n        max_attempts = 3\n        attempt = 1\n        relevancy_score = None\n\n        while attempt <= max_attempts:\n            try:\n                response = openai.Completion.create(\n                    engine=\"text-curie-001\",\n                    max_tokens=150,\n                    temperature=0.0,\n                    n=1,\n                    stop=None\n                    )\n\n                completions = response.choices[0].text.strip().split(\"\\n\")\n                relevancy_score = int(completions[-1].strip())\n                break  # Break out of the loop if a valid relevancy score is obtained\n\n            except (ValueError, KeyError):\n                print(\"Invalid response received. Please enter a valid number.\")\n\n            attempt += 1\n\n        if relevancy_score is None:\n            print(\"Maximum number of attempts reached. Unable to retrieve a valid relevancy score.\")\n\n        else:\n            print(f\"Relevancy score for {self.name}: {relevancy_score}%\")\n\n        return relevancy_score",
      "created_at": "2023-05-13T12:02:31.913271",
      "sequence_order": 0,
      "parent_id": "dcb0ab3e-12e1-4967-8db9-9573d02cd244",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "33455b5b-e4a7-4a65-854d-410848a13472",
      "role": "assistant",
      "content": "Sure, I'll modify the code as per your request. The main changes include adding a check to verify that the relevancy score is between 0 and 100, and returning 0 if the maximum number of attempts is reached without a valid score.\n\nHere is the updated code:\n\n```python\ndef calculate_relevancy(self, chat_context: str) -> int:\n    print(\"Calculating relevancy...\")\n    prompt = f\"Return the result as a number. How relevant, from 0-100 is this context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n\n    max_attempts = 3\n    attempt = 1\n    relevancy_score = None\n\n    while attempt <= max_attempts:\n        try:\n            response = openai.Completion.create(\n                engine=\"text-curie-001\",\n                prompt=prompt,\n                max_tokens=150,\n                temperature=0.0,\n                n=1,\n                stop=None\n                )\n\n            completions = response.choices[0].text.strip().split(\"\\n\")\n            score = int(completions[-1].strip())\n\n            if 0 <= score <= 100:  # Check if score is within valid range\n                relevancy_score = score\n                break  # Break out of the loop if a valid relevancy score is obtained\n\n            else:\n                print(\"Invalid response received. Please enter a number from 0 to 100.\")\n\n        except (ValueError, KeyError):\n            print(\"Invalid response received. Please enter a valid number.\")\n\n        attempt += 1\n\n    if relevancy_score is None:\n        print(\"Maximum number of attempts reached. Unable to retrieve a valid relevancy score.\")\n        relevancy_score = 0  # Return 0 if no valid score obtained after max attempts\n\n    else:\n        print(f\"Relevancy score for {self.name}: {relevancy_score}%\")\n\n    return relevancy_score\n```\n\nPlease note that I've added the `prompt` parameter to the `openai.Completion.create()` method call, as I assume this is what you intended. This is because the original code did not use the `prompt` variable at all. The new code now prompts the user for input and checks the response for validity.",
      "created_at": "2023-05-13T12:03:23.084901",
      "sequence_order": 1,
      "parent_id": "aaa2283c-1ef6-41c6-9ebf-58c096ea5dcb",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa28505-5138-4205-b4ff-16f67d53af53",
      "role": "user",
      "content": "can you make the code more recursive and small and cute and pythonic?def calculate_relevancy(self, chat_context: str) -> int:\n    print(\"Calculating relevancy...\")\n    prompt = f\"Return the result as a number. How relevant, from 0-100 is this context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n\n    max_attempts = 3\n    attempt = 1\n    relevancy_score = None\n\n    while attempt <= max_attempts:\n        try:\n            response = openai.Completion.create(\n                engine=\"text-curie-001\",\n                prompt=prompt,\n                max_tokens=150,\n                temperature=0.0,\n                n=1,\n                stop=None\n                )\n\n            completions = response.choices[0].text.strip().split(\"\\n\")\n            score = int(completions[-1].strip())\n\n            if 0 <= score <= 100:  # Check if score is within valid range\n                relevancy_score = score\n                break  # Break out of the loop if a valid relevancy score is obtained\n\n            else:\n                print(\"Invalid response received. Please enter a number from 0 to 100.\")\n\n        except (ValueError, KeyError):\n            print(\"Invalid response received. Please enter a valid number.\")\n\n        attempt += 1\n\n    if relevancy_score is None:\n        print(\"Maximum number of attempts reached. Unable to retrieve a valid relevancy score.\")\n        relevancy_score = 0  # Return 0 if no valid score obtained after max attempts\n\n    else:\n        print(f\"Relevancy score for {self.name}: {relevancy_score}%\")\n\n    return relevancy_score\n",
      "created_at": "2023-05-13T12:04:12.688096",
      "sequence_order": 2,
      "parent_id": "33455b5b-e4a7-4a65-854d-410848a13472",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "31aec380-4e21-45f7-a430-854a2def9b93",
      "role": "assistant",
      "content": "In order to make the code more Pythonic and recursive, you could refactor the code so that the `calculate_relevancy` function calls itself recursively when an invalid response is received. This eliminates the need for the while loop and the `attempt` variable. I also created a helper function `_get_score()` to handle the OpenAI call and the score processing:\n\n```python\ndef calculate_relevancy(self, chat_context: str, attempts: int = 3) -> int:\n    print(\"Calculating relevancy...\")\n    prompt = f\"Return the result as a number. How relevant, from 0-100 is this context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n\n    def _get_score():\n        try:\n            response = openai.Completion.create(\n                engine=\"text-curie-001\",\n                prompt=prompt,\n                max_tokens=150,\n                temperature=0.0,\n                n=1,\n                stop=None\n            )\n            return int(response.choices[0].text.strip().split(\"\\n\")[-1].strip())\n        except (ValueError, KeyError):\n            print(\"Invalid response received. Please enter a valid number.\")\n            return None\n\n    relevancy_score = _get_score()\n\n    if relevancy_score is None or not 0 <= relevancy_score <= 100:\n        if attempts > 1:\n            print(\"Please enter a number from 0 to 100.\")\n            return self.calculate_relevancy(chat_context, attempts - 1)\n        else:\n            print(\"Maximum number of attempts reached. Unable to retrieve a valid relevancy score.\")\n            return 0\n\n    print(f\"Relevancy score for {self.name}: {relevancy_score}%\")\n    return relevancy_score\n```\n\nPlease note that recursion is not always a recommended approach in Python due to the risk of reaching the maximum recursion depth, especially in situations where the number of recursive calls could potentially be very large. In this case, however, the number of recursive calls is limited to 3, so it should not pose a problem.",
      "created_at": "2023-05-13T12:04:59.406862",
      "sequence_order": 3,
      "parent_id": "aaa28505-5138-4205-b4ff-16f67d53af53",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2c09e-6b9f-4f66-a306-a1db3c54be8a",
      "role": "user",
      "content": "why does the code keep calculating relevancy over and over after a single message from the user? come up with 3 reasons and pick the most likely to fix:\nparliament.py\nimport asyncio\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\n\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.speaking_pressure = speaking_pressure_increment\n        self.tagged = False\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.is_speaking = False\n    def calculate_relevancy(self, chat_context: str) -> int:\n        print(\"Calculating relevancy...\")\n        prompt = f\"Return the result as a number. How relevant, from 0-100 is this context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n\n        max_attempts = 3\n        attempt = 1\n        relevancy_score = None\n\n        while attempt <= max_attempts:\n            try:\n                response = openai.Completion.create(\n                    engine=\"text-curie-001\",\n                    prompt=prompt,\n                    max_tokens=150,\n                    temperature=0.0,\n                    n=1,\n                    stop=None\n                    )\n\n                completions = response.choices[0].text.strip().split(\"\\n\")\n                score = int(completions[-1].strip())\n\n                if 0 <= score <= 100:  # Check if score is within valid range\n                    relevancy_score = score\n                    break  # Break out of the loop if a valid relevancy score is obtained\n\n                else:\n                    print(\"Invalid response received. Please enter a number from 0 to 100.\")\n\n            except (ValueError, KeyError):\n                print(\"Invalid response received. Please enter a valid number.\")\n\n            attempt += 1\n\n        if relevancy_score is None:\n            print(\"Maximum number of attempts reached. Unable to retrieve a valid relevancy score.\")\n            relevancy_score = 0  # Return 0 if no valid score obtained after max attempts\n\n        else:\n            print(f\"Relevancy score for {self.name}: {relevancy_score}%\")\n\n        return relevancy_score\n\n\n    def should_speak(self):\n        return self.parliament.speaker_manager.should_speak(self)  # Call parliament's speaker_manager\n\n    async def try_to_speak(self):\n        if self.should_speak() and not self.is_speaking:\n            await self.speak()\n\n    async def increment_pressure(self):\n        while True:\n            await asyncio.sleep(PRESSURE_INCREMENT_INTERVAL)\n            self.speaking_pressure += self.speaking_pressure_increment\n            await self.try_to_speak()\n\n    def get_agent_message(self, chat_history):\n        \"\"\"\n        Generate a message from this agent based on the current chat history.\n        \"\"\"\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = self.agent_instance.get_response(chat_history)\n            message = f\"{response}\"\n        return message\n    \n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue.queue\n    \n    async def speak(self):\n        self.is_speaking = True\n        await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n        agent_message = self.get_agent_message(self.parliament.chat_history)\n        await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n        self.speaking_pressure = 0\n        self.is_speaking = False\n        if self.in_queue():\n            self.parliament.speaking_queue.remove(self.name)\n\n    def reset_pressure(self):\n        self.speaking_pressure = 0\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = [] \n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history() \n\n    def truncate_chat_history(self, max_length=2000):\n        \"\"\"\n        Truncate the chat history to the last max_length characters.\n        \"\"\"\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def last_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakingQueue:\n    def __init__(self):\n        self.queue = deque()\n\n    def add(self, agent_name):\n        self.queue.append(agent_name)\n\n    def pop(self):\n        if len(self.queue) > 0:\n            return self.queue.pop()\n        else:\n            return None\n        \n    def enqueue(self, name):\n        self.queue.append(name)\n\n    def dequeue(self):\n        return self.queue.popleft() if self.queue else None\n\n    def front(self):\n        return self.queue[0] if self.queue else None\n\n    def remove(self, name):\n        self.queue.remove(name)\n\n    def contains(self, name):\n        return name in self.queue\n\n    def to_json(self):\n        return list(self.queue)\n    \nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue.front() == agent.name\n\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, chat_history):\n        system_msg = self.initial_context\n\n        messages = [{\"role\": \"system\", \"content\": system_msg}]\n        for message in chat_history.chat_history:\n            role = message[\"sender\"]\n            msg = message[\"message\"]\n            messages.append({\"role\": \"assistant\" if role != \"assistant\" else role, \"content\": msg})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n\n\nclass GPT4AllAgent:\n    def __init__(self):\n        # Download and set up the GPT4All model\n        self._initialize_gpt4all_model()\n        self._initialize_llm_chain()\n\n    def _initialize_gpt4all_model(self):\n        local_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n\n        url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n        response = requests.get(url, stream=True)\n\n        with open(local_path, 'wb') as f:\n            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n                if chunk:\n                    f.write(chunk)\n\n        self.model_path = local_path\n\n    def _initialize_llm_chain(self):\n        template = \"\"\"{chat_history}\n\n        Question: {question}\n\n        Answer: Let's think step by step.\"\"\"\n        prompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\n\n        callbacks = [StreamingStdOutCallbackHandler()]\n        llm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\n        self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n\n    def get_response(self, chat_history, question):\n        return self.llm_chain.run(chat_history=chat_history, question=question)\n\n\n\n\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = SpeakingQueue()\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {} \n\n    def set_typing_status(self, agent_name: str, status: bool):\n        self.typing_status[agent_name] = status\n\n    def get_typing_status(self, agent_name: str):\n        return self.typing_status.get(agent_name, False)\n\n    async def broadcast_message(self, message, sender, timestamp):\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n        self.update_speaking_queue()\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):\n                await agent.try_to_speak()\n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        first_agent_in_queue = self.speaking_queue.dequeue()\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n    def add_to_speaking_queue(self, agent):\n        if not self.speaking_queue.contains(agent.name):\n            self.speaking_queue.enqueue(agent.name)\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n    \n    def get_speaking_queue(self):\n        return self.speaking_queue\n            \n    def add_agent(self, agent: Agent):\n        self.agents[agent.name] = agent\n        self.typing_status[agent.name] = False  # Initialize typing status when adding an agent\n        asyncio.create_task(agent.increment_pressure())        \n\n    def remove_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        del self.agents[agent_name]\n\n    def get_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        return self.agents[agent_name]\n\n    def add_to_chat_history(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = 100\n                self.agents[agent_name].tagged = True\n                print(f\"Tagged agent: {agent_name}\")  # Debug print\n        return mentioned_agents\n\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def add_tagged_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.tagged and agent.name not in self.speaking_queue.queue:    \n                self.speaking_queue.add(agent.name)\n                agent.tagged = False\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def add_high_pressure_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n                self.speaking_queue.add(agent.name)\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def trigger_next_speaker(self):\n        if self.speaking_queue:\n            next_speaker = self.get_agent(self.speaking_queue.pop())  # Remove the agent from the queue\n\n    def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n        most_relevant_agent = None\n        highest_relevancy_score = -1\n        for agent in self.agents.values():\n            chat_context = self.chat_history.truncated_chat_history\n            relevancy_score = agent.calculate_relevancy(chat_context)\n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n            \n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent:\n            self.speaking_queue.enqueue(most_relevant_agent.name)\n            \n        sorted_agents = self.get_sorted_agents_based_on_relevancy()\n        for agent in sorted_agents[:3]: # Add the N most relevant agents \n            self.speaking_queue.add(agent.name)\n        \n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n        \n        for agent in self.agents.values():\n            if agent.tagged and not agent.is_speaking:\n                self.add_to_speaking_queue(agent)\n                agent.tagged = False\n                agent.speaking_pressure = 0 # Reset speaking pressure\n            \n        self.trigger_next_speaker()  \n\n\n    def get_sorted_agents_based_on_relevancy(self):\n        return sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history) if agent.calculate_relevancy(self.chat_history) is not None else 0, reverse=True)\n\n\n    def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent_name, agent in self.agents.items():\n            agents_info.append({\n                \"name\": agent_name,\n                \"speaking_pressure\": agent.speaking_pressure,\n                \"speaking_pressure_increment\": agent.speaking_pressure_increment,\n                \"context\": agent.context,\n                \"agent_type\": agent.agent_type,\n                \"relevancy\": agent.calculate_relevancy(self.chat_history)\n            })\n        return agents_info",
      "created_at": "2023-05-13T12:06:20.895203",
      "sequence_order": 4,
      "parent_id": "31aec380-4e21-45f7-a430-854a2def9b93",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "90b8781f-96d9-4e33-8e94-24a13e65cf19",
      "role": "assistant",
      "content": "The code calculates relevancy multiple times after a single message from the user because:\n\n1. **Relevancy Calculation in `update_speaking_queue` method**: In the `update_speaking_queue` method of the `Parliament` class, the relevancy of the conversation context for each agent is calculated in order to determine the most relevant agent. This calculation is performed each time the speaking queue is updated, which seems to occur after each message from the user. \n\n2. **Relevancy Calculation in `get_sorted_agents_based_on_relevancy` method**: The `get_sorted_agents_based_on_relevancy` method of the `Parliament` class also calculates the relevancy of the conversation context for each agent. This method sorts the agents based on their relevancy scores.\n\n3. **Relevancy Calculation in `should_speak` method**: Although not directly present in the code you shared, the `should_speak` method (which is called inside `try_to_speak` method of the `Agent` class) might also contain relevancy calculation. This method seems to decide whether an agent should speak or not, and it's logical to assume that this decision could be based on relevancy score.\n\nThe most likely fix to avoid unnecessary computation is to introduce a caching mechanism for the relevancy calculation. In other words, once the relevancy is calculated for a specific conversation context, it should be stored and reused instead of being recalculated. This can be achieved by adding a `relevancy_score` attribute to the `Agent` class and updating it only when necessary, i.e., when the conversation context changes.\n\nHere's a simplified implementation:\n\n```python\nclass Agent:\n    def __init__(self, ...):\n        ...\n        self.relevancy_score = None\n\n    def calculate_relevancy(self, chat_context: str) -> int:\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            # existing implementation...\n            self.initial_context = chat_context\n            self.relevancy_score = relevancy_score\n        else:\n            print(\"Using cached relevancy score...\")\n        return self.relevancy_score\n```\n\nIn this implementation, the `calculate_relevancy` method first checks if the `relevancy_score` attribute is `None` or if the `initial_context` has changed. If either condition is true, it calculates the relevancy as before and updates `initial_context` and `relevancy_score`. If not, it simply returns the cached `relevancy_score`. This approach ensures that the relevancy is recalculated only when necessary, thus saving computational resources.\n",
      "created_at": "2023-05-13T12:07:27.998084",
      "sequence_order": 5,
      "parent_id": "aaa2c09e-6b9f-4f66-a306-a1db3c54be8a",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2d9c5-ef26-49c5-845a-4fd47ea27e93",
      "role": "user",
      "content": "is this the correct implementation?\n\n    def calculate_relevancy(self, chat_context: str) -> int:\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"Return the result as a number. How relevant, from 0-100 is this context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n\n            max_attempts = 3\n            attempt = 1\n            relevancy_score = None\n\n            while attempt <= max_attempts:\n                try:\n                    response = openai.Completion.create(\n                        engine=\"text-curie-001\",\n                        prompt=prompt,\n                        max_tokens=150,\n                        temperature=0.0,\n                        n=1,\n                        stop=None\n                        )\n\n                    completions = response.choices[0].text.strip().split(\"\\n\")\n                    score = int(completions[-1].strip())\n\n                    if 0 <= score <= 100:  # Check if score is within valid range\n                        relevancy_score = score\n                        break  # Break out of the loop if a valid relevancy score is obtained\n\n                    else:\n                        print(\"Invalid response received. Please enter a number from 0 to 100.\")\n\n                except (ValueError, KeyError):\n                    print(\"Invalid response received. Please enter a valid number.\")\n\n                attempt += 1\n            self.initial_context = chat_context\n            self.relevancy_score = relevancy_score\n        else:\n            print(\"Using cached relevancy score...\")\n\n        if relevancy_score is None:\n            print(\"Maximum number of attempts reached. Unable to retrieve a valid relevancy score.\")\n            relevancy_score = 0  # Return 0 if no valid score obtained after max attempts\n\n        else:\n            print(f\"Relevancy score for {self.name}: {relevancy_score}%\")\n            \n        return self.relevancy_score",
      "created_at": "2023-05-13T12:10:36.271536",
      "sequence_order": 6,
      "parent_id": "90b8781f-96d9-4e33-8e94-24a13e65cf19",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "df17217e-93db-4476-8d5f-028d8677df6e",
      "role": "assistant",
      "content": "The code you posted should work fine for the task you described. Here's a brief overview of what your function does:\n\n1. It calculates the relevancy score of a chat context, using OpenAI's GPT model to generate a score.\n2. The chat context is passed as a parameter to the function.\n3. The relevancy score is calculated only if it has not been previously calculated, or if the chat context has changed.\n4. The relevancy score is generated by the GPT model using a fixed prompt, and it is expected to be a number between 0 and 100.\n5. The function attempts to generate a relevancy score up to a maximum of three times, in case the GPT model returns an invalid score.\n6. The generated relevancy score is stored and returned by the function.\n\nHowever, it seems like there's a minor mistake in the code. In the last few lines, you're checking if the local variable `relevancy_score` is `None` but you should be checking the instance variable `self.relevancy_score` instead, as the local variable `relevancy_score` goes out of scope after the while loop. Here's the corrected section:\n\n```python\nif self.relevancy_score is None:\n    print(\"Maximum number of attempts reached. Unable to retrieve a valid relevancy score.\")\n    self.relevancy_score = 0  # Return 0 if no valid score obtained after max attempts\n\nelse:\n    print(f\"Relevancy score for {self.name}: {self.relevancy_score}%\")\n            \nreturn self.relevancy_score\n```\n\nThis corrected code will ensure that the instance variable `self.relevancy_score` is correctly updated and returned by the function. The local variable `relevancy_score` is not necessary here.",
      "created_at": "2023-05-13T12:11:11.327040",
      "sequence_order": 7,
      "parent_id": "aaa2d9c5-ef26-49c5-845a-4fd47ea27e93",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2e2c0-1b88-4159-a537-b25be54e1183",
      "role": "user",
      "content": "Getting this error:\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 37, in chat\n    await self.handle_send_message(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 75, in handle_send_message\n    await self.parliament.broadcast_message(user_message, sender, timestamp)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 275, in broadcast_message\n    self.update_speaking_queue()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 367, in update_speaking_queue\n    relevancy_score = agent.calculate_relevancy(chat_context)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 70, in calculate_relevancy\n    return min(self.relevancy_score, 100) # Cap maximum score at 100\nTypeError: '<' not supported between instances of 'int' and 'NoneType'\n\n\n    def calculate_relevancy(self, chat_context: str) -> int:\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"Return the result as a number. How relevant, from 0-100 is this context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n\n            max_attempts = 3\n            attempt = 1\n            relevancy_score = None\n\n            while attempt <= max_attempts:\n                try:\n                    response = openai.Completion.create(\n                        engine=\"text-curie-001\",\n                        prompt=prompt,\n                        max_tokens=150,\n                        temperature=0.0,\n                        n=1,\n                        stop=None\n                        )\n\n                    completions = response.choices[0].text.strip().split(\"\\n\")\n                    score = int(completions[-1].strip())\n\n                    if 0 <= score <= 100:  # Check if score is within valid range\n                        relevancy_score = score\n                        break  # Break out of the loop if a valid relevancy score is obtained\n\n                    else:\n                        print(\"Invalid response received. Please enter a number from 0 to 100.\")\n\n                except (ValueError, KeyError):\n                    print(\"Invalid response received. Please enter a valid number.\")\n\n                attempt += 1\n            self.initial_context = chat_context\n            self.relevancy_score = relevancy_score\n            print(f\"Relevancy score for {self.name}: {self.relevancy_score}%\")\n        else:\n            print(\"Using cached relevancy score...\")\n        return min(self.relevancy_score, 100) # Cap maximum score at 100\n    \n",
      "created_at": "2023-05-13T12:27:08.736529",
      "sequence_order": 8,
      "parent_id": "df17217e-93db-4476-8d5f-028d8677df6e",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "7e22ed69-f978-4d7b-85ce-db7192ec8764",
      "role": "assistant",
      "content": "The issue seems to be that `self.relevancy_score` can be `None` at the time `min(self.relevancy_score, 100)` is called. This happens when the maximum number of attempts is reached without a valid relevancy score.\n\nYou can handle this by first checking if `self.relevancy_score` is `None`, and if so, returning a default score (for example, 0) or throwing an exception. Here's the adjusted code:\n\n```python\ndef calculate_relevancy(self, chat_context: str) -> int:\n    if self.relevancy_score is None or self.initial_context != chat_context:\n        print(\"Calculating relevancy...\")\n        prompt = f\"Return the result as a number. How relevant, from 0-100 is this context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n\n        max_attempts = 3\n        attempt = 1\n        relevancy_score = None\n\n        while attempt <= max_attempts:\n            try:\n                response = openai.Completion.create(\n                    engine=\"text-curie-001\",\n                    prompt=prompt,\n                    max_tokens=150,\n                    temperature=0.0,\n                    n=1,\n                    stop=None\n                    )\n\n                completions = response.choices[0].text.strip().split(\"\\n\")\n                score = int(completions[-1].strip())\n\n                if 0 <= score <= 100:  # Check if score is within valid range\n                    relevancy_score = score\n                    break  # Break out of the loop if a valid relevancy score is obtained\n\n                else:\n                    print(\"Invalid response received. Please enter a number from 0 to 100.\")\n\n            except (ValueError, KeyError):\n                print(\"Invalid response received. Please enter a valid number.\")\n\n            attempt += 1\n        self.initial_context = chat_context\n        self.relevancy_score = relevancy_score\n        print(f\"Relevancy score for {self.name}: {self.relevancy_score}%\")\n    else:\n        print(\"Using cached relevancy score...\")\n\n    if self.relevancy_score is None:\n        print(\"Maximum number of attempts reached. Unable to retrieve a valid relevancy score.\")\n        return 0  # default score if no valid score obtained after max attempts\n\n    return min(self.relevancy_score, 100)  # Cap maximum score at 100\n```\n\nThis code checks if `self.relevancy_score` is `None` before attempting to compare it with 100. If `self.relevancy_score` is `None`, the function returns a default score of 0. Otherwise, it returns the minimum of `self.relevancy_score` and 100.",
      "created_at": "2023-05-13T12:28:07.271685",
      "sequence_order": 9,
      "parent_id": "aaa2e2c0-1b88-4159-a537-b25be54e1183",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2d028-5208-4516-95eb-0a7c8c0af466",
      "role": "user",
      "content": "do we need the try_to_speak function still? or do we have the speaking algorithm covered by having agents speak when they hit the highest relevancy and then they get pushed to the top of a queue and the one on the top speaks. We should have them speak and then everyone stops speaking unless someone else is tagged, then we wait for another user message to check relevancy again \nimport asyncio\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nclass Agent:\ndef init(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\nself.name = agent_name\nself.speaking_pressure_increment = speaking_pressure_increment\nself.context = initial_context\nself.initial_context = initial_context\nself.speaking_pressure = speaking_pressure_increment\nself.tagged = False\nself.agent_type = agent_type\nself.agent_instance = agent_instance\nself.websocket = websocket\nself.parliament = parliament\nself.is_speaking = False\nself.relevancy_score = None\nasync def update_relevancy(self):\nself.relevancy_score = self.calculate_relevancy(self.parliament.chat_history.truncated_chat_history)\nagent_info = [\n{\n\"name\": self.name,\n\"relevancy_score\": self.relevancy_score\n}\n]\nawait self.websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\nasync def calculate_relevancy(self, chat_context: str) -> int:\nif self.relevancy_score is None or self.initial_context != chat_context:\nprint(\"Calculating relevancy...\")\nprompt = f\"Return the result as a number. How relevant, from 0-100 is this context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\nmax_attempts = 3\nattempt = 1\nrelevancy_score = 0\nwhile attempt <= max_attempts:\ntry:\nresponse = openai.Completion.create(\nengine=\"text-curie-001\",\nprompt=prompt,\nmax_tokens=150,\ntemperature=0.0,\nn=1,\nstop=None\n)\ncompletions = response.choices[0].text.strip().split(\"\\n\")\nscore = int(completions[-1].strip())\nif 0 <= score <= 100: # Check if score is within valid range\nrelevancy_score = score\nbreak # Break out of the loop if a valid relevancy score is obtained\nelse:\nprint(\"Invalid response received. Please enter a number from 0 to 100.\")\nexcept (ValueError, KeyError):\nprint(\"Invalid response received. Please enter a valid number.\")\nattempt += 1\nself.initial_context = chat_context\nself.relevancy_score = relevancy_score\nprint(f\"Relevancy score for {self.name}: {self.relevancy_score}%\")\nagent_info = [\n{\n\"name\": self.name,\n\"relevancy_score\": self.relevancy_score # Return updated score here\n}\n]\nawait self.websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\nelse:\nprint(\"Using cached relevancy score...\")\nreturn min(self.relevancy_score, 100) # Cap maximum score at 100\ndef should_speak(self):\nreturn self.parliament.speaker_manager.should_speak(self) # Call parliament's speaker_manager\nasync def try_to_speak(self):\nif self.should_speak() and not self.is_speaking:\nawait self.speak()\nasync def increment_pressure(self):\nwhile True:\nawait asyncio.sleep(PRESSURE_INCREMENT_INTERVAL)\nself.speaking_pressure += self.speaking_pressure_increment\nawait self.try_to_speak()\ndef get_agent_message(self, chat_history):\n\"\"\"\nGenerate a message from this agent based on the current chat history.\n\"\"\"\nmessage = \"\"\nif isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\nresponse = self.agent_instance.get_response(chat_history)\nmessage = f\"{response}\"\nreturn message\ndef in_queue(self):\nreturn self.name in self.parliament.speaking_queue.queue\nasync def speak(self):\nself.is_speaking = True\nawait self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\nawait self.websocket.send(json.dumps({\"action\": STOPPED_TYPING, \"sender\": self.name}))\nagent_message = self.get_agent_message(self.parliament.chat_history)\nawait self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\nself.speaking_pressure = 0\nself.is_speaking = False\nif self.in_queue():\nself.parliament.speaking_queue.remove(self.name)\ndef reset_pressure(self):\nself.speaking_pressure = 0\nclass ChatHistory:\ndef init(self):\nself.chat_history = []\nself.truncated_chat_history = []\ndef add(self, message, sender, timestamp):\nself.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\nself.truncate_chat_history()\ndef truncate_chat_history(self, max_length=2000):\n\"\"\"\nTruncate the chat history to the last max_length characters.\n\"\"\"\nchat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\nself.truncated_chat_history = chat_history_str[-max_length:]\ndef last_message(self):\nreturn self.chat_history[-1] if self.chat_history else None\nclass SpeakingQueue:\ndef init(self):\nself.queue = deque()\ndef add(self, agent_name):\nself.queue.append(agent_name)\ndef pop(self):\nif len(self.queue) > 0:\nreturn self.queue.pop()\nelse:\nreturn None\ndef enqueue(self, name):\nself.queue.append(name)\ndef dequeue(self):\nreturn self.queue.popleft() if self.queue else None\ndef front(self):\nreturn self.queue[0] if self.queue else None\ndef remove(self, name):\nself.queue.remove(name)\ndef contains(self, name):\nreturn name in self.queue\ndef to_json(self):\nreturn list(self.queue)\nclass SpeakerManager:\ndef init(self, parliament):\nself.parliament = parliament\ndef should_speak(self, agent):\nreturn self.parliament.speaking_queue.front() == agent.name\nclass OpenAIAgent:\ndef init(self, initial_context: str):\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\nopenai.api_key = \"REDACTED_API_KEY\"\nself.model = \"gpt-3.5-turbo\"\nself.initial_context = initial_context\ndef get_response(self, chat_history):\nsystem_msg = self.initial_context\nmessages = [{\"role\": \"system\", \"content\": system_msg}]\nfor message in chat_history.chat_history:\nrole = message[\"sender\"]\nmsg = message[\"message\"]\nmessages.append({\"role\": \"assistant\" if role != \"assistant\" else role, \"content\": msg})\nmax_retries = 3\nretry_delay = 5\nfor i in range(max_retries):\ntry:\n# Call the OpenAI API with the messages array\nresponse = openai.ChatCompletion.create(\nmodel=self.model,\nmessages=messages,\nmax_tokens=150,\ntemperature=0.5,\ntop_p=1,\nfrequency_penalty=0,\npresence_penalty=0,\n)\n# Extract and return the assistant's response from the API response\nagent_response = response.choices[0].message[\"content\"].strip()\nprint(f\" {agent_response}\") # Add logging\nreturn agent_response\nexcept RateLimitError as e:\nprint(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\nif i < max_retries - 1: # Don't sleep on the last iteration\ntime.sleep(retry_delay)\nelse:\nraise\nreturn \"Sorry, I am unable to respond at the moment.\"\nclass GPT4AllAgent:\ndef init(self):\n# Download and set up the GPT4All model\nself._initialize_gpt4all_model()\nself._initialize_llm_chain()\ndef _initialize_gpt4all_model(self):\nlocal_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\nPath(local_path).parent.mkdir(parents=True, exist_ok=True)\nurl = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\nresponse = requests.get(url, stream=True)\nwith open(local_path, 'wb') as f:\nfor chunk in tqdm(response.iter_content(chunk_size=8192)):\nif chunk:\nf.write(chunk)\nself.model_path = local_path\ndef _initialize_llm_chain(self):\ntemplate = \"\"\"{chat_history}\nQuestion: {question}\nAnswer: Let's think step by step.\"\"\"\nprompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\ncallbacks = [StreamingStdOutCallbackHandler()]\nllm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\nself.llm_chain = LLMChain(prompt=prompt, llm=llm)\ndef get_response(self, chat_history, question):\nreturn self.llm_chain.run(chat_history=chat_history, question=question)\nclass Parliament:\ndef init(self, name: str):\nself.name = name\nself.speaker_manager = SpeakerManager(self)\nself.agents = {}\nself.chat_history = ChatHistory()\nself.speaking_queue = SpeakingQueue()\nself.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\nself.typing_status = {}\ndef set_typing_status(self, agent_name: str, status: bool):\nself.typing_status[agent_name] = status\ndef get_typing_status(self, agent_name: str):\nreturn self.typing_status.get(agent_name, False)\nasync def broadcast_message(self, message, sender, timestamp):\nself.chat_history.add(message, sender, timestamp)\nmentioned_agents = self.identify_and_tag_mentioned_agents(message)\nself.increment_speaking_pressure(mentioned_agents)\nself.update_speaking_queue()\nfor agent in self.agents.values():\nawait agent.update_relevancy()\nif not self.get_typing_status(agent.name):\nawait agent.try_to_speak()\nawait asyncio.sleep(BROADCAST_DELAY)\nfirst_agent_in_queue = self.speaking_queue.dequeue()\nif first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\nawait self.agents[first_agent_in_queue].speak()\ndef add_to_speaking_queue(self, agent):\nif not self.speaking_queue.contains(agent.name):\nself.speaking_queue.enqueue(agent.name)\ndef increment_speaking_pressure(self, mentioned_agents):\nfor agent in self.agents.values():\nif agent.name not in mentioned_agents:\nagent.speaking_pressure += agent.speaking_pressure_increment\ndef identify_and_tag_mentioned_agents(self, message):\nmentioned_agents = []\nfor agent_name in self.agents:\nif '@'+agent_name in message:\nmentioned_agents.append(agent_name)\nself.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\nself.agents[agent_name].tagged = True\nreturn mentioned_agents\ndef get_speaking_queue(self):\nreturn self.speaking_queue\ndef add_agent(self, agent: Agent):\nself.agents[agent.name] = agent\nself.typing_status[agent.name] = False # Initialize typing status when adding an agent\nasyncio.create_task(agent.increment_pressure())\ndef remove_agent(self, agent_name: str):\nif agent_name not in self.agents:\nraise ValueError(f\"Agent '{agent_name}' not found.\")\ndel self.agents[agent_name]\ndef get_agent(self, agent_name: str):\nif agent_name not in self.agents:\nraise ValueError(f\"Agent '{agent_name}' not found.\")\nreturn self.agents[agent_name]\ndef add_to_chat_history(self, message, sender, timestamp):\nself.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\ndef identify_and_tag_mentioned_agents(self, message):\nmentioned_agents = []\nfor agent_name in self.agents:\nif '@'+agent_name in message:\nmentioned_agents.append(agent_name)\nself.agents[agent_name].speaking_pressure = 100\nself.agents[agent_name].tagged = True\nprint(f\"Tagged agent: {agent_name}\") # Debug print\nreturn mentioned_agents\ndef increment_speaking_pressure(self, mentioned_agents):\nfor agent in self.agents.values():\nif agent.name not in mentioned_agents:\nagent.speaking_pressure += agent.speaking_pressure_increment\ndef add_tagged_agents_to_queue(self):\nfor agent in self.agents.values():\nif agent.tagged and agent.name not in self.speaking_queue.queue:\nself.speaking_queue.add(agent.name)\nagent.tagged = False\nagent.speaking_pressure = 0 # Reset speaking pressure\ndef add_high_pressure_agents_to_queue(self):\nfor agent in self.agents.values():\nif agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\nself.speaking_queue.add(agent.name)\nagent.speaking_pressure = 0 # Reset speaking pressure\ndef trigger_next_speaker(self):\nif self.speaking_queue:\nnext_speaker = self.get_agent(self.speaking_queue.pop()) # Remove the agent from the queue\ndef update_speaking_queue(self):\n\"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\nmost_relevant_agent = None\nhighest_relevancy_score = -1\nfor agent in self.agents.values():\nchat_context = self.chat_history.truncated_chat_history\nrelevancy_score = agent.calculate_relevancy(chat_context)\nif relevancy_score > highest_relevancy_score:\nhighest_relevancy_score = relevancy_score\nmost_relevant_agent = agent\n# Add the most relevant agent to the speaking queue\nif most_relevant_agent:\nself.speaking_queue.enqueue(most_relevant_agent.name)\nself.add_tagged_agents_to_queue()\nself.add_high_pressure_agents_to_queue()\ndef get_sorted_agents_based_on_relevancy(self):\nreturn sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history) if agent.calculate_relevancy(self.chat_history) is not None else 0, reverse=True)\ndef get_agents_info(self) -> List[dict]:\nagents_info = []\nfor agent_name, agent in self.agents.items():\nagents_info.append({\n\"name\": agent_name,\n\"speaking_pressure\": agent.speaking_pressure,\n\"speaking_pressure_increment\": agent.speaking_pressure_increment,\n\"context\": agent.context,\n\"agent_type\": agent.agent_type,\n\"relevancy_score\": agent.relevancy_score # Return the actual score here\n})\nreturn agents_info\n",
      "created_at": "2023-05-13T18:28:04.394642",
      "sequence_order": 10,
      "parent_id": "7e22ed69-f978-4d7b-85ce-db7192ec8764",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "807ceaa1-4a72-4745-ab55-d6b64febe206",
      "role": "assistant",
      "content": "Based on your description, the `try_to_speak` function may not be necessary anymore. If the system is designed so that agents speak only when they have the highest relevancy, and then are placed at the top of a queue to wait their turn to speak, it could simplify the code.\n\nThis approach implies that the agent doesn't need to attempt to speak until it's its turn according to the queue, which is managed outside of the agent itself. So it seems the `try_to_speak` functionality could be handled within the queuing mechanism or the `speak` function itself, if needed.\n\nHowever, keep in mind that removing `try_to_speak` could lead to the removal of the `increment_pressure` function as well, which in turn will make the speaking pressure related variables and methods redundant. If the speaking pressure mechanism is not required anymore, then these parts of the code could be removed or refactored.\n\nAs always, remember to thoroughly test your application after such a change to ensure that it's still behaving as expected. It would also be a good idea to consider any potential edge cases or unusual scenarios to see if the new approach handles them appropriately.",
      "created_at": "2023-05-13T18:28:34.243171",
      "sequence_order": 11,
      "parent_id": "aaa2d028-5208-4516-95eb-0a7c8c0af466",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa205fd-11d9-4966-b1d3-bfe11d905501",
      "role": "user",
      "content": "Traceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 37, in chat\n    await self.handle_send_message(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 75, in handle_send_message\n    await self.parliament.broadcast_message(user_message, sender, timestamp)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 290, in broadcast_message\n    self.update_speaking_queue()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 384, in update_speaking_queue\n    if relevancy_score > highest_relevancy_score:\nTypeError: '>' not supported between instances of 'coroutine' and 'int'\n/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py:-1: RuntimeWarning: coroutine 'Agent.calculate_relevancy' was never awaited\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\nerror from server.py:\nfrom datetime import datetime\nimport asyncio\nimport json\nfrom websockets import serve\nfrom parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent\nimport openai\n\n# Constants\nSET_PARLIAMENT = \"set_parliament\"\nSEND_MESSAGE = \"send_message\"\nADD_AGENTS = \"add_agents\"\nUPDATE_QUEUE = \"update_queue\"\nUPDATE_AGENTS = \"update_agents\"\nRECEIVE_MESSAGE = \"receive_message\"\nERROR = \"error\"\nTYPING = \"typing\"\nSTOPPED_TYPING = \"stopped_typing\"\n\nclass ParliamentServer:\n    def __init__(self, host=\"localhost\", port=8080):\n        self.host = host\n        self.port = port\n        self.parliament = None\n        self.start_server = serve(self.chat, self.host, self.port)\n\n    def configure_openai(self):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n\n    async def chat(self, websocket, path):\n        async for message in websocket:\n            data = json.loads(message)\n            action = data.get(\"action\")\n            if action == SET_PARLIAMENT:\n                await self.handle_set_parliament(websocket, data)\n            elif action == SEND_MESSAGE:\n                await self.handle_send_message(websocket, data)\n            elif action == ADD_AGENTS:\n                await self.handle_add_agents(websocket, data)\n            elif action in [TYPING, STOPPED_TYPING]:  \n                await self.handle_typing(websocket, data)\n\n    async def handle_typing(self, websocket, data):\n        sender = data.get('sender')\n        action = data.get('action')\n        is_typing = action == TYPING\n\n        self.parliament.set_typing_status(sender, is_typing)\n\n        # Send the typing status update to other clients:\n        await websocket.send(json.dumps({\n            \"action\": action,\n            \"sender\": sender,\n            \"is_typing\": is_typing\n        }))\n\n    async def handle_set_parliament(self, websocket, data):\n        parliament_name = data.get(\"name\")\n        if parliament_name:\n            self.parliament = Parliament(parliament_name)\n            await self.update_queue(websocket)\n\n    async def handle_send_message(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n        sender = data.get(\"sender\")\n        user_message = data.get(\"message\")\n        timestamp = datetime.now()\n        await websocket.send(json.dumps({\n            \"action\": RECEIVE_MESSAGE,\n            \"message\": user_message,\n            \"sender\": sender,\n            \"timestamp\": timestamp.isoformat()}))\n        await self.parliament.broadcast_message(user_message, sender, timestamp)\n        print(f\"Broadcast message: {user_message}\")  # Add logging \n\n        # Sending agent info after broadcasting message\n        agent_info = self.parliament.get_agents_info()  # Assuming that this method returns agents' information\n        await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        await self.update_queue(websocket)\n            \n    async def handle_add_agents(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n\n        agents_data = data.get(\"agents\")\n        if not agents_data:\n            await self.send_error(websocket, \"No agent data provided.\")\n            return\n\n        for agent_data in agents_data:\n            agent_name = agent_data.get(\"name\")  # Extract the name\n            speaking_pressure_increment = int(agent_data.get(\"speaking_pressure_increment\"))\n\n            other_agents = \", \".join([agent['name'] for agent in agents_data if agent['name'] != agent_name])\n            initial_context = (\n                f\"Hello assistant, your name is: @{agent_data.get('name')} and your context is \"\n                f\"{agent_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n                f\"alongside your fellow agents in a parliament, which is a sort \"\n                f\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n                f\"with you are {other_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n                f\"{agent_data.get('speaking_pressure_increment')} out of 100\"\n            )\n            agent_type = agent_data.get(\"type\")\n            agent_class = self.parliament.agent_types.get(agent_type)\n            if not agent_class:\n                await self.send_error(websocket, f\"Unknown agent type: {agent_type}\")\n                continue\n\n            agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n            agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n            self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n        await self.update_queue(websocket)\n\n\n    async def update_queue(self, websocket):\n        if self.parliament:\n            speaking_queue = self.parliament.get_speaking_queue()\n            print(f\"Queue updated: {speaking_queue.to_json()}\")\n            await websocket.send(json.dumps({\"action\": UPDATE_QUEUE, \"queue\": speaking_queue.to_json()}))\n\n    async def send_error(self, websocket, message):\n        await websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\n    def run(self):\n        self.configure_openai()\n        asyncio.get_event_loop().run_until_complete(self.start_server)\n        print(\"Starting WebSocket server...\")\n        print(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n        asyncio.get_event_loop().run_forever()\n\n\nif __name__ == \"__main__\":\n    server = ParliamentServer()\n    server.run()\n",
      "created_at": "2023-05-13T18:32:13.404419",
      "sequence_order": 12,
      "parent_id": "807ceaa1-4a72-4745-ab55-d6b64febe206",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "881c0e42-d0fe-453c-ada7-5488c5bfd120",
      "role": "assistant",
      "content": "It appears that you're experiencing a TypeError in your Python script. This error is coming from a comparison operation between a coroutine and an integer in this line:\n\n```python\nif relevancy_score > highest_relevancy_score:\n```\n\nThe error message states that the `'>' not supported between instances of 'coroutine' and 'int'`. This error occurs because `relevancy_score` is a coroutine object, but the '>' operation is not defined for coroutine objects.\n\nThe problem lies in this line of code:\n\n```python\nrelevancy_score = agent.calculate_relevancy(message)\n```\n\nIt seems that `agent.calculate_relevancy()` is an async function (i.e., a coroutine). If you need the result of this function for comparison, you should await it:\n\n```python\nrelevancy_score = await agent.calculate_relevancy(message)\n```\n\nJust make sure that the function containing this line is also async. If not, you'll need to refactor your code to ensure that this function is called inside an async function. \n\nThere's also a warning in your traceback about `coroutine 'Agent.calculate_relevancy' was never awaited`. This warning will be resolved when you add the await keyword before the `agent.calculate_relevancy()` function call. \n\nLet me know if you need further assistance!",
      "created_at": "2023-05-13T18:32:44.254226",
      "sequence_order": 13,
      "parent_id": "aaa205fd-11d9-4966-b1d3-bfe11d905501",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa244a3-4a29-47ba-8dc4-3eb842e48c89",
      "role": "user",
      "content": "Traceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 37, in chat\n    await self.handle_send_message(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 75, in handle_send_message\n    await self.parliament.broadcast_message(user_message, sender, timestamp)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 293, in broadcast_message\n    await agent.update_relevancy()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 40, in update_relevancy\n    await self.websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/__init__.py\", line 231, in dumps\n    return _default_encoder.encode(obj)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/encoder.py\", line 199, in encode\n    chunks = self.iterencode(o, _one_shot=True)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/encoder.py\", line 257, in iterencode\n    return _iterencode(o, 0)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/encoder.py\", line 179, in default\n    raise TypeError(f'Object of type {o.__class__.__name__} '\nTypeError: Object of type coroutine is not JSON serializable\nfrom datetime import datetime\nimport asyncio\nimport json\nfrom websockets import serve\nfrom parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent\nimport openai\n\n# Constants\nSET_PARLIAMENT = \"set_parliament\"\nSEND_MESSAGE = \"send_message\"\nADD_AGENTS = \"add_agents\"\nUPDATE_QUEUE = \"update_queue\"\nUPDATE_AGENTS = \"update_agents\"\nRECEIVE_MESSAGE = \"receive_message\"\nERROR = \"error\"\nTYPING = \"typing\"\nSTOPPED_TYPING = \"stopped_typing\"\n\nclass ParliamentServer:\n    def __init__(self, host=\"localhost\", port=8080):\n        self.host = host\n        self.port = port\n        self.parliament = None\n        self.start_server = serve(self.chat, self.host, self.port)\n\n    def configure_openai(self):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n\n    async def chat(self, websocket, path):\n        async for message in websocket:\n            data = json.loads(message)\n            action = data.get(\"action\")\n            if action == SET_PARLIAMENT:\n                await self.handle_set_parliament(websocket, data)\n            elif action == SEND_MESSAGE:\n                await self.handle_send_message(websocket, data)\n            elif action == ADD_AGENTS:\n                await self.handle_add_agents(websocket, data)\n            elif action in [TYPING, STOPPED_TYPING]:  \n                await self.handle_typing(websocket, data)\n\n    async def handle_typing(self, websocket, data):\n        sender = data.get('sender')\n        action = data.get('action')\n        is_typing = action == TYPING\n\n        self.parliament.set_typing_status(sender, is_typing)\n\n        # Send the typing status update to other clients:\n        await websocket.send(json.dumps({\n            \"action\": action,\n            \"sender\": sender,\n            \"is_typing\": is_typing\n        }))\n\n    async def handle_set_parliament(self, websocket, data):\n        parliament_name = data.get(\"name\")\n        if parliament_name:\n            self.parliament = Parliament(parliament_name)\n            await self.update_queue(websocket)\n\n    async def handle_send_message(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n        sender = data.get(\"sender\")\n        user_message = data.get(\"message\")\n        timestamp = datetime.now()\n        await websocket.send(json.dumps({\n            \"action\": RECEIVE_MESSAGE,\n            \"message\": user_message,\n            \"sender\": sender,\n            \"timestamp\": timestamp.isoformat()}))\n        await self.parliament.broadcast_message(user_message, sender, timestamp)\n        print(f\"Broadcast message: {user_message}\")  # Add logging \n\n        # Sending agent info after broadcasting message\n        agent_info = self.parliament.get_agents_info()  # Assuming that this method returns agents' information\n        await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        await self.update_queue(websocket)\n            \n    async def handle_add_agents(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n\n        agents_data = data.get(\"agents\")\n        if not agents_data:\n            await self.send_error(websocket, \"No agent data provided.\")\n            return\n\n        for agent_data in agents_data:\n            agent_name = agent_data.get(\"name\")  # Extract the name\n            speaking_pressure_increment = int(agent_data.get(\"speaking_pressure_increment\"))\n\n            other_agents = \", \".join([agent['name'] for agent in agents_data if agent['name'] != agent_name])\n            initial_context = (\n                f\"Hello assistant, your name is: @{agent_data.get('name')} and your context is \"\n                f\"{agent_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n                f\"alongside your fellow agents in a parliament, which is a sort \"\n                f\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n                f\"with you are {other_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n                f\"{agent_data.get('speaking_pressure_increment')} out of 100\"\n            )\n            agent_type = agent_data.get(\"type\")\n            agent_class = self.parliament.agent_types.get(agent_type)\n            if not agent_class:\n                await self.send_error(websocket, f\"Unknown agent type: {agent_type}\")\n                continue\n\n            agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n            agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n            self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n        await self.update_queue(websocket)\n\n\n    async def update_queue(self, websocket):\n        if self.parliament:\n            speaking_queue = self.parliament.get_speaking_queue()\n            print(f\"Queue updated: {speaking_queue.to_json()}\")\n            await websocket.send(json.dumps({\"action\": UPDATE_QUEUE, \"queue\": speaking_queue.to_json()}))\n\n    async def send_error(self, websocket, message):\n        await websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\n    def run(self):\n        self.configure_openai()\n        asyncio.get_event_loop().run_until_complete(self.start_server)\n        print(\"Starting WebSocket server...\")\n        print(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n        asyncio.get_event_loop().run_forever()\n\n\nif __name__ == \"__main__\":\n    server = ParliamentServer()\n    server.run()\n",
      "created_at": "2023-05-13T18:37:31.043728",
      "sequence_order": 14,
      "parent_id": "881c0e42-d0fe-453c-ada7-5488c5bfd120",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "c43cd8f6-4e97-4029-a8b5-26b06e9ef5f7",
      "role": "assistant",
      "content": "The error is happening because you're trying to serialize a coroutine object into JSON format, which is not supported. The coroutine object in question is probably a result of an `async` function call that you've not `await`ed.\n\nFrom your code, it's not immediately clear where this coroutine object is coming from, as you seem to correctly `await` all async function calls. However, the error message indicates that the error occurs in the `update_relevancy()` method, which is called in `broadcast_message()`:\n\n```python\nawait agent.update_relevancy()\n```\n\nIt's likely that this `update_relevancy()` method is returning a coroutine that you're trying to convert to JSON. If this is the case, make sure that `update_relevancy()` either returns a JSON-serializable object, or that you `await` it properly and handle the result correctly.\n\nFor example, if `update_relevancy()` should update some property of `agent` that you then want to send as JSON, you might want to do something like this:\n\n```python\nawait agent.update_relevancy()\nagent_info = agent.to_json()  # assuming that `to_json()` is a method that returns a JSON-serializable representation of the agent\nawait self.websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n```\n\nWithout seeing the `update_relevancy()` method, it's difficult to provide a more specific solution. I hope this general guidance helps you to solve the problem. Let me know if you need further assistance.",
      "created_at": "2023-05-13T18:38:07.907530",
      "sequence_order": 15,
      "parent_id": "aaa244a3-4a29-47ba-8dc4-3eb842e48c89",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2ff6b-48d9-4e74-a9c4-f0b7bee9bdff",
      "role": "user",
      "content": "Traceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 37, in chat\n    await self.handle_send_message(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 75, in handle_send_message\n    await self.parliament.broadcast_message(user_message, sender, timestamp)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 293, in broadcast_message\n    await agent.update_relevancy()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 40, in update_relevancy\n    await self.websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/__init__.py\", line 231, in dumps\n    return _default_encoder.encode(obj)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/encoder.py\", line 199, in encode\n    chunks = self.iterencode(o, _one_shot=True)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/encoder.py\", line 257, in iterencode\n    return _iterencode(o, 0)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/encoder.py\", line 179, in default\n    raise TypeError(f'Object of type {o.__class__.__name__} '\nTypeError: Object of type coroutine is not JSON serializable\nfrom datetime import datetime\nimport asyncio\nimport json\nfrom websockets import serve\nfrom parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent\nimport openai\n\n# Constants\nSET_PARLIAMENT = \"set_parliament\"\nSEND_MESSAGE = \"send_message\"\nADD_AGENTS = \"add_agents\"\nUPDATE_QUEUE = \"update_queue\"\nUPDATE_AGENTS = \"update_agents\"\nRECEIVE_MESSAGE = \"receive_message\"\nERROR = \"error\"\nTYPING = \"typing\"\nSTOPPED_TYPING = \"stopped_typing\"\n\nclass ParliamentServer:\n    def __init__(self, host=\"localhost\", port=8080):\n        self.host = host\n        self.port = port\n        self.parliament = None\n        self.start_server = serve(self.chat, self.host, self.port)\n\n    def configure_openai(self):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n\n    async def chat(self, websocket, path):\n        async for message in websocket:\n            data = json.loads(message)\n            action = data.get(\"action\")\n            if action == SET_PARLIAMENT:\n                await self.handle_set_parliament(websocket, data)\n            elif action == SEND_MESSAGE:\n                await self.handle_send_message(websocket, data)\n            elif action == ADD_AGENTS:\n                await self.handle_add_agents(websocket, data)\n            elif action in [TYPING, STOPPED_TYPING]:  \n                await self.handle_typing(websocket, data)\n\n    async def handle_typing(self, websocket, data):\n        sender = data.get('sender')\n        action = data.get('action')\n        is_typing = action == TYPING\n\n        self.parliament.set_typing_status(sender, is_typing)\n\n        # Send the typing status update to other clients:\n        await websocket.send(json.dumps({\n            \"action\": action,\n            \"sender\": sender,\n            \"is_typing\": is_typing\n        }))\n\n    async def handle_set_parliament(self, websocket, data):\n        parliament_name = data.get(\"name\")\n        if parliament_name:\n            self.parliament = Parliament(parliament_name)\n            await self.update_queue(websocket)\n\n    async def handle_send_message(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n        sender = data.get(\"sender\")\n        user_message = data.get(\"message\")\n        timestamp = datetime.now()\n        await websocket.send(json.dumps({\n            \"action\": RECEIVE_MESSAGE,\n            \"message\": user_message,\n            \"sender\": sender,\n            \"timestamp\": timestamp.isoformat()}))\n        await self.parliament.broadcast_message(user_message, sender, timestamp)\n        print(f\"Broadcast message: {user_message}\")  # Add logging \n\n        # Sending agent info after broadcasting message\n        agent_info = self.parliament.get_agents_info()  # Assuming that this method returns agents' information\n        await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        await self.update_queue(websocket)\n            \n    async def handle_add_agents(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n\n        agents_data = data.get(\"agents\")\n        if not agents_data:\n            await self.send_error(websocket, \"No agent data provided.\")\n            return\n\n        for agent_data in agents_data:\n            agent_name = agent_data.get(\"name\")  # Extract the name\n            speaking_pressure_increment = int(agent_data.get(\"speaking_pressure_increment\"))\n\n            other_agents = \", \".join([agent['name'] for agent in agents_data if agent['name'] != agent_name])\n            initial_context = (\n                f\"Hello assistant, your name is: @{agent_data.get('name')} and your context is \"\n                f\"{agent_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n                f\"alongside your fellow agents in a parliament, which is a sort \"\n                f\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n                f\"with you are {other_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n                f\"{agent_data.get('speaking_pressure_increment')} out of 100\"\n            )\n            agent_type = agent_data.get(\"type\")\n            agent_class = self.parliament.agent_types.get(agent_type)\n            if not agent_class:\n                await self.send_error(websocket, f\"Unknown agent type: {agent_type}\")\n                continue\n\n            agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n            agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n            self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n        await self.update_queue(websocket)\n\n\n    async def update_queue(self, websocket):\n        if self.parliament:\n            speaking_queue = self.parliament.get_speaking_queue()\n            print(f\"Queue updated: {speaking_queue.to_json()}\")\n            await websocket.send(json.dumps({\"action\": UPDATE_QUEUE, \"queue\": speaking_queue.to_json()}))\n\n    async def send_error(self, websocket, message):\n        await websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\n    def run(self):\n        self.configure_openai()\n        asyncio.get_event_loop().run_until_complete(self.start_server)\n        print(\"Starting WebSocket server...\")\n        print(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n        asyncio.get_event_loop().run_forever()\n\n\nif __name__ == \"__main__\":\n    server = ParliamentServer()\n    server.run()\n\nHere's the update relevancy code:\n\n    async def update_relevancy(self): \n        self.relevancy_score = self.calculate_relevancy(self.parliament.chat_history.truncated_chat_history)\n        agent_info = [\n            {\n                \"name\": self.name,\n                \"relevancy_score\": self.relevancy_score  \n            }\n        ]\n        await self.websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info})) \n        \n",
      "created_at": "2023-05-13T18:39:30.229576",
      "sequence_order": 16,
      "parent_id": "881c0e42-d0fe-453c-ada7-5488c5bfd120",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "f3ed6876-b0f6-4bf8-89da-d4b90ddb681a",
      "role": "assistant",
      "content": "The `TypeError: Object of type coroutine is not JSON serializable` error suggests that you're trying to convert a coroutine (an asynchronous function) into JSON format, which is not allowed. \n\nLet's break down the traceback:\n\nThe error occurs at this line in your `ParliamentServer` class's `handle_send_message` method:\n\n```python\nawait websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n```\n\nHere, `agent_info` is the result of the `self.parliament.get_agents_info()` method call. \n\nThis method call appears to be expected to return some sort of data structure (likely a list or dictionary) that represents information about agents. However, the error message suggests that it's actually returning a coroutine. \n\nIt seems like `get_agents_info` is likely an asynchronous method that you need to `await` to get the actual result from. If `get_agents_info` is indeed an async function, you should change the respective line to:\n\n```python\nagent_info = await self.parliament.get_agents_info()\n```\n\nHowever, without seeing the implementation of the `get_agents_info` method, I can't definitively say if this is the issue. If `get_agents_info` is not a coroutine function, then the problem lies elsewhere, possibly in the implementation of that method or how your agents are represented.\n\nAlso, it's worth mentioning that in your `update_relevancy` function, you're trying to send data over the websocket. This seems odd considering the function's purpose is just to update relevancy. You might want to separate concerns here and handle sending updates over the websocket elsewhere in your code.\n\n```python\n    async def update_relevancy(self): \n        self.relevancy_score = self.calculate_relevancy(self.parliament.chat_history.truncated_chat_history)\n```\n\nYou could then handle sending updates over the websocket in a different function or part of your code where it makes more sense to do so.",
      "created_at": "2023-05-13T18:40:18.810654",
      "sequence_order": 17,
      "parent_id": "aaa2ff6b-48d9-4e74-a9c4-f0b7bee9bdff",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2b998-be34-4f0b-b9ca-bf233fd7b26f",
      "role": "user",
      "content": "remove the class speaking queue and make it a simple dictionary or list whichever is better/easier. I think the class is excessive, yeah?\nimport asyncio\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.speaking_pressure = speaking_pressure_increment\n        self.tagged = False\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.is_speaking = False\n        self.relevancy_score = None\n\n    async def update_relevancy(self): \n        self.relevancy_score = self.calculate_relevancy(self.parliament.chat_history.truncated_chat_history)\n        agent_info = [\n            {\n                \"name\": self.name,\n                \"relevancy_score\": self.relevancy_score  \n            }\n        ]\n        await self.websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info})) \n        \n    async def calculate_relevancy(self, chat_context: str) -> int:\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"Return the result as a number. How relevant, from 0-100 is this context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n\n            max_attempts = 3\n            attempt = 1\n            relevancy_score = 0\n\n            while attempt <= max_attempts:\n                try:\n                    response = openai.Completion.create(\n                        engine=\"text-curie-001\",\n                        prompt=prompt,\n                        max_tokens=150,\n                        temperature=0.0,\n                        n=1,\n                        stop=None\n                        )\n\n                    completions = response.choices[0].text.strip().split(\"\\n\")\n                    score = int(completions[-1].strip())\n\n                    if 0 <= score <= 100:  # Check if score is within valid range\n                        relevancy_score = score\n                        break  # Break out of the loop if a valid relevancy score is obtained\n\n                    else:\n                        print(\"Invalid response received. Please enter a number from 0 to 100.\")\n\n                except (ValueError, KeyError):\n                    print(\"Invalid response received. Please enter a valid number.\")\n\n                attempt += 1\n            self.initial_context = chat_context\n            self.relevancy_score = relevancy_score\n            print(f\"Relevancy score for {self.name}: {self.relevancy_score}%\")\n            agent_info = [\n                {\n                    \"name\": self.name,\n                    \"relevancy_score\": self.relevancy_score  # Return updated score here\n                }\n            ]\n            await self.websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        else:\n            print(\"Using cached relevancy score...\")\n        return min(self.relevancy_score, 100) # Cap maximum score at 100\n    \n\n\n    def should_speak(self):\n        return self.parliament.speaker_manager.should_speak(self)  # Call parliament's speaker_manager\n\n    async def increment_pressure(self):\n        while True:\n            await asyncio.sleep(PRESSURE_INCREMENT_INTERVAL)\n            self.speaking_pressure += self.speaking_pressure_increment\n\n    def get_agent_message(self, chat_history):\n        \"\"\"\n        Generate a message from this agent based on the current chat history.\n        \"\"\"\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = self.agent_instance.get_response(chat_history)\n            message = f\"{response}\"\n        return message\n    \n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue.queue\n    \n    async def speak(self):\n        if self.should_speak():\n            self.is_speaking = True\n            await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n            await self.websocket.send(json.dumps({\"action\": STOPPED_TYPING, \"sender\": self.name}))\n            agent_message = self.get_agent_message(self.parliament.chat_history)\n            await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n            self.speaking_pressure = 0\n            self.is_speaking = False\n            if self.in_queue():\n                self.parliament.speaking_queue.remove(self.name)\n\n    def reset_pressure(self):\n        self.speaking_pressure = 0\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = [] \n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history() \n\n    def truncate_chat_history(self, max_length=2000):\n        \"\"\"\n        Truncate the chat history to the last max_length characters.\n        \"\"\"\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def last_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakingQueue:\n    def __init__(self):\n        self.queue = deque()\n\n    def add(self, agent_name):\n        self.queue.append(agent_name)\n\n    def pop(self):\n        if len(self.queue) > 0:\n            return self.queue.pop()\n        else:\n            return None\n        \n    def enqueue(self, name):\n        self.queue.append(name)\n\n    def dequeue(self):\n        return self.queue.popleft() if self.queue else None\n\n    def front(self):\n        return self.queue[0] if self.queue else None\n\n    def remove(self, name):\n        self.queue.remove(name)\n\n    def contains(self, name):\n        return name in self.queue\n\n    def to_json(self):\n        return list(self.queue)\n    \nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue.front() == agent.name\n\n\n\n\n\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = SpeakingQueue()\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {} \n\n    def set_typing_status(self, agent_name: str, status: bool):\n        self.typing_status[agent_name] = status\n\n    def get_typing_status(self, agent_name: str):\n        return self.typing_status.get(agent_name, False)\n\n    async def broadcast_message(self, message, sender, timestamp):\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n        await self.update_speaking_queue()\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):  \n                await agent.speak() \n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        first_agent_in_queue = self.speaking_queue.dequeue()\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n    def add_to_speaking_queue(self, agent):\n        if not self.speaking_queue.contains(agent.name):\n            self.speaking_queue.enqueue(agent.name)\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n    \n    def get_speaking_queue(self):\n        return self.speaking_queue\n            \n    def add_agent(self, agent: Agent):\n        self.agents[agent.name] = agent\n        self.typing_status[agent.name] = False  # Initialize typing status when adding an agent\n        asyncio.create_task(agent.increment_pressure())        \n\n    def remove_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        del self.agents[agent_name]\n\n    def get_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        return self.agents[agent_name]\n\n    def add_to_chat_history(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = 100\n                self.agents[agent_name].tagged = True\n                print(f\"Tagged agent: {agent_name}\")  # Debug print\n        return mentioned_agents\n\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def add_tagged_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.tagged and agent.name not in self.speaking_queue.queue:    \n                self.speaking_queue.add(agent.name)\n                agent.tagged = False\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def add_high_pressure_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n                self.speaking_queue.add(agent.name)\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def trigger_next_speaker(self):\n        if self.speaking_queue:\n            next_speaker = self.get_agent(self.speaking_queue.pop())  # Remove the agent from the queue\n\n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n        \n        most_relevant_agent = None\n        highest_relevancy_score = -1\n\n        for agent in self.agents.values():\n            chat_context = self.chat_history.truncated_chat_history\n            relevancy_score = await agent.calculate_relevancy(chat_context) \n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n\n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent:\n            self.speaking_queue.enqueue(most_relevant_agent.name)\n\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n        self.trigger_next_speaker()\n        \n    def get_sorted_agents_based_on_relevancy(self):\n        return sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history) if agent.calculate_relevancy(self.chat_history) is not None else 0, reverse=True)\n\n    async def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent_name, agent in self.agents.items():\n            relevancy_score = await agent.calculate_relevancy(self.chat_history) \n            agents_info.append({\n                \"name\": agent_name,\n                \"speaking_pressure\": agent.speaking_pressure,\n                \"speaking_pressure_increment\": agent.speaking_pressure_increment, \n                \"context\": agent.context,\n                \"agent_type\": agent.agent_type,\n                \"relevancy_score\": relevancy_score  # Return the actual score here\n            })\n        return agents_info ",
      "created_at": "2023-05-14T01:56:00.606915",
      "sequence_order": 18,
      "parent_id": "f3ed6876-b0f6-4bf8-89da-d4b90ddb681a",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "dccd43dc-8a8b-4730-9854-a79272e4149d",
      "role": "assistant",
      "content": "Sure, we can replace the `SpeakingQueue` class with a simple Python list. I've made the necessary changes below:\n\n```python\nclass Agent:\n    ...\n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue\n\n    async def speak(self):\n        if self.should_speak():\n            self.is_speaking = True\n            await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n            await self.websocket.send(json.dumps({\"action\": STOPPED_TYPING, \"sender\": self.name}))\n            agent_message = self.get_agent_message(self.parliament.chat_history)\n            await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n            self.speaking_pressure = 0\n            self.is_speaking = False\n            if self.in_queue():\n                self.parliament.speaking_queue.remove(self.name)\n    ...\n\nclass SpeakerManager:\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = []\n        ...\n\n    def add_to_speaking_queue(self, agent):\n        if agent.name not in self.speaking_queue:\n            self.speaking_queue.append(agent.name)\n\n    ...\n\n    async def broadcast_message(self, message, sender, timestamp):\n        ...\n        first_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n    ...\n    \n    async def update_speaking_queue(self):\n        ...\n        if most_relevant_agent and most_relevant_agent.name not in self.speaking_queue:\n            self.speaking_queue.append(most_relevant_agent.name)\n\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n        self.trigger_next_speaker()\n\n    ...\n```\n\nHere's a summary of changes made:\n\n1. Replaced `SpeakingQueue` class with a list in `Parliament` class. The class attribute `speaking_queue` is now a Python list.\n\n2. Removed all the methods of `SpeakingQueue` class and replaced them with equivalent list operations where needed. For instance, `self.speaking_queue.enqueue(agent.name)` becomes `self.speaking_queue.append(agent.name)`, `self.speaking_queue.dequeue()` becomes `self.speaking_queue.pop(0)`, and `self.speaking_queue.front()` becomes `self.speaking_queue[0]` (with appropriate checks to avoid `IndexError`).\n\n3. In `Agent` class, method `in_queue` checks if agent's name is in the `speaking_queue` list of `Parliament` class.\n\n4. In `SpeakerManager` class, method `should_speak` checks if agent's name is the first element in the `speaking_queue` list.\n\n5. Updated the `broadcast_message` and `update_speaking_queue` methods in `Parliament` class to work with the list-based speaking queue. \n\n6. In the `Agent` class, method `speak` removes the agent's name from the `speaking_queue` list after speaking.\n\nThis simplifies the design by removing the `SpeakingQueue` class, but remember that the list operations have different time complexities compared to the deque",
      "created_at": "2023-05-14T01:57:06.561650",
      "sequence_order": 19,
      "parent_id": "aaa2b998-be34-4f0b-b9ca-bf233fd7b26f",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": false
      }
    },
    {
      "id": "aaa23a2f-e152-41f2-a5b2-89ede6b45b25",
      "role": "user",
      "content": "should it be a dictionary or a list?",
      "created_at": "2023-05-14T01:58:24.646739",
      "sequence_order": 20,
      "parent_id": "dccd43dc-8a8b-4730-9854-a79272e4149d",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "09906a90-3980-4456-a9fc-13fa5305efe7",
      "role": "assistant",
      "content": "In the context of the Speaking Queue, a list would be a more suitable data structure than a dictionary. Here's why:\n\n- You need to maintain the order of the agents who will speak. Lists inherently maintain the order of elements, whereas dictionaries do not guarantee order (although this has changed in Python 3.7 and onwards where dictionaries maintain the insertion order, it's not their primary use case).\n\n- The operations you perform on the Speaking Queue, such as adding an agent to the end, removing an agent from the front, or checking if an agent is in the queue, are straightforward with a list.\n\n- You don't have a key-value relationship, which is what dictionaries are used for. In a dictionary, you have a unique key associated with a value. In your case, you just have a series of agent names.\n\nHere's how you could simplify the SpeakingQueue class by replacing it with a list:\n\n```python\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = []  # Changed from SpeakingQueue() to []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {} \n\n    # Other methods ...\n\n    def add_to_speaking_queue(self, agent):\n        if agent.name not in self.speaking_queue:\n            self.speaking_queue.append(agent.name)  # Changed from enqueue to append\n\n    # Other methods ...\n\n    def remove_from_speaking_queue(self, agent_name):\n        if agent_name in self.speaking_queue:\n            self.speaking_queue.remove(agent_name)  # Remove agent from queue\n\n    # Other methods ...\n```\n\nThe SpeakerManager's should_speak method will also need a slight modification:\n\n```python\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n```\n\nNote that you'll need to adapt the rest of your code to work with the list instead of the SpeakingQueue class.",
      "created_at": "2023-05-14T01:59:09.853748",
      "sequence_order": 21,
      "parent_id": "aaa23a2f-e152-41f2-a5b2-89ede6b45b25",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa29ec2-5c7f-4309-91d7-a9633011447d",
      "role": "user",
      "content": "how do we update the server with the new list speaking queue? \nfrom datetime import datetime\nimport asyncio\nimport json\nfrom websockets import serve\nfrom parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent\nimport openai\n\n# Constants\nSET_PARLIAMENT = \"set_parliament\"\nSEND_MESSAGE = \"send_message\"\nADD_AGENTS = \"add_agents\"\nUPDATE_QUEUE = \"update_queue\"\nUPDATE_AGENTS = \"update_agents\"\nRECEIVE_MESSAGE = \"receive_message\"\nERROR = \"error\"\nTYPING = \"typing\"\nSTOPPED_TYPING = \"stopped_typing\"\n\nclass ParliamentServer:\n    def __init__(self, host=\"localhost\", port=8080):\n        self.host = host\n        self.port = port\n        self.parliament = None\n        self.start_server = serve(self.chat, self.host, self.port)\n\n    def configure_openai(self):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n\n    async def chat(self, websocket, path):\n        async for message in websocket:\n            data = json.loads(message)\n            action = data.get(\"action\")\n            if action == SET_PARLIAMENT:\n                await self.handle_set_parliament(websocket, data)\n            elif action == SEND_MESSAGE:\n                await self.handle_send_message(websocket, data)\n            elif action == ADD_AGENTS:\n                await self.handle_add_agents(websocket, data)\n            elif action in [TYPING, STOPPED_TYPING]:  \n                await self.handle_typing(websocket, data)\n\n    async def handle_typing(self, websocket, data):\n        sender = data.get('sender')\n        action = data.get('action')\n        is_typing = action == TYPING\n\n        self.parliament.set_typing_status(sender, is_typing)\n\n        # Send the typing status update to other clients:\n        await websocket.send(json.dumps({\n            \"action\": action,\n            \"sender\": sender,\n            \"is_typing\": is_typing\n        }))\n\n    async def handle_set_parliament(self, websocket, data):\n        parliament_name = data.get(\"name\")\n        if parliament_name:\n            self.parliament = Parliament(parliament_name)\n            await self.update_queue(websocket)\n\n    async def handle_send_message(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n        sender = data.get(\"sender\")\n        user_message = data.get(\"message\")\n        timestamp = datetime.now()\n        await websocket.send(json.dumps({\n            \"action\": RECEIVE_MESSAGE,\n            \"message\": user_message,\n            \"sender\": sender,\n            \"timestamp\": timestamp.isoformat()}))\n        await self.parliament.broadcast_message(user_message, sender, timestamp)\n        print(f\"Broadcast message: {user_message}\")  # Add logging \n\n        # Sending agent info after broadcasting message\n        agent_info = await self.parliament.get_agents_info()  \n        await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        await self.update_queue(websocket)\n            \n    async def handle_add_agents(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n\n        agents_data = data.get(\"agents\")\n        if not agents_data:\n            await self.send_error(websocket, \"No agent data provided.\")\n            return\n\n        for agent_data in agents_data:\n            agent_name = agent_data.get(\"name\")  # Extract the name\n            speaking_pressure_increment = int(agent_data.get(\"speaking_pressure_increment\"))\n\n            other_agents = \", \".join([agent['name'] for agent in agents_data if agent['name'] != agent_name])\n            initial_context = (\n                f\"Hello assistant, your name is: @{agent_data.get('name')} and your context is \"\n                f\"{agent_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n                f\"alongside your fellow agents in a parliament, which is a sort \"\n                f\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n                f\"with you are {other_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n                f\"{agent_data.get('speaking_pressure_increment')} out of 100\"\n            )\n            agent_type = agent_data.get(\"type\")\n            agent_class = self.parliament.agent_types.get(agent_type)\n            if not agent_class:\n                await self.send_error(websocket, f\"Unknown agent type: {agent_type}\")\n                continue\n\n            agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n            agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n            self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n        await self.update_queue(websocket)\n\n\n    async def update_queue(self, websocket):\n        if self.parliament:\n            speaking_queue = self.parliament.get_speaking_queue()\n            print(f\"Queue updated: {speaking_queue.to_json()}\")\n            await websocket.send(json.dumps({\"action\": UPDATE_QUEUE, \"queue\": speaking_queue.to_json()}))\n\n    async def send_error(self, websocket, message):\n        await websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\n    def run(self):\n        self.configure_openai()\n        asyncio.get_event_loop().run_until_complete(self.start_server)\n        print(\"Starting WebSocket server...\")\n        print(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n        asyncio.get_event_loop().run_forever()\n\n\nif __name__ == \"__main__\":\n    server = ParliamentServer()\n    server.run()\n",
      "created_at": "2023-05-14T02:02:25.881835",
      "sequence_order": 22,
      "parent_id": "09906a90-3980-4456-a9fc-13fa5305efe7",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "37d15fbe-49b2-4f99-a611-08107a68e8d0",
      "role": "assistant",
      "content": "You're currently using the `speaking_queue.to_json()` method in your `update_queue` function. Now that you've replaced `SpeakingQueue` with a list, you no longer need `to_json()`. Just pass the list directly to `json.dumps()`. \n\nAlso, you'll have to update the `get_speaking_queue()` method in your `Parliament` class to return the `speaking_queue` list. Here's the updated `update_queue` method:\n\n```python\nasync def update_queue(self, websocket):\n    if self.parliament:\n        speaking_queue = self.parliament.get_speaking_queue()  # This should return a list\n        print(f\"Queue updated: {speaking_queue}\")\n        await websocket.send(json.dumps({\"action\": UPDATE_QUEUE, \"queue\": speaking_queue}))  # Directly send the list\n```\n\nAnd here's the updated `get_speaking_queue()` method in your `Parliament` class:\n\n```python\ndef get_speaking_queue(self):\n    return self.speaking_queue\n```\n\nThe returned list should be serialized correctly by `json.dumps()`, and you can process it on the client side as a regular JSON array.",
      "created_at": "2023-05-14T02:02:50.015740",
      "sequence_order": 23,
      "parent_id": "aaa29ec2-5c7f-4309-91d7-a9633011447d",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2caff-779f-4ed7-b542-418308f52477",
      "role": "user",
      "content": "now getting this error:\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 37, in chat\n    await self.handle_send_message(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 75, in handle_send_message\n    await self.parliament.broadcast_message(user_message, sender, timestamp)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 259, in broadcast_message\n    if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\nUnboundLocalError: local variable 'first_agent_in_queue' referenced before assignment\nimport asyncio\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.speaking_pressure = speaking_pressure_increment\n        self.tagged = False\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.is_speaking = False\n        self.relevancy_score = None\n\n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue\n\n    async def update_relevancy(self): \n        self.relevancy_score = self.calculate_relevancy(self.parliament.chat_history.truncated_chat_history)\n        agent_info = [\n            {\n                \"name\": self.name,\n                \"relevancy_score\": self.relevancy_score  \n            }\n        ]\n        await self.websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info})) \n        \n    async def calculate_relevancy(self, chat_context: str) -> int:\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"Return the result as a number. How relevant, from 0-100 is this context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n\n            max_attempts = 3\n            attempt = 1\n            relevancy_score = 0\n\n            while attempt <= max_attempts:\n                try:\n                    response = openai.Completion.create(\n                        engine=\"text-curie-001\",\n                        prompt=prompt,\n                        max_tokens=150,\n                        temperature=0.0,\n                        n=1,\n                        stop=None\n                        )\n\n                    completions = response.choices[0].text.strip().split(\"\\n\")\n                    score = int(completions[-1].strip())\n\n                    if 0 <= score <= 100:  # Check if score is within valid range\n                        relevancy_score = score\n                        break  # Break out of the loop if a valid relevancy score is obtained\n\n                    else:\n                        print(\"Invalid response received. Please enter a number from 0 to 100.\")\n\n                except (ValueError, KeyError):\n                    print(\"Invalid response received. Please enter a valid number.\")\n\n                attempt += 1\n            self.initial_context = chat_context\n            self.relevancy_score = relevancy_score\n            print(f\"Relevancy score for {self.name}: {self.relevancy_score}%\")\n            agent_info = [\n                {\n                    \"name\": self.name,\n                    \"relevancy_score\": self.relevancy_score  # Return updated score here\n                }\n            ]\n            await self.websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        else:\n            print(\"Using cached relevancy score...\")\n        return min(self.relevancy_score, 100) # Cap maximum score at 100\n    \n\n\n    def should_speak(self):\n        return self.parliament.speaker_manager.should_speak(self)  # Call parliament's speaker_manager\n\n    async def increment_pressure(self):\n        while True:\n            await asyncio.sleep(PRESSURE_INCREMENT_INTERVAL)\n            self.speaking_pressure += self.speaking_pressure_increment\n\n    def get_agent_message(self, chat_history):\n        \"\"\"\n        Generate a message from this agent based on the current chat history.\n        \"\"\"\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = self.agent_instance.get_response(chat_history)\n            message = f\"{response}\"\n        return message\n    \n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue.queue\n    \n    async def speak(self):\n        if self.should_speak():\n            self.is_speaking = True\n            await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n            await self.websocket.send(json.dumps({\"action\": STOPPED_TYPING, \"sender\": self.name}))\n            agent_message = self.get_agent_message(self.parliament.chat_history)\n            await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n            self.speaking_pressure = 0\n            self.is_speaking = False\n            if self.in_queue():\n                self.parliament.speaking_queue.remove(self.name)\n\n    def reset_pressure(self):\n        self.speaking_pressure = 0\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = [] \n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history() \n\n    def truncate_chat_history(self, max_length=2000):\n        \"\"\"\n        Truncate the chat history to the last max_length characters.\n        \"\"\"\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def last_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\n\n\n\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {} \n\n    def set_typing_status(self, agent_name: str, status: bool):\n        self.typing_status[agent_name] = status\n\n    def get_typing_status(self, agent_name: str):\n        return self.typing_status.get(agent_name, False)\n\n    async def broadcast_message(self, message, sender, timestamp):\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n        await self.update_speaking_queue()\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):  \n                await agent.speak() \n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        first_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n    def add_to_speaking_queue(self, agent):\n        if agent.name not in self.speaking_queue:\n            self.speaking_queue.append(agent.name)\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n    \n    def get_speaking_queue(self):\n        return self.speaking_queue            \n\n    def add_agent(self, agent: Agent):\n        self.agents[agent.name] = agent\n        self.typing_status[agent.name] = False  # Initialize typing status when adding an agent\n        asyncio.create_task(agent.increment_pressure())        \n\n    def remove_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        del self.agents[agent_name]\n\n    def get_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        return self.agents[agent_name]\n\n    def add_to_chat_history(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = 100\n                self.agents[agent_name].tagged = True\n                print(f\"Tagged agent: {agent_name}\")  # Debug print\n        return mentioned_agents\n\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def add_tagged_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.tagged and agent.name not in self.speaking_queue.queue:    \n                self.speaking_queue.add(agent.name)\n                agent.tagged = False\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def add_high_pressure_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n                self.speaking_queue.add(agent.name)\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def trigger_next_speaker(self):\n        if self.speaking_queue:\n            next_speaker = self.get_agent(self.speaking_queue.pop())  # Remove the agent from the queue\n\n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n        \n        most_relevant_agent = None\n        highest_relevancy_score = -1\n\n        for agent in self.agents.values():\n            chat_context = self.chat_history.truncated_chat_history\n            relevancy_score = await agent.calculate_relevancy(chat_context) \n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n\n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent and most_relevant_agent.name not in self.speaking_queue:\n            self.speaking_queue.append(most_relevant_agent.name)\n\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n        self.trigger_next_speaker()\n\n    def get_sorted_agents_based_on_relevancy(self):\n        return sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history) if agent.calculate_relevancy(self.chat_history) is not None else 0, reverse=True)\n\n    async def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent_name, agent in self.agents.items():\n            relevancy_score = await agent.calculate_relevancy(self.chat_history) \n            agents_info.append({\n                \"name\": agent_name,\n                \"speaking_pressure\": agent.speaking_pressure,\n                \"speaking_pressure_increment\": agent.speaking_pressure_increment, \n                \"context\": agent.context,\n                \"agent_type\": agent.agent_type,\n                \"relevancy_score\": relevancy_score  # Return the actual score here\n            })\n        return agents_info ",
      "created_at": "2023-05-14T02:05:55.821698",
      "sequence_order": 24,
      "parent_id": "37d15fbe-49b2-4f99-a611-08107a68e8d0",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "5536998e-a197-4ca0-86bd-6a703c0943e2",
      "role": "assistant",
      "content": "It seems like the problem you're encountering is due to referencing a variable before it is assigned. The variable in question is `first_agent_in_queue`, which you're trying to use before it has been assigned any value. This happens at two locations in your `broadcast_message` function:\n\n```python\nasync def broadcast_message(self, message, sender, timestamp):\n    if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n        await self.agents[first_agent_in_queue].speak()\n\n    ...\n\n    first_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n    if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n        await self.agents[first_agent_in_queue].speak()\n```\n\nYou're trying to use `first_agent_in_queue` in the first `if` statement, but you only assign a value to it after these lines. To fix this issue, you need to assign a value to `first_agent_in_queue` before using it.\n\nHere's a suggestion on how you can modify your function:\n\n```python\nasync def broadcast_message(self, message, sender, timestamp):\n    # Assign a value to first_agent_in_queue before using it\n    first_agent_in_queue = self.speaking_queue[0] if self.speaking_queue else None\n\n    if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n        await self.agents[first_agent_in_queue].speak()\n\n    ...\n\n    first_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n    if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n        await self.agents[first_agent_in_queue].speak()\n```\n\nIn this modification, I added a line to assign `first_agent_in_queue` before its first usage in the function. Please note that `self.speaking_queue[0]` will fetch the first item from the queue without removing it, which seems to be the desired behaviour here. You should also consider what you want to happen when `self.speaking_queue` is empty, as `first_agent_in_queue` will be `None` in such cases.",
      "created_at": "2023-05-14T02:06:44.834536",
      "sequence_order": 25,
      "parent_id": "aaa2caff-779f-4ed7-b542-418308f52477",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa21387-c7b1-4d42-aa3e-f568b104af93",
      "role": "user",
      "content": "parliament get response is broken:\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, chat_history):\n        system_msg = self.initial_context\n\n    messages = [{\"role\": \"system\", \"content\": system_msg}]\n    for message in self.parliament.chat_history.truncated_chat_history:\n        role = message[\"sender\"]\n        msg = message[\"message\"]\n        messages.append({\"role\": \"assistant\" if role != \"assistant\" else role, \"content\": msg})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n\n\nclass GPT4AllAgent:\n    def __init__(self):\n        # Download and set up the GPT4All model\n        self._initialize_gpt4all_model()\n        self._initialize_llm_chain()\n\n    def _initialize_gpt4all_model(self):\n        local_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n\n        url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n        response = requests.get(url, stream=True)\n\n        with open(local_path, 'wb') as f:\n            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n                if chunk:\n                    f.write(chunk)\n\n        self.model_path = local_path\n\n    def _initialize_llm_chain(self):\n        template = \"\"\"{chat_history}\n\n        Question: {question}\n\n        Answer: Let's think step by step.\"\"\"\n        prompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\n\n        callbacks = [StreamingStdOutCallbackHandler()]\n        llm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\n        self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n\n    def get_response(self, chat_history, question):\n        return self.llm_chain.run(chat_history=chat_history, question=question)\n\n\n\n\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {} \n\n    def set_typing_status(self, agent_name: str, status: bool):\n        self.typing_status[agent_name] = status\n\n    def get_typing_status(self, agent_name: str):\n        return self.typing_status.get(agent_name, False)\n\n    async def broadcast_message(self, message, sender, timestamp):\n        # Assign a value to first_agent_in_queue before using it\n        first_agent_in_queue = self.speaking_queue[0] if self.speaking_queue else None\n\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n        await self.update_speaking_queue()\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):  \n                await agent.speak() \n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        first_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n    def add_to_speaking_queue(self, agent):\n        if agent.name not in self.speaking_queue:\n            self.speaking_queue.append(agent.name)\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n    \n    def get_speaking_queue(self):\n        return self.speaking_queue            \n\n    def add_agent(self, agent: Agent):\n        self.agents[agent.name] = agent\n        self.typing_status[agent.name] = False  \n\n    def remove_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        del self.agents[agent_name]\n\n    def get_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        return self.agents[agent_name]\n\n    def add_to_chat_history(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = 100\n                self.agents[agent_name].tagged = True\n                print(f\"Tagged agent: {agent_name}\")  # Debug print\n        return mentioned_agents\n\n\n    def add_tagged_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.tagged and agent.name not in self.speaking_queue.queue:    \n                self.speaking_queue.add(agent.name)\n                agent.tagged = False\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def add_high_pressure_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n                self.speaking_queue.add(agent.name)\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def trigger_next_speaker(self):\n        if self.speaking_queue:\n            next_speaker = self.get_agent(self.speaking_queue.pop())  # Remove the agent from the queue\n\n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n        \n        most_relevant_agent = None\n        highest_relevancy_score = -1\n\n        for agent in self.agents.values():\n            chat_context = self.chat_history.truncated_chat_history\n            relevancy_score = await agent.calculate_relevancy(chat_context) \n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n\n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent and self.speaking_queue and self.speaking_queue[0] != most_relevant_agent.name:\n            self.speaking_queue.insert(0, most_relevant_agent.name) \n\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n        self.trigger_next_speaker()\n\n    def get_sorted_agents_based_on_relevancy(self):\n        return sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history) if agent.calculate_relevancy(self.chat_history) is not None else 0, reverse=True)\n\n    async def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent_name, agent in self.agents.items():\n            relevancy_score = await agent.calculate_relevancy(self.chat_history) \n            agents_info.append({\n                \"name\": agent_name,\n                \"speaking_pressure\": agent.speaking_pressure,\n                \"speaking_pressure_increment\": agent.speaking_pressure_increment, \n                \"context\": agent.context,\n                \"agent_type\": agent.agent_type,\n                \"relevancy_score\": relevancy_score  # Return the actual score here\n            })\n        return agents_info ",
      "created_at": "2023-05-14T02:29:44.534193",
      "sequence_order": 26,
      "parent_id": "5536998e-a197-4ca0-86bd-6a703c0943e2",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "39bc6f52-91ac-47b9-b2f9-658f5bd40fb8",
      "role": "assistant",
      "content": "From the script you have provided, it appears that you are creating an environment in which multiple AI models, such as OpenAI's GPT-3 and a custom GPT4All model, can interact with each other and respond to user inputs. Your `Parliament` class orchestrates these interactions, managing a \"speaking queue\" of agents and providing a mechanism for agents to \"speak\" (i.e., generate a response).\n\nHowever, you're indicating that the `get_response` method in the `Parliament` class is broken. Here are a few things that might be causing issues:\n\n1. **Incorrect Indentation in the OpenAIAgent's `get_response` method**: The messages array is being defined and then immediately used within the first iteration of the loop. The array should be populated entirely before being used. It seems you have an indentation error.\n\n   Here's the corrected code:\n   ```python\n    def get_response(self, chat_history):\n        system_msg = self.initial_context\n        messages = [{\"role\": \"system\", \"content\": system_msg}]\n        for message in chat_history:\n            role = message[\"sender\"]\n            msg = message[\"message\"]\n            messages.append({\"role\": \"assistant\" if role != \"assistant\" else role, \"content\": msg})\n   \n        max_retries = 3\n        retry_delay = 5\n        # Rest of your code...\n   ```\n\n2. **Assuming every agent has a `speak` method**: In the `broadcast_message` method of `Parliament`, you call `agent.speak()`, assuming that every agent has a `speak` method. But from the provided code, neither `OpenAIAgent` nor `GPT4AllAgent` has a `speak` method.\n\n3. **Use of async functions**: There are several methods in your `Parliament` class that are marked `async`, such as `broadcast_message` and `update_speaking_queue`. However, the methods they call (such as `agent.speak()`) are not `async`, nor are they awaited. It would be advisable to make sure all of your async/await usage is consistent and correct.\n\n4. **Undefined variables and constants**: Variables like `SPEAKING_PRESSURE_LIMIT` and `BROADCAST_DELAY` are used but not defined in the provided code. Also, your `Parliament` class uses `self.parliament.chat_history.truncated_chat_history` in the `get_response` method, but it's not clear what `self.parliament` is or where it comes from. \n\n5. **Agent's `get_response` method usage**: In your Parliament class, you're not actually calling any of the agents' `get_response` methods. You're just calling `agent.speak()`, which as per your code, does not exist. \n\nWithout more information, it's hard to provide a more detailed answer. The above points should be a good start for debugging. It would be beneficial to have a clear understanding of what exactly you want to accomplish, and then making sure that each part of your code is working as expected, possibly by writing tests for individual components. You may also find it helpful to include logging statements in your code to track the flow of execution and identify where things might be going wrong.",
      "created_at": "2023-05-14T02:30:43.851398",
      "sequence_order": 27,
      "parent_id": "aaa21387-c7b1-4d42-aa3e-f568b104af93",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2e6c7-72a7-42cb-8389-fed254f6f450",
      "role": "user",
      "content": "should truncated chat history just be a string not an array?\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = [] \n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history() \n\n    def truncate_chat_history(self, max_length=2000):\n        \"\"\"\n        Truncate the chat history to the last max_length characters.\n        \"\"\"\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def last_message(self):\n        return self.chat_history[-1] if self.chat_history else None",
      "created_at": "2023-05-14T02:50:20.183979",
      "sequence_order": 28,
      "parent_id": "39bc6f52-91ac-47b9-b2f9-658f5bd40fb8",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "0f1c1ac6-0f54-4fcf-bcc8-a12d2ed971ff",
      "role": "assistant",
      "content": "The `truncate_chat_history` method seems to be trying to keep the last `max_length` characters of the chat history, which is a reasonable approach if you're looking to limit the amount of text that you're sending to the model for context. If that's the case, then `truncated_chat_history` should indeed be a string.\n\nHowever, you're currently initializing `truncated_chat_history` as a list (`[]`) in the `ChatHistory` constructor (`__init__` method), which could cause confusion. If you're planning to use it as a string, then it should be initialized as an empty string (`''`).\n\nYour class would then look like:\n\n```python\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = ''  # Initialize as an empty string\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history() \n\n    def truncate_chat_history(self, max_length=2000):\n        \"\"\"\n        Truncate the chat history to the last max_length characters.\n        \"\"\"\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def last_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n```\n\nRemember, when you pass `truncated_chat_history` to your models, you may need to handle it differently depending on the model. If your model expects an array of messages, you would need to convert this string back into an appropriate format.",
      "created_at": "2023-05-14T02:50:46.031279",
      "sequence_order": 29,
      "parent_id": "aaa2e6c7-72a7-42cb-8389-fed254f6f450",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa28af5-1701-4e1f-a1e4-38d84407b3ac",
      "role": "user",
      "content": "calculating relevancy doesn't seem to be working?\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.speaking_pressure = speaking_pressure_increment\n        self.tagged = False\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.is_speaking = False\n        self.relevancy_score = None\n\n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue\n\n    # async def update_relevancy(self): \n    #     self.relevancy_score = self.calculate_relevancy(self.parliament.chat_history.truncated_chat_history)\n    #     agent_info = [\n    #         {\n    #             \"name\": self.name,\n    #             \"relevancy_score\": self.relevancy_score  \n    #         }\n    #     ]\n    #     await self.websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info})) \n        \n    async def calculate_relevancy(self, chat_context: str) -> int:\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"Return the result as a number by answering how relevant, from 0-100 is this agent and their context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n            print(prompt)\n            max_attempts = 3\n            attempt = 1\n            relevancy_score = 0\n\n            while attempt <= max_attempts:\n                try:\n                    response = openai.Completion.create(\n                        engine=\"text-davinci-001\",\n                        prompt=prompt,\n                        max_tokens=150,\n                        temperature=0.0,\n                        n=1,\n                        stop=None\n                        )\n\n                    completions = response.choices[0].text.strip().split(\"\\n\")\n                    print(completions)\n                    score = int(completions[-1].strip())\n\n                    if 0 <= score <= 100:  # Check if score is within valid range\n                        relevancy_score = score\n                        break  # Break out of the loop if a valid relevancy score is obtained\n\n                    else:\n                        print(\"Invalid response received. Please enter a number from 0 to 100.\")\n\n                except (ValueError, KeyError):\n                    print(\"Invalid response received. Please enter a valid number.\")\n\n                attempt += 1\n            self.initial_context = chat_context\n            self.relevancy_score = relevancy_score\n            print(f\"Relevancy score for {self.name}: {self.relevancy_score}%\")\n        else:\n            print(\"Using cached relevancy score...\")\n        return min(self.relevancy_score, 100) # Cap maximum score at 100\n    \n\n\n    def should_speak(self):\n        return self.parliament.speaker_manager.should_speak(self)  # Call parliament's speaker_manager\n\n    async def increment_pressure(self):\n        while True:\n            self.speaking_pressure += self.speaking_pressure_increment\n\n    def get_agent_message(self, truncated_chat_history):\n        \"\"\"\n        Generate a message from this agent based on the current chat history.\n        \"\"\"\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n    \n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue.queue\n    \n    async def speak(self):\n        truncated_chat_history = self.parliament.chat_history.truncated_chat_history\n        if self.should_speak():\n            self.is_speaking = True\n            await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n            await self.websocket.send(json.dumps({\"action\": STOPPED_TYPING, \"sender\": self.name}))\n            agent_message = self.get_agent_message(self.parliament.chat_history)\n            await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n            self.speaking_pressure = 0\n            self.is_speaking = False\n            if self.in_queue():\n                self.parliament.speaking_queue.remove(self.name)\n\n    def reset_pressure(self):\n        self.speaking_pressure = 0\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history() \n\n    def truncate_chat_history(self, max_length=2000):\n        \"\"\"\n        Truncate the chat history to the last max_length characters.\n        \"\"\"\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def last_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {} \n\n    def set_typing_status(self, agent_name: str, status: bool):\n        self.typing_status[agent_name] = status\n\n    def get_typing_status(self, agent_name: str):\n        return self.typing_status.get(agent_name, False)\n\n    async def broadcast_message(self, message, sender, timestamp):\n        # Assign a value to first_agent_in_queue before using it\n        first_agent_in_queue = self.speaking_queue[0] if self.speaking_queue else None\n\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n        await self.update_speaking_queue()\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):  \n                await agent.speak() \n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        first_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n    def add_to_speaking_queue(self, agent):\n        if agent.name not in self.speaking_queue:\n            self.speaking_queue.append(agent.name)\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n    \n    def get_speaking_queue(self):\n        return self.speaking_queue            \n\n    def add_agent(self, agent: Agent):\n        self.agents[agent.name] = agent\n        self.typing_status[agent.name] = False  \n\n    def remove_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        del self.agents[agent_name]\n\n    def get_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        return self.agents[agent_name]\n\n    def add_to_chat_history(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = 100\n                self.agents[agent_name].tagged = True\n                print(f\"Tagged agent: {agent_name}\")  # Debug print\n        return mentioned_agents\n\n    def add_tagged_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.tagged and agent.name not in self.speaking_queue.queue:    \n                self.speaking_queue.add(agent.name)\n                agent.tagged = False\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def add_high_pressure_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n                self.speaking_queue.add(agent.name)\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def trigger_next_speaker(self):\n        if self.speaking_queue:\n            next_speaker = self.get_agent(self.speaking_queue.pop())  # Remove the agent from the queue\n\n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n        \n        most_relevant_agent = None\n        highest_relevancy_score = -1\n\n        for agent in self.agents.values():\n            truncated_chat_history = self.chat_history.truncated_chat_history\n            relevancy_score = await agent.calculate_relevancy(truncated_chat_history) \n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n\n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent and self.speaking_queue and self.speaking_queue[0] != most_relevant_agent.name:\n            self.speaking_queue.insert(0, most_relevant_agent.name) \n\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n        self.trigger_next_speaker()\n\n    #def get_sorted_agents_based_on_relevancy(self):\n    #    return sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history) if agent.calculate_relevancy(self.chat_history) is not None else 0, reverse=True)\n\n    async def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent_name, agent in self.agents.items():\n            agents_info.append({\n                \"name\": agent_name,\n                \"speaking_pressure\": agent.speaking_pressure,\n                \"speaking_pressure_increment\": agent.speaking_pressure_increment, \n                \"context\": agent.context,\n                \"agent_type\": agent.agent_type,\n                \"relevancy_score\": agent.relevancy_score  # Return the cached score\n            })\n        return agents_info ",
      "created_at": "2023-05-14T02:52:39.722791",
      "sequence_order": 30,
      "parent_id": "0f1c1ac6-0f54-4fcf-bcc8-a12d2ed971ff",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "7263767e-5071-4069-b181-8458b3926af5",
      "role": "assistant",
      "content": "First, I assume that you are calling the `update_speaking_queue` function somewhere in your program, which in turn calls the `calculate_relevancy` method for each agent. If not, the `calculate_relevancy` method will never be executed.\n\nThe issue might come from this line in your `calculate_relevancy` method:\n\n```python\nresponse = openai.Completion.create(\n    engine=\"text-davinci-001\",\n    prompt=prompt,\n    max_tokens=150,\n    temperature=0.0,\n    n=1,\n    stop=None\n    )\n```\n\nYou are trying to use OpenAI's GPT-3 API to generate a completion for a prompt that asks the model to rate the relevancy of an agent to a conversation. The model is then expected to output a number between 0 and 100. \n\nHowever, there are a few potential issues here:\n\n1. **Prompt formulation**: The prompt you're using is complex and might not be well understood by the model. Here is your current prompt:\n\n    ```python\n    prompt = f\"Return the result as a number by answering how relevant, from 0-100 is this agent and their context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n    ```\n    This prompt might be too complex for the model to understand, especially when the contexts are long. Consider simplifying and clarifying the prompt.\n\n2. **Model choice**: The DaVinci model might not be the best choice for this task. While it's the most capable model offered by OpenAI, it's also the most expensive and the slowest. Unless the task requires complex reasoning or understanding, you might want to consider using a smaller model like Curie or Babbage.\n\n3. **API call errors**: Make sure you're correctly calling the OpenAI API and that your API key is correctly set up. If the API call fails, it could explain why the relevancy calculation isn't working. You should add some error handling to catch any potential API errors.\n\n4. **Rate Limit**: Ensure that you're not hitting any rate limits. If you're making too many requests to OpenAI's API in a short period of time, your requests might be throttled, causing some requests to fail.\n\n5. **Extracting the score**: You're expecting the last line of the model's output to be a number between 0 and 100. If the model's output doesn't meet this expectation, the score extraction will fail. Make sure the model's output is as expected.\n\nTry to debug your `calculate_relevancy` method by printing out the model's output and any potential errors from the API call. This should help you identify where the problem is.",
      "created_at": "2023-05-14T02:53:41.115209",
      "sequence_order": 31,
      "parent_id": "aaa28af5-1701-4e1f-a1e4-38d84407b3ac",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa231a5-06d4-493c-b914-448426a6e5a3",
      "role": "user",
      "content": "errors:\nReturn the result as a number by answering how relevant, from 0-100 is this agent and their context: 'Hello assistant, your name is: @Green Hat and your context is I generate new ideas and creative solutions.. Your job is to help hi by discussing hihi alongside your fellow agents in a parliament, which is a sort of town hall or large meeting, called hihi. The other agents discussing with you are White Hat, Red Hat, Black Hat, Yellow Hat, Blue Hat, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is 7 out of 100' for this conversation: 'hi all redhats', remember only respond with a number from 0 to 100? \nconnection handler failed\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/openai/api_requestor.py\", line 677, in _interpret_response_line\n    data = json.loads(rbody)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 37, in chat\n    await self.handle_send_message(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 74, in handle_send_message\n    await self.parliament.broadcast_message(user_message, sender, timestamp)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 257, in broadcast_message\n    await self.update_speaking_queue()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 342, in update_speaking_queue\n    relevancy_score = await agent.calculate_relevancy(truncated_chat_history)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 56, in calculate_relevancy\n    response = openai.Completion.create(\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/openai/api_resources/completion.py\", line 25, in create\n    return super().create(*args, **kwargs)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n    response, _, api_key = requestor.request(\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/openai/api_requestor.py\", line 230, in request\n    resp, got_stream = self._interpret_response(result, stream)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/openai/api_requestor.py\", line 624, in _interpret_response\n    self._interpret_response_line(\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/openai/api_requestor.py\", line 679, in _interpret_response_line\n    raise error.APIError(\nopenai.error.APIError: HTTP code 400 from API (<html>\n  <head>\n    <title>Bad Request</title>\n  </head>\n  <body>\n    <h1><p>Bad Request</p></h1>\n    Invalid HTTP header name: &#x27;X-ORIGINAL\\rFORWARDED-FOR&#x27;\n  </body>\n</html>\n",
      "created_at": "2023-05-14T02:54:12.455190",
      "sequence_order": 32,
      "parent_id": "7263767e-5071-4069-b181-8458b3926af5",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "25d04762-68c4-4b1e-9b74-40720d949558",
      "role": "assistant",
      "content": "The error appears to be a result of a malformed HTTP request being sent to the OpenAI API. More specifically, it seems that there's an issue with the 'X-ORIGINAL\\rFORWARDED-FOR' HTTP header which is invalid.\n\nThis kind of error typically arises when there's a mistake in the request configuration or in the underlying library used to make the HTTP request. It's likely a bug in the code that's building the HTTP request to the OpenAI API, possibly the server.py file. It may also be an issue with the version of the library being used to make the request.\n\nTo fix this issue, I would recommend the following steps:\n\n1. Review the server.py file, particularly where the request is being made to the OpenAI API. Make sure the headers are set correctly.\n\n2. Check the version of the library (such as requests or urllib in Python) being used to make the HTTP request. If it's outdated, consider updating it to the latest stable version.\n\n3. If you're using any middleware or proxy that might be altering the HTTP headers, consider bypassing it or checking its configuration.\n\n4. If none of the above steps work, consider reaching out to OpenAI support for further assistance.\n\nWithout more information about your setup and the code you're using, it's hard to provide more specific advice. However, I hope this general guidance can help you start troubleshooting the issue.",
      "created_at": "2023-05-14T02:54:38.030431",
      "sequence_order": 33,
      "parent_id": "aaa231a5-06d4-493c-b914-448426a6e5a3",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2497b-5194-4b8b-9902-cfc200bbdb29",
      "role": "user",
      "content": "can you write. a calculate relevancy from scratch using curie or ada from open ai?\n    async def calculate_relevancy(self, chat_context: str) -> int:\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"Return the result as a number by answering how relevant, from 0-100 is this agent and their context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n      ",
      "created_at": "2023-05-14T02:56:27.794235",
      "sequence_order": 34,
      "parent_id": "25d04762-68c4-4b1e-9b74-40720d949558",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "391710b3-253c-456c-a6b5-c5fb4eedccae",
      "role": "assistant",
      "content": "Sure, here's a simple way to calculate relevancy using the OpenAI API with Curie or Ada:\n\n```python\nimport openai\nimport asyncio\nimport os\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")  # your OpenAI API key\n\nclass Agent:\n    def __init__(self, initial_context):\n        self.initial_context = initial_context\n        self.relevancy_score = None\n\n    async def calculate_relevancy(self, chat_context):\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"Return the result as a number by answering how relevant, from 0-100 is this agent and their context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n            response = openai.Completion.create(\n                engine=\"text-davinci-002\",  # or \"text-curie-002\" for Curie\n                prompt=prompt,\n                temperature=0.5,\n                max_tokens=100\n            )\n            # Here we assume the model's response will be a single number.\n            # The strip is used to remove any whitespace around the number\n            relevancy_score = int(response.choices[0].text.strip())\n        return relevancy_score\n\nasync def main():\n    agent = Agent(\"I'm a helpful assistant\")\n    relevancy_score = await agent.calculate_relevancy(\"Can you help me with my math homework?\")\n    print(f\"The relevancy score is {relevancy_score}\")\n\nasyncio.run(main())\n```\n\nThis script defines an `Agent` class with an `initial_context` and a method `calculate_relevancy` to compute the relevancy of the agent given a `chat_context`. It creates a `prompt` that asks how relevant the agent is for the given conversation and uses the OpenAI API to get a response to this prompt. The `int()` function is used to convert the response from a string to an integer.\n\nNote that in practice, the model's response might not always be a valid number, so you should add error handling code to handle cases where the response can't be converted to an integer. You should also consider setting a default relevancy score in case the model does not return a valid number.\n\nPlease replace `\"text-davinci-002\"` with `\"text-curie-002\"` if you want to use Curie, or `\"text-ada-002\"` for Ada.",
      "created_at": "2023-05-14T02:57:14.097614",
      "sequence_order": 35,
      "parent_id": "aaa2497b-5194-4b8b-9902-cfc200bbdb29",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa25d80-274b-445d-9fb9-04c4f8fbf4e8",
      "role": "user",
      "content": "can you add print functions to     async def calculate_relevancy(self, chat_context):\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"Return the result as a number by answering how relevant, from 0-100 is this agent and their context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n            response = openai.Completion.create(\n                engine=\"text-davinci-002\",  # or \"text-curie-002\" for Curie\n                prompt=prompt,\n                temperature=0.5,\n                max_tokens=100\n            )\n            # Here we assume the model's response will be a single number.\n            # The strip is used to remove any whitespace around the number\n            relevancy_score = int(response.choices[0].text.strip())\n        return relevancy_score\n\nto debug",
      "created_at": "2023-05-14T02:58:12.658340",
      "sequence_order": 36,
      "parent_id": "391710b3-253c-456c-a6b5-c5fb4eedccae",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "edde9c66-24e7-453c-86e6-c2c6e73aec17",
      "role": "assistant",
      "content": "Sure, you can add print statements in various places to help with debugging. Here's an updated version of your code with additional print statements:\n\n```python\nimport openai\nimport asyncio\nimport os\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")  # your OpenAI API key\n\nclass Agent:\n    def __init__(self, initial_context):\n        self.initial_context = initial_context\n        self.relevancy_score = None\n\n    async def calculate_relevancy(self, chat_context):\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"Return the result as a number by answering how relevant, from 0-100 is this agent and their context: '{self.initial_context}' for this conversation: '{chat_context}', remember only respond with a number from 0 to 100? \"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-002\",  # or \"text-curie-002\" for Curie\n                prompt=prompt,\n                temperature=0.5,\n                max_tokens=100\n            )\n            print(f\"Response: {response}\")\n            # Here we assume the model's response will be a single number.\n            # The strip is used to remove any whitespace around the number\n            relevancy_score = int(response.choices[0].text.strip())\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        return relevancy_score\n\nasync def main():\n    agent = Agent(\"I'm a helpful assistant\")\n    relevancy_score = await agent.calculate_relevancy(\"Can you help me with my math homework?\")\n    print(f\"The final relevancy score is {relevancy_score}\")\n\nasyncio.run(main())\n```\n\nIn this version, we're printing:\n\n1. The prompt that is sent to the model.\n2. The full response from the model.\n3. The parsed relevancy score.\n4. A message when the relevancy score has already been calculated, and it's not necessary to recalculate it. \n\nThese print statements should give you a good idea of what's happening during execution.",
      "created_at": "2023-05-14T02:58:46.750899",
      "sequence_order": 37,
      "parent_id": "aaa25d80-274b-445d-9fb9-04c4f8fbf4e8",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa26bcf-b3b2-48fc-9d7f-8144d6302798",
      "role": "user",
      "content": "for this function strip everything except a number from the response and return only the number:\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",  # or \"text-curie-002\" for Curie\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            # Here we assume the model's response will be a single number.\n            # The strip is used to remove any whitespace around the number\n            relevancy_score = int(response.choices[0].text.strip())\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n    ",
      "created_at": "2023-05-14T03:12:29.704248",
      "sequence_order": 38,
      "parent_id": "edde9c66-24e7-453c-86e6-c2c6e73aec17",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "c2328abb-a5b9-4ec1-a1b9-5acd9d8d87cf",
      "role": "assistant",
      "content": "I understand that you want to ensure that the response from the model is a valid number between 0 and 100. You can use a regular expression to strip out everything but numbers from the response. Here's an updated version of your function:\n\n```python\nimport openai\nimport asyncio\nimport os\nimport re\nimport time\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")  # your OpenAI API key\n\nclass Agent:\n    def __init__(self, initial_context):\n        self.initial_context = initial_context\n        self.relevancy_score = None\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",  # or \"text-curie-002\" for Curie\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            # Here we use a regular expression to remove anything that isn't a digit\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            relevancy_score = int(stripped_response)\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n\nasync def main():\n    agent = Agent(\"I'm a helpful assistant\")\n    relevancy_score = await agent.calculate_relevancy(\"Can you help me with my math homework?\")\n    print(f\"The final relevancy score is {relevancy_score}\")\n\nasyncio.run(main())\n```\n\nThis version uses the `re.sub` function to remove anything from the response that isn't a digit (0-9). This ensures that when the string is converted to an integer, it won't cause an error. However, please note that if the model's response doesn't contain any digits, this will cause a `ValueError` when trying to convert the empty string to an integer. You may want to add error handling to account for this possibility.",
      "created_at": "2023-05-14T03:13:17.365323",
      "sequence_order": 39,
      "parent_id": "aaa26bcf-b3b2-48fc-9d7f-8144d6302798",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa26c08-0b88-47fb-af85-19df4135863b",
      "role": "user",
      "content": "add a catch if there's no number return 0",
      "created_at": "2023-05-14T03:15:42.325414",
      "sequence_order": 40,
      "parent_id": "c2328abb-a5b9-4ec1-a1b9-5acd9d8d87cf",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "1135264c-7c0d-4df8-9dbb-4e36f70d6d01",
      "role": "assistant",
      "content": "Sure, adding a try-except block to handle any potential `ValueError` would take care of that. Here's how to modify the function:\n\n```python\nimport openai\nimport asyncio\nimport os\nimport re\nimport time\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")  # your OpenAI API key\n\nclass Agent:\n    def __init__(self, initial_context):\n        self.initial_context = initial_context\n        self.relevancy_score = None\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",  # or \"text-curie-002\" for Curie\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            # Here we use a regular expression to remove anything that isn't a digit\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            # Try to convert the response to an integer, if it fails, return 0\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n\nasync def main():\n    agent = Agent(\"I'm a helpful assistant\")\n    relevancy_score = await agent.calculate_relevancy(\"Can you help me with my math homework?\")\n    print(f\"The final relevancy score is {relevancy_score}\")\n\nasyncio.run(main())\n```\n\nThis version of the function uses a try-except block to handle any `ValueError` that might occur when trying to convert the stripped response to an integer. If the conversion fails, it sets `relevancy_score` to 0.",
      "created_at": "2023-05-14T03:16:28.438970",
      "sequence_order": 41,
      "parent_id": "aaa26c08-0b88-47fb-af85-19df4135863b",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa26d4c-1581-4925-b624-876b041e86aa",
      "role": "user",
      "content": "is update speaker queue logic right?\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {} \n\n    def set_typing_status(self, agent_name: str, status: bool):\n        self.typing_status[agent_name] = status\n\n    def get_typing_status(self, agent_name: str):\n        return self.typing_status.get(agent_name, False)\n\n    async def broadcast_message(self, message, sender, timestamp):\n        # Assign a value to first_agent_in_queue before using it\n        first_agent_in_queue = self.speaking_queue[0] if self.speaking_queue else None\n\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n        await self.update_speaking_queue()\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):  \n                await agent.speak() \n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        first_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n    def add_to_speaking_queue(self, agent):\n        if agent.name not in self.speaking_queue:\n            self.speaking_queue.append(agent.name)\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n    \n    def get_speaking_queue(self):\n        return self.speaking_queue            \n\n    def add_agent(self, agent: Agent):\n        self.agents[agent.name] = agent\n        self.typing_status[agent.name] = False  \n\n    def remove_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        del self.agents[agent_name]\n\n    def get_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        return self.agents[agent_name]\n\n    def add_to_chat_history(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = 100\n                self.agents[agent_name].tagged = True\n                print(f\"Tagged agent: {agent_name}\")  # Debug print\n        return mentioned_agents\n\n    def add_tagged_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.tagged and agent.name not in self.speaking_queue.queue:    \n                self.speaking_queue.add(agent.name)\n                agent.tagged = False\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def add_high_pressure_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n                self.speaking_queue.add(agent.name)\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def trigger_next_speaker(self):\n        if self.speaking_queue:\n            next_speaker = self.get_agent(self.speaking_queue.pop())  # Remove the agent from the queue\n\n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n        \n        most_relevant_agent = None\n        highest_relevancy_score = -1\n\n        for agent in self.agents.values():\n            truncated_chat_history = self.chat_history.truncated_chat_history\n            relevancy_score = await agent.calculate_relevancy(truncated_chat_history) \n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n\n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent and self.speaking_queue and self.speaking_queue[0] != most_relevant_agent.name:\n            self.speaking_queue.insert(0, most_relevant_agent.name) \n\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n        self.trigger_next_speaker()\n\n    #def get_sorted_agents_based_on_relevancy(self):\n    #    return sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history) if agent.calculate_relevancy(self.chat_history) is not None else 0, reverse=True)\n\n    async def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent_name, agent in self.agents.items():\n            agents_info.append({\n                \"name\": agent_name,\n                \"speaking_pressure\": agent.speaking_pressure,\n                \"speaking_pressure_increment\": agent.speaking_pressure_increment, \n                \"context\": agent.context,\n                \"agent_type\": agent.agent_type,\n                \"relevancy_score\": agent.relevancy_score  # Return the cached score\n            })\n        return agents_info ",
      "created_at": "2023-05-14T03:20:11.070301",
      "sequence_order": 42,
      "parent_id": "1135264c-7c0d-4df8-9dbb-4e36f70d6d01",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "157ba8ed-4f3f-499c-b914-4c0ea09584d1",
      "role": "assistant",
      "content": "The logic for updating the speaker queue in your `Parliament` class seems well-implemented. Here's a summary of what it's doing:\n\n1. In the `update_speaking_queue` method, it loops through each agent and calculates the relevancy of that agent to the current chat context. It tracks the agent with the highest relevancy score. If this agent is not currently the first in the speaking queue, it is inserted at the beginning of the queue. \n\n2. It calls the `add_tagged_agents_to_queue` method to add any agents that have been tagged (mentioned) in the most recent chat message to the queue. The speaking pressure for these agents is reset to zero, and their tagged status is reset to False. \n\n3. It calls the `add_high_pressure_agents_to_queue` method to add any agents whose speaking pressure has exceeded a certain threshold (in this case, 100) to the queue. Again, the speaking pressure for these agents is reset to zero.\n\n4. Finally, it calls the `trigger_next_speaker` method to prompt the next agent in the queue to speak.\n\nOne thing to note is that if an agent is already in the queue and is tagged or its speaking pressure exceeds the threshold, it is not added to the queue again. This is controlled by checking `agent.name not in self.speaking_queue.queue` before adding an agent to the queue.\n\nAlso, the `trigger_next_speaker` method currently just removes the next speaker from the queue without doing anything else. You probably want to add some functionality here to actually prompt the next speaker to speak.\n\nFinally, the `update_speaking_queue` method only considers the most relevant agent, regardless of their current speaking pressure or whether they were tagged in the most recent message. Depending on your specific use case, you might want to modify this to take these factors into account as well.",
      "created_at": "2023-05-14T03:20:50.005077",
      "sequence_order": 43,
      "parent_id": "aaa26d4c-1581-4925-b624-876b041e86aa",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa20b2a-cffa-4ef0-b7f9-c533e09bf279",
      "role": "user",
      "content": "can you add trigger next speaker with     def get_response(self, truncated_chat):\n",
      "created_at": "2023-05-14T03:21:34.816754",
      "sequence_order": 44,
      "parent_id": "157ba8ed-4f3f-499c-b914-4c0ea09584d1",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "8be96df8-c90a-4f9a-ae75-13b84700ddaf",
      "role": "assistant",
      "content": "Sure, I assume you want to call the `get_response` function for the agent who is next in line to speak. The `get_response` function should be defined in your `Agent` class and should take the current chat context as input to generate a response. You can modify the `trigger_next_speaker` method like this:\n\n```python\ndef trigger_next_speaker(self):\n    if self.speaking_queue:\n        next_speaker_name = self.speaking_queue.pop(0)  # Remove the agent from the queue\n        next_speaker = self.get_agent(next_speaker_name)\n        response = next_speaker.get_response(self.chat_history.truncated_chat_history)\n        # Do something with the response, e.g. add to chat history, print it, etc.\n```\n\nThis will trigger the next speaker in the queue to generate a response based on the current chat context. However, please note that this response is not used anywhere. Depending on what you want to do with this response, you might want to add it to the chat history, print it, send it to some other function, etc. You'll need to add this functionality to the `trigger_next_speaker` method. Also note that the `get_response` method must be an asynchronous method if it makes an API call, like calling OpenAI's API to generate a response. In this case, `trigger_next_speaker` should also be an asynchronous method, and you should use `await` to call `get_response`:\n\n```python\nasync def trigger_next_speaker(self):\n    if self.speaking_queue:\n        next_speaker_name = self.speaking_queue.pop(0)  # Remove the agent from the queue\n        next_speaker = self.get_agent(next_speaker_name)\n        response = await next_speaker.get_response(self.chat_history.truncated_chat_history)\n        # Do something with the response, e.g. add to chat history, print it, etc.\n```",
      "created_at": "2023-05-14T03:22:08.899578",
      "sequence_order": 45,
      "parent_id": "aaa20b2a-cffa-4ef0-b7f9-c533e09bf279",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa20011-842b-45d6-b741-63a2b97d4ad0",
      "role": "user",
      "content": "Relevancy score: 1\n/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py:341: RuntimeWarning: coroutine 'Parliament.trigger_next_speaker' was never awaited\n  self.trigger_next_speaker()\n",
      "created_at": "2023-05-14T03:24:17.962556",
      "sequence_order": 46,
      "parent_id": "8be96df8-c90a-4f9a-ae75-13b84700ddaf",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "c7db8474-a549-441d-bcaa-b3fc0dcaab05",
      "role": "assistant",
      "content": "The warning message you're seeing is because you're calling an asynchronous function without `await`. In Python, when you define a function using `async def`, it becomes a coroutine function. This type of function is meant to be used with the `await` keyword, which allows the function to yield control back to the event loop and allows other tasks to run in the meantime.\n\nIn your case, the `trigger_next_speaker()` function is a coroutine (asynchronous function) and should be awaited when called. Here's how you can do it:\n\n```python\nawait self.trigger_next_speaker()\n```\n\nHowever, this line of code needs to be inside an asynchronous function as well. So, if you're calling it from a synchronous function or from the top level script, you need to use `asyncio.run()`:\n\n```python\nasyncio.run(self.trigger_next_speaker())\n```\n\nIt's important to remember that `asyncio.run()` should be used as a main entry point for asyncio programs, and should ideally only be called once.\n\nPlease also remember that any function that calls an `async def` function will also need to be an `async def` function. In other words, async \"infects\" the rest of your codebase; once a function is async, all functions that call it must be async as well. This can lead to quite a few changes in your codebase to handle async properly.",
      "created_at": "2023-05-14T03:24:46.390747",
      "sequence_order": 47,
      "parent_id": "aaa20011-842b-45d6-b741-63a2b97d4ad0",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa277b5-ca00-4505-b30b-58e8a9d77ba3",
      "role": "user",
      "content": "the update speaking queue expects the agent.calculate_relevancy to do one agent at a time and it does them all, how do we merge thees two functions to work together?\n\n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n        \n        most_relevant_agent = None\n        highest_relevancy_score = -1\n\n        for agent in self.agents.values():\n            truncated_chat_history = self.chat_history.truncated_chat_history\n            relevancy_score = await agent.calculate_relevancy(truncated_chat_history) \n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n\n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent and self.speaking_queue and self.speaking_queue[0] != most_relevant_agent.name:\n            self.speaking_queue.insert(0, most_relevant_agent.name) \n\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n        await self.trigger_next_speaker()\n\nagent class:",
      "created_at": "2023-05-14T03:30:16.003176",
      "sequence_order": 48,
      "parent_id": "c7db8474-a549-441d-bcaa-b3fc0dcaab05",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "0e1a7b88-b7a8-4140-b49f-106c7c541579",
      "role": "assistant",
      "content": "The code you posted does not include the `Agent` class, but I understand what you mean. In order to have the `calculate_relevancy` function process one agent at a time, you might consider using an asynchronous for loop (i.e., an `async for` loop) with an asynchronous generator, which yields agents one by one.\n\nThe structure would look something like this:\n\n```python\nasync def update_speaking_queue(self):\n    \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n    \n    most_relevant_agent = None\n    highest_relevancy_score = -1\n\n    async for agent in self.agent_generator():\n        truncated_chat_history = self.chat_history.truncated_chat_history\n        relevancy_score = await agent.calculate_relevancy(truncated_chat_history) \n        if relevancy_score > highest_relevancy_score:\n            highest_relevancy_score = relevancy_score\n            most_relevant_agent = agent\n\n    # Add the most relevant agent to the speaking queue\n    if most_relevant_agent and self.speaking_queue and self.speaking_queue[0] != most_relevant_agent.name:\n        self.speaking_queue.insert(0, most_relevant_agent.name) \n\n    self.add_tagged_agents_to_queue()\n    self.add_high_pressure_agents_to_queue()\n    await self.trigger_next_speaker()\n\nasync def agent_generator(self):\n    for agent in self.agents.values():\n        yield agent\n```\n\nThis way, the `calculate_relevancy` function will be called and awaited for each agent one at a time before moving onto the next agent.\n\nPlease note that this approach assumes that the `calculate_relevancy` function is an asynchronous function. If it is not, you don't need to use the `await` keyword and the `agent_generator` doesn't need to be an async generator. You can just use a regular for loop instead of an async for loop. \n\nIf the `calculate_relevancy` function does involve IO-bound tasks such as HTTP requests, it should ideally be an async function to allow for concurrency and better performance.",
      "created_at": "2023-05-14T03:30:49.424875",
      "sequence_order": 49,
      "parent_id": "aaa277b5-ca00-4505-b30b-58e8a9d77ba3",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa28d2e-ebfe-4cbd-9bc6-5f78fae5f0ef",
      "role": "user",
      "content": "the update speaking queue expects the agent.calculate_relevancy to do one agent at a time and it does them all, how do we merge thees two functions to work together?\n\n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n        \n        most_relevant_agent = None\n        highest_relevancy_score = -1\n\n        for agent in self.agents.values():\n            truncated_chat_history = self.chat_history.truncated_chat_history\n            relevancy_score = await agent.calculate_relevancy(truncated_chat_history) \n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n\n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent and self.speaking_queue and self.speaking_queue[0] != most_relevant_agent.name:\n            self.speaking_queue.insert(0, most_relevant_agent.name) \n\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n        await self.trigger_next_speaker()\n\nagent class:\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",  # or \"text-curie-002\" for Curie\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            # Here we assume the model's response will be a single number.\n            # The strip is used to remove any whitespace around the number\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score",
      "created_at": "2023-05-14T03:30:55.170433",
      "sequence_order": 50,
      "parent_id": "0e1a7b88-b7a8-4140-b49f-106c7c541579",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "1d28fcf2-b9e4-4809-9e79-c268b62fc854",
      "role": "assistant",
      "content": "The structure of your code looks correct. The function `calculate_relevancy` is correctly defined as asynchronous and is awaited for each agent in the `update_speaking_queue` function. \n\nHowever, it seems like you are using `openai.Completion.create()` which is not an asynchronous function. It means it will block the execution of the code while waiting for the response from the OpenAI API. This can slow down the whole process considerably as it will not make use of the advantages of asynchronous programming.\n\nAs of my knowledge cutoff in September 2021, the official OpenAI Python client does not support async operations. However, you could use a third-party library that supports async HTTP requests, such as `aiohttp`, and rewrite the request to the OpenAI API to be asynchronous.\n\nHere's an example of how you might do this with `aiohttp`:\n\n```python\nimport aiohttp\nimport json\n\nasync with aiohttp.ClientSession() as session:\n    async with session.post(\n        'https://api.openai.com/v1/engines/davinci-codex/completions',\n        headers={\"Authorization\": f\"Bearer {api_key}\"},\n        data=json.dumps({\n            \"prompt\": prompt,\n            \"temperature\": 0.0,\n            \"max_tokens\": 300\n        })\n    ) as resp:\n        response = await resp.json()\n```\n\nIn this example, replace `{api_key}` with your actual OpenAI API key.\n\nRemember, however, that using a third-party library for making requests to the OpenAI API is not officially supported by OpenAI, and you should do so at your own risk. Always ensure you're handling your API keys securely and following best practices for asynchronous programming.\n\nAlso, note that `time.sleep(.5)` in `calculate_relevancy` is a blocking operation. In an async function, you should use `await asyncio.sleep(.5)` instead to avoid blocking the event loop.\n\nPlease note that this solution assumes you have a basic understanding of Python's `asyncio` library and asynchronous programming in general. If you're not familiar with these concepts, you might want to take some time to learn about them before implementing this solution. Asynchronous programming can be quite tricky to get right, especially when combined with other advanced features like concurrency and parallelism.",
      "created_at": "2023-05-14T03:31:35.145683",
      "sequence_order": 51,
      "parent_id": "aaa28d2e-ebfe-4cbd-9bc6-5f78fae5f0ef",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2daec-d118-409a-8c18-250b2dc6fd73",
      "role": "user",
      "content": "what does this if statement do:        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent and self.speaking_queue and self.speaking_queue[0] != most_relevant_agent.name:\n            self.speaking_queue.insert(0, most_relevant_agent.name) \n can we make it simpler? ",
      "created_at": "2023-05-14T03:33:56.464408",
      "sequence_order": 52,
      "parent_id": "1d28fcf2-b9e4-4809-9e79-c268b62fc854",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "64c86afe-d675-4940-8aee-0f639f0935b5",
      "role": "assistant",
      "content": "This statement checks the following conditions:\n\n1. `most_relevant_agent`: It checks if the variable `most_relevant_agent` is not `None`. It's important because you don't want to add a non-existent agent (None) to the speaking queue.\n\n2. `self.speaking_queue`: It checks if `self.speaking_queue` is not empty. If the speaking queue is empty, `self.speaking_queue[0]` would raise an `IndexError`. \n\n3. `self.speaking_queue[0] != most_relevant_agent.name`: It checks if the most relevant agent is not already at the front of the speaking queue. If the agent is already at the front, there's no need to add it again.\n\nIf all three conditions are true, then the `most_relevant_agent` is inserted at the beginning of the speaking queue.\n\nWe can simplify this statement by using Python's `list.insert()` method, which won't raise an error even when the list is empty, and by using Python's `list.count()` method to check if the agent is already in the queue. Here's the simplified code:\n\n```python\n# Add the most relevant agent to the speaking queue\nif most_relevant_agent and self.speaking_queue.count(most_relevant_agent.name) == 0:\n    self.speaking_queue.insert(0, most_relevant_agent.name)\n```\n\nThis version of the code will add the `most_relevant_agent` to the front of the queue only if the agent is not `None` and it's not already in the queue, eliminating the need for the third condition in the original code. Please note that this will not check if the agent is at the front of the queue. If you want the agent to be placed in the front specifically, you might need to write additional code to handle that case.",
      "created_at": "2023-05-14T03:34:19.740552",
      "sequence_order": 53,
      "parent_id": "aaa2daec-d118-409a-8c18-250b2dc6fd73",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa28f9f-b668-41c0-ae31-d43b1f64eb0c",
      "role": "user",
      "content": "add logging to print to terminal for this function: \n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n        \n        most_relevant_agent = None\n        highest_relevancy_score = -1\n\n        for agent in self.agents.values():\n            truncated_chat_history = self.chat_history.truncated_chat_history\n            relevancy_score = await agent.calculate_relevancy(truncated_chat_history) \n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n\n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent and self.speaking_queue.count(most_relevant_agent.name) == 0:\n            self.speaking_queue.insert(0, most_relevant_agent.name)\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n        await self.trigger_next_speaker()\n",
      "created_at": "2023-05-14T03:37:47.751656",
      "sequence_order": 54,
      "parent_id": "64c86afe-d675-4940-8aee-0f639f0935b5",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "dcdf28e1-13a4-4f35-a81a-52bcb7de1490",
      "role": "assistant",
      "content": "Here's your function with added logging for each important step:\n\n```python\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\n\nasync def update_speaking_queue(self):\n    \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n\n    most_relevant_agent = None\n    highest_relevancy_score = -1\n\n    for agent in self.agents.values():\n        truncated_chat_history = self.chat_history.truncated_chat_history\n        relevancy_score = await agent.calculate_relevancy(truncated_chat_history) \n        if relevancy_score > highest_relevancy_score:\n            highest_relevancy_score = relevancy_score\n            most_relevant_agent = agent\n        logging.info(f\"Calculated relevancy for agent {agent.name}. Score: {relevancy_score}\")\n\n    # Add the most relevant agent to the speaking queue\n    if most_relevant_agent and self.speaking_queue.count(most_relevant_agent.name) == 0:\n        self.speaking_queue.insert(0, most_relevant_agent.name)\n        logging.info(f\"Added agent {most_relevant_agent.name} to the front of the speaking queue. Current queue: {self.speaking_queue}\")\n\n    self.add_tagged_agents_to_queue()\n    self.add_high_pressure_agents_to_queue()\n\n    logging.info(f\"Triggering next speaker...\")\n    await self.trigger_next_speaker()\n```\n\nThis will print the following types of messages to the terminal:\n\n- When it has calculated the relevancy for each agent.\n- When it has added the most relevant agent to the front of the speaking queue.\n- Before it triggers the next speaker.\n\nThe `logging.info()` function is used to write informational messages to the terminal. If you want to include debugging information or error messages, you can use `logging.debug()` and `logging.error()`, respectively.",
      "created_at": "2023-05-14T03:38:21.028434",
      "sequence_order": 55,
      "parent_id": "aaa28f9f-b668-41c0-ae31-d43b1f64eb0c",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2bd62-dc27-4524-ac15-de8e5bc9d1ea",
      "role": "user",
      "content": "just print to terminal no need for logging ",
      "created_at": "2023-05-14T03:38:24.043293",
      "sequence_order": 56,
      "parent_id": "dcdf28e1-13a4-4f35-a81a-52bcb7de1490",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "fc3cd46c-b3a6-476c-a197-b5a3693c3f1f",
      "role": "assistant",
      "content": "Alright, here's your function using `print()` instead of logging:\n\n```python\nasync def update_speaking_queue(self):\n    \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n\n    most_relevant_agent = None\n    highest_relevancy_score = -1\n\n    for agent in self.agents.values():\n        truncated_chat_history = self.chat_history.truncated_chat_history\n        relevancy_score = await agent.calculate_relevancy(truncated_chat_history) \n        if relevancy_score > highest_relevancy_score:\n            highest_relevancy_score = relevancy_score\n            most_relevant_agent = agent\n        print(f\"Calculated relevancy for agent {agent.name}. Score: {relevancy_score}\")\n\n    # Add the most relevant agent to the speaking queue\n    if most_relevant_agent and self.speaking_queue.count(most_relevant_agent.name) == 0:\n        self.speaking_queue.insert(0, most_relevant_agent.name)\n        print(f\"Added agent {most_relevant_agent.name} to the front of the speaking queue. Current queue: {self.speaking_queue}\")\n\n    self.add_tagged_agents_to_queue()\n    self.add_high_pressure_agents_to_queue()\n\n    print(f\"Triggering next speaker...\")\n    await self.trigger_next_speaker()\n```\n\nThis function will now print information directly to the terminal using the `print()` function.",
      "created_at": "2023-05-14T03:38:48.373420",
      "sequence_order": 57,
      "parent_id": "aaa2bd62-dc27-4524-ac15-de8e5bc9d1ea",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa27c40-14b4-4102-b711-22dbbb3572fb",
      "role": "user",
      "content": "why did I get the error:\nAdded agent Red Hat to the front of the speaking queue. Current queue: ['Red Hat']\nTriggering next speaker...\nconnection handler failed\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 37, in chat\n    await self.handle_send_message(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 74, in handle_send_message\n    await self.parliament.broadcast_message(user_message, sender, timestamp)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 243, in broadcast_message\n    await self.update_speaking_queue()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 344, in update_speaking_queue\n    await self.trigger_next_speaker()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 320, in trigger_next_speaker\n    response = await next_speaker.get_response(self.chat_history.truncated_chat_history)\nAttributeError: 'Agent' object has no attribute 'get_response'\n\n\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {} \n\n    def set_typing_status(self, agent_name: str, status: bool):\n        self.typing_status[agent_name] = status\n\n    def get_typing_status(self, agent_name: str):\n        return self.typing_status.get(agent_name, False)\n\n    async def broadcast_message(self, message, sender, timestamp):\n        # Assign a value to first_agent_in_queue before using it\n        first_agent_in_queue = self.speaking_queue[0] if self.speaking_queue else None\n\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n        await self.update_speaking_queue()\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):  \n                await agent.speak() \n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        first_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n    def add_to_speaking_queue(self, agent):\n        if agent.name not in self.speaking_queue:\n            self.speaking_queue.append(agent.name)\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n    \n    def get_speaking_queue(self):\n        return self.speaking_queue            \n\n    def add_agent(self, agent: Agent):\n        self.agents[agent.name] = agent\n        self.typing_status[agent.name] = False  \n\n    def remove_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        del self.agents[agent_name]\n\n    def get_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        return self.agents[agent_name]\n\n    def add_to_chat_history(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = 100\n                self.agents[agent_name].tagged = True\n                print(f\"Tagged agent: {agent_name}\")  # Debug print\n        return mentioned_agents\n\n    def add_tagged_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.tagged and agent.name not in self.speaking_queue.queue:    \n                self.speaking_queue.add(agent.name)\n                agent.tagged = False\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def add_high_pressure_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n                self.speaking_queue.add(agent.name)\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    async def trigger_next_speaker(self):\n        if self.speaking_queue:\n            next_speaker_name = self.speaking_queue.pop(0)  # Remove the agent from the queue\n            next_speaker = self.get_agent(next_speaker_name)\n            response = await next_speaker.get_response(self.chat_history.truncated_chat_history)\n    \n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n\n        most_relevant_agent = None\n        highest_relevancy_score = -1\n\n        for agent in self.agents.values():\n            truncated_chat_history = self.chat_history.truncated_chat_history\n            relevancy_score = await agent.calculate_relevancy(truncated_chat_history) \n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n            print(f\"Calculated relevancy for agent {agent.name}. Score: {relevancy_score}\")\n\n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent and self.speaking_queue.count(most_relevant_agent.name) == 0:\n            self.speaking_queue.insert(0, most_relevant_agent.name)\n            print(f\"Added agent {most_relevant_agent.name} to the front of the speaking queue. Current queue: {self.speaking_queue}\")\n\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n\n        print(f\"Triggering next speaker...\")\n        await self.trigger_next_speaker()\n    #def get_sorted_agents_based_on_relevancy(self):\n    #    return sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history) if agent.calculate_relevancy(self.chat_history) is not None else 0, reverse=True)\n\n    async def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent_name, agent in self.agents.items():\n            agents_info.append({\n                \"name\": agent_name,\n                \"speaking_pressure\": agent.speaking_pressure,\n                \"speaking_pressure_increment\": agent.speaking_pressure_increment, \n                \"context\": agent.context,\n                \"agent_type\": agent.agent_type,\n                \"relevancy_score\": agent.relevancy_score  # Return the cached score\n            })\n        return agents_info \n\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.speaking_pressure = speaking_pressure_increment\n        self.tagged = False\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.is_speaking = False\n        self.relevancy_score = None\n\n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",  # or \"text-curie-002\" for Curie\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            # Here we assume the model's response will be a single number.\n            # The strip is used to remove any whitespace around the number\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n    \n\n\n    def should_speak(self):\n        return self.parliament.speaker_manager.should_speak(self)  # Call parliament's speaker_manager\n\n    async def increment_pressure(self):\n        while True:\n            self.speaking_pressure += self.speaking_pressure_increment\n\n    def get_agent_message(self, truncated_chat_history):\n        \"\"\"\n        Generate a message from this agent based on the current chat history.\n        \"\"\"\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n    \n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue.queue\n    \n    async def speak(self):\n        truncated_chat_history = self.parliament.chat_history.truncated_chat_history\n        if self.should_speak():\n            self.is_speaking = True\n            await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n            await self.websocket.send(json.dumps({\"action\": STOPPED_TYPING, \"sender\": self.name}))\n            agent_message = self.get_agent_message(self.parliament.chat_history)\n            await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n            self.speaking_pressure = 0\n            self.is_speaking = False\n            if self.in_queue():\n                self.parliament.speaking_queue.remove(self.name)\n\n    def reset_pressure(self):\n        self.speaking_pressure = 0\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history() \n\n    def truncate_chat_history(self, max_length=2000):\n        \"\"\"\n        Truncate the chat history to the last max_length characters.\n        \"\"\"\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def last_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n",
      "created_at": "2023-05-14T03:43:15.910123",
      "sequence_order": 58,
      "parent_id": "fc3cd46c-b3a6-476c-a197-b5a3693c3f1f",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "d302726a-35df-48b8-8c5b-a74928ae1c6b",
      "role": "assistant",
      "content": "The error `AttributeError: 'Agent' object has no attribute 'get_response'` is happening because the `Agent` class in your code does not have a `get_response` method, yet it's being called here: `response = await next_speaker.get_response(self.chat_history.truncated_chat_history)`.\n\nTo resolve this, you need to ensure that every agent you're working with has a `get_response` method. In your code, the `OpenAIAgent` class has a `get_response` method, but the base `Agent` class does not. The error indicates that an instance of the `Agent` class (or a subclass without a `get_response` method) was added to the queue and then tried to respond.\n\nOne solution could be to make `get_response` an abstract method in the base `Agent` class, forcing all subclasses to implement it. Here's how you can do this:\n\n```python\nfrom abc import ABC, abstractmethod\n\nclass Agent(ABC):\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        # rest of your code\n\n    @abstractmethod\n    async def get_response(self, chat_history):\n        pass\n    # rest of your code\n```\n\nIn this case, any class that inherits from `Agent` will need to implement the `get_response` method, otherwise, you'll get a `TypeError` at the time of instantiation. You can then implement this method in each of your specific agent classes (like `OpenAIAgent`). Make sure the `get_response` in `OpenAIAgent` is an async function to match the base class.\n\n```python\nclass OpenAIAgent(Agent):\n    # rest of your code\n\n    async def get_response(self, truncated_chat):\n        # rest of your code\n```\n\nIf you're adding instances of `Agent` directly, you'll need to reconsider that, as `Agent` is now an abstract base class and should not be instantiated directly. Instead, consider creating specific agent classes for each type of agent you want to add to your parliament, ensuring each one implements the `get_response` method.\n",
      "created_at": "2023-05-14T03:43:56.670404",
      "sequence_order": 59,
      "parent_id": "aaa27c40-14b4-4102-b711-22dbbb3572fb",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2d3fa-3587-404a-be1d-58155a53797a",
      "role": "user",
      "content": "Relevancy score: 10011\nCalculated relevancy for agent Blue Hat. Score: 10011\nAdded agent White Hat to the front of the speaking queue. Current queue: ['White Hat']\nTriggering next speaker...\nconnection handler failed\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 37, in chat\n    await self.handle_send_message(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 74, in handle_send_message\n    await self.parliament.broadcast_message(user_message, sender, timestamp)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 238, in broadcast_message\n    await self.update_speaking_queue()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 342, in update_speaking_queue\n    await self.trigger_next_speaker()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 315, in trigger_next_speaker\n    response = await next_speaker.get_response(self.chat_history.truncated_chat_history)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 34, in get_response\n    agent_message = self.get_agent_message(truncated_chat_history)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 82, in get_agent_message\n    response = self.agent_instance.get_response(truncated_chat_history)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 142, in get_response\n    messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\nNameError: name 'messages' is not defined\n\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n\n",
      "created_at": "2023-05-14T03:51:13.599724",
      "sequence_order": 60,
      "parent_id": "d302726a-35df-48b8-8c5b-a74928ae1c6b",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "f387a826-15fd-416d-bc28-d339754cd53c",
      "role": "assistant",
      "content": "The error you're encountering is due to the variable `messages` not being defined in your `get_response` method of the `OpenAIAgent` class. The `messages` variable should be a list of message objects, where each object is a dictionary that represents a single message in the conversation. Each dictionary should have the keys `role` and `content`.\n\nYou're trying to append a message to `messages` but it seems you haven't initialized it. Here's how to fix the problem:\n\n```python\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages = []  # Initialize the messages list\n        messages.append({\"role\": \"assistant\", \"content\": system_msg})\n        messages.append({\"role\": \"user\", \"content\": truncated_chat})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n```\n\nIn the updated code, I've initialized `messages` as an empty list, then appended the system message (the assistant's initial context) and the user's message (the `truncated_chat`). Note that the `role` for the system message is \"assistant\" and the `role` for the user message is \"user\".",
      "created_at": "2023-05-14T03:52:07.381507",
      "sequence_order": 61,
      "parent_id": "aaa2d3fa-3587-404a-be1d-58155a53797a",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa20be9-57e1-4027-875b-45f24de76e47",
      "role": "user",
      "content": "Calculated relevancy for agent Cost Structure. Score: 1\nAdded agent Customer to the front of the speaking queue. Current queue: ['Customer']\nTriggering next speaker...\n A customer is a person, organization, or company that purchases goods or services from another person, organization, or company.\nconnection handler failed\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 37, in chat\n    await self.handle_send_message(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 74, in handle_send_message\n    await self.parliament.broadcast_message(user_message, sender, timestamp)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 239, in broadcast_message\n    await self.update_speaking_queue()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 343, in update_speaking_queue\n    await self.trigger_next_speaker()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 316, in trigger_next_speaker\n    response = await next_speaker.get_response(self.chat_history.truncated_chat_history)\nTypeError: object str can't be used in 'await' expression\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {} \n\n    def set_typing_status(self, agent_name: str, status: bool):\n        self.typing_status[agent_name] = status\n\n    def get_typing_status(self, agent_name: str):\n        return self.typing_status.get(agent_name, False)\n\n    async def broadcast_message(self, message, sender, timestamp):\n        # Assign a value to first_agent_in_queue before using it\n        first_agent_in_queue = self.speaking_queue[0] if self.speaking_queue else None\n\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n        await self.update_speaking_queue()\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):  \n                await agent.speak() \n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        first_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n    def add_to_speaking_queue(self, agent):\n        if agent.name not in self.speaking_queue:\n            self.speaking_queue.append(agent.name)\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n    \n    def get_speaking_queue(self):\n        return self.speaking_queue            \n\n    def add_agent(self, agent: Agent):\n        self.agents[agent.name] = agent\n        self.typing_status[agent.name] = False  \n\n    def remove_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        del self.agents[agent_name]\n\n    def get_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        return self.agents[agent_name]\n\n    def add_to_chat_history(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = 100\n                self.agents[agent_name].tagged = True\n                print(f\"Tagged agent: {agent_name}\")  # Debug print\n        return mentioned_agents\n\n    def add_tagged_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.tagged and agent.name not in self.speaking_queue.queue:    \n                self.speaking_queue.add(agent.name)\n                agent.tagged = False\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def add_high_pressure_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n                self.speaking_queue.add(agent.name)\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    async def trigger_next_speaker(self):\n        if self.speaking_queue:\n            next_speaker_name = self.speaking_queue.pop(0)  \n            next_speaker = self.get_agent(next_speaker_name)\n            response = await next_speaker.get_response(self.chat_history.truncated_chat_history)\n            print(f\"The next speaker is: {next_speaker.name}\") \n            print(f\"Message: {response}\")\n            \n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n\n        most_relevant_agent = None\n        highest_relevancy_score = -1\n\n        for agent in self.agents.values():\n            truncated_chat_history = self.chat_history.truncated_chat_history\n            relevancy_score = await agent.calculate_relevancy(truncated_chat_history) \n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n            print(f\"Calculated relevancy for agent {agent.name}. Score: {relevancy_score}\")\n\n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent and self.speaking_queue.count(most_relevant_agent.name) == 0:\n            self.speaking_queue.insert(0, most_relevant_agent.name)\n            print(f\"Added agent {most_relevant_agent.name} to the front of the speaking queue. Current queue: {self.speaking_queue}\")\n\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n\n        print(f\"Triggering next speaker...\")\n        await self.trigger_next_speaker()\n    #def get_sorted_agents_based_on_relevancy(self):\n    #    return sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history) if agent.calculate_relevancy(self.chat_history) is not None else 0, reverse=True)\n\n    async def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent_name, agent in self.agents.items():\n            agents_info.append({\n                \"name\": agent_name,\n                \"speaking_pressure\": agent.speaking_pressure,\n                \"speaking_pressure_increment\": agent.speaking_pressure_increment, \n                \"context\": agent.context,\n                \"agent_type\": agent.agent_type,\n                \"relevancy_score\": agent.relevancy_score  # Return the cached score\n            })\n        return agents_info ",
      "created_at": "2023-05-14T03:53:05.438827",
      "sequence_order": 62,
      "parent_id": "f387a826-15fd-416d-bc28-d339754cd53c",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "e9810ed0-6e75-470f-b67f-4b4fdc50ff09",
      "role": "assistant",
      "content": "It seems like there are several things going on in the provided code snippets which are causing errors. Here are a few issues I've noticed:\n\n1. NameError: name 'messages' is not defined: In the OpenAIAgent.get_response() method, you're trying to append to the `messages` list, but it has not been defined. You need to initialize it before appending to it.\n\n2. TypeError: object str can't be used in 'await' expression: This error is likely due to a string being used in an await expression, which is not allowed in Python. The 'await' keyword is used with coroutines, which are special functions that can be paused and resumed, allowing other tasks to run in the meantime. \n\n3. The Parliament class seems to be a managing class for handling multiple \"speaking\" agents. There are multiple methods related to managing the speaking queue and managing the agents. However, the design of these methods and the overall structure of the class may need some rethinking or restructuring. For example, in the method `broadcast_message`, you are popping the first agent from the queue twice, but it is not clear why this is necessary.\n\n4. You are using the `await` keyword with the `Agent.get_response()` and `Agent.calculate_relevancy()` methods, which suggests that these methods are designed to be coroutines, but in the provided code snippets, these methods do not appear to be defined as asynchronous.\n\n5. In the `trigger_next_speaker()` method, you are attempting to call `get_response()` on `next_speaker`, which could be a string according to your `speaking_queue` structure, causing the TypeError mentioned in point 2. You should ensure that `next_speaker` is an instance of an agent before calling `get_response()`.\n\nWithout more context about the rest of your code, it's hard to offer more specific advice. However, here are some general suggestions:\n\n- Make sure you fully understand asynchronous programming in Python, including how the `async` and `await` keywords work. This is crucial if you are planning to use these features in your project.\n\n- Try to simplify your code as much as possible. This will make it easier to understand and debug.\n\n- Consider writing unit tests for your methods. This can help you catch errors and unexpected behavior early in the development process.\n\n- If you're not already using one, consider using an Integrated Development Environment (IDE) with good Python support, like PyCharm or Visual Studio Code. These tools can provide helpful features like code linting and debugging, which can help you catch errors more easily.",
      "created_at": "2023-05-14T03:53:50.739525",
      "sequence_order": 63,
      "parent_id": "aaa20be9-57e1-4027-875b-45f24de76e47",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2e764-7ca7-4e94-8b8c-c5b3b4f6ed93",
      "role": "user",
      "content": "got this code error for the following code, help me fix it and find any other potential errors:\nRelevancy score: 50\nCalculated relevancy for agent Cost Structure. Score: 50\nAdded agent Value Proposition to the front of the speaking queue. Current queue: ['Value Proposition']\nTriggering next speaker...\n I'm sorry, I don't understand what you mean. Could you please provide more context or clarify your request?\nconnection handler failed\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 37, in chat\n    await self.handle_send_message(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 74, in handle_send_message\n    await self.parliament.broadcast_message(user_message, sender, timestamp)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 239, in broadcast_message\n    await self.update_speaking_queue()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 343, in update_speaking_queue\n    await self.trigger_next_speaker()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 316, in trigger_next_speaker\n    response = await next_speaker.get_response(self.chat_history.truncated_chat_history)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 82, in get_agent_message\n    response = await self.agent_instance.get_response(truncated_chat_history)\nTypeError: object str can't be used in 'await' expression\n\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {} \n\n    def set_typing_status(self, agent_name: str, status: bool):\n        self.typing_status[agent_name] = status\n\n    def get_typing_status(self, agent_name: str):\n        return self.typing_status.get(agent_name, False)\n\n    async def broadcast_message(self, message, sender, timestamp):\n        # Assign a value to first_agent_in_queue before using it\n        first_agent_in_queue = self.speaking_queue[0] if self.speaking_queue else None\n\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n        await self.update_speaking_queue()\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):  \n                await agent.speak() \n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        first_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n    def add_to_speaking_queue(self, agent):\n        if agent.name not in self.speaking_queue:\n            self.speaking_queue.append(agent)\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n    \n    def get_speaking_queue(self):\n        return self.speaking_queue            \n\n    def add_agent(self, agent: Agent):\n        self.agents[agent.name] = agent\n        self.typing_status[agent.name] = False  \n\n    def remove_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        del self.agents[agent_name]\n\n    def get_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        return self.agents[agent_name]\n\n    def add_to_chat_history(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = 100\n                self.agents[agent_name].tagged = True\n                print(f\"Tagged agent: {agent_name}\")  # Debug print\n        return mentioned_agents\n\n    def add_tagged_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.tagged and agent.name not in self.speaking_queue.queue:    \n                self.speaking_queue.add(agent.name)\n                agent.tagged = False\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def add_high_pressure_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n                self.speaking_queue.add(agent.name)\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    async def trigger_next_speaker(self):\n        if self.speaking_queue:\n            next_speaker_name = self.speaking_queue.pop(0)  \n            next_speaker = self.get_agent(next_speaker_name)\n            response = await next_speaker.get_response(self.chat_history.truncated_chat_history)\n            print(f\"The next speaker is: {next_speaker.name}\") \n            print(f\"Message: {response}\")\n            \n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n\n        most_relevant_agent = None\n        highest_relevancy_score = -1\n\n        for agent in self.agents.values():\n            truncated_chat_history = self.chat_history.truncated_chat_history\n            relevancy_score = await agent.calculate_relevancy(truncated_chat_history) \n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n            print(f\"Calculated relevancy for agent {agent.name}. Score: {relevancy_score}\")\n\n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent and self.speaking_queue.count(most_relevant_agent.name) == 0:\n            self.speaking_queue.insert(0, most_relevant_agent.name)\n            print(f\"Added agent {most_relevant_agent.name} to the front of the speaking queue. Current queue: {self.speaking_queue}\")\n\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n\n        print(f\"Triggering next speaker...\")\n        await self.trigger_next_speaker()\n    #def get_sorted_agents_based_on_relevancy(self):\n    #    return sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history) if agent.calculate_relevancy(self.chat_history) is not None else 0, reverse=True)\n\n    async def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent_name, agent in self.agents.items():\n            agents_info.append({\n                \"name\": agent_name,\n                \"speaking_pressure\": agent.speaking_pressure,\n                \"speaking_pressure_increment\": agent.speaking_pressure_increment, \n                \"context\": agent.context,\n                \"agent_type\": agent.agent_type,\n                \"relevancy_score\": agent.relevancy_score  # Return the cached score\n            })\n        return agents_info \n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.speaking_pressure = speaking_pressure_increment\n        self.tagged = False\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.is_speaking = False\n        self.relevancy_score = None\n\n    def get_response(self, truncated_chat_history):\n        agent_message = self.get_agent_message(truncated_chat_history)\n        return agent_message\n\n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",  # or \"text-curie-002\" for Curie\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            # Here we assume the model's response will be a single number.\n            # The strip is used to remove any whitespace around the number\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n    \n\n\n    def should_speak(self):\n        return self.parliament.speaker_manager.should_speak(self)  # Call parliament's speaker_manager\n\n    async def increment_pressure(self):\n        while True:\n            self.speaking_pressure += self.speaking_pressure_increment\n\n    async def get_agent_message(self, truncated_chat_history):\n        \"\"\"\n        Generate a message from this agent based on the current chat history.\n        \"\"\"\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n    \n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue.queue\n    \n    async def speak(self):\n        truncated_chat_history = self.parliament.chat_history.truncated_chat_history\n        if self.should_speak():\n            self.is_speaking = True\n\n            await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n            await self.websocket.send(json.dumps({\"action\": STOPPED_TYPING, \"sender\": self.name}))\n            agent_message = await self.get_response(self.parliament.chat_history.truncated_chat_history)\n            await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name})) \n            self.speaking_pressure = 0\n            self.is_speaking = False\n            if self.in_queue():\n                self.parliament.speaking_queue.remove(self.name)\n\n    def reset_pressure(self):\n        self.speaking_pressure = 0\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history() \n\n    def truncate_chat_history(self, max_length=2000):\n        \"\"\"\n        Truncate the chat history to the last max_length characters.\n        \"\"\"\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def last_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages=[]\n        messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n\n",
      "created_at": "2023-05-14T03:59:52.242335",
      "sequence_order": 64,
      "parent_id": "e9810ed0-6e75-470f-b67f-4b4fdc50ff09",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "09f37b39-5e6d-4f3b-84a6-308cb3b98436",
      "role": "assistant",
      "content": "The error you're encountering is due to the misuse of the `await` keyword. The error message states that: `TypeError: object str can't be used in 'await' expression`. This is because you're trying to `await` a function that is not a coroutine (it doesn't have `async` in its definition). \n\nThe error originates from this part of your `Parliament` class:\n\n```python\nasync def trigger_next_speaker(self):\n    if self.speaking_queue:\n        next_speaker_name = self.speaking_queue.pop(0)  \n        next_speaker = self.get_agent(next_speaker_name)\n        response = await next_speaker.get_response(self.chat_history.truncated_chat_history)\n        print(f\"The next speaker is: {next_speaker.name}\") \n        print(f\"Message: {response}\")\n```\nHere, the `get_response` method of the `Agent` class is not a coroutine, but you're trying to `await` it.\n\nIn your `Agent` class:\n\n```python\ndef get_response(self, truncated_chat_history):\n    agent_message = self.get_agent_message(truncated_chat_history)\n    return agent_message\n```\n\nYou can solve this by making `get_response` and any other function that is awaited an `async` function:\n\n```python\nasync def get_response(self, truncated_chat_history):\n    agent_message = await self.get_agent_message(truncated_chat_history)\n    return agent_message\n```\n\nAnd similarly for `get_agent_message`:\n\n```python\nasync def get_agent_message(self, truncated_chat_history):\n    \"\"\"\n    Generate a message from this agent based on the current chat history.\n    \"\"\"\n    message = \"\"\n    if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n        response = await self.agent_instance.get_response(truncated_chat_history)\n        message = f\"{response}\"\n    return message\n```\n\nThen, in your `OpenAIAgent` class, you should make `get_response` a coroutine:\n\n```python\nasync def get_response(self, truncated_chat):\n    system_msg = self.initial_context\n    messages=[]\n    messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n\n    max_retries = 3\n    retry_delay = 5\n\n    for i in range(max_retries):\n        try:\n            # Call the OpenAI API with the messages array\n            response = await openai.ChatCompletion.create(\n                model=self.model,\n                messages=messages,\n                max_tokens=150,\n                temperature=0.5,\n                top_p=1,\n                frequency_penalty=0,\n                presence_penalty=0,\n            )\n            # Extract and return the assistant's response from the API response\n            agent_response = response.choices[0].message[\"content\"].strip()\n            print(f\" {agent_response}\")  # Add logging\n            return agent_response\n\n        except RateLimitError as e:\n            print(f\"Rate limit error: {e}. Retrying...\n```\n\nHowever, it's worth noting that you might not be able to directly `await` the `openai.ChatCompletion.create` function, because as of my knowledge cutoff in September 2021, the OpenAI Python client does not support asyncio natively.\n\nIn case the OpenAI Python client doesn't support asyncio, you'll need to use a workaround. You could use a library like `aiohttp` to make the HTTP request, or use `run_in_executor` to run the blocking function in a separate thread. It's recommended to check the OpenAI Python client's documentation or the OpenAI API's documentation to get the most accurate information.\n\nAlso, it's worth noting that you've defined `identify_and_tag_mentioned_agents` method twice in the `Parliament` class",
      "created_at": "2023-05-14T04:01:13.513570",
      "sequence_order": 65,
      "parent_id": "aaa2e764-7ca7-4e94-8b8c-c5b3b4f6ed93",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": false
      }
    }
  ]
}