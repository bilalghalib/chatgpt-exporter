{
  "id": "23d514ad-800e-4674-a04f-c4cc8cab9172",
  "source": "chatgpt",
  "title": "\"Debugging Python AttributeError\"",
  "created_at": "2023-05-20T18:45:31.903868",
  "updated_at": "2023-05-20T19:41:35",
  "summary": null,
  "message_count": 32,
  "messages": [
    {
      "id": "aaa241d5-6188-4d53-b34e-829a898c881a",
      "role": "user",
      "content": "getting this error\nconnection handler failed\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 39, in chat\n    await self.handle_add_agents(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 108, in handle_add_agents\n    if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\nAttributeError: 'ParliamentServer' object has no attribute 'agent_instance'\nhere: from datetime import datetime\nimport asyncio\nimport json\nfrom websockets import serve\nfrom parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent\nimport openai\n\n# Constants\nSET_PARLIAMENT = \"set_parliament\"\nSEND_MESSAGE = \"send_message\"\nADD_AGENTS = \"add_agents\"\nUPDATE_QUEUE = \"update_queue\"\nUPDATE_AGENTS = \"update_agents\"\nRECEIVE_MESSAGE = \"receive_message\"\nERROR = \"error\"\nTYPING = \"typing\"\nSTOPPED_TYPING = \"stopped_typing\"\n\nclass ParliamentServer:\n    def __init__(self, host=\"localhost\", port=8080):\n        self.host = host\n        self.port = port\n        self.parliament = None\n        self.start_server = serve(self.chat, self.host, self.port)\n\n    def configure_openai(self):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n\n    async def chat(self, websocket, path):\n        async for message in websocket:\n            data = json.loads(message)\n            action = data.get(\"action\")\n            if action == SET_PARLIAMENT:\n                await self.handle_set_parliament(websocket, data)\n            elif action == SEND_MESSAGE:\n                await self.handle_send_message(websocket, data)\n            elif action == ADD_AGENTS:\n                await self.handle_add_agents(websocket, data)\n            elif action in [TYPING, STOPPED_TYPING]:  \n                await self.handle_typing(websocket, data)\n\n    async def handle_typing(self, websocket, data):\n        sender = data.get('sender')\n        action = data.get('action')\n        is_typing = action == TYPING\n\n        self.parliament.set_typing_status(sender, is_typing)\n\n        # Send the typing status update to other clients:\n        await websocket.send(json.dumps({\n            \"action\": action,\n            \"sender\": sender,\n            \"is_typing\": is_typing\n        }))\n\n    async def handle_set_parliament(self, websocket, data):\n        parliament_name = data.get(\"name\")\n        if parliament_name:\n            self.parliament = Parliament(parliament_name)\n\n    async def handle_send_message(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n        sender = data.get(\"sender\")\n        user_message = data.get(\"message\")\n        timestamp = datetime.now()\n        await websocket.send(json.dumps({\n            \"action\": RECEIVE_MESSAGE,\n            \"message\": user_message,\n            \"sender\": sender,\n            \"timestamp\": timestamp.isoformat()}))\n        await self.parliament.broadcast_message(user_message, sender, timestamp)\n        print(f\"Broadcast message: {user_message}\")  # Add logging \n\n        # Sending agent info after broadcasting message\n        agent_info = await self.parliament.get_agents_info()  \n        await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        await self.update_queue(websocket)\n            \n    async def handle_add_agents(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n\n        agents_data = data.get(\"agents\")\n        if not agents_data:\n            await self.send_error(websocket, \"No agent data provided.\")\n            return\n\n        for agent_data in agents_data:\n            agent_name = agent_data.get(\"name\")  # Extract the name\n            speaking_pressure_increment = int(agent_data.get(\"speaking_pressure_increment\"))\n\n            other_agents = \", \".join([agent['name'] for agent in agents_data if agent['name'] != agent_name])\n            initial_context = (\n                f\"Hello assistant, your name is: @{agent_data.get('name')} and your context is \"\n                f\"{agent_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n                f\"alongside your fellow agents in a parliament, which is a sort \"\n                f\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n                f\"with you are {other_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n                f\"{agent_data.get('speaking_pressure_increment')} out of 100\"\n            )\n            agent_type = agent_data.get(\"type\")\n            agent_class = self.parliament.agent_types.get(agent_type)  # Get OpenAIAgent or GPT4AllAgent\n            agent_instance = agent_class(initial_context)  # Properly instantiate the class\n            if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n                agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n                agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n                self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n            else: \n                print(\"Error occurred attempting to get agent message!\")\n                return \"Sorry, I'm unable to generate a relevant response at this time.\" \n                await self.send_error(websocket, f\"Unknown agent type: {agent_type}\")\n                continue\n\n\n    async def update_queue(self, websocket):\n        if self.parliament:\n            speaking_queue = self.parliament.get_speaking_queue()\n            print(f\"Queue updated: {speaking_queue}\")\n            await websocket.send(json.dumps({\"action\": UPDATE_QUEUE, \"queue\": speaking_queue}))\n\n    async def send_error(self, websocket, message):\n        await websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\n    def run(self):\n        self.configure_openai()\n        asyncio.get_event_loop().run_until_complete(self.start_server)\n        print(\"Starting WebSocket server...\")\n        print(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n        asyncio.get_event_loop().run_forever()\n\n\nif __name__ == \"__main__\":\n    server = ParliamentServer()\n    server.run()\n",
      "created_at": "2023-05-20T18:45:31.905332",
      "sequence_order": 0,
      "parent_id": "906ed3b6-65ad-4433-960f-fe2b2c70412c",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "d33afad2-6d0f-4348-aafd-d5a498649fb9",
      "role": "assistant",
      "content": "The error you're seeing is related to a variable `self.agent_instance` that does not exist in your class. The `self.agent_instance` variable is not initialized or used anywhere else in your code. \n\nI see a possible mistake in your `handle_add_agents` method. At these lines:\n\n```python\nagent_instance = agent_class(initial_context)  # Properly instantiate the class\nif isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n    agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n```\n\nHere, you are using `self.agent_instance` but it seems like you mean to be using `agent_instance`, which you just created. Additionally, `self.agent_type` is also not defined anywhere. \n\nIf your intention is to check if the agent instance is of a particular type before creating an `OpenAIAgent`, you should correct this code to something like:\n\n```python\nagent_instance = agent_class(initial_context)  # Properly instantiate the class\nif isinstance(agent_instance, self.parliament.agent_types[agent_type]):\n    agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n```\n\nAssuming that `agent_type` is correctly passed and `self.parliament.agent_types[agent_type]` is the class you want to check against, this code will verify if `agent_instance` is an instance of the expected class before creating an `OpenAIAgent`. \n\nI would also recommend initializing all instance variables in your class's `__init__` method to avoid confusion. In your case, if `agent_instance` or `agent_type` are expected to be instance variables, you should initialize them in `__init__`.",
      "created_at": "2023-05-20T18:45:59.090888",
      "sequence_order": 1,
      "parent_id": "aaa241d5-6188-4d53-b34e-829a898c881a",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa29608-07a5-4be8-9540-ca2c380cf185",
      "role": "user",
      "content": "getting this error\nconnection handler failed\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 108, in handle_add_agents\n    if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\nAttributeError: 'ParliamentServer' object has no attribute 'agent_instance'\nhere:\nFrom server.py\n\nclass ParliamentServer:\n    def __init__(self, host=\"localhost\", port=8080):\n        self.host = host\n        self.port = port\n        self.parliament = None\n        self.start_server = serve(self.chat, self.host, self.port)\n\n    def configure_openai(self):\n\n    async def chat(self, websocket, path):\n        async for message in websocket:\n            data = json.loads(message)\n            action = data.get(\"action\")\n            if action == SET_PARLIAMENT:\n                await self.handle_set_parliament(websocket, data)\n            elif action == SEND_MESSAGE:\n                await self.handle_send_message(websocket, data)\n            elif action == ADD_AGENTS:\n                await self.handle_add_agents(websocket, data)\n            elif action in [TYPING, STOPPED_TYPING]:  \n                await self.handle_typing(websocket, data)\n\n    async def handle_typing(self, websocket, data):\n        sender = data.get('sender')\n        action = data.get('action')\n        is_typing = action == TYPING\n\n        self.parliament.set_typing_status(sender, is_typing)\n\n        # Send the typing status update to other clients:\n        await websocket.send(json.dumps({\n            \"action\": action,\n            \"sender\": sender,\n            \"is_typing\": is_typing\n        }))\n\n    async def handle_set_parliament(self, websocket, data):\n        parliament_name = data.get(\"name\")\n        if parliament_name:\n            self.parliament = Parliament(parliament_name)\n\n    async def handle_send_message(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n        sender = data.get(\"sender\")\n        user_message = data.get(\"message\")\n        timestamp = datetime.now()\n        await websocket.send(json.dumps({\n            \"action\": RECEIVE_MESSAGE,\n            \"message\": user_message,\n            \"sender\": sender,\n            \"timestamp\": timestamp.isoformat()}))\n        await self.parliament.broadcast_message(user_message, sender, timestamp)\n\n        # Sending agent info after broadcasting message\n        agent_info = await self.parliament.get_agents_info()  \n        await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        await self.update_queue(websocket)\n            \n    async def handle_add_agents(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n\n        agents_data = data.get(\"agents\")\n        if not agents_data:\n            await self.send_error(websocket, \"No agent data provided.\")\n            return\n\n        for agent_data in agents_data:\n            agent_name = agent_data.get(\"name\")  # Extract the name\n            speaking_pressure_increment = int(agent_data.get(\"speaking_pressure_increment\"))\n\n            other_agents = \", \".join([agent['name'] for agent in agents_data if agent['name'] != agent_name])\n            initial_context = (\n                f\"Hello 00\"\n            )\n            agent_type = agent_data.get(\"type\")\n            agent_class = self.parliament.agent_types.get(agent_type)  # Get OpenAIAgent or GPT4AllAgent\n            agent_instance = agent_class(initial_context)  # Properly instantiate the class\n            if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n                agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n                agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n                self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n            else: \n                return \"Sorry, I'm unable to generate a relevant response at this time.\" \n                await self.send_error(websocket, f\"Unknown agent type: {agent_type}\")\n                continue\n\n\n    async def update_queue(self, websocket):\n        if self.parliament:\n            speaking_queue = self.parliament.get_speaking_queue()\n            await websocket.send(json.dumps({\"action\": UPDATE_QUEUE, \"queue\": speaking_queue}))\n\n    async def send_error(self, websocket, message):\n        await websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\n    def run(self):\n        self.configure_openai()\n        asyncio.get_event_loop().run_until_complete(self.start_server)\n        asyncio.get_event_loop().run_forever()\n\nif __name__ == \"__main__\":\n    server = ParliamentServer()\n    server.run()\n\nthis is parliament.py:\n\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.speaking_pressure = speaking_pressure_increment\n        self.tagged = False\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.is_speaking = False\n        self.relevancy_score = None\n\n    def get_response(self, truncated_chat_history):\n        agent_message = self.get_agent_message(truncated_chat_history)\n        return agent_message\n\n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",  # or \"text-curie-002\" for Curie\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            # Here we assume the model's response will be a single number.\n            # The strip is used to remove any whitespace around the number\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n\n        else:\n        time.sleep(.5)\n        return relevancy_score\n    \n\n\n    def should_speak(self):\n        return self.parliament.speaker_manager.should_speak(self)  # Call parliament's speaker_manager\n\n    async def increment_pressure(self):\n        while True:\n            self.speaking_pressure += self.speaking_pressure_increment\n\n    async def get_agent_message(self, truncated_chat_history):\n        \"\"\"\n        Generate a message from this agent based on the current chat history.\n        \"\"\"\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n    \n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue.queue\n    \n    async def speak(self):\n        truncated_chat_history = self.parliament.chat_history.truncated_chat_history\n        if self.should_speak():\n            self.is_speaking = True\n\n            await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n            await self.websocket.send(json.dumps({\"action\": STOPPED_TYPING, \"sender\": self.name}))\n            agent_message = await self.get_response(self.parliament.chat_history.truncated_chat_history)\n            await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name})) \n            self.speaking_pressure = 0\n            self.is_speaking = False\n            if self.in_queue():\n                self.parliament.speaking_queue.remove(self.name)\n\n    def reset_pressure(self):\n        self.speaking_pressure = 0\n\n\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {} \n\n    def set_typing_status(self, agent_name: str, status: bool):\n        self.typing_status[agent_name] = status\n\n    def get_typing_status(self, agent_name: str):\n        return self.typing_status.get(agent_name, False)\n\n    async def broadcast_message(self, message, sender, timestamp):\n        # Assign a value to first_agent_in_queue before using it\n        first_agent_in_queue = self.speaking_queue[0] if self.speaking_queue else None\n\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n        await self.update_speaking_queue()\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):  \n                await agent.speak() \n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        first_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n    def add_to_speaking_queue(self, agent):\n        if agent.name not in self.speaking_queue:\n            self.speaking_queue.append(agent)\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n    \n    def get_speaking_queue(self):\n        return self.speaking_queue            \n\n    def add_agent(self, agent: Agent):\n        self.agents[agent.name] = agent\n        self.typing_status[agent.name] = False  \n\n    def remove_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        del self.agents[agent_name]\n\n    def get_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        return self.agents[agent_name]\n\n    def add_to_chat_history(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\n    def add_tagged_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.tagged and agent.name not in self.speaking_queue.queue:    \n                self.speaking_queue.add(agent.name)\n                agent.tagged = False\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def add_high_pressure_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n                self.speaking_queue.add(agent.name)\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    async def trigger_next_speaker(self):\n        if self.speaking_queue:\n            next_speaker_name = self.speaking_queue.pop(0)  \n            next_speaker = self.get_agent(next_speaker_name)\n            response = await next_speaker.get_response(self.chat_history.truncated_chat_history)\n            \n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n\n        most_relevant_agent = None\n        highest_relevancy_score = -1\n\n        for agent in self.agents.values():\n            truncated_chat_history = self.chat_history.truncated_chat_history\n            relevancy_score = await agent.calculate_relevancy(truncated_chat_history) \n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent and self.speaking_queue.count(most_relevant_agent.name) == 0:\n            self.speaking_queue.insert(0, most_relevant_agent.name)\n            print(f\"Added agent {most_relevant_agent.name} to the front of the speaking queue. Current queue: {self.speaking_queue}\")\n\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n\n        await self.trigger_next_speaker()\n    #def get_sorted_agents_based_on_relevancy(self):\n    #    return sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history) if agent.calculate_relevancy(self.chat_history) is not None else 0, reverse=True)\n\n    async def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent_name, agent in self.agents.items():\n            agents_info.append({\n                \"name\": agent_name,\n                \"speaking_pressure\": agent.speaking_pressure,\n                \"speaking_pressure_increment\": agent.speaking_pressure_increment, \n                \"context\": agent.context,\n                \"agent_type\": agent.agent_type,\n                \"relevancy_score\": agent.relevancy_score  # Return the cached score\n            })\n        return agents_info ",
      "created_at": "2023-05-20T18:50:21.308307",
      "sequence_order": 2,
      "parent_id": "906ed3b6-65ad-4433-960f-fe2b2c70412c",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "e59817c0-aa13-4f74-a66c-c57481410a13",
      "role": "assistant",
      "content": "The problem seems to be coming from these lines in the `handle_add_agents` method in your `ParliamentServer` class:\n\n```python\nif isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n    agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n    agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n    self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n```\n\nIn the first line, you're trying to check if `self.agent_instance` is an instance of a certain type, but `self.agent_instance` does not exist as an attribute in `ParliamentServer` hence the `AttributeError: 'ParliamentServer' object has no attribute 'agent_instance'` error.\n\nAdditionally, `self.agent_type` is also not defined. It seems like you are trying to access local variables as instance variables.\n\nThe code should be fixed like this:\n\n```python\nif isinstance(agent_instance, self.parliament.agent_types[agent_type]):\n    agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n    agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n    self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n```\n\nWith this fix, you're checking if `agent_instance`, which you've created on the line above, is an instance of the type specified by `agent_type` (which is also created on the lines above within the `for` loop). This should help you move past this issue.",
      "created_at": "2023-05-20T18:50:51.053588",
      "sequence_order": 3,
      "parent_id": "aaa29608-07a5-4be8-9540-ca2c380cf185",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2cdb9-8583-40bf-93ef-ba80c86a7045",
      "role": "user",
      "content": "connection handler failed\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 37, in chat\n    await self.handle_send_message(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 74, in handle_send_message\n    await self.parliament.broadcast_message(user_message, sender, timestamp)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 239, in broadcast_message\n    await self.update_speaking_queue()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 333, in update_speaking_queue\n    await self.trigger_next_speaker()\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 306, in trigger_next_speaker\n    response = await next_speaker.get_response(self.chat_history.truncated_chat_history)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 82, in get_agent_message\n    response = await self.agent_instance.get_response(truncated_chat_history)\nTypeError: object str can't be used in 'await' expression\n\nFrom server.py\n\nclass ParliamentServer:\n    def __init__(self, host=\"localhost\", port=8080):\n        self.host = host\n        self.port = port\n        self.parliament = None\n        self.start_server = serve(self.chat, self.host, self.port)\n\n    def configure_openai(self):\n\n    async def chat(self, websocket, path):\n        async for message in websocket:\n            data = json.loads(message)\n            action = data.get(\"action\")\n            if action == SET_PARLIAMENT:\n                await self.handle_set_parliament(websocket, data)\n            elif action == SEND_MESSAGE:\n                await self.handle_send_message(websocket, data)\n            elif action == ADD_AGENTS:\n                await self.handle_add_agents(websocket, data)\n            elif action in [TYPING, STOPPED_TYPING]:  \n                await self.handle_typing(websocket, data)\n\n    async def handle_typing(self, websocket, data):\n        sender = data.get('sender')\n        action = data.get('action')\n        is_typing = action == TYPING\n\n        self.parliament.set_typing_status(sender, is_typing)\n\n        # Send the typing status update to other clients:\n        await websocket.send(json.dumps({\n            \"action\": action,\n            \"sender\": sender,\n            \"is_typing\": is_typing\n        }))\n\n    async def handle_set_parliament(self, websocket, data):\n        parliament_name = data.get(\"name\")\n        if parliament_name:\n            self.parliament = Parliament(parliament_name)\n\n    async def handle_send_message(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n        sender = data.get(\"sender\")\n        user_message = data.get(\"message\")\n        timestamp = datetime.now()\n        await websocket.send(json.dumps({\n            \"action\": RECEIVE_MESSAGE,\n            \"message\": user_message,\n            \"sender\": sender,\n            \"timestamp\": timestamp.isoformat()}))\n        await self.parliament.broadcast_message(user_message, sender, timestamp)\n\n        # Sending agent info after broadcasting message\n        agent_info = await self.parliament.get_agents_info()  \n        await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        await self.update_queue(websocket)\n            \n    async def handle_add_agents(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n\n        agents_data = data.get(\"agents\")\n        if not agents_data:\n            await self.send_error(websocket, \"No agent data provided.\")\n            return\n\n        for agent_data in agents_data:\n            agent_name = agent_data.get(\"name\")  # Extract the name\n            speaking_pressure_increment = int(agent_data.get(\"speaking_pressure_increment\"))\n\n            other_agents = \", \".join([agent['name'] for agent in agents_data if agent['name'] != agent_name])\n            initial_context = (\n                f\"Hello 00\"\n            )\n            agent_type = agent_data.get(\"type\")\n            agent_class = self.parliament.agent_types.get(agent_type)  # Get OpenAIAgent or GPT4AllAgent\n            agent_instance = agent_class(initial_context)  # Properly instantiate the class\n            if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n                agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n                agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n                self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n            else: \n                return \"Sorry, I'm unable to generate a relevant response at this time.\" \n                await self.send_error(websocket, f\"Unknown agent type: {agent_type}\")\n                continue\n\n\n    async def update_queue(self, websocket):\n        if self.parliament:\n            speaking_queue = self.parliament.get_speaking_queue()\n            await websocket.send(json.dumps({\"action\": UPDATE_QUEUE, \"queue\": speaking_queue}))\n\n    async def send_error(self, websocket, message):\n        await websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\n    def run(self):\n        self.configure_openai()\n        asyncio.get_event_loop().run_until_complete(self.start_server)\n        asyncio.get_event_loop().run_forever()\n\nif __name__ == \"__main__\":\n    server = ParliamentServer()\n    server.run()\n\nthis is parliament.py:\n\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.speaking_pressure = speaking_pressure_increment\n        self.tagged = False\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.is_speaking = False\n        self.relevancy_score = None\n\n    def get_response(self, truncated_chat_history):\n        agent_message = self.get_agent_message(truncated_chat_history)\n        return agent_message\n\n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",  # or \"text-curie-002\" for Curie\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            # Here we assume the model's response will be a single number.\n            # The strip is used to remove any whitespace around the number\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n\n        else:\n        time.sleep(.5)\n        return relevancy_score\n    \n\n\n    def should_speak(self):\n        return self.parliament.speaker_manager.should_speak(self)  # Call parliament's speaker_manager\n\n    async def increment_pressure(self):\n        while True:\n            self.speaking_pressure += self.speaking_pressure_increment\n\n    async def get_agent_message(self, truncated_chat_history):\n        \"\"\"\n        Generate a message from this agent based on the current chat history.\n        \"\"\"\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n    \n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue.queue\n    \n    async def speak(self):\n        truncated_chat_history = self.parliament.chat_history.truncated_chat_history\n        if self.should_speak():\n            self.is_speaking = True\n\n            await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n            await self.websocket.send(json.dumps({\"action\": STOPPED_TYPING, \"sender\": self.name}))\n            agent_message = await self.get_response(self.parliament.chat_history.truncated_chat_history)\n            await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name})) \n            self.speaking_pressure = 0\n            self.is_speaking = False\n            if self.in_queue():\n                self.parliament.speaking_queue.remove(self.name)\n\n    def reset_pressure(self):\n        self.speaking_pressure = 0\n\n\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {} \n\n    def set_typing_status(self, agent_name: str, status: bool):\n        self.typing_status[agent_name] = status\n\n    def get_typing_status(self, agent_name: str):\n        return self.typing_status.get(agent_name, False)\n\n    async def broadcast_message(self, message, sender, timestamp):\n        # Assign a value to first_agent_in_queue before using it\n        first_agent_in_queue = self.speaking_queue[0] if self.speaking_queue else None\n\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n        await self.update_speaking_queue()\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):  \n                await agent.speak() \n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        first_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n    def add_to_speaking_queue(self, agent):\n        if agent.name not in self.speaking_queue:\n            self.speaking_queue.append(agent)\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n    \n    def get_speaking_queue(self):\n        return self.speaking_queue            \n\n    def add_agent(self, agent: Agent):\n        self.agents[agent.name] = agent\n        self.typing_status[agent.name] = False  \n\n    def remove_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        del self.agents[agent_name]\n\n    def get_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        return self.agents[agent_name]\n\n    def add_to_chat_history(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\n    def add_tagged_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.tagged and agent.name not in self.speaking_queue.queue:    \n                self.speaking_queue.add(agent.name)\n                agent.tagged = False\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def add_high_pressure_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n                self.speaking_queue.add(agent.name)\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    async def trigger_next_speaker(self):\n        if self.speaking_queue:\n            next_speaker_name = self.speaking_queue.pop(0)  \n            next_speaker = self.get_agent(next_speaker_name)\n            response = await next_speaker.get_response(self.chat_history.truncated_chat_history)\n            \n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n\n        most_relevant_agent = None\n        highest_relevancy_score = -1\n\n        for agent in self.agents.values():\n            truncated_chat_history = self.chat_history.truncated_chat_history\n            relevancy_score = await agent.calculate_relevancy(truncated_chat_history) \n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent and self.speaking_queue.count(most_relevant_agent.name) == 0:\n            self.speaking_queue.insert(0, most_relevant_agent.name)\n            print(f\"Added agent {most_relevant_agent.name} to the front of the speaking queue. Current queue: {self.speaking_queue}\")\n\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n\n        await self.trigger_next_speaker()\n    #def get_sorted_agents_based_on_relevancy(self):\n    #    return sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history) if agent.calculate_relevancy(self.chat_history) is not None else 0, reverse=True)\n\n    async def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent_name, agent in self.agents.items():\n            agents_info.append({\n                \"name\": agent_name,\n                \"speaking_pressure\": agent.speaking_pressure,\n                \"speaking_pressure_increment\": agent.speaking_pressure_increment, \n                \"context\": agent.context,\n                \"agent_type\": agent.agent_type,\n                \"relevancy_score\": agent.relevancy_score  # Return the cached score\n            })\n        return agents_info ",
      "created_at": "2023-05-20T18:56:51.202681",
      "sequence_order": 4,
      "parent_id": "906ed3b6-65ad-4433-960f-fe2b2c70412c",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "5c4619f6-befe-47bd-ae88-1e1a55ac0eae",
      "role": "assistant",
      "content": "It looks like the error is coming from the following line:\n\n```python\nresponse = await next_speaker.get_response(self.chat_history.truncated_chat_history)\n```\n\nThe `await` keyword is used to denote a coroutine that you want to wait for. It appears that the `get_response` method of `next_speaker` (which is an instance of the `Agent` class) is not a coroutine, i.e., it is not an async function.\n\nYou can confirm this by checking the `Agent` class:\n\n```python\nclass Agent:\n    ...\n    def get_response(self, truncated_chat_history):\n        agent_message = self.get_agent_message(truncated_chat_history)\n        return agent_message\n    ...\n```\n\nIn this class, the `get_response` method is a regular function, not an async function. Therefore, you can't use `await` with it. This is what the `TypeError: object str can't be used in 'await' expression` error is about.\n\nTo solve this, you can either:\n\n1. Remove the `await` from `response = await next_speaker.get_response(self.chat_history.truncated_chat_history)`, so it becomes `response = next_speaker.get_response(self.chat_history.truncated_chat_history)`. This solution assumes that there is no asynchronous code in the `get_response` method or any method it calls.\n\n2. Change `get_response` to be an async function if it contains or calls other async functions. If there are any async functions used in `get_response`, you need to ensure those are awaited appropriately. For example, if `get_agent_message` is an async function, `get_response` should look something like this:\n\n```python\nclass Agent:\n    ...\n    async def get_response(self, truncated_chat_history):\n        agent_message = await self.get_agent_message(truncated_chat_history)\n        return agent_message\n    ...\n```\nNote: If `get_agent_message` is asynchronous and it's called from a synchronous function like `get_response`, you won't be able to use `await` with it unless `get_response` itself is also made asynchronous.\n\nPlease choose the approach that fits with your implementation.",
      "created_at": "2023-05-20T18:57:31.746590",
      "sequence_order": 5,
      "parent_id": "aaa2cdb9-8583-40bf-93ef-ba80c86a7045",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa28729-b533-4699-ac65-3ecebd77319a",
      "role": "user",
      "content": " I want to remove the queue idea can you help me do that and keep the code intact? \nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.speaking_pressure = speaking_pressure_increment\n        self.tagged = False\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.is_speaking = False\n        self.relevancy_score = None\n\n    def get_response(self, truncated_chat_history):\n        agent_message = self.get_agent_message(truncated_chat_history)\n        return agent_message\n\n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",  # or \"text-curie-002\" for Curie\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            # Here we assume the model's response will be a single number.\n            # The strip is used to remove any whitespace around the number\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n    \n\n\n    def should_speak(self):\n        return self.parliament.speaker_manager.should_speak(self)  # Call parliament's speaker_manager\n\n    async def increment_pressure(self):\n        while True:\n            self.speaking_pressure += self.speaking_pressure_increment\n\n    async def get_agent_message(self, truncated_chat_history):\n        \"\"\"\n        Generate a message from this agent based on the current chat history.\n        \"\"\"\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n    \n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue.queue\n    \n    async def speak(self):\n        truncated_chat_history = self.parliament.chat_history.truncated_chat_history\n        if self.should_speak():\n            self.is_speaking = True\n\n            await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n            await self.websocket.send(json.dumps({\"action\": STOPPED_TYPING, \"sender\": self.name}))\n            agent_message = await self.get_response(self.parliament.chat_history.truncated_chat_history)\n            await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name})) \n            self.speaking_pressure = 0\n            self.is_speaking = False\n            if self.in_queue():\n                self.parliament.speaking_queue.remove(self.name)\n\n    def reset_pressure(self):\n        self.speaking_pressure = 0\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history() \n\n    def truncate_chat_history(self, max_length=2000):\n        \"\"\"\n        Truncate the chat history to the last max_length characters.\n        \"\"\"\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def last_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages=[]\n        messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n\n\nclass GPT4AllAgent:\n    def __init__(self):\n        # Download and set up the GPT4All model\n        self._initialize_gpt4all_model()\n        self._initialize_llm_chain()\n\n    def _initialize_gpt4all_model(self):\n        local_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n\n        url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n        response = requests.get(url, stream=True)\n\n        with open(local_path, 'wb') as f:\n            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n                if chunk:\n                    f.write(chunk)\n\n        self.model_path = local_path\n\n    def _initialize_llm_chain(self):\n        template = \"\"\"{chat_history}\n\n        Question: {question}\n\n        Answer: Let's think step by step.\"\"\"\n        prompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\n\n        callbacks = [StreamingStdOutCallbackHandler()]\n        llm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\n        self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n\n    def get_response(self, chat_history, question):\n        return self.llm_chain.run(chat_history=chat_history, question=question)\n\n\n\n\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {} \n\n    def set_typing_status(self, agent_name: str, status: bool):\n        self.typing_status[agent_name] = status\n\n    def get_typing_status(self, agent_name: str):\n        return self.typing_status.get(agent_name, False)\n\n    async def broadcast_message(self, message, sender, timestamp):\n        # Assign a value to first_agent_in_queue before using it\n        first_agent_in_queue = self.speaking_queue[0] if self.speaking_queue else None\n\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n        await self.update_speaking_queue()\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):  \n                await agent.speak() \n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        first_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n    def add_to_speaking_queue(self, agent):\n        if agent.name not in self.speaking_queue:\n            self.speaking_queue.append(agent)\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n    \n    def get_speaking_queue(self):\n        return self.speaking_queue            \n\n    def add_agent(self, agent: Agent):\n        self.agents[agent.name] = agent\n        self.typing_status[agent.name] = False  \n\n    def remove_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        del self.agents[agent_name]\n\n    def get_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        return self.agents[agent_name]\n\n    def add_to_chat_history(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\n    def add_tagged_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.tagged and agent.name not in self.speaking_queue.queue:    \n                self.speaking_queue.add(agent.name)\n                agent.tagged = False\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def add_high_pressure_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n                self.speaking_queue.add(agent.name)\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    async def trigger_next_speaker(self):\n        if self.speaking_queue:\n            next_speaker_name = self.speaking_queue.pop(0)  \n            next_speaker = self.get_agent(next_speaker_name)\n            response = next_speaker.get_response(self.chat_history.truncated_chat_history)\n            print(f\"The next speaker is: {next_speaker.name}\") \n            print(f\"Message: {response}\")\n            \n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n\n        most_relevant_agent = None\n        highest_relevancy_score = -1\n\n        for agent in self.agents.values():\n            truncated_chat_history = self.chat_history.truncated_chat_history\n            relevancy_score = await agent.calculate_relevancy(truncated_chat_history) \n            if relevancy_score > highest_relevancy_score:\n                highest_relevancy_score = relevancy_score\n                most_relevant_agent = agent\n            print(f\"Calculated relevancy for agent {agent.name}. Score: {relevancy_score}\")\n\n        # Add the most relevant agent to the speaking queue\n        if most_relevant_agent and self.speaking_queue.count(most_relevant_agent.name) == 0:\n            self.speaking_queue.insert(0, most_relevant_agent.name)\n            print(f\"Added agent {most_relevant_agent.name} to the front of the speaking queue. Current queue: {self.speaking_queue}\")\n\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n\n        print(f\"Triggering next speaker...\")\n        await self.trigger_next_speaker()\n    #def get_sorted_agents_based_on_relevancy(self):\n    #    return sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history) if agent.calculate_relevancy(self.chat_history) is not None else 0, reverse=True)\n\n    async def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent_name, agent in self.agents.items():\n            agents_info.append({\n                \"name\": agent_name,\n                \"speaking_pressure\": agent.speaking_pressure,\n                \"speaking_pressure_increment\": agent.speaking_pressure_increment, \n                \"context\": agent.context,\n                \"agent_type\": agent.agent_type,\n                \"relevancy_score\": agent.relevancy_score  # Return the cached score\n            })\n        return agents_info ",
      "created_at": "2023-05-20T19:02:57.849937",
      "sequence_order": 6,
      "parent_id": "5c4619f6-befe-47bd-ae88-1e1a55ac0eae",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "59260ad4-f9ee-469b-b134-48743aee5a2a",
      "role": "assistant",
      "content": "It looks like the queue idea in your code is implemented in the `Parliament` class with methods like `add_to_speaking_queue`, `add_high_pressure_agents_to_queue`, `add_tagged_agents_to_queue`, `trigger_next_speaker`, and `update_speaking_queue`. The `Agent` class also has a method `in_queue` related to this. If you want to remove the queue idea, you'll need to change the logic of these methods.\n\nHowever, without knowing more about how you would like the communication between agents to work after removing the queue, I can provide only a rough approximation. \n\nFor this example, I'll assume that instead of having a queue, we'll let agents speak whenever they are relevant and are not currently speaking. Note that without a queue to structure who speaks next, agents may frequently interrupt one another. You may need to add more logic to prevent this based on your specific use case. Here is an example of how you might modify the code to reflect this change:\n\nIn the `Agent` class, remove `in_queue` function since we won't be using a queue anymore:\n\n```python\n    # def in_queue(self):\n    #     return self.name in self.parliament.speaking_queue.queue\n```\n\nAlso, modify the `speak` function, removing the last lines related to the queue:\n\n```python\n    async def speak(self):\n        truncated_chat_history = self.parliament.chat_history.truncated_chat_history\n        if self.should_speak():\n            self.is_speaking = True\n\n            await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n            await self.websocket.send(json.dumps({\"action\": STOPPED_TYPING, \"sender\": self.name}))\n            agent_message = await self.get_response(self.parliament.chat_history.truncated_chat_history)\n            await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name})) \n            self.speaking_pressure = 0\n            self.is_speaking = False\n```\n\nIn the `Parliament` class, remove or comment out all the methods related to managing the queue:\n\n```python\n    # def add_to_speaking_queue(self, agent):\n    #     if agent.name not in self.speaking_queue:\n    #         self.speaking_queue.append(agent)\n\n    # def add_tagged_agents_to_queue(self):\n    #     for agent in self.agents.values():\n    #         if agent.tagged and agent.name not in self.speaking_queue.queue:    \n    #             self.speaking_queue.add(agent.name)\n    #             agent.tagged = False\n    #             agent.speaking_pressure = 0  # Reset speaking pressure\n\n    # def add_high_pressure_agents_to_queue(self):\n    #     for agent in self.agents.values():\n    #         if agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n    #             self.speaking_queue.add(agent.name)\n    #             agent.speaking_pressure = 0  # Reset speaking pressure\n\n    # async def trigger_next_speaker(self):\n    #     if self.speaking_queue:\n    #         next_speaker_name = self.speaking_queue.pop(0)  \n    #         next_speaker = self.get_agent(next_speaker_name)\n    #         response = next_speaker.get_response(self.chat_history.truncated_chat_history)\n    #         print(f\"The next speaker is: {next_speaker.name}\") \n    #         print(f\"Message: {response}\")\n```\n\nModify `broadcast_message` and `update_speaking_queue` methods:\n\n```python\n    async def broadcast_message(self, message,",
      "created_at": "2023-05-20T19:04:24.128225",
      "sequence_order": 7,
      "parent_id": "aaa28729-b533-4699-ac65-3ecebd77319a",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": false
      }
    },
    {
      "id": "3294f04a-ae05-44d0-bff0-b39c073a06e6",
      "role": "assistant",
      "content": " and 5 replacements to: gpt_code_rewrite.AI ============================================================================\nAI to=python code<|im_sep|>In order to remove the queue concept from this code, you can simply modify your approach by not using a queue to decide who should speak next. Instead, you can use a condition-based approach. \n\nYou need to make changes to these areas:\n\n- Remove all instances of `self.speaking_queue`.\n- The `should_speak` method in the `SpeakerManager` class now doesn't need to check the first agent in the queue. Instead, it can check whether the agent's `speaking_pressure` is above a certain threshold. In this case, I use `SPEAKING_PRESSURE_LIMIT`.\n- Modify the `broadcast_message` function and the `trigger_next_speaker` function in the `Parliament` class to work without a queue. Now it will use `broadcast_message` to find out the agents who should speak based on their `speaking_pressure` instead of checking who is next in the queue. \n- Modify the `update_speaking_queue` function to find the agent with the highest `speaking_pressure` instead of manipulating the queue. The agent with the highest `speaking_pressure` will speak next.\n\nHere is the updated version of your code without the queue concept:\n\n```python\nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\n\n# Remaining part of Agent class\n\n\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return agent.speaking_pressure >= SPEAKING_PRESSURE_LIMIT\n\n\n# Remaining part of OpenAIAgent, GPT4AllAgent classes\n\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {}\n\n    # Remaining part of Parliament class\n\n    async def broadcast_message(self, message, sender, timestamp):\n\n        for agent_name, agent in self.agents.items():\n            if not self.get_typing_status(agent_name) and agent.speaking_pressure >= SPEAKING_PRESSURE_LIMIT:\n                await agent.speak()\n\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n\n        for agent_name, agent in self.agents.items():\n            if not self.get_typing_status(agent_name) and agent.speaking_pressure >= SPEAKING_PRESSURE_LIMIT:\n                await agent.speak() \n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n    async def trigger_next_speaker(self):\n        # Find the agent with the highest speaking pressure\n        next_speaker = max(self.agents.values(), key=lambda agent: agent.speaking_pressure)\n        response = next_speaker.get_response(self.chat_history.truncated_chat_history)\n        print(f\"The next speaker is: {next_speaker.name}\") \n        print(f\"Message: {response}\")\n\n    async def update_speaking_queue(self):\n        \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n\n        # Remaining part of update",
      "created_at": "2023-05-20T19:05:45.116301",
      "sequence_order": 8,
      "parent_id": "59260ad4-f9ee-469b-b134-48743aee5a2a",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": false
      }
    },
    {
      "id": "e8f02324-d73a-4537-ada3-63b3511597f8",
      "role": "assistant",
      "content": "",
      "created_at": "2023-05-20T19:07:08.733640",
      "sequence_order": 9,
      "parent_id": "3294f04a-ae05-44d0-bff0-b39c073a06e6",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": false
      }
    },
    {
      "id": "aaa2800f-ff59-4d9a-88a1-7262b67fb6b5",
      "role": "user",
      "content": "yes you're right, I want to remove the concept of the queue from this code. Instead of the \"speaker pressure\" idea I want the code to update everyone's relevancy when the app first loads based on the parliament topic. And then I want the user to click reply in the right hand side where there is reply buttons near the relevancy percentage. Rather than this complicated queue I'd rather it be more user driven.\n\nCan you update this entire parliament.py file with those ideas and give it to me in one go?\n\nimport asyncio\n\nimport re\n\nimport random\n\nimport json\n\nimport openai\n\nfrom openai.error import RateLimitError\n\nimport time\n\nfrom typing import List\n\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15\n\nSPEAKING_PRESSURE_LIMIT = 100\n\nBROADCAST_DELAY = 10\n\nRELEVANCY_THRESHOLD = 100\n\nSTOPPED_TYPING = \"stopped_typing\"\n\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n\ndef init(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n\nself.name = agent_name\n\nself.speaking_pressure_increment = speaking_pressure_increment\n\nself.context = initial_context\n\nself.initial_context = initial_context\n\nself.speaking_pressure = speaking_pressure_increment\n\nself.tagged = False\n\nself.agent_type = agent_type\n\nself.agent_instance = agent_instance\n\nself.websocket = websocket\n\nself.parliament = parliament\n\nself.is_speaking = False\n\nself.relevancy_score = None\n\ndef get_response(self, truncated_chat_history):\n\nagent_message = self.get_agent_message(truncated_chat_history)\n\nreturn agent_message\n\ndef in_queue(self):\n\nreturn self.name in self.parliament.speaking_queue\n\nasync def calculate_relevancy(self, chat_context):\n\nrelevancy_score = 0\n\nif self.relevancy_score is None or self.initial_context != chat_context:\n\nprint(\"Calculating relevancy...\")\n\nprompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n\nprint(f\"Prompt: {prompt}\")\n\nresponse = openai.Completion.create(\n\nengine=\"text-davinci-001\", # or \"text-curie-002\" for Curie\n\nprompt=prompt,\n\ntemperature=0.0,\n\nmax_tokens=300\n\n )\n\nprint(f\"Response: {response}\")\n\n# Here we assume the model's response will be a single number.\n\n# The strip is used to remove any whitespace around the number\n\nstripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n\ntry:\n\nrelevancy_score = int(stripped_response)\n\nexcept ValueError:\n\nrelevancy_score = 0\n\nprint(f\"Relevancy score: {relevancy_score}\")\n\nelse:\n\nprint(\"Relevancy score already calculated.\")\n\ntime.sleep(.5)\n\nreturn relevancy_score\n\ndef should_speak(self):\n\nreturn self.parliament.speaker_manager.should_speak(self) # Call parliament's speaker_manager\n\nasync def increment_pressure(self):\n\nwhile True:\n\nself.speaking_pressure += self.speaking_pressure_increment\n\nasync def get_agent_message(self, truncated_chat_history):\n\n\"\"\"\n\n Generate a message from this agent based on the current chat history.\n\n \"\"\"\n\nmessage = \"\"\n\nif isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n\nresponse = await self.agent_instance.get_response(truncated_chat_history)\n\nmessage = f\"{response}\"\n\nreturn message\n\ndef in_queue(self):\n\nreturn self.name in self.parliament.speaking_queue.queue\n\nasync def speak(self):\n\ntruncated_chat_history = self.parliament.chat_history.truncated_chat_history\n\nif self.should_speak():\n\nself.is_speaking = True\n\nawait self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n\nawait self.websocket.send(json.dumps({\"action\": STOPPED_TYPING, \"sender\": self.name}))\n\nagent_message = await self.get_response(self.parliament.chat_history.truncated_chat_history)\n\nawait self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n\nself.speaking_pressure = 0\n\nself.is_speaking = False\n\nif self.in_queue():\n\nself.parliament.speaking_queue.remove(self.name)\n\ndef reset_pressure(self):\n\nself.speaking_pressure = 0\n\nclass ChatHistory:\n\ndef init(self):\n\nself.chat_history = []\n\nself.truncated_chat_history = \"\"\n\ndef add(self, message, sender, timestamp):\n\nself.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\nself.truncate_chat_history()\n\ndef truncate_chat_history(self, max_length=2000):\n\n\"\"\"\n\n Truncate the chat history to the last max_length characters.\n\n \"\"\"\n\nchat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n\nself.truncated_chat_history = chat_history_str[-max_length:]\n\ndef last_message(self):\n\nreturn self.chat_history[-1] if self.chat_history else None\n\nclass SpeakerManager:\n\ndef init(self, parliament):\n\nself.parliament = parliament\n\ndef should_speak(self, agent):\n\nreturn self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\nclass OpenAIAgent:\n\ndef init(self, initial_context: str):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api_key = \"REDACTED_API_KEY\"\n\nself.model = \"gpt-3.5-turbo\"\n\nself.initial_context = initial_context\n\ndef get_response(self, truncated_chat):\n\nsystem_msg = self.initial_context\n\nmessages=[]\n\nmessages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n\nmax_retries = 3\n\nretry_delay = 5\n\nfor i in range(max_retries):\n\ntry:\n\n# Call the OpenAI API with the messages array\n\nresponse = openai.ChatCompletion.create(\n\nmodel=self.model,\n\nmessages=messages,\n\nmax_tokens=150,\n\ntemperature=0.5,\n\ntop_p=1,\n\nfrequency_penalty=0,\n\npresence_penalty=0,\n\n )\n\n# Extract and return the assistant's response from the API response\n\nagent_response = response.choices[0].message[\"content\"].strip()\n\nprint(f\" {agent_response}\") # Add logging\n\nreturn agent_response\n\nexcept RateLimitError as e:\n\nprint(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n\nif i < max_retries - 1: # Don't sleep on the last iteration\n\ntime.sleep(retry_delay)\n\nelse:\n\nraise\n\nreturn \"Sorry, I am unable to respond at the moment.\"\n\nclass GPT4AllAgent:\n\ndef init(self):\n\n# Download and set up the GPT4All model\n\nself._initialize_gpt4all_model()\n\nself._initialize_llm_chain()\n\ndef initializegpt4all_model(self):\n\nlocal_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n\n Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n\nurl = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n\nresponse = requests.get(url, stream=True)\n\nwith open(local_path, 'wb') as f:\n\nfor chunk in tqdm(response.iter_content(chunk_size=8192)):\n\nif chunk:\n\nf.write(chunk)\n\nself.model_path = local_path\n\ndef initializellm_chain(self):\n\ntemplate = \"\"\"{chat_history}\n\n Question: {question}\n\n Answer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\n\ncallbacks = [StreamingStdOutCallbackHandler()]\n\nllm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\n\nself.llm_chain = LLMChain(prompt=prompt, llm=llm)\n\ndef get_response(self, chat_history, question):\n\nreturn self.llm_chain.run(chat_history=chat_history, question=question)\n\nclass Parliament:\n\ndef init(self, name: str):\n\nself.name = name\n\nself.speaker_manager = SpeakerManager(self)\n\nself.agents = {}\n\nself.chat_history = ChatHistory()\n\nself.speaking_queue = []\n\nself.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n\nself.typing_status = {}\n\ndef set_typing_status(self, agent_name: str, status: bool):\n\nself.typing_status[agent_name] = status\n\ndef get_typing_status(self, agent_name: str):\n\nreturn self.typing_status.get(agent_name, False)\n\nasync def broadcast_message(self, message, sender, timestamp):\n\n# Assign a value to first_agent_in_queue before using it\n\nfirst_agent_in_queue = self.speaking_queue[0] if self.speaking_queue else None\n\nif first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n\nawait self.agents[first_agent_in_queue].speak()\n\nself.chat_history.add(message, sender, timestamp)\n\nmentioned_agents = self.identify_and_tag_mentioned_agents(message)\n\nself.increment_speaking_pressure(mentioned_agents)\n\nawait self.update_speaking_queue()\n\nfor agent in self.agents.values():\n\nif not self.get_typing_status(agent.name):\n\nawait agent.speak()\n\nawait asyncio.sleep(BROADCAST_DELAY)\n\nfirst_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n\nif first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n\nawait self.agents[first_agent_in_queue].speak()\n\ndef add_to_speaking_queue(self, agent):\n\nif agent.name not in self.speaking_queue:\n\nself.speaking_queue.append(agent)\n\ndef increment_speaking_pressure(self, mentioned_agents):\n\nfor agent in self.agents.values():\n\nif agent.name not in mentioned_agents:\n\nagent.speaking_pressure += agent.speaking_pressure_increment\n\ndef identify_and_tag_mentioned_agents(self, message):\n\nmentioned_agents = []\n\nfor agent_name in self.agents:\n\nif '@'+agent_name in message:\n\nmentioned_agents.append(agent_name)\n\nself.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n\nself.agents[agent_name].tagged = True\n\nreturn mentioned_agents\n\ndef get_speaking_queue(self):\n\nreturn self.speaking_queue\n\ndef add_agent(self, agent: Agent):\n\nself.agents[agent.name] = agent\n\nself.typing_status[agent.name] = False\n\ndef remove_agent(self, agent_name: str):\n\nif agent_name not in self.agents:\n\nraise ValueError(f\"Agent '{agent_name}' not found.\")\n\ndel self.agents[agent_name]\n\ndef get_agent(self, agent_name: str):\n\nif agent_name not in self.agents:\n\nraise ValueError(f\"Agent '{agent_name}' not found.\")\n\nreturn self.agents[agent_name]\n\ndef add_to_chat_history(self, message, sender, timestamp):\n\nself.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\ndef add_tagged_agents_to_queue(self):\n\nfor agent in self.agents.values():\n\nif agent.tagged and agent.name not in self.speaking_queue.queue:\n\nself.speaking_queue.add(agent.name)\n\nagent.tagged = False\n\nagent.speaking_pressure = 0 # Reset speaking pressure\n\ndef add_high_pressure_agents_to_queue(self):\n\nfor agent in self.agents.values():\n\nif agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n\nself.speaking_queue.add(agent.name)\n\nagent.speaking_pressure = 0 # Reset speaking pressure\n\nasync def trigger_next_speaker(self):\n\nif self.speaking_queue:\n\nnext_speaker_name = self.speaking_queue.pop(0)\n\nnext_speaker = self.get_agent(next_speaker_name)\n\nresponse = next_speaker.get_response(self.chat_history.truncated_chat_history)\n\nprint(f\"The next speaker is: {next_speaker.name}\")\n\nprint(f\"Message: {response}\")\n\nasync def update_speaking_queue(self):\n\n\"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n\nmost_relevant_agent = None\n\nhighest_relevancy_score = -1\n\nfor agent in self.agents.values():\n\ntruncated_chat_history = self.chat_history.truncated_chat_history\n\nrelevancy_score = await agent.calculate_relevancy(truncated_chat_history)\n\nif relevancy_score > highest_relevancy_score:\n\nhighest_relevancy_score = relevancy_score\n\nmost_relevant_agent = agent\n\nprint(f\"Calculated relevancy for agent {agent.name}. Score: {relevancy_score}\")\n\n# Add the most relevant agent to the speaking queue\n\nif most_relevant_agent and self.speaking_queue.count(most_relevant_agent.name) == 0:\n\nself.speaking_queue.insert(0, most_relevant_agent.name)\n\nprint(f\"Added agent {most_relevant_agent.name} to the front of the speaking queue. Current queue: {self.speaking_queue}\")\n\nself.add_tagged_agents_to_queue()\n\nself.add_high_pressure_agents_to_queue()\n\nprint(f\"Triggering next speaker...\")\n\nawait self.trigger_next_speaker()\n\n#def get_sorted_agents_based_on_relevancy(self):\n\n# return sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history) if agent.calculate_relevancy(self.chat_history) is not None else 0, reverse=True)\n\nasync def get_agents_info(self) -> List[dict]:\n\nagents_info = []\n\nfor agent_name, agent in self.agents.items():\n\nagents_info.append({\n\n\"name\": agent_name,\n\n\"speaking_pressure\": agent.speaking_pressure,\n\n\"speaking_pressure_increment\": agent.speaking_pressure_increment,\n\n\"context\": agent.context,\n\n\"agent_type\": agent.agent_type,\n\n\"relevancy_score\": agent.relevancy_score # Return the cached score\n\n })\n\nreturn agents_info",
      "created_at": "2023-05-20T19:10:12.737510",
      "sequence_order": 10,
      "parent_id": "e8f02324-d73a-4537-ada3-63b3511597f8",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "c138d642-bb07-4685-9cf2-58ab048f0132",
      "role": "assistant",
      "content": "Given your request, I will replace the concept of a queue and speaker pressure with a user-driven approach, where relevancy is updated at the start. I will also add functionality for the user to initiate a response from a specific agent by clicking a reply button.\n\nHere's your updated `parliament.py`:\n\n```python\nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nRELEVANCY_THRESHOLD = 100\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n\n    def __init__(self, parliament, agent_name, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.tagged = False\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n\n    def get_response(self, truncated_chat_history):\n        agent_message = self.get_agent_message(truncated_chat_history)\n        return agent_message\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n\n    async def get_agent_message(self, truncated_chat_history):\n        \"\"\"\n        Generate a message from this agent based on the current chat history.\n        \"\"\"\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n\n    async def respond(self):\n        truncated_chat_history = self.parliament.chat_history.truncated_chat_history\n        await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n        await self.websocket.send(json.dumps({\"action\": \"stopped_typing\", \"sender\": self.name}))\n        agent_message = await self.get_response(self.parliament.chat_history.truncated_chat_history)\n        await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n\n    def reset_relevancy_score(self):\n        self.relevancy_score = None\n\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history()\n\n    def truncate_chat_history(self, max_length=2000):\n        chat_history_str = '\\n'.join([message[\"message",
      "created_at": "2023-05-20T19:11:37.801367",
      "sequence_order": 11,
      "parent_id": "aaa2800f-ff59-4d9a-88a1-7262b67fb6b5",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": false
      }
    },
    {
      "id": "84056654-c292-4aff-afee-a739835e6604",
      "role": "assistant",
      "content": " to: ChatGPT.AI",
      "created_at": "2023-05-20T19:11:45.757132",
      "sequence_order": 12,
      "parent_id": "c138d642-bb07-4685-9cf2-58ab048f0132",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa24e30-3048-4fe1-9634-e7fa825718e5",
      "role": "user",
      "content": "continue the code from the class ChatHistory:\n ",
      "created_at": "2023-05-20T19:12:50.085881",
      "sequence_order": 13,
      "parent_id": "84056654-c292-4aff-afee-a739835e6604",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "a28029f7-e1e4-452e-80ea-65fdd5cb6931",
      "role": "assistant",
      "content": "Apologies for the cutoff. Here is the continuation of the `ChatHistory` class:\n\n```python\n        for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def get_latest_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\n\nclass Parliament:\n    def __init__(self):\n        self.agents: List[Agent] = []\n        self.agent_types = {}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n\n    async def handle_client(self, websocket, path):\n        async for message in websocket:\n            message = json.loads(message)\n            if message['action'] == 'send_message':\n                self.chat_history.add(message['message'], message['sender'], message['timestamp'])\n                for agent in self.agents:\n                    if agent.websocket == websocket:\n                        agent.reset_relevancy_score()\n\n                if message.get('reply_agent', None):\n                    for agent in self.agents:\n                        if agent.name == message['reply_agent']:\n                            await agent.respond()\n\n            elif message['action'] == 'request_agents':\n                await self.send_agent_list(websocket)\n\n            elif message['action'] == UPDATE_AGENTS:\n                self.update_agents(message['agents'], websocket)\n\n    async def send_agent_list(self, websocket):\n        agents_list = [{\"name\": agent.name, \"context\": agent.context} for agent in self.agents]\n        await websocket.send(json.dumps({\"action\": \"receive_agents\", \"agents\": agents_list}))\n\n    def update_agents(self, agents, websocket):\n        self.agents = []\n        for agent in agents:\n            self.agents.append(Agent(self, agent['name'], agent['context'], agent['type'], self.agent_instances[agent['type']], websocket))\n\n    def add_agent_type(self, agent_type_name, agent_type_class):\n        self.agent_types[agent_type_name] = agent_type_class\n\n    def add_agent_instance(self, agent_instance_name, agent_instance):\n        self.agent_instances[agent_instance_name] = agent_instance\n```\n\nPlease note that you may have to further adapt this to the specific structure of your project and to handle possible exceptions or edge cases. Furthermore, this modification adds the possibility to specify an agent to reply to a message, but doesn't include any form of agent selection strategy. It also assumes that the `get_response` method of your agents is an asynchronous function. If this is not the case, you will need to adapt the `Agent.get_agent_message` method accordingly.",
      "created_at": "2023-05-20T19:13:31.497037",
      "sequence_order": 14,
      "parent_id": "aaa24e30-3048-4fe1-9634-e7fa825718e5",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2786c-c2b1-47d1-8efc-e749ad5e8a8a",
      "role": "user",
      "content": "update your code with these changes as well:\nAdded a topic attribute to store the conversation topic\nAdded a startup method to calculate and cache all agent relevancy scores based on the topic\nAdded an agent_reply method to have an agent respond when their \"reply\" button is clicked\nRemoved the speaking queue and all related logic\nSimplified the broadcast_message method by removing the queue log\nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nRELEVANCY_THRESHOLD = 100\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n\n    def __init__(self, parliament, agent_name, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.tagged = False\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n\n    def get_response(self, truncated_chat_history):\n        agent_message = self.get_agent_message(truncated_chat_history)\n        return agent_message\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n\n    async def get_agent_message(self, truncated_chat_history):\n        \"\"\"\n        Generate a message from this agent based on the current chat history.\n        \"\"\"\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n\n    async def respond(self):\n        truncated_chat_history = self.parliament.chat_history.truncated_chat_history\n        await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n        await self.websocket.send(json.dumps({\"action\": \"stopped_typing\", \"sender\": self.name}))\n        agent_message = await self.get_response(self.parliament.chat_history.truncated_chat_history)\n        await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n\n    def reset_relevancy_score(self):\n        self.relevancy_score = None\n\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history()\n\n    def truncate_chat_history(self, max_length=2000):\n        chat_history_str = '\\n'.join([message[\"message to: ChatGPT.AI\n        for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def get_latest_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\n\nclass Parliament:\n    def __init__(self):\n        self.agents: List[Agent] = []\n        self.agent_types = {}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n\n    async def handle_client(self, websocket, path):\n        async for message in websocket:\n            message = json.loads(message)\n            if message['action'] == 'send_message':\n                self.chat_history.add(message['message'], message['sender'], message['timestamp'])\n                for agent in self.agents:\n                    if agent.websocket == websocket:\n                        agent.reset_relevancy_score()\n\n                if message.get('reply_agent', None):\n                    for agent in self.agents:\n                        if agent.name == message['reply_agent']:\n                            await agent.respond()\n\n            elif message['action'] == 'request_agents':\n                await self.send_agent_list(websocket)\n\n            elif message['action'] == UPDATE_AGENTS:\n                self.update_agents(message['agents'], websocket)\n\n    async def send_agent_list(self, websocket):\n        agents_list = [{\"name\": agent.name, \"context\": agent.context} for agent in self.agents]\n        await websocket.send(json.dumps({\"action\": \"receive_agents\", \"agents\": agents_list}))\n\n    def update_agents(self, agents, websocket):\n        self.agents = []\n        for agent in agents:\n            self.agents.append(Agent(self, agent['name'], agent['context'], agent['type'], self.agent_instances[agent['type']], websocket))\n\n    def add_agent_type(self, agent_type_name, agent_type_class):\n        self.agent_types[agent_type_name] = agent_type_class\n\n    def add_agent_instance(self, agent_instance_name, agent_instance):\n        self.agent_instances[agent_instance_name] = agent_instance\n\nyour output should go class by class entire chunks I can copy and paste one at a time",
      "created_at": "2023-05-20T19:17:05.231794",
      "sequence_order": 15,
      "parent_id": "a28029f7-e1e4-452e-80ea-65fdd5cb6931",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "d2d1bd1c-b5e5-4978-a9fd-fea179973a66",
      "role": "assistant",
      "content": "Apologies for the confusion. Here's the updated code separated by classes.\n\nFirst, the `Agent` class:\n\n```python\nimport re\nimport openai\nimport time\n\nRELEVANCY_THRESHOLD = 100\n\nclass Agent:\n    def __init__(self, parliament, agent_name, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n\n    async def get_agent_message(self, truncated_chat_history):\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n\n    async def respond(self):\n        await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n        await self.websocket.send(json.dumps({\"action\": \"stopped_typing\", \"sender\": self.name}))\n        agent_message = await self.get_agent_message(self.parliament.chat_history.truncated_chat_history)\n        await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n\n    def reset_relevancy_score(self):\n        self.relevancy_score = None\n```\n\nNext, the `ChatHistory` class:\n\n```python\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history()\n\n    def truncate_chat_history(self, max_length=2000):\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def get_latest_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n```\n\nFinally, the `Parliament` class:\n\n```python\nimport json\nfrom typing import List\n\nUPDATE_AGENTS = \"update_agents\"\n\nclass Parliament:\n    def __init__(self):\n        self.agents: List[Agent] = []\n        self.agent_types = {}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n\n    async def handle_client(self, websocket, path):\n        async",
      "created_at": "2023-05-20T19:17:54.180559",
      "sequence_order": 16,
      "parent_id": "aaa2786c-c2b1-47d1-8efc-e749ad5e8a8a",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": false
      }
    },
    {
      "id": "fee825c4-bb76-4d9e-b211-1f8a223a0d28",
      "role": "assistant",
      "content": " for message in websocket:\n            message = json.loads(message)\n            if message['action'] == 'send_message':\n                self.chat_history.add(message['message'], message['sender'], message['timestamp'])\n                for agent in self.agents:\n                    if agent.websocket == websocket:\n                        agent.reset_relevancy_score()\n\n                if message.get('reply_agent', None):\n                    for agent in self.agents:\n                        if agent.name == message['reply_agent']:\n                            await agent.respond()\n\n            elif message['action'] == 'request_agents':\n                await self.send_agent_list(websocket)\n\n            elif message['action'] == UPDATE_AGENTS:\n                self.update_agents(message['agents'], websocket)\n\n    async def send_agent_list(self, websocket):\n        agents_list = [{\"name\": agent.name, \"context\": agent.context} for agent in self.agents]\n        await websocket.send(json.dumps({\"action\": \"receive_agents\", \"agents\": agents_list}))\n\n    def update_agents(self, agents, websocket):\n        self.agents = []\n        for agent in agents:\n            self.agents.append(Agent(self, agent['name'], agent['context'], agent['type'], self.agent_instances[agent['type']], websocket))\n\n    def add_agent_type(self, agent_type_name, agent_type_class):\n        self.agent_types[agent_type_name] = agent_type_class\n\n    def add_agent_instance(self, agent_instance_name, agent_instance):\n        self.agent_instances[agent_instance_name] = agent_instance\n```\n\nPlease ensure you copy each code block separately.",
      "created_at": "2023-05-20T19:20:34.880762",
      "sequence_order": 17,
      "parent_id": "d2d1bd1c-b5e5-4978-a9fd-fea179973a66",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa24282-134c-4f3d-bfbb-044dad940a36",
      "role": "user",
      "content": "error in parliament now: \nconnection handler failed\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 35, in chat\n    await self.handle_set_parliament(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 60, in handle_set_parliament\n    self.parliament = Parliament(parliament_name)\nTypeError: Parliament.__init__() takes 1 positional argument but 2 were given\nParliament.py\nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n\n    async def get_agent_message(self, truncated_chat_history):\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n\n    async def respond(self):\n        await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n        await self.websocket.send(json.dumps({\"action\": \"stopped_typing\", \"sender\": self.name}))\n        agent_message = await self.get_agent_message(self.parliament.chat_history.truncated_chat_history)\n        await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n\n    def reset_relevancy_score(self):\n        self.relevancy_score = None\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history()\n\n    def truncate_chat_history(self, max_length=2000):\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def get_latest_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages=[]\n        messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n\n\nclass GPT4AllAgent:\n    def __init__(self):\n        # Download and set up the GPT4All model\n        self._initialize_gpt4all_model()\n        self._initialize_llm_chain()\n\n    def _initialize_gpt4all_model(self):\n        local_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n\n        url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n        response = requests.get(url, stream=True)\n\n        with open(local_path, 'wb') as f:\n            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n                if chunk:\n                    f.write(chunk)\n\n        self.model_path = local_path\n\n    def _initialize_llm_chain(self):\n        template = \"\"\"{chat_history}\n\n        Question: {question}\n\n        Answer: Let's think step by step.\"\"\"\n        prompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\n\n        callbacks = [StreamingStdOutCallbackHandler()]\n        llm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\n        self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n\n    def get_response(self, chat_history, question):\n        return self.llm_chain.run(chat_history=chat_history, question=question)\n\n\n\n\n\nimport json\nfrom typing import List\n\nUPDATE_AGENTS = \"update_agents\"\n\nclass Parliament:\n    def __init__(self):\n        self.agents: List[Agent] = []\n        self.agent_types = {}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n\n    async def handle_client(self, websocket, path):\n        async for message in websocket:\n            message = json.loads(message)\n            if message['action'] == 'send_message':\n                self.chat_history.add(message['message'], message['sender'], message['timestamp'])\n                for agent in self.agents:\n                    if agent.websocket == websocket:\n                        agent.reset_relevancy_score()\n\n                if message.get('reply_agent', None):\n                    for agent in self.agents:\n                        if agent.name == message['reply_agent']:\n                            await agent.respond()\n\n            elif message['action'] == 'request_agents':\n                await self.send_agent_list(websocket)\n\n            elif message['action'] == UPDATE_AGENTS:\n                self.update_agents(message['agents'], websocket)\n\n    async def send_agent_list(self, websocket):\n        agents_list = [{\"name\": agent.name, \"context\": agent.context} for agent in self.agents]\n        await websocket.send(json.dumps({\"action\": \"receive_agents\", \"agents\": agents_list}))\n\n    def update_agents(self, agents, websocket):\n        self.agents = []\n        for agent in agents:\n            self.agents.append(Agent(self, agent['name'], agent['context'], agent['type'], self.agent_instances[agent['type']], websocket))\n\n    def add_agent_type(self, agent_type_name, agent_type_class):\n        self.agent_types[agent_type_name] = agent_type_class\n\n    def add_agent_instance(self, agent_instance_name, agent_instance):\n        self.agent_instances[agent_instance_name] = agent_instance\nServer.py:\nfrom datetime import datetime\nimport asyncio\nimport json\nfrom websockets import serve\nfrom parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent\nimport openai\n\n# Constants\nSET_PARLIAMENT = \"set_parliament\"\nSEND_MESSAGE = \"send_message\"\nADD_AGENTS = \"add_agents\"\nUPDATE_QUEUE = \"update_queue\"\nUPDATE_AGENTS = \"update_agents\"\nRECEIVE_MESSAGE = \"receive_message\"\nERROR = \"error\"\nTYPING = \"typing\"\nSTOPPED_TYPING = \"stopped_typing\"\n\nclass ParliamentServer:\n    def __init__(self, host=\"localhost\", port=8080):\n        self.host = host\n        self.port = port\n        self.parliament = None\n        self.start_server = serve(self.chat, self.host, self.port)\n\n    def configure_openai(self):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n\n    async def chat(self, websocket, path):\n        async for message in websocket:\n            data = json.loads(message)\n            action = data.get(\"action\")\n            if action == SET_PARLIAMENT:\n                await self.handle_set_parliament(websocket, data)\n            elif action == SEND_MESSAGE:\n                await self.handle_send_message(websocket, data)\n            elif action == ADD_AGENTS:\n                await self.handle_add_agents(websocket, data)\n            elif action in [TYPING, STOPPED_TYPING]:  \n                await self.handle_typing(websocket, data)\n\n    async def handle_typing(self, websocket, data):\n        sender = data.get('sender')\n        action = data.get('action')\n        is_typing = action == TYPING\n\n        self.parliament.set_typing_status(sender, is_typing)\n\n        # Send the typing status update to other clients:\n        await websocket.send(json.dumps({\n            \"action\": action,\n            \"sender\": sender,\n            \"is_typing\": is_typing\n        }))\n\n    async def handle_set_parliament(self, websocket, data):\n        parliament_name = data.get(\"name\")\n        if parliament_name:\n            self.parliament = Parliament(parliament_name)\n\n    async def handle_send_message(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n        sender = data.get(\"sender\")\n        user_message = data.get(\"message\")\n        timestamp = datetime.now()\n        await websocket.send(json.dumps({\n            \"action\": RECEIVE_MESSAGE,\n            \"message\": user_message,\n            \"sender\": sender,\n            \"timestamp\": timestamp.isoformat()}))\n        await self.parliament.broadcast_message(user_message, sender, timestamp)\n        print(f\"Broadcast message: {user_message}\")  # Add logging \n\n        # Sending agent info after broadcasting message\n        agent_info = await self.parliament.get_agents_info()  \n        await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        await self.update_queue(websocket)\n            \n    async def handle_add_agents(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n\n        agents_data = data.get(\"agents\")\n        if not agents_data:\n            await self.send_error(websocket, \"No agent data provided.\")\n            return\n\n        for agent_data in agents_data:\n            agent_name = agent_data.get(\"name\")  # Extract the name\n            speaking_pressure_increment = int(agent_data.get(\"speaking_pressure_increment\"))\n\n            other_agents = \", \".join([agent['name'] for agent in agents_data if agent['name'] != agent_name])\n            initial_context = (\n                f\"Hello assistant, your name is: @{agent_data.get('name')} and your context is \"\n                f\"{agent_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n                f\"alongside your fellow agents in a parliament, which is a sort \"\n                f\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n                f\"with you are {other_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n                f\"{agent_data.get('speaking_pressure_increment')} out of 100\"\n            )\n            agent_type = agent_data.get(\"type\")\n            agent_class = self.parliament.agent_types.get(agent_type)  # Get OpenAIAgent or GPT4AllAgent\n            agent_instance = agent_class(initial_context)  # Properly instantiate the class\n            if isinstance(agent_instance, self.parliament.agent_types[agent_type]):\n                agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n                agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n                self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n            else: \n                print(\"Error occurred attempting to get agent message!\")\n                return \"Sorry, I'm unable to generate a relevant response at this time.\" \n                await self.send_error(websocket, f\"Unknown agent type: {agent_type}\")\n                continue\n\n\n    async def update_queue(self, websocket):\n        if self.parliament:\n            speaking_queue = self.parliament.get_speaking_queue()\n            print(f\"Queue updated: {speaking_queue}\")\n            await websocket.send(json.dumps({\"action\": UPDATE_QUEUE, \"queue\": speaking_queue}))\n\n    async def send_error(self, websocket, message):\n        await websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\n    def run(self):\n        self.configure_openai()\n        asyncio.get_event_loop().run_until_complete(self.start_server)\n        print(\"Starting WebSocket server...\")\n        print(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n        asyncio.get_event_loop().run_forever()\n\n\nif __name__ == \"__main__\":\n    server = ParliamentServer()\n    server.run()\n",
      "created_at": "2023-05-20T19:22:57.458634",
      "sequence_order": 18,
      "parent_id": "fee825c4-bb76-4d9e-b211-1f8a223a0d28",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "8d04c1ea-8adf-415c-9411-55fecccb0468",
      "role": "assistant",
      "content": "The problem lies in the line `self.parliament = Parliament(parliament_name)` inside the `handle_set_parliament` method of your `ParliamentServer` class in `server.py`. This line is causing the `TypeError: Parliament.__init__() takes 1 positional argument but 2 were given` error because your `Parliament` class does not accept any arguments in its constructor.\n\nYour `Parliament` class is currently defined as follows:\n\n```python\nclass Parliament:\n    def __init__(self):\n        self.agents: List[Agent] = []\n        self.agent_types = {}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n```\n\nAs you can see, the `__init__` method of the `Parliament` class doesn't accept any arguments besides `self`, but in your `ParliamentServer` class, you're trying to pass `parliament_name` as an argument, hence the error.\n\nIf you want your `Parliament` class to accept a name when it is instantiated, you need to modify the `__init__` method of the `Parliament` class to take an additional argument. Here's an example:\n\n```python\nclass Parliament:\n    def __init__(self, name: str):  # Added name argument\n        self.name = name  # Added this line to store the name\n        self.agents: List[Agent] = []\n        self.agent_types = {}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n```\n\nNow, you can create a new `Parliament` with a name like this: `self.parliament = Parliament(parliament_name)`. Just ensure you update any other parts of your code that instantiate a `Parliament` object to pass in the required `name` argument.",
      "created_at": "2023-05-20T19:23:25.838214",
      "sequence_order": 19,
      "parent_id": "aaa24282-134c-4f3d-bfbb-044dad940a36",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa20aaf-3cbb-4f39-ba02-73cdc57292b4",
      "role": "user",
      "content": "error I server.py \nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 39, in chat\n    await self.handle_add_agents(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 107, in handle_add_agents\n    agent_instance = agent_class(initial_context)  # Properly instantiate the class\nTypeError: 'NoneType' object is not callable\n\nfrom datetime import datetime\nimport asyncio\nimport json\nfrom websockets import serve\nfrom parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent\nimport openai\n\n# Constants\nSET_PARLIAMENT = \"set_parliament\"\nSEND_MESSAGE = \"send_message\"\nADD_AGENTS = \"add_agents\"\nUPDATE_QUEUE = \"update_queue\"\nUPDATE_AGENTS = \"update_agents\"\nRECEIVE_MESSAGE = \"receive_message\"\nERROR = \"error\"\nTYPING = \"typing\"\nSTOPPED_TYPING = \"stopped_typing\"\n\nclass ParliamentServer:\n    def __init__(self, host=\"localhost\", port=8080):\n        self.host = host\n        self.port = port\n        self.parliament = None\n        self.start_server = serve(self.chat, self.host, self.port)\n\n    def configure_openai(self):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n\n    async def chat(self, websocket, path):\n        async for message in websocket:\n            data = json.loads(message)\n            action = data.get(\"action\")\n            if action == SET_PARLIAMENT:\n                await self.handle_set_parliament(websocket, data)\n            elif action == SEND_MESSAGE:\n                await self.handle_send_message(websocket, data)\n            elif action == ADD_AGENTS:\n                await self.handle_add_agents(websocket, data)\n            elif action in [TYPING, STOPPED_TYPING]:  \n                await self.handle_typing(websocket, data)\n\n    async def handle_typing(self, websocket, data):\n        sender = data.get('sender')\n        action = data.get('action')\n        is_typing = action == TYPING\n\n        self.parliament.set_typing_status(sender, is_typing)\n\n        # Send the typing status update to other clients:\n        await websocket.send(json.dumps({\n            \"action\": action,\n            \"sender\": sender,\n            \"is_typing\": is_typing\n        }))\n\n    async def handle_set_parliament(self, websocket, data):\n        parliament_name = data.get(\"name\")\n        if parliament_name:\n            self.parliament = Parliament(parliament_name)\n\n    async def handle_send_message(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n        sender = data.get(\"sender\")\n        user_message = data.get(\"message\")\n        timestamp = datetime.now()\n        await websocket.send(json.dumps({\n            \"action\": RECEIVE_MESSAGE,\n            \"message\": user_message,\n            \"sender\": sender,\n            \"timestamp\": timestamp.isoformat()}))\n        await self.parliament.broadcast_message(user_message, sender, timestamp)\n        print(f\"Broadcast message: {user_message}\")  # Add logging \n\n        # Sending agent info after broadcasting message\n        agent_info = await self.parliament.get_agents_info()  \n        await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        await self.update_queue(websocket)\n            \n    async def handle_add_agents(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n\n        agents_data = data.get(\"agents\")\n        if not agents_data:\n            await self.send_error(websocket, \"No agent data provided.\")\n            return\n\n        for agent_data in agents_data:\n            agent_name = agent_data.get(\"name\")  # Extract the name\n            speaking_pressure_increment = int(agent_data.get(\"speaking_pressure_increment\"))\n\n            other_agents = \", \".join([agent['name'] for agent in agents_data if agent['name'] != agent_name])\n            initial_context = (\n                f\"Hello assistant, your name is: @{agent_data.get('name')} and your context is \"\n                f\"{agent_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n                f\"alongside your fellow agents in a parliament, which is a sort \"\n                f\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n                f\"with you are {other_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n                f\"{agent_data.get('speaking_pressure_increment')} out of 100\"\n            )\n            agent_type = agent_data.get(\"type\")\n            agent_class = self.parliament.agent_types.get(agent_type)  # Get OpenAIAgent or GPT4AllAgent\n            agent_instance = agent_class(initial_context)  # Properly instantiate the class\n            if isinstance(agent_instance, self.parliament.agent_types[agent_type]):\n                agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n                agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n                self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n            else: \n                print(\"Error occurred attempting to get agent message!\")\n                return \"Sorry, I'm unable to generate a relevant response at this time.\" \n                await self.send_error(websocket, f\"Unknown agent type: {agent_type}\")\n                continue\n\n\n    async def update_queue(self, websocket):\n        if self.parliament:\n            speaking_queue = self.parliament.get_speaking_queue()\n            print(f\"Queue updated: {speaking_queue}\")\n            await websocket.send(json.dumps({\"action\": UPDATE_QUEUE, \"queue\": speaking_queue}))\n\n    async def send_error(self, websocket, message):\n        await websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\n    def run(self):\n        self.configure_openai()\n        asyncio.get_event_loop().run_until_complete(self.start_server)\n        print(\"Starting WebSocket server...\")\n        print(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n        asyncio.get_event_loop().run_forever()\n\n\nif __name__ == \"__main__\":\n    server = ParliamentServer()\n    server.run()\n\nparliament.py\nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n\n    async def get_agent_message(self, truncated_chat_history):\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n\n    async def respond(self):\n        await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n        await self.websocket.send(json.dumps({\"action\": \"stopped_typing\", \"sender\": self.name}))\n        agent_message = await self.get_agent_message(self.parliament.chat_history.truncated_chat_history)\n        await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n\n    def reset_relevancy_score(self):\n        self.relevancy_score = None\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history()\n\n    def truncate_chat_history(self, max_length=2000):\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def get_latest_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages=[]\n        messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n\n\nclass GPT4AllAgent:\n    def __init__(self):\n        # Download and set up the GPT4All model\n        self._initialize_gpt4all_model()\n        self._initialize_llm_chain()\n\n    def _initialize_gpt4all_model(self):\n        local_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n\n        url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n        response = requests.get(url, stream=True)\n\n        with open(local_path, 'wb') as f:\n            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n                if chunk:\n                    f.write(chunk)\n\n        self.model_path = local_path\n\n    def _initialize_llm_chain(self):\n        template = \"\"\"{chat_history}\n\n        Question: {question}\n\n        Answer: Let's think step by step.\"\"\"\n        prompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\n\n        callbacks = [StreamingStdOutCallbackHandler()]\n        llm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\n        self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n\n    def get_response(self, chat_history, question):\n        return self.llm_chain.run(chat_history=chat_history, question=question)\n\n\n\n\n\nimport json\nfrom typing import List\n\nUPDATE_AGENTS = \"update_agents\"\n\nclass Parliament:\n    def __init__(self, name: str):  # Added name argument\n        self.name = name  # Added this line to store the name\n        self.agents: List[Agent] = []\n        self.agent_types = {}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n\n    async def handle_client(self, websocket, path):\n        async for message in websocket:\n            message = json.loads(message)\n            if message['action'] == 'send_message':\n                self.chat_history.add(message['message'], message['sender'], message['timestamp'])\n                for agent in self.agents:\n                    if agent.websocket == websocket:\n                        agent.reset_relevancy_score()\n\n                if message.get('reply_agent', None):\n                    for agent in self.agents:\n                        if agent.name == message['reply_agent']:\n                            await agent.respond()\n\n            elif message['action'] == 'request_agents':\n                await self.send_agent_list(websocket)\n\n            elif message['action'] == UPDATE_AGENTS:\n                self.update_agents(message['agents'], websocket)\n\n    async def send_agent_list(self, websocket):\n        agents_list = [{\"name\": agent.name, \"context\": agent.context} for agent in self.agents]\n        await websocket.send(json.dumps({\"action\": \"receive_agents\", \"agents\": agents_list}))\n\n    def update_agents(self, agents, websocket):\n        self.agents = []\n        for agent in agents:\n            self.agents.append(Agent(self, agent['name'], agent['context'], agent['type'], self.agent_instances[agent['type']], websocket))\n\n    def add_agent_type(self, agent_type_name, agent_type_class):\n        self.agent_types[agent_type_name] = agent_type_class\n\n    def add_agent_instance(self, agent_instance_name, agent_instance):\n        self.agent_instances[agent_instance_name] = agent_instance\n",
      "created_at": "2023-05-20T19:25:00.732876",
      "sequence_order": 20,
      "parent_id": "8d04c1ea-8adf-415c-9411-55fecccb0468",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "aff0e731-45fc-47f6-9203-a17150dfd199",
      "role": "assistant",
      "content": "The issue seems to be related to the `agent_class` variable not being callable. This typically happens when the `get` function is unable to find the agent type in the `agent_types` dictionary of `parliament`. In this case, `None` is returned, and the TypeError is raised when the script attempts to instantiate this non-callable `None`.\n\nThe potential problem could be in this line:\n\n```python\nagent_class = self.parliament.agent_types.get(agent_type)  # Get OpenAIAgent or GPT4AllAgent\n```\n\nThis line is trying to fetch the appropriate agent class (`OpenAIAgent` or `GPT4AllAgent`) from the `agent_types` dictionary based on the `agent_type` key. If the `agent_type` does not exist in the dictionary, `get` will return `None`, which will cause the TypeError you're seeing.\n\nTo solve this issue, there are two steps you can take:\n\n1. Ensure that the `agent_type` value sent from the client is always one of the keys in the `parliament.agent_types` dictionary.\n2. Add error checking to handle the case where the agent type doesn't exist. Here's an example:\n\n```python\nagent_class = self.parliament.agent_types.get(agent_type)\nif agent_class is None:\n    await self.send_error(websocket, f\"Unknown agent type: {agent_type}\")\n    continue\nagent_instance = agent_class(initial_context)  # Properly instantiate the class\n```\n\nIn the `Parliament` class, the `agent_types` dictionary should be initialized like this:\n\n```python\nself.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n```\n\nEnsure that the `agent_type` sent from the client always matches one of the keys in this dictionary.\n\nKeep in mind, the `TypeError: 'NoneType' object is not callable` is a common Python error and usually occurs when you try to call a `NoneType` object as a function. This error indicates that you attempted to call a function on a `NoneType` object. In Python, `None` is a special singleton object used to denote the absence of a value. It has no methods, so calling it raises an `AttributeError`.",
      "created_at": "2023-05-20T19:25:37.513032",
      "sequence_order": 21,
      "parent_id": "aaa20aaf-3cbb-4f39-ba02-73cdc57292b4",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa25fe6-1890-4523-a4e9-c0d4df93985e",
      "role": "user",
      "content": "connection handler failed\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 39, in chat\n    await self.handle_add_agents(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 110, in handle_add_agents\n    agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\nTypeError: Agent.__init__() takes from 6 to 7 positional arguments but 8 were given\nparliament.py\nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n\n    async def get_agent_message(self, truncated_chat_history):\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n\n    async def respond(self):\n        await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n        await self.websocket.send(json.dumps({\"action\": \"stopped_typing\", \"sender\": self.name}))\n        agent_message = await self.get_agent_message(self.parliament.chat_history.truncated_chat_history)\n        await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n\n    def reset_relevancy_score(self):\n        self.relevancy_score = None\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history()\n\n    def truncate_chat_history(self, max_length=2000):\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def get_latest_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages=[]\n        messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n\n\nclass GPT4AllAgent:\n    def __init__(self):\n        # Download and set up the GPT4All model\n        self._initialize_gpt4all_model()\n        self._initialize_llm_chain()\n\n    def _initialize_gpt4all_model(self):\n        local_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n\n        url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n        response = requests.get(url, stream=True)\n\n        with open(local_path, 'wb') as f:\n            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n                if chunk:\n                    f.write(chunk)\n\n        self.model_path = local_path\n\n    def _initialize_llm_chain(self):\n        template = \"\"\"{chat_history}\n\n        Question: {question}\n\n        Answer: Let's think step by step.\"\"\"\n        prompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\n\n        callbacks = [StreamingStdOutCallbackHandler()]\n        llm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\n        self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n\n    def get_response(self, chat_history, question):\n        return self.llm_chain.run(chat_history=chat_history, question=question)\n\n\n\n\n\nimport json\nfrom typing import List\n\nUPDATE_AGENTS = \"update_agents\"\n\nclass Parliament:\n    def __init__(self, name: str):  # Added name argument\n        self.name = name  # Added this line to store the name\n        self.agents: List[Agent] = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n\n    async def handle_client(self, websocket, path):\n        async for message in websocket:\n            message = json.loads(message)\n            if message['action'] == 'send_message':\n                self.chat_history.add(message['message'], message['sender'], message['timestamp'])\n                for agent in self.agents:\n                    if agent.websocket == websocket:\n                        agent.reset_relevancy_score()\n\n                if message.get('reply_agent', None):\n                    for agent in self.agents:\n                        if agent.name == message['reply_agent']:\n                            await agent.respond()\n\n            elif message['action'] == 'request_agents':\n                await self.send_agent_list(websocket)\n\n            elif message['action'] == UPDATE_AGENTS:\n                self.update_agents(message['agents'], websocket)\n\n    async def send_agent_list(self, websocket):\n        agents_list = [{\"name\": agent.name, \"context\": agent.context} for agent in self.agents]\n        await websocket.send(json.dumps({\"action\": \"receive_agents\", \"agents\": agents_list}))\n\n    def update_agents(self, agents, websocket):\n        self.agents = []\n        for agent in agents:\n            self.agents.append(Agent(self, agent['name'], agent['context'], agent['type'], self.agent_instances[agent['type']], websocket))\n\n    def add_agent_type(self, agent_type_name, agent_type_class):\n        self.agent_types[agent_type_name] = agent_type_class\n\n    def add_agent_instance(self, agent_instance_name, agent_instance):\n        self.agent_instances[agent_instance_name] = agent_instance\nserver.py\nfrom datetime import datetime\nimport asyncio\nimport json\nfrom websockets import serve\nfrom parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent\nimport openai\n\n# Constants\nSET_PARLIAMENT = \"set_parliament\"\nSEND_MESSAGE = \"send_message\"\nADD_AGENTS = \"add_agents\"\nUPDATE_QUEUE = \"update_queue\"\nUPDATE_AGENTS = \"update_agents\"\nRECEIVE_MESSAGE = \"receive_message\"\nERROR = \"error\"\nTYPING = \"typing\"\nSTOPPED_TYPING = \"stopped_typing\"\n\nclass ParliamentServer:\n    def __init__(self, host=\"localhost\", port=8080):\n        self.host = host\n        self.port = port\n        self.parliament = None\n        self.start_server = serve(self.chat, self.host, self.port)\n\n    def configure_openai(self):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n\n    async def chat(self, websocket, path):\n        async for message in websocket:\n            data = json.loads(message)\n            action = data.get(\"action\")\n            if action == SET_PARLIAMENT:\n                await self.handle_set_parliament(websocket, data)\n            elif action == SEND_MESSAGE:\n                await self.handle_send_message(websocket, data)\n            elif action == ADD_AGENTS:\n                await self.handle_add_agents(websocket, data)\n            elif action in [TYPING, STOPPED_TYPING]:  \n                await self.handle_typing(websocket, data)\n\n    async def handle_typing(self, websocket, data):\n        sender = data.get('sender')\n        action = data.get('action')\n        is_typing = action == TYPING\n\n        self.parliament.set_typing_status(sender, is_typing)\n\n        # Send the typing status update to other clients:\n        await websocket.send(json.dumps({\n            \"action\": action,\n            \"sender\": sender,\n            \"is_typing\": is_typing\n        }))\n\n    async def handle_set_parliament(self, websocket, data):\n        parliament_name = data.get(\"name\")\n        if parliament_name:\n            self.parliament = Parliament(parliament_name)\n\n    async def handle_send_message(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n        sender = data.get(\"sender\")\n        user_message = data.get(\"message\")\n        timestamp = datetime.now()\n        await websocket.send(json.dumps({\n            \"action\": RECEIVE_MESSAGE,\n            \"message\": user_message,\n            \"sender\": sender,\n            \"timestamp\": timestamp.isoformat()}))\n        await self.parliament.broadcast_message(user_message, sender, timestamp)\n        print(f\"Broadcast message: {user_message}\")  # Add logging \n\n        # Sending agent info after broadcasting message\n        agent_info = await self.parliament.get_agents_info()  \n        await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        await self.update_queue(websocket)\n            \n    async def handle_add_agents(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n\n        agents_data = data.get(\"agents\")\n        if not agents_data:\n            await self.send_error(websocket, \"No agent data provided.\")\n            return\n\n        for agent_data in agents_data:\n            agent_name = agent_data.get(\"name\")  # Extract the name\n            speaking_pressure_increment = int(agent_data.get(\"speaking_pressure_increment\"))\n\n            other_agents = \", \".join([agent['name'] for agent in agents_data if agent['name'] != agent_name])\n            initial_context = (\n                f\"Hello assistant, your name is: @{agent_data.get('name')} and your context is \"\n                f\"{agent_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n                f\"alongside your fellow agents in a parliament, which is a sort \"\n                f\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n                f\"with you are {other_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n                f\"{agent_data.get('speaking_pressure_increment')} out of 100\"\n            )\n            agent_type = agent_data.get(\"type\")\n            agent_class = self.parliament.agent_types.get(agent_type)  # Get OpenAIAgent or GPT4AllAgent\n            agent_instance = agent_class(initial_context)  # Properly instantiate the class\n            if isinstance(agent_instance, self.parliament.agent_types[agent_type]):\n                agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n                agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n                self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n            else: \n                print(\"Error occurred attempting to get agent message!\")\n                return \"Sorry, I'm unable to generate a relevant response at this time.\" \n                await self.send_error(websocket, f\"Unknown agent type: {agent_type}\")\n                continue\n\n\n    async def update_queue(self, websocket):\n        if self.parliament:\n            speaking_queue = self.parliament.get_speaking_queue()\n            print(f\"Queue updated: {speaking_queue}\")\n            await websocket.send(json.dumps({\"action\": UPDATE_QUEUE, \"queue\": speaking_queue}))\n\n    async def send_error(self, websocket, message):\n        await websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\n    def run(self):\n        self.configure_openai()\n        asyncio.get_event_loop().run_until_complete(self.start_server)\n        print(\"Starting WebSocket server...\")\n        print(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n        asyncio.get_event_loop().run_forever()\n\n\nif __name__ == \"__main__\":\n    server = ParliamentServer()\n    server.run()\n",
      "created_at": "2023-05-20T19:26:33.706705",
      "sequence_order": 22,
      "parent_id": "aff0e731-45fc-47f6-9203-a17150dfd199",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "ff69deef-722e-4ae4-860d-16fc8115c14a",
      "role": "assistant",
      "content": "The error you're experiencing appears to be due to a mismatch in the expected and actual number of arguments passed into the `Agent` class constructor. It expects between 6 and 7 positional arguments, but 8 were given in the following function call:\n\n```python\nagent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n```\n\nLooking at your `Agent` class definition:\n\n```python\nclass Agent:\n    def __init__(self, parliament, agent_name, initial_context, agent_type, agent_instance, websocket=None):\n        # Code\n```\n\nIt seems like the `speaking_pressure_increment` argument is not actually defined in your class constructor. To resolve this issue, you'll need to update the `Agent` class's constructor to accept this argument, like this:\n\n```python\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n```\n\nThen you can use `speaking_pressure_increment` elsewhere in your class as needed.",
      "created_at": "2023-05-20T19:26:57.801977",
      "sequence_order": 23,
      "parent_id": "aaa25fe6-1890-4523-a4e9-c0d4df93985e",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2c771-b904-4962-ac37-a7db628ed6aa",
      "role": "user",
      "content": "py\nStarting WebSocket server...\nWebSocket server is running on ws://localhost:8080\nconnection handler failed\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 39, in chat\n    await self.handle_add_agents(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 111, in handle_add_agents\n    self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\nAttributeError: 'Parliament' object has no attribute 'add_agent'\nparliament.py\nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n\n    async def get_agent_message(self, truncated_chat_history):\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n\n    async def respond(self):\n        await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n        await self.websocket.send(json.dumps({\"action\": \"stopped_typing\", \"sender\": self.name}))\n        agent_message = await self.get_agent_message(self.parliament.chat_history.truncated_chat_history)\n        await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n\n    def reset_relevancy_score(self):\n        self.relevancy_score = None\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history()\n\n    def truncate_chat_history(self, max_length=2000):\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def get_latest_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages=[]\n        messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n\n\nclass GPT4AllAgent:\n    def __init__(self):\n        # Download and set up the GPT4All model\n        self._initialize_gpt4all_model()\n        self._initialize_llm_chain()\n\n    def _initialize_gpt4all_model(self):\n        local_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n\n        url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n        response = requests.get(url, stream=True)\n\n        with open(local_path, 'wb') as f:\n            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n                if chunk:\n                    f.write(chunk)\n\n        self.model_path = local_path\n\n    def _initialize_llm_chain(self):\n        template = \"\"\"{chat_history}\n\n        Question: {question}\n\n        Answer: Let's think step by step.\"\"\"\n        prompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\n\n        callbacks = [StreamingStdOutCallbackHandler()]\n        llm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\n        self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n\n    def get_response(self, chat_history, question):\n        return self.llm_chain.run(chat_history=chat_history, question=question)\n\n\n\n\n\nimport json\nfrom typing import List\n\nUPDATE_AGENTS = \"update_agents\"\n\nclass Parliament:\n    def __init__(self, name: str):  # Added name argument\n        self.name = name  # Added this line to store the name\n        self.agents: List[Agent] = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n\n    async def handle_client(self, websocket, path):\n        async for message in websocket:\n            message = json.loads(message)\n            if message['action'] == 'send_message':\n                self.chat_history.add(message['message'], message['sender'], message['timestamp'])\n                for agent in self.agents:\n                    if agent.websocket == websocket:\n                        agent.reset_relevancy_score()\n\n                if message.get('reply_agent', None):\n                    for agent in self.agents:\n                        if agent.name == message['reply_agent']:\n                            await agent.respond()\n\n            elif message['action'] == 'request_agents':\n                await self.send_agent_list(websocket)\n\n            elif message['action'] == UPDATE_AGENTS:\n                self.update_agents(message['agents'], websocket)\n\n    async def send_agent_list(self, websocket):\n        agents_list = [{\"name\": agent.name, \"context\": agent.context} for agent in self.agents]\n        await websocket.send(json.dumps({\"action\": \"receive_agents\", \"agents\": agents_list}))\n\n    def update_agents(self, agents, websocket):\n        self.agents = []\n        for agent in agents:\n            self.agents.append(Agent(self, agent['name'], agent['context'], agent['type'], self.agent_instances[agent['type']], websocket))\n\n    def add_agent_type(self, agent_type_name, agent_type_class):\n        self.agent_types[agent_type_name] = agent_type_class\n\n    def add_agent_instance(self, agent_instance_name, agent_instance):\n        self.agent_instances[agent_instance_name] = agent_instance\nserver.py\nfrom datetime import datetime\nimport asyncio\nimport json\nfrom websockets import serve\nfrom parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent\nimport openai\n\n# Constants\nSET_PARLIAMENT = \"set_parliament\"\nSEND_MESSAGE = \"send_message\"\nADD_AGENTS = \"add_agents\"\nUPDATE_QUEUE = \"update_queue\"\nUPDATE_AGENTS = \"update_agents\"\nRECEIVE_MESSAGE = \"receive_message\"\nERROR = \"error\"\nTYPING = \"typing\"\nSTOPPED_TYPING = \"stopped_typing\"\n\nclass ParliamentServer:\n    def __init__(self, host=\"localhost\", port=8080):\n        self.host = host\n        self.port = port\n        self.parliament = None\n        self.start_server = serve(self.chat, self.host, self.port)\n\n    def configure_openai(self):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n\n    async def chat(self, websocket, path):\n        async for message in websocket:\n            data = json.loads(message)\n            action = data.get(\"action\")\n            if action == SET_PARLIAMENT:\n                await self.handle_set_parliament(websocket, data)\n            elif action == SEND_MESSAGE:\n                await self.handle_send_message(websocket, data)\n            elif action == ADD_AGENTS:\n                await self.handle_add_agents(websocket, data)\n            elif action in [TYPING, STOPPED_TYPING]:  \n                await self.handle_typing(websocket, data)\n\n    async def handle_typing(self, websocket, data):\n        sender = data.get('sender')\n        action = data.get('action')\n        is_typing = action == TYPING\n\n        self.parliament.set_typing_status(sender, is_typing)\n\n        # Send the typing status update to other clients:\n        await websocket.send(json.dumps({\n            \"action\": action,\n            \"sender\": sender,\n            \"is_typing\": is_typing\n        }))\n\n    async def handle_set_parliament(self, websocket, data):\n        parliament_name = data.get(\"name\")\n        if parliament_name:\n            self.parliament = Parliament(parliament_name)\n\n    async def handle_send_message(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n        sender = data.get(\"sender\")\n        user_message = data.get(\"message\")\n        timestamp = datetime.now()\n        await websocket.send(json.dumps({\n            \"action\": RECEIVE_MESSAGE,\n            \"message\": user_message,\n            \"sender\": sender,\n            \"timestamp\": timestamp.isoformat()}))\n        await self.parliament.broadcast_message(user_message, sender, timestamp)\n        print(f\"Broadcast message: {user_message}\")  # Add logging \n\n        # Sending agent info after broadcasting message\n        agent_info = await self.parliament.get_agents_info()  \n        await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        await self.update_queue(websocket)\n            \n    async def handle_add_agents(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n\n        agents_data = data.get(\"agents\")\n        if not agents_data:\n            await self.send_error(websocket, \"No agent data provided.\")\n            return\n\n        for agent_data in agents_data:\n            agent_name = agent_data.get(\"name\")  # Extract the name\n            speaking_pressure_increment = int(agent_data.get(\"speaking_pressure_increment\"))\n\n            other_agents = \", \".join([agent['name'] for agent in agents_data if agent['name'] != agent_name])\n            initial_context = (\n                f\"Hello assistant, your name is: @{agent_data.get('name')} and your context is \"\n                f\"{agent_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n                f\"alongside your fellow agents in a parliament, which is a sort \"\n                f\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n                f\"with you are {other_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n                f\"{agent_data.get('speaking_pressure_increment')} out of 100\"\n            )\n            agent_type = agent_data.get(\"type\")\n            agent_class = self.parliament.agent_types.get(agent_type)  # Get OpenAIAgent or GPT4AllAgent\n            agent_instance = agent_class(initial_context)  # Properly instantiate the class\n            if isinstance(agent_instance, self.parliament.agent_types[agent_type]):\n                agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n                agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n                self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n            else: \n                print(\"Error occurred attempting to get agent message!\")\n                return \"Sorry, I'm unable to generate a relevant response at this time.\" \n                await self.send_error(websocket, f\"Unknown agent type: {agent_type}\")\n                continue\n\n\n    async def update_queue(self, websocket):\n        if self.parliament:\n            speaking_queue = self.parliament.get_speaking_queue()\n            print(f\"Queue updated: {speaking_queue}\")\n            await websocket.send(json.dumps({\"action\": UPDATE_QUEUE, \"queue\": speaking_queue}))\n\n    async def send_error(self, websocket, message):\n        await websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\n    def run(self):\n        self.configure_openai()\n        asyncio.get_event_loop().run_until_complete(self.start_server)\n        print(\"Starting WebSocket server...\")\n        print(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n        asyncio.get_event_loop().run_forever()\n\n\nif __name__ == \"__main__\":\n    server = ParliamentServer()\n    server.run()\n",
      "created_at": "2023-05-20T19:29:16.351088",
      "sequence_order": 24,
      "parent_id": "ff69deef-722e-4ae4-860d-16fc8115c14a",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "ee3781e0-8546-4e50-8346-a84cd491dfaf",
      "role": "assistant",
      "content": "From the given traceback, the error arises from line 111 of `server.py`. It suggests that the `Parliament` object does not have an attribute `add_agent`.\n\n```python\nself.parliament.add_agent(agent)  # Pass the agent instance to add_agent\nAttributeError: 'Parliament' object has no attribute 'add_agent'\n```\n\nHowever, in the provided code of the `Parliament` class, there indeed isn't a method `add_agent`. This is most likely the cause of the error.\n\n```python\nclass Parliament:\n    def __init__(self, name: str):  # Added name argument\n        self.name = name  # Added this line to store the name\n        self.agents: List[Agent] = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n\n    # There are other methods but none named 'add_agent'.\n```\n\nTo fix this issue, you need to add an `add_agent` method in your `Parliament` class. The method should take an `Agent` object and add it to the `agents` list of the `Parliament` object. Here is an example:\n\n```python\nclass Parliament:\n    # Existing methods...\n\n    def add_agent(self, agent):\n        self.agents.append(agent)\n```\n\nThis method simply takes an `Agent` instance as an argument and appends it to the `agents` attribute of the `Parliament` instance.\n\nMake sure to update the `Parliament` class in your actual code to include this new method. Then, the line that's causing the error in `server.py` should work as intended.",
      "created_at": "2023-05-20T19:29:57.223372",
      "sequence_order": 25,
      "parent_id": "aaa2c771-b904-4962-ac37-a7db628ed6aa",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2629a-83e8-4e19-b8c7-80357f4115dc",
      "role": "user",
      "content": "error\nWebSocket server is running on ws://localhost:8080\nconnection handler failed\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 41, in chat\n    await self.handle_typing(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 48, in handle_typing\n    self.parliament.set_typing_status(sender, is_typing)\nAttributeError: 'Parliament' object has no attribute 'set_typing_status'\nWhy can't I set typing status on the agents directly rather than sending into parliament?\nserver.py\n# Constants\nSET_PARLIAMENT = \"set_parliament\"\nSEND_MESSAGE = \"send_message\"\nADD_AGENTS = \"add_agents\"\nUPDATE_QUEUE = \"update_queue\"\nUPDATE_AGENTS = \"update_agents\"\nRECEIVE_MESSAGE = \"receive_message\"\nERROR = \"error\"\nTYPING = \"typing\"\nSTOPPED_TYPING = \"stopped_typing\"\n\nclass ParliamentServer:\n    def __init__(self, host=\"localhost\", port=8080):\n        self.host = host\n        self.port = port\n        self.parliament = None\n        self.start_server = serve(self.chat, self.host, self.port)\n\n    def configure_openai(self):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n\n    async def chat(self, websocket, path):\n        async for message in websocket:\n            data = json.loads(message)\n            action = data.get(\"action\")\n            if action == SET_PARLIAMENT:\n                await self.handle_set_parliament(websocket, data)\n            elif action == SEND_MESSAGE:\n                await self.handle_send_message(websocket, data)\n            elif action == ADD_AGENTS:\n                await self.handle_add_agents(websocket, data)\n            elif action in [TYPING, STOPPED_TYPING]:  \n                await self.handle_typing(websocket, data)\n\n    async def handle_typing(self, websocket, data):\n        sender = data.get('sender')\n        action = data.get('action')\n        is_typing = action == TYPING\n\n        self.parliament.set_typing_status(sender, is_typing)\n\n        # Send the typing status update to other clients:\n        await websocket.send(json.dumps({\n            \"action\": action,\n            \"sender\": sender,\n            \"is_typing\": is_typing\n        }))\n\n    async def handle_set_parliament(self, websocket, data):\n        parliament_name = data.get(\"name\")\n        if parliament_name:\n            self.parliament = Parliament(parliament_name)\n\n    async def handle_send_message(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n        sender = data.get(\"sender\")\n        user_message = data.get(\"message\")\n        timestamp = datetime.now()\n        await websocket.send(json.dumps({\n            \"action\": RECEIVE_MESSAGE,\n            \"message\": user_message,\n            \"sender\": sender,\n            \"timestamp\": timestamp.isoformat()}))\n        await self.parliament.broadcast_message(user_message, sender, timestamp)\n        print(f\"Broadcast message: {user_message}\")  # Add logging \n\n        # Sending agent info after broadcasting message\n        agent_info = await self.parliament.get_agents_info()  \n        await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        await self.update_queue(websocket)\n            \n    async def handle_add_agents(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n\n        agents_data = data.get(\"agents\")\n        if not agents_data:\n            await self.send_error(websocket, \"No agent data provided.\")\n            return\n\n        for agent_data in agents_data:\n            agent_name = agent_data.get(\"name\")  # Extract the name\n            speaking_pressure_increment = int(agent_data.get(\"speaking_pressure_increment\"))\n\n            other_agents = \", \".join([agent['name'] for agent in agents_data if agent['name'] != agent_name])\n            initial_context = (\n                f\"Hello assistant, your name is: @{agent_data.get('name')} and your context is \"\n                f\"{agent_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n                f\"alongside your fellow agents in a parliament, which is a sort \"\n                f\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n                f\"with you are {other_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n                f\"{agent_data.get('speaking_pressure_increment')} out of 100\"\n            )\n            agent_type = agent_data.get(\"type\")\n            agent_class = self.parliament.agent_types.get(agent_type)  # Get OpenAIAgent or GPT4AllAgent\n            agent_instance = agent_class(initial_context)  # Properly instantiate the class\n            if isinstance(agent_instance, self.parliament.agent_types[agent_type]):\n                agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n                agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n                self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n            else: \n                print(\"Error occurred attempting to get agent message!\")\n                return \"Sorry, I'm unable to generate a relevant response at this time.\" \n                await self.send_error(websocket, f\"Unknown agent type: {agent_type}\")\n                continue\n\n\n    async def update_queue(self, websocket):\n        if self.parliament:\n            speaking_queue = self.parliament.get_speaking_queue()\n            print(f\"Queue updated: {speaking_queue}\")\n            await websocket.send(json.dumps({\"action\": UPDATE_QUEUE, \"queue\": speaking_queue}))\n\n    async def send_error(self, websocket, message):\n        await websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\n    def run(self):\n        self.configure_openai()\n        asyncio.get_event_loop().run_until_complete(self.start_server)\n        print(\"Starting WebSocket server...\")\n        print(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n        asyncio.get_event_loop().run_forever()\n\n\nif __name__ == \"__main__\":\n    server = ParliamentServer()\n    server.run()\nparliament.py\nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n\n    async def get_agent_message(self, truncated_chat_history):\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n\n    async def respond(self):\n        await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n        await self.websocket.send(json.dumps({\"action\": \"stopped_typing\", \"sender\": self.name}))\n        agent_message = await self.get_agent_message(self.parliament.chat_history.truncated_chat_history)\n        await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n\n    def reset_relevancy_score(self):\n        self.relevancy_score = None\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history()\n\n    def truncate_chat_history(self, max_length=2000):\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def get_latest_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages=[]\n        messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n\n\nclass GPT4AllAgent:\n    def __init__(self):\n        # Download and set up the GPT4All model\n        self._initialize_gpt4all_model()\n        self._initialize_llm_chain()\n\n    def _initialize_gpt4all_model(self):\n        local_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n\n        url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n        response = requests.get(url, stream=True)\n\n        with open(local_path, 'wb') as f:\n            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n                if chunk:\n                    f.write(chunk)\n\n        self.model_path = local_path\n\n    def _initialize_llm_chain(self):\n        template = \"\"\"{chat_history}\n\n        Question: {question}\n\n        Answer: Let's think step by step.\"\"\"\n        prompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\n\n        callbacks = [StreamingStdOutCallbackHandler()]\n        llm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\n        self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n\n    def get_response(self, chat_history, question):\n        return self.llm_chain.run(chat_history=chat_history, question=question)\n\n\n\n\n\nimport json\nfrom typing import List\n\nUPDATE_AGENTS = \"update_agents\"\n\nclass Parliament:\n    def __init__(self, name: str):  # Added name argument\n        self.name = name  # Added this line to store the name\n        self.agents: List[Agent] = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n\n    async def handle_client(self, websocket, path):\n        async for message in websocket:\n            message = json.loads(message)\n            if message['action'] == 'send_message':\n                self.chat_history.add(message['message'], message['sender'], message['timestamp'])\n                for agent in self.agents:\n                    if agent.websocket == websocket:\n                        agent.reset_relevancy_score()\n\n                if message.get('reply_agent', None):\n                    for agent in self.agents:\n                        if agent.name == message['reply_agent']:\n                            await agent.respond()\n\n            elif message['action'] == 'request_agents':\n                await self.send_agent_list(websocket)\n\n            elif message['action'] == UPDATE_AGENTS:\n                self.update_agents(message['agents'], websocket)\n\n    async def send_agent_list(self, websocket):\n        agents_list = [{\"name\": agent.name, \"context\": agent.context} for agent in self.agents]\n        await websocket.send(json.dumps({\"action\": \"receive_agents\", \"agents\": agents_list}))\n\n    def update_agents(self, agents, websocket):\n        self.agents = []\n        for agent in agents:\n            self.agents.append(Agent(self, agent['name'], agent['context'], agent['type'], self.agent_instances[agent['type']], websocket))\n\n    def add_agent_type(self, agent_type_name, agent_type_class):\n        self.agent_types[agent_type_name] = agent_type_class\n\n    def add_agent_instance(self, agent_instance_name, agent_instance):\n        self.agent_instances[agent_instance_name] = agent_instance\n\n    def add_agent(self, agent):\n        self.agents.append(agent)",
      "created_at": "2023-05-20T19:34:18.317701",
      "sequence_order": 26,
      "parent_id": "ee3781e0-8546-4e50-8346-a84cd491dfaf",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "824dcf9e-ba99-4aff-bf27-c7717cfaa35c",
      "role": "assistant",
      "content": "The issue here seems to be that the 'Parliament' object doesn't have a 'set_typing_status' method. This method appears to be intended to update whether or not an agent is currently typing. The error occurs when the WebSocket server tries to invoke this method on the 'Parliament' object in the 'handle_typing' method of the 'ParliamentServer' class.\n\nIn order to resolve this issue, you could do one of the following:\n\n1. Add a 'set_typing_status' method to the 'Parliament' class. This method would accept two arguments: the 'sender' (presumably the agent's name) and 'is_typing' (a boolean indicating whether or not the agent is typing).\n\n```python\nclass Parliament:\n    # ...existing code...\n\n    def set_typing_status(self, sender: str, is_typing: bool):\n        # Implement method logic here\n```\n\n2. If it's preferable to manage typing status at the agent level (i.e., if each 'Agent' object should keep track of whether it's typing), you could instead add a 'set_typing_status' method to the 'Agent' class:\n\n```python\nclass Agent:\n    # ...existing code...\n\n    def set_typing_status(self, is_typing: bool):\n        # Implement method logic here\n```\n\nThen, in the 'handle_typing' method of the 'ParliamentServer' class, you'd need to find the agent corresponding to 'sender' and call 'set_typing_status' on that agent. Note that this would require 'Parliament' to have a method for retrieving an agent by name.\n\n3. If neither of these approaches is suitable, and you want to be able to set the typing status directly from the WebSocket server without involving the 'Parliament' object, you'd need to revise your design to store the typing status information somewhere that the 'ParliamentServer' can access it. For example, this might involve storing a mapping from agent names to typing statuses in the 'ParliamentServer' itself. However, this could potentially complicate your design, particularly if typing statuses need to be synchronized across multiple instances of 'ParliamentServer'.\n\nUltimately, the best solution will depend on the specifics of your application and how you want to manage state across different objects.",
      "created_at": "2023-05-20T19:35:11.202963",
      "sequence_order": 27,
      "parent_id": "aaa2629a-83e8-4e19-b8c7-80357f4115dc",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2561e-747c-473e-b828-c14521a1bd39",
      "role": "user",
      "content": "error \nStarting WebSocket server...\nWebSocket server is running on ws://localhost:8080\nconnection handler failed\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 37, in chat\n    await self.handle_send_message(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 74, in handle_send_message\n    await self.parliament.broadcast_message(user_message, sender, timestamp)\nAttributeError: 'Parliament' object has no attribute 'broadcast_message'\n\nOld broadcast messages code:\n    async def broadcast_message(self, message, sender, timestamp):\n        # Assign a value to first_agent_in_queue before using it\n        first_agent_in_queue = self.speaking_queue[0] if self.speaking_queue else None\n\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n        await self.update_speaking_queue()\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):  \n                await agent.speak() \n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        first_agent_in_queue = self.speaking_queue.pop(0) if self.speaking_queue else None\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\nnew parliament.ai\nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n        \n    def set_typing_status(self, status: bool):\n        self.is_typing = status \n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n\n    async def get_agent_message(self, truncated_chat_history):\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n\n    async def respond(self):\n        await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n        await self.websocket.send(json.dumps({\"action\": \"stopped_typing\", \"sender\": self.name}))\n        agent_message = await self.get_agent_message(self.parliament.chat_history.truncated_chat_history)\n        await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n\n    def reset_relevancy_score(self):\n        self.relevancy_score = None\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history()\n\n    def truncate_chat_history(self, max_length=2000):\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def get_latest_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages=[]\n        messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n\n\nclass GPT4AllAgent:\n    def __init__(self):\n        # Download and set up the GPT4All model\n        self._initialize_gpt4all_model()\n        self._initialize_llm_chain()\n\n    def _initialize_gpt4all_model(self):\n        local_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n\n        url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n        response = requests.get(url, stream=True)\n\n        with open(local_path, 'wb') as f:\n            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n                if chunk:\n                    f.write(chunk)\n\n        self.model_path = local_path\n\n    def _initialize_llm_chain(self):\n        template = \"\"\"{chat_history}\n\n        Question: {question}\n\n        Answer: Let's think step by step.\"\"\"\n        prompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\n\n        callbacks = [StreamingStdOutCallbackHandler()]\n        llm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\n        self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n\n    def get_response(self, chat_history, question):\n        return self.llm_chain.run(chat_history=chat_history, question=question)\n\n\n\n\n\nimport json\nfrom typing import List\n\nUPDATE_AGENTS = \"update_agents\"\n\nclass Parliament:\n    def __init__(self, name: str):  # Added name argument\n        self.name = name  # Added this line to store the name\n        self.agents: List[Agent] = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n\n    async def handle_client(self, websocket, path):\n        async for message in websocket:\n            message = json.loads(message)\n            if message['action'] == 'send_message':\n                self.chat_history.add(message['message'], message['sender'], message['timestamp'])\n                for agent in self.agents:\n                    if agent.websocket == websocket:\n                        agent.reset_relevancy_score()\n\n                if message.get('reply_agent', None):\n                    for agent in self.agents:\n                        if agent.name == message['reply_agent']:\n                            await agent.respond()\n\n            elif message['action'] == 'request_agents':\n                await self.send_agent_list(websocket)\n\n            elif message['action'] == UPDATE_AGENTS:\n                self.update_agents(message['agents'], websocket)\n\n    async def send_agent_list(self, websocket):\n        agents_list = [{\"name\": agent.name, \"context\": agent.context} for agent in self.agents]\n        await websocket.send(json.dumps({\"action\": \"receive_agents\", \"agents\": agents_list}))\n\n    def update_agents(self, agents, websocket):\n        self.agents = []\n        for agent in agents:\n            self.agents.append(Agent(self, agent['name'], agent['context'], agent['type'], self.agent_instances[agent['type']], websocket))\n\n    def add_agent_type(self, agent_type_name, agent_type_class):\n        self.agent_types[agent_type_name] = agent_type_class\n\n    def add_agent_instance(self, agent_instance_name, agent_instance):\n        self.agent_instances[agent_instance_name] = agent_instance\n\n    def add_agent(self, agent):\n        self.agents.append(agent)\n\nrelevant code in server.py\n\n    async def handle_set_parliament(self, websocket, data):\n        parliament_name = data.get(\"name\")\n        if parliament_name:\n            self.parliament = Parliament(parliament_name)\n\n    async def handle_send_message(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n        sender = data.get(\"sender\")\n        user_message = data.get(\"message\")\n        timestamp = datetime.now()\n        await websocket.send(json.dumps({\n            \"action\": RECEIVE_MESSAGE,\n            \"message\": user_message,\n            \"sender\": sender,\n            \"timestamp\": timestamp.isoformat()}))\n        await self.parliament.broadcast_message(user_message, sender, timestamp)\n        print(f\"Broadcast message: {user_message}\")  # Add logging \n\n        # Sending agent info after broadcasting message\n        agent_info = await self.parliament.get_agents_info()  \n        await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        await self.update_queue(websocket)",
      "created_at": "2023-05-20T19:39:06.878147",
      "sequence_order": 28,
      "parent_id": "824dcf9e-ba99-4aff-bf27-c7717cfaa35c",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "a144c11f-cc87-42a4-875a-38cb7e7b6ade",
      "role": "assistant",
      "content": "The error message indicates that the 'Parliament' object has no attribute 'broadcast_message'. This is because in your new `Parliament` class implementation, the method `broadcast_message()` does not exist.\n\nFrom your old code snippet, it seems `broadcast_message` was a method that manages the chat dynamics of the conversation. It was responsible for managing the speaking queue of the agents, incrementing their speaking pressure, updating the chat history, and deciding when an agent should speak.\n\nIn the new version of your `Parliament` class, it seems like you've divided the logic of `broadcast_message` across different methods and classes (e.g., the `Agent` and `ChatHistory` classes). You need to ensure that these tasks are being handled correctly in your new implementation. \n\nHere's a sketch of how you might implement something similar to `broadcast_message` in the new structure:\n\n```python\nclass Parliament:\n    def __init__(self, name: str):\n        ...\n        self.speaking_queue = deque()\n\n    ...\n\n    async def broadcast_message(self, message, sender, timestamp):\n        self.chat_history.add(message, sender, timestamp)\n\n        for agent in self.agents:\n            if agent.websocket == websocket:\n                agent.reset_relevancy_score()\n\n        if self.speaking_queue:\n            first_agent_in_queue = self.speaking_queue[0]\n            if not first_agent_in_queue.is_typing:  \n                await first_agent_in_queue.respond()\n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        if self.speaking_queue:\n            first_agent_in_queue = self.speaking_queue.popleft()\n            if not first_agent_in_queue.is_typing:\n                await first_agent_in_queue.respond()\n```\n\nPlease note, however, that this is a rough sketch. You'll need to adapt it to fit your needs, and there may be other changes you'll need to make in your code to support this logic. You may also need to add or modify other parts of your code to manage the speaking queue, manage the speaking pressure, and identify mentioned agents, among other things.\n\nYou may also want to consider creating a separate `ConversationManager` class or similar, to manage the dynamics of the conversation. This could help to keep your code better organized and make it easier to manage complex conversation dynamics.",
      "created_at": "2023-05-20T19:39:57.578684",
      "sequence_order": 29,
      "parent_id": "aaa2561e-747c-473e-b828-c14521a1bd39",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa2a780-8572-47f7-a703-bf86c3a9830f",
      "role": "user",
      "content": "error broadcast messages:\nStarting WebSocket server...\nWebSocket server is running on ws://localhost:8080\nconnection handler failed\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 37, in chat\n    await self.handle_send_message(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 74, in handle_send_message\n    await self.parliament.broadcast_message(user_message, sender, timestamp)\nAttributeError: 'Parliament' object has no attribute 'broadcast_message'\nServer.py\nfrom datetime import datetime\nimport asyncio\nimport json\nfrom websockets import serve\nfrom parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent\nimport openai\n\n# Constants\nSET_PARLIAMENT = \"set_parliament\"\nSEND_MESSAGE = \"send_message\"\nADD_AGENTS = \"add_agents\"\nUPDATE_QUEUE = \"update_queue\"\nUPDATE_AGENTS = \"update_agents\"\nRECEIVE_MESSAGE = \"receive_message\"\nERROR = \"error\"\nTYPING = \"typing\"\nSTOPPED_TYPING = \"stopped_typing\"\n\nclass ParliamentServer:\n    def __init__(self, host=\"localhost\", port=8080):\n        self.host = host\n        self.port = port\n        self.parliament = None\n        self.start_server = serve(self.chat, self.host, self.port)\n\n    def configure_openai(self):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n\n    async def chat(self, websocket, path):\n        async for message in websocket:\n            data = json.loads(message)\n            action = data.get(\"action\")\n            if action == SET_PARLIAMENT:\n                await self.handle_set_parliament(websocket, data)\n            elif action == SEND_MESSAGE:\n                await self.handle_send_message(websocket, data)\n            elif action == ADD_AGENTS:\n                await self.handle_add_agents(websocket, data)\n            elif action in [TYPING, STOPPED_TYPING]:  \n                await self.handle_typing(websocket, data)\n\n    async def handle_typing(self, websocket, data):\n        sender = data.get('sender')\n        action = data.get('action')\n        is_typing = action == TYPING\n        for agent in self.parliament.agents:\n            if agent.name == sender:\n                agent.set_typing_status(is_typing)\n        # Send the typing status update to other clients:\n        await websocket.send(json.dumps({\n            \"action\": action,\n            \"sender\": sender,\n            \"is_typing\": is_typing \n        })) \n        \n    async def handle_set_parliament(self, websocket, data):\n        parliament_name = data.get(\"name\")\n        if parliament_name:\n            self.parliament = Parliament(parliament_name)\n\n    async def handle_send_message(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n        sender = data.get(\"sender\")\n        user_message = data.get(\"message\")\n        timestamp = datetime.now()\n        await websocket.send(json.dumps({\n            \"action\": RECEIVE_MESSAGE,\n            \"message\": user_message,\n            \"sender\": sender,\n            \"timestamp\": timestamp.isoformat()}))\n        await self.parliament.broadcast_message(user_message, sender, timestamp)\n        print(f\"Broadcast message: {user_message}\")  # Add logging \n\n        # Sending agent info after broadcasting message\n        agent_info = await self.parliament.get_agents_info()  \n        await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n        await self.update_queue(websocket)\n            \n    async def handle_add_agents(self, websocket, data):\n        if not self.parliament:\n            await self.send_error(websocket, \"Parliament not set.\")\n            return\n\n        agents_data = data.get(\"agents\")\n        if not agents_data:\n            await self.send_error(websocket, \"No agent data provided.\")\n            return\n\n        for agent_data in agents_data:\n            agent_name = agent_data.get(\"name\")  # Extract the name\n            speaking_pressure_increment = int(agent_data.get(\"speaking_pressure_increment\"))\n\n            other_agents = \", \".join([agent['name'] for agent in agents_data if agent['name'] != agent_name])\n            initial_context = (\n                f\"Hello assi of 100\"\n            )\n            agent_type = agent_data.get(\"type\")\n            agent_class = self.parliament.agent_types.get(agent_type)  # Get OpenAIAgent or GPT4AllAgent\n            agent_instance = agent_class(initial_context)  # Properly instantiate the class\n            if isinstance(agent_instance, self.parliament.agent_types[agent_type]):\n                agent_instance = OpenAIAgent(initial_context)  # Create the OpenAIAgent instance\n                agent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket)\n                self.parliament.add_agent(agent)  # Pass the agent instance to add_agent\n            else: \n                print(\"Error occurred attempting to get agent message!\")\n                return \"Sorry, I'm unable to generate a relevant response at this time.\" \n                await self.send_error(websocket, f\"Unknown agent type: {agent_type}\")\n                continue\n\n\n    async def update_queue(self, websocket):\n        if self.parliament:\n            speaking_queue = self.parliament.get_speaking_queue()\n            print(f\"Queue updated: {speaking_queue}\")\n            await websocket.send(json.dumps({\"action\": UPDATE_QUEUE, \"queue\": speaking_queue}))\n\n    async def send_error(self, websocket, message):\n        await websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\n    def run(self):\n        self.configure_openai()\n        asyncio.get_event_loop().run_until_complete(self.start_server)\n        print(\"Starting WebSocket server...\")\n        print(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n        asyncio.get_event_loop().run_forever()\n\n\nif __name__ == \"__main__\":\n    server = ParliamentServer()\n    server.run()\nparliament.py\nimport asyncio\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n        \n    def set_typing_status(self, status: bool):\n        self.is_typing = status \n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n\n    async def get_agent_message(self, truncated_chat_history):\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n\n    async def respond(self):\n        await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n        await self.websocket.send(json.dumps({\"action\": \"stopped_typing\", \"sender\": self.name}))\n        agent_message = await self.get_agent_message(self.parliament.chat_history.truncated_chat_history)\n        await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n\n    def reset_relevancy_score(self):\n        self.relevancy_score = None\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history()\n\n    def truncate_chat_history(self, max_length=2000):\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def get_latest_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages=[]\n        messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n\n\n\n\nimport json\nfrom typing import List\n\nUPDATE_AGENTS = \"update_agents\"\n\nclass Parliament:\n    def __init__(self, name: str):  # Added name argument\n        self.name = name  # Added this line to store the name\n        self.agents: List[Agent] = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n\n    async def handle_client(self, websocket, path):\n        async for message in websocket:\n            message = json.loads(message)\n            if message['action'] == 'send_message':\n                self.chat_history.add(message['message'], message['sender'], message['timestamp'])\n                for agent in self.agents:\n                    if agent.websocket == websocket:\n                        agent.reset_relevancy_score()\n\n                if message.get('reply_agent', None):\n                    for agent in self.agents:\n                        if agent.name == message['reply_agent']:\n                            await agent.respond()\n\n            elif message['action'] == 'request_agents':\n                await self.send_agent_list(websocket)\n\n            elif message['action'] == UPDATE_AGENTS:\n                self.update_agents(message['agents'], websocket)\n\n    async def send_agent_list(self, websocket):\n        agents_list = [{\"name\": agent.name, \"context\": agent.context} for agent in self.agents]\n        await websocket.send(json.dumps({\"action\": \"receive_agents\", \"agents\": agents_list}))\n\n    def update_agents(self, agents, websocket):\n        self.agents = []\n        for agent in agents:\n            self.agents.append(Agent(self, agent['name'], agent['context'], agent['type'], self.agent_instances[agent['type']], websocket))\n\n    def add_agent_type(self, agent_type_name, agent_type_class):\n        self.agent_types[agent_type_name] = agent_type_class\n\n    def add_agent_instance(self, agent_instance_name, agent_instance):\n        self.agent_instances[agent_instance_name] = agent_instance\n\n    def add_agent(self, agent):\n        self.agents.append(agent)",
      "created_at": "2023-05-20T19:41:35.623092",
      "sequence_order": 30,
      "parent_id": "a144c11f-cc87-42a4-875a-38cb7e7b6ade",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "e8367e06-6fec-4844-9740-2b5345a1a576",
      "role": "assistant",
      "content": "The error message `AttributeError: 'Parliament' object has no attribute 'broadcast_message'` is indicating that the `broadcast_message` method is being called on an instance of the `Parliament` class, but that method is not defined in the `Parliament` class.\n\nThe `broadcast_message` method is called in the `ParliamentServer` class within the `handle_send_message` method. \n\nTo fix this, you should add a `broadcast_message` method to the `Parliament` class. The `broadcast_message` method needs to accept the arguments `user_message`, `sender`, and `timestamp` and it should perform the necessary broadcast operations.\n\nHere is an example of how you could define it:\n\n```python\nclass Parliament:\n    ...\n    async def broadcast_message(self, user_message, sender, timestamp):\n        for agent in self.agents:\n            if agent.websocket is not None and agent.name != sender:\n                await agent.websocket.send(json.dumps({\n                    \"action\": \"receive_message\",\n                    \"message\": user_message,\n                    \"sender\": sender,\n                    \"timestamp\": timestamp.isoformat()\n                }))\n        print(f\"Broadcast message: {user_message}\")\n```\nThis example assumes that each agent has a `websocket` attribute and that a message should be sent to each agent (except the sender) whenever `broadcast_message` is called. Adjust it as needed for your use case.\n\nOnce you've defined `broadcast_message` in the `Parliament` class, the `AttributeError` should be resolved.\n\nPlease note that this is a general example, you need to consider how broadcasting works in your specific case. Broadcasting might involve ensuring the message is received by the intended recipients and could involve retries, acknowledgements, error handling, etc.",
      "created_at": "2023-05-20T19:42:15.411865",
      "sequence_order": 31,
      "parent_id": "aaa2a780-8572-47f7-a703-bf86c3a9830f",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    }
  ]
}