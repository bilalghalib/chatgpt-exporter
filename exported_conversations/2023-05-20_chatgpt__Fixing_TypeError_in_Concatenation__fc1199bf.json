{
  "id": "fc1199bf-6d96-47f6-91b4-c752c6fea246",
  "source": "chatgpt",
  "title": "\"Fixing TypeError in Concatenation\"",
  "created_at": "2023-05-20T19:49:15.421283",
  "updated_at": "2023-05-20T19:49:18",
  "summary": null,
  "message_count": 2,
  "messages": [
    {
      "id": "aaa22939-3aa4-471c-b092-470537d31667",
      "role": "user",
      "content": "error:\nconnection handler failed\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n    await self.ws_handler(self)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n    return await cast(\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 37, in chat\n    await self.handle_send_message(websocket, data)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/server.py\", line 74, in handle_send_message\n    await self.parliament.broadcast_message(user_message, sender, timestamp)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 231, in broadcast_message\n    mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n  File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament_backend/parliament.py\", line 243, in identify_and_tag_mentioned_agents\n    if '@'+agent_name in message:\nTypeError: can only concatenate str (not \"Agent\") to str\nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, is_typing, websocket=None):\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n        self.is_typing = is_typing  \n        \n    def set_typing_status(self, status: bool):\n        self.is_typing = status\n\n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",\n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300\n            )\n            print(f\"Response: {response}\")\n            stripped_response = re.sub(\"[^0-9]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n\n    async def get_agent_message(self, truncated_chat_history):\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history)\n            message = f\"{response}\"\n        return message\n\n    async def respond(self):\n        await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n        await self.websocket.send(json.dumps({\"action\": \"stopped_typing\", \"sender\": self.name}))\n        agent_message = await self.get_agent_message(self.parliament.chat_history.truncated_chat_history)\n        await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n\n    def reset_relevancy_score(self):\n        self.relevancy_score = None\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history()\n\n    def truncate_chat_history(self, max_length=2000):\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def get_latest_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages=[]\n        messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()\n                print(f\" {agent_response}\")  # Add logging\n                return agent_response\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n\n\nclass GPT4AllAgent:\n    def __init__(self):\n        # Download and set up the GPT4All model\n        self._initialize_gpt4all_model()\n        self._initialize_llm_chain()\n\n    def _initialize_gpt4all_model(self):\n        local_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n\n        url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n        response = requests.get(url, stream=True)\n\n        with open(local_path, 'wb') as f:\n            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n                if chunk:\n                    f.write(chunk)\n\n        self.model_path = local_path\n\n    def _initialize_llm_chain(self):\n        template = \"\"\"{chat_history}\n\n        Question: {question}\n\n        Answer: Let's think step by step.\"\"\"\n        prompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\n\n        callbacks = [StreamingStdOutCallbackHandler()]\n        llm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\n        self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n\n    def get_response(self, chat_history, question):\n        return self.llm_chain.run(chat_history=chat_history, question=question)\n\n\n\n\n\nimport json\nfrom typing import List\n\nUPDATE_AGENTS = \"update_agents\"\n\nclass Parliament:\n    def __init__(self, name: str):  # Added name argument\n        self.name = name  # Added this line to store the name\n        self.agents: List[Agent] = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n\n    async def handle_client(self, websocket, path):\n        async for message in websocket:\n            message = json.loads(message)\n            if message['action'] == 'send_message':\n                self.chat_history.add(message['message'], message['sender'], message['timestamp'])\n                for agent in self.agents:\n                    if agent.websocket == websocket:\n                        agent.reset_relevancy_score()\n\n                if message.get('reply_agent', None):\n                    for agent in self.agents:\n                        if agent.name == message['reply_agent']:\n                            await agent.respond()\n\n            elif message['action'] == 'request_agents':\n                await self.send_agent_list(websocket)\n\n            elif message['action'] == UPDATE_AGENTS:\n                self.update_agents(message['agents'], websocket)\n\n    async def send_agent_list(self, websocket):\n        agents_list = [{\"name\": agent.name, \"context\": agent.context} for agent in self.agents]\n        await websocket.send(json.dumps({\"action\": \"receive_agents\", \"agents\": agents_list}))\n\n    def update_agents(self, agents, websocket):\n        self.agents = []\n        for agent in agents:\n            self.agents.append(Agent(self, agent['name'], agent['context'], agent['type'], self.agent_instances[agent['type']], websocket))\n\n    def add_agent_type(self, agent_type_name, agent_type_class):\n        self.agent_types[agent_type_name] = agent_type_class\n\n    def add_agent_instance(self, agent_instance_name, agent_instance):\n        self.agent_instances[agent_instance_name] = agent_instance\n\n    def add_agent(self, agent):\n        self.agents.append(agent)\n        \n    async def broadcast_message(self, message, sender, timestamp):\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):  \n                await agent.speak() \n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents",
      "created_at": "2023-05-20T19:49:15.441774",
      "sequence_order": 0,
      "parent_id": "eed697a6-b67e-47bd-a64f-51c844c62795",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "c31b0930-cb47-4de0-92ee-854c1ca67965",
      "role": "assistant",
      "content": "The error message indicates that there is a type error in the code. Specifically, the error occurs in the line:\n\n```python\nif '@'+agent_name in message:\n```\n\nThe error message states that you can only concatenate a string (`str`) to another string, but the variable `agent_name` is of type `Agent`. \n\nTo fix this error, you need to convert the `agent_name` to a string before concatenating it with the '@' symbol. You can do this by using the `str()` function. Here's the modified code:\n\n```python\nif '@' + str(agent_name) in message:\n```\n\nBy converting `agent_name` to a string, you can concatenate it with the '@' symbol, and the error should be resolved.",
      "created_at": "2023-05-20T19:49:18.180115",
      "sequence_order": 1,
      "parent_id": "aaa22939-3aa4-471c-b092-470537d31667",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    }
  ]
}