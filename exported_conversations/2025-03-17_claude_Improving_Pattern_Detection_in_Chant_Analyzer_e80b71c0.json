{
  "id": "e80b71c0-2ccf-4ec0-8112-027d9f59c53c",
  "source": "claude",
  "title": "Improving Pattern Detection in Chant Analyzer",
  "created_at": "2025-03-17T16:44:34.742693Z",
  "updated_at": "2025-03-17T17:11:48.002628Z",
  "summary": "",
  "message_count": 8,
  "messages": [
    {
      "id": "f53074f4-0a59-4196-b0c9-908753ded3b9",
      "role": "human",
      "content": "I need a streamlined, cleaned, easier way to have it work, it doesn't get to the last element of the sequence if i pick 3/4/5 or any of them, why not, how can we maybe add some padding so we can find it in the rolling window? not sure review the code and determine the idea and continue code generation that stopped at this line: [[[// Label const label = document.createElement('div'); label.className = 'segment-label';]]] please you continue from there\nlet's merge this code address the issues and return one with a cleaned-up issue where it finds the patterns easily and has a way of tweaking the variables to help detect, what is a simple solution i'm not thinking of think of them all and return the code in full to try",
      "created_at": "2025-03-17T16:44:35.872124Z",
      "sequence_order": 0,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-03-17T01:47:56.594384Z",
            "stop_timestamp": "2025-03-17T01:47:56.594384Z",
            "flags": null,
            "type": "text",
            "text": "I need a streamlined, cleaned, easier way to have it work, it doesn't get to the last element of the sequence if i pick 3/4/5 or any of them, why not, how can we maybe add some padding so we can find it in the rolling window? not sure review the code and determine the idea and continue code generation that stopped at this line: [[[// Label const label = document.createElement('div'); label.className = 'segment-label';]]] please you continue from there\nlet's merge this code address the issues and return one with a cleaned-up issue where it finds the patterns easily and has a way of tweaking the variables to help detect, what is a simple solution i'm not thinking of think of them all and return the code in full to try",
            "citations": []
          }
        ],
        "updated_at": "2025-03-17T16:44:35.872124Z",
        "attachments": [
          {
            "file_name": "paste.txt",
            "file_size": 79035,
            "file_type": "txt",
            "extracted_content": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>Improved Chant Detector</title>\n  <script src=\"https://unpkg.com/meyda@5.2.0/dist/web/meyda.min.js\"></script>\n  <style>\n    body {\n      font-family: monospace;\n      max-width: 900px;\n      margin: 0 auto;\n      padding: 10px;\n      line-height: 1.4;\n    }\n    section {\n      background: #f8f9fa;\n      padding: 10px;\n      margin-bottom: 10px;\n      border: 1px solid #ddd;\n    }\n    h1, h2 { margin-top: 0; }\n    button {\n      background: #4285f4;\n      color: white;\n      border: none;\n      padding: 8px 12px;\n      margin-right: 5px;\n      cursor: pointer;\n    }\n    button:disabled { background: #ccc; }\n    .counter {\n      font-size: 40px;\n      font-weight: bold;\n      text-align: center;\n      margin: 10px 0;\n    }\n    .row {\n      display: flex;\n      align-items: center;\n      margin: 5px 0;\n    }\n    label {\n      width: 180px;\n      margin-right: 10px;\n    }\n    .status {\n      background: #e9ecef;\n      padding: 8px;\n      margin: 5px 0;\n      font-family: monospace;\n    }\n    \n    /* Visualization Styles */\n    .spectrogram-container {\n      position: relative;\n      height: 150px;\n      margin: 5px 0;\n      border: 1px solid #ddd;\n      background-color: #000;\n    }\n    .spectrogram-canvas {\n      position: absolute;\n      top: 0;\n      left: 0;\n      width: 100%;\n      height: 100%;\n    }\n    .segment-markers {\n      position: absolute;\n      top: 0;\n      left: 0;\n      width: 100%;\n      height: 100%;\n      pointer-events: none;\n    }\n    .segment-marker {\n      position: absolute;\n      top: 0;\n      height: 100%;\n      width: 2px;\n      background-color: rgba(255, 255, 255, 0.5);\n    }\n    .segment-label {\n      position: absolute;\n      top: 5px;\n      background-color: rgba(0, 0, 0, 0.6);\n      color: white;\n      padding: 2px 5px;\n      border-radius: 3px;\n      font-size: 10px;\n    }\n    .time-cursor {\n      position: absolute;\n      top: 0;\n      height: 100%;\n      width: 2px;\n      background-color: rgb(255, 0, 0);\n    }\n    \n    .sequence-progress {\n      display: flex;\n      height: 30px;\n      background: #f0f0f0;\n      margin: 10px 0;\n      border-radius: 4px;\n      overflow: hidden;\n    }\n    .segment-box {\n      flex: 1;\n      height: 100%;\n      display: flex;\n      align-items: center;\n      justify-content: center;\n      color: white;\n      font-weight: bold;\n      transition: background-color 0.3s;\n      border-right: 1px solid rgba(255,255,255,0.3);\n    }\n    .segment-pending { background-color: #9e9e9e; }\n    .segment-active { background-color: #ff9800; }\n    .segment-complete { background-color: #4caf50; }\n    .segment-invalid { background-color: #f44336; }\n    \n    .detection-bar {\n      height: 20px;\n      position: relative;\n      margin: 5px 0;\n      background: #f0f0f0;\n      border-radius: 4px;\n      overflow: hidden;\n    }\n    .detection-progress {\n      position: absolute;\n      height: 100%;\n      width: 0%;\n      background: #4caf50;\n      transition: width 0.2s;\n    }\n    \n    .pattern-display {\n      width: 100%;\n      height: 100px;\n      position: relative;\n      background: #000;\n      margin-top: 10px;\n      display: flex;\n    }\n    .pattern-segment {\n      flex: 1;\n      height: 100%;\n      overflow: hidden;\n      position: relative;\n      border-right: 1px dashed rgba(255,255,255,0.3);\n    }\n    .pattern-segment-label {\n      position: absolute;\n      top: 5px;\n      left: 5px;\n      background-color: rgba(0,0,0,0.6);\n      color: white;\n      padding: 2px 5px;\n      font-size: 10px;\n      z-index: 10;\n    }\n    \n    .debug-panel {\n      display: grid;\n      grid-template-columns: repeat(3, 1fr);\n      grid-gap: 5px;\n      margin: 5px 0;\n    }\n    .debug-item {\n      background: #f0f0f0;\n      padding: 5px;\n      font-size: 12px;\n      border-radius: 3px;\n    }\n    .debug-item-title {\n      font-weight: bold;\n      margin-bottom: 3px;\n    }\n    \n    .log {\n      height: 100px;\n      overflow-y: auto;\n      background: #f8f9fa;\n      border: 1px solid #ddd;\n      padding: 8px;\n      font-family: monospace;\n      font-size: 12px;\n    }\n    .highlight { color: #f44336; font-weight: bold; }\n    .green { color: #4caf50; }\n    \n    .pattern-info {\n      display: flex;\n      flex-wrap: wrap;\n      margin: 5px 0;\n    }\n    .pattern-stat {\n      background: #e0e0e0;\n      padding: 2px 6px;\n      margin-right: 5px;\n      margin-bottom: 5px;\n      border-radius: 2px;\n      font-size: 12px;\n    }\n    \n    .pattern-tabs {\n      display: flex;\n      margin-bottom: 5px;\n    }\n    .pattern-tab {\n      padding: 5px 10px;\n      background: #e0e0e0;\n      margin-right: 5px;\n      cursor: pointer;\n      border-radius: 3px 3px 0 0;\n      font-size: 12px;\n    }\n    .pattern-tab.active {\n      background: #4285f4;\n      color: white;\n    }\n    \n    .slider-value {\n      display: inline-block;\n      min-width: 40px;\n      text-align: right;\n    }\n    \n    .panel-title {\n      display: flex;\n      justify-content: space-between;\n      align-items: center;\n      margin-bottom: 5px;\n    }\n    .panel-title h3 {\n      margin: 0;\n    }\n  </style>\n</head>\n<body>\n  <h1>Improved Chant Detector</h1>\n\n  <section>\n    <div class=\"panel-title\">\n      <h2>1. Record Your Chant Pattern</h2>\n      <div class=\"pattern-tabs\">\n        <div class=\"pattern-tab active\" data-pattern=\"1\">Pattern 1</div>\n        <div class=\"pattern-tab\" data-pattern=\"2\">Pattern 2</div>\n        <div class=\"pattern-tab\" data-pattern=\"3\">Pattern 3</div>\n      </div>\n    </div>\n    \n    <div class=\"spectrogram-container\">\n      <canvas id=\"recordSpectrogram\" class=\"spectrogram-canvas\"></canvas>\n      <div class=\"segment-markers\" id=\"recordSegmentMarkers\"></div>\n    </div>\n    \n    <div id=\"recordingStatus\" class=\"status\">Ready to record your chant pattern</div>\n    <div>\n      <button id=\"recordBtn\">Record (Hold)</button>\n      <button id=\"clearBtn\">Clear</button>\n      <button id=\"averageBtn\" disabled>Average Patterns</button>\n      <span id=\"patternInfo\"></span>\n    </div>\n    \n    <div class=\"pattern-display\" id=\"patternDisplay\"></div>\n    <div class=\"pattern-info\" id=\"patternStats\"></div>\n  </section>\n\n  <section>\n    <h2>2. Settings</h2>\n    <div class=\"row\">\n      <label for=\"detectionMode\">Detection Mode:</label>\n      <select id=\"detectionMode\">\n        <option value=\"sequential\" selected>Strict Sequential</option>\n        <option value=\"flexible\">Flexible Sequential</option>\n        <option value=\"adaptive\">Adaptive (Self-Adjusting)</option>\n      </select>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"minMatchSlider\">Segment Match Threshold:</label>\n      <input type=\"range\" id=\"minMatchSlider\" min=\"0.3\" max=\"0.9\" step=\"0.05\" value=\"0.6\">\n      <span id=\"minMatchValue\" class=\"slider-value\">0.6</span>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"advanceThresholdSlider\">Advance Threshold:</label>\n      <input type=\"range\" id=\"advanceThresholdSlider\" min=\"0.2\" max=\"0.8\" step=\"0.05\" value=\"0.5\">\n      <span id=\"advanceThresholdValue\" class=\"slider-value\">0.5</span>\n      <span>(Lower = easier progression)</span>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"timeoutSlider\">Segment Timeout (ms):</label>\n      <input type=\"range\" id=\"timeoutSlider\" min=\"500\" max=\"5000\" step=\"100\" value=\"2000\">\n      <span id=\"timeoutValue\" class=\"slider-value\">2000</span>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"cooldownSlider\">Cooldown Period (ms):</label>\n      <input type=\"range\" id=\"cooldownSlider\" min=\"500\" max=\"3000\" step=\"100\" value=\"1500\">\n      <span id=\"cooldownValue\" class=\"slider-value\">1500</span>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"segmentCountSelect\">Pattern Segments:</label>\n      <select id=\"segmentCountSelect\">\n        <option value=\"3\">3</option>\n        <option value=\"4\" selected>4</option>\n        <option value=\"5\">5</option>\n        <option value=\"6\">6</option>\n      </select>\n    </div>\n  </section>\n\n  <section>\n    <h2>3. Detection</h2>\n    <div class=\"counter\" id=\"counterValue\">0</div>\n    \n    <div class=\"spectrogram-container\">\n      <canvas id=\"liveSpectrogram\" class=\"spectrogram-canvas\"></canvas>\n      <div class=\"segment-markers\" id=\"liveSegmentMarkers\"></div>\n      <div class=\"time-cursor\" id=\"timeCursor\" style=\"left: 75%;\"></div>\n    </div>\n    \n    <div class=\"sequence-progress\" id=\"sequenceProgress\"></div>\n    <div class=\"detection-bar\">\n      <div id=\"detectionProgress\" class=\"detection-progress\"></div>\n    </div>\n    \n    <div id=\"detectionStatus\" class=\"status\">No pattern recorded yet</div>\n    <div>\n      <button id=\"startBtn\" disabled>Start Detection</button>\n      <button id=\"stopBtn\" disabled>Stop</button>\n      <button id=\"resetBtn\">Reset Counter</button>\n    </div>\n    \n    <h3>Debug Info</h3>\n    <div class=\"debug-panel\" id=\"debugPanel\"></div>\n    <div class=\"log\" id=\"detectionLog\"></div>\n  </section>\n\n<script>\n/**\n * Improved Chant Detector\n * \n * Key improvements:\n * 1. Visual alignment of spectrogram and segments\n * 2. Multiple pattern recording and averaging\n * 3. Flexible sequence progression with timeout\n * 4. Better visualization of pattern segments\n */\nclass ImprovedChantDetector {\n  constructor() {\n    // Audio system\n    this.audioContext = null;\n    this.analyzer = null;\n    this.mediaStream = null;\n    this.processor = null;\n    \n    // Configuration\n    this.config = {\n      bufferSize: 1024,\n      fftSize: 2048,\n      sampleRate: 44100,\n      minRecordDuration: 500,\n      detectionMode: 'sequential',\n      minMatchThreshold: 0.6,     // Minimum score to consider a match\n      advanceThreshold: 0.5,      // Threshold to advance to next segment\n      segmentTimeout: 2000,       // Time before resetting stuck segment (ms)\n      cooldownTime: 1500,         // Cooldown between detections (ms)\n      segmentCount: 4,            // Number of segments in pattern\n      maxPatterns: 3,             // Maximum number of patterns to store\n      spectrogramHistory: 150,    // Number of columns in spectrogram\n      lookAheadFrames: 10,        // Frames to look ahead for flexible mode\n      \n      // Feature weights\n      featureWeights: {\n        spectrogram: 0.6,  // Weight for spectrogram match\n        mfcc: 0.3,         // Weight for MFCC match\n        energy: 0.1        // Weight for energy profile match\n      }\n    };\n    \n    // State\n    this.state = {\n      isRecording: false,\n      isDetecting: false,\n      inCooldown: false,\n      \n      // Active pattern\n      activePatternIndex: 0,\n      \n      // Recording state\n      recordStartTime: 0,\n      recordingData: {\n        audio: [],\n        spectrogram: [],\n        mfcc: [],\n        energy: [],\n        duration: 0\n      },\n      \n      // Patterns (multiple can be stored)\n      patterns: [],\n      \n      // Detection state\n      detectionBuffer: {\n        audio: [],\n        spectrogram: [],\n        mfcc: [],\n        energy: [],\n        timeWindow: []  // Time values for visualization\n      },\n      \n      // Sequence tracking\n      sequenceState: {\n        segments: [],          // State of each segment (pending, active, complete, invalid)\n        currentIndex: 0,       // Current segment being matched\n        progress: 0,           // Overall progress (0-1)\n        matchScores: [],       // Match scores for each segment\n        segmentStartTimes: [], // When each segment started matching\n        stuckTime: 0,          // How long we've been stuck on a segment\n        lastAdvanceTime: 0     // When we last advanced segments\n      },\n      \n      // Results\n      counter: 0,\n      lastDetectionTime: 0,\n      \n      // Visualization\n      spectrogramData: {\n        recording: [],\n        pattern: [],\n        live: []\n      },\n      \n      // Timing markers for visualization\n      timeMarkers: {\n        pattern: [],\n        live: []\n      }\n    };\n    \n    // Callbacks\n    this.callbacks = {\n      onStatusUpdate: null,\n      onVisualizationUpdate: null,\n      onDetection: null,\n      onProgressUpdate: null,\n      onError: null\n    };\n    \n    // Animation\n    this.animationFrame = null;\n  }\n  \n  /**\n   * Set up callbacks\n   */\n  setCallbacks(callbacks) {\n    Object.assign(this.callbacks, callbacks);\n  }\n  \n  /**\n   * Initialize audio system\n   */\n  async setupAudio() {\n    if (this.audioContext) return true;\n    \n    try {\n      this.audioContext = new (window.AudioContext || window.webkitAudioContext)();\n      this.config.sampleRate = this.audioContext.sampleRate;\n      \n      this.mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });\n      \n      this.analyzer = this.audioContext.createAnalyser();\n      this.analyzer.fftSize = this.config.fftSize;\n      \n      this.log('info', 'Audio system initialized');\n      return true;\n    } catch (error) {\n      this.handleError('Audio setup failed', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Start recording a pattern\n   */\n  async startRecording() {\n    if (this.state.isRecording) return false;\n    \n    // Setup audio\n    const success = await this.setupAudio();\n    if (!success) return false;\n    \n    // Initialize recording state\n    this.state.isRecording = true;\n    this.state.recordStartTime = Date.now();\n    this.state.recordingData = {\n      audio: [],\n      spectrogram: [],\n      mfcc: [],\n      energy: [],\n      duration: 0\n    };\n    \n    // Also initialize spectrogram data for visualization\n    this.state.spectrogramData.recording = [];\n    \n    // Create processor node\n    this.processor = this.audioContext.createScriptProcessor(\n      this.config.bufferSize, 1, 1\n    );\n    \n    // Process audio data\n    this.processor.onaudioprocess = (event) => {\n      if (!this.state.isRecording) return;\n      \n      try {\n        // Get audio data\n        const inputData = event.inputBuffer.getChannelData(0);\n        const audioData = new Float32Array(inputData.length);\n        audioData.set(inputData);\n        \n        // Extract features\n        const features = this.extractFeatures(audioData);\n        \n        // Store data\n        this.state.recordingData.audio.push(audioData);\n        this.state.recordingData.spectrogram.push(features.spectrogram);\n        this.state.recordingData.mfcc.push(features.mfcc);\n        this.state.recordingData.energy.push(features.energy);\n        \n        // Store spectrogram for visualization\n        this.state.spectrogramData.recording.push(features.spectrogram);\n        \n        // Update visualization\n        if (this.callbacks.onVisualizationUpdate) {\n          this.callbacks.onVisualizationUpdate('recording', audioData, features);\n        }\n      } catch (error) {\n        this.handleError('Error processing recording', error);\n      }\n    };\n    \n    // Connect audio nodes\n    const source = this.audioContext.createMediaStreamSource(this.mediaStream);\n    source.connect(this.analyzer);\n    source.connect(this.processor);\n    this.processor.connect(this.audioContext.destination);\n    \n    this.log('status', 'Recording chant pattern...');\n    return true;\n  }\n  \n  /**\n   * Stop recording and process the pattern\n   */\n  stopRecording() {\n    if (!this.state.isRecording) return false;\n    \n    // Update state\n    this.state.isRecording = false;\n    this.state.recordingData.duration = Date.now() - this.state.recordStartTime;\n    \n    // Clean up\n    if (this.processor) {\n      this.processor.disconnect();\n      this.processor = null;\n    }\n    \n    // Check recording duration\n    if (this.state.recordingData.duration < this.config.minRecordDuration) {\n      this.log('status', 'Recording too short, please try again');\n      return false;\n    }\n    \n    this.log('status', 'Processing pattern...');\n    \n    // Process the pattern\n    const success = this.processRecordingToPattern();\n    \n    if (success) {\n      this.log('status', `Pattern ${this.state.activePatternIndex + 1} recorded (${(this.state.recordingData.duration/1000).toFixed(1)}s)`);\n      return true;\n    } else {\n      this.log('status', 'Failed to process pattern');\n      return false;\n    }\n  }\n  \n  /**\n   * Process recording data into a pattern\n   */\n  processRecordingToPattern() {\n    try {\n      // Get current pattern index\n      const patternIndex = this.state.activePatternIndex;\n      \n      // Create a new pattern if it doesn't exist\n      if (!this.state.patterns[patternIndex]) {\n        this.state.patterns[patternIndex] = {\n          rawData: {\n            spectrogram: [],\n            mfcc: [],\n            energy: [],\n            duration: 0\n          },\n          segments: [],\n          sampleCount: 0\n        };\n      }\n      \n      // Store recording data\n      const pattern = this.state.patterns[patternIndex];\n      \n      // If this is the first recording for this pattern, just copy it\n      if (pattern.sampleCount === 0) {\n        pattern.rawData = {\n          spectrogram: [...this.state.recordingData.spectrogram],\n          mfcc: [...this.state.recordingData.mfcc],\n          energy: [...this.state.recordingData.energy],\n          duration: this.state.recordingData.duration\n        };\n      } else {\n        // Average with existing pattern data (simple arithmetic mean)\n        // First, we need to time-normalize the new recording\n        const normalizedRecording = this.normalizeRecordingLength(\n          this.state.recordingData, \n          pattern.rawData\n        );\n        \n        // Now average with existing pattern\n        this.averagePatternData(pattern, normalizedRecording);\n      }\n      \n      // Increment sample count\n      pattern.sampleCount++;\n      \n      // Segment the pattern\n      pattern.segments = this.segmentPattern(pattern.rawData);\n      \n      // Calculate segment boundaries for visualization\n      this.calculateSegmentBoundaries(pattern);\n      \n      // Store pattern visualization data\n      this.state.spectrogramData.pattern = [...pattern.rawData.spectrogram];\n      \n      // Clear recording data to save memory\n      this.state.recordingData = {\n        audio: [],\n        spectrogram: [],\n        mfcc: [],\n        energy: [],\n        duration: 0\n      };\n      \n      // Enable averaging if we have multiple patterns\n      if (this.checkMultiplePatternsExist()) {\n        // Check if averaging button should be enabled\n        if (this.callbacks.onStatusUpdate) {\n          this.callbacks.onStatusUpdate('control', 'enableAveraging', true);\n        }\n      }\n      \n      return true;\n    } catch (error) {\n      this.handleError('Error processing pattern', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Normalize recording length to match target pattern\n   */\n  normalizeRecordingLength(recording, targetPattern) {\n    // Create a normalized version of the recording\n    const normalized = {\n      spectrogram: [],\n      mfcc: [],\n      energy: [],\n      duration: targetPattern.duration\n    };\n    \n    const sourceLength = recording.energy.length;\n    const targetLength = targetPattern.energy.length;\n    \n    // Simple linear resampling\n    for (let i = 0; i < targetLength; i++) {\n      const sourceIdx = Math.floor(i * sourceLength / targetLength);\n      \n      normalized.spectrogram[i] = recording.spectrogram[sourceIdx];\n      normalized.mfcc[i] = recording.mfcc[sourceIdx];\n      normalized.energy[i] = recording.energy[sourceIdx];\n    }\n    \n    return normalized;\n  }\n  \n  /**\n   * Average new recording data with existing pattern\n   */\n  averagePatternData(pattern, newData) {\n    const sampleCount = pattern.sampleCount;\n    \n    // Weight for averaging: existing data gets more weight as sample count increases\n    const existingWeight = sampleCount / (sampleCount + 1);\n    const newWeight = 1 / (sampleCount + 1);\n    \n    // Average spectrograms\n    pattern.rawData.spectrogram = pattern.rawData.spectrogram.map((existingSpectrum, i) => {\n      const newSpectrum = newData.spectrogram[i] || [];\n      return this.weightedAverageArrays(existingSpectrum, newSpectrum, existingWeight, newWeight);\n    });\n    \n    // Average MFCCs\n    pattern.rawData.mfcc = pattern.rawData.mfcc.map((existingMfcc, i) => {\n      const newMfcc = newData.mfcc[i] || [];\n      return this.weightedAverageArrays(existingMfcc, newMfcc, existingWeight, newWeight);\n    });\n    \n    // Average energy\n    pattern.rawData.energy = pattern.rawData.energy.map((existing, i) => {\n      const newEnergy = newData.energy[i] || 0;\n      return existing * existingWeight + newEnergy * newWeight;\n    });\n    \n    // Keep original duration (we've already normalized the new recording)\n    pattern.rawData.duration = pattern.rawData.duration;\n  }\n  \n  /**\n   * Weighted average of two arrays\n   */\n  weightedAverageArrays(arrA, arrB, weightA, weightB) {\n    if (!arrA || !arrB) return arrA || arrB || [];\n    \n    const length = Math.min(arrA.length, arrB.length);\n    const result = new Array(length);\n    \n    for (let i = 0; i < length; i++) {\n      result[i] = (arrA[i] || 0) * weightA + (arrB[i] || 0) * weightB;\n    }\n    \n    return result;\n  }\n  \n  /**\n   * Check if multiple patterns exist\n   */\n  checkMultiplePatternsExist() {\n    let count = 0;\n    \n    for (const pattern of this.state.patterns) {\n      if (pattern && pattern.sampleCount > 0) {\n        count++;\n      }\n    }\n    \n    return count > 1;\n  }\n  \n  /**\n   * Average all recorded patterns into one\n   */\n  averageAllPatterns() {\n    try {\n      // Ensure we have at least 2 patterns\n      const validPatterns = this.state.patterns.filter(p => p && p.sampleCount > 0);\n      \n      if (validPatterns.length < 2) {\n        this.log('status', 'Need at least 2 patterns to average');\n        return false;\n      }\n      \n      // Use the first pattern as the base\n      const basePattern = validPatterns[0];\n      \n      // Create a new averaged pattern\n      const averagedPattern = {\n        rawData: {\n          spectrogram: [...basePattern.rawData.spectrogram],\n          mfcc: [...basePattern.rawData.mfcc],\n          energy: [...basePattern.rawData.energy],\n          duration: basePattern.rawData.duration\n        },\n        segments: [],\n        sampleCount: 0\n      };\n      \n      // Add all other patterns\n      for (let i = 1; i < validPatterns.length; i++) {\n        const pattern = validPatterns[i];\n        const normalized = this.normalizeRecordingLength(\n          pattern.rawData, \n          averagedPattern.rawData\n        );\n        \n        // Average with equal weights\n        const weight = 1 / validPatterns.length;\n        \n        // Average spectrograms\n        averagedPattern.rawData.spectrogram = averagedPattern.rawData.spectrogram.map((existingSpectrum, j) => {\n          const newSpectrum = normalized.spectrogram[j] || [];\n          return this.weightedAverageArrays(\n            existingSpectrum, \n            newSpectrum, \n            1 - weight, \n            weight\n          );\n        });\n        \n        // Average MFCCs\n        averagedPattern.rawData.mfcc = averagedPattern.rawData.mfcc.map((existingMfcc, j) => {\n          const newMfcc = normalized.mfcc[j] || [];\n          return this.weightedAverageArrays(\n            existingMfcc,\n            newMfcc,\n            1 - weight,\n            weight\n          );\n        });\n        \n        // Average energy\n        averagedPattern.rawData.energy = averagedPattern.rawData.energy.map((existing, j) => {\n          const newEnergy = normalized.energy[j] || 0;\n          return existing * (1 - weight) + newEnergy * weight;\n        });\n      }\n      \n      // Set combined sample count\n      averagedPattern.sampleCount = validPatterns.reduce((sum, p) => sum + p.sampleCount, 0);\n      \n      // Segment the pattern\n      averagedPattern.segments = this.segmentPattern(averagedPattern.rawData);\n      \n      // Calculate segment boundaries\n      this.calculateSegmentBoundaries(averagedPattern);\n      \n      // Replace the active pattern with the averaged one\n      this.state.patterns[this.state.activePatternIndex] = averagedPattern;\n      \n      // Update visualization\n      this.state.spectrogramData.pattern = [...averagedPattern.rawData.spectrogram];\n      \n      this.log('status', `Created averaged pattern from ${validPatterns.length} recordings`);\n      return true;\n    } catch (error) {\n      this.handleError('Error averaging patterns', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Set active pattern\n   */\n  setActivePattern(index) {\n    if (index < 0 || index >= this.config.maxPatterns) {\n      return false;\n    }\n    \n    this.state.activePatternIndex = index;\n    \n    // Update visualization if pattern exists\n    const pattern = this.state.patterns[index];\n    if (pattern && pattern.sampleCount > 0) {\n      this.state.spectrogramData.pattern = [...pattern.rawData.spectrogram];\n      \n      if (this.callbacks.onVisualizationUpdate) {\n        this.callbacks.onVisualizationUpdate('patternSwitch', null, pattern);\n      }\n      \n      this.log('status', `Switched to pattern ${index + 1}`);\n    } else {\n      this.state.spectrogramData.pattern = [];\n      \n      this.log('status', `Pattern ${index + 1} is empty`);\n    }\n    \n    return true;\n  }\n  \n  /**\n   * Clear the active pattern\n   */\n  clearActivePattern() {\n    const index = this.state.activePatternIndex;\n    \n    this.state.patterns[index] = null;\n    this.state.spectrogramData.pattern = [];\n    \n    this.log('status', `Cleared pattern ${index + 1}`);\n    \n    // Disable averaging button if needed\n    if (!this.checkMultiplePatternsExist() && this.callbacks.onStatusUpdate) {\n      this.callbacks.onStatusUpdate('control', 'enableAveraging', false);\n    }\n    \n    return true;\n  }\n  \n  /**\n   * Segment pattern into logical parts\n   */\n  segmentPattern(patternData) {\n    try {\n      const segmentCount = this.config.segmentCount;\n      const energy = patternData.energy;\n      const mfcc = patternData.mfcc;\n      const spectrogram = patternData.spectrogram;\n      \n      if (!energy || energy.length === 0) {\n        return [];\n      }\n      \n      // Find segment boundaries\n      let boundaries = [];\n      \n      // Try to find natural boundaries in energy profile\n      const smoothedEnergy = this.smoothArray([...energy], 3);\n      \n      // Find significant peaks and valleys\n      const peaks = this.findPeaks(smoothedEnergy);\n      const valleys = this.findValleys(smoothedEnergy);\n      \n      if (valleys.length >= segmentCount - 1) {\n        // Use valleys as natural breakpoints\n        boundaries = [0, ...valleys, energy.length - 1];\n        \n        // Keep strongest valleys if we have too many\n        while (boundaries.length > segmentCount + 1) {\n          // Find the shallowest valley\n          let shallowestIdx = -1;\n          let shallowestDepth = Infinity;\n          \n          for (let i = 1; i < boundaries.length - 1; i++) {\n            const idx = boundaries[i];\n            const depth = Math.min(\n              smoothedEnergy[idx-1] - smoothedEnergy[idx],\n              smoothedEnergy[idx+1] - smoothedEnergy[idx]\n            );\n            \n            if (depth < shallowestDepth) {\n              shallowestDepth = depth;\n              shallowestIdx = i;\n            }\n          }\n          \n          if (shallowestIdx > 0) {\n            boundaries.splice(shallowestIdx, 1);\n          } else {\n            break;\n          }\n        }\n      } else {\n        // Fallback to equal divisions\n        const segmentSize = Math.floor(energy.length / segmentCount);\n        \n        boundaries = [];\n        for (let i = 0; i <= segmentCount; i++) {\n          boundaries.push(Math.min(i * segmentSize, energy.length - 1));\n        }\n      }\n      \n      // Sort boundaries\n      boundaries = [...new Set(boundaries)].sort((a, b) => a - b);\n      \n      // Create segments\n      const segments = [];\n      for (let i = 0; i < boundaries.length - 1; i++) {\n        const start = boundaries[i];\n        const end = boundaries[i + 1];\n        \n        // Skip if segment is too small\n        if (end - start < 2) continue;\n        \n        // Create segment data\n        const segment = {\n          index: i,\n          startFrame: start,\n          endFrame: end,\n          frameCount: end - start,\n          // Extract feature slices\n          energy: energy.slice(start, end),\n          mfcc: mfcc.slice(start, end),\n          spectrogram: spectrogram.slice(start, end),\n          // Calculate averages\n          avgEnergy: this.average(energy.slice(start, end)),\n          avgSpectrogram: this.averageSpectrograms(spectrogram.slice(start, end)),\n          avgMfcc: this.averageArrays(mfcc.slice(start, end))\n        };\n        \n        segments.push(segment);\n      }\n      \n      return segments;\n    } catch (error) {\n      this.handleError('Error segmenting pattern', error);\n      return [];\n    }\n  }\n  \n  /**\n   * Calculate segment boundaries for visualization\n   */\n  calculateSegmentBoundaries(pattern) {\n    if (!pattern || !pattern.segments || pattern.segments.length === 0) return;\n    \n    // Calculate total frames\n    const totalFrames = pattern.rawData.energy.length;\n    \n    // Calculate boundaries as percentages\n    const boundaries = [];\n    \n    for (const segment of pattern.segments) {\n      const startPct = segment.startFrame / totalFrames;\n      const endPct = segment.endFrame / totalFrames;\n      \n      boundaries.push({\n        start: startPct,\n        end: endPct,\n        index: segment.index\n      });\n    }\n    \n    // Store boundaries\n    pattern.boundaries = boundaries;\n    \n    // Update time markers\n    this.state.timeMarkers.pattern = boundaries.map(b => b.start);\n  }\n  \n  /**\n   * Start detection\n   */\n  async startDetection() {\n    if (this.state.isDetecting) return false;\n    \n    // Get active pattern\n    const pattern = this.state.patterns[this.state.activePatternIndex];\n    \n    // Check if we have a pattern\n    if (!pattern || !pattern.segments || pattern.segments.length === 0) {\n      this.log('status', 'No pattern recorded yet');\n      return false;\n    }\n    \n    // Setup audio\n    const success = await this.setupAudio();\n    if (!success) return false;\n    \n    // Initialize detection state\n    this.state.isDetecting = true;\n    this.state.inCooldown = false;\n    \n    // Clear detection buffer\n    this.state.detectionBuffer = {\n      audio: [],\n      spectrogram: [],\n      mfcc: [],\n      energy: [],\n      timeWindow: []\n    };\n    \n    // Clear spectrogram data\n    this.state.spectrogramData.live = [];\n    \n    // Reset sequence state\n    this.resetSequenceState();\n    \n    // Create processor node\n    this.processor = this.audioContext.createScriptProcessor(\n      this.config.bufferSize, 1, 1\n    );\n    \n    // Store start time\n    const detectionStartTime = Date.now();\n    \n    // Process audio data for detection\n    this.processor.onaudioprocess = (event) => {\n      if (!this.state.isDetecting) return;\n      \n      try {\n        // Get audio data\n        const inputData = event.inputBuffer.getChannelData(0);\n        const audioData = new Float32Array(inputData.length);\n        audioData.set(inputData);\n        \n        // Extract features\n        const features = this.extractFeatures(audioData);\n        \n        // Current time in detection\n        const currentTime = Date.now() - detectionStartTime;\n        \n        // Add to detection buffer\n        this.state.detectionBuffer.audio.push(audioData);\n        this.state.detectionBuffer.spectrogram.push(features.spectrogram);\n        this.state.detectionBuffer.mfcc.push(features.mfcc);\n        this.state.detectionBuffer.energy.push(features.energy);\n        this.state.detectionBuffer.timeWindow.push(currentTime);\n        \n        // Update spectrogram data\n        this.state.spectrogramData.live.push(features.spectrogram);\n        \n        // Trim buffer to manageable size\n        this.trimDetectionBuffer();\n        \n        // Update visualization\n        if (this.callbacks.onVisualizationUpdate) {\n          this.callbacks.onVisualizationUpdate('detection', audioData, features);\n        }\n        \n        // Process detection if not in cooldown\n        if (!this.state.inCooldown) {\n          this.detectPattern();\n        }\n      } catch (error) {\n        this.handleError('Error in detection process', error);\n      }\n    };\n    \n    // Connect audio nodes\n    const source = this.audioContext.createMediaStreamSource(this.mediaStream);\n    source.connect(this.analyzer);\n    source.connect(this.processor);\n    this.processor.connect(this.audioContext.destination);\n    \n    // Start animation loop for cursor\n    this.startAnimationLoop();\n    \n    this.log('status', 'Listening for pattern...');\n    return true;\n  }\n  \n  /**\n   * Stop detection\n   */\n  stopDetection() {\n    if (!this.state.isDetecting) return false;\n    \n    // Update state\n    this.state.isDetecting = false;\n    this.state.inCooldown = false;\n    \n    // Stop animation\n    this.stopAnimationLoop();\n    \n    // Clean up\n    if (this.processor) {\n      this.processor.disconnect();\n      this.processor = null;\n    }\n    \n    // Reset sequence state\n    this.resetSequenceState();\n    \n    // Update progress\n    if (this.callbacks.onProgressUpdate) {\n      this.callbacks.onProgressUpdate(this.state.sequenceState);\n    }\n    \n    this.log('status', 'Detection stopped');\n    return true;\n  }\n  \n  /**\n   * Reset counter\n   */\n  resetCounter() {\n    this.state.counter = 0;\n    this.log('status', 'Counter reset to 0');\n    \n    if (this.callbacks.onDetection) {\n      this.callbacks.onDetection(0, 0);\n    }\n    \n    return true;\n  }\n  \n  /**\n   * Reset sequence state\n   */\n  resetSequenceState() {\n    // Get active pattern\n    const pattern = this.state.patterns[this.state.activePatternIndex];\n    \n    if (!pattern || !pattern.segments) {\n      this.state.sequenceState = {\n        segments: [],\n        currentIndex: 0,\n        progress: 0,\n        matchScores: [],\n        segmentStartTimes: [],\n        stuckTime: 0,\n        lastAdvanceTime: 0\n      };\n      return;\n    }\n    \n    // Initialize sequence tracking\n    this.state.sequenceState = {\n      segments: pattern.segments.map(() => 'pending'),\n      currentIndex: 0,\n      progress: 0,\n      matchScores: pattern.segments.map(() => 0),\n      segmentStartTimes: [],\n      stuckTime: 0,\n      lastAdvanceTime: Date.now()\n    };\n    \n    // Update visualization\n    if (this.callbacks.onProgressUpdate) {\n      this.callbacks.onProgressUpdate(this.state.sequenceState);\n    }\n  }\n  \n  /**\n   * Trim detection buffer\n   */\n  trimDetectionBuffer() {\n    // Get active pattern\n    const pattern = this.state.patterns[this.state.activePatternIndex];\n    if (!pattern) return;\n    \n    // Maximum frames to keep (2x pattern length)\n    const maxFrames = Math.max(\n      150,\n      pattern.segments.reduce((sum, s) => sum + s.frameCount, 0) * 2\n    );\n    \n    if (this.state.detectionBuffer.energy.length > maxFrames) {\n      const framesToRemove = this.state.detectionBuffer.energy.length - maxFrames;\n      \n      // Trim all buffer arrays\n      this.state.detectionBuffer.audio.splice(0, framesToRemove);\n      this.state.detectionBuffer.spectrogram.splice(0, framesToRemove);\n      this.state.detectionBuffer.mfcc.splice(0, framesToRemove);\n      this.state.detectionBuffer.energy.splice(0, framesToRemove);\n      this.state.detectionBuffer.timeWindow.splice(0, framesToRemove);\n    }\n    \n    // Also trim spectrogram history\n    if (this.state.spectrogramData.live.length > this.config.spectrogramHistory) {\n      this.state.spectrogramData.live.splice(\n        0, \n        this.state.spectrogramData.live.length - this.config.spectrogramHistory\n      );\n    }\n  }\n  \n  /**\n   * Core detection algorithm\n   */\n  detectPattern() {\n    try {\n      // Get active pattern\n      const pattern = this.state.patterns[this.state.activePatternIndex];\n      if (!pattern || !pattern.segments || pattern.segments.length === 0) {\n        return false;\n      }\n      \n      // Check if we have enough data\n      if (this.state.detectionBuffer.energy.length < 10) {\n        return false;\n      }\n      \n      // Get current sequence state\n      const sequenceState = this.state.sequenceState;\n      const currentIndex = sequenceState.currentIndex;\n      \n      // Get the target segment\n      const segment = pattern.segments[currentIndex];\n      if (!segment) return false;\n      \n      // Use different detection strategies based on mode\n      let result;\n      \n      switch (this.config.detectionMode) {\n        case 'flexible':\n          result = this.flexibleSequentialDetection(pattern);\n          break;\n        case 'adaptive':\n          result = this.adaptiveDetection(pattern);\n          break;\n        case 'sequential':\n        default:\n          result = this.strictSequentialDetection(pattern);\n          break;\n      }\n      \n      // Process result\n      if (result) {\n        // Update progress visualization\n        if (this.callbacks.onProgressUpdate) {\n          this.callbacks.onProgressUpdate(this.state.sequenceState, result.debugInfo);\n        }\n        \n        // Check if we detected the full pattern\n        if (result.patternDetected) {\n          this.registerDetection(result.confidence);\n        }\n        \n        return result.patternDetected;\n      }\n      \n      return false;\n    } catch (error) {\n      this.handleError('Error in pattern detection', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Strict sequential detection algorithm\n   */\n  strictSequentialDetection(pattern) {\n    // Current sequence state\n    const sequenceState = this.state.sequenceState;\n    const currentIndex = sequenceState.currentIndex;\n    \n    // Current segment\n    const segment = pattern.segments[currentIndex];\n    \n    // Get recent frames for matching\n    const windowSize = Math.min(segment.frameCount * 2, this.state.detectionBuffer.energy.length);\n    const recentFrames = {\n      energy: this.state.detectionBuffer.energy.slice(-windowSize),\n      mfcc: this.state.detectionBuffer.mfcc.slice(-windowSize),\n      spectrogram: this.state.detectionBuffer.spectrogram.slice(-windowSize)\n    };\n    \n    // Calculate match score for current segment\n    const matchScore = this.calculateSegmentMatch(recentFrames, segment);\n    \n    // Update match scores\n    sequenceState.matchScores[currentIndex] = matchScore;\n    \n    // Current time\n    const now = Date.now();\n    \n    // Check for timeout on current segment\n    if (sequenceState.segments[currentIndex] === 'active') {\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      \n      if (timeInSegment > this.config.segmentTimeout) {\n        // Stuck too long, reset\n        this.log('info', `Timeout on segment ${currentIndex + 1}`);\n        this.resetSequenceState();\n        return {\n          patternDetected: false,\n          confidence: 0,\n          debugInfo: {\n            currentSegment: 1,\n            matchScore: 0,\n            timeout: true\n          }\n        };\n      }\n    }\n    \n    // Debug info\n    const debugInfo = {\n      currentSegment: currentIndex + 1,\n      totalSegments: pattern.segments.length,\n      matchScore: matchScore,\n      threshold: this.config.minMatchThreshold\n    };\n    \n    // Handle current segment based on match score\n    if (matchScore >= this.config.minMatchThreshold) {\n      // If we just started matching this segment, record the start time\n      if (sequenceState.segments[currentIndex] === 'pending') {\n        sequenceState.segments[currentIndex] = 'active';\n        sequenceState.segmentStartTimes[currentIndex] = now;\n        sequenceState.lastAdvanceTime = now;\n        this.log('info', `Matching segment ${currentIndex + 1}/${pattern.segments.length}`);\n      }\n      \n      // Check if we've been matching long enough to advance\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      const minSegmentTime = Math.max(\n        300,  // At least 300ms per segment\n        (segment.frameCount / pattern.rawData.energy.length) * pattern.rawData.duration * 0.5\n      );\n      \n      if (timeInSegment >= minSegmentTime && matchScore >= this.config.advanceThreshold) {\n        // Mark segment as complete\n        sequenceState.segments[currentIndex] = 'complete';\n        \n        // Check if this was the last segment\n        if (currentIndex === pattern.segments.length - 1) {\n          // Completed the full pattern\n          return {\n            patternDetected: true,\n            confidence: this.calculateOverallConfidence(),\n            debugInfo: {\n              ...debugInfo,\n              timeInSegment,\n              minSegmentTime,\n              completed: true\n            }\n          };\n        } else {\n          // Move to next segment\n          sequenceState.currentIndex++;\n          sequenceState.lastAdvanceTime = now;\n          this.log('info', `Advanced to segment ${sequenceState.currentIndex + 1}/${pattern.segments.length}`);\n          \n          // Add progress data to debug info\n          debugInfo.advanced = true;\n          debugInfo.nextSegment = sequenceState.currentIndex + 1;\n        }\n      }\n      \n      // Add timing to debug info\n      debugInfo.timeInSegment = timeInSegment;\n      debugInfo.minSegmentTime = minSegmentTime;\n    } else {\n      // If we were matching but lost it, mark as invalid\n      if (sequenceState.segments[currentIndex] === 'active') {\n        sequenceState.segments[currentIndex] = 'invalid';\n        this.log('info', `Lost match for segment ${currentIndex + 1}`);\n        \n        // Reset after a short delay\n        setTimeout(() => {\n          // Only reset if we're still on this segment and still invalid\n          if (this.state.isDetecting && \n              this.state.sequenceState.currentIndex === currentIndex &&\n              this.state.sequenceState.segments[currentIndex] === 'invalid') {\n            this.resetSequenceState();\n            this.log('info', 'Reset sequence state');\n          }\n        }, 300);\n      }\n    }\n    \n    // Calculate overall progress\n    const completedSegments = sequenceState.segments.filter(s => s === 'complete').length;\n    const activeSegment = sequenceState.segments.indexOf('active');\n    \n    if (activeSegment !== -1) {\n      // Include partial progress of active segment\n      const activeProgress = matchScore * (1 / pattern.segments.length);\n      sequenceState.progress = (completedSegments / pattern.segments.length) + activeProgress;\n    } else {\n      sequenceState.progress = completedSegments / pattern.segments.length;\n    }\n    \n    // Add progress to debug info\n    debugInfo.progress = sequenceState.progress;\n    debugInfo.segments = [...sequenceState.segments];\n    \n    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };\n  }\n  \n  /**\n   * Flexible sequential detection\n   * Allows some segments to be skipped or detected out of order\n   */\n  flexibleSequentialDetection(pattern) {\n    // Current sequence state\n    const sequenceState = this.state.sequenceState;\n    const currentIndex = sequenceState.currentIndex;\n    \n    // Calculate match scores for all segments\n    const matchScores = pattern.segments.map((segment, i) => {\n      // Get window size based on segment size\n      const windowSize = Math.min(segment.frameCount * 2, this.state.detectionBuffer.energy.length);\n      \n      // Get recent frames\n      const recentFrames = {\n        energy: this.state.detectionBuffer.energy.slice(-windowSize),\n        mfcc: this.state.detectionBuffer.mfcc.slice(-windowSize),\n        spectrogram: this.state.detectionBuffer.spectrogram.slice(-windowSize)\n      };\n      \n      // Calculate match score\n      return this.calculateSegmentMatch(recentFrames, segment);\n    });\n    \n    // Update match scores\n    sequenceState.matchScores = matchScores;\n    \n    // Find best matching segment\n    const bestMatchIndex = matchScores.indexOf(Math.max(...matchScores));\n    const bestMatchScore = matchScores[bestMatchIndex];\n    \n    // Current time\n    const now = Date.now();\n    \n    // Debug info\n    const debugInfo = {\n      currentSegment: currentIndex + 1,\n      totalSegments: pattern.segments.length,\n      matchScores,\n      bestMatchIndex: bestMatchIndex + 1,\n      bestMatchScore,\n      threshold: this.config.minMatchThreshold\n    };\n    \n    // Check for timeout\n    if (sequenceState.segments[currentIndex] === 'active') {\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      \n      if (timeInSegment > this.config.segmentTimeout) {\n        // Check if a later segment is matching better\n        if (bestMatchIndex > currentIndex && bestMatchScore >= this.config.advanceThreshold) {\n          // Skip to that segment\n          for (let i = currentIndex; i < bestMatchIndex; i++) {\n            sequenceState.segments[i] = 'complete';\n          }\n          sequenceState.currentIndex = bestMatchIndex;\n          sequenceState.segmentStartTimes[bestMatchIndex] = now;\n          sequenceState.segments[bestMatchIndex] = 'active';\n          sequenceState.lastAdvanceTime = now;\n          \n          this.log('info', `Skipped to segment ${bestMatchIndex + 1} (better match)`);\n          \n          // Update debug info\n          debugInfo.skipped = true;\n          debugInfo.skippedTo = bestMatchIndex + 1;\n        } else {\n          // Reset if stuck too long with no better matches\n          this.log('info', `Timeout on segment ${currentIndex + 1}`);\n          this.resetSequenceState();\n          \n          // Update debug info\n          debugInfo.timeout = true;\n          \n          return {\n            patternDetected: false,\n            confidence: 0,\n            debugInfo\n          };\n        }\n      }\n    }\n    \n    // Current segment match\n    const currentMatch = matchScores[currentIndex];\n    \n    // Forward lookahead - if a later segment is matching very well\n    if (sequenceState.segments[currentIndex] === 'pending' && currentMatch < this.config.minMatchThreshold) {\n      // Check if any later segment is matching well\n      for (let i = currentIndex + 1; i < matchScores.length; i++) {\n        if (matchScores[i] >= this.config.minMatchThreshold * 1.2) {\n          // Skip to this segment\n          sequenceState.currentIndex = i;\n          sequenceState.segments[i] = 'active';\n          sequenceState.segmentStartTimes[i] = now;\n          sequenceState.lastAdvanceTime = now;\n          \n          this.log('info', `Jumped to segment ${i + 1} (strong match)`);\n          \n          // Update debug info\n          debugInfo.jumped = true;\n          debugInfo.jumpedTo = i + 1;\n          \n          break;\n        }\n      }\n    }\n    \n    // Update current index after possible jumps\n    const updatedCurrentIndex = sequenceState.currentIndex;\n    const currentSegment = pattern.segments[updatedCurrentIndex];\n    \n    // Handle current segment based on match score\n    if (matchScores[updatedCurrentIndex] >= this.config.minMatchThreshold) {\n      // If we just started matching this segment, record the start time\n      if (sequenceState.segments[updatedCurrentIndex] === 'pending') {\n        sequenceState.segments[updatedCurrentIndex] = 'active';\n        sequenceState.segmentStartTimes[updatedCurrentIndex] = now;\n        sequenceState.lastAdvanceTime = now;\n        this.log('info', `Matching segment ${updatedCurrentIndex + 1}/${pattern.segments.length}`);\n      }\n      \n      // Check if we've been matching long enough to advance\n      const timeInSegment = now - (sequenceState.segmentStartTimes[updatedCurrentIndex] || now);\n      const minSegmentTime = Math.max(\n        200,  // Shorter minimum time for flexible mode\n        (currentSegment.frameCount / pattern.rawData.energy.length) * pattern.rawData.duration * 0.4\n      );\n      \n      // Add timing to debug info\n      debugInfo.timeInSegment = timeInSegment;\n      debugInfo.minSegmentTime = minSegmentTime;\n      \n      if (timeInSegment >= minSegmentTime && matchScores[updatedCurrentIndex] >= this.config.advanceThreshold) {\n        // Mark segment as complete\n        sequenceState.segments[updatedCurrentIndex] = 'complete';\n        \n        // Check if this was the last segment\n        if (updatedCurrentIndex === pattern.segments.length - 1) {\n          // Completed the full pattern\n          return {\n            patternDetected: true,\n            confidence: this.calculateOverallConfidence(),\n            debugInfo: {\n              ...debugInfo,\n              completed: true\n            }\n          };\n        } else {\n          // Move to next segment\n          sequenceState.currentIndex++;\n          sequenceState.lastAdvanceTime = now;\n          this.log('info', `Advanced to segment ${sequenceState.currentIndex + 1}/${pattern.segments.length}`);\n          \n          // Add progress data to debug info\n          debugInfo.advanced = true;\n          debugInfo.nextSegment = sequenceState.currentIndex + 1;\n        }\n      }\n    } else {\n      // If we were matching but lost it, check if a different segment matches better\n      if (sequenceState.segments[updatedCurrentIndex] === 'active') {\n        // If best match is a different segment with a good score\n        if (bestMatchIndex !== updatedCurrentIndex && bestMatchScore >= this.config.minMatchThreshold) {\n          // If it's a later segment, skip to it\n          if (bestMatchIndex > updatedCurrentIndex) {\n            // Mark all segments up to best match as complete\n            for (let i = updatedCurrentIndex; i < bestMatchIndex; i++) {\n              sequenceState.segments[i] = 'complete';\n            }\n            \n            sequenceState.currentIndex = bestMatchIndex;\n            sequenceState.segments[bestMatchIndex] = 'active';\n            sequenceState.segmentStartTimes[bestMatchIndex] = now;\n            sequenceState.lastAdvanceTime = now;\n            \n            this.log('info', `Skipped to segment ${bestMatchIndex + 1} (better match)`);\n            \n            // Update debug info\n            debugInfo.skipped = true;\n            debugInfo.skippedTo = bestMatchIndex + 1;\n          } \n          // If it's an earlier segment, allow jumping back\n          else if (bestMatchIndex < updatedCurrentIndex) {\n            // Only jump back if the score is significantly better\n            if (bestMatchScore > matchScores[updatedCurrentIndex] * 1.5) {\n              // Reset segments after best match\n              for (let i = bestMatchIndex + 1; i < sequenceState.segments.length; i++) {\n                sequenceState.segments[i] = 'pending';\n              }\n              \n              sequenceState.currentIndex = bestMatchIndex;\n              sequenceState.segments[bestMatchIndex] = 'active';\n              sequenceState.segmentStartTimes[bestMatchIndex] = now;\n              sequenceState.lastAdvanceTime = now;\n              \n              this.log('info', `Jumped back to segment ${bestMatchIndex + 1} (much better match)`);\n              \n              // Update debug info\n              debugInfo.jumpedBack = true;\n              debugInfo.jumpedBackTo = bestMatchIndex + 1;\n            }\n          }\n        } else {\n          // Mark as invalid if no better matches found\n          sequenceState.segments[updatedCurrentIndex] = 'invalid';\n          this.log('info', `Lost match for segment ${updatedCurrentIndex + 1}`);\n          \n          // Reset after a short delay\n          setTimeout(() => {\n            if (this.state.isDetecting && \n                this.state.sequenceState.currentIndex === updatedCurrentIndex &&\n                this.state.sequenceState.segments[updatedCurrentIndex] === 'invalid') {\n              this.resetSequenceState();\n              this.log('info', 'Reset sequence state');\n            }\n          }, 300);\n        }\n      }\n    }\n    \n    // Calculate overall progress\n    const completedSegments = sequenceState.segments.filter(s => s === 'complete').length;\n    const activeSegment = sequenceState.segments.indexOf('active');\n    \n    if (activeSegment !== -1) {\n      // Include partial progress of active segment\n      const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);\n      sequenceState.progress = (completedSegments / pattern.segments.length) + activeProgress;\n    } else {\n      sequenceState.progress = completedSegments / pattern.segments.length;\n    }\n    \n    // Add progress to debug info\n    debugInfo.progress = sequenceState.progress;\n    debugInfo.segments = [...sequenceState.segments];\n    \n    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };\n  }\n  \n  /**\n   * Adaptive detection that self-adjusts based on input\n   */\n  adaptiveDetection(pattern) {\n    // Similar to flexible detection but with dynamic thresholds\n    const sequenceState = this.state.sequenceState;\n    \n    // Dynamically adjust thresholds based on recent history\n    const currentMatch = sequenceState.matchScores[sequenceState.currentIndex] || 0;\n    \n    // If we've been stuck on a segment for a while, gradually lower the threshold\n    if (sequenceState.segments[sequenceState.currentIndex] === 'active') {\n      const timeInSegment = Date.now() - (sequenceState.segmentStartTimes[sequenceState.currentIndex] || Date.now());\n      \n      // Lower threshold if stuck for a while but still matching somewhat\n      if (timeInSegment > 1000 && currentMatch > this.config.minMatchThreshold * 0.7) {\n        // Calculate adaptive threshold - decrease over time\n        const adaptiveFactor = Math.max(0.5, 1 - (timeInSegment / this.config.segmentTimeout));\n        const adaptiveThreshold = this.config.advanceThreshold * adaptiveFactor;\n        \n        // Use this for advance decision\n        if (currentMatch >= adaptiveThreshold) {\n          // Force advancement\n          sequenceState.stuckTime += timeInSegment;\n          \n          // Call flexible detection with temporarily lowered threshold\n          const origThreshold = this.config.advanceThreshold;\n          this.config.advanceThreshold = adaptiveThreshold;\n          \n          const result = this.flexibleSequentialDetection(pattern);\n          \n          // Restore original threshold\n          this.config.advanceThreshold = origThreshold;\n          \n          // Add adaptive info\n          result.debugInfo.adaptive = true;\n          result.debugInfo.adaptiveThreshold = adaptiveThreshold;\n          result.debugInfo.stuckTime = sequenceState.stuckTime;\n          \n          return result;\n        }\n      }\n    }\n    \n    // Otherwise use flexible detection\n    return this.flexibleSequentialDetection(pattern);\n  }\n  \n  /**\n   * Calculate match between audio and a pattern segment\n   */\n  calculateSegmentMatch(audioData, segment) {\n    // Nothing to match\n    if (!audioData || !segment) return 0;\n    \n    // Get feature arrays\n    const energy = audioData.energy;\n    const mfcc = audioData.mfcc;\n    const spectrogram = audioData.spectrogram;\n    \n    if (!energy.length || !mfcc.length || !spectrogram.length) return 0;\n    \n    // Sliding window approach\n    let bestMatch = 0;\n    const windowSize = Math.min(segment.frameCount, energy.length);\n    \n    for (let i = 0; i <= energy.length - windowSize; i++) {\n      const windowEnergy = energy.slice(i, i + windowSize);\n      const windowMfcc = mfcc.slice(i, i + windowSize);\n      const windowSpectrogram = spectrogram.slice(i, i + windowSize);\n      \n      // Calculate similarity scores\n      const energyMatch = this.calculateEnergySimilarity(windowEnergy, segment.energy);\n      \n      // Average MFCC across window\n      const avgWindowMfcc = this.averageArrays(windowMfcc);\n      const mfccMatch = this.cosineSimilarity(avgWindowMfcc, segment.avgMfcc);\n      \n      // Average spectrogram\n      const avgWindowSpectrogram = this.averageSpectrograms(windowSpectrogram);\n      const spectrogramMatch = this.spectrogramSimilarity(\n        avgWindowSpectrogram, segment.avgSpectrogram\n      );\n      \n      // Weighted combination\n      const score = \n        (energyMatch * this.config.featureWeights.energy) +\n        (mfccMatch * this.config.featureWeights.mfcc) +\n        (spectrogramMatch * this.config.featureWeights.spectrogram);\n      \n      bestMatch = Math.max(bestMatch, score);\n    }\n    \n    return bestMatch;\n  }\n  \n  /**\n   * Calculate similarity between energy profiles\n   */\n  calculateEnergySimilarity(energyA, energyB) {\n    if (!energyA || !energyB || !energyA.length || !energyB.length) {\n      return 0;\n    }\n    \n    // Normalize lengths\n    const lenA = energyA.length;\n    const lenB = energyB.length;\n    const normalized = [];\n    \n    // Simple resampling\n    for (let i = 0; i < lenB; i++) {\n      const idx = Math.floor(i * lenA / lenB);\n      normalized[i] = energyA[idx];\n    }\n    \n    // Calculate correlation\n    return this.correlationSimilarity(normalized, energyB);\n  }\n  \n  /**\n   * Calculate correlation similarity between arrays\n   */\n  correlationSimilarity(arrA, arrB) {\n    // Calculate means\n    const meanA = this.average(arrA);\n    const meanB = this.average(arrB);\n    \n    // Calculate correlation\n    let num = 0;\n    let denA = 0;\n    let denB = 0;\n    \n    for (let i = 0; i < Math.min(arrA.length, arrB.length); i++) {\n      const a = arrA[i] - meanA;\n      const b = arrB[i] - meanB;\n      \n      num += a * b;\n      denA += a * a;\n      denB += b * b;\n    }\n    \n    // Avoid division by zero\n    if (denA === 0 || denB === 0) return 0;\n    \n    // Return Pearson correlation (between -1 and 1)\n    const corr = num / Math.sqrt(denA * denB);\n    \n    // Convert to similarity (0-1)\n    return (corr + 1) / 2;\n  }\n  \n  /**\n   * Compare two spectrograms\n   */\n  spectrogramSimilarity(spectrogramA, spectrogramB) {\n    if (!spectrogramA || !spectrogramB || \n        !spectrogramA.length || !spectrogramB.length) {\n      return 0;\n    }\n    \n    // Use cosine similarity between flattened spectrograms\n    const flatA = spectrogramA.flat ? spectrogramA.flat() : this.flattenArray(spectrogramA);\n    const flatB = spectrogramB.flat ? spectrogramB.flat() : this.flattenArray(spectrogramB);\n    \n    return this.cosineSimilarity(flatA, flatB);\n  }\n  \n  /**\n   * Register a detection\n   */\n  registerDetection(confidence) {\n    if (this.state.inCooldown) return false;\n    \n    // Increment counter\n    this.state.counter++;\n    this.state.lastDetectionTime = Date.now();\n    this.state.inCooldown = true;\n    \n    // Log detection\n    this.log('detection', `Pattern detected! Count: ${this.state.counter}`, true);\n    \n    // Reset sequence state\n    this.resetSequenceState();\n    \n    // Trigger callback\n    if (this.callbacks.onDetection) {\n      this.callbacks.onDetection(this.state.counter, confidence);\n    }\n    \n    // Start cooldown timer\n    setTimeout(() => {\n      this.state.inCooldown = false;\n    }, this.config.cooldownTime);\n    \n    return true;\n  }\n  \n  /**\n   * Calculate overall confidence for current match\n   */\n  calculateOverallConfidence() {\n    const matchScores = this.state.sequenceState.matchScores;\n    const segments = this.state.sequenceState.segments;\n    \n    if (!matchScores || matchScores.length === 0) {\n      return 0;\n    }\n    \n    // Weight completed segments more heavily\n    let weightedSum = 0;\n    let weightSum = 0;\n    \n    matchScores.forEach((score, index) => {\n      // Higher weight for completed segments\n      let weight = 1;\n      \n      if (segments[index] === 'complete') {\n        weight = 1.5;\n      } else if (segments[index] === 'active') {\n        weight = 1.2;\n      }\n      \n      weightedSum += score * weight;\n      weightSum += weight;\n    });\n    \n    return weightSum > 0 ? weightedSum / weightSum : 0;\n  }\n  \n  /**\n   * Extract features from audio data\n   */\n  extractFeatures(audioData) {\n    try {\n      // Basic amplitude/energy\n      let sum = 0;\n      for (let i = 0; i < audioData.length; i++) {\n        sum += Math.abs(audioData[i]);\n      }\n      const amplitude = sum / audioData.length;\n      const energy = amplitude * amplitude * 100;\n      \n      // Get frequency data\n      const frequencyData = new Uint8Array(this.analyzer.frequencyBinCount);\n      this.analyzer.getByteFrequencyData(frequencyData);\n      \n      // Extract MFCC using Meyda\n      let mfcc = new Array(13).fill(0);\n      try {\n        const meydaFeatures = Meyda.extract('mfcc', audioData);\n        if (meydaFeatures && meydaFeatures.mfcc) {\n          mfcc = meydaFeatures.mfcc;\n        }\n      } catch (e) {\n        // Ignore Meyda errors and use fallback\n      }\n      \n      // Convert spectrogram data\n      const spectrogram = this.processSpectrumData(frequencyData);\n      \n      return {\n        amplitude,\n        energy,\n        mfcc,\n        spectrogram,\n        raw: {\n          frequencyData\n        }\n      };\n    } catch (error) {\n      this.handleError('Error extracting features', error);\n      \n      // Return dummy features\n      return {\n        amplitude: 0,\n        energy: 0,\n        mfcc: new Array(13).fill(0),\n        spectrogram: new Array(128).fill(0),\n        raw: {\n          frequencyData: new Uint8Array(1024)\n        }\n      };\n    }\n  }\n  \n  /**\n   * Process raw spectrum data into a more compact format\n   */\n  processSpectrumData(frequencyData) {\n    // Reduce dimensionality for efficiency\n    const bins = 128; // 128 frequency bins\n    const result = new Array(bins).fill(0);\n    \n    const binSize = Math.floor(frequencyData.length / bins);\n    \n    for (let i = 0; i < bins; i++) {\n      const start = i * binSize;\n      const end = (i + 1) * binSize;\n      \n      // Average values in this frequency bin\n      let sum = 0;\n      for (let j = start; j < end && j < frequencyData.length; j++) {\n        sum += frequencyData[j];\n      }\n      \n      result[i] = sum / binSize / 255; // Normalize to 0-1\n    }\n    \n    return result;\n  }\n  \n  /**\n   * Start animation loop for cursor movement\n   */\n  startAnimationLoop() {\n    // Stop any existing loop\n    this.stopAnimationLoop();\n    \n    // Animation function\n    const animate = () => {\n      // Move time cursor\n      const cursor = document.getElementById('timeCursor');\n      if (cursor) {\n        // Get a position that oscillates between 25% and 75%\n        const time = Date.now() / 1000;\n        const position = 50 + 25 * Math.sin(time);\n        cursor.style.left = `${position}%`;\n      }\n      \n      // Request next frame\n      this.animationFrame = requestAnimationFrame(animate);\n    };\n    \n    // Start animation\n    this.animationFrame = requestAnimationFrame(animate);\n  }\n  \n  /**\n   * Stop animation loop\n   */\n  stopAnimationLoop() {\n    if (this.animationFrame) {\n      cancelAnimationFrame(this.animationFrame);\n      this.animationFrame = null;\n    }\n  }\n  \n  /**\n   * Update configuration\n   */\n  updateConfig(config) {\n    Object.assign(this.config, config);\n    \n    // If segment count changed and we have a pattern, re-segment it\n    if (config.segmentCount !== undefined && this.state.patterns[this.state.activePatternIndex]) {\n      const pattern = this.state.patterns[this.state.activePatternIndex];\n      \n      if (pattern && pattern.rawData) {\n        pattern.segments = this.segmentPattern(pattern.rawData);\n        this.calculateSegmentBoundaries(pattern);\n      }\n    }\n  }\n  \n  /**\n   * Find peaks in energy profile\n   */\n  findPeaks(signal, minHeight = 0.1) {\n    const peaks = [];\n    for (let i = 2; i < signal.length - 2; i++) {\n      if (signal[i] > minHeight && \n          signal[i] > signal[i-1] && signal[i] >= signal[i-2] &&\n          signal[i] > signal[i+1] && signal[i] >= signal[i+2]) {\n        peaks.push(i);\n      }\n    }\n    return peaks;\n  }\n  \n  /**\n   * Find valleys in energy profile\n   */\n  findValleys(signal, maxHeight = 0.9) {\n    const valleys = [];\n    for (let i = 2; i < signal.length - 2; i++) {\n      if (signal[i] < maxHeight && \n          signal[i] < signal[i-1] && signal[i] <= signal[i-2] &&\n          signal[i] < signal[i+1] && signal[i] <= signal[i+2]) {\n        valleys.push(i);\n      }\n    }\n    return valleys;\n  }\n  \n  /**\n   * Smooth an array using moving average\n   */\n  smoothArray(array, windowSize = 3) {\n    const result = [];\n    const half = Math.floor(windowSize / 2);\n    \n    for (let i = 0; i < array.length; i++) {\n      let sum = 0;\n      let count = 0;\n      \n      for (let j = Math.max(0, i - half); j <= Math.min(array.length - 1, i + half); j++) {\n        sum += array[j];\n        count++;\n      }\n      \n      result.push(sum / count);\n    }\n    \n    return result;\n  }\n  \n  /**\n   * Average multiple arrays\n   */\n  averageArrays(arrays) {\n    if (!arrays || arrays.length === 0 || !arrays[0]) return [];\n    \n    const result = new Array(arrays[0].length).fill(0);\n    let validArrays = 0;\n    \n    for (const arr of arrays) {\n      if (!arr) continue;\n      \n      validArrays++;\n      for (let i = 0; i < Math.min(result.length, arr.length); i++) {\n        result[i] += arr[i];\n      }\n    }\n    \n    return validArrays > 0 ? result.map(val => val / validArrays) : result;\n  }\n  \n  /**\n   * Average multiple spectrograms\n   */\n  averageSpectrograms(spectrograms) {\n    return this.averageArrays(spectrograms);\n  }\n  \n  /**\n   * Calculate average of array\n   */\n  average(array) {\n    if (!array || array.length === 0) return 0;\n    return array.reduce((sum, val) => sum + val, 0) / array.length;\n  }\n  \n  /**\n   * Calculate cosine similarity between arrays\n   */\n  cosineSimilarity(arrA, arrB) {\n    if (!arrA || !arrB || arrA.length === 0 || arrB.length === 0) {\n      return 0;\n    }\n    \n    const length = Math.min(arrA.length, arrB.length);\n    \n    let dotProduct = 0;\n    let normA = 0;\n    let normB = 0;\n    \n    for (let i = 0; i < length; i++) {\n      dotProduct += arrA[i] * arrB[i];\n      normA += arrA[i] * arrA[i];\n      normB += arrB[i] * arrB[i];\n    }\n    \n    const denominator = Math.sqrt(normA) * Math.sqrt(normB);\n    \n    return denominator === 0 ? 0 : dotProduct / denominator;\n  }\n  \n  /**\n   * Flatten a 2D array\n   */\n  flattenArray(array) {\n    if (array.flat) return array.flat();\n    \n    return [].concat(...array);\n  }\n  \n  /**\n   * Handle errors\n   */\n  handleError(message, error) {\n    const errorMessage = `${message}: ${error.message || error}`;\n    console.error(errorMessage);\n    \n    if (this.callbacks.onError) {\n      this.callbacks.onError(message, error);\n    }\n  }\n  \n  /**\n   * Log messages\n   */\n  log(type, message, highlight = false) {\n    console.log(`[${type.toUpperCase()}] ${message}`);\n    \n    if (this.callbacks.onStatusUpdate) {\n      this.callbacks.onStatusUpdate(type, message, highlight);\n    }\n    \n    return { type, message, highlight };\n  }\n}\n\n// Main Application\ndocument.addEventListener('DOMContentLoaded', () => {\n  // Elements\n  const elements = {\n    // Pattern recording \n    recordingStatus: document.getElementById('recordingStatus'),\n    recordBtn: document.getElementById('recordBtn'),\n    clearBtn: document.getElementById('clearBtn'),\n    averageBtn: document.getElementById('averageBtn'),\n    patternInfo: document.getElementById('patternInfo'),\n    patternStats: document.getElementById('patternStats'),\n    patternDisplay: document.getElementById('patternDisplay'),\n    recordSpectrogram: document.getElementById('recordSpectrogram'),\n    recordSegmentMarkers: document.getElementById('recordSegmentMarkers'),\n    \n    // Detection\n    liveSpectrogram: document.getElementById('liveSpectrogram'),\n    liveSegmentMarkers: document.getElementById('liveSegmentMarkers'),\n    timeCursor: document.getElementById('timeCursor'),\n    detectionStatus: document.getElementById('detectionStatus'),\n    counterValue: document.getElementById('counterValue'),\n    sequenceProgress: document.getElementById('sequenceProgress'),\n    detectionProgress: document.getElementById('detectionProgress'),\n    \n    // Controls\n    startBtn: document.getElementById('startBtn'),\n    stopBtn: document.getElementById('stopBtn'),\n    resetBtn: document.getElementById('resetBtn'),\n    patternTabs: document.querySelectorAll('.pattern-tab'),\n    \n    // Settings\n    detectionMode: document.getElementById('detectionMode'),\n    minMatchSlider: document.getElementById('minMatchSlider'),\n    minMatchValue: document.getElementById('minMatchValue'),\n    advanceThresholdSlider: document.getElementById('advanceThresholdSlider'),\n    advanceThresholdValue: document.getElementById('advanceThresholdValue'),\n    timeoutSlider: document.getElementById('timeoutSlider'),\n    timeoutValue: document.getElementById('timeoutValue'),\n    cooldownSlider: document.getElementById('cooldownSlider'),\n    cooldownValue: document.getElementById('cooldownValue'),\n    segmentCountSelect: document.getElementById('segmentCountSelect'),\n    \n    // Debug\n    debugPanel: document.getElementById('debugPanel'),\n    detectionLog: document.getElementById('detectionLog')\n  };\n  \n  // Canvas contexts\n  const contexts = {\n    recordSpectrogram: elements.recordSpectrogram.getContext('2d'),\n    liveSpectrogram: elements.liveSpectrogram.getContext('2d')\n  };\n  \n  // Create detector\n  const detector = new ImprovedChantDetector();\n  \n  // Set up detector callbacks\n  detector.setCallbacks({\n    onStatusUpdate: (type, message, data) => {\n      if (type === 'status') {\n        elements.detectionStatus.textContent = message;\n      } else if (type === 'info') {\n        logDetection(message, false);\n      } else if (type === 'detection') {\n        logDetection(message, data);\n      } else if (type === 'control') {\n        if (message === 'enableAveraging') {\n          elements.averageBtn.disabled = !data;\n        }\n      }\n    },\n    \n    onVisualizationUpdate: (mode, audioData, features) => {\n      if (mode === 'recording') {\n        drawSpectrogram(contexts.recordSpectrogram, features.raw.frequencyData);\n      } else if (mode === 'detection') {\n        drawSpectrogram(contexts.liveSpectrogram, features.raw.frequencyData);\n      } else if (mode === 'patternSwitch') {\n        updatePatternDisplay(features);\n      }\n    },\n    \n    onDetection: (count, confidence) => {\n      elements.counterValue.textContent = count;\n      elements.detectionProgress.style.backgroundColor = '#f44336';\n      \n      setTimeout(() => {\n        elements.detectionProgress.style.backgroundColor = '#4caf50';\n      }, 300);\n    },\n    \n    onProgressUpdate: (sequenceState, debugData) => {\n      // Update progress bar\n      elements.detectionProgress.style.width = `${Math.round(sequenceState.progress * 100)}%`;\n      \n      // Update sequence progress visualization\n      updateSequenceProgress(sequenceState);\n      \n      // Update debug panel\n      if (debugData) {\n        updateDebugPanel(debugData);\n      }\n    },\n    \n    onError: (message, error) => {\n      console.error(message, error);\n      logDetection(`Error: ${message}`, true);\n    }\n  });\n  \n  // Button handlers\n  elements.recordBtn.addEventListener('mousedown', () => {\n    detector.startRecording();\n    elements.recordBtn.textContent = 'Recording...';\n  });\n  \n  elements.recordBtn.addEventListener('mouseup', () => {\n    detector.stopRecording();\n    elements.recordBtn.textContent = 'Record (Hold)';\n    updatePatternInfo();\n  });\n  \n  elements.recordBtn.addEventListener('mouseleave', () => {\n    if (detector.state.isRecording) {\n      detector.stopRecording();\n      elements.recordBtn.textContent = 'Record (Hold)';\n      updatePatternInfo();\n    }\n  });\n  \n  elements.clearBtn.addEventListener('click', () => {\n    detector.clearActivePattern();\n    updatePatternInfo();\n    elements.startBtn.disabled = true;\n    \n    // Clear display\n    elements.patternDisplay.innerHTML = '';\n    elements.recordSegmentMarkers.innerHTML = '';\n    clearCanvas(contexts.recordSpectrogram);\n  });\n  \n  elements.averageBtn.addEventListener('click', () => {\n    detector.averageAllPatterns();\n    updatePatternInfo();\n  });\n  \n  elements.startBtn.addEventListener('click', () => {\n    detector.startDetection();\n    elements.startBtn.disabled = true;\n    elements.stopBtn.disabled = false;\n  });\n  \n  elements.stopBtn.addEventListener('click', () => {\n    detector.stopDetection();\n    elements.startBtn.disabled = false;\n    elements.stopBtn.disabled = true;\n    \n    // Reset visualizations\n    elements.detectionProgress.style.width = '0%';\n    elements.sequenceProgress.innerHTML = '';\n    elements.liveSegmentMarkers.innerHTML = '';\n    clearCanvas(contexts.liveSpectrogram);\n  });\n  \n  elements.resetBtn.addEventListener('click', () => {\n    detector.resetCounter();\n  });\n  \n  // Pattern tabs\n  elements.patternTabs.forEach(tab => {\n    tab.addEventListener('click', () => {\n      const patternIndex = parseInt(tab.getAttribute('data-pattern')) - 1;\n      \n      // Update active tab\n      elements.patternTabs.forEach(t => t.classList.remove('active'));\n      tab.classList.add('active');\n      \n      // Set active pattern\n      detector.setActivePattern(patternIndex);\n      \n      updatePatternInfo();\n    });\n  });\n  \n  // Settings handlers\n  elements.detectionMode.addEventListener('change', () => {\n    detector.updateConfig({\n      detectionMode: elements.detectionMode.value\n    });\n    \n    logDetection(`Detection mode changed to: ${elements.detectionMode.value}`);\n  });\n  \n  elements.minMatchSlider.addEventListener('input', () => {\n    const value = elements.minMatchSlider.value;\n    elements.minMatchValue.textContent = value;\n    \n    detector.updateConfig({\n      minMatchThreshold: parseFloat(value)\n    });\n  });\n  \n  elements.advanceThresholdSlider.addEventListener('input', () => {\n    const value = elements.advanceThresholdSlider.value;\n    elements.advanceThresholdValue.textContent = value;\n    \n    detector.updateConfig({\n      advanceThreshold: parseFloat(value)\n    });\n  });\n  \n  elements.timeoutSlider.addEventListener('input', () => {\n    const value = elements.timeoutSlider.value;\n    elements.timeoutValue.textContent = value;\n    \n    detector.updateConfig({\n      segmentTimeout: parseInt(value)\n    });\n  });\n  \n  elements.cooldownSlider.addEventListener('input', () => {\n    const value = elements.cooldownSlider.value;\n    elements.cooldownValue.textContent = value;\n    \n    detector.updateConfig({\n      cooldownTime: parseInt(value)\n    });\n  });\n  \n  elements.segmentCountSelect.addEventListener('change', () => {\n    detector.updateConfig({\n      segmentCount: parseInt(elements.segmentCountSelect.value)\n    });\n    \n    // Update pattern info if we have a pattern\n    if (detector.state.patterns[detector.state.activePatternIndex]) {\n      updatePatternInfo();\n    }\n  });\n  \n  // Visualization functions\n  function drawSpectrogram(ctx, frequencyData) {\n    const width = ctx.canvas.width;\n    const height = ctx.canvas.height;\n    \n    // Shift existing spectrogram left\n    const imgData = ctx.getImageData(1, 0, width - 1, height);\n    ctx.putImageData(imgData, 0, 0);\n    \n    // Draw new column\n    const columnWidth = 1;\n    const binCount = Math.min(128, frequencyData.length / 4);\n    const binHeight = height / binCount;\n    \n    for (let i = 0; i < binCount; i++) {\n      // Reverse order (low frequency at bottom)\n      const y = height - (i + 1) * binHeight;\n      \n      // Average a range of frequency bins\n      const startBin = i * 4;\n      const endBin = startBin + 4;\n      \n      let binSum = 0;\n      for (let j = startBin; j < endBin && j < frequencyData.length; j++) {\n        binSum += frequencyData[j];\n      }\n      \n      const intensity = binSum / 4;\n      \n      // Create color (blue to red gradient)\n      const hue = 240 * (1 - intensity / 255);\n      const saturation = '100%';\n      const lightness = '50%';\n      \n      ctx.fillStyle = `hsl(${hue}, ${saturation}, ${lightness})`;\n      ctx.fillRect(width - columnWidth, y, columnWidth, binHeight);\n    }\n  }\n  \n  function clearCanvas(ctx) {\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n  }\n  \n  function updateSequenceProgress(sequenceState) {\n    const container = elements.sequenceProgress;\n    container.innerHTML = '';\n    \n    // Create segment boxes\n    sequenceState.segments.forEach((state, index) => {\n      const segmentBox = document.createElement('div');\n      segmentBox.className = `segment-box segment-${state}`;\n      segmentBox.textContent = index + 1;\n      \n      container.appendChild(segmentBox);\n    });\n    \n    // Update segment markers on live spectrogram\n    updateSegmentMarkers(\n      elements.liveSegmentMarkers, \n      detector.state.patterns[detector.state.activePatternIndex]\n    );\n  }\n  \n  function updatePatternDisplay(pattern) {\n    if (!pattern || !pattern.segments || pattern.segments.length === 0) {\n      elements.patternDisplay.innerHTML = '';\n      elements.recordSegmentMarkers.innerHTML = '';\n      return;\n    }\n    \n    // Create segment display\n    const container = elements.patternDisplay;\n    container.innerHTML = '';\n    \n    // Create segment divs\n    pattern.segments.forEach((segment, index) => {\n      const segmentDiv = document.createElement('div');\n      segmentDiv.className = 'pattern-segment';\n      \n      // Add label\n      const labelDiv = document.createElement('div');\n      labelDiv.className = 'pattern-segment-label';\n      labelDiv.textContent = `Segment ${index + 1}`;\n      \n      // Create canvas for segment visualization\n      const canvas = document.createElement('canvas');\n      canvas.width = container.clientWidth / pattern.segments.length;\n      canvas.height = container.clientHeight;\n      \n      segmentDiv.appendChild(labelDiv);\n      segmentDiv.appendChild(canvas);\n      container.appendChild(segmentDiv);\n      \n      // Draw segment spectrogram\n      const ctx = canvas.getContext('2d');\n      \n      // Draw as a grid of colored cells\n      const blockWidth = canvas.width / segment.spectrogram.length;\n      const blockHeight = canvas.height / segment.spectrogram[0].length;\n      \n      for (let i = 0; i < segment.spectrogram.length; i++) {\n        for (let j = 0; j < segment.spectrogram[i].length; j++) {\n          const value = segment.spectrogram[i][j];\n          const hue = 240 * (1 - value);\n          ctx.fillStyle = `hsl(${hue}, 100%, 50%)`;\n          ctx.fillRect(\n            i * blockWidth, \n            canvas.height - (j + 1) * blockHeight,\n            blockWidth,\n            blockHeight\n          );\n        }\n      }\n    });\n    \n    // Update segment markers\n    updateSegmentMarkers(elements.recordSegmentMarkers, pattern);\n  }\n  \n  function updateSegmentMarkers(container, pattern) {\n    if (!pattern || !pattern.boundaries) {\n      container.innerHTML = '';\n      return;\n    }\n    \n    container.innerHTML = '';\n    \n    // Create markers\n    pattern.boundaries.forEach(boundary => {\n      // Start marker\n      const startMarker = document.createElement('div');\n      startMarker.className = 'segment-marker';\n      startMarker.style.left = `${boundary.start * 100}%`;\n      container.appendChild(startMarker);\n      \n      // Label\n      const label = document.createElement('div');\n      label.className = 'segment-label';"
          },
          {
            "file_name": "paste-2.txt",
            "file_size": 122541,
            "file_type": "txt",
            "extracted_content": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Enhanced Thikr Pattern Detector</title>\n  <style>\n    body {\n      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n      margin: 0;\n      padding: 20px;\n      max-width: 900px;\n      margin: 0 auto;\n      background-color: #f9f9f9;\n      color: #333;\n    }\n    h1, h2, h3 {\n      color: #2c3e50;\n    }\n    .container {\n      background-color: #fff;\n      border-radius: 8px;\n      padding: 15px;\n      box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n      margin-bottom: 20px;\n    }\n    .visualizer {\n      background-color: #f5f5f5;\n      border: 1px solid #ddd;\n      border-radius: 4px;\n      height: 120px;\n      margin: 10px 0;\n      position: relative;\n      overflow: hidden;\n    }\n    .visualizer-overlay {\n      position: absolute;\n      top: 0;\n      left: 0;\n      right: 0;\n      bottom: 0;\n      pointer-events: none;\n    }\n    .feature-visualizer {\n      height: 60px;\n      background-color: #f5f5f5;\n      border-radius: 4px;\n      margin: 5px 0;\n      position: relative;\n    }\n    .btn {\n      background-color: #3498db;\n      color: white;\n      border: none;\n      padding: 8px 16px;\n      border-radius: 4px;\n      cursor: pointer;\n      font-size: 14px;\n      margin-right: 10px;\n      margin-bottom: 5px;\n    }\n    .btn:hover {\n      background-color: #2980b9;\n    }\n    .btn:disabled {\n      background-color: #bdc3c7;\n      cursor: not-allowed;\n    }\n    .btn.recording {\n      background-color: #e74c3c;\n    }\n    .status {\n      margin: 10px 0;\n      padding: 8px;\n      background-color: #f5f5f5;\n      border-radius: 4px;\n      font-size: 14px;\n    }\n    .counter {\n      font-size: 28px;\n      font-weight: bold;\n      margin: 10px 0;\n      text-align: center;\n    }\n    .setting-row {\n      display: flex;\n      align-items: center;\n      margin: 8px 0;\n    }\n    .setting-row label {\n      width: 200px;\n      margin-right: 10px;\n    }\n    .setting-row input, .setting-row select {\n      flex: 1;\n      margin-right: 10px;\n      padding: 5px;\n      border: 1px solid #ddd;\n      border-radius: 4px;\n    }\n    .setting-value {\n      width: 50px;\n      text-align: right;\n      font-weight: bold;\n    }\n    .debug-container {\n      margin-top: 15px;\n      max-height: 300px;\n      overflow-y: auto;\n      border: 1px solid #ddd;\n      padding: 10px;\n      background-color: #f9f9f9;\n      border-radius: 4px;\n      font-family: monospace;\n      font-size: 12px;\n    }\n    .segments-container {\n      display: flex;\n      flex-direction: column;\n      margin: 15px 0;\n    }\n    .segment-display {\n      display: flex;\n      flex-wrap: wrap;\n      margin-bottom: 15px;\n    }\n    .segment {\n      flex: 1;\n      min-width: 150px;\n      background-color: #f5f5f5;\n      border: 1px solid #ddd;\n      border-radius: 4px;\n      margin: 5px;\n      position: relative;\n      overflow: hidden;\n      height: 100px;\n    }\n    .segment-title {\n      position: absolute;\n      top: 5px;\n      left: 5px;\n      background-color: rgba(255, 255, 255, 0.7);\n      padding: 2px 5px;\n      border-radius: 3px;\n      font-size: 12px;\n      font-weight: bold;\n    }\n    .confidence-meter {\n      display: flex;\n      height: 40px;\n      margin: 10px 0;\n      background-color: #f5f5f5;\n      border-radius: 4px;\n      overflow: hidden;\n    }\n    .confidence-segment {\n      height: 100%;\n      transition: width 0.3s, background-color 0.3s;\n      display: flex;\n      align-items: center;\n      justify-content: center;\n      color: white;\n      font-weight: bold;\n      text-shadow: 0 0 2px rgba(0, 0, 0, 0.5);\n    }\n    .detection-log {\n      max-height: 200px;\n      overflow-y: auto;\n      font-size: 12px;\n      padding: 10px;\n      background-color: #f5f5f5;\n      border-radius: 4px;\n    }\n    .detection-log div {\n      margin-bottom: 4px;\n      padding-bottom: 4px;\n      border-bottom: 1px dashed #ddd;\n    }\n    .detection-log .highlight {\n      color: #e74c3c;\n      font-weight: bold;\n    }\n    .match-indicator {\n      position: absolute;\n      bottom: 0;\n      left: 0;\n      height: 5px;\n      background-color: #27ae60;\n      transition: width 0.2s;\n    }\n    .timestamp {\n      color: #7f8c8d;\n      font-size: 0.9em;\n    }\n    .info-box {\n      padding: 10px;\n      background-color: #eef7ff;\n      border-left: 4px solid #3498db;\n      margin: 10px 0;\n      font-size: 14px;\n    }\n    .tabs {\n      display: flex;\n      border-bottom: 1px solid #ddd;\n      margin-bottom: 15px;\n    }\n    .tab {\n      padding: 8px 15px;\n      cursor: pointer;\n      background-color: #f5f5f5;\n      border: 1px solid #ddd;\n      border-bottom: none;\n      border-radius: 4px 4px 0 0;\n      margin-right: 5px;\n    }\n    .tab.active {\n      background-color: #fff;\n      border-bottom: 1px solid #fff;\n      margin-bottom: -1px;\n    }\n    .tab-content {\n      display: none;\n    }\n    .tab-content.active {\n      display: block;\n    }\n    .segment-timeline {\n      height: 40px;\n      background-color: #f5f5f5;\n      border-radius: 4px;\n      margin: 15px 0;\n      position: relative;\n      overflow: hidden;\n    }\n    .segment-marker {\n      position: absolute;\n      top: 0;\n      width: 3px;\n      height: 100%;\n      background-color: #e74c3c;\n      transition: left 0.3s;\n    }\n    .method-badge {\n      display: inline-block;\n      padding: 2px 6px;\n      background-color: #3498db;\n      color: white;\n      border-radius: 4px;\n      font-size: 12px;\n      margin-top: 5px;\n    }\n    .feature-badge {\n      display: inline-block;\n      background-color: #f1c40f;\n      color: #333;\n      padding: 1px 5px;\n      border-radius: 3px;\n      font-size: 11px;\n      margin-right: 5px;\n    }\n    #timelineCanvas {\n      width: 100%;\n      height: 100%;\n    }\n    .feature-container {\n      margin-top: 10px;\n      display: flex;\n      flex-wrap: wrap;\n    }\n    .feature-item {\n      flex: 1;\n      min-width: 120px;\n      margin: 5px;\n      background-color: #f5f5f5;\n      border-radius: 4px;\n      padding: 5px;\n      font-size: 12px;\n    }\n    .feature-label {\n      font-weight: bold;\n      margin-bottom: 3px;\n    }\n    .feature-value {\n      display: flex;\n      height: 15px;\n      background-color: #ddd;\n      border-radius: 3px;\n      overflow: hidden;\n      margin-bottom: 3px;\n    }\n    .feature-bar {\n      height: 100%;\n      background-color: #3498db;\n      transition: width 0.3s;\n    }\n    .phoneme-display {\n      margin-top: 10px;\n      border: 1px solid #ddd;\n      border-radius: 4px;\n      padding: 5px;\n      background-color: #f9f9f9;\n      min-height: 60px;\n    }\n    .phoneme-item {\n      display: inline-block;\n      margin: 3px;\n      padding: 3px 6px;\n      background-color: #3498db;\n      color: white;\n      border-radius: 3px;\n      font-size: 12px;\n      opacity: 0.7;\n    }\n    .phoneme-item.active {\n      opacity: 1;\n      box-shadow: 0 0 5px rgba(0,0,0,0.3);\n    }\n    .phoneme-item.vowel {\n      background-color: #e74c3c;\n    }\n    .phoneme-item.consonant {\n      background-color: #2980b9;\n    }\n    .phoneme-item.silence {\n      background-color: #95a5a6;\n    }\n    .detected-pattern {\n      background-color: #dff0d8;\n      border: 1px solid #d6e9c6;\n      color: #3c763d;\n      padding: 10px;\n      margin: 10px 0;\n      border-radius: 4px;\n      position: relative;\n      overflow: hidden;\n    }\n    .detected-pattern.fade {\n      animation: fadeOut 2s forwards;\n    }\n    .pattern-sequence {\n      display: flex;\n      margin: 10px 0;\n      flex-wrap: wrap;\n    }\n    .pattern-sequence-item {\n      display: flex;\n      flex-direction: column;\n      align-items: center;\n      margin: 0 5px;\n      position: relative;\n    }\n    .pattern-sequence-segment {\n      width: 40px;\n      height: 40px;\n      border-radius: 5px;\n      display: flex;\n      align-items: center;\n      justify-content: center;\n      font-weight: bold;\n      color: white;\n      margin-bottom: 5px;\n    }\n    .expected-pattern {\n      background-color: #3498db;\n    }\n    .actual-pattern {\n      background-color: #e74c3c;\n    }\n    .pattern-match {\n      border: 2px solid #27ae60;\n    }\n    .pattern-mismatch {\n      border: 2px solid #c0392b;\n    }\n    .pattern-sequence-arrow {\n      position: absolute;\n      top: 15px;\n      right: -10px;\n      font-size: 14px;\n    }\n    .progress-tracker {\n      height: 30px;\n      background-color: #f5f5f5;\n      border-radius: 4px;\n      position: relative;\n      margin: 10px 0;\n      overflow: hidden;\n    }\n    .progress-segment {\n      height: 100%;\n      float: left;\n      text-align: center;\n      color: white;\n      font-weight: bold;\n      line-height: 30px;\n      transition: background-color 0.3s;\n    }\n    .waiting {\n      background-color: #95a5a6;\n    }\n    .in-progress {\n      background-color: #f39c12;\n    }\n    .completed {\n      background-color: #27ae60;\n    }\n    @keyframes fadeOut {\n      from { opacity: 1; }\n      to { opacity: 0.2; }\n    }\n    .details-toggle {\n      cursor: pointer;\n      color: #3498db;\n      text-decoration: underline;\n      font-size: 12px;\n      margin-top: 5px;\n      display: inline-block;\n    }\n    .details-content {\n      display: none;\n      background-color: #f9f9f9;\n      padding: 10px;\n      border-radius: 4px;\n      margin-top: 5px;\n      font-size: 12px;\n    }\n    .lockout-indicator {\n      background-color: rgba(231, 76, 60, 0.2);\n      position: absolute;\n      top: 0;\n      left: 0;\n      right: 0;\n      bottom: 0;\n      display: flex;\n      align-items: center;\n      justify-content: center;\n      font-weight: bold;\n      color: #e74c3c;\n      transition: opacity 0.5s;\n    }\n    .chart-container {\n      height: 200px;\n      margin: 10px 0;\n      background-color: #f5f5f5;\n      border-radius: 4px;\n      position: relative;\n    }\n    .normalizer-control {\n      display: flex;\n      align-items: center;\n      margin: 5px 0;\n    }\n    .normalizer-label {\n      margin-right: 10px;\n      font-size: 12px;\n      width: 100px;\n    }\n    .feature-chart {\n      position: relative;\n      height: 150px;\n      margin: 10px 0;\n    }\n    .pattern-match-details {\n      margin-top: 10px;\n      border: 1px solid #ddd;\n      border-radius: 4px;\n      padding: 10px;\n      background-color: #f9f9f9;\n    }\n    .match-detail-row {\n      display: flex;\n      margin-bottom: 5px;\n      align-items: center;\n    }\n    .match-detail-label {\n      width: 150px;\n      font-weight: bold;\n      font-size: 12px;\n    }\n    .match-detail-value {\n      flex: 1;\n      height: 20px;\n      background-color: #eee;\n      border-radius: 3px;\n      position: relative;\n      overflow: hidden;\n    }\n    .match-detail-bar {\n      height: 100%;\n      background-color: #3498db;\n      text-align: right;\n      line-height: 20px;\n      padding-right: 5px;\n      font-size: 11px;\n      color: white;\n    }\n    .threshold-marker {\n      position: absolute;\n      height: 100%;\n      width: 2px;\n      background-color: #e74c3c;\n      right: 0;\n    }\n  </style>\n</head>\n<body>\n  <h1>Enhanced Thikr Pattern Detector</h1>\n  <p>Combining Rhythm, Phonetic, and Spectral Pattern Recognition</p>\n\n  <div class=\"container\">\n    <h2>1. Record Thikr Pattern</h2>\n    <div class=\"info-box\">\n      Press and hold the Record button while reciting your complete thikr phrase, then release.\n      Recording multiple samples (2-3) will significantly improve detection accuracy.\n    </div>\n    \n    <div class=\"visualizer\">\n      <canvas id=\"recordingCanvas\"></canvas>\n      <div id=\"recordingIndicator\" class=\"match-indicator\"></div>\n    </div>\n    \n    <div class=\"status\" id=\"recordingStatus\">Ready to record your thikr pattern.</div>\n    \n    <div>\n      <button id=\"recordBtn\" class=\"btn\">Record Thikr (Press & Hold)</button>\n      <button id=\"playLastBtn\" class=\"btn\" disabled>Play Last Sample</button>\n      <button id=\"clearBtn\" class=\"btn\">Clear All Samples</button>\n      <span id=\"sampleCount\">No samples recorded</span>\n    </div>\n  </div>\n\n  <div class=\"container\">\n    <h2>2. Adjust Detection Settings</h2>\n    \n    <div class=\"setting-row\">\n      <label for=\"detectionMethodSelect\">Detection Strategy:</label>\n      <select id=\"detectionMethodSelect\">\n        <option value=\"markov\">Markov Model (Recommended)</option>\n        <option value=\"phonetic\">Phonetic Focus</option>\n        <option value=\"rhythm\">Rhythm Focus</option>\n        <option value=\"spectral\">Spectral Focus</option>\n      </select>\n    </div>\n    \n    <div class=\"setting-row\">\n      <label for=\"sensitivitySlider\">Detection Sensitivity:</label>\n      <input type=\"range\" id=\"sensitivitySlider\" min=\"20\" max=\"90\" value=\"60\" step=\"5\">\n      <span id=\"sensitivityValue\" class=\"setting-value\">60%</span>\n    </div>\n    \n    <div class=\"setting-row\">\n      <label for=\"patternStrictnessSlider\">Pattern Strictness:</label>\n      <input type=\"range\" id=\"patternStrictnessSlider\" min=\"20\" max=\"90\" value=\"60\" step=\"5\">\n      <span id=\"patternStrictnessValue\" class=\"setting-value\">60%</span>\n    </div>\n    \n    <div class=\"setting-row\">\n      <label for=\"coolingPeriodSlider\">Cooldown Period:</label>\n      <input type=\"range\" id=\"coolingPeriodSlider\" min=\"1000\" max=\"5000\" value=\"2500\" step=\"100\">\n      <span id=\"coolingPeriodValue\" class=\"setting-value\">2500ms</span>\n    </div>\n    \n    <div class=\"setting-row\">\n      <label for=\"noiseThresholdSlider\">Noise Threshold:</label>\n      <input type=\"range\" id=\"noiseThresholdSlider\" min=\"5\" max=\"30\" value=\"15\" step=\"1\">\n      <span id=\"noiseThresholdValue\" class=\"setting-value\">15%</span>\n    </div>\n  </div>\n\n  <div class=\"container\">\n    <h2>3. Start Detection</h2>\n    \n    <div class=\"counter\">\n      <span id=\"counterValue\">0</span>\n    </div>\n    \n    <div>\n      <button id=\"startBtn\" class=\"btn\" disabled>Start Detection</button>\n      <button id=\"stopBtn\" class=\"btn\" disabled>Stop</button>\n      <button id=\"resetBtn\" class=\"btn\">Reset Counter</button>\n    </div>\n    \n    <div class=\"visualizer\">\n      <canvas id=\"detectionCanvas\"></canvas>\n      <div id=\"detectionIndicator\" class=\"match-indicator\"></div>\n      <div id=\"lockoutIndicator\" class=\"lockout-indicator\" style=\"display: none;\">COOLDOWN</div>\n    </div>\n    \n    <div class=\"status\" id=\"detectionStatus\">Record a pattern first, then start detection.</div>\n    \n    <div id=\"patternMatchSummary\" class=\"detected-pattern\" style=\"display: none;\">\n      <div id=\"matchHeaderText\">Pattern detected! Confidence: 0%</div>\n      <div class=\"pattern-sequence\" id=\"patternSequenceDisplay\">\n        <!-- Pattern sequence items will be added here -->\n      </div>\n      <span class=\"details-toggle\" id=\"matchDetailsToggle\">Show details</span>\n      <div class=\"details-content\" id=\"matchDetailsContent\">\n        <div class=\"pattern-match-details\" id=\"matchDetailsContainer\">\n          <!-- Match details will be added here -->\n        </div>\n      </div>\n    </div>\n    \n    <div class=\"tabs\">\n      <div class=\"tab active\" data-tab=\"patternViz\">Pattern Viewer</div>\n      <div class=\"tab\" data-tab=\"detection\">Detection Live View</div>\n      <div class=\"tab\" data-tab=\"features\">Feature Analysis</div>\n      <div class=\"tab\" data-tab=\"logs\">Debug Logs</div>\n    </div>\n    \n    <div id=\"patternVizTab\" class=\"tab-content active\">\n      <h3>Pattern Segmentation</h3>\n      <div class=\"segment-timeline\">\n        <canvas id=\"timelineCanvas\"></canvas>\n        <div id=\"currentSegmentMarker\" class=\"segment-marker\"></div>\n      </div>\n      \n      <div class=\"progress-tracker\" id=\"sequenceProgressTracker\">\n        <!-- Progress segments will be added here -->\n      </div>\n      \n      <div class=\"phoneme-display\" id=\"sequenceDisplay\">\n        <div class=\"feature-label\">Phonetic Pattern:</div>\n        <!-- Phoneme sequence will be added here -->\n      </div>\n      \n      <div id=\"segmentsContainer\" class=\"segments-container\">\n        <!-- Segments will be generated dynamically -->\n      </div>\n      \n      <div class=\"status\" id=\"patternStats\">\n        No pattern analyzed yet\n      </div>\n    </div>\n    \n    <div id=\"detectionTab\" class=\"tab-content\">\n      <h3>Real-time Detection</h3>\n      \n      <div class=\"confidence-meter\">\n        <div id=\"sequenceConfidence\" class=\"confidence-segment\" style=\"width: 0%; background-color: #3498db;\">0%</div>\n      </div>\n      \n      <div class=\"phoneme-display\" id=\"livePhonemeDisplay\">\n        <div class=\"feature-label\">Live Phoneme Detection:</div>\n        <!-- Live phoneme items will be added here -->\n      </div>\n      \n      <div class=\"detection-log\" id=\"detectionLog\">\n        <div>Start detection to see log...</div>\n      </div>\n    </div>\n    \n    <div id=\"featuresTab\" class=\"tab-content\">\n      <h3>Audio Feature Analysis</h3>\n      \n      <div class=\"feature-visualizer\">\n        <canvas id=\"melCanvas\"></canvas>\n      </div>\n      \n      <div class=\"normalizer-control\">\n        <span class=\"normalizer-label\">Normalization:</span>\n        <select id=\"normalizationSelect\">\n          <option value=\"running\">Running (Auto)</option>\n          <option value=\"fixed\">Fixed (Manual)</option>\n          <option value=\"none\">None (Raw Values)</option>\n        </select>\n      </div>\n      \n      <div class=\"feature-container\" id=\"featureContainer\">\n        <!-- Feature items will be inserted here -->\n      </div>\n      \n      <div class=\"feature-chart\">\n        <canvas id=\"featureHistoryCanvas\"></canvas>\n      </div>\n      \n      <div class=\"phoneme-display\" id=\"phonemeDisplay\">\n        <div class=\"feature-label\">Estimated Phonetic Units:</div>\n        <!-- Phoneme items will be inserted here -->\n      </div>\n    </div>\n    \n    <div id=\"logsTab\" class=\"tab-content\">\n      <button id=\"clearLogsBtn\" class=\"btn\">Clear Logs</button>\n      <div class=\"debug-container\" id=\"debugLog\"></div>\n    </div>\n  </div>\n\n  <script>\n    // DOM Elements\n    const elements = {\n      recordingCanvas: document.getElementById('recordingCanvas'),\n      detectionCanvas: document.getElementById('detectionCanvas'),\n      timelineCanvas: document.getElementById('timelineCanvas'),\n      melCanvas: document.getElementById('melCanvas'),\n      featureHistoryCanvas: document.getElementById('featureHistoryCanvas'),\n      recordBtn: document.getElementById('recordBtn'),\n      playLastBtn: document.getElementById('playLastBtn'),\n      clearBtn: document.getElementById('clearBtn'),\n      startBtn: document.getElementById('startBtn'),\n      stopBtn: document.getElementById('stopBtn'),\n      resetBtn: document.getElementById('resetBtn'),\n      clearLogsBtn: document.getElementById('clearLogsBtn'),\n      recordingStatus: document.getElementById('recordingStatus'),\n      detectionStatus: document.getElementById('detectionStatus'),\n      patternMatchSummary: document.getElementById('patternMatchSummary'),\n      matchHeaderText: document.getElementById('matchHeaderText'),\n      patternSequenceDisplay: document.getElementById('patternSequenceDisplay'),\n      matchDetailsToggle: document.getElementById('matchDetailsToggle'),\n      matchDetailsContent: document.getElementById('matchDetailsContent'),\n      matchDetailsContainer: document.getElementById('matchDetailsContainer'),\n      lockoutIndicator: document.getElementById('lockoutIndicator'),\n      sampleCount: document.getElementById('sampleCount'),\n      counterValue: document.getElementById('counterValue'),\n      patternStats: document.getElementById('patternStats'),\n      debugLog: document.getElementById('debugLog'),\n      detectionLog: document.getElementById('detectionLog'),\n      segmentsContainer: document.getElementById('segmentsContainer'),\n      featureContainer: document.getElementById('featureContainer'),\n      phonemeDisplay: document.getElementById('phonemeDisplay'),\n      livePhonemeDisplay: document.getElementById('livePhonemeDisplay'),\n      sequenceDisplay: document.getElementById('sequenceDisplay'),\n      sequenceProgressTracker: document.getElementById('sequenceProgressTracker'),\n      sequenceConfidence: document.getElementById('sequenceConfidence'),\n      recordingIndicator: document.getElementById('recordingIndicator'),\n      detectionIndicator: document.getElementById('detectionIndicator'),\n      currentSegmentMarker: document.getElementById('currentSegmentMarker'),\n      detectionMethodSelect: document.getElementById('detectionMethodSelect'),\n      sensitivitySlider: document.getElementById('sensitivitySlider'),\n      sensitivityValue: document.getElementById('sensitivityValue'),\n      patternStrictnessSlider: document.getElementById('patternStrictnessSlider'),\n      patternStrictnessValue: document.getElementById('patternStrictnessValue'),\n      coolingPeriodSlider: document.getElementById('coolingPeriodSlider'),\n      coolingPeriodValue: document.getElementById('coolingPeriodValue'),\n      noiseThresholdSlider: document.getElementById('noiseThresholdSlider'),\n      noiseThresholdValue: document.getElementById('noiseThresholdValue'),\n      normalizationSelect: document.getElementById('normalizationSelect'),\n      tabs: document.querySelectorAll('.tab'),\n      tabContents: document.querySelectorAll('.tab-content')\n    };\n\n    // Audio Context and Stream\n    let audioContext = null;\n    let mediaStream = null;\n    let analyzer = null;\n    let recorderNode = null;\n\n    // Configuration\n    const config = {\n      bufferSize: 1024,\n      fftSize: 2048,\n      melBands: 26, // Number of Mel frequency bands\n      sampleRate: 44100,\n      minRecordDuration: 500,\n      maxRecordDuration: 10000,\n      detectionSensitivity: 0.6,\n      patternStrictness: 0.6,\n      coolingPeriod: 2500,\n      lockoutPeriod: 3000, // Extended cooldown after detection\n      noiseThreshold: 0.15,\n      bufferMaxLength: 5000,\n      detectionMethod: 'markov',\n      windowSize: 10,\n      featureHistorySize: 100,\n      normalizationMode: 'running',\n      showDebugInfo: true,\n      adaptiveThreshold: true,\n      phonemeDetection: true,\n      matchingMethod: 'fuzzy',\n      baseConfidenceThreshold: 0.5,\n      // Markov model transition matrix - probabilities of moving between states\n      // Format: [fromState][toState]\n      transitionMatrix: [\n        [0.7, 0.3, 0.0, 0.0], // From state 0\n        [0.05, 0.7, 0.25, 0.0], // From state 1\n        [0.0, 0.05, 0.7, 0.25], // From state 2\n        [0.1, 0.0, 0.05, 0.85]  // From state 3\n      ],\n      // Require consecutive state progression\n      requireSequentialProgress: true,\n      // Number of frames required to stay in a state before it's \"confirmed\"\n      minFramesInState: 3,\n      // How many consecutive detected phonemes to display\n      livePhonemeDisplayCount: 10,\n      // Minimum confidence to register a detection\n      minDetectionConfidence: 0.6\n    };\n\n    // State Variables\n    const state = {\n      isRecording: false,\n      isDetecting: false,\n      inLockoutPeriod: false,\n      recordStartTime: 0,\n      samples: [],\n      detectionBuffer: [],\n      lastDetectionTime: 0,\n      ambientNoiseLevel: 0.01,\n      counter: 0,\n      patternSegments: [],\n      patternPhonemeSequence: [],\n      detectedPhonemeSequence: [],\n      sequenceProgress: [],\n      segmentCanvases: {},\n      currentConfidence: 0,\n      lastMatchConfidence: 0,\n      lastMatchDetails: null,\n      stateDistribution: [1, 0, 0, 0], // Start in first state\n      stateHistory: [], // Track which states we've been in\n      framesSinceStateChange: 0,\n      currentState: 0,\n      detectedPhonemes: [],\n      currentFeatures: {},\n      featureHistory: {}, // Store feature history for charts\n      confidenceHistory: [],\n      adaptiveThreshold: 0.5,\n      noiseEstimation: [],\n      livePhonemeBuffer: [],\n      lastPhonemeTime: 0,\n      // Custom running normalization values per feature\n      normalization: {\n        min: {},\n        max: {},\n        reset: function() {\n          this.min = {};\n          this.max = {};\n        }\n      }\n    };\n\n    // Initialize canvas contexts\n    const contexts = {\n      recording: elements.recordingCanvas.getContext('2d'),\n      detection: elements.detectionCanvas.getContext('2d'),\n      timeline: elements.timelineCanvas.getContext('2d'),\n      mel: elements.melCanvas.getContext('2d'),\n      featureHistory: elements.featureHistoryCanvas.getContext('2d')\n    };\n\n    // Initialization & Setup\n    document.addEventListener('DOMContentLoaded', () => {\n      setupEventListeners();\n      updateSettingsUI();\n      resizeCanvases();\n      createFeatureDisplay();\n      initializeFeatureHistory();\n      logDebug('Enhanced Thikr Detector initialized');\n    });\n\n    function setupEventListeners() {\n      elements.recordBtn.addEventListener('mousedown', startRecording);\n      elements.recordBtn.addEventListener('touchstart', startRecording, { passive: false });\n      elements.recordBtn.addEventListener('mouseup', stopRecording);\n      elements.recordBtn.addEventListener('touchend', stopRecording);\n      elements.recordBtn.addEventListener('mouseleave', stopRecording);\n      elements.playLastBtn.addEventListener('click', playLastSample);\n      elements.clearBtn.addEventListener('click', clearSamples);\n      elements.startBtn.addEventListener('click', startDetection);\n      elements.stopBtn.addEventListener('click', stopDetection);\n      elements.resetBtn.addEventListener('click', resetCounter);\n      elements.clearLogsBtn.addEventListener('click', clearLogs);\n      elements.matchDetailsToggle.addEventListener('click', toggleMatchDetails);\n\n      elements.detectionMethodSelect.addEventListener('change', () => {\n        config.detectionMethod = elements.detectionMethodSelect.value;\n        logDebug(`Detection method changed to: ${config.detectionMethod}`);\n      });\n\n      elements.sensitivitySlider.addEventListener('input', () => {\n        config.detectionSensitivity = parseInt(elements.sensitivitySlider.value) / 100;\n        elements.sensitivityValue.textContent = `${elements.sensitivitySlider.value}%`;\n      });\n\n      elements.patternStrictnessSlider.addEventListener('input', () => {\n        config.patternStrictness = parseInt(elements.patternStrictnessSlider.value) / 100;\n        elements.patternStrictnessValue.textContent = `${elements.patternStrictnessSlider.value}%`;\n      });\n\n      elements.coolingPeriodSlider.addEventListener('input', () => {\n        config.coolingPeriod = parseInt(elements.coolingPeriodSlider.value);\n        elements.coolingPeriodValue.textContent = `${config.coolingPeriod}ms`;\n      });\n\n      elements.noiseThresholdSlider.addEventListener('input', () => {\n        config.noiseThreshold = parseInt(elements.noiseThresholdSlider.value) / 100;\n        elements.noiseThresholdValue.textContent = `${elements.noiseThresholdSlider.value}%`;\n      });\n\n      elements.normalizationSelect.addEventListener('change', () => {\n        config.normalizationMode = elements.normalizationSelect.value;\n        if (config.normalizationMode === 'running') {\n          state.normalization.reset();\n        }\n        logDebug(`Normalization mode changed to: ${config.normalizationMode}`);\n      });\n\n      elements.tabs.forEach(tab => {\n        tab.addEventListener('click', () => {\n          const tabId = tab.getAttribute('data-tab');\n          elements.tabs.forEach(t => t.classList.remove('active'));\n          tab.classList.add('active');\n          elements.tabContents.forEach(content => content.classList.remove('active'));\n          document.getElementById(`${tabId}Tab`).classList.add('active');\n        });\n      });\n\n      window.addEventListener('resize', resizeCanvases);\n    }\n\n    function toggleMatchDetails() {\n      const content = elements.matchDetailsContent;\n      if (content.style.display === 'block') {\n        content.style.display = 'none';\n        elements.matchDetailsToggle.textContent = 'Show details';\n      } else {\n        content.style.display = 'block';\n        elements.matchDetailsToggle.textContent = 'Hide details';\n      }\n    }\n\n    function updateSettingsUI() {\n      elements.sensitivityValue.textContent = `${elements.sensitivitySlider.value}%`;\n      elements.patternStrictnessValue.textContent = `${elements.patternStrictnessSlider.value}%`;\n      elements.coolingPeriodValue.textContent = `${config.coolingPeriod}ms`;\n      elements.noiseThresholdValue.textContent = `${parseInt(config.noiseThreshold * 100)}%`;\n    }\n\nfunction resizeCanvases() {\n  Object.entries(contexts).forEach(([key, ctx]) => {\n    const canvas = ctx.canvas;\n    canvas.width = canvas.parentElement.clientWidth;\n    canvas.height = canvas.parentElement.clientHeight;\n  });\n  if (state.segmentCanvases) {\n    Object.values(state.segmentCanvases).forEach(ctx => {\n      const canvas = ctx.canvas;\n      canvas.width = canvas.parentElement.clientWidth;\n      canvas.height = canvas.parentElement.clientHeight;\n    });\n  }\n  if (state.patternSegments && state.patternSegments.length) {\n    drawSegmentedTimeline();\n  }\n  // Only draw feature history if initialized\n  if (state.featureHistory && state.featureHistory.timestamps) {\n    drawFeatureHistory();\n  }\n}\n\nfunction initializeFeatureHistory() {\n  state.featureHistory = {\n    timestamps: [],\n    amplitude: [],\n    zcr: [],\n    formants: [],\n    vowelness: [],\n    consonantness: []\n  };\n}\n    async function setupAudio() {\n      if (audioContext) return true;\n      try {\n        audioContext = new (window.AudioContext || window.webkitAudioContext)();\n        config.sampleRate = audioContext.sampleRate;\n        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        analyzer = audioContext.createAnalyser();\n        analyzer.fftSize = config.fftSize;\n        \n        // Initialize Mel filter bank for better speech feature extraction\n        initMelFilterBank();\n        \n        logDebug('Audio system initialized successfully');\n        return true;\n      } catch (error) {\n        logError('Failed to initialize audio system: ' + error.message);\n        elements.recordingStatus.textContent = 'Microphone access error. Please check permissions.';\n        return false;\n      }\n    }\n\n    // Mel-frequency filterbank setup\n    let melFilterBank = [];\n    function initMelFilterBank() {\n      melFilterBank = [];\n      const nyquist = config.sampleRate / 2;\n      const melLow = 300; // Hz\n      const melHigh = 8000; // Hz\n      const numBands = config.melBands;\n      const fftBins = analyzer.frequencyBinCount;\n      \n      // Convert Hz to Mel\n      const hzToMel = hz => 2595 * Math.log10(1 + hz / 700);\n      // Convert Mel to Hz\n      const melToHz = mel => 700 * (Math.pow(10, mel / 2595) - 1);\n      \n      const melLowMel = hzToMel(melLow);\n      const melHighMel = hzToMel(melHigh);\n      const melStep = (melHighMel - melLowMel) / (numBands + 1);\n      \n      // Create mel filter bank\n      for (let i = 0; i < numBands; i++) {\n        const filter = new Array(fftBins).fill(0);\n        const centerMel = melLowMel + (i + 1) * melStep;\n        const centerHz = melToHz(centerMel);\n        const centerBin = Math.floor(centerHz / nyquist * fftBins);\n        \n        const leftMel = melLowMel + i * melStep;\n        const rightMel = melLowMel + (i + 2) * melStep;\n        const leftHz = melToHz(leftMel);\n        const rightHz = melToHz(rightMel);\n        const leftBin = Math.floor(leftHz / nyquist * fftBins);\n        const rightBin = Math.min(Math.floor(rightHz / nyquist * fftBins), fftBins - 1);\n        \n        // Triangular filter\n        for (let j = leftBin; j <= rightBin; j++) {\n          if (j <= centerBin) {\n            filter[j] = (j - leftBin) / (centerBin - leftBin);\n          } else {\n            filter[j] = 1 - (j - centerBin) / (rightBin - centerBin);\n          }\n        }\n        melFilterBank.push(filter);\n      }\n      \n      logDebug(`Initialized ${numBands} Mel filter banks`);\n    }\n\n    // Feature extraction for speech sounds\n    function extractMelFeatures(frequencyData) {\n      if (!melFilterBank.length) return new Array(config.melBands).fill(0);\n      \n      const melFeatures = [];\n      \n      // Apply each filter and compute energy\n      for (let i = 0; i < melFilterBank.length; i++) {\n        let sum = 0;\n        for (let j = 0; j < frequencyData.length; j++) {\n          sum += frequencyData[j] * melFilterBank[i][j];\n        }\n        // Log energy (avoid log(0))\n        melFeatures.push(Math.log(1 + sum));\n      }\n      \n      return melFeatures;\n    }\n\n    // Recording Functions\n    async function startRecording() {\n      if (state.isRecording) return;\n      const success = await setupAudio();\n      if (!success) return;\n      \n      state.isRecording = true;\n      state.recordStartTime = Date.now();\n      elements.recordBtn.textContent = 'Recording... (Release when done)';\n      elements.recordBtn.classList.add('recording');\n      elements.recordingStatus.textContent = 'Recording thikr pattern... Please recite clearly.';\n      \n      const newSample = {\n        audio: [],\n        features: [],\n        envelope: [],\n        spectrogram: [],\n        melFeatures: [],\n        phonemeFeatures: [],\n        timestamps: [],\n        duration: 0\n      };\n      state.samples.push(newSample);\n      \n      recorderNode = audioContext.createScriptProcessor(config.bufferSize, 1, 1);\n      recorderNode.onaudioprocess = (event) => {\n        if (!state.isRecording) return;\n        const inputData = event.inputBuffer.getChannelData(0);\n        const dataCopy = new Float32Array(inputData.length);\n        dataCopy.set(inputData);\n        const features = extractFeatures(dataCopy);\n        \n        newSample.audio.push(dataCopy);\n        newSample.features.push(features);\n        newSample.envelope.push(features.amplitude);\n        newSample.spectrogram.push(features.frequencyData);\n        newSample.melFeatures.push(features.melFeatures);\n        newSample.phonemeFeatures.push(features.phonemeFeatures);\n        newSample.timestamps.push(Date.now() - state.recordStartTime);\n        \n        drawWaveform(contexts.recording, dataCopy);\n        drawMelSpectrogram(contexts.mel, features.melFeatures);\n        \n        elements.recordingIndicator.style.width = '100%';\n        if (Date.now() - state.recordStartTime > config.maxRecordDuration) {\n          stopRecording();\n        }\n      };\n      \n      const micSource = audioContext.createMediaStreamSource(mediaStream);\n      micSource.connect(analyzer);\n      micSource.connect(recorderNode);\n      recorderNode.connect(audioContext.destination);\n      \n      logDebug('Started recording thikr pattern');\n    }\n\n    function stopRecording() {\n      if (!state.isRecording) return;\n      state.isRecording = false;\n      const duration = Date.now() - state.recordStartTime;\n      const currentSample = state.samples[state.samples.length - 1];\n      currentSample.duration = duration;\n      \n      if (duration < config.minRecordDuration) {\n        elements.recordingStatus.textContent = 'Recording too short. Please try again.';\n        state.samples.pop();\n      } else {\n        elements.recordingStatus.textContent = 'Processing recorded pattern...';\n        processPatterns();\n        elements.playLastBtn.disabled = false;\n        elements.recordingStatus.textContent = `Recorded thikr pattern (${(duration/1000).toFixed(1)}s). Ready for detection.`;\n      }\n      \n      elements.recordBtn.textContent = 'Record Thikr (Press & Hold)';\n      elements.recordBtn.classList.remove('recording');\n      elements.sampleCount.textContent = `Samples: ${state.samples.length}`;\n      elements.recordingIndicator.style.width = '0%';\n      \n      if (recorderNode) {\n        recorderNode.disconnect();\n        recorderNode = null;\n      }\n      \n      if (state.samples.length > 0) {\n        elements.startBtn.disabled = false;\n      }\n      \n      logDebug(`Finished recording. Duration: ${(duration/1000).toFixed(2)}s`);\n      \n      // Estimate ambient noise from silent parts of the recording\n      estimateAmbientNoise(currentSample);\n    }\n\n    function estimateAmbientNoise(sample) {\n      // Find sections with lowest amplitude (likely silence)\n      const envelopes = sample.envelope;\n      if (!envelopes || envelopes.length < 10) return;\n      \n      // Sort by amplitude and take bottom 10%\n      const sortedAmplitudes = [...envelopes].sort((a, b) => a - b);\n      const silenceThreshold = sortedAmplitudes[Math.floor(sortedAmplitudes.length * 0.1)];\n      \n      const silenceAmplitudes = envelopes.filter(amp => amp <= silenceThreshold);\n      if (silenceAmplitudes.length > 0) {\n        const avgNoise = average(silenceAmplitudes);\n        // Update noise estimation\n        state.noiseEstimation.push(avgNoise);\n        // Compute average noise level from all recordings\n        state.ambientNoiseLevel = average(state.noiseEstimation);\n        logDebug(`Estimated ambient noise level: ${state.ambientNoiseLevel.toFixed(5)}`);\n      }\n    }\n\n    function playLastSample() {\n      if (state.samples.length === 0) return;\n      const lastSample = state.samples[state.samples.length - 1];\n      try {\n        const source = audioContext.createBufferSource();\n        const totalLength = lastSample.audio.reduce((sum, chunk) => sum + chunk.length, 0);\n        const audioBuffer = audioContext.createBuffer(1, totalLength, audioContext.sampleRate);\n        const channelData = audioBuffer.getChannelData(0);\n        let offset = 0;\n        for (let i = 0; i < lastSample.audio.length; i++) {\n          channelData.set(lastSample.audio[i], offset);\n          offset += lastSample.audio[i].length;\n        }\n        source.buffer = audioBuffer;\n        source.connect(audioContext.destination);\n        source.start();\n        elements.recordingStatus.textContent = 'Playing back recorded pattern...';\n        source.onended = () => {\n          elements.recordingStatus.textContent = 'Playback complete.';\n        };\n        logDebug('Playing back last sample');\n      } catch (error) {\n        logError('Error playing sample: ' + error.message);\n        elements.recordingStatus.textContent = 'Error during playback.';\n      }\n    }\n\n    function clearSamples() {\n      state.samples = [];\n      state.patternSegments = [];\n      state.patternPhonemeSequence = [];\n      state.detectedPhonemeSequence = [];\n      state.noiseEstimation = [];\n      elements.sampleCount.textContent = 'No samples recorded';\n      elements.recordingStatus.textContent = 'All samples cleared. Record a new pattern.';\n      elements.playLastBtn.disabled = true;\n      elements.startBtn.disabled = true;\n      \n      Object.values(contexts).forEach(ctx => {\n        ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n      });\n      \n      elements.segmentsContainer.innerHTML = '';\n      elements.patternStats.textContent = 'No pattern analyzed yet';\n      elements.sequenceDisplay.innerHTML = '<div class=\"feature-label\">Phonetic Pattern:</div>';\n      elements.sequenceProgressTracker.innerHTML = '';\n      elements.phonemeDisplay.innerHTML = '<div class=\"feature-label\">Estimated Phonetic Units:</div>';\n      elements.livePhonemeDisplay.innerHTML = '<div class=\"feature-label\">Live Phoneme Detection:</div>';\n      \n      logDebug('All samples cleared');\n    }\n\n    // Enhanced Feature Extraction\n    function extractFeatures(audioData) {\n      // Basic amplitude analysis\n      let sum = 0;\n      for (let i = 0; i < audioData.length; i++) {\n        sum += Math.abs(audioData[i]);\n      }\n      const amplitude = sum / audioData.length;\n      \n      // Frequency domain analysis\n      const frequencyData = new Uint8Array(analyzer.frequencyBinCount);\n      analyzer.getByteFrequencyData(frequencyData);\n      \n      // Mel-frequency features\n      const melFeatures = extractMelFeatures(frequencyData);\n      \n      // Zero crossing rate\n      let zeroCrossings = 0;\n      for (let i = 1; i < audioData.length; i++) {\n        if ((audioData[i - 1] >= 0 && audioData[i] < 0) || \n            (audioData[i - 1] < 0 && audioData[i] >= 0)) {\n          zeroCrossings++;\n        }\n      }\n      const zcr = zeroCrossings / audioData.length;\n      \n      // Extract phonetic features\n      const phonemeFeatures = extractPhonemeFeatures(audioData, frequencyData, melFeatures, zcr);\n      \n      // Find spectral centroids and formants for vowel detection\n      const spectralCentroid = calculateSpectralCentroid(frequencyData);\n      \n      // Calculate energy in specific frequency bands for consonant detection\n      const bandEnergies = calculateBandEnergies(frequencyData);\n      \n      // Estimate formants (peaks in the spectrum)\n      const formants = findFormants(melFeatures);\n      \n      // Calculate phoneme type probabilities\n      const phonemeTypes = classifyPhoneme(amplitude, zcr, formants, spectralCentroid, bandEnergies);\n      \n      // Update feature history for visualization\n      updateFeatureHistory({\n        timestamp: Date.now(),\n        amplitude,\n        zcr,\n        formants,\n        vowelness: phonemeTypes.vowel,\n        consonantness: phonemeTypes.consonant\n      });\n      \n      // Determine the most likely phoneme\n      if (amplitude > state.ambientNoiseLevel * 3) {\n        const now = Date.now();\n        if (now - state.lastPhonemeTime > 100) { // Limit phoneme detection rate\n          state.lastPhonemeTime = now;\n          const phonemeType = getPhonemeType(phonemeTypes);\n          updateLivePhonemeDisplay(phonemeType);\n        }\n      }\n      \n      // Update current features for the UI\n      state.currentFeatures = {\n        amplitude,\n        zcr,\n        spectralCentroid,\n        formants,\n        melFeatures,\n        phonemeTypes\n      };\n      \n      updateFeatureDisplay();\n      \n      return {\n        amplitude,\n        frequencyData: Array.from(frequencyData).slice(0, 100),\n        melFeatures,\n        phonemeFeatures,\n        phonemeTypes,\n        zcr,\n        spectralCentroid,\n        bandEnergies,\n        formants,\n        timestamp: Date.now()\n      };\n    }\n\n    function updateFeatureHistory(features) {\n      const maxHistory = config.featureHistorySize;\n      \n      // Add new features to history\n      state.featureHistory.timestamps.push(features.timestamp);\n      state.featureHistory.amplitude.push(features.amplitude);\n      state.featureHistory.zcr.push(features.zcr);\n      \n      if (features.formants && features.formants.length > 0) {\n        state.featureHistory.formants.push(features.formants[0]);\n      } else {\n        state.featureHistory.formants.push(0);\n      }\n      \n      state.featureHistory.vowelness.push(features.vowelness);\n      state.featureHistory.consonantness.push(features.consonantness);\n      \n      // Trim history if too long\n      if (state.featureHistory.timestamps.length > maxHistory) {\n        state.featureHistory.timestamps.shift();\n        state.featureHistory.amplitude.shift();\n        state.featureHistory.zcr.shift();\n        state.featureHistory.formants.shift();\n        state.featureHistory.vowelness.shift();\n        state.featureHistory.consonantness.shift();\n      }\n      \n      // Update normalization values\n      if (config.normalizationMode === 'running') {\n        updateNormalizationRanges(features);\n      }\n      \n      // Update feature chart\n      if (elements.tabContents[2].classList.contains('active')) {\n        drawFeatureHistory();\n      }\n    }\n\n    function updateNormalizationRanges(features) {\n      const keys = ['amplitude', 'zcr', 'vowelness', 'consonantness'];\n      \n      keys.forEach(key => {\n        const value = features[key];\n        if (value !== undefined) {\n          if (state.normalization.min[key] === undefined || value < state.normalization.min[key]) {\n            state.normalization.min[key] = value;\n          }\n          if (state.normalization.max[key] === undefined || value > state.normalization.max[key]) {\n            state.normalization.max[key] = value;\n          }\n        }\n      });\n      \n      // Special case for formants\n      if (features.formants && features.formants.length > 0) {\n        const formant = features.formants[0];\n        if (state.normalization.min.formant === undefined || formant < state.normalization.min.formant) {\n          state.normalization.min.formant = formant;\n        }\n        if (state.normalization.max.formant === undefined || formant > state.normalization.max.formant) {\n          state.normalization.max.formant = formant;\n        }\n      }\n    }\n\n    function normalizeValue(value, key) {\n      if (config.normalizationMode === 'none') return value;\n      \n      let min, max;\n      \n      if (key === 'formants' && value) {\n        key = 'formant';\n      }\n      \n      if (config.normalizationMode === 'running') {\n        min = state.normalization.min[key] || 0;\n        max = state.normalization.max[key] || 1;\n      } else {\n        // Fixed normalization ranges\n        switch (key) {\n          case 'amplitude':\n            min = 0;\n            max = 0.2;\n            break;\n          case 'zcr':\n            min = 0;\n            max = 0.2;\n            break;\n          case 'formant':\n            min = 0;\n            max = 20;\n            break;\n          case 'vowelness':\n          case 'consonantness':\n            min = 0;\n            max = 1;\n            break;\n          default:\n            min = 0;\n            max = 1;\n        }\n      }\n      \n      // Prevent division by zero\n      if (max === min) return 0.5;\n      \n      return Math.max(0, Math.min(1, (value - min) / (max - min)));\n    }\n\n    function drawFeatureHistory() {\n  const canvas = elements.featureHistoryCanvas;\n  const ctx = contexts.featureHistory;\n  const width = canvas.width;\n  const height = canvas.height;\n  \n  ctx.clearRect(0, 0, width, height);\n  \n  // Guard clause: ensure timestamps is an array and has data\n  if (!state.featureHistory || \n      !Array.isArray(state.featureHistory.timestamps) || \n      state.featureHistory.timestamps.length < 2) {\n    ctx.font = '12px sans-serif';\n    ctx.fillStyle = '#666';\n    ctx.fillText('No feature data yet', width / 2 - 50, height / 2);\n    return;\n  }\n  \n  // Draw grid lines\n  ctx.strokeStyle = '#ddd';\n  ctx.lineWidth = 1;\n  \n  // Horizontal grid lines\n  for (let i = 0; i <= 4; i++) {\n    const y = height * (i / 4);\n    ctx.beginPath();\n    ctx.moveTo(0, y);\n    ctx.lineTo(width, y);\n    ctx.stroke();\n  }\n  \n  // Draw feature lines\n  const drawFeature = (data, color, key) => {\n    if (!Array.isArray(data) || data.length < 2) return;\n    \n    ctx.strokeStyle = color;\n    ctx.lineWidth = 2;\n    ctx.beginPath();\n    \n    for (let i = 0; i < data.length; i++) {\n      const x = (i / (data.length - 1)) * width;\n      const normalizedValue = normalizeValue(data[i], key);\n      const y = height - (normalizedValue * height);\n      \n      if (i === 0) {\n        ctx.moveTo(x, y);\n      } else {\n        ctx.lineTo(x, y);\n      }\n    }\n    \n    ctx.stroke();\n  };\n  \n  drawFeature(state.featureHistory.amplitude, '#e74c3c', 'amplitude');\n  drawFeature(state.featureHistory.zcr, '#3498db', 'zcr');\n  drawFeature(state.featureHistory.formants, '#2ecc71', 'formants');\n  drawFeature(state.featureHistory.vowelness, '#9b59b6', 'vowelness');\n  drawFeature(state.featureHistory.consonantness, '#f39c12', 'consonantness');\n  \n  // Draw labels\n  ctx.font = '10px sans-serif';\n  ctx.fillStyle = '#e74c3c';\n  ctx.fillText('Amplitude', 5, 12);\n  ctx.fillStyle = '#3498db';\n  ctx.fillText('ZCR', 70, 12);\n  ctx.fillStyle = '#2ecc71';\n  ctx.fillText('Formant', 110, 12);\n  ctx.fillStyle = '#9b59b6';\n  ctx.fillText('Vowel', 160, 12);\n  ctx.fillStyle = '#f39c12';\n  ctx.fillText('Consonant', 200, 12);\n}\n\n    // Phonetic feature extraction\n    function extractPhonemeFeatures(audioData, frequencyData, melFeatures, zcr) {\n      // 1. Analyze if frame likely contains a vowel or consonant\n      const isHighAmplitude = average(audioData.map(Math.abs)) > 0.1;\n      const isHighZcr = zcr > 0.1;\n      const spectralTilt = calculateSpectralTilt(frequencyData);\n      \n      // 2. Detect sound category\n      let soundType = \"silence\";\n      if (isHighAmplitude) {\n        if (isHighZcr) {\n          soundType = \"fricative\"; // consonants like 's', 'f', 'sh'\n        } else if (spectralTilt < 0.3) {\n          soundType = \"plosive\";  // consonants like 'p', 't', 'k'\n        } else {\n          soundType = \"vowel\";    // vowels like 'a', 'e', 'i'\n        }\n      }\n      \n      // 3. Calculate formant-like measures for vowel classification\n      const formantEstimates = findFormants(melFeatures);\n      \n      // 4. Extract consonant features\n      const burstEnergy = isHighZcr ? normalizeArray(frequencyData.slice(50, 100)) : [];\n      \n      // 5. Energy contour\n      const energyContour = calculateEnergyContour(audioData);\n      \n      // Return phonetic features\n      return {\n        soundType,\n        formantEstimates,\n        isVoiced: !isHighZcr && isHighAmplitude,\n        spectralTilt,\n        burstEnergy,\n        energyContour,\n        zcr\n      };\n    }\n\n    function classifyPhoneme(amplitude, zcr, formants, spectralCentroid, bandEnergies) {\n      // Calculate probability for each phoneme type\n      \n      // Check if it's silence based on amplitude\n      const isSilence = amplitude < state.ambientNoiseLevel * 3;\n      \n      if (isSilence) {\n        return {\n          vowel: 0.1,\n          consonant: 0.1,\n          silence: 0.8\n        };\n      }\n      \n      // Vowel probability based on ZCR and formants\n      let vowelProb = 0;\n      if (zcr < 0.1) {\n        vowelProb += 0.5;\n        \n        // Additional boost based on formant pattern (typical for vowels)\n        if (formants.length >= 2) {\n          vowelProb += 0.3;\n        }\n      }\n      \n      // Consonant probability based on ZCR and spectral characteristics\n      let consonantProb = 0;\n      if (zcr > 0.1) {\n        consonantProb += 0.5;\n        \n        // Fricatives have high spectral centroid\n        if (spectralCentroid > 50) {\n          consonantProb += 0.3;\n        }\n      }\n      \n      // Normalize probabilities\n      const total = vowelProb + consonantProb + 0.1; // Add small constant for silence\n      vowelProb = vowelProb / total;\n      consonantProb = consonantProb / total;\n      const silenceProb = 0.1 / total;\n      \n      return {\n        vowel: vowelProb,\n        consonant: consonantProb,\n        silence: silenceProb\n      };\n    }\n\n    function getPhonemeType(phonemeTypes) {\n      // Determine the most likely phoneme type\n      if (phonemeTypes.silence > 0.5) {\n        return \"silence\";\n      } else if (phonemeTypes.vowel > phonemeTypes.consonant) {\n        return \"vowel\";\n      } else {\n        return \"consonant\";\n      }\n    }\n\n    function updateLivePhonemeDisplay(phonemeType) {\n      // Add new phoneme to buffer\n      state.livePhonemeBuffer.push(phonemeType);\n      \n      // Trim buffer to max size\n      if (state.livePhonemeBuffer.length > config.livePhonemeDisplayCount) {\n        state.livePhonemeBuffer.shift();\n      }\n      \n      // Update display\n      const display = elements.livePhonemeDisplay;\n      \n      // Clear existing items (except the label)\n      while (display.childNodes.length > 1) {\n        display.removeChild(display.lastChild);\n      }\n      \n      // Add phoneme items\n      state.livePhonemeBuffer.forEach(type => {\n        const phonemeElem = document.createElement('div');\n        phonemeElem.className = `phoneme-item ${type}`;\n        phonemeElem.textContent = type.charAt(0).toUpperCase();\n        display.appendChild(phonemeElem);\n      });\n    }\n\n    function calculateSpectralTilt(frequencyData) {\n      // Simple spectral tilt - ratio of high to low frequency energy\n      const lowIdx = Math.floor(frequencyData.length * 0.1);\n      const highIdx = Math.floor(frequencyData.length * 0.7);\n      \n      const lowSum = sum(frequencyData.slice(0, lowIdx));\n      const highSum = sum(frequencyData.slice(lowIdx, highIdx));\n      \n      return highSum / (lowSum + 1e-10);\n    }\n\n    function calculateEnergyContour(audioData) {\n      // Divide frame into sub-frames and calculate energy contour\n      const windowSize = 32;\n      const numSubframes = Math.floor(audioData.length / windowSize);\n      const energies = [];\n      \n      for (let i = 0; i < numSubframes; i++) {\n        const start = i * windowSize;\n        const end = start + windowSize;\n        const subframe = audioData.slice(start, end);\n        const energy = subframe.reduce((sum, val) => sum + val * val, 0) / windowSize;\n        energies.push(energy);\n      }\n      \n      return energies;\n    }\n\n    function calculateSpectralCentroid(frequencyData) {\n      let numerator = 0;\n      let denominator = 0;\n      \n      for (let i = 0; i < frequencyData.length; i++) {\n        numerator += i * frequencyData[i];\n        denominator += frequencyData[i];\n      }\n      \n      return denominator === 0 ? 0 : numerator / denominator;\n    }\n\n    function calculateBandEnergies(frequencyData) {\n      // Calculate energy in different frequency bands\n      const bands = [\n        [0, 500],      // Low frequencies\n        [500, 1000],   // Mid-low\n        [1000, 2000],  // Mid\n        [2000, 4000],  // Mid-high\n        [4000, 8000]   // High frequencies\n      ];\n      \n      const bandEnergies = [];\n      const sr = config.sampleRate;\n      const binWidth = sr / (2 * frequencyData.length);\n      \n      for (const [min, max] of bands) {\n        const minBin = Math.floor(min / binWidth);\n        const maxBin = Math.min(Math.floor(max / binWidth), frequencyData.length - 1);\n        \n        let energy = 0;\n        for (let i = minBin; i <= maxBin; i++) {\n          energy += frequencyData[i];\n        }\n        \n        bandEnergies.push(energy / (maxBin - minBin + 1));\n      }\n      \n      return bandEnergies;\n    }\n\n    function findFormants(melFeatures) {\n      // Find peaks in the Mel spectrum\n      const formants = [];\n      \n      for (let i = 1; i < melFeatures.length - 1; i++) {\n        if (melFeatures[i] > melFeatures[i-1] && \n            melFeatures[i] > melFeatures[i+1] &&\n            melFeatures[i] > 0.5 * Math.max(...melFeatures)) {\n          formants.push({\n            index: i,\n            value: melFeatures[i]\n          });\n        }\n      }\n      \n      return formants.slice(0, 3).map(f => f.index);\n    }\n\n    // Function to create visual feature display\n    function createFeatureDisplay() {\n      const container = elements.featureContainer;\n      container.innerHTML = '';\n      \n      // Create feature items for the most important features\n      const features = [\n        { id: 'amplitude', label: 'Amplitude' },\n        { id: 'zcr', label: 'Zero Cross Rate' },\n        { id: 'spectralCentroid', label: 'Spectral Centroid' },\n        { id: 'formant1', label: 'Formant 1' },\n        { id: 'formant2', label: 'Formant 2' },\n        { id: 'vowelness', label: 'Vowel-like' },\n        { id: 'consonantness', label: 'Consonant-like' },\n        { id: 'energy', label: 'Energy' }\n      ];\n      \n      features.forEach(feature => {\n        const featureItem = document.createElement('div');\n        featureItem.className = 'feature-item';\n        featureItem.innerHTML = `\n          <div class=\"feature-label\">${feature.label}</div>\n          <div class=\"feature-value\">\n            <div id=\"${feature.id}_bar\" class=\"feature-bar\" style=\"width: 0%\"></div>\n          </div>\n          <div id=\"${feature.id}_value\">0.0</div>\n        `;\n        container.appendChild(featureItem);\n      });\n    }\n\n    function updateFeatureDisplay() {\n      const features = state.currentFeatures;\n      if (!features) return;\n      \n      // Update amplitude\n      const amplitudeBar = document.getElementById('amplitude_bar');\n      const amplitudeValue = document.getElementById('amplitude_value');\n      if (amplitudeBar && amplitudeValue) {\n        const normAmplitude = normalizeValue(features.amplitude, 'amplitude') * 100;\n        amplitudeBar.style.width = `${normAmplitude}%`;\n        amplitudeValue.textContent = features.amplitude.toFixed(3);\n      }\n      \n      // Update zero-crossing rate\n      const zcrBar = document.getElementById('zcr_bar');\n      const zcrValue = document.getElementById('zcr_value');\n      if (zcrBar && zcrValue) {\n        const normZcr = normalizeValue(features.zcr, 'zcr') * 100;\n        zcrBar.style.width = `${normZcr}%`;\n        zcrValue.textContent = features.zcr.toFixed(3);\n      }\n      \n      // Update spectral centroid\n      const centroidBar = document.getElementById('spectralCentroid_bar');\n      const centroidValue = document.getElementById('spectralCentroid_value');\n      if (centroidBar && centroidValue) {\n        const normCentroid = normalizeValue(features.spectralCentroid / 100, 'spectralCentroid') * 100;\n        centroidBar.style.width = `${normCentroid}%`;\n        centroidValue.textContent = features.spectralCentroid.toFixed(1);\n      }\n      \n      // Update formants\n      const formants = features.formants || [];\n      const formant1Bar = document.getElementById('formant1_bar');\n      const formant1Value = document.getElementById('formant1_value');\n      if (formant1Bar && formant1Value && formants.length > 0) {\n        const f1 = normalizeValue(formants[0], 'formants') * 100;\n        formant1Bar.style.width = `${f1}%`;\n        formant1Value.textContent = formants[0];\n      }\n      \n      const formant2Bar = document.getElementById('formant2_bar');\n      const formant2Value = document.getElementById('formant2_value');\n      if (formant2Bar && formant2Value && formants.length > 1) {\n        const f2 = normalizeValue(formants[1], 'formants') * 100;\n        formant2Bar.style.width = `${f2}%`;\n        formant2Value.textContent = formants[1];\n      }\n      \n      // Update vowel/consonant likelihood\n      const vowelBar = document.getElementById('vowelness_bar');\n      const vowelValue = document.getElementById('vowelness_value');\n      if (vowelBar && vowelValue && features.phonemeTypes) {\n        const vowelness = features.phonemeTypes.vowel * 100;\n        vowelBar.style.width = `${vowelness}%`;\n        vowelValue.textContent = vowelness.toFixed(1) + '%';\n      }\n      \n      const consonantBar = document.getElementById('consonantness_bar');\n      const consonantValue = document.getElementById('consonantness_value');\n      if (consonantBar && consonantValue && features.phonemeTypes) {\n        const consonantness = features.phonemeTypes.consonant * 100;\n        consonantBar.style.width = `${consonantness}%`;\n        consonantValue.textContent = consonantness.toFixed(1) + '%';\n      }\n      \n      // Update energy\n      const energyBar = document.getElementById('energy_bar');\n      const energyValue = document.getElementById('energy_value');\n      if (energyBar && energyValue) {\n        const energy = features.amplitude > state.ambientNoiseLevel * 5 ? \n                      features.amplitude * 100 : \n                      0;\n        energyBar.style.width = `${Math.min(energy, 100)}%`;\n        energyValue.textContent = energy.toFixed(1);\n      }\n    }\n\n    // Pattern Processing\n    function processPatterns() {\n      if (state.samples.length === 0) return;\n      logDebug('Processing recorded patterns...');\n      \n      // Use the longest sample as the primary pattern template\n      const patternSample = state.samples.reduce((longest, current) => {\n        return (current.duration > longest.duration) ? current : longest;\n      }, state.samples[0]);\n      \n      // Segment the pattern using energy-based approach\n      state.patternSegments = segmentPattern(patternSample);\n      \n      // Extract the phonetic pattern sequence\n      extractPhoneticPatternSequence();\n      \n      // Create visualizations\n      createSegmentVisualizations();\n      createSequenceDisplay();\n      createProgressTracker();\n      drawSegmentedTimeline();\n      updatePatternStats();\n      \n      logDebug('Pattern processed and segmented successfully');\n    }\n\n    function segmentPattern(sample) {\n      // Calculate amplitude envelope\n      const envelope = sample.envelope;\n      const smoothedEnvelope = smoothArray(envelope, 3);\n      const normalizedEnvelope = normalizeArray(smoothedEnvelope);\n      \n      // Identify segments using energy peaks and transitions\n      const segmentBoundaries = findSegmentBoundaries(normalizedEnvelope, 4);\n      \n      // Create segments from boundaries\n      const segments = [];\n      for (let i = 0; i < segmentBoundaries.length - 1; i++) {\n        const startIdx = segmentBoundaries[i];\n        const endIdx = segmentBoundaries[i + 1];\n        \n        // Create segment data\n        const segmentData = {\n          name: `segment_${i}`,\n          audio: sample.audio.slice(startIdx, endIdx),\n          envelope: sample.envelope.slice(startIdx, endIdx),\n          spectrogram: sample.spectrogram.slice(startIdx, endIdx),\n          melFeatures: sample.melFeatures.slice(startIdx, endIdx),\n          phonemeFeatures: sample.phonemeFeatures.slice(startIdx, endIdx),\n          features: sample.features.slice(startIdx, endIdx),\n          startTime: sample.timestamps[startIdx] || 0,\n          endTime: sample.timestamps[endIdx - 1] || sample.duration,\n          index: i\n        };\n        \n        // Extract distinctive features for this segment\n        segmentData.fingerprint = createSegmentFingerprint(segmentData);\n        \n        // Mark if this segment appears to be silence\n        const avgAmplitude = average(segmentData.envelope);\n        segmentData.isSilence = avgAmplitude < state.ambientNoiseLevel * 2;\n        \n        // Classify segment by phoneme type\n        if (segmentData.isSilence) {\n          segmentData.phonemeType = 'silence';\n        } else if (segmentData.fingerprint.phonemeFeatures.vowelRatio > 0.6) {\n          segmentData.phonemeType = 'vowel';\n        } else if (segmentData.fingerprint.phonemeFeatures.consonantRatio > 0.4) {\n          segmentData.phonemeType = 'consonant';\n        } else {\n          segmentData.phonemeType = 'mixed';\n        }\n        \n        segments.push(segmentData);\n      }\n      \n      return segments;\n    }\n\n    function extractPhoneticPatternSequence() {\n      state.patternPhonemeSequence = [];\n      \n      state.patternSegments.forEach(segment => {\n        // Skip very short segments\n        if (!segment || segment.audio.length < 3) return;\n        \n        state.patternPhonemeSequence.push({\n          type: segment.phonemeType,\n          index: segment.index,\n          duration: segment.endTime - segment.startTime\n        });\n      });\n      \n      logDebug(`Extracted phonetic pattern: ${state.patternPhonemeSequence.map(p => p.type).join('-')}`);\n    }\n\n    function createSequenceDisplay() {\n      const display = elements.sequenceDisplay;\n      \n      // Clear existing items (except the label)\n      while (display.childNodes.length > 1) {\n        display.removeChild(display.lastChild);\n      }\n      \n      // Add phoneme sequence\n      state.patternPhonemeSequence.forEach((phoneme, index) => {\n        const phonemeElem = document.createElement('div');\n        phonemeElem.className = `phoneme-item ${phoneme.type}`;\n        phonemeElem.textContent = phoneme.type.charAt(0).toUpperCase();\n        phonemeElem.dataset.index = index;\n        phonemeElem.title = `Segment ${index + 1}: ${phoneme.type}`;\n        display.appendChild(phonemeElem);\n      });\n    }\n\n    function createProgressTracker() {\n      const tracker = elements.sequenceProgressTracker;\n      tracker.innerHTML = '';\n      \n      if (!state.patternPhonemeSequence.length) return;\n      \n      // Create a segment for each part of the pattern\n      state.patternPhonemeSequence.forEach((segment, index) => {\n        const segmentElem = document.createElement('div');\n        segmentElem.className = 'progress-segment waiting';\n        segmentElem.style.width = `${100 / state.patternPhonemeSequence.length}%`;\n        segmentElem.textContent = (index + 1);\n        segmentElem.id = `progress_segment_${index}`;\n        tracker.appendChild(segmentElem);\n      });\n    }\n\n    function updateProgressTracker(stateDistribution) {\n      const maxStateIdx = stateDistribution.indexOf(Math.max(...stateDistribution));\n      \n      // Update each segment's status\n      state.patternPhonemeSequence.forEach((_, index) => {\n        const segmentElem = document.getElementById(`progress_segment_${index}`);\n        if (!segmentElem) return;\n        \n        if (index < maxStateIdx) {\n          segmentElem.className = 'progress-segment completed';\n        } else if (index === maxStateIdx) {\n          segmentElem.className = 'progress-segment in-progress';\n        } else {\n          segmentElem.className = 'progress-segment waiting';\n        }\n      });\n    }\n\n    function findSegmentBoundaries(envelope, targetSegments) {\n      const minSegmentLength = 5; // Minimum frames per segment\n      \n      // 1. Find local maxima (energy peaks)\n      const peaks = findPeaks(envelope, 0.2);\n      \n      // 2. Find local minima (potential boundaries)\n      const valleys = findValleys(envelope, 0.3);\n      \n      // 3. Combine peaks and valleys for initial segmentation\n      let boundaries = [0, ...valleys, envelope.length - 1];\n      boundaries = boundaries.filter((v, i, a) => a.indexOf(v) === i).sort((a, b) => a - b);\n      \n      // 4. If we have too many segments, merge the smallest ones\n      while (boundaries.length > targetSegments + 1) {\n        let smallestSegmentSize = Infinity;\n        let smallestSegmentIndex = -1;\n        \n        for (let i = 0; i < boundaries.length - 1; i++) {\n          const segmentSize = boundaries[i + 1] - boundaries[i];\n          if (segmentSize < smallestSegmentSize) {\n            smallestSegmentSize = segmentSize;\n            smallestSegmentIndex = i;\n          }\n        }\n        \n        if (smallestSegmentIndex !== -1) {\n          boundaries.splice(smallestSegmentIndex + 1, 1);\n        } else {\n          break; // Safety check\n        }\n      }\n      \n      // 5. If we have too few segments, add more boundaries\n      while (boundaries.length < targetSegments + 1) {\n        let largestSegmentSize = 0;\n        let largestSegmentIndex = -1;\n        \n        for (let i = 0; i < boundaries.length - 1; i++) {\n          const segmentSize = boundaries[i + 1] - boundaries[i];\n          if (segmentSize > largestSegmentSize) {\n            largestSegmentSize = segmentSize;\n            largestSegmentIndex = i;\n          }\n        }\n        \n        if (largestSegmentIndex !== -1 && largestSegmentSize > minSegmentLength * 2) {\n          const newBoundary = Math.floor(boundaries[largestSegmentIndex] + largestSegmentSize / 2);\n          boundaries.splice(largestSegmentIndex + 1, 0, newBoundary);\n          boundaries.sort((a, b) => a - b);\n        } else {\n          break; // Can't add more meaningful segments\n        }\n      }\n      \n      return boundaries;\n    }\n\n    function createSegmentFingerprint(segment) {\n      // 1. Energy envelope pattern\n      const normalizedEnvelope = normalizeArray(segment.envelope);\n      \n      // 2. Spectral features\n      const melFeatures = segment.melFeatures.map(mel => [...mel]);\n      const avgMelFeatures = average2DArray(melFeatures);\n      \n      // 3. Phonetic features\n      const phonemeFeatures = extractPhoneticProfile(segment);\n      \n      // 4. Rhythm features\n      const rhythmFeatures = extractRhythmFeatures(segment);\n      \n      return {\n        envelope: normalizedEnvelope,\n        melFeatures: avgMelFeatures,\n        phonemeFeatures: phonemeFeatures,\n        rhythmFeatures: rhythmFeatures,\n        duration: segment.endTime - segment.startTime\n      };\n    }\n\n    function extractPhoneticProfile(segment) {\n      const phonemeFeatures = segment.phonemeFeatures;\n      if (!phonemeFeatures || phonemeFeatures.length === 0) {\n        return { vowelRatio: 0, consonantRatio: 0, silenceRatio: 1 };\n      }\n      \n      // Count frame types\n      let vowelFrames = 0;\n      let consonantFrames = 0;\n      let silenceFrames = 0;\n      \n      phonemeFeatures.forEach(frame => {\n        if (!frame || !frame.soundType) {\n          silenceFrames++;\n          return;\n        }\n        \n        switch (frame.soundType) {\n          case 'vowel':\n            vowelFrames++;\n            break;\n          case 'fricative':\n          case 'plosive':\n            consonantFrames++;\n            break;\n          case 'silence':\n          default:\n            silenceFrames++;\n        }\n      });\n      \n      const total = vowelFrames + consonantFrames + silenceFrames;\n      return {\n        vowelRatio: total ? vowelFrames / total : 0,\n        consonantRatio: total ? consonantFrames / total : 0,\n        silenceRatio: total ? silenceFrames / total : 1,\n        formantProfile: extractFormantProfile(segment)\n      };\n    }\n\n    function extractFormantProfile(segment) {\n      // Extract dominant formant patterns\n      const formants = [];\n      segment.phonemeFeatures.forEach(frame => {\n        if (frame && frame.formantEstimates) {\n          formants.push(frame.formantEstimates);\n        }\n      });\n      \n      // Find most common formant patterns\n      const formantProfile = [];\n      if (formants.length > 0) {\n        const avgFormants = formants.reduce((acc, curr) => {\n          curr.forEach((f, i) => {\n            acc[i] = (acc[i] || 0) + f;\n          });\n          return acc;\n        }, []).map(f => f / formants.length);\n        \n        formantProfile.push(...avgFormants);\n      }\n      \n      return formantProfile;\n    }\n\n    function extractRhythmFeatures(segment) {\n      const envelope = segment.envelope;\n      const peaks = findPeaks(envelope, 0.2);\n      \n      // Calculate intervals between peaks\n      const intervals = [];\n      for (let i = 1; i < peaks.length; i++) {\n        intervals.push(peaks[i] - peaks[i - 1]);\n      }\n      \n      // Calculate rhythm features\n      const avgInterval = average(intervals) || 0;\n      const stdInterval = standardDeviation(intervals) || 0;\n      const rhythmRegularity = 1 - Math.min(1, stdInterval / (avgInterval + 0.001));\n      \n      return {\n        peakCount: peaks.length,\n        peakPositions: peaks.map(p => p / envelope.length),\n        avgInterval,\n        rhythmRegularity\n      };\n    }\n\n    // Visualization Functions\n    function createSegmentVisualizations() {\n      if (!state.patternSegments || state.patternSegments.length === 0) return;\n      \n      elements.segmentsContainer.innerHTML = '';\n      state.segmentCanvases = {};\n      \n      const segmentDisplay = document.createElement('div');\n      segmentDisplay.className = 'segment-display';\n      \n      state.patternSegments.forEach((segment, index) => {\n        const segmentDiv = document.createElement('div');\n        segmentDiv.className = 'segment';\n        segmentDiv.id = `segment_${index}_container`;\n        \n        const labelDiv = document.createElement('div');\n        labelDiv.className = 'segment-title';\n        labelDiv.textContent = `Segment ${index + 1}`;\n        \n        const canvas = document.createElement('canvas');\n        canvas.id = `segment_${index}_canvas`;\n        canvas.width = 150;\n        canvas.height = 100;\n        \n        const indicator = document.createElement('div');\n        indicator.className = 'match-indicator';\n        indicator.id = `segment_${index}_indicator`;\n        \n        const methodBadge = document.createElement('div');\n        methodBadge.className = 'method-badge';\n        \n        // Color-code by phoneme type\n        switch (segment.phonemeType) {\n          case 'vowel':\n            methodBadge.style.backgroundColor = '#e74c3c';\n            methodBadge.textContent = 'Vowel';\n            break;\n          case 'consonant':\n            methodBadge.style.backgroundColor = '#3498db';\n            methodBadge.textContent = 'Consonant';\n            break;\n          case 'silence':\n            methodBadge.style.backgroundColor = '#95a5a6';\n            methodBadge.textContent = 'Silence';\n            break;\n          default:\n            methodBadge.textContent = 'Mixed';\n        }\n        \n        segmentDiv.appendChild(labelDiv);\n        segmentDiv.appendChild(canvas);\n        segmentDiv.appendChild(indicator);\n        segmentDiv.appendChild(methodBadge);\n        segmentDisplay.appendChild(segmentDiv);\n        \n        const ctx = canvas.getContext('2d');\n        state.segmentCanvases[`segment_${index}`] = ctx;\n        \n        drawSegmentWaveform(ctx, segment);\n      });\n      \n      elements.segmentsContainer.appendChild(segmentDisplay);\n    }\n\n    function drawSegmentedTimeline() {\n      if (!state.patternSegments || state.patternSegments.length === 0) return;\n      \n      const canvas = elements.timelineCanvas;\n      const ctx = contexts.timeline;\n      const width = canvas.width;\n      const height = canvas.height;\n      \n      ctx.clearRect(0, 0, width, height);\n      \n      const totalDuration = state.patternSegments[state.patternSegments.length - 1].endTime;\n      \n      state.patternSegments.forEach((segment, index) => {\n        const startX = (segment.startTime / totalDuration) * width;\n        const segWidth = ((segment.endTime - segment.startTime) / totalDuration) * width;\n        \n        // Set color based on phoneme type\n        switch (segment.phonemeType) {\n          case 'vowel':\n            ctx.fillStyle = '#e74c3c';\n            break;\n          case 'consonant':\n            ctx.fillStyle = '#3498db';\n            break;\n          case 'silence':\n            ctx.fillStyle = '#95a5a6';\n            break;\n          default:\n            ctx.fillStyle = '#2c3e50';\n        }\n        \n        // Highlight current segment during detection\n        if (state.stateDistribution && \n            state.stateDistribution[index] > 0.5 && \n            state.isDetecting) {\n          ctx.fillStyle = '#f39c12';\n        }\n        \n        ctx.fillRect(startX, 0, segWidth, height);\n        \n        ctx.fillStyle = '#fff';\n        ctx.font = '10px sans-serif';\n        ctx.textAlign = 'center';\n        ctx.fillText(`${index + 1}`, startX + segWidth / 2, height / 2 + 4);\n      });\n    }\n\n    function drawWaveform(context, audioData) {\n      const canvas = context.canvas;\n      const width = canvas.width;\n      const height = canvas.height;\n      \n      context.clearRect(0, 0, width, height);\n      \n      // Draw center line\n      context.beginPath();\n      context.strokeStyle = '#e0e0e0';\n      context.lineWidth = 1;\n      context.moveTo(0, height / 2);\n      context.lineTo(width, height / 2);\n      context.stroke();\n      \n      // Draw waveform\n      context.beginPath();\n      context.strokeStyle = '#3498db';\n      context.lineWidth = 2;\n      \n      const sliceWidth = width / audioData.length;\n      let x = 0;\n      \n      for (let i = 0; i < audioData.length; i++) {\n        const y = (audioData[i] * height / 2) + (height / 2);\n        \n        if (i === 0) {\n          context.moveTo(x, y);\n        } else {\n          context.lineTo(x, y);\n        }\n        \n        x += sliceWidth;\n      }\n      \n      context.stroke();\n      \n      // Mark areas above noise threshold with subtle highlight\n      if (state.ambientNoiseLevel > 0) {\n        context.fillStyle = 'rgba(46, 204, 113, 0.1)';\n        let inSignal = false;\n        let startX = 0;\n        \n        for (let i = 0; i < audioData.length; i++) {\n          const amplitude = Math.abs(audioData[i]);\n          const x = i * sliceWidth;\n          \n          if (amplitude > state.ambientNoiseLevel * 5) {\n            if (!inSignal) {\n              inSignal = true;\n              startX = x;\n            }\n          } else if (inSignal) {\n            inSignal = false;\n            context.fillRect(startX, 0, x - startX, height);\n          }\n        }\n        \n        if (inSignal) {\n          context.fillRect(startX, 0, width - startX, height);\n        }\n      }\n    }\n\n    function drawMelSpectrogram(context, melFeatures) {\n      if (!melFeatures || melFeatures.length === 0) return;\n      \n      const canvas = context.canvas;\n      const width = canvas.width;\n      const height = canvas.height;\n      \n      context.clearRect(0, 0, width, height);\n      \n      // Normalize mel features\n      const flatMel = melFeatures.flat();\n      const maxVal = Math.max(...flatMel);\n      const normalizedMel = melFeatures.map(band => band / maxVal);\n      \n      // Draw mel spectrogram\n      const barWidth = width / normalizedMel.length;\n      const barHeightMultiplier = height / normalizedMel.length;\n      \n      for (let i = 0; i < normalizedMel.length; i++) {\n        const value = normalizedMel[i];\n        const barHeight = value * barHeightMultiplier;\n        \n        // Choose color based on frequency band (blue for low, red for high)\n        const hue = 240 - (i / normalizedMel.length) * 180;\n        context.fillStyle = `hsl(${hue}, 70%, 50%)`;\n        \n        context.fillRect(i * barWidth, height - barHeight, barWidth, barHeight);\n      }\n    }\n\n    function drawSegmentWaveform(context, segment) {\n      // Combine audio chunks\n      const totalSamples = segment.audio.reduce((sum, chunk) => sum + chunk.length, 0);\n      const combinedAudio = new Float32Array(totalSamples);\n      let offset = 0;\n      \n      for (let i = 0; i < segment.audio.length; i++) {\n        combinedAudio.set(segment.audio[i], offset);\n        offset += segment.audio[i].length;\n      }\n      \n      // Draw waveform\n      drawWaveform(context, combinedAudio);\n      \n      // Overlay envelope\n      if (segment.envelope && segment.envelope.length > 0) {\n        const canvas = context.canvas;\n        const width = canvas.width;\n        const height = canvas.height;\n        \n        const normalizedEnvelope = normalizeArray(segment.envelope);\n        \n        context.beginPath();\n        context.strokeStyle = 'rgba(231, 76, 60, 0.7)';\n        context.lineWidth = 1.5;\n        \n        const sliceWidth = width / normalizedEnvelope.length;\n        let x = 0;\n        \n        for (let i = 0; i < normalizedEnvelope.length; i++) {\n          const y = height - (normalizedEnvelope[i] * height * 0.8);\n          \n          if (i === 0) {\n            context.moveTo(x, y);\n          } else {\n            context.lineTo(x, y);\n          }\n          \n          x += sliceWidth;\n        }\n        \n        context.stroke();\n      }\n      \n      // Mark detected rhythm peaks\n      if (segment.fingerprint && segment.fingerprint.rhythmFeatures) {\n        const canvas = context.canvas;\n        const width = canvas.width;\n        const height = canvas.height;\n        \n        const peakPositions = segment.fingerprint.rhythmFeatures.peakPositions;\n        \n        if (peakPositions && peakPositions.length) {\n          context.fillStyle = 'rgba(231, 76, 60, 0.8)';\n          \n          peakPositions.forEach(pos => {\n            const x = pos * width;\n            context.beginPath();\n            context.arc(x, height / 2, 3, 0, Math.PI * 2);\n            context.fill();\n          });\n        }\n      }\n    }\n\n    function updatePatternStats() {\n      if (!state.patternSegments || state.patternSegments.length === 0) {\n        elements.patternStats.textContent = 'No pattern analyzed yet';\n        return;\n      }\n      \n      const totalDuration = state.patternSegments[state.patternSegments.length - 1].endTime / 1000;\n      const segmentCount = state.patternSegments.length;\n      \n      // Count phoneme types\n      let vowelCount = 0;\n      let consonantCount = 0;\n      let silenceCount = 0;\n      \n      state.patternSegments.forEach(segment => {\n        switch (segment.phonemeType) {\n          case 'vowel':\n            vowelCount++;\n            break;\n          case 'consonant':\n            consonantCount++;\n            break;\n          case 'silence':\n            silenceCount++;\n            break;\n        }\n      });\n      \n      // Calculate pattern complexity\n      const complexity = calculatePatternComplexity(state.patternSegments);\n      \n      // Determine recommended settings based on pattern analysis\n      const recommendedSettings = getRecommendedSettings(complexity);\n      \n      let statsHtml = `\n        <strong>Pattern Analysis</strong><br>\n        Duration: ${totalDuration.toFixed(2)}s | ${segmentCount} segments | \n        Phoneme Types: ${vowelCount} vowels, ${consonantCount} consonants, ${silenceCount} silence<br>\n        Pattern complexity: <span class=\"feature-badge\">${complexity.level}</span>\n        <br><br>\n        <strong>Phoneme Sequence:</strong> ${state.patternPhonemeSequence.map(p => p.type.charAt(0).toUpperCase()).join('-')}\n        <br><br>\n        <strong>Segment Breakdown:</strong><br>\n      `;\n      \n      state.patternSegments.forEach((segment, i) => {\n        const duration = (segment.endTime - segment.startTime) / 1000;\n        \n        statsHtml += `\n          Segment ${i + 1}: ${duration.toFixed(2)}s | \n          Type: ${segment.phonemeType} |\n          ${segment.fingerprint.rhythmFeatures.peakCount || 0} peaks\n          <br>\n        `;\n      });\n      \n      statsHtml += `<br><strong>Recommended Settings:</strong><br>\n        Sensitivity: ${recommendedSettings.sensitivity}% | \n        Pattern Strictness: ${recommendedSettings.strictness}% |\n        Cooldown: ${recommendedSettings.cooldown}ms\n      `;\n      \n      elements.patternStats.innerHTML = statsHtml;\n      \n      // Apply recommended settings\n      elements.sensitivitySlider.value = recommendedSettings.sensitivity;\n      elements.patternStrictnessSlider.value = recommendedSettings.strictness;\n      elements.coolingPeriodSlider.value = recommendedSettings.cooldown;\n      elements.noiseThresholdSlider.value = recommendedSettings.noiseThreshold;\n      updateSettingsUI();\n      \n      config.detectionSensitivity = recommendedSettings.sensitivity / 100;\n      config.patternStrictness = recommendedSettings.strictness / 100;\n      config.coolingPeriod = recommendedSettings.cooldown;\n      config.noiseThreshold = recommendedSettings.noiseThreshold / 100;\n    }\n\n    function calculatePatternComplexity(segments) {\n      if (!segments || segments.length === 0) {\n        return { score: 0, level: 'Unknown' };\n      }\n      \n      // Factors that contribute to complexity:\n      // 1. Number of segments\n      // 2. Variation in segment durations\n      // 3. Phonetic diversity\n      // 4. Rhythm complexity\n      \n      const segmentCount = segments.length;\n      const durations = segments.map(s => s.endTime - s.startTime);\n      const durationVariability = standardDeviation(durations) / average(durations);\n      \n      // Count distinct phoneme types and their distribution\n      const phonemeTypes = {};\n      segments.forEach(segment => {\n        phonemeTypes[segment.phonemeType] = (phonemeTypes[segment.phonemeType] || 0) + 1;\n      });\n      \n      const phoneticDiversity = Object.keys(phonemeTypes).length / 3; // Normalized by max types (3)\n      \n      // Calculate phonetic alternation (transitions between different types)\n      let alternationCount = 0;\n      for (let i = 1; i < segments.length; i++) {\n        if (segments[i].phonemeType !== segments[i-1].phonemeType) {\n          alternationCount++;\n        }\n      }\n      const alternationRatio = segments.length > 1 ? alternationCount / (segments.length - 1) : 0;\n      \n      // Assess rhythm complexity\n      let rhythmComplexity = 0;\n      segments.forEach(segment => {\n        if (segment.fingerprint && segment.fingerprint.rhythmFeatures) {\n          const rhythm = segment.fingerprint.rhythmFeatures;\n          rhythmComplexity += (1 - rhythm.rhythmRegularity);\n        }\n      });\n      rhythmComplexity /= segments.length;\n      \n      // Calculate overall complexity score\n      const score = \n        (segmentCount * 0.2) + \n        (durationVariability * 2) + \n        (phoneticDiversity * 1.5) +\n        (alternationRatio * 2) +\n        (rhythmComplexity * 3);\n      \n      // Determine complexity level\n      let level = 'Simple';\n      if (score > 5) level = 'Complex';\n      else if (score > 3) level = 'Moderate';\n      \n      return { score, level, phoneticDiversity, alternationRatio };\n    }\n\n    function getRecommendedSettings(complexity) {\n      // Default settings\n      const settings = {\n        sensitivity: 60,\n        strictness: 60,\n        cooldown: config.coolingPeriod,\n        noiseThreshold: 15\n      };\n      \n      // Adjust based on complexity\n      switch (complexity.level) {\n        case 'Simple':\n          // For simple patterns, we can be more strict\n          settings.sensitivity = 70;\n          settings.strictness = 70;\n          settings.cooldown = 2000;\n          break;\n        case 'Moderate':\n          // Balanced settings\n          settings.sensitivity = 60;\n          settings.strictness = 60;\n          settings.cooldown = 2500;\n          break;\n        case 'Complex':\n          // For complex patterns, we need to be more forgiving\n          settings.sensitivity = 50;\n          settings.strictness = 50;\n          settings.cooldown = 3000;\n          break;\n      }\n      \n      // Adjust noise threshold based on ambient noise\n      if (state.ambientNoiseLevel > 0.05) {\n        settings.noiseThreshold = Math.min(30, Math.floor(state.ambientNoiseLevel * 300));\n      }\n      \n      return settings;\n    }\n\n    // Detection Functions\n    async function startDetection() {\n      if (state.isDetecting) return;\n      \n      if (!state.patternSegments || state.patternSegments.length === 0) {\n        elements.detectionStatus.textContent = 'No pattern available. Please record a sample first.';\n        return;\n      }\n      \n      const success = await setupAudio();\n      if (!success) {\n        elements.detectionStatus.textContent = 'Failed to access microphone. Please check permissions.';\n        return;\n      }\n      \n      state.isDetecting = true;\n      state.inLockoutPeriod = false;\n      state.detectionBuffer = [];\n      state.lastDetectionTime = 0;\n      state.confidenceHistory = [];\n      state.stateDistribution = new Array(state.patternSegments.length).fill(0);\n      state.stateDistribution[0] = 1.0; // Start in first state\n      state.stateHistory = [];\n      state.framesSinceStateChange = 0;\n      state.currentState = 0;\n      state.currentConfidence = 0;\n      state.detectedPhonemeSequence = [];\n      \n      // Update adaptive threshold based on current settings\n      state.adaptiveThreshold = config.detectionSensitivity * 0.8;\n      \n      elements.startBtn.disabled = true;\n      elements.stopBtn.disabled = false;\n      elements.detectionStatus.textContent = 'Listening for thikr pattern...';\n      elements.lockoutIndicator.style.display = 'none';\n      \n      recorderNode = audioContext.createScriptProcessor(config.bufferSize, 1, 1);\n      recorderNode.onaudioprocess = (event) => {\n        if (!state.isDetecting) return;\n        \n        const inputData = event.inputBuffer.getChannelData(0);\n        const dataCopy = new Float32Array(inputData.length);\n        dataCopy.set(inputData);\n        \n        const features = extractFeatures(dataCopy);\n        state.detectionBuffer.push({ \n          audio: dataCopy, \n          features: features, \n          timestamp: Date.now() \n        });\n        \n        trimDetectionBuffer();\n        drawWaveform(contexts.detection, dataCopy);\n        drawMelSpectrogram(contexts.mel, features.melFeatures);\n        \n        if (!state.inLockoutPeriod) {\n          processDetectionBuffer();\n        }\n      };\n      \n      const micSource = audioContext.createMediaStreamSource(mediaStream);\n      micSource.connect(analyzer);\n      micSource.connect(recorderNode);\n      recorderNode.connect(audioContext.destination);\n      \n      // Reset segment indicators\n      state.patternSegments.forEach((_, index) => {\n        const indicator = document.getElementById(`segment_${index}_indicator`);\n        if (indicator) indicator.style.width = '0%';\n      });\n      \n      elements.currentSegmentMarker.style.display = 'block';\n      elements.patternMatchSummary.style.display = 'none';\n      \n      logDebug('Started detection mode');\n      logDetection('Listening for thikr pattern...');\n    }\n\n    function stopDetection() {\n      if (!state.isDetecting) return;\n      \n      state.isDetecting = false;\n      state.inLockoutPeriod = false;\n      elements.startBtn.disabled = false;\n      elements.stopBtn.disabled = true;\n      elements.detectionStatus.textContent = 'Detection stopped.';\n      elements.lockoutIndicator.style.display = 'none';\n      \n      if (recorderNode) {\n        recorderNode.disconnect();\n        recorderNode = null;\n      }\n      \n      elements.detectionIndicator.style.width = '0%';\n      elements.sequenceConfidence.style.width = '0%';\n      elements.sequenceConfidence.textContent = '0%';\n      \n      // Reset phoneme display highlights\n      const phonemeItems = elements.phonemeDisplay.querySelectorAll('.phoneme-item');\n      phonemeItems.forEach(item => item.classList.remove('active'));\n      \n      const sequenceItems = elements.sequenceDisplay.querySelectorAll('.phoneme-item');\n      sequenceItems.forEach(item => item.classList.remove('active'));\n      \n      elements.currentSegmentMarker.style.display = 'none';\n      \n      logDebug('Stopped detection mode');\n      logDetection('Detection stopped');\n    }\n\n    function trimDetectionBuffer() {\n      if (state.detectionBuffer.length === 0) return;\n      \n      const now = Date.now();\n      const maxAge = config.bufferMaxLength;\n      \n      while (state.detectionBuffer.length > 0 && now - state.detectionBuffer[0].timestamp > maxAge) {\n        state.detectionBuffer.shift();\n      }\n    }\n\n    function processDetectionBuffer() {\n      if (!state.patternSegments || state.patternSegments.length === 0 || \n          state.detectionBuffer.length < config.windowSize) return;\n      \n      const now = Date.now();\n      \n      // Skip if in lockout period\n      if (state.inLockoutPeriod) {\n        const timeSinceLast = now - state.lastDetectionTime;\n        if (timeSinceLast >= config.lockoutPeriod) {\n          state.inLockoutPeriod = false;\n          elements.lockoutIndicator.style.display = 'none';\n          logDebug('Exiting lockout period');\n        } else {\n          // Still in lockout\n          return;\n        }\n      }\n      \n      // Process the detection buffer\n      const detectionWindow = state.detectionBuffer.slice(-config.windowSize);\n      const currentFrame = detectionWindow[detectionWindow.length - 1];\n      \n      // Skip processing if amplitude is below noise threshold\n      if (currentFrame.features.amplitude < state.ambientNoiseLevel * 3) {\n        // Reset pattern confidence when quiet\n        state.currentConfidence *= 0.95; // Decay confidence during silence\n        updateConfidenceDisplay();\n        return;\n      }\n      \n      // Update state probabilities using Markov model\n      if (config.detectionMethod === 'markov') {\n        updateMarkovStateProbabilities(detectionWindow);\n      } else {\n        updateStateProbabilities(detectionWindow);\n      }\n      \n      // Check for full pattern detection\n      checkForPatternDetection();\n      \n      // Update visualizations\n      updateDetectionVisualizations();\n    }\n\n    function updateMarkovStateProbabilities(frames) {\n      const segments = state.patternSegments;\n      if (!segments || segments.length === 0) return;\n      \n      // Get current phoneme type\n      const currentFrame = frames[frames.length - 1];\n      const currentPhonemeType = getPhonemeType(currentFrame.features.phonemeTypes);\n      \n      // Increment frame counter for current state\n      state.framesSinceStateChange++;\n      \n      // Calculate match scores for each segment\n      const matchScores = segments.map(segment => {\n        return calculatePatternMatchScore(frames, segment);\n      });\n      \n      // Strong evidence for state transition\n      let transitionTriggered = false;\n      \n      // Check for phoneme type match with next state\n      if (state.currentState < segments.length - 1) {\n        const nextSegment = segments[state.currentState + 1];\n        if (currentPhonemeType === nextSegment.phonemeType &&\n            matchScores[state.currentState + 1] > config.detectionSensitivity) {\n          \n          // If we've been in current state for enough frames and have good match for next\n          if (state.framesSinceStateChange >= config.minFramesInState) {\n            // Transition to next state\n            state.currentState++;\n            state.framesSinceStateChange = 0;\n            transitionTriggered = true;\n            \n            // Record this state in history\n            state.stateHistory.push(state.currentState);\n            \n            logDebug(`Transitioned to state ${state.currentState} (${segments[state.currentState].phonemeType})`);\n          }\n        }\n      }\n      \n      // If we're at the last state for enough frames, consider looking for start of pattern again\n      if (!transitionTriggered && \n          state.currentState === segments.length - 1 && \n          state.framesSinceStateChange > config.minFramesInState * 2) {\n        \n        // Check for first segment match to potentially cycle back\n        if (currentPhonemeType === segments[0].phonemeType &&\n            matchScores[0] > config.detectionSensitivity) {\n          \n          // Reset to first state\n          state.currentState = 0;\n          state.framesSinceStateChange = 0;\n          state.stateHistory = [0];\n          \n          logDebug('Reset to first state - potential new pattern');\n        }\n      }\n      \n      // Build new state distribution based on current state focus\n      const newStateProbs = new Array(segments.length).fill(0);\n      newStateProbs[state.currentState] = 1.0;\n      \n      // Update state distribution\n      state.stateDistribution = newStateProbs;\n      \n      // Update sequence progress display\n      updateProgressTracker(state.stateDistribution);\n      \n      // Calculate overall pattern confidence\n      calculatePatternConfidence(matchScores);\n      \n      // Update segment match indicators\n      updateSegmentMatchIndicators();\n      \n      // Track detected phoneme sequence\n      if (transitionTriggered) {\n        state.detectedPhonemeSequence.push(currentPhonemeType);\n        \n        // Trim to match expected length\n        if (state.detectedPhonemeSequence.length > segments.length) {\n          state.detectedPhonemeSequence.shift();\n        }\n      }\n    }\n\n    function updateStateProbabilities(frames) {\n      const segments = state.patternSegments;\n      if (!segments || segments.length === 0) return;\n      \n      // Calculate match score for each segment\n      const matchScores = segments.map(segment => {\n        return calculatePatternMatchScore(frames, segment);\n      });\n      \n      // Convert scores to emission probabilities using soft sigmoid\n      const emissionProbs = matchScores.map(score => {\n        return fuzzyScore(score, config.detectionSensitivity);\n      });\n      \n      // Get the previous state distribution\n      const prevStateProbs = [...state.stateDistribution];\n      \n      // Calculate new state probabilities using transition matrix\n      const newStateProbs = new Array(segments.length).fill(0);\n      \n      for (let nextState = 0; nextState < segments.length; nextState++) {\n        for (let currState = 0; currState < segments.length; currState++) {\n          // Get transition probability from current to next state\n          const transProb = config.transitionMatrix[currState][nextState] || 0;\n          \n          // Calculate state probability\n          newStateProbs[nextState] += prevStateProbs[currState] * transProb * emissionProbs[nextState];\n        }\n      }\n      \n      // Normalize probabilities\n      const sum = newStateProbs.reduce((a, b) => a + b, 0);\n      if (sum > 0) {\n        for (let i = 0; i < newStateProbs.length; i++) {\n          newStateProbs[i] /= sum;\n        }\n      } else {\n        // If all probabilities are zero, reset to initial state\n        newStateProbs[0] = 1;\n        for (let i = 1; i < newStateProbs.length; i++) {\n          newStateProbs[i] = 0;\n        }\n      }\n      \n      // Update state distribution\n      state.stateDistribution = newStateProbs;\n      \n      // Update progress tracker\n      updateProgressTracker(state.stateDistribution);\n      \n      // Calculate overall pattern confidence\n      calculatePatternConfidence(matchScores);\n      \n      // Update segment match indicators\n      updateSegmentMatchIndicators();\n    }\n\n    function calculatePatternMatchScore(frames, patternSegment) {\n      // Select comparison method based on detection method setting\n      switch (config.detectionMethod) {\n        case 'phonetic':\n          return calculatePhoneticMatchScore(frames, patternSegment);\n        case 'rhythm':\n          return calculateRhythmMatchScore(frames, patternSegment);\n        case 'spectral':\n          return calculateSpectralMatchScore(frames, patternSegment);\n        case 'markov':\n        case 'adaptive':\n        default:\n          return calculateCombinedMatchScore(frames, patternSegment);\n      }\n    }\n\n    function calculateCombinedMatchScore(frames, patternSegment) {\n      // Get individual scores\n      const phoneticScore = calculatePhoneticMatchScore(frames, patternSegment);\n      const rhythmScore = calculateRhythmMatchScore(frames, patternSegment);\n      const spectralScore = calculateSpectralMatchScore(frames, patternSegment);\n      \n      // Calculate weighted average based on segment characteristics\n      let weights = [0.4, 0.3, 0.3]; // Default: phonetic, rhythm, spectral\n      \n      // Adjust weights based on segment properties\n      switch (patternSegment.phonemeType) {\n        case 'vowel':\n          // For vowel segments, emphasize phonetic features\n          weights = [0.5, 0.2, 0.3];\n          break;\n        case 'consonant':\n          // For consonant segments, balance phonetic and spectral\n          weights = [0.4, 0.2, 0.4];\n          break;\n        case 'silence':\n          // For silence, emphasize amplitude/energy\n          weights = [0.2, 0.2, 0.6];\n          break;\n      }\n      \n      // Compute weighted score\n      return (\n        phoneticScore * weights[0] +\n        rhythmScore * weights[1] +\n        spectralScore * weights[2]\n      );\n    }\n\n    function calculatePhoneticMatchScore(frames, patternSegment) {\n      // Match phoneme types\n      const currentPhoneme = frames[frames.length - 1].features.phonemeTypes;\n      \n      // For silence segments, check if current frame is quiet\n      if (patternSegment.phonemeType === 'silence') {\n        const avgAmplitude = average(frames.map(f => f.features.amplitude));\n        return avgAmplitude < state.ambientNoiseLevel * 5 ? 0.9 : 0.1;\n      }\n      \n      // For vowel segments\n      if (patternSegment.phonemeType === 'vowel') {\n        return currentPhoneme.vowel * 0.8 + (1 - currentPhoneme.consonant) * 0.2;\n      }\n      \n      // For consonant segments\n      if (patternSegment.phonemeType === 'consonant') {\n        return currentPhoneme.consonant * 0.8 + (1 - currentPhoneme.vowel) * 0.2;\n      }\n      \n      // Fallback for mixed segments\n      return Math.max(currentPhoneme.vowel, currentPhoneme.consonant);\n    }\n\n    function calculateRhythmMatchScore(frames, patternSegment) {\n      // Extract amplitude envelope from frames\n      const frameEnvelope = frames.map(frame => frame.features.amplitude);\n      \n      // Find peaks in the current audio buffer\n      const peaks = findPeaks(frameEnvelope, 0.2);\n      \n      // If no peaks or pattern doesn't have rhythm features, low match\n      if (peaks.length < 2 || \n          !patternSegment.fingerprint.rhythmFeatures || \n          !patternSegment.fingerprint.rhythmFeatures.peakPositions) {\n        return 0.2;\n      }\n      \n      // Calculate normalized peak positions (0-1 range)\n      const peakPositions = peaks.map(p => p / frameEnvelope.length);\n      \n      // Compare with pattern peak positions\n      const patternPeaks = patternSegment.fingerprint.rhythmFeatures.peakPositions;\n      \n      // If significant peak count difference, lower score\n      const peakCountRatio = Math.min(peaks.length, patternPeaks.length) / \n                            Math.max(peaks.length, patternPeaks.length);\n      \n      // Calculate DTW distance between peak patterns\n      let rhythmSimilarity = 0.5; // Default medium similarity\n      \n      if (peakPositions.length > 0 && patternPeaks.length > 0) {\n        // Dynamic time warping to compare peak patterns\n        const dtwDistance = dtw(peakPositions, patternPeaks);\n        \n        // Convert distance to similarity (0-1)\n        rhythmSimilarity = 1 - Math.min(1, dtwDistance * 2);\n      }\n      \n      // Return combined rhythm match score\n      return rhythmSimilarity * 0.7 + peakCountRatio * 0.3;\n    }\n\n    function calculateSpectralMatchScore(frames, patternSegment) {\n      // Calculate mel spectral match\n      const frameMel = frames.map(frame => frame.features.melFeatures);\n      \n      // Average mel features across frames\n      const avgMel = average2DArray(frameMel);\n      \n      // Get pattern mel features\n      const patternMel = patternSegment.fingerprint.melFeatures;\n      \n      // If missing features, return neutral score\n      if (!avgMel.length || !patternMel.length) {\n        return 0.3;\n      }\n      \n      // Calculate cosine similarity between mel features\n      const melSimilarity = cosineSimilarity(\n        avgMel.slice(0, Math.min(avgMel.length, patternMel.length)),\n        patternMel.slice(0, Math.min(avgMel.length, patternMel.length))\n      );\n      \n      // Calculate amplitude similarity\n      const frameAmplitude = average(frames.map(f => f.features.amplitude));\n      const patternAmplitude = average(patternSegment.envelope);\n      \n      // For silence segments, check amplitude difference\n      if (patternSegment.isSilence) {\n        return frameAmplitude < state.ambientNoiseLevel * 3 ? 0.9 : 0.1;\n      }\n      \n      // Compare normalized amplitudes with some tolerance\n      const normFrameAmp = frameAmplitude / Math.max(state.ambientNoiseLevel * 10, 0.001);\n      const normPatternAmp = patternAmplitude / Math.max(state.ambientNoiseLevel * 10, 0.001);\n      \n      const amplitudeSimilarity = 1 - Math.min(1, \n        Math.abs(normFrameAmp - normPatternAmp) / Math.max(normFrameAmp, normPatternAmp, 0.001)\n      );\n      \n      // Return weighted spectral match score\n      return melSimilarity * 0.7 + amplitudeSimilarity * 0.3;\n    }\n\n    function calculatePatternConfidence(segmentScores) {\n      // Calculate overall confidence based on segment match scores and state distribution\n      \n      // 1. Get current state information\n      const maxStateIdx = state.stateDistribution.indexOf(Math.max(...state.stateDistribution));\n      const progressThroughPattern = (maxStateIdx + 1) / state.patternSegments.length;\n      \n      // 2. Calculate average segment match score\n      const avgMatchScore = average(segmentScores);\n      \n      // 3. Calculate sequential progress confidence\n      let sequentialProgress = 0;\n      \n      if (config.detectionMethod === 'markov') {\n        // For Markov method, use state history to verify sequential progression\n        sequentialProgress = state.currentState / (state.patternSegments.length - 1);\n      } else {\n        // For other methods, check state distribution\n        let maxState = 0;\n        for (let i = 0; i < state.stateDistribution.length; i++) {\n          if (state.stateDistribution[i] > 0.5) {\n            maxState = Math.max(maxState, i);\n          }\n        }\n        sequentialProgress = maxState / (state.patternSegments.length - 1);\n      }\n      \n      // 4. Calculate final confidence score\n      const rawConfidence = \n        avgMatchScore * 0.4 + \n        sequentialProgress * 0.6;\n      \n      // 5. Apply smoothing with previous confidence (time-weighted average)\n      state.currentConfidence = state.currentConfidence * 0.8 + rawConfidence * 0.2;\n      \n      // 6. Track confidence history for pattern detection\n      state.confidenceHistory.push(state.currentConfidence);\n      if (state.confidenceHistory.length > 10) {\n        state.confidenceHistory.shift();\n      }\n      \n      // Update UI\n      updateConfidenceDisplay();\n    }\n\n    function updateConfidenceDisplay() {\n      // Update the confidence indicator\n      const confidencePercent = Math.round(state.currentConfidence * 100);\n      elements.sequenceConfidence.style.width = `${confidencePercent}%`;\n      elements.sequenceConfidence.textContent = `${confidencePercent}%`;\n      \n      // Set color based on confidence level\n      if (confidencePercent > 70) {\n        elements.sequenceConfidence.style.backgroundColor = '#27ae60';\n      } else if (confidencePercent > 40) {\n        elements.sequenceConfidence.style.backgroundColor = '#f39c12';\n      } else {\n        elements.sequenceConfidence.style.backgroundColor = '#3498db';\n      }\n    }\n\n    function updateSegmentMatchIndicators() {\n      // Update match indicators for each segment\n      state.patternSegments.forEach((_, index) => {\n        const indicator = document.getElementById(`segment_${index}_indicator`);\n        if (indicator) {\n          indicator.style.width = `${state.stateDistribution[index] * 100}%`;\n        }\n      });\n      \n      // Update phoneme display\n      const sequenceItems = elements.sequenceDisplay.querySelectorAll('.phoneme-item');\n      sequenceItems.forEach(item => {\n        const index = parseInt(item.dataset.index);\n        const maxStateIdx = state.stateDistribution.indexOf(Math.max(...state.stateDistribution));\n        \n        if (index < maxStateIdx) {\n          item.classList.add('active');\n        } else if (index === maxStateIdx) {\n          item.classList.add('active');\n        } else {\n          item.classList.remove('active');\n        }\n      });\n      \n      // Move segment marker on timeline\n      const maxStateIdx = state.stateDistribution.indexOf(Math.max(...state.stateDistribution));\n      if (maxStateIdx >= 0 && state.patternSegments.length > 0) {\n        const totalDuration = state.patternSegments[state.patternSegments.length - 1].endTime;\n        const segmentStart = state.patternSegments[maxStateIdx].startTime;\n        const markerPosition = (segmentStart / totalDuration) * 100;\n        elements.currentSegmentMarker.style.left = `${markerPosition}%`;\n      }\n    }\n\n    function updateDetectionVisualizations() {\n      // Update timeline visualization\n      drawSegmentedTimeline();\n      \n      // Update detection indicator\n      elements.detectionIndicator.style.width = `${state.currentConfidence * 100}%`;\n    }\n\n    function checkForPatternDetection() {\n      const now = Date.now();\n      if (now - state.lastDetectionTime < config.coolingPeriod) return;\n      \n      // Check for pattern detection based on method\n      if (config.detectionMethod === 'markov') {\n        checkMarkovPatternDetection();\n      } else {\n        checkGenericPatternDetection();\n      }\n    }\n\n    function checkMarkovPatternDetection() {\n      // For Markov method, check if we've seen all states in sequence\n      if (state.currentState === state.patternSegments.length - 1 && \n          state.framesSinceStateChange >= config.minFramesInState) {\n        \n        // Verify we've been through all prior states\n        const validSequence = state.stateHistory.length >= state.patternSegments.length - 1;\n        \n        if (validSequence && state.currentConfidence > config.minDetectionConfidence) {\n          // Calculate final match score by combining segment scores and sequence order\n          const matchConfidence = state.currentConfidence;\n          \n          // Check pattern phoneme sequence\n          const patternSequence = state.patternPhonemeSequence.map(p => p.type);\n          const detectedSequence = state.detectedPhonemeSequence.slice(-patternSequence.length);\n          \n          // Calculate phoneme sequence match score\n          let sequenceMatchScore = 0;\n          for (let i = 0; i < patternSequence.length && i < detectedSequence.length; i++) {\n            if (patternSequence[i] === detectedSequence[i]) {\n              sequenceMatchScore += 1.0 / patternSequence.length;\n            }\n          }\n          \n          // Blend match confidence with sequence match\n          const overallConfidence = matchConfidence * 0.7 + sequenceMatchScore * 0.3;\n          \n          // Record match details for display\n          state.lastMatchConfidence = overallConfidence;\n          state.lastMatchDetails = {\n            confidence: overallConfidence,\n            sequenceMatch: sequenceMatchScore,\n            stateProgress: state.currentState / (state.patternSegments.length - 1),\n            expectedSequence: patternSequence,\n            detectedSequence: detectedSequence\n          };\n          \n          // Register detection if confidence is high enough\n          if (overallConfidence > config.patternStrictness) {\n            registerDetection();\n          } else {\n            // Show near-match but don't count\n            showPatternMatchSummary(false);\n            logDetection(`Pattern almost detected, but confidence (${Math.round(overallConfidence * 100)}%) below threshold`, false);\n          }\n        }\n      }\n    }\n\n    function checkGenericPatternDetection() {\n      // For non-Markov methods, check confidence threshold and end of pattern\n      const maxStateIdx = state.stateDistribution.indexOf(Math.max(...state.stateDistribution));\n      const isNearEnd = maxStateIdx >= state.patternSegments.length * 0.8;\n      \n      if (state.currentConfidence > config.patternStrictness && isNearEnd) {\n        // Record match details for display\n        state.lastMatchConfidence = state.currentConfidence;\n        state.lastMatchDetails = {\n          confidence: state.currentConfidence,\n          sequenceMatch: isNearEnd ? 1.0 : 0.5,\n          stateProgress: maxStateIdx / (state.patternSegments.length - 1),\n          expectedSequence: state.patternPhonemeSequence.map(p => p.type),\n          detectedSequence: Array(state.patternPhonemeSequence.length).fill(\"?\")\n        };\n        \n        registerDetection();\n      }\n    }\n\n    function registerDetection() {\n      // Increment the counter\n      state.counter++;\n      elements.counterValue.textContent = state.counter;\n      \n      // Update UI\n      elements.detectionStatus.textContent = `Thikr pattern detected! Count: ${state.counter}`;\n      \n      // Enter lockout period\n      state.inLockoutPeriod = true;\n      elements.lockoutIndicator.style.display = 'flex';\n      elements.lockoutIndicator.textContent = `COOLDOWN (${(config.lockoutPeriod/1000).toFixed(1)}s)`;\n      \n      // Record detection time\n      state.lastDetectionTime = Date.now();\n      \n      // Reset state tracking\n      state.stateDistribution = new Array(state.patternSegments.length).fill(0);\n      state.stateDistribution[0] = 1.0; // Reset to first state\n      state.stateHistory = [];\n      state.currentState = 0;\n      state.framesSinceStateChange = 0;\n      state.currentConfidence = 0.1;\n      state.confidenceHistory = [];\n      \n      // Show detection summary\n      showPatternMatchSummary(true);\n      \n      // Log detection\n      logDetection(`PATTERN DETECTED! Count: ${state.counter}, Confidence: ${(state.lastMatchConfidence * 100).toFixed(0)}%`, true);\n      logDebug(`Thikr pattern detected with confidence ${state.lastMatchConfidence.toFixed(2)}`);\n    }\n\n    function showPatternMatchSummary(isFullMatch) {\n      if (!state.lastMatchDetails) return;\n      \n      // Update match header\n      elements.matchHeaderText.textContent = isFullMatch ? \n        `Pattern detected! Confidence: ${Math.round(state.lastMatchConfidence * 100)}%` :\n        `Pattern almost matched (${Math.round(state.lastMatchConfidence * 100)}% confidence)`;\n      \n      // Clear existing content\n      elements.patternSequenceDisplay.innerHTML = '';\n      elements.matchDetailsContainer.innerHTML = '';\n      \n      // Create pattern sequence visualization\n      const expected = state.lastMatchDetails.expectedSequence;\n      const detected = state.lastMatchDetails.detectedSequence;\n      \n      expected.forEach((type, index) => {\n        const isMatch = type === detected[index];\n        \n        const sequenceItem = document.createElement('div');\n        sequenceItem.className = 'pattern-sequence-item';\n        \n        // Expected pattern\n        const expectedSegment = document.createElement('div');\n        expectedSegment.className = `pattern-sequence-segment expected-pattern ${isMatch ? 'pattern-match' : 'pattern-mismatch'}`;\n        expectedSegment.textContent = type.charAt(0).toUpperCase();\n        \n        // Detected pattern\n        const actualSegment = document.createElement('div');\n        actualSegment.className = `pattern-sequence-segment actual-pattern ${isMatch ? 'pattern-match' : 'pattern-mismatch'}`;\n        actualSegment.textContent = detected[index] ? detected[index].charAt(0).toUpperCase() : '?';\n        \n        // Arrow\n        if (index < expected.length - 1) {\n          const arrow = document.createElement('span');\n          arrow.className = 'pattern-sequence-arrow';\n          arrow.textContent = '';\n          sequenceItem.appendChild(arrow);\n        }\n        \n        sequenceItem.appendChild(expectedSegment);\n        sequenceItem.appendChild(actualSegment);\n        elements.patternSequenceDisplay.appendChild(sequenceItem);\n      });\n      \n      // Add match details\n      const details = [\n        { label: 'Overall Confidence', value: state.lastMatchDetails.confidence },\n        { label: 'Sequence Match', value: state.lastMatchDetails.sequenceMatch },\n        { label: 'State Progress', value: state.lastMatchDetails.stateProgress }\n      ];\n      \n      details.forEach(detail => {\n        const row = document.createElement('div');\n        row.className = 'match-detail-row';\n        \n        const label = document.createElement('div');\n        label.className = 'match-detail-label';\n        label.textContent = detail.label;\n        \n        const valueContainer = document.createElement('div');\n        valueContainer.className = 'match-detail-value';\n        \n        const valueBar = document.createElement('div');\n        valueBar.className = 'match-detail-bar';\n        valueBar.style.width = `${detail.value * 100}%`;\n        valueBar.textContent = `${Math.round(detail.value * 100)}%`;\n        \n        // Add threshold marker\n        const thresholdMarker = document.createElement('div');\n        thresholdMarker.className = 'threshold-marker';\n        thresholdMarker.style.right = `${(1 - config.patternStrictness) * 100}%`;\n        thresholdMarker.title = `Threshold: ${Math.round(config.patternStrictness * 100)}%`;\n        \n        valueContainer.appendChild(valueBar);\n        valueContainer.appendChild(thresholdMarker);\n        \n        row.appendChild(label);\n        row.appendChild(valueContainer);\n        \n        elements.matchDetailsContainer.appendChild(row);\n      });\n      \n      // Display summary\n      elements.patternMatchSummary.style.display = 'block';\n      elements.matchDetailsContent.style.display = 'none';\n      elements.matchDetailsToggle.textContent = 'Show details';\n    }\n\n    function resetCounter() {\n      state.counter = 0;\n      elements.counterValue.textContent = '0';\n      logDebug('Counter reset to zero');\n      logDetection('Counter reset to 0');\n    }\n\n    // Dynamic Time Warping algorithm\n    function dtw(seriesA, seriesB, windowSize = null) {\n      const m = seriesA.length;\n      const n = seriesB.length;\n      \n      if (m === 0 || n === 0) return Infinity;\n      \n      // Default window size is 20% of max length\n      if (windowSize === null) {\n        windowSize = Math.ceil(Math.max(m, n) * 0.2);\n      }\n      \n      // Initialize DTW matrix with infinity\n      const dtwMatrix = Array(m + 1).fill().map(() => Array(n + 1).fill(Infinity));\n      dtwMatrix[0][0] = 0;\n      \n      // Fill the DTW matrix\n      for (let i = 1; i <= m; i++) {\n        // Define window bounds to search\n        const start = Math.max(1, Math.ceil(i * n / m - windowSize));\n        const end = Math.min(n, Math.floor(i * n / m + windowSize));\n        \n        for (let j = start; j <= end; j++) {\n          // Calculate distance between points\n          const cost = Math.abs(seriesA[i - 1] - seriesB[j - 1]);\n          \n          // Find minimum path cost\n          dtwMatrix[i][j] = cost + Math.min(\n            dtwMatrix[i - 1][j],     // Insertion\n            dtwMatrix[i][j - 1],     // Deletion\n            dtwMatrix[i - 1][j - 1]  // Match\n          );\n        }\n      }\n      \n      // Normalize by path length\n      return dtwMatrix[m][n] / (m + n);\n    }\n\n    // Fuzzy scoring function that's more forgiving than strict threshold\n    function fuzzyScore(value, threshold) {\n      const steepness = 8;\n      const midpoint = threshold * 0.8;\n      \n      // Sigmoid curve centered at midpoint\n      return 1 / (1 + Math.exp(-steepness * (value - midpoint)));\n    }\n\n    // Utility Functions\n    function normalizeArray(array) {\n      if (!array || array.length === 0) return [];\n      \n      const min = Math.min(...array);\n      const max = Math.max(...array);\n      \n      if (max === min) return array.map(() => 0.5);\n      \n      return array.map(val => (val - min) / (max - min));\n    }\n\n    function smoothArray(array, windowSize) {\n      if (!array || array.length === 0 || windowSize < 2) return array;\n      \n      const result = [];\n      const halfWindow = Math.floor(windowSize / 2);\n      \n      for (let i = 0; i < array.length; i++) {\n        let sum = 0;\n        let count = 0;\n        \n        for (let j = Math.max(0, i - halfWindow); j <= Math.min(array.length - 1, i + halfWindow); j++) {\n          sum += array[j];\n          count++;\n        }\n        \n        result.push(sum / count);\n      }\n      \n      return result;\n    }\n\n    function average(array) {\n      if (!array || array.length === 0) return 0;\n      return array.reduce((sum, val) => sum + val, 0) / array.length;\n    }\n\n    function sum(array) {\n      if (!array || array.length === 0) return 0;\n      return array.reduce((total, val) => total + val, 0);\n    }\n\n    function average2DArray(arrays) {\n      if (!arrays || arrays.length === 0 || !arrays[0] || arrays[0].length === 0) return [];\n      \n      // Find the common length to work with\n      const lengths = arrays.map(arr => arr.length);\n      const minLength = Math.min(...lengths);\n      \n      // Initialize result array\n      const result = new Array(minLength).fill(0);\n      \n      // Sum values across all arrays\n      for (let i = 0; i < arrays.length; i++) {\n        for (let j = 0; j < minLength; j++) {\n          result[j] += arrays[i][j] || 0;\n        }\n      }\n      \n      // Divide by count to get average\n      for (let j = 0; j < minLength; j++) {\n        result[j] /= arrays.length;\n      }\n      \n      return result;\n    }\n\n    function standardDeviation(array, mean = null) {\n      if (!array || array.length <= 1) return 0;\n      \n      const avg = mean !== null ? mean : average(array);\n      const squaredDiffs = array.map(val => Math.pow(val - avg, 2));\n      \n      return Math.sqrt(average(squaredDiffs));\n    }\n\n    function cosineSimilarity(vecA, vecB) {\n      if (!vecA || !vecB || vecA.length === 0 || vecB.length === 0) return 0;\n      \n      // Use the shorter length\n      const length = Math.min(vecA.length, vecB.length);\n      \n      let dotProduct = 0;\n      let normA = 0;\n      let normB = 0;\n      \n      for (let i = 0; i < length; i++) {\n        dotProduct += vecA[i] * vecB[i];\n        normA += vecA[i] * vecA[i];\n        normB += vecB[i] * vecB[i];\n      }\n      \n      if (normA === 0 || normB === 0) return 0;\n      \n      return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));\n    }\n\n    function findPeaks(array, minHeight = 0.1) {\n      if (!array || array.length < 5) return [];\n      \n      const peaks = [];\n      \n      // Find local maxima in the array\n      for (let i = 2; i < array.length - 2; i++) {\n        if (array[i] > minHeight && \n            array[i] > array[i - 1] && array[i] > array[i - 2] &&\n            array[i] >= array[i + 1] && array[i] > array[i + 2]) {\n          peaks.push(i);\n        }\n      }\n      \n      return peaks;\n    }\n\n    function findValleys(array, maxHeight = 0.5) {\n      if (!array || array.length < 5) return [];\n      \n      const valleys = [];\n      \n      // Find local minima in the array\n      for (let i = 2; i < array.length - 2; i++) {\n        if (array[i] < maxHeight && \n            array[i] < array[i - 1] && array[i] < array[i - 2] &&\n            array[i] <= array[i + 1] && array[i] < array[i + 2]) {\n          valleys.push(i);\n        }\n      }\n      \n      return valleys;\n    }\n\n    function clearLogs() {\n      elements.debugLog.innerHTML = '';\n      elements.detectionLog.innerHTML = '';\n      logDebug('Logs cleared');\n    }\n\n    function logDebug(message) {\n      if (!config.showDebugInfo) return;\n      \n      console.log(`[DEBUG] ${message}`);\n      \n      const logEntry = document.createElement('div');\n      const timestamp = new Date().toLocaleTimeString();\n      logEntry.innerHTML = `<span class=\"timestamp\">[${timestamp}]</span> ${message}`;\n      \n      elements.debugLog.appendChild(logEntry);\n      elements.debugLog.scrollTop = elements.debugLog.scrollHeight;\n    }\n\n    function logError(message) {\n      console.error(`[ERROR] ${message}`);\n      \n      const logEntry = document.createElement('div');\n      const timestamp = new Date().toLocaleTimeString();\n      logEntry.innerHTML = `<span class=\"timestamp\">[${timestamp}]</span> <span style=\"color: #e74c3c;\">${message}</span>`;\n      \n      elements.debugLog.appendChild(logEntry);\n      elements.debugLog.scrollTop = elements.debugLog.scrollHeight;\n    }\n\n    function logDetection(message, highlight = false) {\n      const logEntry = document.createElement('div');\n      const timestamp = new Date().toLocaleTimeString();\n      \n      if (highlight) logEntry.className = 'highlight';\n      \n      logEntry.innerHTML = `<span class=\"timestamp\">[${timestamp}]</span> ${message}`;\n      \n      elements.detectionLog.appendChild(logEntry);\n      elements.detectionLog.scrollTop = elements.detectionLog.scrollHeight;\n      \n      // Limit log size to prevent memory issues\n      while (elements.detectionLog.children.length > 20) {\n        elements.detectionLog.removeChild(elements.detectionLog.firstChild);\n      }\n    }\n  </script>\n</body>\n</html>"
          }
        ],
        "files": [
          {
            "file_name": "paste.txt"
          },
          {
            "file_name": "paste-2.txt"
          }
        ]
      }
    },
    {
      "id": "30e0caf5-5618-492b-b6cd-83a8792c14cb",
      "role": "assistant",
      "content": "\nLet me review the code to understand the issue with pattern detection, particularly why it doesn't detect the last element of the sequence. The code appears to be for an audio pattern detection system, specifically for detecting chants or repetitive patterns (thikr patterns).\n\nFrom my analysis, here are the key issues:\n\n1. **Detection Sequence Problem**: The code appears to have trouble completing the full detection sequence, specifically reaching the last element.\n\n2. **Missing Code**: We need to continue from the segment label code that was cut off.\n\n3. **Pattern Recognition Sensitivity**: The detection parameters may need tuning to better recognize patterns, especially the last segment.\n\nLet's address these issues one by one:\n\n### 1. Fixing the Detection Sequence Issue\n\nLooking at the first file's detection logic, I see several potential problems:\n\n- In `strictSequentialDetection`, `flexibleSequentialDetection`, and `adaptiveDetection` functions, there may be overly strict conditions for advancing to the next segment.\n- The timeouts or thresholds might be causing the detection to reset before completing the last segment.\n- There might be insufficient padding or lookahead in the detection buffer, causing the last segment to be missed.\n\nFor fixing this, we could:\n\na) Add padding to ensure the last segment has enough data to be detected:\n```javascript\n// In trimDetectionBuffer function\n// Keep more frames than strictly necessary\nconst maxFrames = Math.max(\n  200, // Increased from 150\n  pattern.segments.reduce((sum, s) => sum + s.frameCount, 0) * 3 // Increased multiplier\n);\n```\n\nb) Reduce the strictness for the last segment:\n```javascript\n// In strictSequentialDetection/flexibleSequentialDetection\n// Special case for last segment - be more forgiving\nif (currentIndex === pattern.segments.length - 1) {\n  // Lower threshold for last segment\n  const lastSegmentThreshold = this.config.minMatchThreshold * 0.8;\n  if (matchScore >= lastSegmentThreshold) {\n    // More lenient advancement logic for last segment\n  }\n}\n```\n\nc) Add a \"completion boost\" when almost through the pattern:\n```javascript\n// In calculateOverallConfidence\n// Add boost when almost complete\nif (sequenceState.currentIndex >= pattern.segments.length - 1) {\n  confidence *= 1.2; // Boost confidence for last segment\n  confidence = Math.min(confidence, 1.0); // Cap at 1.0\n}\n```\n\n### 2. Continuing the Missing Code\n\nWe need to complete the `label` part of the code and finish the segment marker creation:\n\n```javascript\n// Label\nconst label = document.createElement('div');\nlabel.className = 'segment-label';\nlabel.textContent = `Segment ${boundary.index + 1}`;\nlabel.style.left = `${boundary.start * 100}%`;\ncontainer.appendChild(label);\n\n// End marker\nconst endMarker = document.createElement('div');\nendMarker.className = 'segment-marker';\nendMarker.style.left = `${boundary.end * 100}%`;\ncontainer.appendChild(endMarker);\n```\n\n### 3. Pattern Recognition Improvements\n\nTo make detection more robust, I'll add:\n\na) Adaptive thresholds that adjust based on how far along the pattern we are:\n```javascript\n// Dynamic threshold adjustment\nconst progressAdjustment = 1.0 - (0.1 * sequenceState.currentIndex / pattern.segments.length);\nconst adjustedThreshold = this.config.minMatchThreshold * progressAdjustment;\n```\n\nb) Better windowing for audio analysis:\n```javascript\n// Use different window sizes for different segments\nconst windowSize = Math.min(\n  segment.frameCount * (2 + (index / pattern.segments.length)), // Larger windows for later segments\n  this.state.detectionBuffer.energy.length\n);\n```\n\nc) \"Soft ending\" - allow the pattern to complete even if the last segment isn't perfect:\n```javascript\n// In checkIfPatternDetected\n// If we're on the last segment and have been there for a while\nif (sequenceState.currentIndex === pattern.segments.length - 1 && \n    sequenceState.segments[sequenceState.currentIndex] === 'active' &&\n    timeInSegment > minSegmentTime * 0.75) {\n  // Consider the pattern complete even with slightly lower match\n  return {\n    patternDetected: true,\n    confidence: this.calculateOverallConfidence() * 0.9,\n    debugInfo: { completed: true, softEnding: true }\n  };\n}\n```\n\nd) UI improvements to make the system more user-friendly:\n- Clearer visualization of detected patterns\n- More intuitive controls for adjusting detection parameters\n- Better feedback when patterns are almost detected\n\nLet's put these improvements together into a merged, cleaned-up solution. I'll focus on:\n\n1. Continuing the code from the segment-label part\n2. Fixing the detection sequence issue\n3. Adding the improvements listed above\n4. General code cleanup and optimization\n\nI'll create a comprehensive solution that addresses these issues while maintaining the original functionality.\n\nI can see the main issues in this chant detector code. The key problem is that it's having trouble recognizing the complete pattern sequence, especially the last segment. Let me fix this and streamline the entire implementation.\n\nLooking at the code, I notice several opportunities for improvement:\n\n1. The detection sensitivity for the last segment needs adjustment\n2. There should be better padding in the detection buffer\n3. The segment transition logic can be more flexible\n4. The UI needs some simplification\n\nLet me continue from where the code stopped and implement these improvements:\n```\nViewing artifacts created via the Analysis Tool web feature preview isnt yet supported on mobile.\n```\n",
      "created_at": "2025-03-17T16:49:44.787858Z",
      "sequence_order": 1,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-03-17T16:44:39.164495Z",
            "stop_timestamp": "2025-03-17T16:44:58.859302Z",
            "flags": null,
            "type": "thinking",
            "thinking": "\nLet me review the code to understand the issue with pattern detection, particularly why it doesn't detect the last element of the sequence. The code appears to be for an audio pattern detection system, specifically for detecting chants or repetitive patterns (thikr patterns).\n\nFrom my analysis, here are the key issues:\n\n1. **Detection Sequence Problem**: The code appears to have trouble completing the full detection sequence, specifically reaching the last element.\n\n2. **Missing Code**: We need to continue from the segment label code that was cut off.\n\n3. **Pattern Recognition Sensitivity**: The detection parameters may need tuning to better recognize patterns, especially the last segment.\n\nLet's address these issues one by one:\n\n### 1. Fixing the Detection Sequence Issue\n\nLooking at the first file's detection logic, I see several potential problems:\n\n- In `strictSequentialDetection`, `flexibleSequentialDetection`, and `adaptiveDetection` functions, there may be overly strict conditions for advancing to the next segment.\n- The timeouts or thresholds might be causing the detection to reset before completing the last segment.\n- There might be insufficient padding or lookahead in the detection buffer, causing the last segment to be missed.\n\nFor fixing this, we could:\n\na) Add padding to ensure the last segment has enough data to be detected:\n```javascript\n// In trimDetectionBuffer function\n// Keep more frames than strictly necessary\nconst maxFrames = Math.max(\n  200, // Increased from 150\n  pattern.segments.reduce((sum, s) => sum + s.frameCount, 0) * 3 // Increased multiplier\n);\n```\n\nb) Reduce the strictness for the last segment:\n```javascript\n// In strictSequentialDetection/flexibleSequentialDetection\n// Special case for last segment - be more forgiving\nif (currentIndex === pattern.segments.length - 1) {\n  // Lower threshold for last segment\n  const lastSegmentThreshold = this.config.minMatchThreshold * 0.8;\n  if (matchScore >= lastSegmentThreshold) {\n    // More lenient advancement logic for last segment\n  }\n}\n```\n\nc) Add a \"completion boost\" when almost through the pattern:\n```javascript\n// In calculateOverallConfidence\n// Add boost when almost complete\nif (sequenceState.currentIndex >= pattern.segments.length - 1) {\n  confidence *= 1.2; // Boost confidence for last segment\n  confidence = Math.min(confidence, 1.0); // Cap at 1.0\n}\n```\n\n### 2. Continuing the Missing Code\n\nWe need to complete the `label` part of the code and finish the segment marker creation:\n\n```javascript\n// Label\nconst label = document.createElement('div');\nlabel.className = 'segment-label';\nlabel.textContent = `Segment ${boundary.index + 1}`;\nlabel.style.left = `${boundary.start * 100}%`;\ncontainer.appendChild(label);\n\n// End marker\nconst endMarker = document.createElement('div');\nendMarker.className = 'segment-marker';\nendMarker.style.left = `${boundary.end * 100}%`;\ncontainer.appendChild(endMarker);\n```\n\n### 3. Pattern Recognition Improvements\n\nTo make detection more robust, I'll add:\n\na) Adaptive thresholds that adjust based on how far along the pattern we are:\n```javascript\n// Dynamic threshold adjustment\nconst progressAdjustment = 1.0 - (0.1 * sequenceState.currentIndex / pattern.segments.length);\nconst adjustedThreshold = this.config.minMatchThreshold * progressAdjustment;\n```\n\nb) Better windowing for audio analysis:\n```javascript\n// Use different window sizes for different segments\nconst windowSize = Math.min(\n  segment.frameCount * (2 + (index / pattern.segments.length)), // Larger windows for later segments\n  this.state.detectionBuffer.energy.length\n);\n```\n\nc) \"Soft ending\" - allow the pattern to complete even if the last segment isn't perfect:\n```javascript\n// In checkIfPatternDetected\n// If we're on the last segment and have been there for a while\nif (sequenceState.currentIndex === pattern.segments.length - 1 && \n    sequenceState.segments[sequenceState.currentIndex] === 'active' &&\n    timeInSegment > minSegmentTime * 0.75) {\n  // Consider the pattern complete even with slightly lower match\n  return {\n    patternDetected: true,\n    confidence: this.calculateOverallConfidence() * 0.9,\n    debugInfo: { completed: true, softEnding: true }\n  };\n}\n```\n\nd) UI improvements to make the system more user-friendly:\n- Clearer visualization of detected patterns\n- More intuitive controls for adjusting detection parameters\n- Better feedback when patterns are almost detected\n\nLet's put these improvements together into a merged, cleaned-up solution. I'll focus on:\n\n1. Continuing the code from the segment-label part\n2. Fixing the detection sequence issue\n3. Adding the improvements listed above\n4. General code cleanup and optimization\n\nI'll create a comprehensive solution that addresses these issues while maintaining the original functionality.",
            "summaries": [
              {
                "summary": "Investigating audio pattern detection code's last element issue"
              },
              {
                "summary": "Boosting detection by adding padding and reducing thresholds"
              },
              {
                "summary": "Crafting robust pattern detection with adaptive thresholds"
              },
              {
                "summary": "Engineered robust pattern detection with adaptive detection strategies"
              }
            ],
            "cut_off": false
          },
          {
            "start_timestamp": "2025-03-17T16:44:59.035699Z",
            "stop_timestamp": "2025-03-17T16:45:00.852033Z",
            "flags": null,
            "type": "text",
            "text": "\n\nI can see the main issues in this chant detector code. The key problem is that it's having trouble recognizing the complete pattern sequence, especially the last segment. Let me fix this and streamline the entire implementation.\n\nLooking at the code, I notice several opportunities for improvement:\n\n1. The detection sensitivity for the last segment needs adjustment\n2. There should be better padding in the detection buffer\n3. The segment transition logic can be more flexible\n4. The UI needs some simplification\n\nLet me continue from where the code stopped and implement these improvements:",
            "citations": []
          },
          {
            "start_timestamp": "2025-03-17T16:45:01.114795Z",
            "stop_timestamp": "2025-03-17T16:49:23.281181Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "improved-chant-detector",
              "type": "application/vnd.ant.code",
              "title": "Improved Chant Detector with Better Pattern Recognition",
              "command": "create",
              "content": "// Here's the complete solution - an improved chant detector with better pattern recognition\n// This is a full HTML file with embedded JavaScript\n\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>Enhanced Chant Detector</title>\n  <script src=\"https://unpkg.com/meyda@5.2.0/dist/web/meyda.min.js\"></script>\n  <style>\n    body {\n      font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n      max-width: 900px;\n      margin: 0 auto;\n      padding: 20px;\n      line-height: 1.5;\n      background-color: #f8f9fa;\n      color: #333;\n    }\n    section {\n      background: #fff;\n      padding: 20px;\n      margin-bottom: 20px;\n      border-radius: 8px;\n      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);\n    }\n    h1, h2 { \n      margin-top: 0;\n      color: #2c3e50;\n    }\n    button {\n      background: #4285f4;\n      color: white;\n      border: none;\n      padding: 10px 15px;\n      margin-right: 10px;\n      margin-bottom: 10px;\n      cursor: pointer;\n      border-radius: 4px;\n      font-weight: 500;\n      transition: background 0.2s;\n    }\n    button:hover {\n      background: #356ac3;\n    }\n    button:disabled { \n      background: #ccc;\n      cursor: not-allowed;\n    }\n    .counter {\n      font-size: 48px;\n      font-weight: bold;\n      text-align: center;\n      margin: 15px 0;\n      color: #2c3e50;\n    }\n    .row {\n      display: flex;\n      align-items: center;\n      margin: 10px 0;\n    }\n    label {\n      width: 200px;\n      margin-right: 15px;\n      font-weight: 500;\n    }\n    .settings-value {\n      min-width: 45px;\n      text-align: right;\n      font-weight: bold;\n      margin-left: 10px;\n    }\n    .status {\n      background: #f1f3f5;\n      padding: 12px;\n      margin: 10px 0;\n      border-radius: 4px;\n      font-family: monospace;\n      border-left: 4px solid #4285f4;\n    }\n    \n    /* Visualization Styles */\n    .visualizer-container {\n      position: relative;\n      height: 150px;\n      margin: 15px 0;\n      border: 1px solid #e1e4e8;\n      border-radius: 4px;\n      background-color: #121212;\n      overflow: hidden;\n    }\n    .visualizer-canvas {\n      position: absolute;\n      top: 0;\n      left: 0;\n      width: 100%;\n      height: 100%;\n    }\n    .segment-markers {\n      position: absolute;\n      top: 0;\n      left: 0;\n      width: 100%;\n      height: 100%;\n      pointer-events: none;\n    }\n    .segment-marker {\n      position: absolute;\n      top: 0;\n      height: 100%;\n      width: 2px;\n      background-color: rgba(255, 255, 255, 0.6);\n    }\n    .segment-label {\n      position: absolute;\n      top: 5px;\n      background-color: rgba(0, 0, 0, 0.6);\n      color: white;\n      padding: 3px 6px;\n      border-radius: 3px;\n      font-size: 11px;\n      transform: translateX(-50%);\n    }\n    .time-cursor {\n      position: absolute;\n      top: 0;\n      height: 100%;\n      width: 2px;\n      background-color: rgb(255, 64, 129);\n      transition: left 0.1s ease-out;\n      box-shadow: 0 0 10px rgb(255, 64, 129);\n    }\n    \n    .sequence-progress {\n      display: flex;\n      height: 40px;\n      background: #f1f3f5;\n      margin: 15px 0;\n      border-radius: 4px;\n      overflow: hidden;\n    }\n    .segment-box {\n      flex: 1;\n      height: 100%;\n      display: flex;\n      align-items: center;\n      justify-content: center;\n      color: white;\n      font-weight: bold;\n      transition: background-color 0.3s;\n      border-right: 1px solid rgba(255,255,255,0.3);\n      position: relative;\n    }\n    .segment-box::after {\n      content: '';\n      position: absolute;\n      bottom: 0;\n      left: 0;\n      height: 3px;\n      background-color: #4285f4;\n      transition: width 0.3s ease-out;\n    }\n    .segment-pending { background-color: #90a4ae; }\n    .segment-active { \n      background-color: #ff9800; \n      animation: pulse 1.5s infinite;\n    }\n    .segment-complete { background-color: #4caf50; }\n    .segment-invalid { background-color: #f44336; }\n    \n    @keyframes pulse {\n      0% { background-color: #ff9800; }\n      50% { background-color: #ffb74d; }\n      100% { background-color: #ff9800; }\n    }\n    \n    .detection-bar {\n      height: 20px;\n      position: relative;\n      margin: 10px 0;\n      background: #f1f3f5;\n      border-radius: 4px;\n      overflow: hidden;\n    }\n    .detection-progress {\n      position: absolute;\n      height: 100%;\n      width: 0%;\n      background: linear-gradient(90deg, #4caf50, #8bc34a);\n      transition: width 0.3s ease-out;\n    }\n    \n    .pattern-display {\n      width: 100%;\n      height: 120px;\n      position: relative;\n      background: #121212;\n      margin: 15px 0;\n      display: flex;\n      border-radius: 4px;\n      overflow: hidden;\n    }\n    .pattern-segment {\n      flex: 1;\n      height: 100%;\n      overflow: hidden;\n      position: relative;\n      border-right: 1px dashed rgba(255,255,255,0.3);\n    }\n    .pattern-segment-label {\n      position: absolute;\n      top: 5px;\n      left: 5px;\n      background-color: rgba(0,0,0,0.6);\n      color: white;\n      padding: 2px 5px;\n      font-size: 10px;\n      z-index: 10;\n      border-radius: 3px;\n    }\n    \n    .debug-panel {\n      display: grid;\n      grid-template-columns: repeat(3, 1fr);\n      grid-gap: 10px;\n      margin: 10px 0;\n    }\n    .debug-item {\n      background: #f1f3f5;\n      padding: 8px;\n      font-size: 12px;\n      border-radius: 4px;\n    }\n    .debug-item-title {\n      font-weight: bold;\n      margin-bottom: 3px;\n      color: #2c3e50;\n    }\n    \n    .log {\n      height: 150px;\n      overflow-y: auto;\n      background: #f8f9fa;\n      border: 1px solid #e1e4e8;\n      padding: 10px;\n      font-family: monospace;\n      font-size: 12px;\n      border-radius: 4px;\n    }\n    .log div {\n      margin-bottom: 3px;\n      padding-bottom: 3px;\n      border-bottom: 1px solid #f1f3f5;\n    }\n    .highlight { color: #e91e63; font-weight: bold; }\n    .success { color: #4caf50; font-weight: bold; }\n    \n    .pattern-info {\n      display: flex;\n      flex-wrap: wrap;\n      margin: 10px 0;\n    }\n    .pattern-stat {\n      background: #e9ecef;\n      padding: 3px 8px;\n      margin-right: 8px;\n      margin-bottom: 8px;\n      border-radius: 4px;\n      font-size: 12px;\n    }\n    \n    .pattern-tabs {\n      display: flex;\n      margin-bottom: 10px;\n    }\n    .pattern-tab {\n      padding: 8px 15px;\n      background: #e9ecef;\n      margin-right: 8px;\n      cursor: pointer;\n      border-radius: 4px;\n      font-size: 14px;\n      transition: all 0.2s;\n    }\n    .pattern-tab:hover {\n      background: #dee2e6;\n    }\n    .pattern-tab.active {\n      background: #4285f4;\n      color: white;\n    }\n    \n    .tooltip {\n      position: relative;\n      display: inline-block;\n      cursor: help;\n      margin-left: 5px;\n    }\n    .tooltip .tooltip-text {\n      visibility: hidden;\n      width: 200px;\n      background-color: #333;\n      color: #fff;\n      text-align: center;\n      border-radius: 4px;\n      padding: 5px;\n      position: absolute;\n      z-index: 1;\n      bottom: 125%;\n      left: 50%;\n      transform: translateX(-50%);\n      opacity: 0;\n      transition: opacity 0.3s;\n      font-size: 12px;\n      pointer-events: none;\n    }\n    .tooltip:hover .tooltip-text {\n      visibility: visible;\n      opacity: 1;\n    }\n    \n    /* Responsive adjustments */\n    @media (max-width: 768px) {\n      .row {\n        flex-direction: column;\n        align-items: flex-start;\n      }\n      label {\n        width: 100%;\n        margin-bottom: 5px;\n      }\n      .debug-panel {\n        grid-template-columns: 1fr;\n      }\n    }\n  </style>\n</head>\n<body>\n  <h1>Enhanced Chant Detector</h1>\n  <p>Record a chant pattern and the detector will count repetitions of it.</p>\n\n  <section>\n    <div style=\"display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;\">\n      <h2>1. Record Your Chant Pattern</h2>\n      <div class=\"pattern-tabs\">\n        <div class=\"pattern-tab active\" data-pattern=\"1\">Pattern 1</div>\n        <div class=\"pattern-tab\" data-pattern=\"2\">Pattern 2</div>\n        <div class=\"pattern-tab\" data-pattern=\"3\">Pattern 3</div>\n      </div>\n    </div>\n    \n    <div class=\"visualizer-container\">\n      <canvas id=\"recordSpectrogram\" class=\"visualizer-canvas\"></canvas>\n      <div class=\"segment-markers\" id=\"recordSegmentMarkers\"></div>\n    </div>\n    \n    <div class=\"status\" id=\"recordingStatus\">Ready to record your chant pattern</div>\n    <div>\n      <button id=\"recordBtn\">Record (Hold)</button>\n      <button id=\"playLastBtn\" disabled>Play Recording</button>\n      <button id=\"clearBtn\">Clear</button>\n      <button id=\"averageBtn\" disabled>Average Patterns</button>\n      <span id=\"patternInfo\"></span>\n    </div>\n    \n    <div class=\"pattern-display\" id=\"patternDisplay\"></div>\n    <div class=\"pattern-info\" id=\"patternStats\"></div>\n  </section>\n\n  <section>\n    <h2>2. Settings</h2>\n    <div class=\"row\">\n      <label for=\"detectionMode\">Detection Mode:</label>\n      <select id=\"detectionMode\">\n        <option value=\"adaptive\" selected>Adaptive (Recommended)</option>\n        <option value=\"flexible\">Flexible Sequential</option>\n        <option value=\"sequential\">Strict Sequential</option>\n      </select>\n      <div class=\"tooltip\">\n        <span>?</span>\n        <span class=\"tooltip-text\">Adaptive mode automatically adjusts to find patterns better.</span>\n      </div>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"minMatchSlider\">Segment Match Threshold:</label>\n      <input type=\"range\" id=\"minMatchSlider\" min=\"0.3\" max=\"0.9\" step=\"0.05\" value=\"0.5\">\n      <span id=\"minMatchValue\" class=\"settings-value\">0.5</span>\n      <div class=\"tooltip\">\n        <span>?</span>\n        <span class=\"tooltip-text\">Lower values make detection more sensitive but may increase false positives.</span>\n      </div>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"advanceThresholdSlider\">Advance Threshold:</label>\n      <input type=\"range\" id=\"advanceThresholdSlider\" min=\"0.2\" max=\"0.8\" step=\"0.05\" value=\"0.4\">\n      <span id=\"advanceThresholdValue\" class=\"settings-value\">0.4</span>\n      <div class=\"tooltip\">\n        <span>?</span>\n        <span class=\"tooltip-text\">Lower values = easier progression between segments.</span>\n      </div>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"timeoutSlider\">Segment Timeout (ms):</label>\n      <input type=\"range\" id=\"timeoutSlider\" min=\"500\" max=\"5000\" step=\"100\" value=\"3000\">\n      <span id=\"timeoutValue\" class=\"settings-value\">3000</span>\n      <div class=\"tooltip\">\n        <span>?</span>\n        <span class=\"tooltip-text\">How long to wait before resetting if stuck on a segment.</span>\n      </div>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"cooldownSlider\">Cooldown Period (ms):</label>\n      <input type=\"range\" id=\"cooldownSlider\" min=\"500\" max=\"3000\" step=\"100\" value=\"1500\">\n      <span id=\"cooldownValue\" class=\"settings-value\">1500</span>\n      <div class=\"tooltip\">\n        <span>?</span>\n        <span class=\"tooltip-text\">Wait time between detections to avoid duplicates.</span>\n      </div>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"segmentCountSelect\">Pattern Segments:</label>\n      <select id=\"segmentCountSelect\">\n        <option value=\"3\">3</option>\n        <option value=\"4\" selected>4</option>\n        <option value=\"5\">5</option>\n        <option value=\"6\">6</option>\n      </select>\n      <div class=\"tooltip\">\n        <span>?</span>\n        <span class=\"tooltip-text\">How many parts to divide your pattern into.</span>\n      </div>\n    </div>\n\n    <div class=\"row\">\n      <label for=\"finalSegmentBoostSlider\">Final Segment Boost:</label>\n      <input type=\"range\" id=\"finalSegmentBoostSlider\" min=\"0.5\" max=\"1.5\" step=\"0.1\" value=\"0.8\">\n      <span id=\"finalSegmentBoostValue\" class=\"settings-value\">0.8</span>\n      <div class=\"tooltip\">\n        <span>?</span>\n        <span class=\"tooltip-text\">Makes the last segment easier to detect (lower = easier).</span>\n      </div>\n    </div>\n  </section>\n\n  <section>\n    <h2>3. Detection</h2>\n    <div class=\"counter\" id=\"counterValue\">0</div>\n    \n    <div class=\"visualizer-container\">\n      <canvas id=\"liveSpectrogram\" class=\"visualizer-canvas\"></canvas>\n      <div class=\"segment-markers\" id=\"liveSegmentMarkers\"></div>\n      <div class=\"time-cursor\" id=\"timeCursor\" style=\"left: 50%;\"></div>\n    </div>\n    \n    <div class=\"sequence-progress\" id=\"sequenceProgress\"></div>\n    <div class=\"detection-bar\">\n      <div id=\"detectionProgress\" class=\"detection-progress\"></div>\n    </div>\n    \n    <div class=\"status\" id=\"detectionStatus\">No pattern recorded yet</div>\n    <div>\n      <button id=\"startBtn\" disabled>Start Detection</button>\n      <button id=\"stopBtn\" disabled>Stop</button>\n      <button id=\"resetBtn\">Reset Counter</button>\n    </div>\n    \n    <h3>Debug Info</h3>\n    <div class=\"debug-panel\" id=\"debugPanel\"></div>\n    <div class=\"log\" id=\"detectionLog\"></div>\n  </section>\n\n<script>\n/**\n * Enhanced Chant Detector\n * \n * Improvements:\n * 1. Better handling of the final segment in patterns\n * 2. Adaptive thresholds for different segments\n * 3. Improved visualization and feedback\n * 4. Buffer padding for more reliable detection\n * 5. Cleaner code organization and error handling\n */\nclass EnhancedChantDetector {\n  constructor() {\n    // Audio system\n    this.audioContext = null;\n    this.analyzer = null;\n    this.mediaStream = null;\n    this.processor = null;\n    this.audioBufferSource = null;\n    \n    // Configuration\n    this.config = {\n      bufferSize: 1024,\n      fftSize: 2048,\n      sampleRate: 44100,\n      minRecordDuration: 500,\n      detectionMode: 'adaptive',\n      minMatchThreshold: 0.5,     // Minimum score to consider a match\n      advanceThreshold: 0.4,      // Threshold to advance to next segment\n      segmentTimeout: 3000,       // Time before resetting stuck segment (ms)\n      cooldownTime: 1500,         // Cooldown between detections (ms)\n      segmentCount: 4,            // Number of segments in pattern\n      maxPatterns: 3,             // Maximum number of patterns to store\n      spectrogramHistory: 150,    // Number of columns in spectrogram\n      lookAheadFrames: 15,        // Frames to look ahead for flexible mode\n      finalSegmentBoost: 0.8,     // Threshold multiplier for final segment (lower = easier)\n      \n      // Feature weights for different detection aspects\n      featureWeights: {\n        spectrogram: 0.5,  // Weight for spectrogram match\n        mfcc: 0.3,         // Weight for MFCC match\n        energy: 0.2        // Weight for energy profile match\n      }\n    };\n    \n    // State\n    this.state = {\n      isRecording: false,\n      isDetecting: false,\n      inCooldown: false,\n      isPlaying: false,\n      \n      // Active pattern\n      activePatternIndex: 0,\n      \n      // Recording state\n      recordStartTime: 0,\n      recordingData: {\n        audio: [],\n        spectrogram: [],\n        mfcc: [],\n        energy: [],\n        duration: 0\n      },\n      \n      // Patterns (multiple can be stored)\n      patterns: [],\n      \n      // Detection state\n      detectionBuffer: {\n        audio: [],\n        spectrogram: [],\n        mfcc: [],\n        energy: [],\n        timeWindow: []  // Time values for visualization\n      },\n      \n      // Sequence tracking\n      sequenceState: {\n        segments: [],          // State of each segment (pending, active, complete, invalid)\n        currentIndex: 0,       // Current segment being matched\n        progress: 0,           // Overall progress (0-1)\n        matchScores: [],       // Match scores for each segment\n        segmentStartTimes: [], // When each segment started matching\n        stuckTime: 0,          // How long we've been stuck on a segment\n        lastAdvanceTime: 0     // When we last advanced segments\n      },\n      \n      // Results\n      counter: 0,\n      lastDetectionTime: 0,\n      \n      // Visualization\n      spectrogramData: {\n        recording: [],\n        pattern: [],\n        live: []\n      },\n      \n      // Timing markers for visualization\n      timeMarkers: {\n        pattern: [],\n        live: []\n      }\n    };\n    \n    // Callbacks\n    this.callbacks = {\n      onStatusUpdate: null,\n      onVisualizationUpdate: null,\n      onDetection: null,\n      onProgressUpdate: null,\n      onError: null\n    };\n    \n    // Animation\n    this.animationFrame = null;\n  }\n  \n  /**\n   * Set up callbacks\n   */\n  setCallbacks(callbacks) {\n    Object.assign(this.callbacks, callbacks);\n  }\n  \n  /**\n   * Initialize audio system\n   */\n  async setupAudio() {\n    if (this.audioContext) return true;\n    \n    try {\n      this.audioContext = new (window.AudioContext || window.webkitAudioContext)();\n      this.config.sampleRate = this.audioContext.sampleRate;\n      \n      this.mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });\n      \n      this.analyzer = this.audioContext.createAnalyser();\n      this.analyzer.fftSize = this.config.fftSize;\n      \n      this.log('info', 'Audio system initialized');\n      return true;\n    } catch (error) {\n      this.handleError('Audio setup failed', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Start recording a pattern\n   */\n  async startRecording() {\n    if (this.state.isRecording) return false;\n    \n    // Setup audio\n    const success = await this.setupAudio();\n    if (!success) return false;\n    \n    // Initialize recording state\n    this.state.isRecording = true;\n    this.state.recordStartTime = Date.now();\n    this.state.recordingData = {\n      audio: [],\n      spectrogram: [],\n      mfcc: [],\n      energy: [],\n      duration: 0\n    };\n    \n    // Also initialize spectrogram data for visualization\n    this.state.spectrogramData.recording = [];\n    \n    // Create processor node\n    this.processor = this.audioContext.createScriptProcessor(\n      this.config.bufferSize, 1, 1\n    );\n    \n    // Process audio data\n    this.processor.onaudioprocess = (event) => {\n      if (!this.state.isRecording) return;\n      \n      try {\n        // Get audio data\n        const inputData = event.inputBuffer.getChannelData(0);\n        const audioData = new Float32Array(inputData.length);\n        audioData.set(inputData);\n        \n        // Extract features\n        const features = this.extractFeatures(audioData);\n        \n        // Store data\n        this.state.recordingData.audio.push(audioData);\n        this.state.recordingData.spectrogram.push(features.spectrogram);\n        this.state.recordingData.mfcc.push(features.mfcc);\n        this.state.recordingData.energy.push(features.energy);\n        \n        // Store spectrogram for visualization\n        this.state.spectrogramData.recording.push(features.spectrogram);\n        \n        // Update visualization\n        if (this.callbacks.onVisualizationUpdate) {\n          this.callbacks.onVisualizationUpdate('recording', audioData, features);\n        }\n      } catch (error) {\n        this.handleError('Error processing recording', error);\n      }\n    };\n    \n    // Connect audio nodes\n    const source = this.audioContext.createMediaStreamSource(this.mediaStream);\n    source.connect(this.analyzer);\n    source.connect(this.processor);\n    this.processor.connect(this.audioContext.destination);\n    \n    this.log('status', 'Recording chant pattern...');\n    return true;\n  }\n  \n  /**\n   * Stop recording and process the pattern\n   */\n  stopRecording() {\n    if (!this.state.isRecording) return false;\n    \n    // Update state\n    this.state.isRecording = false;\n    this.state.recordingData.duration = Date.now() - this.state.recordStartTime;\n    \n    // Clean up\n    if (this.processor) {\n      this.processor.disconnect();\n      this.processor = null;\n    }\n    \n    // Check recording duration\n    if (this.state.recordingData.duration < this.config.minRecordDuration) {\n      this.log('status', 'Recording too short, please try again');\n      return false;\n    }\n    \n    this.log('status', 'Processing pattern...');\n    \n    // Process the pattern\n    const success = this.processRecordingToPattern();\n    \n    if (success) {\n      this.log('status', `Pattern ${this.state.activePatternIndex + 1} recorded (${(this.state.recordingData.duration/1000).toFixed(1)}s)`);\n      return true;\n    } else {\n      this.log('status', 'Failed to process pattern');\n      return false;\n    }\n  }\n  \n  /**\n   * Play the last recorded pattern\n   */\n  playLastPattern() {\n    if (this.state.isPlaying || !this.state.patterns[this.state.activePatternIndex]) {\n      return false;\n    }\n    \n    this.state.isPlaying = true;\n    \n    const pattern = this.state.patterns[this.state.activePatternIndex];\n    if (!pattern || !pattern.rawData || !pattern.rawData.audio || pattern.rawData.audio.length === 0) {\n      this.log('status', 'No audio data to play');\n      this.state.isPlaying = false;\n      return false;\n    }\n    \n    this.log('status', 'Playing pattern...');\n    \n    // Setup audio if needed\n    if (!this.audioContext) {\n      this.setupAudio().then(success => {\n        if (success) {\n          this.playAudioData(pattern.rawData.audio);\n        } else {\n          this.state.isPlaying = false;\n        }\n      });\n    } else {\n      this.playAudioData(pattern.rawData.audio);\n    }\n    \n    return true;\n  }\n  \n  /**\n   * Helper method to play audio data\n   */\n  playAudioData(audioDataArray) {\n    try {\n      // Create audio buffer\n      const totalLength = audioDataArray.reduce((sum, chunk) => sum + chunk.length, 0);\n      const audioBuffer = this.audioContext.createBuffer(1, totalLength, this.audioContext.sampleRate);\n      const channelData = audioBuffer.getChannelData(0);\n      \n      // Fill buffer with audio data\n      let offset = 0;\n      for (const chunk of audioDataArray) {\n        channelData.set(chunk, offset);\n        offset += chunk.length;\n      }\n      \n      // Create source and play\n      this.audioBufferSource = this.audioContext.createBufferSource();\n      this.audioBufferSource.buffer = audioBuffer;\n      this.audioBufferSource.connect(this.audioContext.destination);\n      \n      this.audioBufferSource.onended = () => {\n        this.state.isPlaying = false;\n        this.log('status', 'Playback complete');\n      };\n      \n      this.audioBufferSource.start();\n    } catch (error) {\n      this.handleError('Error playing audio', error);\n      this.state.isPlaying = false;\n    }\n  }\n  \n  /**\n   * Process recording data into a pattern\n   */\n  processRecordingToPattern() {\n    try {\n      // Get current pattern index\n      const patternIndex = this.state.activePatternIndex;\n      \n      // Create a new pattern if it doesn't exist\n      if (!this.state.patterns[patternIndex]) {\n        this.state.patterns[patternIndex] = {\n          rawData: {\n            audio: [],\n            spectrogram: [],\n            mfcc: [],\n            energy: [],\n            duration: 0\n          },\n          segments: [],\n          sampleCount: 0\n        };\n      }\n      \n      // Store recording data\n      const pattern = this.state.patterns[patternIndex];\n      \n      // If this is the first recording for this pattern, just copy it\n      if (pattern.sampleCount === 0) {\n        pattern.rawData = {\n          audio: [...this.state.recordingData.audio],\n          spectrogram: [...this.state.recordingData.spectrogram],\n          mfcc: [...this.state.recordingData.mfcc],\n          energy: [...this.state.recordingData.energy],\n          duration: this.state.recordingData.duration\n        };\n      } else {\n        // Average with existing pattern data (simple arithmetic mean)\n        // First, we need to time-normalize the new recording\n        const normalizedRecording = this.normalizeRecordingLength(\n          this.state.recordingData, \n          pattern.rawData\n        );\n        \n        // Now average with existing pattern\n        this.averagePatternData(pattern, normalizedRecording);\n      }\n      \n      // Increment sample count\n      pattern.sampleCount++;\n      \n      // Segment the pattern\n      pattern.segments = this.segmentPattern(pattern.rawData);\n      \n      // Calculate segment boundaries for visualization\n      this.calculateSegmentBoundaries(pattern);\n      \n      // Store pattern visualization data\n      this.state.spectrogramData.pattern = [...pattern.rawData.spectrogram];\n      \n      // Clear recording data to save memory\n      this.state.recordingData = {\n        audio: [],\n        spectrogram: [],\n        mfcc: [],\n        energy: [],\n        duration: 0\n      };\n      \n      // Enable averaging if we have multiple patterns\n      if (this.checkMultiplePatternsExist()) {\n        // Check if averaging button should be enabled\n        if (this.callbacks.onStatusUpdate) {\n          this.callbacks.onStatusUpdate('control', 'enableAveraging', true);\n        }\n      }\n      \n      return true;\n    } catch (error) {\n      this.handleError('Error processing pattern', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Normalize recording length to match target pattern\n   */\n  normalizeRecordingLength(recording, targetPattern) {\n    // Create a normalized version of the recording\n    const normalized = {\n      audio: [],\n      spectrogram: [],\n      mfcc: [],\n      energy: [],\n      duration: targetPattern.duration\n    };\n    \n    const sourceLength = recording.energy.length;\n    const targetLength = targetPattern.energy.length;\n    \n    // Simple linear resampling for feature data\n    for (let i = 0; i < targetLength; i++) {\n      const sourceIdx = Math.floor(i * sourceLength / targetLength);\n      \n      normalized.spectrogram[i] = recording.spectrogram[sourceIdx];\n      normalized.mfcc[i] = recording.mfcc[sourceIdx];\n      normalized.energy[i] = recording.energy[sourceIdx];\n    }\n    \n    // For audio data, we need to do a bit more careful resampling\n    // Here we just take chunks that correspond approximately to the target chunks\n    // This is simplified and not perfect, but works for our averaging purposes\n    const audioChunkSize = Math.ceil(recording.audio.length / sourceLength);\n    const targetAudioChunkSize = Math.ceil(targetPattern.audio.length / targetLength);\n    \n    for (let i = 0; i < targetLength; i++) {\n      const sourceIdx = Math.floor(i * sourceLength / targetLength);\n      const audioStart = sourceIdx * audioChunkSize;\n      const audioChunk = recording.audio[Math.min(Math.floor(audioStart / audioChunkSize), recording.audio.length - 1)];\n      \n      if (audioChunk) {\n        normalized.audio.push(audioChunk);\n      }\n    }\n    \n    return normalized;\n  }\n  \n  /**\n   * Average new recording data with existing pattern\n   */\n  averagePatternData(pattern, newData) {\n    const sampleCount = pattern.sampleCount;\n    \n    // Weight for averaging: existing data gets more weight as sample count increases\n    const existingWeight = sampleCount / (sampleCount + 1);\n    const newWeight = 1 / (sampleCount + 1);\n    \n    // Average spectrograms\n    pattern.rawData.spectrogram = pattern.rawData.spectrogram.map((existingSpectrum, i) => {\n      const newSpectrum = newData.spectrogram[i] || [];\n      return this.weightedAverageArrays(existingSpectrum, newSpectrum, existingWeight, newWeight);\n    });\n    \n    // Average MFCCs\n    pattern.rawData.mfcc = pattern.rawData.mfcc.map((existingMfcc, i) => {\n      const newMfcc = newData.mfcc[i] || [];\n      return this.weightedAverageArrays(existingMfcc, newMfcc, existingWeight, newWeight);\n    });\n    \n    // Average energy\n    pattern.rawData.energy = pattern.rawData.energy.map((existing, i) => {\n      const newEnergy = newData.energy[i] || 0;\n      return existing * existingWeight + newEnergy * newWeight;\n    });\n    \n    // For audio, we keep the original as we don't directly average audio samples\n    // But we do store the new audio in case it's better quality or more representative\n    if (newData.audio.length > 0) {\n      pattern.rawData.audio = newData.audio;\n    }\n    \n    // Keep original duration (we've already normalized the new recording)\n    pattern.rawData.duration = pattern.rawData.duration;\n  }\n  \n  /**\n   * Weighted average of two arrays\n   */\n  weightedAverageArrays(arrA, arrB, weightA, weightB) {\n    if (!arrA || !arrB) return arrA || arrB || [];\n    \n    const length = Math.min(arrA.length, arrB.length);\n    const result = new Array(length);\n    \n    for (let i = 0; i < length; i++) {\n      result[i] = (arrA[i] || 0) * weightA + (arrB[i] || 0) * weightB;\n    }\n    \n    return result;\n  }\n  \n  /**\n   * Check if multiple patterns exist\n   */\n  checkMultiplePatternsExist() {\n    let count = 0;\n    \n    for (const pattern of this.state.patterns) {\n      if (pattern && pattern.sampleCount > 0) {\n        count++;\n      }\n    }\n    \n    return count > 1;\n  }\n  \n  /**\n   * Average all recorded patterns into one\n   */\n  averageAllPatterns() {\n    try {\n      // Ensure we have at least 2 patterns\n      const validPatterns = this.state.patterns.filter(p => p && p.sampleCount > 0);\n      \n      if (validPatterns.length < 2) {\n        this.log('status', 'Need at least 2 patterns to average');\n        return false;\n      }\n      \n      // Use the first pattern as the base\n      const basePattern = validPatterns[0];\n      \n      // Create a new averaged pattern\n      const averagedPattern = {\n        rawData: {\n          audio: [...basePattern.rawData.audio], // Keep audio from first pattern\n          spectrogram: [...basePattern.rawData.spectrogram],\n          mfcc: [...basePattern.rawData.mfcc],\n          energy: [...basePattern.rawData.energy],\n          duration: basePattern.rawData.duration\n        },\n        segments: [],\n        sampleCount: 0\n      };\n      \n      // Add all other patterns\n      for (let i = 1; i < validPatterns.length; i++) {\n        const pattern = validPatterns[i];\n        const normalized = this.normalizeRecordingLength(\n          pattern.rawData, \n          averagedPattern.rawData\n        );\n        \n        // Average with equal weights\n        const weight = 1 / validPatterns.length;\n        \n        // Average spectrograms\n        averagedPattern.rawData.spectrogram = averagedPattern.rawData.spectrogram.map((existingSpectrum, j) => {\n          const newSpectrum = normalized.spectrogram[j] || [];\n          return this.weightedAverageArrays(\n            existingSpectrum, \n            newSpectrum, \n            1 - weight, \n            weight\n          );\n        });\n        \n        // Average MFCCs\n        averagedPattern.rawData.mfcc = averagedPattern.rawData.mfcc.map((existingMfcc, j) => {\n          const newMfcc = normalized.mfcc[j] || [];\n          return this.weightedAverageArrays(\n            existingMfcc,\n            newMfcc,\n            1 - weight,\n            weight\n          );\n        });\n        \n        // Average energy\n        averagedPattern.rawData.energy = averagedPattern.rawData.energy.map((existing, j) => {\n          const newEnergy = normalized.energy[j] || 0;\n          return existing * (1 - weight) + newEnergy * weight;\n        });\n      }\n      \n      // Set combined sample count\n      averagedPattern.sampleCount = validPatterns.reduce((sum, p) => sum + p.sampleCount, 0);\n      \n      // Segment the pattern\n      averagedPattern.segments = this.segmentPattern(averagedPattern.rawData);\n      \n      // Calculate segment boundaries\n      this.calculateSegmentBoundaries(averagedPattern);\n      \n      // Replace the active pattern with the averaged one\n      this.state.patterns[this.state.activePatternIndex] = averagedPattern;\n      \n      // Update visualization\n      this.state.spectrogramData.pattern = [...averagedPattern.rawData.spectrogram];\n      \n      this.log('status', `Created averaged pattern from ${validPatterns.length} recordings`);\n      return true;\n    } catch (error) {\n      this.handleError('Error averaging patterns', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Set active pattern\n   */\n  setActivePattern(index) {\n    if (index < 0 || index >= this.config.maxPatterns) {\n      return false;\n    }\n    \n    this.state.activePatternIndex = index;\n    \n    // Update visualization if pattern exists\n    const pattern = this.state.patterns[index];\n    if (pattern && pattern.sampleCount > 0) {\n      this.state.spectrogramData.pattern = [...pattern.rawData.spectrogram];\n      \n      if (this.callbacks.onVisualizationUpdate) {\n        this.callbacks.onVisualizationUpdate('patternSwitch', null, pattern);\n      }\n      \n      this.log('status', `Switched to pattern ${index + 1}`);\n    } else {\n      this.state.spectrogramData.pattern = [];\n      \n      this.log('status', `Pattern ${index + 1} is empty`);\n    }\n    \n    return true;\n  }\n  \n  /**\n   * Clear the active pattern\n   */\n  clearActivePattern() {\n    const index = this.state.activePatternIndex;\n    \n    this.state.patterns[index] = null;\n    this.state.spectrogramData.pattern = [];\n    \n    this.log('status', `Cleared pattern ${index + 1}`);\n    \n    // Disable averaging button if needed\n    if (!this.checkMultiplePatternsExist() && this.callbacks.onStatusUpdate) {\n      this.callbacks.onStatusUpdate('control', 'enableAveraging', false);\n    }\n    \n    return true;\n  }\n  \n  /**\n   * Segment pattern into logical parts\n   */\n  segmentPattern(patternData) {\n    try {\n      const segmentCount = this.config.segmentCount;\n      const energy = patternData.energy;\n      const mfcc = patternData.mfcc;\n      const spectrogram = patternData.spectrogram;\n      \n      if (!energy || energy.length === 0) {\n        return [];\n      }\n      \n      // Find segment boundaries\n      let boundaries = [];\n      \n      // Try to find natural boundaries in energy profile\n      const smoothedEnergy = this.smoothArray([...energy], 3);\n      \n      // Find significant peaks and valleys\n      const peaks = this.findPeaks(smoothedEnergy);\n      const valleys = this.findValleys(smoothedEnergy);\n      \n      if (valleys.length >= segmentCount - 1) {\n        // Use valleys as natural breakpoints\n        boundaries = [0, ...valleys, energy.length - 1];\n        \n        // Keep strongest valleys if we have too many\n        while (boundaries.length > segmentCount + 1) {\n          // Find the shallowest valley\n          let shallowestIdx = -1;\n          let shallowestDepth = Infinity;\n          \n          for (let i = 1; i < boundaries.length - 1; i++) {\n            const idx = boundaries[i];\n            const depth = Math.min(\n              smoothedEnergy[idx-1] - smoothedEnergy[idx],\n              smoothedEnergy[idx+1] - smoothedEnergy[idx]\n            );\n            \n            if (depth < shallowestDepth) {\n              shallowestDepth = depth;\n              shallowestIdx = i;\n            }\n          }\n          \n          if (shallowestIdx > 0) {\n            boundaries.splice(shallowestIdx, 1);\n          } else {\n            break;\n          }\n        }\n      } else {\n        // Fallback to equal divisions\n        const segmentSize = Math.floor(energy.length / segmentCount);\n        \n        boundaries = [];\n        for (let i = 0; i <= segmentCount; i++) {\n          boundaries.push(Math.min(i * segmentSize, energy.length - 1));\n        }\n      }\n      \n      // Sort boundaries and remove duplicates\n      boundaries = [...new Set(boundaries)].sort((a, b) => a - b);\n      \n      // Create segments\n      const segments = [];\n      for (let i = 0; i < boundaries.length - 1; i++) {\n        const start = boundaries[i];\n        const end = boundaries[i + 1];\n        \n        // Skip if segment is too small\n        if (end - start < 2) continue;\n        \n        // Create segment data\n        const segment = {\n          index: i,\n          startFrame: start,\n          endFrame: end,\n          frameCount: end - start,\n          // Extract feature slices\n          energy: energy.slice(start, end),\n          mfcc: mfcc.slice(start, end),\n          spectrogram: spectrogram.slice(start, end),\n          // Calculate averages\n          avgEnergy: this.average(energy.slice(start, end)),\n          avgSpectrogram: this.averageSpectrograms(spectrogram.slice(start, end)),\n          avgMfcc: this.averageArrays(mfcc.slice(start, end))\n        };\n        \n        segments.push(segment);\n      }\n      \n      // Ensure we have the requested number of segments by duplicating if necessary\n      while (segments.length < segmentCount) {\n        // Find the longest segment to split\n        let longestIdx = 0;\n        let longestLen = 0;\n        \n        for (let i = 0; i < segments.length; i++) {\n          const len = segments[i].frameCount;\n          if (len > longestLen) {\n            longestLen = len;\n            longestIdx = i;\n          }\n        }\n        \n        // Clone the segment with adjusted boundaries\n        const segment = segments[longestIdx];\n        const midPoint = Math.floor(segment.startFrame + segment.frameCount / 2);\n        \n        // Update original segment\n        const updatedOriginal = {\n          ...segment,\n          endFrame: midPoint,\n          frameCount: midPoint - segment.startFrame,\n          energy: energy.slice(segment.startFrame, midPoint),\n          mfcc: mfcc.slice(segment.startFrame, midPoint),\n          spectrogram: spectrogram.slice(segment.startFrame, midPoint)\n        };\n        \n        // Calculate new averages\n        updatedOriginal.avgEnergy = this.average(updatedOriginal.energy);\n        updatedOriginal.avgSpectrogram = this.averageSpectrograms(updatedOriginal.spectrogram);\n        updatedOriginal.avgMfcc = this.averageArrays(updatedOriginal.mfcc);\n        \n        // Create new segment for second half\n        const newSegment = {\n          index: segment.index + 1,\n          startFrame: midPoint,\n          endFrame: segment.endFrame,\n          frameCount: segment.endFrame - midPoint,\n          energy: energy.slice(midPoint, segment.endFrame),\n          mfcc: mfcc.slice(midPoint, segment.endFrame),\n          spectrogram: spectrogram.slice(midPoint, segment.endFrame)\n        };\n        \n        // Calculate averages for new segment\n        newSegment.avgEnergy = this.average(newSegment.energy);\n        newSegment.avgSpectrogram = this.averageSpectrograms(newSegment.spectrogram);\n        newSegment.avgMfcc = this.averageArrays(newSegment.mfcc);\n        \n        // Replace original segment and insert new one\n        segments[longestIdx] = updatedOriginal;\n        segments.splice(longestIdx + 1, 0, newSegment);\n        \n        // Update indices for all segments after the split\n        for (let i = longestIdx + 2; i < segments.length; i++) {\n          segments[i].index = i;\n        }\n      }\n      \n      // If we have too many segments, merge the smallest adjacent ones\n      while (segments.length > segmentCount) {\n        // Find the smallest adjacent segments\n        let smallestPairIdx = 0;\n        let smallestPairSize = Infinity;\n        \n        for (let i = 0; i < segments.length - 1; i++) {\n          const pairSize = segments[i].frameCount + segments[i + 1].frameCount;\n          if (pairSize < smallestPairSize) {\n            smallestPairSize = pairSize;\n            smallestPairIdx = i;\n          }\n        }\n        \n        // Merge the segments\n        const seg1 = segments[smallestPairIdx];\n        const seg2 = segments[smallestPairIdx + 1];\n        \n        const mergedSegment = {\n          index: seg1.index,\n          startFrame: seg1.startFrame,\n          endFrame: seg2.endFrame,\n          frameCount: seg1.frameCount + seg2.frameCount,\n          energy: [...seg1.energy, ...seg2.energy],\n          mfcc: [...seg1.mfcc, ...seg2.mfcc],\n          spectrogram: [...seg1.spectrogram, ...seg2.spectrogram]\n        };\n        \n        // Calculate new averages\n        mergedSegment.avgEnergy = this.average(mergedSegment.energy);\n        mergedSegment.avgSpectrogram = this.averageSpectrograms(mergedSegment.spectrogram);\n        mergedSegment.avgMfcc = this.averageArrays(mergedSegment.mfcc);\n        \n        // Replace segments\n        segments.splice(smallestPairIdx, 2, mergedSegment);\n        \n        // Update indices\n        for (let i = smallestPairIdx + 1; i < segments.length; i++) {\n          segments[i].index = i;\n        }\n      }\n      \n      return segments;\n    } catch (error) {\n      this.handleError('Error segmenting pattern', error);\n      return [];\n    }\n  }\n  \n  /**\n   * Calculate segment boundaries for visualization\n   */\n  calculateSegmentBoundaries(pattern) {\n    if (!pattern || !pattern.segments || pattern.segments.length === 0) return;\n    \n    // Calculate total frames\n    const totalFrames = pattern.rawData.energy.length;\n    \n    // Calculate boundaries as percentages\n    const boundaries = [];\n    \n    for (const segment of pattern.segments) {\n      const startPct = segment.startFrame / totalFrames;\n      const endPct = segment.endFrame / totalFrames;\n      \n      boundaries.push({\n        start: startPct,\n        end: endPct,\n        index: segment.index\n      });\n    }\n    \n    // Store boundaries\n    pattern.boundaries = boundaries;\n    \n    // Update time markers\n    this.state.timeMarkers.pattern = boundaries.map(b => b.start);\n  }\n  \n  /**\n   * Start detection\n   */\n  async startDetection() {\n    if (this.state.isDetecting) return false;\n    \n    // Get active pattern\n    const pattern = this.state.patterns[this.state.activePatternIndex];\n    \n    // Check if we have a pattern\n    if (!pattern || !pattern.segments || pattern.segments.length === 0) {\n      this.log('status', 'No pattern recorded yet');\n      return false;\n    }\n    \n    // Setup audio\n    const success = await this.setupAudio();\n    if (!success) return false;\n    \n    // Initialize detection state\n    this.state.isDetecting = true;\n    this.state.inCooldown = false;\n    \n    // Clear detection buffer\n    this.state.detectionBuffer = {\n      audio: [],\n      spectrogram: [],\n      mfcc: [],\n      energy: [],\n      timeWindow: []\n    };\n    \n    // Clear spectrogram data\n    this.state.spectrogramData.live = [];\n    \n    // Reset sequence state\n    this.resetSequenceState();\n    \n    // Create processor node\n    this.processor = this.audioContext.createScriptProcessor(\n      this.config.bufferSize, 1, 1\n    );\n    \n    // Store start time\n    const detectionStartTime = Date.now();\n    \n    // Process audio data for detection\n    this.processor.onaudioprocess = (event) => {\n      if (!this.state.isDetecting) return;\n      \n      try {\n        // Get audio data\n        const inputData = event.inputBuffer.getChannelData(0);\n        const audioData = new Float32Array(inputData.length);\n        audioData.set(inputData);\n        \n        // Extract features\n        const features = this.extractFeatures(audioData);\n        \n        // Current time in detection\n        const currentTime = Date.now() - detectionStartTime;\n        \n        // Add to detection buffer\n        this.state.detectionBuffer.audio.push(audioData);\n        this.state.detectionBuffer.spectrogram.push(features.spectrogram);\n        this.state.detectionBuffer.mfcc.push(features.mfcc);\n        this.state.detectionBuffer.energy.push(features.energy);\n        this.state.detectionBuffer.timeWindow.push(currentTime);\n        \n        // Update spectrogram data\n        this.state.spectrogramData.live.push(features.spectrogram);\n        \n        // Trim buffer to manageable size\n        this.trimDetectionBuffer();\n        \n        // Update visualization\n        if (this.callbacks.onVisualizationUpdate) {\n          this.callbacks.onVisualizationUpdate('detection', audioData, features);\n        }\n        \n        // Process detection if not in cooldown\n        if (!this.state.inCooldown) {\n          this.detectPattern();\n        }\n      } catch (error) {\n        this.handleError('Error in detection process', error);\n      }\n    };\n    \n    // Connect audio nodes\n    const source = this.audioContext.createMediaStreamSource(this.mediaStream);\n    source.connect(this.analyzer);\n    source.connect(this.processor);\n    this.processor.connect(this.audioContext.destination);\n    \n    // Start animation loop for cursor\n    this.startAnimationLoop();\n    \n    this.log('status', 'Listening for pattern...');\n    return true;\n  }\n  \n  /**\n   * Stop detection\n   */\n  stopDetection() {\n    if (!this.state.isDetecting) return false;\n    \n    // Update state\n    this.state.isDetecting = false;\n    this.state.inCooldown = false;\n    \n    // Stop animation\n    this.stopAnimationLoop();\n    \n    // Clean up\n    if (this.processor) {\n      this.processor.disconnect();\n      this.processor = null;\n    }\n    \n    // Reset sequence state\n    this.resetSequenceState();\n    \n    // Update progress\n    if (this.callbacks.onProgressUpdate) {\n      this.callbacks.onProgressUpdate(this.state.sequenceState);\n    }\n    \n    this.log('status', 'Detection stopped');\n    return true;\n  }\n  \n  /**\n   * Reset counter\n   */\n  resetCounter() {\n    this.state.counter = 0;\n    this.log('status', 'Counter reset to 0');\n    \n    if (this.callbacks.onDetection) {\n      this.callbacks.onDetection(0, 0);\n    }\n    \n    return true;\n  }\n  \n  /**\n   * Reset sequence state\n   */\n  resetSequenceState() {\n    // Get active pattern\n    const pattern = this.state.patterns[this.state.activePatternIndex];\n    \n    if (!pattern || !pattern.segments) {\n      this.state.sequenceState = {\n        segments: [],\n        currentIndex: 0,\n        progress: 0,\n        matchScores: [],\n        segmentStartTimes: [],\n        stuckTime: 0,\n        lastAdvanceTime: 0\n      };\n      return;\n    }\n    \n    // Initialize sequence tracking\n    this.state.sequenceState = {\n      segments: pattern.segments.map(() => 'pending'),\n      currentIndex: 0,\n      progress: 0,\n      matchScores: pattern.segments.map(() => 0),\n      segmentStartTimes: [],\n      stuckTime: 0,\n      lastAdvanceTime: Date.now()\n    };\n    \n    // Update visualization\n    if (this.callbacks.onProgressUpdate) {\n      this.callbacks.onProgressUpdate(this.state.sequenceState);\n    }\n  }\n  \n  /**\n   * Trim detection buffer\n   */\n  trimDetectionBuffer() {\n    // Get active pattern\n    const pattern = this.state.patterns[this.state.activePatternIndex];\n    if (!pattern) return;\n    \n    // Maximum frames to keep (3x pattern length for better endpoint detection)\n    const maxFrames = Math.max(\n      200, // Increased from 150 to provide more context\n      pattern.segments.reduce((sum, s) => sum + s.frameCount, 0) * 3 // Increased multiplier for better last segment detection\n    );\n    \n    if (this.state.detectionBuffer.energy.length > maxFrames) {\n      const framesToRemove = this.state.detectionBuffer.energy.length - maxFrames;\n      \n      // Trim all buffer arrays\n      this.state.detectionBuffer.audio.splice(0, framesToRemove);\n      this.state.detectionBuffer.spectrogram.splice(0, framesToRemove);\n      this.state.detectionBuffer.mfcc.splice(0, framesToRemove);\n      this.state.detectionBuffer.energy.splice(0, framesToRemove);\n      this.state.detectionBuffer.timeWindow.splice(0, framesToRemove);\n    }\n    \n    // Also trim spectrogram history\n    if (this.state.spectrogramData.live.length > this.config.spectrogramHistory) {\n      this.state.spectrogramData.live.splice(\n        0, \n        this.state.spectrogramData.live.length - this.config.spectrogramHistory\n      );\n    }\n  }\n  \n  /**\n   * Core detection algorithm\n   */\n  detectPattern() {\n    try {\n      // Get active pattern\n      const pattern = this.state.patterns[this.state.activePatternIndex];\n      if (!pattern || !pattern.segments || pattern.segments.length === 0) {\n        return false;\n      }\n      \n      // Check if we have enough data\n      if (this.state.detectionBuffer.energy.length < 10) {\n        return false;\n      }\n      \n      // Get current sequence state\n      const sequenceState = this.state.sequenceState;\n      const currentIndex = sequenceState.currentIndex;\n      \n      // Get the target segment\n      const segment = pattern.segments[currentIndex];\n      if (!segment) return false;\n      \n      // Use different detection strategies based on mode\n      let result;\n      \n      switch (this.config.detectionMode) {\n        case 'flexible':\n          result = this.flexibleSequentialDetection(pattern);\n          break;\n        case 'adaptive':\n          result = this.adaptiveDetection(pattern);\n          break;\n        case 'sequential':\n        default:\n          result = this.strictSequentialDetection(pattern);\n          break;\n      }\n      \n      // Process result\n      if (result) {\n        // Update progress visualization\n        if (this.callbacks.onProgressUpdate) {\n          this.callbacks.onProgressUpdate(this.state.sequenceState, result.debugInfo);\n        }\n        \n        // Check if we detected the full pattern\n        if (result.patternDetected) {\n          this.registerDetection(result.confidence);\n        }\n        \n        return result.patternDetected;\n      }\n      \n      return false;\n    } catch (error) {\n      this.handleError('Error in pattern detection', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Strict sequential detection algorithm\n   */\n  strictSequentialDetection(pattern) {\n    // Current sequence state\n    const sequenceState = this.state.sequenceState;\n    const currentIndex = sequenceState.currentIndex;\n    \n    // Current segment\n    const segment = pattern.segments[currentIndex];\n    \n    // Get recent frames for matching\n    const windowSize = Math.min(segment.frameCount * 2, this.state.detectionBuffer.energy.length);\n    const recentFrames = {\n      energy: this.state.detectionBuffer.energy.slice(-windowSize),\n      mfcc: this.state.detectionBuffer.mfcc.slice(-windowSize),\n      spectrogram: this.state.detectionBuffer.spectrogram.slice(-windowSize)\n    };\n    \n    // Calculate match score for current segment\n    const matchScore = this.calculateSegmentMatch(recentFrames, segment);\n    \n    // Update match scores\n    sequenceState.matchScores[currentIndex] = matchScore;\n    \n    // Current time\n    const now = Date.now();\n    \n    // Check for timeout on current segment\n    if (sequenceState.segments[currentIndex] === 'active') {\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      \n      if (timeInSegment > this.config.segmentTimeout) {\n        // Stuck too long, reset\n        this.log('info', `Timeout on segment ${currentIndex + 1}`);\n        this.resetSequenceState();\n        return {\n          patternDetected: false,\n          confidence: 0,\n          debugInfo: {\n            currentSegment: 1,\n            matchScore: 0,\n            timeout: true\n          }\n        };\n      }\n    }\n    \n    // Debug info\n    const debugInfo = {\n      currentSegment: currentIndex + 1,\n      totalSegments: pattern.segments.length,\n      matchScore: matchScore,\n      threshold: this.config.minMatchThreshold\n    };\n    \n    // Adjust threshold for final segment to make it easier to detect\n    let adjustedThreshold = this.config.minMatchThreshold;\n    let adjustedAdvanceThreshold = this.config.advanceThreshold;\n    \n    // Make final segment easier to detect\n    if (currentIndex === pattern.segments.length - 1) {\n      adjustedThreshold *= this.config.finalSegmentBoost;\n      adjustedAdvanceThreshold *= this.config.finalSegmentBoost;\n      debugInfo.finalSegmentBoost = true;\n      debugInfo.adjustedThreshold = adjustedThreshold;\n    }\n    \n    // Handle current segment based on match score\n    if (matchScore >= adjustedThreshold) {\n      // If we just started matching this segment, record the start time\n      if (sequenceState.segments[currentIndex] === 'pending') {\n        sequenceState.segments[currentIndex] = 'active';\n        sequenceState.segmentStartTimes[currentIndex] = now;\n        sequenceState.lastAdvanceTime = now;\n        this.log('info', `Matching segment ${currentIndex + 1}/${pattern.segments.length}`);\n      }\n      \n      // Check if we've been matching long enough to advance\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      const minSegmentTime = Math.max(\n        200,  // Reduced from 300ms for more responsive detection\n        (segment.frameCount / pattern.rawData.energy.length) * pattern.rawData.duration * 0.4 // Reduced from 0.5 for quicker progression\n      );\n      \n      if (timeInSegment >= minSegmentTime && matchScore >= adjustedAdvanceThreshold) {\n        // Mark segment as complete\n        sequenceState.segments[currentIndex] = 'complete';\n        \n        // Check if this was the last segment\n        if (currentIndex === pattern.segments.length - 1) {\n          // Completed the full pattern\n          return {\n            patternDetected: true,\n            confidence: this.calculateOverallConfidence(),\n            debugInfo: {\n              ...debugInfo,\n              timeInSegment,\n              minSegmentTime,\n              completed: true\n            }\n          };\n        } else {\n          // Move to next segment\n          sequenceState.currentIndex++;\n          sequenceState.lastAdvanceTime = now;\n          this.log('info', `Advanced to segment ${sequenceState.currentIndex + 1}/${pattern.segments.length}`);\n          \n          // Add progress data to debug info\n          debugInfo.advanced = true;\n          debugInfo.nextSegment = sequenceState.currentIndex + 1;\n        }\n      }\n      \n      // Add timing to debug info\n      debugInfo.timeInSegment = timeInSegment;\n      debugInfo.minSegmentTime = minSegmentTime;\n    } else {\n      // If we were matching but lost it, mark as invalid\n      if (sequenceState.segments[currentIndex] === 'active') {\n        sequenceState.segments[currentIndex] = 'invalid';\n        this.log('info', `Lost match for segment ${currentIndex + 1}`);\n        \n        // Reset after a short delay\n        setTimeout(() => {\n          // Only reset if we're still on this segment and still invalid\n          if (this.state.isDetecting && \n              this.state.sequenceState.currentIndex === currentIndex &&\n              this.state.sequenceState.segments[currentIndex] === 'invalid') {\n            this.resetSequenceState();\n            this.log('info', 'Reset sequence state');\n          }\n        }, 300);\n      }\n    }\n    \n    // Calculate overall progress\n    const completedSegments = sequenceState.segments.filter(s => s === 'complete').length;\n    const activeSegment = sequenceState.segments.indexOf('active');\n    \n    if (activeSegment !== -1) {\n      // Include partial progress of active segment\n      const activeProgress = matchScore * (1 / pattern.segments.length);\n      sequenceState.progress = (completedSegments / pattern.segments.length) + activeProgress;\n    } else {\n      sequenceState.progress = completedSegments / pattern.segments.length;\n    }\n    \n    // Add progress to debug info\n    debugInfo.progress = sequenceState.progress;\n    debugInfo.segments = [...sequenceState.segments];\n    \n    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };\n  }\n  \n  /**\n   * Flexible sequential detection\n   * Allows some segments to be skipped or detected out of order\n   */\n  flexibleSequentialDetection(pattern) {\n    // Current sequence state\n    const sequenceState = this.state.sequenceState;\n    const currentIndex = sequenceState.currentIndex;\n    \n    // Calculate match scores for all segments\n    const matchScores = pattern.segments.map((segment, i) => {\n      // Get window size based on segment size\n      const windowSize = Math.min(segment.frameCount * 2, this.state.detectionBuffer.energy.length);\n      \n      // Get recent frames\n      const recentFrames = {\n        energy: this.state.detectionBuffer.energy.slice(-windowSize),\n        mfcc: this.state.detectionBuffer.mfcc.slice(-windowSize),\n        spectrogram: this.state.detectionBuffer.spectrogram.slice(-windowSize)\n      };\n      \n      // Calculate match score\n      return this.calculateSegmentMatch(recentFrames, segment);\n    });\n    \n    // Update match scores\n    sequenceState.matchScores = matchScores;\n    \n    // Find best matching segment\n    const bestMatchIndex = matchScores.indexOf(Math.max(...matchScores));\n    const bestMatchScore = matchScores[bestMatchIndex];\n    \n    // Current time\n    const now = Date.now();\n    \n    // Debug info\n    const debugInfo = {\n      currentSegment: currentIndex + 1,\n      totalSegments: pattern.segments.length,\n      matchScores,\n      bestMatchIndex: bestMatchIndex + 1,\n      bestMatchScore,\n      threshold: this.config.minMatchThreshold\n    };\n    \n    // Check for timeout\n    if (sequenceState.segments[currentIndex] === 'active') {\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      \n      if (timeInSegment > this.config.segmentTimeout) {\n        // Check if a later segment is matching better\n        if (bestMatchIndex > currentIndex && bestMatchScore >= this.config.advanceThreshold) {\n          // Skip to that segment\n          for (let i = currentIndex; i < bestMatchIndex; i++) {\n            sequenceState.segments[i] = 'complete';\n          }\n          sequenceState.currentIndex = bestMatchIndex;\n          sequenceState.segmentStartTimes[bestMatchIndex] = now;\n          sequenceState.segments[bestMatchIndex] = 'active';\n          sequenceState.lastAdvanceTime = now;\n          \n          this.log('info', `Skipped to segment ${bestMatchIndex + 1} (better match)`);\n          \n          // Update debug info\n          debugInfo.skipped = true;\n          debugInfo.skippedTo = bestMatchIndex + 1;\n        } else {\n          // Reset if stuck too long with no better matches\n          this.log('info', `Timeout on segment ${currentIndex + 1}`);\n          this.resetSequenceState();\n          \n          // Update debug info\n          debugInfo.timeout = true;\n          \n          return {\n            patternDetected: false,\n            confidence: 0,\n            debugInfo\n          };\n        }\n      }\n    }\n    \n    // Adjust threshold for final segment to make it easier to detect\n    if (currentIndex === pattern.segments.length - 1) {\n      debugInfo.finalSegmentBoost = true;\n      debugInfo.adjustedThreshold = this.config.minMatchThreshold * this.config.finalSegmentBoost;\n    }\n    \n    // Current segment match\n    const currentMatch = matchScores[currentIndex];\n    \n    // Forward lookahead - if a later segment is matching very well\n    if (sequenceState.segments[currentIndex] === 'pending' && currentMatch < this.config.minMatchThreshold) {\n      // Check if any later segment is matching well\n      for (let i = currentIndex + 1; i < matchScores.length; i++) {\n        if (matchScores[i] >= this.config.minMatchThreshold * 1.2) {\n          // Skip to this segment\n          sequenceState.currentIndex = i;\n          sequenceState.segments[i] = 'active';\n          sequenceState.segmentStartTimes[i] = now;\n          sequenceState.lastAdvanceTime = now;\n          \n          this.log('info', `Jumped to segment ${i + 1} (strong match)`);\n          \n          // Update debug info\n          debugInfo.jumped = true;\n          debugInfo.jumpedTo = i + 1;\n          \n          break;\n        }\n      }\n    }\n    \n    // Update current index after possible jumps\n    const updatedCurrentIndex = sequenceState.currentIndex;\n    const currentSegment = pattern.segments[updatedCurrentIndex];\n    \n    // Adjust threshold for final segment\n    let adjustedThreshold = this.config.minMatchThreshold;\n    let adjustedAdvanceThreshold = this.config.advanceThreshold;\n    \n    // Make the final segment easier to detect\n    if (updatedCurrentIndex === pattern.segments.length - 1) {\n      adjustedThreshold *= this.config.finalSegmentBoost;\n      adjustedAdvanceThreshold *= this.config.finalSegmentBoost;\n    }\n    \n    // Handle current segment based on match score\n    if (matchScores[updatedCurrentIndex] >= adjustedThreshold) {\n      // If we just started matching this segment, record the start time\n      if (sequenceState.segments[updatedCurrentIndex] === 'pending') {\n        sequenceState.segments[updatedCurrentIndex] = 'active';\n        sequenceState.segmentStartTimes[updatedCurrentIndex] = now;\n        sequenceState.lastAdvanceTime = now;\n        this.log('info', `Matching segment ${updatedCurrentIndex + 1}/${pattern.segments.length}`);\n      }\n      \n      // Check if we've been matching long enough to advance\n      const timeInSegment = now - (sequenceState.segmentStartTimes[updatedCurrentIndex] || now);\n      const minSegmentTime = Math.max(\n        200,  // Shorter minimum time for flexible mode\n        (currentSegment.frameCount / pattern.rawData.energy.length) * pattern.rawData.duration * 0.3 // Even shorter for flexible mode\n      );\n      \n      // Add timing to debug info\n      debugInfo.timeInSegment = timeInSegment;\n      debugInfo.minSegmentTime = minSegmentTime;\n      \n      // For the last segment, allow even shorter minimum time\n      const isLastSegment = updatedCurrentIndex === pattern.segments.length - 1;\n      const effectiveMinTime = isLastSegment ? minSegmentTime * 0.75 : minSegmentTime;\n      \n      if (timeInSegment >= effectiveMinTime && matchScores[updatedCurrentIndex] >= adjustedAdvanceThreshold) {\n        // Mark segment as complete\n        sequenceState.segments[updatedCurrentIndex] = 'complete';\n        \n        // Check if this was the last segment\n        if (updatedCurrentIndex === pattern.segments.length - 1) {\n          // Completed the full pattern\n          return {\n            patternDetected: true,\n            confidence: this.calculateOverallConfidence(),\n            debugInfo: {\n              ...debugInfo,\n              completed: true\n            }\n          };\n        } else {\n          // Move to next segment\n          sequenceState.currentIndex++;\n          sequenceState.lastAdvanceTime = now;\n          this.log('info', `Advanced to segment ${sequenceState.currentIndex + 1}/${pattern.segments.length}`);\n          \n          // Add progress data to debug info\n          debugInfo.advanced = true;\n          debugInfo.nextSegment = sequenceState.currentIndex + 1;\n        }\n      }\n    } else {\n      // If we were matching but lost it, check if a different segment matches better\n      if (sequenceState.segments[updatedCurrentIndex] === 'active') {\n        // If best match is a different segment with a good score\n        if (bestMatchIndex !== updatedCurrentIndex && bestMatchScore >= this.config.minMatchThreshold) {\n          // If it's a later segment, skip to it\n          if (bestMatchIndex > updatedCurrentIndex) {\n            // Mark all segments up to best match as complete\n            for (let i = updatedCurrentIndex; i < bestMatchIndex; i++) {\n              sequenceState.segments[i] = 'complete';\n            }\n            \n            sequenceState.currentIndex = bestMatchIndex;\n            sequenceState.segments[bestMatchIndex] = 'active';\n            sequenceState.segmentStartTimes[bestMatchIndex] = now;\n            sequenceState.lastAdvanceTime = now;\n            \n            this.log('info', `Skipped to segment ${bestMatchIndex + 1} (better match)`);\n            \n            // Update debug info\n            debugInfo.skipped = true;\n            debugInfo.skippedTo = bestMatchIndex + 1;\n          } \n          // If it's an earlier segment, allow jumping back\n          else if (bestMatchIndex < updatedCurrentIndex) {\n            // Only jump back if the score is significantly better\n            if (bestMatchScore > matchScores[updatedCurrentIndex] * 1.5) {\n              // Reset segments after best match\n              for (let i = bestMatchIndex + 1; i < sequenceState.segments.length; i++) {\n                sequenceState.segments[i] = 'pending';\n              }\n              \n              sequenceState.currentIndex = bestMatchIndex;\n              sequenceState.segments[bestMatchIndex] = 'active';\n              sequenceState.segmentStartTimes[bestMatchIndex] = now;\n              sequenceState.lastAdvanceTime = now;\n              \n              this.log('info', `Jumped back to segment ${bestMatchIndex + 1} (much better match)`);\n              \n              // Update debug info\n              debugInfo.jumpedBack = true;\n              debugInfo.jumpedBackTo = bestMatchIndex + 1;\n            }\n          }\n        } else {\n          // Mark as invalid if no better matches found\n          sequenceState.segments[updatedCurrentIndex] = 'invalid';\n          this.log('info', `Lost match for segment ${updatedCurrentIndex + 1}`);\n          \n          // Reset after a short delay\n          setTimeout(() => {\n            if (this.state.isDetecting && \n                this.state.sequenceState.currentIndex === updatedCurrentIndex &&\n                this.state.sequenceState.segments[updatedCurrentIndex] === 'invalid') {\n              this.resetSequenceState();\n              this.log('info', 'Reset sequence state');\n            }\n          }, 300);\n        }\n      }\n    }\n    \n    // Calculate overall progress\n    const completedSegments = sequenceState.segments.filter(s => s === 'complete').length;\n    const activeSegment = sequenceState.segments.indexOf('active');\n    \n    if (activeSegment !== -1) {\n      // Include partial progress of active segment\n      const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);\n      sequenceState.progress = (completedSegments / pattern.segments.length) + activeProgress;\n    } else {\n      sequenceState.progress = completedSegments / pattern.segments.length;\n    }\n    \n    // Add progress to debug info\n    debugInfo.progress = sequenceState.progress;\n    debugInfo.segments = [...sequenceState.segments];\n    \n    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };\n  }\n  \n  /**\n   * Adaptive detection that self-adjusts based on input\n   */\n  adaptiveDetection(pattern) {\n    // Current sequence state\n    const sequenceState = this.state.sequenceState;\n    const currentIndex = sequenceState.currentIndex;\n    \n    // Calculate match scores for all segments with larger window for final segment\n    const matchScores = pattern.segments.map((segment, i) => {\n      // Use larger window for the final segment to improve detection\n      const isLastSegment = i === pattern.segments.length - 1;\n      const windowMultiplier = isLastSegment ? 3 : 2;\n      \n      // Get window size based on segment size\n      const windowSize = Math.min(\n        segment.frameCount * windowMultiplier, \n        this.state.detectionBuffer.energy.length\n      );\n      \n      // Get recent frames\n      const recentFrames = {\n        energy: this.state.detectionBuffer.energy.slice(-windowSize),\n        mfcc: this.state.detectionBuffer.mfcc.slice(-windowSize),\n        spectrogram: this.state.detectionBuffer.spectrogram.slice(-windowSize)\n      };\n      \n      // Calculate match score with adaptive feature weights\n      let featureWeights = {...this.config.featureWeights};\n      \n      // Adjust weights based on segment position\n      if (isLastSegment) {\n        // For last segment, emphasize spectrogram for better pattern ending detection\n        featureWeights.spectrogram = 0.6;\n        featureWeights.energy = 0.3;\n        featureWeights.mfcc = 0.1;\n      } else if (i === 0) {\n        // For first segment, balanced approach\n        featureWeights.spectrogram = 0.4;\n        featureWeights.energy = 0.3;\n        featureWeights.mfcc = 0.3;\n      }\n      \n      // Calculate match with custom weights\n      return this.calculateSegmentMatch(recentFrames, segment, featureWeights);\n    });\n    \n    // Update match scores\n    sequenceState.matchScores = matchScores;\n    \n    // Find best matching segment\n    const bestMatchIndex = matchScores.indexOf(Math.max(...matchScores));\n    const bestMatchScore = matchScores[bestMatchIndex];\n    \n    // Current time\n    const now = Date.now();\n    \n    // Debug info\n    const debugInfo = {\n      currentSegment: currentIndex + 1,\n      totalSegments: pattern.segments.length,\n      matchScores,\n      bestMatchIndex: bestMatchIndex + 1,\n      bestMatchScore,\n      mode: 'adaptive'\n    };\n    \n    // Dynamically adjust thresholds based on where we are in the pattern\n    const baseMatchThreshold = this.config.minMatchThreshold;\n    const baseAdvanceThreshold = this.config.advanceThreshold;\n    \n    // Progressive adjustment - easier thresholds for later segments\n    const progress = currentIndex / (pattern.segments.length - 1);\n    const progressAdjustment = 1.0 - (0.2 * progress); // Up to 20% easier for final segment\n    \n    let currentMatchThreshold = baseMatchThreshold * progressAdjustment;\n    let currentAdvanceThreshold = baseAdvanceThreshold * progressAdjustment;\n    \n    // Special case for final segment\n    if (currentIndex === pattern.segments.length - 1) {\n      // Make final segment significantly easier to detect\n      currentMatchThreshold *= this.config.finalSegmentBoost;\n      currentAdvanceThreshold *= this.config.finalSegmentBoost;\n      debugInfo.finalSegmentBoost = true;\n    }\n    \n    // Check for timeout on current segment\n    if (sequenceState.segments[currentIndex] === 'active') {\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      \n      // Gradually reduce threshold the longer we stay in a segment\n      const timeoutAdjustment = Math.max(0.7, 1.0 - (timeInSegment / this.config.segmentTimeout * 0.3));\n      currentMatchThreshold *= timeoutAdjustment;\n      currentAdvanceThreshold *= timeoutAdjustment;\n      \n      debugInfo.timeInSegment = timeInSegment;\n      debugInfo.timeoutAdjustment = timeoutAdjustment;\n      \n      // If really stuck for a long time, try skipping ahead\n      if (timeInSegment > this.config.segmentTimeout * 0.8) {\n        // Check if a later segment matches well\n        for (let i = currentIndex + 1; i < matchScores.length; i++) {\n          if (matchScores[i] >= baseMatchThreshold * 0.8) {\n            // Skip to this segment\n            for (let j = currentIndex; j < i; j++) {\n              sequenceState.segments[j] = 'complete';\n            }\n            \n            sequenceState.currentIndex = i;\n            sequenceState.segments[i] = 'active';\n            sequenceState.segmentStartTimes[i] = now;\n            sequenceState.lastAdvanceTime = now;\n            \n            this.log('info', `Adaptive skip to segment ${i + 1} (timeout recovery)`);\n            \n            debugInfo.adaptiveSkip = true;\n            debugInfo.skippedTo = i + 1;\n            debugInfo.reason = 'timeout';\n            \n            // Check if we skipped to the last segment\n            if (i === pattern.segments.length - 1) {\n              // If the last segment has a good match, consider the pattern detected\n              if (matchScores[i] >= baseMatchThreshold * 0.9) {\n                // Calculate a confidence penalty for skipping\n                const confidencePenalty = 0.8;\n                \n                return {\n                  patternDetected: true,\n                  confidence: this.calculateOverallConfidence() * confidencePenalty,\n                  debugInfo: {\n                    ...debugInfo,\n                    completed: true,\n                    confidencePenalty\n                  }\n                };\n              }\n            }\n            \n            return {\n              patternDetected: false,\n              confidence: this.calculateOverallConfidence(),\n              debugInfo\n            };\n          }\n        }\n        \n        // If no good skips found, eventually reset\n        if (timeInSegment > this.config.segmentTimeout) {\n          this.log('info', `Adaptive reset (timeout)`);\n          this.resetSequenceState();\n          \n          debugInfo.adaptiveReset = true;\n          debugInfo.reason = 'full timeout';\n          \n          return {\n            patternDetected: false,\n            confidence: 0,\n            debugInfo\n          };\n        }\n      }\n    }\n    \n    // Handle current segment based on match score\n    if (matchScores[currentIndex] >= currentMatchThreshold) {\n      // If we just started matching this segment, record the start time\n      if (sequenceState.segments[currentIndex] === 'pending') {\n        sequenceState.segments[currentIndex] = 'active';\n        sequenceState.segmentStartTimes[currentIndex] = now;\n        sequenceState.lastAdvanceTime = now;\n        this.log('info', `Matching segment ${currentIndex + 1}/${pattern.segments.length}`);\n      }\n      \n      // Check if we've been matching long enough to advance\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      \n      // Adaptive minimum time based on segment position\n      let minSegmentTime = Math.max(\n        150, // Base minimum time (reduced for adaptive mode)\n        (pattern.segments[currentIndex].frameCount / pattern.rawData.energy.length) \n          * pattern.rawData.duration \n          * (0.4 - 0.1 * progress) // Progressively shorter required match time\n      );\n      \n      // For the final segment, reduce time requirement further\n      if (currentIndex === pattern.segments.length - 1) {\n        minSegmentTime *= 0.7;\n      }\n      \n      debugInfo.timeInSegment = timeInSegment;\n      debugInfo.minSegmentTime = minSegmentTime;\n      debugInfo.matchThreshold = currentMatchThreshold;\n      debugInfo.advanceThreshold = currentAdvanceThreshold;\n      \n      if (timeInSegment >= minSegmentTime && matchScores[currentIndex] >= currentAdvanceThreshold) {\n        // Mark segment as complete\n        sequenceState.segments[currentIndex] = 'complete';\n        \n        // Check if this was the last segment\n        if (currentIndex === pattern.segments.length - 1) {\n          // Completed the full pattern\n          return {\n            patternDetected: true,\n            confidence: this.calculateOverallConfidence(),\n            debugInfo: {\n              ...debugInfo,\n              completed: true\n            }\n          };\n        } else {\n          // Move to next segment\n          sequenceState.currentIndex++;\n          sequenceState.lastAdvanceTime = now;\n          this.log('info', `Advanced to segment ${sequenceState.currentIndex + 1}/${pattern.segments.length}`);\n          \n          // Add progress data to debug info\n          debugInfo.advanced = true;\n          debugInfo.nextSegment = sequenceState.currentIndex + 1;\n        }\n      }\n    } else {\n      // If we lost the match, check if a better matching segment exists\n      if (sequenceState.segments[currentIndex] === 'active') {\n        const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n        \n        // If stuck for a little while, check for better matches\n        if (timeInSegment > this.config.segmentTimeout * 0.3) {\n          // If a significantly better match exists elsewhere\n          if (bestMatchIndex !== currentIndex && bestMatchScore > matchScores[currentIndex] * 1.3) {\n            // If it's a later segment, consider skipping\n            if (bestMatchIndex > currentIndex) {\n              // Mark segments as complete up to the best match\n              for (let i = currentIndex; i < bestMatchIndex; i++) {\n                sequenceState.segments[i] = 'complete';\n              }\n              \n              sequenceState.currentIndex = bestMatchIndex;\n              sequenceState.segments[bestMatchIndex] = 'active';\n              sequenceState.segmentStartTimes[bestMatchIndex] = now;\n              sequenceState.lastAdvanceTime = now;\n              \n              this.log('info', `Adaptive skip to segment ${bestMatchIndex + 1} (better match)`);\n              \n              debugInfo.adaptiveSkip = true;\n              debugInfo.skippedTo = bestMatchIndex + 1;\n              debugInfo.reason = 'better match';\n              \n              // If we skipped to the last segment, check for completion\n              if (bestMatchIndex === pattern.segments.length - 1 && bestMatchScore >= baseMatchThreshold * 0.9) {\n                const confidencePenalty = 0.9;\n                \n                return {\n                  patternDetected: true,\n                  confidence: this.calculateOverallConfidence() * confidencePenalty,\n                  debugInfo: {\n                    ...debugInfo,\n                    completed: true,\n                    confidencePenalty\n                  }\n                };\n              }\n            }\n            // Allow jumping backward only in extreme cases\n            else if (bestMatchIndex < currentIndex && bestMatchScore > matchScores[currentIndex] * 2) {\n              // Reset segments after the best match\n              for (let i = bestMatchIndex + 1; i < sequenceState.segments.length; i++) {\n                sequenceState.segments[i] = 'pending';\n              }\n              \n              sequenceState.currentIndex = bestMatchIndex;\n              sequenceState.segments[bestMatchIndex] = 'active';\n              sequenceState.segmentStartTimes[bestMatchIndex] = now;\n              sequenceState.lastAdvanceTime = now;\n              \n              this.log('info', `Adaptive jump back to segment ${bestMatchIndex + 1} (much better match)`);\n              \n              debugInfo.adaptiveJumpBack = true;\n              debugInfo.jumpedBackTo = bestMatchIndex + 1;\n            }\n          } else {\n            // If we've been stuck for a while with no better options, mark as invalid\n            if (timeInSegment > this.config.segmentTimeout * 0.6) {\n              sequenceState.segments[currentIndex] = 'invalid';\n              this.log('info', `Lost match for segment ${currentIndex + 1}`);\n              \n              // Reset after a short delay\n              setTimeout(() => {\n                if (this.state.isDetecting && \n                    this.state.sequenceState.currentIndex === currentIndex &&\n                    this.state.sequenceState.segments[currentIndex] === 'invalid') {\n                  this.resetSequenceState();\n                  this.log('info', 'Reset sequence state');\n                }\n              }, 250); // Shorter reset delay for adaptive mode\n            }\n          }\n        }\n      }\n    }\n    \n    // Calculate overall progress\n    const completedSegments = sequenceState.segments.filter(s => s === 'complete').length;\n    const activeSegment = sequenceState.segments.indexOf('active');\n    \n    if (activeSegment !== -1) {\n      // Include partial progress of active segment\n      const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);\n      ",
              "language": "javascript",
              "version_uuid": "1be97589-78b7-4ec8-ac6a-f9a5982f04cd"
            },
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          }
        ],
        "updated_at": "2025-03-17T16:49:44.787858Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "20269f06-2773-4533-a346-15e476572fcc",
      "role": "human",
      "content": "stopped generating here, can you continue the code from where you left off: // Calculate overall progress const completedSegments = sequenceState.segments.filter(s => s === 'complete').length; const activeSegment = sequenceState.segments.indexOf('active'); if (activeSegment !== -1) { // Include partial progress of active segment const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);",
      "created_at": "2025-03-17T16:51:06.087268Z",
      "sequence_order": 2,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-03-17T14:30:23.332131Z",
            "stop_timestamp": "2025-03-17T14:30:23.332131Z",
            "flags": null,
            "type": "text",
            "text": "stopped generating here, can you continue the code from where you left off: // Calculate overall progress const completedSegments = sequenceState.segments.filter(s => s === 'complete').length; const activeSegment = sequenceState.segments.indexOf('active'); if (activeSegment !== -1) { // Include partial progress of active segment const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);",
            "citations": []
          }
        ],
        "updated_at": "2025-03-17T16:51:06.087268Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "e55fdf78-c7e7-49cd-9a99-484e32cb1712",
      "role": "assistant",
      "content": "\nI need to continue implementing the EnhancedChantDetector class from where it left off. Looking at the code, I was in the middle of the `adaptiveDetection` method and specifically, calculating the overall progress. Let me continue from there and complete the full implementation of the method and the rest of the class.\n\nI'll need to:\n1. Complete the adaptiveDetection method\n2. Implement the remaining methods (calculateSegmentMatch, registerDetection, calculateOverallConfidence, etc.)\n3. Complete the script section with the UI initialization and integration\n4. Add any remaining functionality for the improved chant detector\n\nLet's continue from the exact point where the generation stopped.\n\nLet me continue the code from where it left off:\n```\nViewing artifacts created via the Analysis Tool web feature preview isnt yet supported on mobile.\n```\n\n\n\nLet me continue implementing the rest of the EnhancedChantDetector class:\n```\nViewing artifacts created via the Analysis Tool web feature preview isnt yet supported on mobile.\n```\n\n\n\nLet me continue by adding more methods to the class:\n```\nViewing artifacts created via the Analysis Tool web feature preview isnt yet supported on mobile.\n```\n\n\n\n\n\nLet's continue with the feature extraction and more utility methods:\n```\nViewing artifacts created via the Analysis Tool web feature preview isnt yet supported on mobile.\n```\n",
      "created_at": "2025-03-17T16:52:02.503019Z",
      "sequence_order": 3,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-03-17T16:51:08.315216Z",
            "stop_timestamp": "2025-03-17T16:51:10.907741Z",
            "flags": null,
            "type": "thinking",
            "thinking": "\nI need to continue implementing the EnhancedChantDetector class from where it left off. Looking at the code, I was in the middle of the `adaptiveDetection` method and specifically, calculating the overall progress. Let me continue from there and complete the full implementation of the method and the rest of the class.\n\nI'll need to:\n1. Complete the adaptiveDetection method\n2. Implement the remaining methods (calculateSegmentMatch, registerDetection, calculateOverallConfidence, etc.)\n3. Complete the script section with the UI initialization and integration\n4. Add any remaining functionality for the improved chant detector\n\nLet's continue from the exact point where the generation stopped.",
            "summaries": [
              {
                "summary": "Thinking about continuing code generation for progress calculation"
              },
              {
                "summary": "Continuing implementation of EnhancedChantDetector class method"
              },
              {
                "summary": "Strategized completing AI chant detector implementation methodically."
              }
            ],
            "cut_off": false
          },
          {
            "start_timestamp": "2025-03-17T16:51:11.254731Z",
            "stop_timestamp": "2025-03-17T16:51:11.254731Z",
            "flags": null,
            "type": "text",
            "text": "\n\nLet me continue the code from where it left off:",
            "citations": []
          },
          {
            "start_timestamp": "2025-03-17T16:51:11.699013Z",
            "stop_timestamp": "2025-03-17T16:51:15.390051Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "improved-chant-detector",
              "command": "update",
              "new_str": "// Calculate overall progress\n    const completedSegments = sequenceState.segments.filter(s => s === 'complete').length;\n    const activeSegment = sequenceState.segments.indexOf('active');\n    \n    if (activeSegment !== -1) {\n      // Include partial progress of active segment\n      const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);\n      sequenceState.progress = (completedSegments / pattern.segments.length) + activeProgress;\n    } else {\n      sequenceState.progress = completedSegments / pattern.segments.length;\n    }\n    \n    // Add progress to debug info\n    debugInfo.progress = sequenceState.progress;\n    debugInfo.segments = [...sequenceState.segments];\n    \n    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };",
              "old_str": "// Calculate overall progress\n    const completedSegments = sequenceState.segments.filter(s => s === 'complete').length;\n    const activeSegment = sequenceState.segments.indexOf('active');\n    \n    if (activeSegment !== -1) {\n      // Include partial progress of active segment\n      const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);",
              "version_uuid": "889970ef-8093-41e7-a693-b8b487894b29"
            },
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "74ea51ff-c889-4a39-aa63-1e4d8dae4faa"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-03-17T16:51:18.540094Z",
            "stop_timestamp": "2025-03-17T16:51:18.800418Z",
            "flags": null,
            "type": "text",
            "text": "\n\nLet me continue implementing the rest of the EnhancedChantDetector class:",
            "citations": []
          },
          {
            "start_timestamp": "2025-03-17T16:51:19.028055Z",
            "stop_timestamp": "2025-03-17T16:51:27.524948Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "improved-chant-detector",
              "command": "update",
              "new_str": "  }\n  \n  /**\n   * Calculate match between audio and a pattern segment\n   */\n  calculateSegmentMatch(audioData, segment, customWeights = null) {\n    // Nothing to match\n    if (!audioData || !segment) return 0;\n    \n    // Get feature arrays\n    const energy = audioData.energy;\n    const mfcc = audioData.mfcc;\n    const spectrogram = audioData.spectrogram;\n    \n    if (!energy.length || !mfcc.length || !spectrogram.length) return 0;\n    \n    // Use custom weights if provided, otherwise use config\n    const weights = customWeights || this.config.featureWeights;\n    \n    // Sliding window approach\n    let bestMatch = 0;\n    const windowSize = Math.min(segment.frameCount, energy.length);\n    \n    for (let i = 0; i <= energy.length - windowSize; i++) {\n      const windowEnergy = energy.slice(i, i + windowSize);\n      const windowMfcc = mfcc.slice(i, i + windowSize);\n      const windowSpectrogram = spectrogram.slice(i, i + windowSize);\n      \n      // Calculate similarity scores\n      const energyMatch = this.calculateEnergySimilarity(windowEnergy, segment.energy);\n      \n      // Average MFCC across window\n      const avgWindowMfcc = this.averageArrays(windowMfcc);\n      const mfccMatch = this.cosineSimilarity(avgWindowMfcc, segment.avgMfcc);\n      \n      // Average spectrogram\n      const avgWindowSpectrogram = this.averageSpectrograms(windowSpectrogram);\n      const spectrogramMatch = this.spectrogramSimilarity(\n        avgWindowSpectrogram, segment.avgSpectrogram\n      );\n      \n      // Weighted combination\n      const score = \n        (energyMatch * weights.energy) +\n        (mfccMatch * weights.mfcc) +\n        (spectrogramMatch * weights.spectrogram);\n      \n      bestMatch = Math.max(bestMatch, score);\n    }\n    \n    return bestMatch;\n  }\n  \n  /**\n   * Adaptive detection that self-adjusts based on input\n   */\n  adaptiveDetection(pattern) {",
              "old_str": "  }\n  \n  /**\n   * Adaptive detection that self-adjusts based on input\n   */\n  adaptiveDetection(pattern) {",
              "version_uuid": "fa66dc76-1115-48ae-a30b-57be51c8ce7d"
            },
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "02b39efa-5f90-41b7-b9e7-e31eb83f843c"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-03-17T16:51:29.683112Z",
            "stop_timestamp": "2025-03-17T16:51:29.900956Z",
            "flags": null,
            "type": "text",
            "text": "\n\nLet me continue by adding more methods to the class:",
            "citations": []
          },
          {
            "start_timestamp": "2025-03-17T16:51:30.295043Z",
            "stop_timestamp": "2025-03-17T16:51:44.683952Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "improved-chant-detector",
              "command": "update",
              "new_str": "    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };\n  }\n  \n  /**\n   * Calculate similarity between energy profiles\n   */\n  calculateEnergySimilarity(energyA, energyB) {\n    if (!energyA || !energyB || !energyA.length || !energyB.length) {\n      return 0;\n    }\n    \n    // Normalize lengths\n    const lenA = energyA.length;\n    const lenB = energyB.length;\n    const normalized = [];\n    \n    // Simple resampling\n    for (let i = 0; i < lenB; i++) {\n      const idx = Math.floor(i * lenA / lenB);\n      normalized[i] = energyA[idx];\n    }\n    \n    // Calculate correlation\n    return this.correlationSimilarity(normalized, energyB);\n  }\n  \n  /**\n   * Calculate correlation similarity between arrays\n   */\n  correlationSimilarity(arrA, arrB) {\n    // Calculate means\n    const meanA = this.average(arrA);\n    const meanB = this.average(arrB);\n    \n    // Calculate correlation\n    let num = 0;\n    let denA = 0;\n    let denB = 0;\n    \n    for (let i = 0; i < Math.min(arrA.length, arrB.length); i++) {\n      const a = arrA[i] - meanA;\n      const b = arrB[i] - meanB;\n      \n      num += a * b;\n      denA += a * a;\n      denB += b * b;\n    }\n    \n    // Avoid division by zero\n    if (denA === 0 || denB === 0) return 0;\n    \n    // Return Pearson correlation (between -1 and 1)\n    const corr = num / Math.sqrt(denA * denB);\n    \n    // Convert to similarity (0-1)\n    return (corr + 1) / 2;\n  }\n  \n  /**\n   * Compare two spectrograms\n   */\n  spectrogramSimilarity(spectrogramA, spectrogramB) {\n    if (!spectrogramA || !spectrogramB || \n        !spectrogramA.length || !spectrogramB.length) {\n      return 0;\n    }\n    \n    // Use cosine similarity between flattened spectrograms\n    const flatA = spectrogramA.flat ? spectrogramA.flat() : this.flattenArray(spectrogramA);\n    const flatB = spectrogramB.flat ? spectrogramB.flat() : this.flattenArray(spectrogramB);\n    \n    return this.cosineSimilarity(flatA, flatB);\n  }\n  \n  /**\n   * Register a detection\n   */\n  registerDetection(confidence) {\n    if (this.state.inCooldown) return false;\n    \n    // Increment counter\n    this.state.counter++;\n    this.state.lastDetectionTime = Date.now();\n    this.state.inCooldown = true;\n    \n    // Log detection\n    this.log('detection', `Pattern detected! Count: ${this.state.counter}`, true);\n    \n    // Reset sequence state\n    this.resetSequenceState();\n    \n    // Trigger callback\n    if (this.callbacks.onDetection) {\n      this.callbacks.onDetection(this.state.counter, confidence);\n    }\n    \n    // Start cooldown timer\n    setTimeout(() => {\n      this.state.inCooldown = false;\n    }, this.config.cooldownTime);\n    \n    return true;\n  }\n  \n  /**\n   * Calculate overall confidence for current match\n   */\n  calculateOverallConfidence() {\n    const matchScores = this.state.sequenceState.matchScores;\n    const segments = this.state.sequenceState.segments;\n    \n    if (!matchScores || matchScores.length === 0) {\n      return 0;\n    }\n    \n    // Weight completed segments more heavily\n    let weightedSum = 0;\n    let weightSum = 0;\n    \n    matchScores.forEach((score, index) => {\n      // Higher weight for completed segments\n      let weight = 1;\n      \n      if (segments[index] === 'complete') {\n        weight = 1.5;\n      } else if (segments[index] === 'active') {\n        weight = 1.2;\n      }\n      \n      weightedSum += score * weight;\n      weightSum += weight;\n    });\n    \n    return weightSum > 0 ? weightedSum / weightSum : 0;\n  }",
              "old_str": "    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };",
              "version_uuid": "06c5e738-17a9-425c-9065-ff5852de30ef"
            },
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "afa2c6de-3a30-4bf4-af35-d4e8e4c8c130"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-03-17T16:51:47.632803Z",
            "stop_timestamp": "2025-03-17T16:51:47.781030Z",
            "flags": null,
            "type": "text",
            "text": "\n\n\n\nLet's continue with the feature extraction and more utility methods:",
            "citations": []
          },
          {
            "start_timestamp": "2025-03-17T16:51:48.027057Z",
            "stop_timestamp": "2025-03-17T16:52:00.973539Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "improved-chant-detector",
              "command": "update",
              "new_str": "  /**\n   * Calculate overall confidence for current match\n   */\n  calculateOverallConfidence() {\n    const matchScores = this.state.sequenceState.matchScores;\n    const segments = this.state.sequenceState.segments;\n    \n    if (!matchScores || matchScores.length === 0) {\n      return 0;\n    }\n    \n    // Weight completed segments more heavily\n    let weightedSum = 0;\n    let weightSum = 0;\n    \n    matchScores.forEach((score, index) => {\n      // Higher weight for completed segments\n      let weight = 1;\n      \n      if (segments[index] === 'complete') {\n        weight = 1.5;\n      } else if (segments[index] === 'active') {\n        weight = 1.2;\n      }\n      \n      weightedSum += score * weight;\n      weightSum += weight;\n    });\n    \n    return weightSum > 0 ? weightedSum / weightSum : 0;\n  }\n  \n  /**\n   * Extract features from audio data\n   */\n  extractFeatures(audioData) {\n    try {\n      // Basic amplitude/energy\n      let sum = 0;\n      for (let i = 0; i < audioData.length; i++) {\n        sum += Math.abs(audioData[i]);\n      }\n      const amplitude = sum / audioData.length;\n      const energy = amplitude * amplitude * 100;\n      \n      // Get frequency data\n      const frequencyData = new Uint8Array(this.analyzer.frequencyBinCount);\n      this.analyzer.getByteFrequencyData(frequencyData);\n      \n      // Extract MFCC using Meyda if available\n      let mfcc = new Array(13).fill(0);\n      try {\n        if (window.Meyda) {\n          const meydaFeatures = Meyda.extract('mfcc', audioData);\n          if (meydaFeatures && meydaFeatures.mfcc) {\n            mfcc = meydaFeatures.mfcc;\n          }\n        }\n      } catch (e) {\n        // Ignore Meyda errors and use fallback\n      }\n      \n      // Convert spectrogram data\n      const spectrogram = this.processSpectrumData(frequencyData);\n      \n      return {\n        amplitude,\n        energy,\n        mfcc,\n        spectrogram,\n        raw: {\n          frequencyData\n        }\n      };\n    } catch (error) {\n      this.handleError('Error extracting features', error);\n      \n      // Return dummy features\n      return {\n        amplitude: 0,\n        energy: 0,\n        mfcc: new Array(13).fill(0),\n        spectrogram: new Array(128).fill(0),\n        raw: {\n          frequencyData: new Uint8Array(1024)\n        }\n      };\n    }\n  }\n  \n  /**\n   * Process raw spectrum data into a more compact format\n   */\n  processSpectrumData(frequencyData) {\n    // Reduce dimensionality for efficiency\n    const bins = 128; // 128 frequency bins\n    const result = new Array(bins).fill(0);\n    \n    const binSize = Math.floor(frequencyData.length / bins);\n    \n    for (let i = 0; i < bins; i++) {\n      const start = i * binSize;\n      const end = (i + 1) * binSize;\n      ",
              "old_str": "  /**\n   * Calculate overall confidence for current match\n   */\n  calculateOverallConfidence() {\n    const matchScores = this.state.sequenceState.matchScores;\n    const segments = this.state.sequenceState.segments;\n    \n    if (!matchScores || matchScores.length === 0) {\n      return 0;\n    }\n    \n    // Weight completed segments more heavily\n    let weightedSum = 0;\n    let weightSum = 0;\n    \n    matchScores.forEach((score, index) => {\n      // Higher weight for completed segments\n      let weight = 1;\n      \n      if (segments[index] === 'complete') {\n        weight = 1.5;\n      } else if (segments[index] === 'active') {\n        weight = 1.2;\n      }\n      \n      weightedSum += score * weight;\n      weightSum += weight;\n    });\n    \n    return weightSum > 0 ? weightedSum / weightSum : 0;\n  }",
              "version_uuid": "e2ebaa5c-a76e-46d3-a3d4-1c8a77715f8a"
            },
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": "2025-03-17T16:52:02.478179Z",
            "stop_timestamp": "2025-03-17T16:52:02.478179Z",
            "flags": null,
            "type": "text",
            "text": "",
            "citations": []
          }
        ],
        "updated_at": "2025-03-17T16:52:02.503019Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "21364bc4-6291-455b-971e-c511195d74cb",
      "role": "human",
      "content": "the code stopped generating, please continue the code from thi ssection here [[[// Calculate overall progress const completedSegments = sequenceState.segments.filter(s => s === 'complete').length; const activeSegment = sequenceState.segments.indexOf('active'); if (activeSegment !== -1) { // Include partial progress of active segment const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);]]]",
      "created_at": "2025-03-17T16:52:38.396570Z",
      "sequence_order": 4,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-03-14T21:49:43.864066Z",
            "stop_timestamp": "2025-03-14T21:49:43.864066Z",
            "flags": null,
            "type": "text",
            "text": "the code stopped generating, please continue the code from thi ssection here [[[// Calculate overall progress const completedSegments = sequenceState.segments.filter(s => s === 'complete').length; const activeSegment = sequenceState.segments.indexOf('active'); if (activeSegment !== -1) { // Include partial progress of active segment const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);]]]",
            "citations": []
          }
        ],
        "updated_at": "2025-03-17T16:52:38.396570Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "a63dc765-369e-475e-9f9e-968a90e0a4c4",
      "role": "assistant",
      "content": "\nThe code stopped in the middle of the `adaptiveDetection` method in the `EnhancedChantDetector` class. Let me continue where it left off. This part is calculating the overall progress of the pattern recognition, and it had just started determining the progress contribution from the active segment.\n\nHere's how I'll continue:\n\n1. Finish calculating the `sequenceState.progress` value\n2. Add the progress to debug info\n3. Return the detection result (not detected yet, with confidence and debug info)\n4. Complete the rest of the class methods:\n   - `calculateSegmentMatch`\n   - `registerDetection`\n   - `calculateOverallConfidence`\n   - `extractFeatures` \n   - And other supporting methods\n5. Add any remaining animation, visualization, and utility methods\n6. Close out the class definition\n7. Add the initialization and event listener code\n\nI'll focus on continuing the immediate section first, then fill in the rest of the class.\n\nI'll continue the code from where it left off:\n```\nViewing artifacts created via the Analysis Tool web feature preview isnt yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isnt yet supported on mobile.\n```\n\n\n\nNow I'll add the segment matching calculation method and other essential functions:\n```\nViewing artifacts created via the Analysis Tool web feature preview isnt yet supported on mobile.\n```\n\n\n\nNow let me add the main application code to initialize and connect the detector to the UI:\n```\nViewing artifacts created via the Analysis Tool web feature preview isnt yet supported on mobile.\n```\n\n\n\nI've created a streamlined, enhanced chant detector that addresses the key issues in the original code. Here are the major improvements I've implemented:\n\n1. **Better Final Segment Detection**:\n   - Added a dedicated \"Final Segment Boost\" slider that makes it easier to recognize the last segment by lowering its threshold\n   - Increased the detection buffer size specifically for the last segment\n   - Added more flexible timing thresholds for the final segment\n\n2. **Improved Visualization and Feedback**:\n   - Enhanced the spectrogram visualization with better color mapping\n   - Added confidence indicators to show how well each segment matches\n   - Improved the sequence progress display with more informative visual cues\n\n3. **Adaptive Detection Algorithm**:\n   - Made the adaptive algorithm the default since it works better in most cases\n   - Implemented progressive threshold adjustments that get easier as you progress through the pattern\n   - Added intelligent pattern recovery that can skip segments when appropriate\n\n4. **More Efficient Pattern Segmentation**:\n   - Better handling of pattern division to ensure the correct number of segments\n   - Improved boundary detection for more natural pattern division\n   - Balanced segmentation when natural boundaries aren't clear\n\n5. **Mobile-Friendly Updates**:\n   - Added touch event support for recording on mobile devices\n   - Improved button sizes and responsive layout\n   - Simplified the UI for better usability\n\nTo use this improved detector:\n\n1. Press and hold the \"Record\" button while chanting your pattern\n2. When you finish your chant, release the button\n3. The pattern will be automatically segmented (you'll see the segments in the display)\n4. Click \"Start Detection\" and repeat your chant - it should now detect it reliably!\n\nFor best results:\n- Use the \"Adaptive\" detection mode (default)\n- Record 2-3 samples and use the \"Average Patterns\" button\n- If the final segment isn't detected well, lower the \"Final Segment Boost\" value\n- For more challenging patterns, lower the \"Match Threshold\" slightly\n\nThis solution should make it much easier to detect complete patterns, especially addressing the issue with recognizing the final segment.",
      "created_at": "2025-03-17T16:55:15.962173Z",
      "sequence_order": 5,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-03-17T16:52:40.411407Z",
            "stop_timestamp": "2025-03-17T16:52:44.617060Z",
            "flags": null,
            "type": "thinking",
            "thinking": "\nThe code stopped in the middle of the `adaptiveDetection` method in the `EnhancedChantDetector` class. Let me continue where it left off. This part is calculating the overall progress of the pattern recognition, and it had just started determining the progress contribution from the active segment.\n\nHere's how I'll continue:\n\n1. Finish calculating the `sequenceState.progress` value\n2. Add the progress to debug info\n3. Return the detection result (not detected yet, with confidence and debug info)\n4. Complete the rest of the class methods:\n   - `calculateSegmentMatch`\n   - `registerDetection`\n   - `calculateOverallConfidence`\n   - `extractFeatures` \n   - And other supporting methods\n5. Add any remaining animation, visualization, and utility methods\n6. Close out the class definition\n7. Add the initialization and event listener code\n\nI'll focus on continuing the immediate section first, then fill in the rest of the class.",
            "summaries": [
              {
                "summary": "Thinking about completing partially generated code segment calculation"
              },
              {
                "summary": "Continuing code generation in adaptive detection method"
              },
              {
                "summary": "Mapped out code continuation strategy for detection algorithm."
              }
            ],
            "cut_off": false
          },
          {
            "start_timestamp": "2025-03-17T16:52:44.958626Z",
            "stop_timestamp": "2025-03-17T16:52:44.958626Z",
            "flags": null,
            "type": "text",
            "text": "\n\nI'll continue the code from where it left off:",
            "citations": []
          },
          {
            "start_timestamp": "2025-03-17T16:52:45.411797Z",
            "stop_timestamp": "2025-03-17T16:52:49.059713Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "improved-chant-detector",
              "command": "update",
              "new_str": "    // Calculate overall progress\n    const completedSegments = sequenceState.segments.filter(s => s === 'complete').length;\n    const activeSegment = sequenceState.segments.indexOf('active');\n    \n    if (activeSegment !== -1) {\n      // Include partial progress of active segment\n      const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);\n      sequenceState.progress = (completedSegments / pattern.segments.length) + activeProgress;\n    } else {\n      sequenceState.progress = completedSegments / pattern.segments.length;\n    }\n    \n    // Add progress to debug info\n    debugInfo.progress = sequenceState.progress;\n    debugInfo.segments = [...sequenceState.segments];\n    \n    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };",
              "old_str": "    // Calculate overall progress\n    const completedSegments = sequenceState.segments.filter(s => s === 'complete').length;\n    const activeSegment = sequenceState.segments.indexOf('active');\n    \n    if (activeSegment !== -1) {\n      // Include partial progress of active segment\n      const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);",
              "version_uuid": "164d1800-20e3-4bb9-9a83-390c0f47c02f"
            },
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "0fe63df4-9aa3-47d6-bfdc-2de2c9e54856"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-03-17T16:52:51.007841Z",
            "stop_timestamp": "2025-03-17T16:52:52.806227Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "improved-chant-detector",
              "command": "update",
              "new_str": "  /**\n   * Adaptive detection that self-adjusts based on input\n   * This method provides the most flexible and user-friendly detection\n   * by dynamically adjusting thresholds and allowing for pattern variations\n   */",
              "old_str": "  /**\n   * Adaptive detection that self-adjusts based on input\n   */",
              "version_uuid": "ac793d28-cdc0-4c15-9c9e-fd00a942f89c"
            },
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "d59e84b2-00d7-4677-bc7b-ca163e14dded"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-03-17T16:52:54.025613Z",
            "stop_timestamp": "2025-03-17T16:52:54.454472Z",
            "flags": null,
            "type": "text",
            "text": "\n\nNow I'll add the segment matching calculation method and other essential functions:",
            "citations": []
          },
          {
            "start_timestamp": "2025-03-17T16:52:54.676921Z",
            "stop_timestamp": "2025-03-17T16:53:44.280413Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "improved-chant-detector",
              "command": "update",
              "new_str": "  }\n  \n  /**\n   * Calculate match between audio and a pattern segment\n   */\n  calculateSegmentMatch(audioData, segment, customFeatureWeights = null) {\n    // Nothing to match\n    if (!audioData || !segment) return 0;\n    \n    // Get feature arrays\n    const energy = audioData.energy;\n    const mfcc = audioData.mfcc;\n    const spectrogram = audioData.spectrogram;\n    \n    if (!energy.length || !mfcc.length || !spectrogram.length) return 0;\n    \n    // Use provided weights or defaults\n    const featureWeights = customFeatureWeights || this.config.featureWeights;\n    \n    // Sliding window approach\n    let bestMatch = 0;\n    const windowSize = Math.min(segment.frameCount, energy.length);\n    \n    for (let i = 0; i <= energy.length - windowSize; i++) {\n      const windowEnergy = energy.slice(i, i + windowSize);\n      const windowMfcc = mfcc.slice(i, i + windowSize);\n      const windowSpectrogram = spectrogram.slice(i, i + windowSize);\n      \n      // Calculate similarity scores\n      const energyMatch = this.calculateEnergySimilarity(windowEnergy, segment.energy);\n      \n      // Average MFCC across window\n      const avgWindowMfcc = this.averageArrays(windowMfcc);\n      const mfccMatch = this.cosineSimilarity(avgWindowMfcc, segment.avgMfcc);\n      \n      // Average spectrogram\n      const avgWindowSpectrogram = this.averageSpectrograms(windowSpectrogram);\n      const spectrogramMatch = this.spectrogramSimilarity(\n        avgWindowSpectrogram, segment.avgSpectrogram\n      );\n      \n      // Weighted combination\n      const score = \n        (energyMatch * featureWeights.energy) +\n        (mfccMatch * featureWeights.mfcc) +\n        (spectrogramMatch * featureWeights.spectrogram);\n      \n      bestMatch = Math.max(bestMatch, score);\n    }\n    \n    return bestMatch;\n  }\n  \n  /**\n   * Calculate similarity between energy profiles\n   */\n  calculateEnergySimilarity(energyA, energyB) {\n    if (!energyA || !energyB || !energyA.length || !energyB.length) {\n      return 0;\n    }\n    \n    // Normalize lengths\n    const lenA = energyA.length;\n    const lenB = energyB.length;\n    const normalized = [];\n    \n    // Simple resampling\n    for (let i = 0; i < lenB; i++) {\n      const idx = Math.floor(i * lenA / lenB);\n      normalized[i] = energyA[idx];\n    }\n    \n    // Calculate correlation\n    return this.correlationSimilarity(normalized, energyB);\n  }\n  \n  /**\n   * Calculate correlation similarity between arrays\n   */\n  correlationSimilarity(arrA, arrB) {\n    // Calculate means\n    const meanA = this.average(arrA);\n    const meanB = this.average(arrB);\n    \n    // Calculate correlation\n    let num = 0;\n    let denA = 0;\n    let denB = 0;\n    \n    for (let i = 0; i < Math.min(arrA.length, arrB.length); i++) {\n      const a = arrA[i] - meanA;\n      const b = arrB[i] - meanB;\n      \n      num += a * b;\n      denA += a * a;\n      denB += b * b;\n    }\n    \n    // Avoid division by zero\n    if (denA === 0 || denB === 0) return 0;\n    \n    // Return Pearson correlation (between -1 and 1)\n    const corr = num / Math.sqrt(denA * denB);\n    \n    // Convert to similarity (0-1)\n    return (corr + 1) / 2;\n  }\n  \n  /**\n   * Compare two spectrograms\n   */\n  spectrogramSimilarity(spectrogramA, spectrogramB) {\n    if (!spectrogramA || !spectrogramB || \n        !spectrogramA.length || !spectrogramB.length) {\n      return 0;\n    }\n    \n    // Use cosine similarity between flattened spectrograms\n    const flatA = spectrogramA.flat ? spectrogramA.flat() : this.flattenArray(spectrogramA);\n    const flatB = spectrogramB.flat ? spectrogramB.flat() : this.flattenArray(spectrogramB);\n    \n    return this.cosineSimilarity(flatA, flatB);\n  }\n  \n  /**\n   * Register a detection\n   */\n  registerDetection(confidence) {\n    if (this.state.inCooldown) return false;\n    \n    // Increment counter\n    this.state.counter++;\n    this.state.lastDetectionTime = Date.now();\n    this.state.inCooldown = true;\n    \n    // Log detection\n    this.log('detection', `Pattern detected! Count: ${this.state.counter}`, true);\n    \n    // Reset sequence state\n    this.resetSequenceState();\n    \n    // Trigger callback\n    if (this.callbacks.onDetection) {\n      this.callbacks.onDetection(this.state.counter, confidence);\n    }\n    \n    // Start cooldown timer\n    setTimeout(() => {\n      this.state.inCooldown = false;\n    }, this.config.cooldownTime);\n    \n    return true;\n  }\n  \n  /**\n   * Calculate overall confidence for current match\n   */\n  calculateOverallConfidence() {\n    const matchScores = this.state.sequenceState.matchScores;\n    const segments = this.state.sequenceState.segments;\n    \n    if (!matchScores || matchScores.length === 0) {\n      return 0;\n    }\n    \n    // Weight completed segments more heavily\n    let weightedSum = 0;\n    let weightSum = 0;\n    \n    matchScores.forEach((score, index) => {\n      // Higher weight for completed segments\n      let weight = 1;\n      \n      if (segments[index] === 'complete') {\n        weight = 1.5;\n      } else if (segments[index] === 'active') {\n        weight = 1.2;\n      }\n      \n      weightedSum += score * weight;\n      weightSum += weight;\n    });\n    \n    return weightSum > 0 ? weightedSum / weightSum : 0;\n  }\n  \n  /**\n   * Extract features from audio data\n   */\n  extractFeatures(audioData) {\n    try {\n      // Basic amplitude/energy\n      let sum = 0;\n      for (let i = 0; i < audioData.length; i++) {\n        sum += Math.abs(audioData[i]);\n      }\n      const amplitude = sum / audioData.length;\n      const energy = amplitude * amplitude * 100;\n      \n      // Get frequency data\n      const frequencyData = new Uint8Array(this.analyzer.frequencyBinCount);\n      this.analyzer.getByteFrequencyData(frequencyData);\n      \n      // Extract MFCC using Meyda\n      let mfcc = new Array(13).fill(0);\n      try {\n        const meydaFeatures = Meyda.extract('mfcc', audioData);\n        if (meydaFeatures && meydaFeatures.mfcc) {\n          mfcc = meydaFeatures.mfcc;\n        }\n      } catch (e) {\n        // Ignore Meyda errors and use fallback\n      }\n      \n      // Convert spectrogram data\n      const spectrogram = this.processSpectrumData(frequencyData);\n      \n      return {\n        amplitude,\n        energy,\n        mfcc,\n        spectrogram,\n        raw: {\n          frequencyData\n        }\n      };\n    } catch (error) {\n      this.handleError('Error extracting features', error);\n      \n      // Return dummy features\n      return {\n        amplitude: 0,\n        energy: 0,\n        mfcc: new Array(13).fill(0),\n        spectrogram: new Array(128).fill(0),\n        raw: {\n          frequencyData: new Uint8Array(1024)\n        }\n      };\n    }\n  }\n  \n  /**\n   * Process raw spectrum data into a more compact format\n   */\n  processSpectrumData(frequencyData) {\n    // Reduce dimensionality for efficiency\n    const bins = 128; // 128 frequency bins\n    const result = new Array(bins).fill(0);\n    \n    const binSize = Math.floor(frequencyData.length / bins);\n    \n    for (let i = 0; i < bins; i++) {\n      const start = i * binSize;\n      const end = (i + 1) * binSize;\n      \n      // Average values in this frequency bin\n      let sum = 0;\n      for (let j = start; j < end && j < frequencyData.length; j++) {\n        sum += frequencyData[j];\n      }\n      \n      result[i] = sum / binSize / 255; // Normalize to 0-1\n    }\n    \n    return result;\n  }\n  \n  /**\n   * Start animation loop for cursor movement\n   */\n  startAnimationLoop() {\n    // Stop any existing loop\n    this.stopAnimationLoop();\n    \n    // Animation function\n    const animate = () => {\n      // Move time cursor\n      const cursor = document.getElementById('timeCursor');\n      if (cursor) {\n        // Get a position that oscillates between 25% and 75%\n        const time = Date.now() / 1000;\n        const position = 50 + 25 * Math.sin(time);\n        cursor.style.left = `${position}%`;\n      }\n      \n      // Request next frame\n      this.animationFrame = requestAnimationFrame(animate);\n    };\n    \n    // Start animation\n    this.animationFrame = requestAnimationFrame(animate);\n  }\n  \n  /**\n   * Stop animation loop\n   */\n  stopAnimationLoop() {\n    if (this.animationFrame) {\n      cancelAnimationFrame(this.animationFrame);\n      this.animationFrame = null;\n    }\n  }\n  \n  /**\n   * Update configuration\n   */\n  updateConfig(config) {\n    Object.assign(this.config, config);\n    \n    // If segment count changed and we have a pattern, re-segment it\n    if (config.segmentCount !== undefined && this.state.patterns[this.state.activePatternIndex]) {\n      const pattern = this.state.patterns[this.state.activePatternIndex];\n      \n      if (pattern && pattern.rawData) {\n        pattern.segments = this.segmentPattern(pattern.rawData);\n        this.calculateSegmentBoundaries(pattern);\n      }\n    }\n  }\n  \n  /**\n   * Find peaks in energy profile\n   */\n  findPeaks(signal, minHeight = 0.1) {\n    const peaks = [];\n    for (let i = 2; i < signal.length - 2; i++) {\n      if (signal[i] > minHeight && \n          signal[i] > signal[i-1] && signal[i] >= signal[i-2] &&\n          signal[i] > signal[i+1] && signal[i] >= signal[i+2]) {\n        peaks.push(i);\n      }\n    }\n    return peaks;\n  }\n  \n  /**\n   * Find valleys in energy profile\n   */\n  findValleys(signal, maxHeight = 0.9) {\n    const valleys = [];\n    for (let i = 2; i < signal.length - 2; i++) {\n      if (signal[i] < maxHeight && \n          signal[i] < signal[i-1] && signal[i] <= signal[i-2] &&\n          signal[i] < signal[i+1] && signal[i] <= signal[i+2]) {\n        valleys.push(i);\n      }\n    }\n    return valleys;\n  }\n  \n  /**\n   * Smooth an array using moving average\n   */\n  smoothArray(array, windowSize = 3) {\n    const result = [];\n    const half = Math.floor(windowSize / 2);\n    \n    for (let i = 0; i < array.length; i++) {\n      let sum = 0;\n      let count = 0;\n      \n      for (let j = Math.max(0, i - half); j <= Math.min(array.length - 1, i + half); j++) {\n        sum += array[j];\n        count++;\n      }\n      \n      result.push(sum / count);\n    }\n    \n    return result;\n  }\n  \n  /**\n   * Average multiple arrays\n   */\n  averageArrays(arrays) {\n    if (!arrays || arrays.length === 0 || !arrays[0]) return [];\n    \n    const result = new Array(arrays[0].length).fill(0);\n    let validArrays = 0;\n    \n    for (const arr of arrays) {\n      if (!arr) continue;\n      \n      validArrays++;\n      for (let i = 0; i < Math.min(result.length, arr.length); i++) {\n        result[i] += arr[i];\n      }\n    }\n    \n    return validArrays > 0 ? result.map(val => val / validArrays) : result;\n  }\n  \n  /**\n   * Average multiple spectrograms\n   */\n  averageSpectrograms(spectrograms) {\n    return this.averageArrays(spectrograms);\n  }\n  \n  /**\n   * Calculate average of array\n   */\n  average(array) {\n    if (!array || array.length === 0) return 0;\n    return array.reduce((sum, val) => sum + val, 0) / array.length;\n  }\n  \n  /**\n   * Calculate cosine similarity between arrays\n   */\n  cosineSimilarity(arrA, arrB) {\n    if (!arrA || !arrB || arrA.length === 0 || arrB.length === 0) {\n      return 0;\n    }\n    \n    const length = Math.min(arrA.length, arrB.length);\n    \n    let dotProduct = 0;\n    let normA = 0;\n    let normB = 0;\n    \n    for (let i = 0; i < length; i++) {\n      dotProduct += arrA[i] * arrB[i];\n      normA += arrA[i] * arrA[i];\n      normB += arrB[i] * arrB[i];\n    }\n    \n    const denominator = Math.sqrt(normA) * Math.sqrt(normB);\n    \n    return denominator === 0 ? 0 : dotProduct / denominator;\n  }\n  \n  /**\n   * Flatten a 2D array\n   */\n  flattenArray(array) {\n    if (array.flat) return array.flat();\n    \n    return [].concat(...array);\n  }\n  \n  /**\n   * Handle errors\n   */\n  handleError(message, error) {\n    const errorMessage = `${message}: ${error.message || error}`;\n    console.error(errorMessage);\n    \n    if (this.callbacks.onError) {\n      this.callbacks.onError(message, error);\n    }\n  }\n  \n  /**\n   * Log messages\n   */\n  log(type, message, highlight = false) {\n    console.log(`[${type.toUpperCase()}] ${message}`);\n    \n    if (this.callbacks.onStatusUpdate) {\n      this.callbacks.onStatusUpdate(type, message, highlight);\n    }\n    \n    return { type, message, highlight };\n  }\n}",
              "old_str": "  }\n}",
              "version_uuid": "62a88d28-5926-497c-8cd1-3595d163abd9"
            },
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "347657b2-986f-481d-ba0b-234b91cfae6b"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-03-17T16:53:48.913525Z",
            "stop_timestamp": "2025-03-17T16:53:49.235898Z",
            "flags": null,
            "type": "text",
            "text": "\n\nNow let me add the main application code to initialize and connect the detector to the UI:",
            "citations": []
          },
          {
            "start_timestamp": "2025-03-17T16:53:49.635335Z",
            "stop_timestamp": "2025-03-17T16:55:01.328834Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "improved-chant-detector",
              "command": "update",
              "new_str": "}\n\n// Main Application\ndocument.addEventListener('DOMContentLoaded', () => {\n  // Elements\n  const elements = {\n    // Pattern recording \n    recordingStatus: document.getElementById('recordingStatus'),\n    recordBtn: document.getElementById('recordBtn'),\n    playLastBtn: document.getElementById('playLastBtn'),\n    clearBtn: document.getElementById('clearBtn'),\n    averageBtn: document.getElementById('averageBtn'),\n    patternInfo: document.getElementById('patternInfo'),\n    patternStats: document.getElementById('patternStats'),\n    patternDisplay: document.getElementById('patternDisplay'),\n    recordSpectrogram: document.getElementById('recordSpectrogram'),\n    recordSegmentMarkers: document.getElementById('recordSegmentMarkers'),\n    \n    // Detection\n    liveSpectrogram: document.getElementById('liveSpectrogram'),\n    liveSegmentMarkers: document.getElementById('liveSegmentMarkers'),\n    timeCursor: document.getElementById('timeCursor'),\n    detectionStatus: document.getElementById('detectionStatus'),\n    counterValue: document.getElementById('counterValue'),\n    sequenceProgress: document.getElementById('sequenceProgress'),\n    detectionProgress: document.getElementById('detectionProgress'),\n    \n    // Controls\n    startBtn: document.getElementById('startBtn'),\n    stopBtn: document.getElementById('stopBtn'),\n    resetBtn: document.getElementById('resetBtn'),\n    patternTabs: document.querySelectorAll('.pattern-tab'),\n    \n    // Settings\n    detectionMode: document.getElementById('detectionMode'),\n    minMatchSlider: document.getElementById('minMatchSlider'),\n    minMatchValue: document.getElementById('minMatchValue'),\n    advanceThresholdSlider: document.getElementById('advanceThresholdSlider'),\n    advanceThresholdValue: document.getElementById('advanceThresholdValue'),\n    timeoutSlider: document.getElementById('timeoutSlider'),\n    timeoutValue: document.getElementById('timeoutValue'),\n    cooldownSlider: document.getElementById('cooldownSlider'),\n    cooldownValue: document.getElementById('cooldownValue'),\n    segmentCountSelect: document.getElementById('segmentCountSelect'),\n    finalSegmentBoostSlider: document.getElementById('finalSegmentBoostSlider'),\n    finalSegmentBoostValue: document.getElementById('finalSegmentBoostValue'),\n    \n    // Debug\n    debugPanel: document.getElementById('debugPanel'),\n    detectionLog: document.getElementById('detectionLog')\n  };\n  \n  // Canvas contexts\n  const contexts = {\n    recordSpectrogram: elements.recordSpectrogram.getContext('2d'),\n    liveSpectrogram: elements.liveSpectrogram.getContext('2d')\n  };\n  \n  // Create detector\n  const detector = new EnhancedChantDetector();\n  \n  // Set up detector callbacks\n  detector.setCallbacks({\n    onStatusUpdate: (type, message, data) => {\n      if (type === 'status') {\n        elements.detectionStatus.textContent = message;\n      } else if (type === 'info') {\n        logDetection(message, false);\n      } else if (type === 'detection') {\n        logDetection(message, data);\n      } else if (type === 'control') {\n        if (message === 'enableAveraging') {\n          elements.averageBtn.disabled = !data;\n        }\n      }\n    },\n    \n    onVisualizationUpdate: (mode, audioData, features) => {\n      if (mode === 'recording') {\n        drawSpectrogram(contexts.recordSpectrogram, features.raw.frequencyData);\n      } else if (mode === 'detection') {\n        drawSpectrogram(contexts.liveSpectrogram, features.raw.frequencyData);\n      } else if (mode === 'patternSwitch') {\n        updatePatternDisplay(features);\n      }\n    },\n    \n    onDetection: (count, confidence) => {\n      elements.counterValue.textContent = count;\n      \n      // Flash effect on detection\n      elements.detectionProgress.style.background = 'linear-gradient(90deg, #f44336, #e91e63)';\n      \n      setTimeout(() => {\n        elements.detectionProgress.style.background = 'linear-gradient(90deg, #4caf50, #8bc34a)';\n      }, 300);\n      \n      // Add success class to latest log entry\n      const lastLog = elements.detectionLog.lastElementChild;\n      if (lastLog) {\n        lastLog.classList.add('success');\n      }\n    },\n    \n    onProgressUpdate: (sequenceState, debugData) => {\n      // Update progress bar\n      elements.detectionProgress.style.width = `${Math.round(sequenceState.progress * 100)}%`;\n      \n      // Update sequence progress visualization\n      updateSequenceProgress(sequenceState);\n      \n      // Update debug panel\n      if (debugData) {\n        updateDebugPanel(debugData);\n      }\n    },\n    \n    onError: (message, error) => {\n      console.error(message, error);\n      logDetection(`Error: ${message}`, true);\n    }\n  });\n  \n  // Button handlers\n  elements.recordBtn.addEventListener('mousedown', () => {\n    detector.startRecording();\n    elements.recordBtn.textContent = 'Recording...';\n    elements.recordBtn.classList.add('recording');\n  });\n  \n  elements.recordBtn.addEventListener('mouseup', () => {\n    detector.stopRecording();\n    elements.recordBtn.textContent = 'Record (Hold)';\n    elements.recordBtn.classList.remove('recording');\n    updatePatternInfo();\n  });\n  \n  elements.recordBtn.addEventListener('mouseleave', () => {\n    if (detector.state.isRecording) {\n      detector.stopRecording();\n      elements.recordBtn.textContent = 'Record (Hold)';\n      elements.recordBtn.classList.remove('recording');\n      updatePatternInfo();\n    }\n  });\n  \n  // Touch support for mobile\n  elements.recordBtn.addEventListener('touchstart', (e) => {\n    e.preventDefault(); // Prevent scrolling\n    detector.startRecording();\n    elements.recordBtn.textContent = 'Recording...';\n    elements.recordBtn.classList.add('recording');\n  });\n  \n  elements.recordBtn.addEventListener('touchend', (e) => {\n    e.preventDefault();\n    detector.stopRecording();\n    elements.recordBtn.textContent = 'Record (Hold)';\n    elements.recordBtn.classList.remove('recording');\n    updatePatternInfo();\n  });\n  \n  elements.playLastBtn.addEventListener('click', () => {\n    detector.playLastPattern();\n  });\n  \n  elements.clearBtn.addEventListener('click', () => {\n    detector.clearActivePattern();\n    updatePatternInfo();\n    elements.startBtn.disabled = true;\n    elements.playLastBtn.disabled = true;\n    \n    // Clear display\n    elements.patternDisplay.innerHTML = '';\n    elements.recordSegmentMarkers.innerHTML = '';\n    clearCanvas(contexts.recordSpectrogram);\n  });\n  \n  elements.averageBtn.addEventListener('click', () => {\n    detector.averageAllPatterns();\n    updatePatternInfo();\n  });\n  \n  elements.startBtn.addEventListener('click', () => {\n    detector.startDetection();\n    elements.startBtn.disabled = true;\n    elements.stopBtn.disabled = false;\n  });\n  \n  elements.stopBtn.addEventListener('click', () => {\n    detector.stopDetection();\n    elements.startBtn.disabled = false;\n    elements.stopBtn.disabled = true;\n    \n    // Reset visualizations\n    elements.detectionProgress.style.width = '0%';\n    elements.sequenceProgress.innerHTML = '';\n    elements.liveSegmentMarkers.innerHTML = '';\n    clearCanvas(contexts.liveSpectrogram);\n  });\n  \n  elements.resetBtn.addEventListener('click', () => {\n    detector.resetCounter();\n  });\n  \n  // Pattern tabs\n  elements.patternTabs.forEach(tab => {\n    tab.addEventListener('click', () => {\n      const patternIndex = parseInt(tab.getAttribute('data-pattern')) - 1;\n      \n      // Update active tab\n      elements.patternTabs.forEach(t => t.classList.remove('active'));\n      tab.classList.add('active');\n      \n      // Set active pattern\n      detector.setActivePattern(patternIndex);\n      \n      updatePatternInfo();\n    });\n  });\n  \n  // Settings handlers\n  elements.detectionMode.addEventListener('change', () => {\n    detector.updateConfig({\n      detectionMode: elements.detectionMode.value\n    });\n    \n    logDetection(`Detection mode changed to: ${elements.detectionMode.value}`);\n  });\n  \n  elements.minMatchSlider.addEventListener('input', () => {\n    const value = elements.minMatchSlider.value;\n    elements.minMatchValue.textContent = value;\n    \n    detector.updateConfig({\n      minMatchThreshold: parseFloat(value)\n    });\n  });\n  \n  elements.advanceThresholdSlider.addEventListener('input', () => {\n    const value = elements.advanceThresholdSlider.value;\n    elements.advanceThresholdValue.textContent = value;\n    \n    detector.updateConfig({\n      advanceThreshold: parseFloat(value)\n    });\n  });\n  \n  elements.timeoutSlider.addEventListener('input', () => {\n    const value = elements.timeoutSlider.value;\n    elements.timeoutValue.textContent = value;\n    \n    detector.updateConfig({\n      segmentTimeout: parseInt(value)\n    });\n  });\n  \n  elements.cooldownSlider.addEventListener('input', () => {\n    const value = elements.cooldownSlider.value;\n    elements.cooldownValue.textContent = value;\n    \n    detector.updateConfig({\n      cooldownTime: parseInt(value)\n    });\n  });\n  \n  elements.segmentCountSelect.addEventListener('change', () => {\n    detector.updateConfig({\n      segmentCount: parseInt(elements.segmentCountSelect.value)\n    });\n    \n    // Update pattern info if we have a pattern\n    if (detector.state.patterns[detector.state.activePatternIndex]) {\n      updatePatternInfo();\n    }\n  });\n  \n  elements.finalSegmentBoostSlider.addEventListener('input', () => {\n    const value = elements.finalSegmentBoostSlider.value;\n    elements.finalSegmentBoostValue.textContent = value;\n    \n    detector.updateConfig({\n      finalSegmentBoost: parseFloat(value)\n    });\n  });\n  \n  // Visualization functions\n  function drawSpectrogram(ctx, frequencyData) {\n    const width = ctx.canvas.width;\n    const height = ctx.canvas.height;\n    \n    // Shift existing spectrogram left\n    const imgData = ctx.getImageData(1, 0, width - 1, height);\n    ctx.putImageData(imgData, 0, 0);\n    \n    // Draw new column\n    const columnWidth = 1;\n    const binCount = Math.min(128, frequencyData.length / 4);\n    const binHeight = height / binCount;\n    \n    for (let i = 0; i < binCount; i++) {\n      // Reverse order (low frequency at bottom)\n      const y = height - (i + 1) * binHeight;\n      \n      // Average a range of frequency bins\n      const startBin = i * 4;\n      const endBin = startBin + 4;\n      \n      let binSum = 0;\n      for (let j = startBin; j < endBin && j < frequencyData.length; j++) {\n        binSum += frequencyData[j];\n      }\n      \n      const intensity = binSum / 4;\n      \n      // Create color (blue to red gradient)\n      // Improved color mapping for better visualization\n      const hue = intensity < 50 ? 240 : 240 - ((intensity - 50) / 205 * 240);\n      const saturation = '100%';\n      const lightness = `${Math.min(50 + intensity / 10, 80)}%`;\n      \n      ctx.fillStyle = `hsl(${hue}, ${saturation}, ${lightness})`;\n      ctx.fillRect(width - columnWidth, y, columnWidth, binHeight);\n    }\n  }\n  \n  function clearCanvas(ctx) {\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n  }\n  \n  function updateSequenceProgress(sequenceState) {\n    const container = elements.sequenceProgress;\n    container.innerHTML = '';\n    \n    // Create segment boxes\n    sequenceState.segments.forEach((state, index) => {\n      const segmentBox = document.createElement('div');\n      segmentBox.className = `segment-box segment-${state}`;\n      segmentBox.textContent = index + 1;\n      \n      // Add confidence indicator bar at bottom\n      if (sequenceState.matchScores && sequenceState.matchScores[index]) {\n        const score = sequenceState.matchScores[index] * 100;\n        segmentBox.style.setProperty('--score', `${score}%`);\n        segmentBox.style.setProperty('--score-color', getScoreColor(score));\n        segmentBox.setAttribute('title', `Match: ${Math.round(score)}%`);\n        \n        // Set width of score indicator\n        segmentBox.style.setProperty('--after-width', `${score}%`);\n      }\n      \n      container.appendChild(segmentBox);\n    });\n    \n    // Update segment markers on live spectrogram\n    updateSegmentMarkers(\n      elements.liveSegmentMarkers, \n      detector.state.patterns[detector.state.activePatternIndex]\n    );\n  }\n  \n  function getScoreColor(score) {\n    if (score >= 80) return '#4caf50';\n    if (score >= 60) return '#8bc34a';\n    if (score >= 40) return '#ffc107';\n    if (score >= 20) return '#ff9800';\n    return '#f44336';\n  }\n  \n  function updatePatternDisplay(pattern) {\n    if (!pattern || !pattern.segments || pattern.segments.length === 0) {\n      elements.patternDisplay.innerHTML = '';\n      elements.recordSegmentMarkers.innerHTML = '';\n      return;\n    }\n    \n    // Create segment display\n    const container = elements.patternDisplay;\n    container.innerHTML = '';\n    \n    // Create segment divs\n    pattern.segments.forEach((segment, index) => {\n      const segmentDiv = document.createElement('div');\n      segmentDiv.className = 'pattern-segment';\n      \n      // Add label\n      const labelDiv = document.createElement('div');\n      labelDiv.className = 'pattern-segment-label';\n      labelDiv.textContent = `Segment ${index + 1}`;\n      \n      // Create canvas for segment visualization\n      const canvas = document.createElement('canvas');\n      canvas.width = container.clientWidth / pattern.segments.length;\n      canvas.height = container.clientHeight;\n      \n      segmentDiv.appendChild(labelDiv);\n      segmentDiv.appendChild(canvas);\n      container.appendChild(segmentDiv);\n      \n      // Draw segment spectrogram\n      const ctx = canvas.getContext('2d');\n      \n      // Draw as a grid of colored cells\n      const blockWidth = canvas.width / segment.spectrogram.length;\n      const blockHeight = canvas.height / 128;\n      \n      for (let i = 0; i < segment.spectrogram.length; i++) {\n        for (let j = 0; j < segment.spectrogram[i].length; j++) {\n          const value = segment.spectrogram[i][j];\n          const hue = value < 0.2 ? 240 : 240 - (value - 0.2) / 0.8 * 240;\n          ctx.fillStyle = `hsl(${hue}, 100%, 50%)`;\n          ctx.fillRect(\n            i * blockWidth, \n            canvas.height - (j + 1) * blockHeight,\n            blockWidth,\n            blockHeight\n          );\n        }\n      }\n    });\n    \n    // Update segment markers\n    updateSegmentMarkers(elements.recordSegmentMarkers, pattern);\n  }\n  \n  function updateSegmentMarkers(container, pattern) {\n    if (!pattern || !pattern.boundaries) {\n      container.innerHTML = '';\n      return;\n    }\n    \n    container.innerHTML = '';\n    \n    // Create markers\n    pattern.boundaries.forEach(boundary => {\n      // Start marker\n      const startMarker = document.createElement('div');\n      startMarker.className = 'segment-marker';\n      startMarker.style.left = `${boundary.start * 100}%`;\n      container.appendChild(startMarker);\n      \n      // Label\n      const label = document.createElement('div');\n      label.className = 'segment-label';\n      label.textContent = `${boundary.index + 1}`;\n      label.style.left = `${(boundary.start + (boundary.end - boundary.start) / 2) * 100}%`;\n      container.appendChild(label);\n    });\n  }\n  \n  function updatePatternInfo() {\n    const pattern = detector.state.patterns[detector.state.activePatternIndex];\n    \n    if (!pattern || !pattern.segments || pattern.segments.length === 0) {\n      elements.patternInfo.textContent = 'No pattern recorded';\n      elements.patternStats.innerHTML = '';\n      elements.startBtn.disabled = true;\n      elements.playLastBtn.disabled = true;\n      return;\n    }\n    \n    // Update basic info\n    elements.patternInfo.textContent = `Pattern ${detector.state.activePatternIndex + 1}: ${pattern.segments.length} segments (${(pattern.rawData.duration/1000).toFixed(1)}s)`;\n    \n    // Enable buttons\n    elements.startBtn.disabled = false;\n    elements.playLastBtn.disabled = false;\n    \n    // Show segment stats\n    const statsContainer = elements.patternStats;\n    statsContainer.innerHTML = '';\n    \n    // Add pattern stats\n    pattern.segments.forEach((segment, index) => {\n      const segmentStat = document.createElement('div');\n      segmentStat.className = 'pattern-stat';\n      segmentStat.textContent = `Segment ${index + 1}: ${((segment.endFrame - segment.startFrame) / pattern.rawData.energy.length * pattern.rawData.duration / 1000).toFixed(2)}s`;\n      statsContainer.appendChild(segmentStat);\n    });\n    \n    // Add a recommendation based on pattern length\n    const recommendStat = document.createElement('div');\n    recommendStat.className = 'pattern-stat';\n    \n    if (pattern.rawData.duration < 1000) {\n      recommendStat.textContent = 'Recommended: Record a longer pattern';\n    } else if (pattern.segments.length <= 3) {\n      recommendStat.textContent = 'Recommended: Use Adaptive mode';\n    } else {\n      recommendStat.textContent = 'Pattern looks good!';\n    }\n    \n    statsContainer.appendChild(recommendStat);\n  }\n  \n  function updateDebugPanel(debugData) {\n    const panel = elements.debugPanel;\n    panel.innerHTML = '';\n    \n    // Helper to create debug items\n    const createItem = (title, value) => {\n      const item = document.createElement('div');\n      item.className = 'debug-item';\n      item.innerHTML = `<div class=\"debug-item-title\">${title}</div>${value}`;\n      panel.appendChild(item);\n    };\n    \n    // Create debug info items\n    if (debugData.currentSegment) {\n      createItem('Current Segment', `${debugData.currentSegment} of ${debugData.totalSegments}`);\n    }\n    \n    if (debugData.matchScore !== undefined) {\n      const score = Math.round(debugData.matchScore * 100);\n      const threshold = Math.round((debugData.adjustedThreshold || debugData.threshold) * 100);\n      const scoreDiff = score - threshold;\n      const color = scoreDiff >= 0 ? '#4caf50' : '#f44336';\n      \n      createItem('Match Score', `<span style=\"color:${color}\">${score}%</span> (threshold: ${threshold}%)`);\n    }\n    \n    if (debugData.timeInSegment) {\n      const time = debugData.timeInSegment;\n      const minTime = debugData.minSegmentTime;\n      const timePercent = Math.min(100, Math.round(time / minTime * 100));\n      \n      createItem('Time in Segment', `${time}ms / ${minTime}ms (${timePercent}%)`);\n    }\n    \n    if (debugData.bestMatchIndex) {\n      const bestScore = Math.round(debugData.bestMatchScore * 100);\n      createItem('Best Match', `Segment ${debugData.bestMatchIndex} (${bestScore}%)`);\n    }\n    \n    if (debugData.progress !== undefined) {\n      const progress = Math.round(debugData.progress * 100);\n      createItem('Overall Progress', `${progress}%`);\n    }\n    \n    // Add special status indicators\n    if (debugData.advanced) {\n      createItem('Status', '<span style=\"color:#4caf50\">Advanced to next segment</span>');\n    } else if (debugData.timeout) {\n      createItem('Status', '<span style=\"color:#f44336\">Timeout - reset</span>');\n    } else if (debugData.skipped) {\n      createItem('Status', `<span style=\"color:#ff9800\">Skipped to segment ${debugData.skippedTo}</span>`);\n    } else if (debugData.jumped) {\n      createItem('Status', `<span style=\"color:#ff9800\">Jumped ahead to ${debugData.jumpedTo}</span>`);\n    } else if (debugData.adaptiveSkip) {\n      createItem('Status', `<span style=\"color:#2196f3\">Adaptive skip to ${debugData.skippedTo}</span>`);\n    } else if (debugData.finalSegmentBoost) {\n      createItem('Final Segment Boost', '<span style=\"color:#8bc34a\">Active</span>');\n    }\n  }\n  \n  function logDetection(message, highlight = false) {\n    const entry = document.createElement('div');\n    \n    if (highlight) {\n      entry.className = 'highlight';\n    }\n    \n    const time = new Date().toLocaleTimeString();\n    entry.innerHTML = `<span class=\"time\">[${time}]</span> ${message}`;\n    \n    elements.detectionLog.appendChild(entry);\n    \n    // Scroll to bottom\n    elements.detectionLog.scrollTop = elements.detectionLog.scrollHeight;\n    \n    // Limit log size\n    while (elements.detectionLog.childNodes.length > 50) {\n      elements.detectionLog.removeChild(elements.detectionLog.firstChild);\n    }\n  }\n  \n  // Initial setup\n  updatePatternInfo();\n  \n  // Add initial log entry\n  logDetection('Enhanced Chant Detector ready. Record a pattern to begin.');\n});",
              "old_str": "}",
              "version_uuid": "b49d9a7e-e03f-48cd-acff-03efee2a3e52"
            },
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "81bfd7d8-9ff1-459a-843a-f4e1b6d32b29"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-03-17T16:55:05.638781Z",
            "stop_timestamp": "2025-03-17T16:55:15.135912Z",
            "flags": null,
            "type": "text",
            "text": "\n\nI've created a streamlined, enhanced chant detector that addresses the key issues in the original code. Here are the major improvements I've implemented:\n\n1. **Better Final Segment Detection**:\n   - Added a dedicated \"Final Segment Boost\" slider that makes it easier to recognize the last segment by lowering its threshold\n   - Increased the detection buffer size specifically for the last segment\n   - Added more flexible timing thresholds for the final segment\n\n2. **Improved Visualization and Feedback**:\n   - Enhanced the spectrogram visualization with better color mapping\n   - Added confidence indicators to show how well each segment matches\n   - Improved the sequence progress display with more informative visual cues\n\n3. **Adaptive Detection Algorithm**:\n   - Made the adaptive algorithm the default since it works better in most cases\n   - Implemented progressive threshold adjustments that get easier as you progress through the pattern\n   - Added intelligent pattern recovery that can skip segments when appropriate\n\n4. **More Efficient Pattern Segmentation**:\n   - Better handling of pattern division to ensure the correct number of segments\n   - Improved boundary detection for more natural pattern division\n   - Balanced segmentation when natural boundaries aren't clear\n\n5. **Mobile-Friendly Updates**:\n   - Added touch event support for recording on mobile devices\n   - Improved button sizes and responsive layout\n   - Simplified the UI for better usability\n\nTo use this improved detector:\n\n1. Press and hold the \"Record\" button while chanting your pattern\n2. When you finish your chant, release the button\n3. The pattern will be automatically segmented (you'll see the segments in the display)\n4. Click \"Start Detection\" and repeat your chant - it should now detect it reliably!\n\nFor best results:\n- Use the \"Adaptive\" detection mode (default)\n- Record 2-3 samples and use the \"Average Patterns\" button\n- If the final segment isn't detected well, lower the \"Final Segment Boost\" value\n- For more challenging patterns, lower the \"Match Threshold\" slightly\n\nThis solution should make it much easier to detect complete patterns, especially addressing the issue with recognizing the final segment.",
            "citations": []
          }
        ],
        "updated_at": "2025-03-17T16:55:15.962173Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "81b344e0-d4a6-4674-8810-fc69da86d72c",
      "role": "human",
      "content": "finish this file, what comes next?",
      "created_at": "2025-03-17T17:10:30.125088Z",
      "sequence_order": 6,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-03-14T21:50:46.686594Z",
            "stop_timestamp": "2025-03-14T21:50:46.686594Z",
            "flags": null,
            "type": "text",
            "text": "finish this file, what comes next?",
            "citations": []
          }
        ],
        "updated_at": "2025-03-17T17:10:30.125088Z",
        "attachments": [
          {
            "file_name": "paste.txt",
            "file_size": 99312,
            "file_type": "txt",
            "extracted_content": "// Here's the complete solution - an improved chant detector with better pattern recognition\n// This is a full HTML file with embedded JavaScript\n\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <title>Enhanced Chant Detector</title>\n  <script src=\"https://unpkg.com/meyda@5.2.0/dist/web/meyda.min.js\"></script>\n  <style>\n    body {\n      font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n      max-width: 900px;\n      margin: 0 auto;\n      padding: 20px;\n      line-height: 1.5;\n      background-color: #f8f9fa;\n      color: #333;\n    }\n\n// Main Application\ndocument.addEventListener('DOMContentLoaded', () => {\n  // Elements\n  const elements = {\n    // Pattern recording \n    recordingStatus: document.getElementById('recordingStatus'),\n    recordBtn: document.getElementById('recordBtn'),\n    playLastBtn: document.getElementById('playLastBtn'),\n    clearBtn: document.getElementById('clearBtn'),\n    averageBtn: document.getElementById('averageBtn'),\n    patternInfo: document.getElementById('patternInfo'),\n    patternStats: document.getElementById('patternStats'),\n    patternDisplay: document.getElementById('patternDisplay'),\n    recordSpectrogram: document.getElementById('recordSpectrogram'),\n    recordSegmentMarkers: document.getElementById('recordSegmentMarkers'),\n    \n    // Detection\n    liveSpectrogram: document.getElementById('liveSpectrogram'),\n    liveSegmentMarkers: document.getElementById('liveSegmentMarkers'),\n    timeCursor: document.getElementById('timeCursor'),\n    detectionStatus: document.getElementById('detectionStatus'),\n    counterValue: document.getElementById('counterValue'),\n    sequenceProgress: document.getElementById('sequenceProgress'),\n    detectionProgress: document.getElementById('detectionProgress'),\n    \n    // Controls\n    startBtn: document.getElementById('startBtn'),\n    stopBtn: document.getElementById('stopBtn'),\n    resetBtn: document.getElementById('resetBtn'),\n    patternTabs: document.querySelectorAll('.pattern-tab'),\n    \n    // Settings\n    detectionMode: document.getElementById('detectionMode'),\n    minMatchSlider: document.getElementById('minMatchSlider'),\n    minMatchValue: document.getElementById('minMatchValue'),\n    advanceThresholdSlider: document.getElementById('advanceThresholdSlider'),\n    advanceThresholdValue: document.getElementById('advanceThresholdValue'),\n    timeoutSlider: document.getElementById('timeoutSlider'),\n    timeoutValue: document.getElementById('timeoutValue'),\n    cooldownSlider: document.getElementById('cooldownSlider'),\n    cooldownValue: document.getElementById('cooldownValue'),\n    segmentCountSelect: document.getElementById('segmentCountSelect'),\n    finalSegmentBoostSlider: document.getElementById('finalSegmentBoostSlider'),\n    finalSegmentBoostValue: document.getElementById('finalSegmentBoostValue'),\n    \n    // Debug\n    debugPanel: document.getElementById('debugPanel'),\n    detectionLog: document.getElementById('detectionLog')\n  };\n  \n  // Canvas contexts\n  const contexts = {\n    recordSpectrogram: elements.recordSpectrogram.getContext('2d'),\n    liveSpectrogram: elements.liveSpectrogram.getContext('2d')\n  };\n  \n  // Create detector\n  const detector = new EnhancedChantDetector();\n  \n  // Set up detector callbacks\n  detector.setCallbacks({\n    onStatusUpdate: (type, message, data) => {\n      if (type === 'status') {\n        elements.detectionStatus.textContent = message;\n      } else if (type === 'info') {\n        logDetection(message, false);\n      } else if (type === 'detection') {\n        logDetection(message, data);\n      } else if (type === 'control') {\n        if (message === 'enableAveraging') {\n          elements.averageBtn.disabled = !data;\n        }\n      }\n    },\n    \n    onVisualizationUpdate: (mode, audioData, features) => {\n      if (mode === 'recording') {\n        drawSpectrogram(contexts.recordSpectrogram, features.raw.frequencyData);\n      } else if (mode === 'detection') {\n        drawSpectrogram(contexts.liveSpectrogram, features.raw.frequencyData);\n      } else if (mode === 'patternSwitch') {\n        updatePatternDisplay(features);\n      }\n    },\n    \n    onDetection: (count, confidence) => {\n      elements.counterValue.textContent = count;\n      \n      // Flash effect on detection\n      elements.detectionProgress.style.background = 'linear-gradient(90deg, #f44336, #e91e63)';\n      \n      setTimeout(() => {\n        elements.detectionProgress.style.background = 'linear-gradient(90deg, #4caf50, #8bc34a)';\n      }, 300);\n      \n      // Add success class to latest log entry\n      const lastLog = elements.detectionLog.lastElementChild;\n      if (lastLog) {\n        lastLog.classList.add('success');\n      }\n    },\n    \n    onProgressUpdate: (sequenceState, debugData) => {\n      // Update progress bar\n      elements.detectionProgress.style.width = `${Math.round(sequenceState.progress * 100)}%`;\n      \n      // Update sequence progress visualization\n      updateSequenceProgress(sequenceState);\n      \n      // Update debug panel\n      if (debugData) {\n        updateDebugPanel(debugData);\n      }\n    },\n    \n    onError: (message, error) => {\n      console.error(message, error);\n      logDetection(`Error: ${message}`, true);\n    }\n  });\n  \n  // Button handlers\n  elements.recordBtn.addEventListener('mousedown', () => {\n    detector.startRecording();\n    elements.recordBtn.textContent = 'Recording...';\n    elements.recordBtn.classList.add('recording');\n  });\n  \n  elements.recordBtn.addEventListener('mouseup', () => {\n    detector.stopRecording();\n    elements.recordBtn.textContent = 'Record (Hold)';\n    elements.recordBtn.classList.remove('recording');\n    updatePatternInfo();\n  });\n  \n  elements.recordBtn.addEventListener('mouseleave', () => {\n    if (detector.state.isRecording) {\n      detector.stopRecording();\n      elements.recordBtn.textContent = 'Record (Hold)';\n      elements.recordBtn.classList.remove('recording');\n      updatePatternInfo();\n    }\n  });\n  \n  // Touch support for mobile\n  elements.recordBtn.addEventListener('touchstart', (e) => {\n    e.preventDefault(); // Prevent scrolling\n    detector.startRecording();\n    elements.recordBtn.textContent = 'Recording...';\n    elements.recordBtn.classList.add('recording');\n  });\n  \n  elements.recordBtn.addEventListener('touchend', (e) => {\n    e.preventDefault();\n    detector.stopRecording();\n    elements.recordBtn.textContent = 'Record (Hold)';\n    elements.recordBtn.classList.remove('recording');\n    updatePatternInfo();\n  });\n  \n  elements.playLastBtn.addEventListener('click', () => {\n    detector.playLastPattern();\n  });\n  \n  elements.clearBtn.addEventListener('click', () => {\n    detector.clearActivePattern();\n    updatePatternInfo();\n    elements.startBtn.disabled = true;\n    elements.playLastBtn.disabled = true;\n    \n    // Clear display\n    elements.patternDisplay.innerHTML = '';\n    elements.recordSegmentMarkers.innerHTML = '';\n    clearCanvas(contexts.recordSpectrogram);\n  });\n  \n  elements.averageBtn.addEventListener('click', () => {\n    detector.averageAllPatterns();\n    updatePatternInfo();\n  });\n  \n  elements.startBtn.addEventListener('click', () => {\n    detector.startDetection();\n    elements.startBtn.disabled = true;\n    elements.stopBtn.disabled = false;\n  });\n  \n  elements.stopBtn.addEventListener('click', () => {\n    detector.stopDetection();\n    elements.startBtn.disabled = false;\n    elements.stopBtn.disabled = true;\n    \n    // Reset visualizations\n    elements.detectionProgress.style.width = '0%';\n    elements.sequenceProgress.innerHTML = '';\n    elements.liveSegmentMarkers.innerHTML = '';\n    clearCanvas(contexts.liveSpectrogram);\n  });\n  \n  elements.resetBtn.addEventListener('click', () => {\n    detector.resetCounter();\n  });\n  \n  // Pattern tabs\n  elements.patternTabs.forEach(tab => {\n    tab.addEventListener('click', () => {\n      const patternIndex = parseInt(tab.getAttribute('data-pattern')) - 1;\n      \n      // Update active tab\n      elements.patternTabs.forEach(t => t.classList.remove('active'));\n      tab.classList.add('active');\n      \n      // Set active pattern\n      detector.setActivePattern(patternIndex);\n      \n      updatePatternInfo();\n    });\n  });\n  \n  // Settings handlers\n  elements.detectionMode.addEventListener('change', () => {\n    detector.updateConfig({\n      detectionMode: elements.detectionMode.value\n    });\n    \n    logDetection(`Detection mode changed to: ${elements.detectionMode.value}`);\n  });\n  \n  elements.minMatchSlider.addEventListener('input', () => {\n    const value = elements.minMatchSlider.value;\n    elements.minMatchValue.textContent = value;\n    \n    detector.updateConfig({\n      minMatchThreshold: parseFloat(value)\n    });\n  });\n  \n  elements.advanceThresholdSlider.addEventListener('input', () => {\n    const value = elements.advanceThresholdSlider.value;\n    elements.advanceThresholdValue.textContent = value;\n    \n    detector.updateConfig({\n      advanceThreshold: parseFloat(value)\n    });\n  });\n  \n  elements.timeoutSlider.addEventListener('input', () => {\n    const value = elements.timeoutSlider.value;\n    elements.timeoutValue.textContent = value;\n    \n    detector.updateConfig({\n      segmentTimeout: parseInt(value)\n    });\n  });\n  \n  elements.cooldownSlider.addEventListener('input', () => {\n    const value = elements.cooldownSlider.value;\n    elements.cooldownValue.textContent = value;\n    \n    detector.updateConfig({\n      cooldownTime: parseInt(value)\n    });\n  });\n  \n  elements.segmentCountSelect.addEventListener('change', () => {\n    detector.updateConfig({\n      segmentCount: parseInt(elements.segmentCountSelect.value)\n    });\n    \n    // Update pattern info if we have a pattern\n    if (detector.state.patterns[detector.state.activePatternIndex]) {\n      updatePatternInfo();\n    }\n  });\n  \n  elements.finalSegmentBoostSlider.addEventListener('input', () => {\n    const value = elements.finalSegmentBoostSlider.value;\n    elements.finalSegmentBoostValue.textContent = value;\n    \n    detector.updateConfig({\n      finalSegmentBoost: parseFloat(value)\n    });\n  });\n  \n  // Visualization functions\n  function drawSpectrogram(ctx, frequencyData) {\n    const width = ctx.canvas.width;\n    const height = ctx.canvas.height;\n    \n    // Shift existing spectrogram left\n    const imgData = ctx.getImageData(1, 0, width - 1, height);\n    ctx.putImageData(imgData, 0, 0);\n    \n    // Draw new column\n    const columnWidth = 1;\n    const binCount = Math.min(128, frequencyData.length / 4);\n    const binHeight = height / binCount;\n    \n    for (let i = 0; i < binCount; i++) {\n      // Reverse order (low frequency at bottom)\n      const y = height - (i + 1) * binHeight;\n      \n      // Average a range of frequency bins\n      const startBin = i * 4;\n      const endBin = startBin + 4;\n      \n      let binSum = 0;\n      for (let j = startBin; j < endBin && j < frequencyData.length; j++) {\n        binSum += frequencyData[j];\n      }\n      \n      const intensity = binSum / 4;\n      \n      // Create color (blue to red gradient)\n      // Improved color mapping for better visualization\n      const hue = intensity < 50 ? 240 : 240 - ((intensity - 50) / 205 * 240);\n      const saturation = '100%';\n      const lightness = `${Math.min(50 + intensity / 10, 80)}%`;\n      \n      ctx.fillStyle = `hsl(${hue}, ${saturation}, ${lightness})`;\n      ctx.fillRect(width - columnWidth, y, columnWidth, binHeight);\n    }\n  }\n  \n  function clearCanvas(ctx) {\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n  }\n  \n  function updateSequenceProgress(sequenceState) {\n    const container = elements.sequenceProgress;\n    container.innerHTML = '';\n    \n    // Create segment boxes\n    sequenceState.segments.forEach((state, index) => {\n      const segmentBox = document.createElement('div');\n      segmentBox.className = `segment-box segment-${state}`;\n      segmentBox.textContent = index + 1;\n      \n      // Add confidence indicator bar at bottom\n      if (sequenceState.matchScores && sequenceState.matchScores[index]) {\n        const score = sequenceState.matchScores[index] * 100;\n        segmentBox.style.setProperty('--score', `${score}%`);\n        segmentBox.style.setProperty('--score-color', getScoreColor(score));\n        segmentBox.setAttribute('title', `Match: ${Math.round(score)}%`);\n        \n        // Set width of score indicator\n        segmentBox.style.setProperty('--after-width', `${score}%`);\n      }\n      \n      container.appendChild(segmentBox);\n    });\n    \n    // Update segment markers on live spectrogram\n    updateSegmentMarkers(\n      elements.liveSegmentMarkers, \n      detector.state.patterns[detector.state.activePatternIndex]\n    );\n  }\n  \n  function getScoreColor(score) {\n    if (score >= 80) return '#4caf50';\n    if (score >= 60) return '#8bc34a';\n    if (score >= 40) return '#ffc107';\n    if (score >= 20) return '#ff9800';\n    return '#f44336';\n  }\n  \n  function updatePatternDisplay(pattern) {\n    if (!pattern || !pattern.segments || pattern.segments.length === 0) {\n      elements.patternDisplay.innerHTML = '';\n      elements.recordSegmentMarkers.innerHTML = '';\n      return;\n    }\n    \n    // Create segment display\n    const container = elements.patternDisplay;\n    container.innerHTML = '';\n    \n    // Create segment divs\n    pattern.segments.forEach((segment, index) => {\n      const segmentDiv = document.createElement('div');\n      segmentDiv.className = 'pattern-segment';\n      \n      // Add label\n      const labelDiv = document.createElement('div');\n      labelDiv.className = 'pattern-segment-label';\n      labelDiv.textContent = `Segment ${index + 1}`;\n      \n      // Create canvas for segment visualization\n      const canvas = document.createElement('canvas');\n      canvas.width = container.clientWidth / pattern.segments.length;\n      canvas.height = container.clientHeight;\n      \n      segmentDiv.appendChild(labelDiv);\n      segmentDiv.appendChild(canvas);\n      container.appendChild(segmentDiv);\n      \n      // Draw segment spectrogram\n      const ctx = canvas.getContext('2d');\n      \n      // Draw as a grid of colored cells\n      const blockWidth = canvas.width / segment.spectrogram.length;\n      const blockHeight = canvas.height / 128;\n      \n      for (let i = 0; i < segment.spectrogram.length; i++) {\n        for (let j = 0; j < segment.spectrogram[i].length; j++) {\n          const value = segment.spectrogram[i][j];\n          const hue = value < 0.2 ? 240 : 240 - (value - 0.2) / 0.8 * 240;\n          ctx.fillStyle = `hsl(${hue}, 100%, 50%)`;\n          ctx.fillRect(\n            i * blockWidth, \n            canvas.height - (j + 1) * blockHeight,\n            blockWidth,\n            blockHeight\n          );\n        }\n      }\n    });\n    \n    // Update segment markers\n    updateSegmentMarkers(elements.recordSegmentMarkers, pattern);\n  }\n  \n  function updateSegmentMarkers(container, pattern) {\n    if (!pattern || !pattern.boundaries) {\n      container.innerHTML = '';\n      return;\n    }\n    \n    container.innerHTML = '';\n    \n    // Create markers\n    pattern.boundaries.forEach(boundary => {\n      // Start marker\n      const startMarker = document.createElement('div');\n      startMarker.className = 'segment-marker';\n      startMarker.style.left = `${boundary.start * 100}%`;\n      container.appendChild(startMarker);\n      \n      // Label\n      const label = document.createElement('div');\n      label.className = 'segment-label';\n      label.textContent = `${boundary.index + 1}`;\n      label.style.left = `${(boundary.start + (boundary.end - boundary.start) / 2) * 100}%`;\n      container.appendChild(label);\n    });\n  }\n  \n  function updatePatternInfo() {\n    const pattern = detector.state.patterns[detector.state.activePatternIndex];\n    \n    if (!pattern || !pattern.segments || pattern.segments.length === 0) {\n      elements.patternInfo.textContent = 'No pattern recorded';\n      elements.patternStats.innerHTML = '';\n      elements.startBtn.disabled = true;\n      elements.playLastBtn.disabled = true;\n      return;\n    }\n    \n    // Update basic info\n    elements.patternInfo.textContent = `Pattern ${detector.state.activePatternIndex + 1}: ${pattern.segments.length} segments (${(pattern.rawData.duration/1000).toFixed(1)}s)`;\n    \n    // Enable buttons\n    elements.startBtn.disabled = false;\n    elements.playLastBtn.disabled = false;\n    \n    // Show segment stats\n    const statsContainer = elements.patternStats;\n    statsContainer.innerHTML = '';\n    \n    // Add pattern stats\n    pattern.segments.forEach((segment, index) => {\n      const segmentStat = document.createElement('div');\n      segmentStat.className = 'pattern-stat';\n      segmentStat.textContent = `Segment ${index + 1}: ${((segment.endFrame - segment.startFrame) / pattern.rawData.energy.length * pattern.rawData.duration / 1000).toFixed(2)}s`;\n      statsContainer.appendChild(segmentStat);\n    });\n    \n    // Add a recommendation based on pattern length\n    const recommendStat = document.createElement('div');\n    recommendStat.className = 'pattern-stat';\n    \n    if (pattern.rawData.duration < 1000) {\n      recommendStat.textContent = 'Recommended: Record a longer pattern';\n    } else if (pattern.segments.length <= 3) {\n      recommendStat.textContent = 'Recommended: Use Adaptive mode';\n    } else {\n      recommendStat.textContent = 'Pattern looks good!';\n    }\n    \n    statsContainer.appendChild(recommendStat);\n  }\n  \n  function updateDebugPanel(debugData) {\n    const panel = elements.debugPanel;\n    panel.innerHTML = '';\n    \n    // Helper to create debug items\n    const createItem = (title, value) => {\n      const item = document.createElement('div');\n      item.className = 'debug-item';\n      item.innerHTML = `<div class=\"debug-item-title\">${title}</div>${value}`;\n      panel.appendChild(item);\n    };\n    \n    // Create debug info items\n    if (debugData.currentSegment) {\n      createItem('Current Segment', `${debugData.currentSegment} of ${debugData.totalSegments}`);\n    }\n    \n    if (debugData.matchScore !== undefined) {\n      const score = Math.round(debugData.matchScore * 100);\n      const threshold = Math.round((debugData.adjustedThreshold || debugData.threshold) * 100);\n      const scoreDiff = score - threshold;\n      const color = scoreDiff >= 0 ? '#4caf50' : '#f44336';\n      \n      createItem('Match Score', `<span style=\"color:${color}\">${score}%</span> (threshold: ${threshold}%)`);\n    }\n    \n    if (debugData.timeInSegment) {\n      const time = debugData.timeInSegment;\n      const minTime = debugData.minSegmentTime;\n      const timePercent = Math.min(100, Math.round(time / minTime * 100));\n      \n      createItem('Time in Segment', `${time}ms / ${minTime}ms (${timePercent}%)`);\n    }\n    \n    if (debugData.bestMatchIndex) {\n      const bestScore = Math.round(debugData.bestMatchScore * 100);\n      createItem('Best Match', `Segment ${debugData.bestMatchIndex} (${bestScore}%)`);\n    }\n    \n    if (debugData.progress !== undefined) {\n      const progress = Math.round(debugData.progress * 100);\n      createItem('Overall Progress', `${progress}%`);\n    }\n    \n    // Add special status indicators\n    if (debugData.advanced) {\n      createItem('Status', '<span style=\"color:#4caf50\">Advanced to next segment</span>');\n    } else if (debugData.timeout) {\n      createItem('Status', '<span style=\"color:#f44336\">Timeout - reset</span>');\n    } else if (debugData.skipped) {\n      createItem('Status', `<span style=\"color:#ff9800\">Skipped to segment ${debugData.skippedTo}</span>`);\n    } else if (debugData.jumped) {\n      createItem('Status', `<span style=\"color:#ff9800\">Jumped ahead to ${debugData.jumpedTo}</span>`);\n    } else if (debugData.adaptiveSkip) {\n      createItem('Status', `<span style=\"color:#2196f3\">Adaptive skip to ${debugData.skippedTo}</span>`);\n    } else if (debugData.finalSegmentBoost) {\n      createItem('Final Segment Boost', '<span style=\"color:#8bc34a\">Active</span>');\n    }\n  }\n  \n  function logDetection(message, highlight = false) {\n    const entry = document.createElement('div');\n    \n    if (highlight) {\n      entry.className = 'highlight';\n    }\n    \n    const time = new Date().toLocaleTimeString();\n    entry.innerHTML = `<span class=\"time\">[${time}]</span> ${message}`;\n    \n    elements.detectionLog.appendChild(entry);\n    \n    // Scroll to bottom\n    elements.detectionLog.scrollTop = elements.detectionLog.scrollHeight;\n    \n    // Limit log size\n    while (elements.detectionLog.childNodes.length > 50) {\n      elements.detectionLog.removeChild(elements.detectionLog.firstChild);\n    }\n  }\n  \n  // Initial setup\n  updatePatternInfo();\n  \n  // Add initial log entry\n  logDetection('Enhanced Chant Detector ready. Record a pattern to begin.');\n});\n    section {\n      background: #fff;\n      padding: 20px;\n      margin-bottom: 20px;\n      border-radius: 8px;\n      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);\n    }\n    h1, h2 { \n      margin-top: 0;\n      color: #2c3e50;\n    }\n    button {\n      background: #4285f4;\n      color: white;\n      border: none;\n      padding: 10px 15px;\n      margin-right: 10px;\n      margin-bottom: 10px;\n      cursor: pointer;\n      border-radius: 4px;\n      font-weight: 500;\n      transition: background 0.2s;\n    }\n    button:hover {\n      background: #356ac3;\n    }\n    button:disabled { \n      background: #ccc;\n      cursor: not-allowed;\n    }\n    .counter {\n      font-size: 48px;\n      font-weight: bold;\n      text-align: center;\n      margin: 15px 0;\n      color: #2c3e50;\n    }\n    .row {\n      display: flex;\n      align-items: center;\n      margin: 10px 0;\n    }\n    label {\n      width: 200px;\n      margin-right: 15px;\n      font-weight: 500;\n    }\n    .settings-value {\n      min-width: 45px;\n      text-align: right;\n      font-weight: bold;\n      margin-left: 10px;\n    }\n    .status {\n      background: #f1f3f5;\n      padding: 12px;\n      margin: 10px 0;\n      border-radius: 4px;\n      font-family: monospace;\n      border-left: 4px solid #4285f4;\n    }\n    \n    /* Visualization Styles */\n    .visualizer-container {\n      position: relative;\n      height: 150px;\n      margin: 15px 0;\n      border: 1px solid #e1e4e8;\n      border-radius: 4px;\n      background-color: #121212;\n      overflow: hidden;\n    }\n    .visualizer-canvas {\n      position: absolute;\n      top: 0;\n      left: 0;\n      width: 100%;\n      height: 100%;\n    }\n    .segment-markers {\n      position: absolute;\n      top: 0;\n      left: 0;\n      width: 100%;\n      height: 100%;\n      pointer-events: none;\n    }\n    .segment-marker {\n      position: absolute;\n      top: 0;\n      height: 100%;\n      width: 2px;\n      background-color: rgba(255, 255, 255, 0.6);\n    }\n    .segment-label {\n      position: absolute;\n      top: 5px;\n      background-color: rgba(0, 0, 0, 0.6);\n      color: white;\n      padding: 3px 6px;\n      border-radius: 3px;\n      font-size: 11px;\n      transform: translateX(-50%);\n    }\n    .time-cursor {\n      position: absolute;\n      top: 0;\n      height: 100%;\n      width: 2px;\n      background-color: rgb(255, 64, 129);\n      transition: left 0.1s ease-out;\n      box-shadow: 0 0 10px rgb(255, 64, 129);\n    }\n    \n    .sequence-progress {\n      display: flex;\n      height: 40px;\n      background: #f1f3f5;\n      margin: 15px 0;\n      border-radius: 4px;\n      overflow: hidden;\n    }\n    .segment-box {\n      flex: 1;\n      height: 100%;\n      display: flex;\n      align-items: center;\n      justify-content: center;\n      color: white;\n      font-weight: bold;\n      transition: background-color 0.3s;\n      border-right: 1px solid rgba(255,255,255,0.3);\n      position: relative;\n    }\n    .segment-box::after {\n      content: '';\n      position: absolute;\n      bottom: 0;\n      left: 0;\n      height: 3px;\n      background-color: #4285f4;\n      transition: width 0.3s ease-out;\n    }\n    .segment-pending { background-color: #90a4ae; }\n    .segment-active { \n      background-color: #ff9800; \n      animation: pulse 1.5s infinite;\n    }\n    .segment-complete { background-color: #4caf50; }\n    .segment-invalid { background-color: #f44336; }\n    \n    @keyframes pulse {\n      0% { background-color: #ff9800; }\n      50% { background-color: #ffb74d; }\n      100% { background-color: #ff9800; }\n    }\n    \n    .detection-bar {\n      height: 20px;\n      position: relative;\n      margin: 10px 0;\n      background: #f1f3f5;\n      border-radius: 4px;\n      overflow: hidden;\n    }\n    .detection-progress {\n      position: absolute;\n      height: 100%;\n      width: 0%;\n      background: linear-gradient(90deg, #4caf50, #8bc34a);\n      transition: width 0.3s ease-out;\n    }\n    \n    .pattern-display {\n      width: 100%;\n      height: 120px;\n      position: relative;\n      background: #121212;\n      margin: 15px 0;\n      display: flex;\n      border-radius: 4px;\n      overflow: hidden;\n    }\n    .pattern-segment {\n      flex: 1;\n      height: 100%;\n      overflow: hidden;\n      position: relative;\n      border-right: 1px dashed rgba(255,255,255,0.3);\n    }\n    .pattern-segment-label {\n      position: absolute;\n      top: 5px;\n      left: 5px;\n      background-color: rgba(0,0,0,0.6);\n      color: white;\n      padding: 2px 5px;\n      font-size: 10px;\n      z-index: 10;\n      border-radius: 3px;\n    }\n    \n    .debug-panel {\n      display: grid;\n      grid-template-columns: repeat(3, 1fr);\n      grid-gap: 10px;\n      margin: 10px 0;\n    }\n    .debug-item {\n      background: #f1f3f5;\n      padding: 8px;\n      font-size: 12px;\n      border-radius: 4px;\n    }\n    .debug-item-title {\n      font-weight: bold;\n      margin-bottom: 3px;\n      color: #2c3e50;\n    }\n    \n    .log {\n      height: 150px;\n      overflow-y: auto;\n      background: #f8f9fa;\n      border: 1px solid #e1e4e8;\n      padding: 10px;\n      font-family: monospace;\n      font-size: 12px;\n      border-radius: 4px;\n    }\n    .log div {\n      margin-bottom: 3px;\n      padding-bottom: 3px;\n      border-bottom: 1px solid #f1f3f5;\n    }\n    .highlight { color: #e91e63; font-weight: bold; }\n    .success { color: #4caf50; font-weight: bold; }\n    \n    .pattern-info {\n      display: flex;\n      flex-wrap: wrap;\n      margin: 10px 0;\n    }\n    .pattern-stat {\n      background: #e9ecef;\n      padding: 3px 8px;\n      margin-right: 8px;\n      margin-bottom: 8px;\n      border-radius: 4px;\n      font-size: 12px;\n    }\n    \n    .pattern-tabs {\n      display: flex;\n      margin-bottom: 10px;\n    }\n    .pattern-tab {\n      padding: 8px 15px;\n      background: #e9ecef;\n      margin-right: 8px;\n      cursor: pointer;\n      border-radius: 4px;\n      font-size: 14px;\n      transition: all 0.2s;\n    }\n    .pattern-tab:hover {\n      background: #dee2e6;\n    }\n    .pattern-tab.active {\n      background: #4285f4;\n      color: white;\n    }\n    \n    .tooltip {\n      position: relative;\n      display: inline-block;\n      cursor: help;\n      margin-left: 5px;\n    }\n    .tooltip .tooltip-text {\n      visibility: hidden;\n      width: 200px;\n      background-color: #333;\n      color: #fff;\n      text-align: center;\n      border-radius: 4px;\n      padding: 5px;\n      position: absolute;\n      z-index: 1;\n      bottom: 125%;\n      left: 50%;\n      transform: translateX(-50%);\n      opacity: 0;\n      transition: opacity 0.3s;\n      font-size: 12px;\n      pointer-events: none;\n    }\n    .tooltip:hover .tooltip-text {\n      visibility: visible;\n      opacity: 1;\n    }\n    \n    /* Responsive adjustments */\n    @media (max-width: 768px) {\n      .row {\n        flex-direction: column;\n        align-items: flex-start;\n      }\n      label {\n        width: 100%;\n        margin-bottom: 5px;\n      }\n      .debug-panel {\n        grid-template-columns: 1fr;\n      }\n    }\n  </style>\n</head>\n<body>\n  <h1>Enhanced Chant Detector</h1>\n  <p>Record a chant pattern and the detector will count repetitions of it.</p>\n\n  <section>\n    <div style=\"display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;\">\n      <h2>1. Record Your Chant Pattern</h2>\n      <div class=\"pattern-tabs\">\n        <div class=\"pattern-tab active\" data-pattern=\"1\">Pattern 1</div>\n        <div class=\"pattern-tab\" data-pattern=\"2\">Pattern 2</div>\n        <div class=\"pattern-tab\" data-pattern=\"3\">Pattern 3</div>\n      </div>\n    </div>\n    \n    <div class=\"visualizer-container\">\n      <canvas id=\"recordSpectrogram\" class=\"visualizer-canvas\"></canvas>\n      <div class=\"segment-markers\" id=\"recordSegmentMarkers\"></div>\n    </div>\n    \n    <div class=\"status\" id=\"recordingStatus\">Ready to record your chant pattern</div>\n    <div>\n      <button id=\"recordBtn\">Record (Hold)</button>\n      <button id=\"playLastBtn\" disabled>Play Recording</button>\n      <button id=\"clearBtn\">Clear</button>\n      <button id=\"averageBtn\" disabled>Average Patterns</button>\n      <span id=\"patternInfo\"></span>\n    </div>\n    \n    <div class=\"pattern-display\" id=\"patternDisplay\"></div>\n    <div class=\"pattern-info\" id=\"patternStats\"></div>\n  </section>\n\n  <section>\n    <h2>2. Settings</h2>\n    <div class=\"row\">\n      <label for=\"detectionMode\">Detection Mode:</label>\n      <select id=\"detectionMode\">\n        <option value=\"adaptive\" selected>Adaptive (Recommended)</option>\n        <option value=\"flexible\">Flexible Sequential</option>\n        <option value=\"sequential\">Strict Sequential</option>\n      </select>\n      <div class=\"tooltip\">\n        <span>?</span>\n        <span class=\"tooltip-text\">Adaptive mode automatically adjusts to find patterns better.</span>\n      </div>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"minMatchSlider\">Segment Match Threshold:</label>\n      <input type=\"range\" id=\"minMatchSlider\" min=\"0.3\" max=\"0.9\" step=\"0.05\" value=\"0.5\">\n      <span id=\"minMatchValue\" class=\"settings-value\">0.5</span>\n      <div class=\"tooltip\">\n        <span>?</span>\n        <span class=\"tooltip-text\">Lower values make detection more sensitive but may increase false positives.</span>\n      </div>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"advanceThresholdSlider\">Advance Threshold:</label>\n      <input type=\"range\" id=\"advanceThresholdSlider\" min=\"0.2\" max=\"0.8\" step=\"0.05\" value=\"0.4\">\n      <span id=\"advanceThresholdValue\" class=\"settings-value\">0.4</span>\n      <div class=\"tooltip\">\n        <span>?</span>\n        <span class=\"tooltip-text\">Lower values = easier progression between segments.</span>\n      </div>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"timeoutSlider\">Segment Timeout (ms):</label>\n      <input type=\"range\" id=\"timeoutSlider\" min=\"500\" max=\"5000\" step=\"100\" value=\"3000\">\n      <span id=\"timeoutValue\" class=\"settings-value\">3000</span>\n      <div class=\"tooltip\">\n        <span>?</span>\n        <span class=\"tooltip-text\">How long to wait before resetting if stuck on a segment.</span>\n      </div>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"cooldownSlider\">Cooldown Period (ms):</label>\n      <input type=\"range\" id=\"cooldownSlider\" min=\"500\" max=\"3000\" step=\"100\" value=\"1500\">\n      <span id=\"cooldownValue\" class=\"settings-value\">1500</span>\n      <div class=\"tooltip\">\n        <span>?</span>\n        <span class=\"tooltip-text\">Wait time between detections to avoid duplicates.</span>\n      </div>\n    </div>\n    \n    <div class=\"row\">\n      <label for=\"segmentCountSelect\">Pattern Segments:</label>\n      <select id=\"segmentCountSelect\">\n        <option value=\"3\">3</option>\n        <option value=\"4\" selected>4</option>\n        <option value=\"5\">5</option>\n        <option value=\"6\">6</option>\n      </select>\n      <div class=\"tooltip\">\n        <span>?</span>\n        <span class=\"tooltip-text\">How many parts to divide your pattern into.</span>\n      </div>\n    </div>\n\n    <div class=\"row\">\n      <label for=\"finalSegmentBoostSlider\">Final Segment Boost:</label>\n      <input type=\"range\" id=\"finalSegmentBoostSlider\" min=\"0.5\" max=\"1.5\" step=\"0.1\" value=\"0.8\">\n      <span id=\"finalSegmentBoostValue\" class=\"settings-value\">0.8</span>\n      <div class=\"tooltip\">\n        <span>?</span>\n        <span class=\"tooltip-text\">Makes the last segment easier to detect (lower = easier).</span>\n      </div>\n    </div>\n  </section>\n\n  <section>\n    <h2>3. Detection</h2>\n    <div class=\"counter\" id=\"counterValue\">0</div>\n    \n    <div class=\"visualizer-container\">\n      <canvas id=\"liveSpectrogram\" class=\"visualizer-canvas\"></canvas>\n      <div class=\"segment-markers\" id=\"liveSegmentMarkers\"></div>\n      <div class=\"time-cursor\" id=\"timeCursor\" style=\"left: 50%;\"></div>\n    </div>\n    \n    <div class=\"sequence-progress\" id=\"sequenceProgress\"></div>\n    <div class=\"detection-bar\">\n      <div id=\"detectionProgress\" class=\"detection-progress\"></div>\n    </div>\n    \n    <div class=\"status\" id=\"detectionStatus\">No pattern recorded yet</div>\n    <div>\n      <button id=\"startBtn\" disabled>Start Detection</button>\n      <button id=\"stopBtn\" disabled>Stop</button>\n      <button id=\"resetBtn\">Reset Counter</button>\n    </div>\n    \n    <h3>Debug Info</h3>\n    <div class=\"debug-panel\" id=\"debugPanel\"></div>\n    <div class=\"log\" id=\"detectionLog\"></div>\n  </section>\n\n<script>\n/**\n * Enhanced Chant Detector\n * \n * Improvements:\n * 1. Better handling of the final segment in patterns\n * 2. Adaptive thresholds for different segments\n * 3. Improved visualization and feedback\n * 4. Buffer padding for more reliable detection\n * 5. Cleaner code organization and error handling\n */\nclass EnhancedChantDetector {\n  constructor() {\n    // Audio system\n    this.audioContext = null;\n    this.analyzer = null;\n    this.mediaStream = null;\n    this.processor = null;\n    this.audioBufferSource = null;\n    \n    // Configuration\n    this.config = {\n      bufferSize: 1024,\n      fftSize: 2048,\n      sampleRate: 44100,\n      minRecordDuration: 500,\n      detectionMode: 'adaptive',\n      minMatchThreshold: 0.5,     // Minimum score to consider a match\n      advanceThreshold: 0.4,      // Threshold to advance to next segment\n      segmentTimeout: 3000,       // Time before resetting stuck segment (ms)\n      cooldownTime: 1500,         // Cooldown between detections (ms)\n      segmentCount: 4,            // Number of segments in pattern\n      maxPatterns: 3,             // Maximum number of patterns to store\n      spectrogramHistory: 150,    // Number of columns in spectrogram\n      lookAheadFrames: 15,        // Frames to look ahead for flexible mode\n      finalSegmentBoost: 0.8,     // Threshold multiplier for final segment (lower = easier)\n      \n      // Feature weights for different detection aspects\n      featureWeights: {\n        spectrogram: 0.5,  // Weight for spectrogram match\n        mfcc: 0.3,         // Weight for MFCC match\n        energy: 0.2        // Weight for energy profile match\n      }\n    };\n    \n    // State\n    this.state = {\n      isRecording: false,\n      isDetecting: false,\n      inCooldown: false,\n      isPlaying: false,\n      \n      // Active pattern\n      activePatternIndex: 0,\n      \n      // Recording state\n      recordStartTime: 0,\n      recordingData: {\n        audio: [],\n        spectrogram: [],\n        mfcc: [],\n        energy: [],\n        duration: 0\n      },\n      \n      // Patterns (multiple can be stored)\n      patterns: [],\n      \n      // Detection state\n      detectionBuffer: {\n        audio: [],\n        spectrogram: [],\n        mfcc: [],\n        energy: [],\n        timeWindow: []  // Time values for visualization\n      },\n      \n      // Sequence tracking\n      sequenceState: {\n        segments: [],          // State of each segment (pending, active, complete, invalid)\n        currentIndex: 0,       // Current segment being matched\n        progress: 0,           // Overall progress (0-1)\n        matchScores: [],       // Match scores for each segment\n        segmentStartTimes: [], // When each segment started matching\n        stuckTime: 0,          // How long we've been stuck on a segment\n        lastAdvanceTime: 0     // When we last advanced segments\n      },\n      \n      // Results\n      counter: 0,\n      lastDetectionTime: 0,\n      \n      // Visualization\n      spectrogramData: {\n        recording: [],\n        pattern: [],\n        live: []\n      },\n      \n      // Timing markers for visualization\n      timeMarkers: {\n        pattern: [],\n        live: []\n      }\n    };\n    \n    // Callbacks\n    this.callbacks = {\n      onStatusUpdate: null,\n      onVisualizationUpdate: null,\n      onDetection: null,\n      onProgressUpdate: null,\n      onError: null\n    };\n    \n    // Animation\n    this.animationFrame = null;\n  }\n  \n  /**\n   * Set up callbacks\n   */\n  setCallbacks(callbacks) {\n    Object.assign(this.callbacks, callbacks);\n  }\n  \n  /**\n   * Initialize audio system\n   */\n  async setupAudio() {\n    if (this.audioContext) return true;\n    \n    try {\n      this.audioContext = new (window.AudioContext || window.webkitAudioContext)();\n      this.config.sampleRate = this.audioContext.sampleRate;\n      \n      this.mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });\n      \n      this.analyzer = this.audioContext.createAnalyser();\n      this.analyzer.fftSize = this.config.fftSize;\n      \n      this.log('info', 'Audio system initialized');\n      return true;\n    } catch (error) {\n      this.handleError('Audio setup failed', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Start recording a pattern\n   */\n  async startRecording() {\n    if (this.state.isRecording) return false;\n    \n    // Setup audio\n    const success = await this.setupAudio();\n    if (!success) return false;\n    \n    // Initialize recording state\n    this.state.isRecording = true;\n    this.state.recordStartTime = Date.now();\n    this.state.recordingData = {\n      audio: [],\n      spectrogram: [],\n      mfcc: [],\n      energy: [],\n      duration: 0\n    };\n    \n    // Also initialize spectrogram data for visualization\n    this.state.spectrogramData.recording = [];\n    \n    // Create processor node\n    this.processor = this.audioContext.createScriptProcessor(\n      this.config.bufferSize, 1, 1\n    );\n    \n    // Process audio data\n    this.processor.onaudioprocess = (event) => {\n      if (!this.state.isRecording) return;\n      \n      try {\n        // Get audio data\n        const inputData = event.inputBuffer.getChannelData(0);\n        const audioData = new Float32Array(inputData.length);\n        audioData.set(inputData);\n        \n        // Extract features\n        const features = this.extractFeatures(audioData);\n        \n        // Store data\n        this.state.recordingData.audio.push(audioData);\n        this.state.recordingData.spectrogram.push(features.spectrogram);\n        this.state.recordingData.mfcc.push(features.mfcc);\n        this.state.recordingData.energy.push(features.energy);\n        \n        // Store spectrogram for visualization\n        this.state.spectrogramData.recording.push(features.spectrogram);\n        \n        // Update visualization\n        if (this.callbacks.onVisualizationUpdate) {\n          this.callbacks.onVisualizationUpdate('recording', audioData, features);\n        }\n      } catch (error) {\n        this.handleError('Error processing recording', error);\n      }\n    };\n    \n    // Connect audio nodes\n    const source = this.audioContext.createMediaStreamSource(this.mediaStream);\n    source.connect(this.analyzer);\n    source.connect(this.processor);\n    this.processor.connect(this.audioContext.destination);\n    \n    this.log('status', 'Recording chant pattern...');\n    return true;\n  }\n  \n  /**\n   * Stop recording and process the pattern\n   */\n  stopRecording() {\n    if (!this.state.isRecording) return false;\n    \n    // Update state\n    this.state.isRecording = false;\n    this.state.recordingData.duration = Date.now() - this.state.recordStartTime;\n    \n    // Clean up\n    if (this.processor) {\n      this.processor.disconnect();\n      this.processor = null;\n    }\n    \n    // Check recording duration\n    if (this.state.recordingData.duration < this.config.minRecordDuration) {\n      this.log('status', 'Recording too short, please try again');\n      return false;\n    }\n    \n    this.log('status', 'Processing pattern...');\n    \n    // Process the pattern\n    const success = this.processRecordingToPattern();\n    \n    if (success) {\n      this.log('status', `Pattern ${this.state.activePatternIndex + 1} recorded (${(this.state.recordingData.duration/1000).toFixed(1)}s)`);\n      return true;\n    } else {\n      this.log('status', 'Failed to process pattern');\n      return false;\n    }\n  }\n  \n  /**\n   * Play the last recorded pattern\n   */\n  playLastPattern() {\n    if (this.state.isPlaying || !this.state.patterns[this.state.activePatternIndex]) {\n      return false;\n    }\n    \n    this.state.isPlaying = true;\n    \n    const pattern = this.state.patterns[this.state.activePatternIndex];\n    if (!pattern || !pattern.rawData || !pattern.rawData.audio || pattern.rawData.audio.length === 0) {\n      this.log('status', 'No audio data to play');\n      this.state.isPlaying = false;\n      return false;\n    }\n    \n    this.log('status', 'Playing pattern...');\n    \n    // Setup audio if needed\n    if (!this.audioContext) {\n      this.setupAudio().then(success => {\n        if (success) {\n          this.playAudioData(pattern.rawData.audio);\n        } else {\n          this.state.isPlaying = false;\n        }\n      });\n    } else {\n      this.playAudioData(pattern.rawData.audio);\n    }\n    \n    return true;\n  }\n  \n  /**\n   * Helper method to play audio data\n   */\n  playAudioData(audioDataArray) {\n    try {\n      // Create audio buffer\n      const totalLength = audioDataArray.reduce((sum, chunk) => sum + chunk.length, 0);\n      const audioBuffer = this.audioContext.createBuffer(1, totalLength, this.audioContext.sampleRate);\n      const channelData = audioBuffer.getChannelData(0);\n      \n      // Fill buffer with audio data\n      let offset = 0;\n      for (const chunk of audioDataArray) {\n        channelData.set(chunk, offset);\n        offset += chunk.length;\n      }\n      \n      // Create source and play\n      this.audioBufferSource = this.audioContext.createBufferSource();\n      this.audioBufferSource.buffer = audioBuffer;\n      this.audioBufferSource.connect(this.audioContext.destination);\n      \n      this.audioBufferSource.onended = () => {\n        this.state.isPlaying = false;\n        this.log('status', 'Playback complete');\n      };\n      \n      this.audioBufferSource.start();\n    } catch (error) {\n      this.handleError('Error playing audio', error);\n      this.state.isPlaying = false;\n    }\n  }\n  \n  /**\n   * Process recording data into a pattern\n   */\n  processRecordingToPattern() {\n    try {\n      // Get current pattern index\n      const patternIndex = this.state.activePatternIndex;\n      \n      // Create a new pattern if it doesn't exist\n      if (!this.state.patterns[patternIndex]) {\n        this.state.patterns[patternIndex] = {\n          rawData: {\n            audio: [],\n            spectrogram: [],\n            mfcc: [],\n            energy: [],\n            duration: 0\n          },\n          segments: [],\n          sampleCount: 0\n        };\n      }\n      \n      // Store recording data\n      const pattern = this.state.patterns[patternIndex];\n      \n      // If this is the first recording for this pattern, just copy it\n      if (pattern.sampleCount === 0) {\n        pattern.rawData = {\n          audio: [...this.state.recordingData.audio],\n          spectrogram: [...this.state.recordingData.spectrogram],\n          mfcc: [...this.state.recordingData.mfcc],\n          energy: [...this.state.recordingData.energy],\n          duration: this.state.recordingData.duration\n        };\n      } else {\n        // Average with existing pattern data (simple arithmetic mean)\n        // First, we need to time-normalize the new recording\n        const normalizedRecording = this.normalizeRecordingLength(\n          this.state.recordingData, \n          pattern.rawData\n        );\n        \n        // Now average with existing pattern\n        this.averagePatternData(pattern, normalizedRecording);\n      }\n      \n      // Increment sample count\n      pattern.sampleCount++;\n      \n      // Segment the pattern\n      pattern.segments = this.segmentPattern(pattern.rawData);\n      \n      // Calculate segment boundaries for visualization\n      this.calculateSegmentBoundaries(pattern);\n      \n      // Store pattern visualization data\n      this.state.spectrogramData.pattern = [...pattern.rawData.spectrogram];\n      \n      // Clear recording data to save memory\n      this.state.recordingData = {\n        audio: [],\n        spectrogram: [],\n        mfcc: [],\n        energy: [],\n        duration: 0\n      };\n      \n      // Enable averaging if we have multiple patterns\n      if (this.checkMultiplePatternsExist()) {\n        // Check if averaging button should be enabled\n        if (this.callbacks.onStatusUpdate) {\n          this.callbacks.onStatusUpdate('control', 'enableAveraging', true);\n        }\n      }\n      \n      return true;\n    } catch (error) {\n      this.handleError('Error processing pattern', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Normalize recording length to match target pattern\n   */\n  normalizeRecordingLength(recording, targetPattern) {\n    // Create a normalized version of the recording\n    const normalized = {\n      audio: [],\n      spectrogram: [],\n      mfcc: [],\n      energy: [],\n      duration: targetPattern.duration\n    };\n    \n    const sourceLength = recording.energy.length;\n    const targetLength = targetPattern.energy.length;\n    \n    // Simple linear resampling for feature data\n    for (let i = 0; i < targetLength; i++) {\n      const sourceIdx = Math.floor(i * sourceLength / targetLength);\n      \n      normalized.spectrogram[i] = recording.spectrogram[sourceIdx];\n      normalized.mfcc[i] = recording.mfcc[sourceIdx];\n      normalized.energy[i] = recording.energy[sourceIdx];\n    }\n    \n    // For audio data, we need to do a bit more careful resampling\n    // Here we just take chunks that correspond approximately to the target chunks\n    // This is simplified and not perfect, but works for our averaging purposes\n    const audioChunkSize = Math.ceil(recording.audio.length / sourceLength);\n    const targetAudioChunkSize = Math.ceil(targetPattern.audio.length / targetLength);\n    \n    for (let i = 0; i < targetLength; i++) {\n      const sourceIdx = Math.floor(i * sourceLength / targetLength);\n      const audioStart = sourceIdx * audioChunkSize;\n      const audioChunk = recording.audio[Math.min(Math.floor(audioStart / audioChunkSize), recording.audio.length - 1)];\n      \n      if (audioChunk) {\n        normalized.audio.push(audioChunk);\n      }\n    }\n    \n    return normalized;\n  }\n  \n  /**\n   * Average new recording data with existing pattern\n   */\n  averagePatternData(pattern, newData) {\n    const sampleCount = pattern.sampleCount;\n    \n    // Weight for averaging: existing data gets more weight as sample count increases\n    const existingWeight = sampleCount / (sampleCount + 1);\n    const newWeight = 1 / (sampleCount + 1);\n    \n    // Average spectrograms\n    pattern.rawData.spectrogram = pattern.rawData.spectrogram.map((existingSpectrum, i) => {\n      const newSpectrum = newData.spectrogram[i] || [];\n      return this.weightedAverageArrays(existingSpectrum, newSpectrum, existingWeight, newWeight);\n    });\n    \n    // Average MFCCs\n    pattern.rawData.mfcc = pattern.rawData.mfcc.map((existingMfcc, i) => {\n      const newMfcc = newData.mfcc[i] || [];\n      return this.weightedAverageArrays(existingMfcc, newMfcc, existingWeight, newWeight);\n    });\n    \n    // Average energy\n    pattern.rawData.energy = pattern.rawData.energy.map((existing, i) => {\n      const newEnergy = newData.energy[i] || 0;\n      return existing * existingWeight + newEnergy * newWeight;\n    });\n    \n    // For audio, we keep the original as we don't directly average audio samples\n    // But we do store the new audio in case it's better quality or more representative\n    if (newData.audio.length > 0) {\n      pattern.rawData.audio = newData.audio;\n    }\n    \n    // Keep original duration (we've already normalized the new recording)\n    pattern.rawData.duration = pattern.rawData.duration;\n  }\n  \n  /**\n   * Weighted average of two arrays\n   */\n  weightedAverageArrays(arrA, arrB, weightA, weightB) {\n    if (!arrA || !arrB) return arrA || arrB || [];\n    \n    const length = Math.min(arrA.length, arrB.length);\n    const result = new Array(length);\n    \n    for (let i = 0; i < length; i++) {\n      result[i] = (arrA[i] || 0) * weightA + (arrB[i] || 0) * weightB;\n    }\n    \n    return result;\n  }\n  \n  /**\n   * Check if multiple patterns exist\n   */\n  checkMultiplePatternsExist() {\n    let count = 0;\n    \n    for (const pattern of this.state.patterns) {\n      if (pattern && pattern.sampleCount > 0) {\n        count++;\n      }\n    }\n    \n    return count > 1;\n  }\n  \n  /**\n   * Average all recorded patterns into one\n   */\n  averageAllPatterns() {\n    try {\n      // Ensure we have at least 2 patterns\n      const validPatterns = this.state.patterns.filter(p => p && p.sampleCount > 0);\n      \n      if (validPatterns.length < 2) {\n        this.log('status', 'Need at least 2 patterns to average');\n        return false;\n      }\n      \n      // Use the first pattern as the base\n      const basePattern = validPatterns[0];\n      \n      // Create a new averaged pattern\n      const averagedPattern = {\n        rawData: {\n          audio: [...basePattern.rawData.audio], // Keep audio from first pattern\n          spectrogram: [...basePattern.rawData.spectrogram],\n          mfcc: [...basePattern.rawData.mfcc],\n          energy: [...basePattern.rawData.energy],\n          duration: basePattern.rawData.duration\n        },\n        segments: [],\n        sampleCount: 0\n      };\n      \n      // Add all other patterns\n      for (let i = 1; i < validPatterns.length; i++) {\n        const pattern = validPatterns[i];\n        const normalized = this.normalizeRecordingLength(\n          pattern.rawData, \n          averagedPattern.rawData\n        );\n        \n        // Average with equal weights\n        const weight = 1 / validPatterns.length;\n        \n        // Average spectrograms\n        averagedPattern.rawData.spectrogram = averagedPattern.rawData.spectrogram.map((existingSpectrum, j) => {\n          const newSpectrum = normalized.spectrogram[j] || [];\n          return this.weightedAverageArrays(\n            existingSpectrum, \n            newSpectrum, \n            1 - weight, \n            weight\n          );\n        });\n        \n        // Average MFCCs\n        averagedPattern.rawData.mfcc = averagedPattern.rawData.mfcc.map((existingMfcc, j) => {\n          const newMfcc = normalized.mfcc[j] || [];\n          return this.weightedAverageArrays(\n            existingMfcc,\n            newMfcc,\n            1 - weight,\n            weight\n          );\n        });\n        \n        // Average energy\n        averagedPattern.rawData.energy = averagedPattern.rawData.energy.map((existing, j) => {\n          const newEnergy = normalized.energy[j] || 0;\n          return existing * (1 - weight) + newEnergy * weight;\n        });\n      }\n      \n      // Set combined sample count\n      averagedPattern.sampleCount = validPatterns.reduce((sum, p) => sum + p.sampleCount, 0);\n      \n      // Segment the pattern\n      averagedPattern.segments = this.segmentPattern(averagedPattern.rawData);\n      \n      // Calculate segment boundaries\n      this.calculateSegmentBoundaries(averagedPattern);\n      \n      // Replace the active pattern with the averaged one\n      this.state.patterns[this.state.activePatternIndex] = averagedPattern;\n      \n      // Update visualization\n      this.state.spectrogramData.pattern = [...averagedPattern.rawData.spectrogram];\n      \n      this.log('status', `Created averaged pattern from ${validPatterns.length} recordings`);\n      return true;\n    } catch (error) {\n      this.handleError('Error averaging patterns', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Set active pattern\n   */\n  setActivePattern(index) {\n    if (index < 0 || index >= this.config.maxPatterns) {\n      return false;\n    }\n    \n    this.state.activePatternIndex = index;\n    \n    // Update visualization if pattern exists\n    const pattern = this.state.patterns[index];\n    if (pattern && pattern.sampleCount > 0) {\n      this.state.spectrogramData.pattern = [...pattern.rawData.spectrogram];\n      \n      if (this.callbacks.onVisualizationUpdate) {\n        this.callbacks.onVisualizationUpdate('patternSwitch', null, pattern);\n      }\n      \n      this.log('status', `Switched to pattern ${index + 1}`);\n    } else {\n      this.state.spectrogramData.pattern = [];\n      \n      this.log('status', `Pattern ${index + 1} is empty`);\n    }\n    \n    return true;\n  }\n  \n  /**\n   * Clear the active pattern\n   */\n  clearActivePattern() {\n    const index = this.state.activePatternIndex;\n    \n    this.state.patterns[index] = null;\n    this.state.spectrogramData.pattern = [];\n    \n    this.log('status', `Cleared pattern ${index + 1}`);\n    \n    // Disable averaging button if needed\n    if (!this.checkMultiplePatternsExist() && this.callbacks.onStatusUpdate) {\n      this.callbacks.onStatusUpdate('control', 'enableAveraging', false);\n    }\n    \n    return true;\n  }\n  \n  /**\n   * Segment pattern into logical parts\n   */\n  segmentPattern(patternData) {\n    try {\n      const segmentCount = this.config.segmentCount;\n      const energy = patternData.energy;\n      const mfcc = patternData.mfcc;\n      const spectrogram = patternData.spectrogram;\n      \n      if (!energy || energy.length === 0) {\n        return [];\n      }\n      \n      // Find segment boundaries\n      let boundaries = [];\n      \n      // Try to find natural boundaries in energy profile\n      const smoothedEnergy = this.smoothArray([...energy], 3);\n      \n      // Find significant peaks and valleys\n      const peaks = this.findPeaks(smoothedEnergy);\n      const valleys = this.findValleys(smoothedEnergy);\n      \n      if (valleys.length >= segmentCount - 1) {\n        // Use valleys as natural breakpoints\n        boundaries = [0, ...valleys, energy.length - 1];\n        \n        // Keep strongest valleys if we have too many\n        while (boundaries.length > segmentCount + 1) {\n          // Find the shallowest valley\n          let shallowestIdx = -1;\n          let shallowestDepth = Infinity;\n          \n          for (let i = 1; i < boundaries.length - 1; i++) {\n            const idx = boundaries[i];\n            const depth = Math.min(\n              smoothedEnergy[idx-1] - smoothedEnergy[idx],\n              smoothedEnergy[idx+1] - smoothedEnergy[idx]\n            );\n            \n            if (depth < shallowestDepth) {\n              shallowestDepth = depth;\n              shallowestIdx = i;\n            }\n          }\n          \n          if (shallowestIdx > 0) {\n            boundaries.splice(shallowestIdx, 1);\n          } else {\n            break;\n          }\n        }\n      } else {\n        // Fallback to equal divisions\n        const segmentSize = Math.floor(energy.length / segmentCount);\n        \n        boundaries = [];\n        for (let i = 0; i <= segmentCount; i++) {\n          boundaries.push(Math.min(i * segmentSize, energy.length - 1));\n        }\n      }\n      \n      // Sort boundaries and remove duplicates\n      boundaries = [...new Set(boundaries)].sort((a, b) => a - b);\n      \n      // Create segments\n      const segments = [];\n      for (let i = 0; i < boundaries.length - 1; i++) {\n        const start = boundaries[i];\n        const end = boundaries[i + 1];\n        \n        // Skip if segment is too small\n        if (end - start < 2) continue;\n        \n        // Create segment data\n        const segment = {\n          index: i,\n          startFrame: start,\n          endFrame: end,\n          frameCount: end - start,\n          // Extract feature slices\n          energy: energy.slice(start, end),\n          mfcc: mfcc.slice(start, end),\n          spectrogram: spectrogram.slice(start, end),\n          // Calculate averages\n          avgEnergy: this.average(energy.slice(start, end)),\n          avgSpectrogram: this.averageSpectrograms(spectrogram.slice(start, end)),\n          avgMfcc: this.averageArrays(mfcc.slice(start, end))\n        };\n        \n        segments.push(segment);\n      }\n      \n      // Ensure we have the requested number of segments by duplicating if necessary\n      while (segments.length < segmentCount) {\n        // Find the longest segment to split\n        let longestIdx = 0;\n        let longestLen = 0;\n        \n        for (let i = 0; i < segments.length; i++) {\n          const len = segments[i].frameCount;\n          if (len > longestLen) {\n            longestLen = len;\n            longestIdx = i;\n          }\n        }\n        \n        // Clone the segment with adjusted boundaries\n        const segment = segments[longestIdx];\n        const midPoint = Math.floor(segment.startFrame + segment.frameCount / 2);\n        \n        // Update original segment\n        const updatedOriginal = {\n          ...segment,\n          endFrame: midPoint,\n          frameCount: midPoint - segment.startFrame,\n          energy: energy.slice(segment.startFrame, midPoint),\n          mfcc: mfcc.slice(segment.startFrame, midPoint),\n          spectrogram: spectrogram.slice(segment.startFrame, midPoint)\n        };\n        \n        // Calculate new averages\n        updatedOriginal.avgEnergy = this.average(updatedOriginal.energy);\n        updatedOriginal.avgSpectrogram = this.averageSpectrograms(updatedOriginal.spectrogram);\n        updatedOriginal.avgMfcc = this.averageArrays(updatedOriginal.mfcc);\n        \n        // Create new segment for second half\n        const newSegment = {\n          index: segment.index + 1,\n          startFrame: midPoint,\n          endFrame: segment.endFrame,\n          frameCount: segment.endFrame - midPoint,\n          energy: energy.slice(midPoint, segment.endFrame),\n          mfcc: mfcc.slice(midPoint, segment.endFrame),\n          spectrogram: spectrogram.slice(midPoint, segment.endFrame)\n        };\n        \n        // Calculate averages for new segment\n        newSegment.avgEnergy = this.average(newSegment.energy);\n        newSegment.avgSpectrogram = this.averageSpectrograms(newSegment.spectrogram);\n        newSegment.avgMfcc = this.averageArrays(newSegment.mfcc);\n        \n        // Replace original segment and insert new one\n        segments[longestIdx] = updatedOriginal;\n        segments.splice(longestIdx + 1, 0, newSegment);\n        \n        // Update indices for all segments after the split\n        for (let i = longestIdx + 2; i < segments.length; i++) {\n          segments[i].index = i;\n        }\n      }\n      \n      // If we have too many segments, merge the smallest adjacent ones\n      while (segments.length > segmentCount) {\n        // Find the smallest adjacent segments\n        let smallestPairIdx = 0;\n        let smallestPairSize = Infinity;\n        \n        for (let i = 0; i < segments.length - 1; i++) {\n          const pairSize = segments[i].frameCount + segments[i + 1].frameCount;\n          if (pairSize < smallestPairSize) {\n            smallestPairSize = pairSize;\n            smallestPairIdx = i;\n          }\n        }\n        \n        // Merge the segments\n        const seg1 = segments[smallestPairIdx];\n        const seg2 = segments[smallestPairIdx + 1];\n        \n        const mergedSegment = {\n          index: seg1.index,\n          startFrame: seg1.startFrame,\n          endFrame: seg2.endFrame,\n          frameCount: seg1.frameCount + seg2.frameCount,\n          energy: [...seg1.energy, ...seg2.energy],\n          mfcc: [...seg1.mfcc, ...seg2.mfcc],\n          spectrogram: [...seg1.spectrogram, ...seg2.spectrogram]\n        };\n        \n        // Calculate new averages\n        mergedSegment.avgEnergy = this.average(mergedSegment.energy);\n        mergedSegment.avgSpectrogram = this.averageSpectrograms(mergedSegment.spectrogram);\n        mergedSegment.avgMfcc = this.averageArrays(mergedSegment.mfcc);\n        \n        // Replace segments\n        segments.splice(smallestPairIdx, 2, mergedSegment);\n        \n        // Update indices\n        for (let i = smallestPairIdx + 1; i < segments.length; i++) {\n          segments[i].index = i;\n        }\n      }\n      \n      return segments;\n    } catch (error) {\n      this.handleError('Error segmenting pattern', error);\n      return [];\n    }\n  }\n  \n  /**\n   * Calculate segment boundaries for visualization\n   */\n  calculateSegmentBoundaries(pattern) {\n    if (!pattern || !pattern.segments || pattern.segments.length === 0) return;\n    \n    // Calculate total frames\n    const totalFrames = pattern.rawData.energy.length;\n    \n    // Calculate boundaries as percentages\n    const boundaries = [];\n    \n    for (const segment of pattern.segments) {\n      const startPct = segment.startFrame / totalFrames;\n      const endPct = segment.endFrame / totalFrames;\n      \n      boundaries.push({\n        start: startPct,\n        end: endPct,\n        index: segment.index\n      });\n    }\n    \n    // Store boundaries\n    pattern.boundaries = boundaries;\n    \n    // Update time markers\n    this.state.timeMarkers.pattern = boundaries.map(b => b.start);\n  }\n  \n  /**\n   * Start detection\n   */\n  async startDetection() {\n    if (this.state.isDetecting) return false;\n    \n    // Get active pattern\n    const pattern = this.state.patterns[this.state.activePatternIndex];\n    \n    // Check if we have a pattern\n    if (!pattern || !pattern.segments || pattern.segments.length === 0) {\n      this.log('status', 'No pattern recorded yet');\n      return false;\n    }\n    \n    // Setup audio\n    const success = await this.setupAudio();\n    if (!success) return false;\n    \n    // Initialize detection state\n    this.state.isDetecting = true;\n    this.state.inCooldown = false;\n    \n    // Clear detection buffer\n    this.state.detectionBuffer = {\n      audio: [],\n      spectrogram: [],\n      mfcc: [],\n      energy: [],\n      timeWindow: []\n    };\n    \n    // Clear spectrogram data\n    this.state.spectrogramData.live = [];\n    \n    // Reset sequence state\n    this.resetSequenceState();\n    \n    // Create processor node\n    this.processor = this.audioContext.createScriptProcessor(\n      this.config.bufferSize, 1, 1\n    );\n    \n    // Store start time\n    const detectionStartTime = Date.now();\n    \n    // Process audio data for detection\n    this.processor.onaudioprocess = (event) => {\n      if (!this.state.isDetecting) return;\n      \n      try {\n        // Get audio data\n        const inputData = event.inputBuffer.getChannelData(0);\n        const audioData = new Float32Array(inputData.length);\n        audioData.set(inputData);\n        \n        // Extract features\n        const features = this.extractFeatures(audioData);\n        \n        // Current time in detection\n        const currentTime = Date.now() - detectionStartTime;\n        \n        // Add to detection buffer\n        this.state.detectionBuffer.audio.push(audioData);\n        this.state.detectionBuffer.spectrogram.push(features.spectrogram);\n        this.state.detectionBuffer.mfcc.push(features.mfcc);\n        this.state.detectionBuffer.energy.push(features.energy);\n        this.state.detectionBuffer.timeWindow.push(currentTime);\n        \n        // Update spectrogram data\n        this.state.spectrogramData.live.push(features.spectrogram);\n        \n        // Trim buffer to manageable size\n        this.trimDetectionBuffer();\n        \n        // Update visualization\n        if (this.callbacks.onVisualizationUpdate) {\n          this.callbacks.onVisualizationUpdate('detection', audioData, features);\n        }\n        \n        // Process detection if not in cooldown\n        if (!this.state.inCooldown) {\n          this.detectPattern();\n        }\n      } catch (error) {\n        this.handleError('Error in detection process', error);\n      }\n    };\n    \n    // Connect audio nodes\n    const source = this.audioContext.createMediaStreamSource(this.mediaStream);\n    source.connect(this.analyzer);\n    source.connect(this.processor);\n    this.processor.connect(this.audioContext.destination);\n    \n    // Start animation loop for cursor\n    this.startAnimationLoop();\n    \n    this.log('status', 'Listening for pattern...');\n    return true;\n  }\n  \n  /**\n   * Stop detection\n   */\n  stopDetection() {\n    if (!this.state.isDetecting) return false;\n    \n    // Update state\n    this.state.isDetecting = false;\n    this.state.inCooldown = false;\n    \n    // Stop animation\n    this.stopAnimationLoop();\n    \n    // Clean up\n    if (this.processor) {\n      this.processor.disconnect();\n      this.processor = null;\n    }\n    \n    // Reset sequence state\n    this.resetSequenceState();\n    \n    // Update progress\n    if (this.callbacks.onProgressUpdate) {\n      this.callbacks.onProgressUpdate(this.state.sequenceState);\n    }\n    \n    this.log('status', 'Detection stopped');\n    return true;\n  }\n  \n  /**\n   * Reset counter\n   */\n  resetCounter() {\n    this.state.counter = 0;\n    this.log('status', 'Counter reset to 0');\n    \n    if (this.callbacks.onDetection) {\n      this.callbacks.onDetection(0, 0);\n    }\n    \n    return true;\n  }\n  \n  /**\n   * Reset sequence state\n   */\n  resetSequenceState() {\n    // Get active pattern\n    const pattern = this.state.patterns[this.state.activePatternIndex];\n    \n    if (!pattern || !pattern.segments) {\n      this.state.sequenceState = {\n        segments: [],\n        currentIndex: 0,\n        progress: 0,\n        matchScores: [],\n        segmentStartTimes: [],\n        stuckTime: 0,\n        lastAdvanceTime: 0\n      };\n      return;\n    }\n    \n    // Initialize sequence tracking\n    this.state.sequenceState = {\n      segments: pattern.segments.map(() => 'pending'),\n      currentIndex: 0,\n      progress: 0,\n      matchScores: pattern.segments.map(() => 0),\n      segmentStartTimes: [],\n      stuckTime: 0,\n      lastAdvanceTime: Date.now()\n    };\n    \n    // Update visualization\n    if (this.callbacks.onProgressUpdate) {\n      this.callbacks.onProgressUpdate(this.state.sequenceState);\n    }\n  }\n  \n  /**\n   * Trim detection buffer\n   */\n  trimDetectionBuffer() {\n    // Get active pattern\n    const pattern = this.state.patterns[this.state.activePatternIndex];\n    if (!pattern) return;\n    \n    // Maximum frames to keep (3x pattern length for better endpoint detection)\n    const maxFrames = Math.max(\n      200, // Increased from 150 to provide more context\n      pattern.segments.reduce((sum, s) => sum + s.frameCount, 0) * 3 // Increased multiplier for better last segment detection\n    );\n    \n    if (this.state.detectionBuffer.energy.length > maxFrames) {\n      const framesToRemove = this.state.detectionBuffer.energy.length - maxFrames;\n      \n      // Trim all buffer arrays\n      this.state.detectionBuffer.audio.splice(0, framesToRemove);\n      this.state.detectionBuffer.spectrogram.splice(0, framesToRemove);\n      this.state.detectionBuffer.mfcc.splice(0, framesToRemove);\n      this.state.detectionBuffer.energy.splice(0, framesToRemove);\n      this.state.detectionBuffer.timeWindow.splice(0, framesToRemove);\n    }\n    \n    // Also trim spectrogram history\n    if (this.state.spectrogramData.live.length > this.config.spectrogramHistory) {\n      this.state.spectrogramData.live.splice(\n        0, \n        this.state.spectrogramData.live.length - this.config.spectrogramHistory\n      );\n    }\n  }\n  \n  /**\n   * Core detection algorithm\n   */\n  detectPattern() {\n    try {\n      // Get active pattern\n      const pattern = this.state.patterns[this.state.activePatternIndex];\n      if (!pattern || !pattern.segments || pattern.segments.length === 0) {\n        return false;\n      }\n      \n      // Check if we have enough data\n      if (this.state.detectionBuffer.energy.length < 10) {\n        return false;\n      }\n      \n      // Get current sequence state\n      const sequenceState = this.state.sequenceState;\n      const currentIndex = sequenceState.currentIndex;\n      \n      // Get the target segment\n      const segment = pattern.segments[currentIndex];\n      if (!segment) return false;\n      \n      // Use different detection strategies based on mode\n      let result;\n      \n      switch (this.config.detectionMode) {\n        case 'flexible':\n          result = this.flexibleSequentialDetection(pattern);\n          break;\n        case 'adaptive':\n          result = this.adaptiveDetection(pattern);\n          break;\n        case 'sequential':\n        default:\n          result = this.strictSequentialDetection(pattern);\n          break;\n      }\n      \n      // Process result\n      if (result) {\n        // Update progress visualization\n        if (this.callbacks.onProgressUpdate) {\n          this.callbacks.onProgressUpdate(this.state.sequenceState, result.debugInfo);\n        }\n        \n        // Check if we detected the full pattern\n        if (result.patternDetected) {\n          this.registerDetection(result.confidence);\n        }\n        \n        return result.patternDetected;\n      }\n      \n      return false;\n    } catch (error) {\n      this.handleError('Error in pattern detection', error);\n      return false;\n    }\n  }\n  \n  /**\n   * Strict sequential detection algorithm\n   */\n  strictSequentialDetection(pattern) {\n    // Current sequence state\n    const sequenceState = this.state.sequenceState;\n    const currentIndex = sequenceState.currentIndex;\n    \n    // Current segment\n    const segment = pattern.segments[currentIndex];\n    \n    // Get recent frames for matching\n    const windowSize = Math.min(segment.frameCount * 2, this.state.detectionBuffer.energy.length);\n    const recentFrames = {\n      energy: this.state.detectionBuffer.energy.slice(-windowSize),\n      mfcc: this.state.detectionBuffer.mfcc.slice(-windowSize),\n      spectrogram: this.state.detectionBuffer.spectrogram.slice(-windowSize)\n    };\n    \n    // Calculate match score for current segment\n    const matchScore = this.calculateSegmentMatch(recentFrames, segment);\n    \n    // Update match scores\n    sequenceState.matchScores[currentIndex] = matchScore;\n    \n    // Current time\n    const now = Date.now();\n    \n    // Check for timeout on current segment\n    if (sequenceState.segments[currentIndex] === 'active') {\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      \n      if (timeInSegment > this.config.segmentTimeout) {\n        // Stuck too long, reset\n        this.log('info', `Timeout on segment ${currentIndex + 1}`);\n        this.resetSequenceState();\n        return {\n          patternDetected: false,\n          confidence: 0,\n          debugInfo: {\n            currentSegment: 1,\n            matchScore: 0,\n            timeout: true\n          }\n        };\n      }\n    }\n    \n    // Debug info\n    const debugInfo = {\n      currentSegment: currentIndex + 1,\n      totalSegments: pattern.segments.length,\n      matchScore: matchScore,\n      threshold: this.config.minMatchThreshold\n    };\n    \n    // Adjust threshold for final segment to make it easier to detect\n    let adjustedThreshold = this.config.minMatchThreshold;\n    let adjustedAdvanceThreshold = this.config.advanceThreshold;\n    \n    // Make final segment easier to detect\n    if (currentIndex === pattern.segments.length - 1) {\n      adjustedThreshold *= this.config.finalSegmentBoost;\n      adjustedAdvanceThreshold *= this.config.finalSegmentBoost;\n      debugInfo.finalSegmentBoost = true;\n      debugInfo.adjustedThreshold = adjustedThreshold;\n    }\n    \n    // Handle current segment based on match score\n    if (matchScore >= adjustedThreshold) {\n      // If we just started matching this segment, record the start time\n      if (sequenceState.segments[currentIndex] === 'pending') {\n        sequenceState.segments[currentIndex] = 'active';\n        sequenceState.segmentStartTimes[currentIndex] = now;\n        sequenceState.lastAdvanceTime = now;\n        this.log('info', `Matching segment ${currentIndex + 1}/${pattern.segments.length}`);\n      }\n      \n      // Check if we've been matching long enough to advance\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      const minSegmentTime = Math.max(\n        200,  // Reduced from 300ms for more responsive detection\n        (segment.frameCount / pattern.rawData.energy.length) * pattern.rawData.duration * 0.4 // Reduced from 0.5 for quicker progression\n      );\n      \n      if (timeInSegment >= minSegmentTime && matchScore >= adjustedAdvanceThreshold) {\n        // Mark segment as complete\n        sequenceState.segments[currentIndex] = 'complete';\n        \n        // Check if this was the last segment\n        if (currentIndex === pattern.segments.length - 1) {\n          // Completed the full pattern\n          return {\n            patternDetected: true,\n            confidence: this.calculateOverallConfidence(),\n            debugInfo: {\n              ...debugInfo,\n              timeInSegment,\n              minSegmentTime,\n              completed: true\n            }\n          };\n        } else {\n          // Move to next segment\n          sequenceState.currentIndex++;\n          sequenceState.lastAdvanceTime = now;\n          this.log('info', `Advanced to segment ${sequenceState.currentIndex + 1}/${pattern.segments.length}`);\n          \n          // Add progress data to debug info\n          debugInfo.advanced = true;\n          debugInfo.nextSegment = sequenceState.currentIndex + 1;\n        }\n      }\n      \n      // Add timing to debug info\n      debugInfo.timeInSegment = timeInSegment;\n      debugInfo.minSegmentTime = minSegmentTime;\n    } else {\n      // If we were matching but lost it, mark as invalid\n      if (sequenceState.segments[currentIndex] === 'active') {\n        sequenceState.segments[currentIndex] = 'invalid';\n        this.log('info', `Lost match for segment ${currentIndex + 1}`);\n        \n        // Reset after a short delay\n        setTimeout(() => {\n          // Only reset if we're still on this segment and still invalid\n          if (this.state.isDetecting && \n              this.state.sequenceState.currentIndex === currentIndex &&\n              this.state.sequenceState.segments[currentIndex] === 'invalid') {\n            this.resetSequenceState();\n            this.log('info', 'Reset sequence state');\n          }\n        }, 300);\n      }\n    }\n    \n    // Calculate overall progress\n    const completedSegments = sequenceState.segments.filter(s => s === 'complete').length;\n    const activeSegment = sequenceState.segments.indexOf('active');\n    \n    if (activeSegment !== -1) {\n      // Include partial progress of active segment\n      const activeProgress = matchScore * (1 / pattern.segments.length);\n      sequenceState.progress = (completedSegments / pattern.segments.length) + activeProgress;\n    } else {\n      sequenceState.progress = completedSegments / pattern.segments.length;\n    }\n    \n    // Add progress to debug info\n    debugInfo.progress = sequenceState.progress;\n    debugInfo.segments = [...sequenceState.segments];\n    \n    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };\n  }\n  \n  /**\n   * Flexible sequential detection\n   * Allows some segments to be skipped or detected out of order\n   */\n  flexibleSequentialDetection(pattern) {\n    // Current sequence state\n    const sequenceState = this.state.sequenceState;\n    const currentIndex = sequenceState.currentIndex;\n    \n    // Calculate match scores for all segments\n    const matchScores = pattern.segments.map((segment, i) => {\n      // Get window size based on segment size\n      const windowSize = Math.min(segment.frameCount * 2, this.state.detectionBuffer.energy.length);\n      \n      // Get recent frames\n      const recentFrames = {\n        energy: this.state.detectionBuffer.energy.slice(-windowSize),\n        mfcc: this.state.detectionBuffer.mfcc.slice(-windowSize),\n        spectrogram: this.state.detectionBuffer.spectrogram.slice(-windowSize)\n      };\n      \n      // Calculate match score\n      return this.calculateSegmentMatch(recentFrames, segment);\n    });\n    \n    // Update match scores\n    sequenceState.matchScores = matchScores;\n    \n    // Find best matching segment\n    const bestMatchIndex = matchScores.indexOf(Math.max(...matchScores));\n    const bestMatchScore = matchScores[bestMatchIndex];\n    \n    // Current time\n    const now = Date.now();\n    \n    // Debug info\n    const debugInfo = {\n      currentSegment: currentIndex + 1,\n      totalSegments: pattern.segments.length,\n      matchScores,\n      bestMatchIndex: bestMatchIndex + 1,\n      bestMatchScore,\n      threshold: this.config.minMatchThreshold\n    };\n    \n    // Check for timeout\n    if (sequenceState.segments[currentIndex] === 'active') {\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      \n      if (timeInSegment > this.config.segmentTimeout) {\n        // Check if a later segment is matching better\n        if (bestMatchIndex > currentIndex && bestMatchScore >= this.config.advanceThreshold) {\n          // Skip to that segment\n          for (let i = currentIndex; i < bestMatchIndex; i++) {\n            sequenceState.segments[i] = 'complete';\n          }\n          sequenceState.currentIndex = bestMatchIndex;\n          sequenceState.segmentStartTimes[bestMatchIndex] = now;\n          sequenceState.segments[bestMatchIndex] = 'active';\n          sequenceState.lastAdvanceTime = now;\n          \n          this.log('info', `Skipped to segment ${bestMatchIndex + 1} (better match)`);\n          \n          // Update debug info\n          debugInfo.skipped = true;\n          debugInfo.skippedTo = bestMatchIndex + 1;\n        } else {\n          // Reset if stuck too long with no better matches\n          this.log('info', `Timeout on segment ${currentIndex + 1}`);\n          this.resetSequenceState();\n          \n          // Update debug info\n          debugInfo.timeout = true;\n          \n          return {\n            patternDetected: false,\n            confidence: 0,\n            debugInfo\n          };\n        }\n      }\n    }\n    \n    // Adjust threshold for final segment to make it easier to detect\n    if (currentIndex === pattern.segments.length - 1) {\n      debugInfo.finalSegmentBoost = true;\n      debugInfo.adjustedThreshold = this.config.minMatchThreshold * this.config.finalSegmentBoost;\n    }\n    \n    // Current segment match\n    const currentMatch = matchScores[currentIndex];\n    \n    // Forward lookahead - if a later segment is matching very well\n    if (sequenceState.segments[currentIndex] === 'pending' && currentMatch < this.config.minMatchThreshold) {\n      // Check if any later segment is matching well\n      for (let i = currentIndex + 1; i < matchScores.length; i++) {\n        if (matchScores[i] >= this.config.minMatchThreshold * 1.2) {\n          // Skip to this segment\n          sequenceState.currentIndex = i;\n          sequenceState.segments[i] = 'active';\n          sequenceState.segmentStartTimes[i] = now;\n          sequenceState.lastAdvanceTime = now;\n          \n          this.log('info', `Jumped to segment ${i + 1} (strong match)`);\n          \n          // Update debug info\n          debugInfo.jumped = true;\n          debugInfo.jumpedTo = i + 1;\n          \n          break;\n        }\n      }\n    }\n    \n    // Update current index after possible jumps\n    const updatedCurrentIndex = sequenceState.currentIndex;\n    const currentSegment = pattern.segments[updatedCurrentIndex];\n    \n    // Adjust threshold for final segment\n    let adjustedThreshold = this.config.minMatchThreshold;\n    let adjustedAdvanceThreshold = this.config.advanceThreshold;\n    \n    // Make the final segment easier to detect\n    if (updatedCurrentIndex === pattern.segments.length - 1) {\n      adjustedThreshold *= this.config.finalSegmentBoost;\n      adjustedAdvanceThreshold *= this.config.finalSegmentBoost;\n    }\n    \n    // Handle current segment based on match score\n    if (matchScores[updatedCurrentIndex] >= adjustedThreshold) {\n      // If we just started matching this segment, record the start time\n      if (sequenceState.segments[updatedCurrentIndex] === 'pending') {\n        sequenceState.segments[updatedCurrentIndex] = 'active';\n        sequenceState.segmentStartTimes[updatedCurrentIndex] = now;\n        sequenceState.lastAdvanceTime = now;\n        this.log('info', `Matching segment ${updatedCurrentIndex + 1}/${pattern.segments.length}`);\n      }\n      \n      // Check if we've been matching long enough to advance\n      const timeInSegment = now - (sequenceState.segmentStartTimes[updatedCurrentIndex] || now);\n      const minSegmentTime = Math.max(\n        200,  // Shorter minimum time for flexible mode\n        (currentSegment.frameCount / pattern.rawData.energy.length) * pattern.rawData.duration * 0.3 // Even shorter for flexible mode\n      );\n      \n      // Add timing to debug info\n      debugInfo.timeInSegment = timeInSegment;\n      debugInfo.minSegmentTime = minSegmentTime;\n      \n      // For the last segment, allow even shorter minimum time\n      const isLastSegment = updatedCurrentIndex === pattern.segments.length - 1;\n      const effectiveMinTime = isLastSegment ? minSegmentTime * 0.75 : minSegmentTime;\n      \n      if (timeInSegment >= effectiveMinTime && matchScores[updatedCurrentIndex] >= adjustedAdvanceThreshold) {\n        // Mark segment as complete\n        sequenceState.segments[updatedCurrentIndex] = 'complete';\n        \n        // Check if this was the last segment\n        if (updatedCurrentIndex === pattern.segments.length - 1) {\n          // Completed the full pattern\n          return {\n            patternDetected: true,\n            confidence: this.calculateOverallConfidence(),\n            debugInfo: {\n              ...debugInfo,\n              completed: true\n            }\n          };\n        } else {\n          // Move to next segment\n          sequenceState.currentIndex++;\n          sequenceState.lastAdvanceTime = now;\n          this.log('info', `Advanced to segment ${sequenceState.currentIndex + 1}/${pattern.segments.length}`);\n          \n          // Add progress data to debug info\n          debugInfo.advanced = true;\n          debugInfo.nextSegment = sequenceState.currentIndex + 1;\n        }\n      }\n    } else {\n      // If we were matching but lost it, check if a different segment matches better\n      if (sequenceState.segments[updatedCurrentIndex] === 'active') {\n        // If best match is a different segment with a good score\n        if (bestMatchIndex !== updatedCurrentIndex && bestMatchScore >= this.config.minMatchThreshold) {\n          // If it's a later segment, skip to it\n          if (bestMatchIndex > updatedCurrentIndex) {\n            // Mark all segments up to best match as complete\n            for (let i = updatedCurrentIndex; i < bestMatchIndex; i++) {\n              sequenceState.segments[i] = 'complete';\n            }\n            \n            sequenceState.currentIndex = bestMatchIndex;\n            sequenceState.segments[bestMatchIndex] = 'active';\n            sequenceState.segmentStartTimes[bestMatchIndex] = now;\n            sequenceState.lastAdvanceTime = now;\n            \n            this.log('info', `Skipped to segment ${bestMatchIndex + 1} (better match)`);\n            \n            // Update debug info\n            debugInfo.skipped = true;\n            debugInfo.skippedTo = bestMatchIndex + 1;\n          } \n          // If it's an earlier segment, allow jumping back\n          else if (bestMatchIndex < updatedCurrentIndex) {\n            // Only jump back if the score is significantly better\n            if (bestMatchScore > matchScores[updatedCurrentIndex] * 1.5) {\n              // Reset segments after best match\n              for (let i = bestMatchIndex + 1; i < sequenceState.segments.length; i++) {\n                sequenceState.segments[i] = 'pending';\n              }\n              \n              sequenceState.currentIndex = bestMatchIndex;\n              sequenceState.segments[bestMatchIndex] = 'active';\n              sequenceState.segmentStartTimes[bestMatchIndex] = now;\n              sequenceState.lastAdvanceTime = now;\n              \n              this.log('info', `Jumped back to segment ${bestMatchIndex + 1} (much better match)`);\n              \n              // Update debug info\n              debugInfo.jumpedBack = true;\n              debugInfo.jumpedBackTo = bestMatchIndex + 1;\n            }\n          }\n        } else {\n          // Mark as invalid if no better matches found\n          sequenceState.segments[updatedCurrentIndex] = 'invalid';\n          this.log('info', `Lost match for segment ${updatedCurrentIndex + 1}`);\n          \n          // Reset after a short delay\n          setTimeout(() => {\n            if (this.state.isDetecting && \n                this.state.sequenceState.currentIndex === updatedCurrentIndex &&\n                this.state.sequenceState.segments[updatedCurrentIndex] === 'invalid') {\n              this.resetSequenceState();\n              this.log('info', 'Reset sequence state');\n            }\n          }, 300);\n        }\n      }\n    }\n    \n    // Calculate overall progress\n    const completedSegments = sequenceState.segments.filter(s => s === 'complete').length;\n    const activeSegment = sequenceState.segments.indexOf('active');\n    \n    if (activeSegment !== -1) {\n      // Include partial progress of active segment\n      const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);\n      sequenceState.progress = (completedSegments / pattern.segments.length) + activeProgress;\n    } else {\n      sequenceState.progress = completedSegments / pattern.segments.length;\n    }\n    \n    // Add progress to debug info\n    debugInfo.progress = sequenceState.progress;\n    debugInfo.segments = [...sequenceState.segments];\n    \n    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };\n      sequenceState.progress = (completedSegments / pattern.segments.length) + activeProgress;\n    } else {\n      sequenceState.progress = completedSegments / pattern.segments.length;\n    }\n    \n    // Add progress to debug info\n    debugInfo.progress = sequenceState.progress;\n    debugInfo.segments = [...sequenceState.segments];\n    \n    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };\n  }\n  \n  /**\n   * Adaptive detection that self-adjusts based on input\n   * This method provides the most flexible and user-friendly detection\n   * by dynamically adjusting thresholds and allowing for pattern variations\n   */\n  adaptiveDetection(pattern) {\n    // Current sequence state\n    const sequenceState = this.state.sequenceState;\n    const currentIndex = sequenceState.currentIndex;\n    \n    // Calculate match scores for all segments with larger window for final segment\n    const matchScores = pattern.segments.map((segment, i) => {\n      // Use larger window for the final segment to improve detection\n      const isLastSegment = i === pattern.segments.length - 1;\n      const windowMultiplier = isLastSegment ? 3 : 2;\n      \n      // Get window size based on segment size\n      const windowSize = Math.min(\n        segment.frameCount * windowMultiplier, \n        this.state.detectionBuffer.energy.length\n      );\n      \n      // Get recent frames\n      const recentFrames = {\n        energy: this.state.detectionBuffer.energy.slice(-windowSize),\n        mfcc: this.state.detectionBuffer.mfcc.slice(-windowSize),\n        spectrogram: this.state.detectionBuffer.spectrogram.slice(-windowSize)\n      };\n      \n      // Calculate match score with adaptive feature weights\n      let featureWeights = {...this.config.featureWeights};\n      \n      // Adjust weights based on segment position\n      if (isLastSegment) {\n        // For last segment, emphasize spectrogram for better pattern ending detection\n        featureWeights.spectrogram = 0.6;\n        featureWeights.energy = 0.3;\n        featureWeights.mfcc = 0.1;\n      } else if (i === 0) {\n        // For first segment, balanced approach\n        featureWeights.spectrogram = 0.4;\n        featureWeights.energy = 0.3;\n        featureWeights.mfcc = 0.3;\n      }\n      \n      // Calculate match with custom weights\n      return this.calculateSegmentMatch(recentFrames, segment, featureWeights);\n    });\n    \n    // Update match scores\n    sequenceState.matchScores = matchScores;\n    \n    // Find best matching segment\n    const bestMatchIndex = matchScores.indexOf(Math.max(...matchScores));\n    const bestMatchScore = matchScores[bestMatchIndex];\n    \n    // Current time\n    const now = Date.now();\n    \n    // Debug info\n    const debugInfo = {\n      currentSegment: currentIndex + 1,\n      totalSegments: pattern.segments.length,\n      matchScores,\n      bestMatchIndex: bestMatchIndex + 1,\n      bestMatchScore,\n      mode: 'adaptive'\n    };\n    \n    // Dynamically adjust thresholds based on where we are in the pattern\n    const baseMatchThreshold = this.config.minMatchThreshold;\n    const baseAdvanceThreshold = this.config.advanceThreshold;\n    \n    // Progressive adjustment - easier thresholds for later segments\n    const progress = currentIndex / (pattern.segments.length - 1);\n    const progressAdjustment = 1.0 - (0.2 * progress); // Up to 20% easier for final segment\n    \n    let currentMatchThreshold = baseMatchThreshold * progressAdjustment;\n    let currentAdvanceThreshold = baseAdvanceThreshold * progressAdjustment;\n    \n    // Special case for final segment\n    if (currentIndex === pattern.segments.length - 1) {\n      // Make final segment significantly easier to detect\n      currentMatchThreshold *= this.config.finalSegmentBoost;\n      currentAdvanceThreshold *= this.config.finalSegmentBoost;\n      debugInfo.finalSegmentBoost = true;\n    }\n    \n    // Check for timeout on current segment\n    if (sequenceState.segments[currentIndex] === 'active') {\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      \n      // Gradually reduce threshold the longer we stay in a segment\n      const timeoutAdjustment = Math.max(0.7, 1.0 - (timeInSegment / this.config.segmentTimeout * 0.3));\n      currentMatchThreshold *= timeoutAdjustment;\n      currentAdvanceThreshold *= timeoutAdjustment;\n      \n      debugInfo.timeInSegment = timeInSegment;\n      debugInfo.timeoutAdjustment = timeoutAdjustment;\n      \n      // If really stuck for a long time, try skipping ahead\n      if (timeInSegment > this.config.segmentTimeout * 0.8) {\n        // Check if a later segment matches well\n        for (let i = currentIndex + 1; i < matchScores.length; i++) {\n          if (matchScores[i] >= baseMatchThreshold * 0.8) {\n            // Skip to this segment\n            for (let j = currentIndex; j < i; j++) {\n              sequenceState.segments[j] = 'complete';\n            }\n            \n            sequenceState.currentIndex = i;\n            sequenceState.segments[i] = 'active';\n            sequenceState.segmentStartTimes[i] = now;\n            sequenceState.lastAdvanceTime = now;\n            \n            this.log('info', `Adaptive skip to segment ${i + 1} (timeout recovery)`);\n            \n            debugInfo.adaptiveSkip = true;\n            debugInfo.skippedTo = i + 1;\n            debugInfo.reason = 'timeout';\n            \n            // Check if we skipped to the last segment\n            if (i === pattern.segments.length - 1) {\n              // If the last segment has a good match, consider the pattern detected\n              if (matchScores[i] >= baseMatchThreshold * 0.9) {\n                // Calculate a confidence penalty for skipping\n                const confidencePenalty = 0.8;\n                \n                return {\n                  patternDetected: true,\n                  confidence: this.calculateOverallConfidence() * confidencePenalty,\n                  debugInfo: {\n                    ...debugInfo,\n                    completed: true,\n                    confidencePenalty\n                  }\n                };\n              }\n            }\n            \n            return {\n              patternDetected: false,\n              confidence: this.calculateOverallConfidence(),\n              debugInfo\n            };\n          }\n        }\n        \n        // If no good skips found, eventually reset\n        if (timeInSegment > this.config.segmentTimeout) {\n          this.log('info', `Adaptive reset (timeout)`);\n          this.resetSequenceState();\n          \n          debugInfo.adaptiveReset = true;\n          debugInfo.reason = 'full timeout';\n          \n          return {\n            patternDetected: false,\n            confidence: 0,\n            debugInfo\n          };\n        }\n      }\n    }\n    \n    // Handle current segment based on match score\n    if (matchScores[currentIndex] >= currentMatchThreshold) {\n      // If we just started matching this segment, record the start time\n      if (sequenceState.segments[currentIndex] === 'pending') {\n        sequenceState.segments[currentIndex] = 'active';\n        sequenceState.segmentStartTimes[currentIndex] = now;\n        sequenceState.lastAdvanceTime = now;\n        this.log('info', `Matching segment ${currentIndex + 1}/${pattern.segments.length}`);\n      }\n      \n      // Check if we've been matching long enough to advance\n      const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n      \n      // Adaptive minimum time based on segment position\n      let minSegmentTime = Math.max(\n        150, // Base minimum time (reduced for adaptive mode)\n        (pattern.segments[currentIndex].frameCount / pattern.rawData.energy.length) \n          * pattern.rawData.duration \n          * (0.4 - 0.1 * progress) // Progressively shorter required match time\n      );\n      \n      // For the final segment, reduce time requirement further\n      if (currentIndex === pattern.segments.length - 1) {\n        minSegmentTime *= 0.7;\n      }\n      \n      debugInfo.timeInSegment = timeInSegment;\n      debugInfo.minSegmentTime = minSegmentTime;\n      debugInfo.matchThreshold = currentMatchThreshold;\n      debugInfo.advanceThreshold = currentAdvanceThreshold;\n      \n      if (timeInSegment >= minSegmentTime && matchScores[currentIndex] >= currentAdvanceThreshold) {\n        // Mark segment as complete\n        sequenceState.segments[currentIndex] = 'complete';\n        \n        // Check if this was the last segment\n        if (currentIndex === pattern.segments.length - 1) {\n          // Completed the full pattern\n          return {\n            patternDetected: true,\n            confidence: this.calculateOverallConfidence(),\n            debugInfo: {\n              ...debugInfo,\n              completed: true\n            }\n          };\n        } else {\n          // Move to next segment\n          sequenceState.currentIndex++;\n          sequenceState.lastAdvanceTime = now;\n          this.log('info', `Advanced to segment ${sequenceState.currentIndex + 1}/${pattern.segments.length}`);\n          \n          // Add progress data to debug info\n          debugInfo.advanced = true;\n          debugInfo.nextSegment = sequenceState.currentIndex + 1;\n        }\n      }\n    } else {\n      // If we lost the match, check if a better matching segment exists\n      if (sequenceState.segments[currentIndex] === 'active') {\n        const timeInSegment = now - (sequenceState.segmentStartTimes[currentIndex] || now);\n        \n        // If stuck for a little while, check for better matches\n        if (timeInSegment > this.config.segmentTimeout * 0.3) {\n          // If a significantly better match exists elsewhere\n          if (bestMatchIndex !== currentIndex && bestMatchScore > matchScores[currentIndex] * 1.3) {\n            // If it's a later segment, consider skipping\n            if (bestMatchIndex > currentIndex) {\n              // Mark segments as complete up to the best match\n              for (let i = currentIndex; i < bestMatchIndex; i++) {\n                sequenceState.segments[i] = 'complete';\n              }\n              \n              sequenceState.currentIndex = bestMatchIndex;\n              sequenceState.segments[bestMatchIndex] = 'active';\n              sequenceState.segmentStartTimes[bestMatchIndex] = now;\n              sequenceState.lastAdvanceTime = now;\n              \n              this.log('info', `Adaptive skip to segment ${bestMatchIndex + 1} (better match)`);\n              \n              debugInfo.adaptiveSkip = true;\n              debugInfo.skippedTo = bestMatchIndex + 1;\n              debugInfo.reason = 'better match';\n              \n              // If we skipped to the last segment, check for completion\n              if (bestMatchIndex === pattern.segments.length - 1 && bestMatchScore >= baseMatchThreshold * 0.9) {\n                const confidencePenalty = 0.9;\n                \n                return {\n                  patternDetected: true,\n                  confidence: this.calculateOverallConfidence() * confidencePenalty,\n                  debugInfo: {\n                    ...debugInfo,\n                    completed: true,\n                    confidencePenalty\n                  }\n                };\n              }\n            }\n            // Allow jumping backward only in extreme cases\n            else if (bestMatchIndex < currentIndex && bestMatchScore > matchScores[currentIndex] * 2) {\n              // Reset segments after the best match\n              for (let i = bestMatchIndex + 1; i < sequenceState.segments.length; i++) {\n                sequenceState.segments[i] = 'pending';\n              }\n              \n              sequenceState.currentIndex = bestMatchIndex;\n              sequenceState.segments[bestMatchIndex] = 'active';\n              sequenceState.segmentStartTimes[bestMatchIndex] = now;\n              sequenceState.lastAdvanceTime = now;\n              \n              this.log('info', `Adaptive jump back to segment ${bestMatchIndex + 1} (much better match)`);\n              \n              debugInfo.adaptiveJumpBack = true;\n              debugInfo.jumpedBackTo = bestMatchIndex + 1;\n            }\n          } else {\n            // If we've been stuck for a while with no better options, mark as invalid\n            if (timeInSegment > this.config.segmentTimeout * 0.6) {\n              sequenceState.segments[currentIndex] = 'invalid';\n              this.log('info', `Lost match for segment ${currentIndex + 1}`);\n              \n              // Reset after a short delay\n              setTimeout(() => {\n                if (this.state.isDetecting && \n                    this.state.sequenceState.currentIndex === currentIndex &&\n                    this.state.sequenceState.segments[currentIndex] === 'invalid') {\n                  this.resetSequenceState();\n                  this.log('info', 'Reset sequence state');\n                }\n              }, 250); // Shorter reset delay for adaptive mode\n            }\n          }\n        }\n      }\n    }\n    \n    // Calculate overall progress\n    const completedSegments = sequenceState.segments.filter(s => s === 'complete').length;\n    const activeSegment = sequenceState.segments.indexOf('active');\n    \n    if (activeSegment !== -1) {\n      // Include partial progress of active segment\n      const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);"
          }
        ],
        "files": [
          {
            "file_name": "paste.txt"
          }
        ]
      }
    },
    {
      "id": "5a25912b-c775-4788-ae19-21031eaf8b12",
      "role": "assistant",
      "content": "\nThe code seems to be cut off at the end of the adaptiveDetection method. I need to continue from the last line:\n\n```javascript\nif (activeSegment !== -1) {\n  // Include partial progress of active segment\n  const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);\n```\n\nLooking at the pattern of other similar methods, the next lines would likely complete the calculation of the progress, update the debug info, and return the detection result, similar to the other detection methods. Let me write the completion of this method and make sure it follows the pattern of the other detection methods.\n\nI should follow with the remaining utility methods that were implemented in the original code, such as:\n- calculateSegmentMatch\n- calculateEnergySimilarity\n- correlationSimilarity\n- spectrogramSimilarity\n- registerDetection\n- calculateOverallConfidence\n- extractFeatures\n- processSpectrumData\n- startAnimationLoop\n- stopAnimationLoop\n- updateConfig\n- findPeaks\n- findValleys\n- smoothArray\n- averageArrays\n- averageSpectrograms\n- average\n- cosineSimilarity\n- flattenArray\n- handleError\n- log\n\nBut looking at the document, it seems like we already have most of these methods implemented. The document appears to already contain a fairly complete implementation, but it got cut off in the middle of the adaptiveDetection method. So I'll focus on completing that method and making sure the HTML structure is complete.\n\nI'll finish the file by completing the `adaptiveDetection` method and adding the missing closing tags:\n\n```javascript\n      sequenceState.progress = (completedSegments / pattern.segments.length) + activeProgress;\n    } else {\n      sequenceState.progress = completedSegments / pattern.segments.length;\n    }\n    \n    // Add progress to debug info\n    debugInfo.progress = sequenceState.progress;\n    debugInfo.segments = [...sequenceState.segments];\n    \n    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };\n  }\n  \n  /**\n   * Calculate match between audio and a pattern segment\n   */\n  calculateSegmentMatch(audioData, segment, customFeatureWeights = null) {\n    // Nothing to match\n    if (!audioData || !segment) return 0;\n    \n    // Get feature arrays\n    const energy = audioData.energy;\n    const mfcc = audioData.mfcc;\n    const spectrogram = audioData.spectrogram;\n    \n    if (!energy.length || !mfcc.length || !spectrogram.length) return 0;\n    \n    // Use provided weights or defaults\n    const featureWeights = customFeatureWeights || this.config.featureWeights;\n    \n    // Sliding window approach\n    let bestMatch = 0;\n    const windowSize = Math.min(segment.frameCount, energy.length);\n    \n    for (let i = 0; i <= energy.length - windowSize; i++) {\n      const windowEnergy = energy.slice(i, i + windowSize);\n      const windowMfcc = mfcc.slice(i, i + windowSize);\n      const windowSpectrogram = spectrogram.slice(i, i + windowSize);\n      \n      // Calculate similarity scores\n      const energyMatch = this.calculateEnergySimilarity(windowEnergy, segment.energy);\n      \n      // Average MFCC across window\n      const avgWindowMfcc = this.averageArrays(windowMfcc);\n      const mfccMatch = this.cosineSimilarity(avgWindowMfcc, segment.avgMfcc);\n      \n      // Average spectrogram\n      const avgWindowSpectrogram = this.averageSpectrograms(windowSpectrogram);\n      const spectrogramMatch = this.spectrogramSimilarity(\n        avgWindowSpectrogram, segment.avgSpectrogram\n      );\n      \n      // Weighted combination\n      const score = \n        (energyMatch * featureWeights.energy) +\n        (mfccMatch * featureWeights.mfcc) +\n        (spectrogramMatch * featureWeights.spectrogram);\n      \n      bestMatch = Math.max(bestMatch, score);\n    }\n    \n    return bestMatch;\n  }\n  \n  /**\n   * Calculate similarity between energy profiles\n   */\n  calculateEnergySimilarity(energyA, energyB) {\n    if (!energyA || !energyB || !energyA.length || !energyB.length) {\n      return 0;\n    }\n    \n    // Normalize lengths\n    const lenA = energyA.length;\n    const lenB = energyB.length;\n    const normalized = [];\n    \n    // Simple resampling\n    for (let i = 0; i < lenB; i++) {\n      const idx = Math.floor(i * lenA / lenB);\n      normalized[i] = energyA[idx];\n    }\n    \n    // Calculate correlation\n    return this.correlationSimilarity(normalized, energyB);\n  }\n  \n  /**\n   * Calculate correlation similarity between arrays\n   */\n  correlationSimilarity(arrA, arrB) {\n    // Calculate means\n    const meanA = this.average(arrA);\n    const meanB = this.average(arrB);\n    \n    // Calculate correlation\n    let num = 0;\n    let denA = 0;\n    let denB = 0;\n    \n    for (let i = 0; i < Math.min(arrA.length, arrB.length); i++) {\n      const a = arrA[i] - meanA;\n      const b = arrB[i] - meanB;\n      \n      num += a * b;\n      denA += a * a;\n      denB += b * b;\n    }\n    \n    // Avoid division by zero\n    if (denA === 0 || denB === 0) return 0;\n    \n    // Return Pearson correlation (between -1 and 1)\n    const corr = num / Math.sqrt(denA * denB);\n    \n    // Convert to similarity (0-1)\n    return (corr + 1) / 2;\n  }\n  \n  /**\n   * Compare two spectrograms\n   */\n  spectrogramSimilarity(spectrogramA, spectrogramB) {\n    if (!spectrogramA || !spectrogramB || \n        !spectrogramA.length || !spectrogramB.length) {\n      return 0;\n    }\n    \n    // Use cosine similarity between flattened spectrograms\n    const flatA = spectrogramA.flat ? spectrogramA.flat() : this.flattenArray(spectrogramA);\n    const flatB = spectrogramB.flat ? spectrogramB.flat() : this.flattenArray(spectrogramB);\n    \n    return this.cosineSimilarity(flatA, flatB);\n  }\n  \n  /**\n   * Register a detection\n   */\n  registerDetection(confidence) {\n    if (this.state.inCooldown) return false;\n    \n    // Increment counter\n    this.state.counter++;\n    this.state.lastDetectionTime = Date.now();\n    this.state.inCooldown = true;\n    \n    // Log detection\n    this.log('detection', `Pattern detected! Count: ${this.state.counter}`, true);\n    \n    // Reset sequence state\n    this.resetSequenceState();\n    \n    // Trigger callback\n    if (this.callbacks.onDetection) {\n      this.callbacks.onDetection(this.state.counter, confidence);\n    }\n    \n    // Start cooldown timer\n    setTimeout(() => {\n      this.state.inCooldown = false;\n    }, this.config.cooldownTime);\n    \n    return true;\n  }\n  \n  /**\n   * Calculate overall confidence for current match\n   */\n  calculateOverallConfidence() {\n    const matchScores = this.state.sequenceState.matchScores;\n    const segments = this.state.sequenceState.segments;\n    \n    if (!matchScores || matchScores.length === 0) {\n      return 0;\n    }\n    \n    // Weight completed segments more heavily\n    let weightedSum = 0;\n    let weightSum = 0;\n    \n    matchScores.forEach((score, index) => {\n      // Higher weight for completed segments\n      let weight = 1;\n      \n      if (segments[index] === 'complete') {\n        weight = 1.5;\n      } else if (segments[index] === 'active') {\n        weight = 1.2;\n      }\n      \n      weightedSum += score * weight;\n      weightSum += weight;\n    });\n    \n    return weightSum > 0 ? weightedSum / weightSum : 0;\n  }\n  \n  /**\n   * Extract features from audio data\n   */\n  extractFeatures(audioData) {\n    try {\n      // Basic amplitude/energy\n      let sum = 0;\n      for (let i = 0; i < audioData.length; i++) {\n        sum += Math.abs(audioData[i]);\n      }\n      const amplitude = sum / audioData.length;\n      const energy = amplitude * amplitude * 100;\n      \n      // Get frequency data\n      const frequencyData = new Uint8Array(this.analyzer.frequencyBinCount);\n      this.analyzer.getByteFrequencyData(frequencyData);\n      \n      // Extract MFCC using Meyda\n      let mfcc = new Array(13).fill(0);\n      try {\n        const meydaFeatures = Meyda.extract('mfcc', audioData);\n        if (meydaFeatures && meydaFeatures.mfcc) {\n          mfcc = meydaFeatures.mfcc;\n        }\n      } catch (e) {\n        // Ignore Meyda errors and use fallback\n      }\n      \n      // Convert spectrogram data\n      const spectrogram = this.processSpectrumData(frequencyData);\n      \n      return {\n        amplitude,\n        energy,\n        mfcc,\n        spectrogram,\n        raw: {\n          frequencyData\n        }\n      };\n    } catch (error) {\n      this.handleError('Error extracting features', error);\n      \n      // Return dummy features\n      return {\n        amplitude: 0,\n        energy: 0,\n        mfcc: new Array(13).fill(0),\n        spectrogram: new Array(128).fill(0),\n        raw: {\n          frequencyData: new Uint8Array(1024)\n        }\n      };\n    }\n  }\n  \n  /**\n   * Process raw spectrum data into a more compact format\n   */\n  processSpectrumData(frequencyData) {\n    // Reduce dimensionality for efficiency\n    const bins = 128; // 128 frequency bins\n    const result = new Array(bins).fill(0);\n    \n    const binSize = Math.floor(frequencyData.length / bins);\n    \n    for (let i = 0; i < bins; i++) {\n      const start = i * binSize;\n      const end = (i + 1) * binSize;\n      \n      // Average values in this frequency bin\n      let sum = 0;\n      for (let j = start; j < end && j < frequencyData.length; j++) {\n        sum += frequencyData[j];\n      }\n      \n      result[i] = sum / binSize / 255; // Normalize to 0-1\n    }\n    \n    return result;\n  }\n  \n  /**\n   * Start animation loop for cursor movement\n   */\n  startAnimationLoop() {\n    // Stop any existing loop\n    this.stopAnimationLoop();\n    \n    // Animation function\n    const animate = () => {\n      // Move time cursor\n      const cursor = document.getElementById('timeCursor');\n      if (cursor) {\n        // Get a position that oscillates between 25% and 75%\n        const time = Date.now() / 1000;\n        const position = 50 + 25 * Math.sin(time);\n        cursor.style.left = `${position}%`;\n      }\n      \n      // Request next frame\n      this.animationFrame = requestAnimationFrame(animate);\n    };\n    \n    // Start animation\n    this.animationFrame = requestAnimationFrame(animate);\n  }\n  \n  /**\n   * Stop animation loop\n   */\n  stopAnimationLoop() {\n    if (this.animationFrame) {\n      cancelAnimationFrame(this.animationFrame);\n      this.animationFrame = null;\n    }\n  }\n  \n  /**\n   * Update configuration\n   */\n  updateConfig(config) {\n    Object.assign(this.config, config);\n    \n    // If segment count changed and we have a pattern, re-segment it\n    if (config.segmentCount !== undefined && this.state.patterns[this.state.activePatternIndex]) {\n      const pattern = this.state.patterns[this.state.activePatternIndex];\n      \n      if (pattern && pattern.rawData) {\n        pattern.segments = this.segmentPattern(pattern.rawData);\n        this.calculateSegmentBoundaries(pattern);\n      }\n    }\n  }\n  \n  /**\n   * Find peaks in energy profile\n   */\n  findPeaks(signal, minHeight = 0.1) {\n    const peaks = [];\n    for (let i = 2; i < signal.length - 2; i++) {\n      if (signal[i] > minHeight && \n          signal[i] > signal[i-1] && signal[i] >= signal[i-2] &&\n          signal[i] > signal[i+1] && signal[i] >= signal[i+2]) {\n        peaks.push(i);\n      }\n    }\n    return peaks;\n  }\n  \n  /**\n   * Find valleys in energy profile\n   */\n  findValleys(signal, maxHeight = 0.9) {\n    const valleys = [];\n    for (let i = 2; i < signal.length - 2; i++) {\n      if (signal[i] < maxHeight && \n          signal[i] < signal[i-1] && signal[i] <= signal[i-2] &&\n          signal[i] < signal[i+1] && signal[i] <= signal[i+2]) {\n        valleys.push(i);\n      }\n    }\n    return valleys;\n  }\n  \n  /**\n   * Smooth an array using moving average\n   */\n  smoothArray(array, windowSize = 3) {\n    const result = [];\n    const half = Math.floor(windowSize / 2);\n    \n    for (let i = 0; i < array.length; i++) {\n      let sum = 0;\n      let count = 0;\n      \n      for (let j = Math.max(0, i - half); j <= Math.min(array.length - 1, i + half); j++) {\n        sum += array[j];\n        count++;\n      }\n      \n      result.push(sum / count);\n    }\n    \n    return result;\n  }\n  \n  /**\n   * Average multiple arrays\n   */\n  averageArrays(arrays) {\n    if (!arrays || arrays.length === 0 || !arrays[0]) return [];\n    \n    const result = new Array(arrays[0].length).fill(0);\n    let validArrays = 0;\n    \n    for (const arr of arrays) {\n      if (!arr) continue;\n      \n      validArrays++;\n      for (let i = 0; i < Math.min(result.length, arr.length); i++) {\n        result[i] += arr[i];\n      }\n    }\n    \n    return validArrays > 0 ? result.map(val => val / validArrays) : result;\n  }\n  \n  /**\n   * Average multiple spectrograms\n   */\n  averageSpectrograms(spectrograms) {\n    return this.averageArrays(spectrograms);\n  }\n  \n  /**\n   * Calculate average of array\n   */\n  average(array) {\n    if (!array || array.length === 0) return 0;\n    return array.reduce((sum, val) => sum + val, 0) / array.length;\n  }\n  \n  /**\n   * Calculate cosine similarity between arrays\n   */\n  cosineSimilarity(arrA, arrB) {\n    if (!arrA || !arrB || arrA.length === 0 || arrB.length === 0) {\n      return 0;\n    }\n    \n    const length = Math.min(arrA.length, arrB.length);\n    \n    let dotProduct = 0;\n    let normA = 0;\n    let normB = 0;\n    \n    for (let i = 0; i < length; i++) {\n      dotProduct += arrA[i] * arrB[i];\n      normA += arrA[i] * arrA[i];\n      normB += arrB[i] * arrB[i];\n    }\n    \n    const denominator = Math.sqrt(normA) * Math.sqrt(normB);\n    \n    return denominator === 0 ? 0 : dotProduct / denominator;\n  }\n  \n  /**\n   * Flatten a 2D array\n   */\n  flattenArray(array) {\n    if (array.flat) return array.flat();\n    \n    return [].concat(...array);\n  }\n  \n  /**\n   * Handle errors\n   */\n  handleError(message, error) {\n    const errorMessage = `${message}: ${error.message || error}`;\n    console.error(errorMessage);\n    \n    if (this.callbacks.onError) {\n      this.callbacks.onError(message, error);\n    }\n  }\n  \n  /**\n   * Log messages\n   */\n  log(type, message, highlight = false) {\n    console.log(`[${type.toUpperCase()}] ${message}`);\n    \n    if (this.callbacks.onStatusUpdate) {\n      this.callbacks.onStatusUpdate(type, message, highlight);\n    }\n    \n    return { type, message, highlight };\n  }\n}\n</script>\n</body>\n</html>\n```\n\nThe file is now complete with the finished `adaptiveDetection` method and all remaining utility methods. The main improvements in this enhanced chant detector are:\n\n1. **Final Segment Boost** - Makes the last segment in the pattern easier to detect (the key issue in your original code)\n2. **Adaptive Detection** - Dynamically adjusts thresholds based on context\n3. **Smart Pattern Segmentation** - Better divides patterns into logical segments\n4. **Improved Visualization** - Better feedback about what's being detected\n5. **Mobile Support** - Touch events for mobile devices\n\nTo use it effectively:\n- The \"adaptive\" mode is set as default since it handles most cases well\n- The \"Final Segment Boost\" slider directly controls how much easier the last segment is to detect (lower value = easier)\n- When recording, try to make clear distinctions between parts of your chant\n- Recording 2-3 samples and averaging them creates a more robust pattern\n\nThis should resolve the problem of the detector not recognizing the complete pattern sequence, particularly the last segment.",
      "created_at": "2025-03-17T17:11:48.002628Z",
      "sequence_order": 7,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-03-17T17:10:36.301987Z",
            "stop_timestamp": "2025-03-17T17:10:41.573311Z",
            "flags": null,
            "type": "thinking",
            "thinking": "\nThe code seems to be cut off at the end of the adaptiveDetection method. I need to continue from the last line:\n\n```javascript\nif (activeSegment !== -1) {\n  // Include partial progress of active segment\n  const activeProgress = matchScores[activeSegment] * (1 / pattern.segments.length);\n```\n\nLooking at the pattern of other similar methods, the next lines would likely complete the calculation of the progress, update the debug info, and return the detection result, similar to the other detection methods. Let me write the completion of this method and make sure it follows the pattern of the other detection methods.\n\nI should follow with the remaining utility methods that were implemented in the original code, such as:\n- calculateSegmentMatch\n- calculateEnergySimilarity\n- correlationSimilarity\n- spectrogramSimilarity\n- registerDetection\n- calculateOverallConfidence\n- extractFeatures\n- processSpectrumData\n- startAnimationLoop\n- stopAnimationLoop\n- updateConfig\n- findPeaks\n- findValleys\n- smoothArray\n- averageArrays\n- averageSpectrograms\n- average\n- cosineSimilarity\n- flattenArray\n- handleError\n- log\n\nBut looking at the document, it seems like we already have most of these methods implemented. The document appears to already contain a fairly complete implementation, but it got cut off in the middle of the adaptiveDetection method. So I'll focus on completing that method and making sure the HTML structure is complete.",
            "summaries": [
              {
                "summary": "Thinking about completing an unspecified file's next section"
              },
              {
                "summary": "Parsing incomplete code segment, seeking resolution"
              },
              {
                "summary": "Reconstructed code method and evaluated implementation completeness."
              }
            ],
            "cut_off": false
          },
          {
            "start_timestamp": "2025-03-17T17:10:41.782656Z",
            "stop_timestamp": "2025-03-17T17:11:35.251796Z",
            "flags": null,
            "type": "text",
            "text": "\n\nI'll finish the file by completing the `adaptiveDetection` method and adding the missing closing tags:\n\n```javascript\n      sequenceState.progress = (completedSegments / pattern.segments.length) + activeProgress;\n    } else {\n      sequenceState.progress = completedSegments / pattern.segments.length;\n    }\n    \n    // Add progress to debug info\n    debugInfo.progress = sequenceState.progress;\n    debugInfo.segments = [...sequenceState.segments];\n    \n    return {\n      patternDetected: false,\n      confidence: this.calculateOverallConfidence(),\n      debugInfo\n    };\n  }\n  \n  /**\n   * Calculate match between audio and a pattern segment\n   */\n  calculateSegmentMatch(audioData, segment, customFeatureWeights = null) {\n    // Nothing to match\n    if (!audioData || !segment) return 0;\n    \n    // Get feature arrays\n    const energy = audioData.energy;\n    const mfcc = audioData.mfcc;\n    const spectrogram = audioData.spectrogram;\n    \n    if (!energy.length || !mfcc.length || !spectrogram.length) return 0;\n    \n    // Use provided weights or defaults\n    const featureWeights = customFeatureWeights || this.config.featureWeights;\n    \n    // Sliding window approach\n    let bestMatch = 0;\n    const windowSize = Math.min(segment.frameCount, energy.length);\n    \n    for (let i = 0; i <= energy.length - windowSize; i++) {\n      const windowEnergy = energy.slice(i, i + windowSize);\n      const windowMfcc = mfcc.slice(i, i + windowSize);\n      const windowSpectrogram = spectrogram.slice(i, i + windowSize);\n      \n      // Calculate similarity scores\n      const energyMatch = this.calculateEnergySimilarity(windowEnergy, segment.energy);\n      \n      // Average MFCC across window\n      const avgWindowMfcc = this.averageArrays(windowMfcc);\n      const mfccMatch = this.cosineSimilarity(avgWindowMfcc, segment.avgMfcc);\n      \n      // Average spectrogram\n      const avgWindowSpectrogram = this.averageSpectrograms(windowSpectrogram);\n      const spectrogramMatch = this.spectrogramSimilarity(\n        avgWindowSpectrogram, segment.avgSpectrogram\n      );\n      \n      // Weighted combination\n      const score = \n        (energyMatch * featureWeights.energy) +\n        (mfccMatch * featureWeights.mfcc) +\n        (spectrogramMatch * featureWeights.spectrogram);\n      \n      bestMatch = Math.max(bestMatch, score);\n    }\n    \n    return bestMatch;\n  }\n  \n  /**\n   * Calculate similarity between energy profiles\n   */\n  calculateEnergySimilarity(energyA, energyB) {\n    if (!energyA || !energyB || !energyA.length || !energyB.length) {\n      return 0;\n    }\n    \n    // Normalize lengths\n    const lenA = energyA.length;\n    const lenB = energyB.length;\n    const normalized = [];\n    \n    // Simple resampling\n    for (let i = 0; i < lenB; i++) {\n      const idx = Math.floor(i * lenA / lenB);\n      normalized[i] = energyA[idx];\n    }\n    \n    // Calculate correlation\n    return this.correlationSimilarity(normalized, energyB);\n  }\n  \n  /**\n   * Calculate correlation similarity between arrays\n   */\n  correlationSimilarity(arrA, arrB) {\n    // Calculate means\n    const meanA = this.average(arrA);\n    const meanB = this.average(arrB);\n    \n    // Calculate correlation\n    let num = 0;\n    let denA = 0;\n    let denB = 0;\n    \n    for (let i = 0; i < Math.min(arrA.length, arrB.length); i++) {\n      const a = arrA[i] - meanA;\n      const b = arrB[i] - meanB;\n      \n      num += a * b;\n      denA += a * a;\n      denB += b * b;\n    }\n    \n    // Avoid division by zero\n    if (denA === 0 || denB === 0) return 0;\n    \n    // Return Pearson correlation (between -1 and 1)\n    const corr = num / Math.sqrt(denA * denB);\n    \n    // Convert to similarity (0-1)\n    return (corr + 1) / 2;\n  }\n  \n  /**\n   * Compare two spectrograms\n   */\n  spectrogramSimilarity(spectrogramA, spectrogramB) {\n    if (!spectrogramA || !spectrogramB || \n        !spectrogramA.length || !spectrogramB.length) {\n      return 0;\n    }\n    \n    // Use cosine similarity between flattened spectrograms\n    const flatA = spectrogramA.flat ? spectrogramA.flat() : this.flattenArray(spectrogramA);\n    const flatB = spectrogramB.flat ? spectrogramB.flat() : this.flattenArray(spectrogramB);\n    \n    return this.cosineSimilarity(flatA, flatB);\n  }\n  \n  /**\n   * Register a detection\n   */\n  registerDetection(confidence) {\n    if (this.state.inCooldown) return false;\n    \n    // Increment counter\n    this.state.counter++;\n    this.state.lastDetectionTime = Date.now();\n    this.state.inCooldown = true;\n    \n    // Log detection\n    this.log('detection', `Pattern detected! Count: ${this.state.counter}`, true);\n    \n    // Reset sequence state\n    this.resetSequenceState();\n    \n    // Trigger callback\n    if (this.callbacks.onDetection) {\n      this.callbacks.onDetection(this.state.counter, confidence);\n    }\n    \n    // Start cooldown timer\n    setTimeout(() => {\n      this.state.inCooldown = false;\n    }, this.config.cooldownTime);\n    \n    return true;\n  }\n  \n  /**\n   * Calculate overall confidence for current match\n   */\n  calculateOverallConfidence() {\n    const matchScores = this.state.sequenceState.matchScores;\n    const segments = this.state.sequenceState.segments;\n    \n    if (!matchScores || matchScores.length === 0) {\n      return 0;\n    }\n    \n    // Weight completed segments more heavily\n    let weightedSum = 0;\n    let weightSum = 0;\n    \n    matchScores.forEach((score, index) => {\n      // Higher weight for completed segments\n      let weight = 1;\n      \n      if (segments[index] === 'complete') {\n        weight = 1.5;\n      } else if (segments[index] === 'active') {\n        weight = 1.2;\n      }\n      \n      weightedSum += score * weight;\n      weightSum += weight;\n    });\n    \n    return weightSum > 0 ? weightedSum / weightSum : 0;\n  }\n  \n  /**\n   * Extract features from audio data\n   */\n  extractFeatures(audioData) {\n    try {\n      // Basic amplitude/energy\n      let sum = 0;\n      for (let i = 0; i < audioData.length; i++) {\n        sum += Math.abs(audioData[i]);\n      }\n      const amplitude = sum / audioData.length;\n      const energy = amplitude * amplitude * 100;\n      \n      // Get frequency data\n      const frequencyData = new Uint8Array(this.analyzer.frequencyBinCount);\n      this.analyzer.getByteFrequencyData(frequencyData);\n      \n      // Extract MFCC using Meyda\n      let mfcc = new Array(13).fill(0);\n      try {\n        const meydaFeatures = Meyda.extract('mfcc', audioData);\n        if (meydaFeatures && meydaFeatures.mfcc) {\n          mfcc = meydaFeatures.mfcc;\n        }\n      } catch (e) {\n        // Ignore Meyda errors and use fallback\n      }\n      \n      // Convert spectrogram data\n      const spectrogram = this.processSpectrumData(frequencyData);\n      \n      return {\n        amplitude,\n        energy,\n        mfcc,\n        spectrogram,\n        raw: {\n          frequencyData\n        }\n      };\n    } catch (error) {\n      this.handleError('Error extracting features', error);\n      \n      // Return dummy features\n      return {\n        amplitude: 0,\n        energy: 0,\n        mfcc: new Array(13).fill(0),\n        spectrogram: new Array(128).fill(0),\n        raw: {\n          frequencyData: new Uint8Array(1024)\n        }\n      };\n    }\n  }\n  \n  /**\n   * Process raw spectrum data into a more compact format\n   */\n  processSpectrumData(frequencyData) {\n    // Reduce dimensionality for efficiency\n    const bins = 128; // 128 frequency bins\n    const result = new Array(bins).fill(0);\n    \n    const binSize = Math.floor(frequencyData.length / bins);\n    \n    for (let i = 0; i < bins; i++) {\n      const start = i * binSize;\n      const end = (i + 1) * binSize;\n      \n      // Average values in this frequency bin\n      let sum = 0;\n      for (let j = start; j < end && j < frequencyData.length; j++) {\n        sum += frequencyData[j];\n      }\n      \n      result[i] = sum / binSize / 255; // Normalize to 0-1\n    }\n    \n    return result;\n  }\n  \n  /**\n   * Start animation loop for cursor movement\n   */\n  startAnimationLoop() {\n    // Stop any existing loop\n    this.stopAnimationLoop();\n    \n    // Animation function\n    const animate = () => {\n      // Move time cursor\n      const cursor = document.getElementById('timeCursor');\n      if (cursor) {\n        // Get a position that oscillates between 25% and 75%\n        const time = Date.now() / 1000;\n        const position = 50 + 25 * Math.sin(time);\n        cursor.style.left = `${position}%`;\n      }\n      \n      // Request next frame\n      this.animationFrame = requestAnimationFrame(animate);\n    };\n    \n    // Start animation\n    this.animationFrame = requestAnimationFrame(animate);\n  }\n  \n  /**\n   * Stop animation loop\n   */\n  stopAnimationLoop() {\n    if (this.animationFrame) {\n      cancelAnimationFrame(this.animationFrame);\n      this.animationFrame = null;\n    }\n  }\n  \n  /**\n   * Update configuration\n   */\n  updateConfig(config) {\n    Object.assign(this.config, config);\n    \n    // If segment count changed and we have a pattern, re-segment it\n    if (config.segmentCount !== undefined && this.state.patterns[this.state.activePatternIndex]) {\n      const pattern = this.state.patterns[this.state.activePatternIndex];\n      \n      if (pattern && pattern.rawData) {\n        pattern.segments = this.segmentPattern(pattern.rawData);\n        this.calculateSegmentBoundaries(pattern);\n      }\n    }\n  }\n  \n  /**\n   * Find peaks in energy profile\n   */\n  findPeaks(signal, minHeight = 0.1) {\n    const peaks = [];\n    for (let i = 2; i < signal.length - 2; i++) {\n      if (signal[i] > minHeight && \n          signal[i] > signal[i-1] && signal[i] >= signal[i-2] &&\n          signal[i] > signal[i+1] && signal[i] >= signal[i+2]) {\n        peaks.push(i);\n      }\n    }\n    return peaks;\n  }\n  \n  /**\n   * Find valleys in energy profile\n   */\n  findValleys(signal, maxHeight = 0.9) {\n    const valleys = [];\n    for (let i = 2; i < signal.length - 2; i++) {\n      if (signal[i] < maxHeight && \n          signal[i] < signal[i-1] && signal[i] <= signal[i-2] &&\n          signal[i] < signal[i+1] && signal[i] <= signal[i+2]) {\n        valleys.push(i);\n      }\n    }\n    return valleys;\n  }\n  \n  /**\n   * Smooth an array using moving average\n   */\n  smoothArray(array, windowSize = 3) {\n    const result = [];\n    const half = Math.floor(windowSize / 2);\n    \n    for (let i = 0; i < array.length; i++) {\n      let sum = 0;\n      let count = 0;\n      \n      for (let j = Math.max(0, i - half); j <= Math.min(array.length - 1, i + half); j++) {\n        sum += array[j];\n        count++;\n      }\n      \n      result.push(sum / count);\n    }\n    \n    return result;\n  }\n  \n  /**\n   * Average multiple arrays\n   */\n  averageArrays(arrays) {\n    if (!arrays || arrays.length === 0 || !arrays[0]) return [];\n    \n    const result = new Array(arrays[0].length).fill(0);\n    let validArrays = 0;\n    \n    for (const arr of arrays) {\n      if (!arr) continue;\n      \n      validArrays++;\n      for (let i = 0; i < Math.min(result.length, arr.length); i++) {\n        result[i] += arr[i];\n      }\n    }\n    \n    return validArrays > 0 ? result.map(val => val / validArrays) : result;\n  }\n  \n  /**\n   * Average multiple spectrograms\n   */\n  averageSpectrograms(spectrograms) {\n    return this.averageArrays(spectrograms);\n  }\n  \n  /**\n   * Calculate average of array\n   */\n  average(array) {\n    if (!array || array.length === 0) return 0;\n    return array.reduce((sum, val) => sum + val, 0) / array.length;\n  }\n  \n  /**\n   * Calculate cosine similarity between arrays\n   */\n  cosineSimilarity(arrA, arrB) {\n    if (!arrA || !arrB || arrA.length === 0 || arrB.length === 0) {\n      return 0;\n    }\n    \n    const length = Math.min(arrA.length, arrB.length);\n    \n    let dotProduct = 0;\n    let normA = 0;\n    let normB = 0;\n    \n    for (let i = 0; i < length; i++) {\n      dotProduct += arrA[i] * arrB[i];\n      normA += arrA[i] * arrA[i];\n      normB += arrB[i] * arrB[i];\n    }\n    \n    const denominator = Math.sqrt(normA) * Math.sqrt(normB);\n    \n    return denominator === 0 ? 0 : dotProduct / denominator;\n  }\n  \n  /**\n   * Flatten a 2D array\n   */\n  flattenArray(array) {\n    if (array.flat) return array.flat();\n    \n    return [].concat(...array);\n  }\n  \n  /**\n   * Handle errors\n   */\n  handleError(message, error) {\n    const errorMessage = `${message}: ${error.message || error}`;\n    console.error(errorMessage);\n    \n    if (this.callbacks.onError) {\n      this.callbacks.onError(message, error);\n    }\n  }\n  \n  /**\n   * Log messages\n   */\n  log(type, message, highlight = false) {\n    console.log(`[${type.toUpperCase()}] ${message}`);\n    \n    if (this.callbacks.onStatusUpdate) {\n      this.callbacks.onStatusUpdate(type, message, highlight);\n    }\n    \n    return { type, message, highlight };\n  }\n}\n</script>\n</body>\n</html>\n```\n\nThe file is now complete with the finished `adaptiveDetection` method and all remaining utility methods. The main improvements in this enhanced chant detector are:\n\n1. **Final Segment Boost** - Makes the last segment in the pattern easier to detect (the key issue in your original code)\n2. **Adaptive Detection** - Dynamically adjusts thresholds based on context\n3. **Smart Pattern Segmentation** - Better divides patterns into logical segments\n4. **Improved Visualization** - Better feedback about what's being detected\n5. **Mobile Support** - Touch events for mobile devices\n\nTo use it effectively:\n- The \"adaptive\" mode is set as default since it handles most cases well\n- The \"Final Segment Boost\" slider directly controls how much easier the last segment is to detect (lower value = easier)\n- When recording, try to make clear distinctions between parts of your chant\n- Recording 2-3 samples and averaging them creates a more robust pattern\n\nThis should resolve the problem of the detector not recognizing the complete pattern sequence, particularly the last segment.",
            "citations": []
          }
        ],
        "updated_at": "2025-03-17T17:11:48.002628Z",
        "attachments": [],
        "files": []
      }
    }
  ]
}