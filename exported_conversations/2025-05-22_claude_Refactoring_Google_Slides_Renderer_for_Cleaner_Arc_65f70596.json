{
  "id": "65f70596-0a87-453d-b26b-3de749e34a20",
  "source": "claude",
  "title": "Refactoring Google Slides Renderer for Cleaner Architecture",
  "created_at": "2025-05-22T15:16:32.455563Z",
  "updated_at": "2025-05-22T15:31:29.949715Z",
  "summary": "",
  "message_count": 4,
  "messages": [
    {
      "id": "66c89c07-ae7f-434c-bd53-c250f3d08dcd",
      "role": "human",
      "content": "ok, so now the google slides is working a little better, except I'm not sure why it's not uploading an image or making diagrams google_slides_renderer.py Â review the code and explain why google_slides_renderer.py isn't making diagrams or uploading images, it's json is like this using some random example.com url instead of the litterbox one we want itÂ  â”‚ â”‚ Â  to use, don't change anything immediately just give me a diagnosis, also include a diagnosis about how the json can get the images and diagrams generated or found and then being uploaded toÂ  Â  Â  Â  Â  â”‚ â”‚ Â  littler box before being included into the google slide so we can have the url - do we need a new service, we have a DDD structure and right now it seems like googleslides renderer is a bit tooÂ  Â  Â  â”‚ â”‚ Â  big, we probably need an intermediate step after the JSON that takes place before both PPTX and google slides rendering what do you think of this diagnosis can you review and think about the best DDD and clean approach we can take and return all the files needed to fix the code - I feel the code is starting to get a bit mixed in purposes - review reflect make a plan and then return all the files",
      "created_at": "2025-05-22T15:16:34.998575Z",
      "sequence_order": 0,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-22T15:16:34.976409Z",
            "stop_timestamp": "2025-05-22T15:16:34.976409Z",
            "flags": null,
            "type": "text",
            "text": "ok, so now the google slides is working a little better, except I'm not sure why it's not uploading an image or making diagrams google_slides_renderer.py Â review the code and explain why google_slides_renderer.py isn't making diagrams or uploading images, it's json is like this using some random example.com url instead of the litterbox one we want itÂ  â”‚ â”‚ Â  to use, don't change anything immediately just give me a diagnosis, also include a diagnosis about how the json can get the images and diagrams generated or found and then being uploaded toÂ  Â  Â  Â  Â  â”‚ â”‚ Â  littler box before being included into the google slide so we can have the url - do we need a new service, we have a DDD structure and right now it seems like googleslides renderer is a bit tooÂ  Â  Â  â”‚ â”‚ Â  big, we probably need an intermediate step after the JSON that takes place before both PPTX and google slides rendering what do you think of this diagnosis can you review and think about the best DDD and clean approach we can take and return all the files needed to fix the code - I feel the code is starting to get a bit mixed in purposes - review reflect make a plan and then return all the files",
            "citations": []
          }
        ],
        "updated_at": "2025-05-22T15:16:34.998575Z",
        "attachments": [
          {
            "file_name": "paste.txt",
            "file_size": 4171,
            "file_type": "txt",
            "extracted_content": "âº After reviewing the code, I can provide a diagnosis of why Google Slides isn't properly handling diagrams and images with the litterbox URLs.\n\n  Diagnosis of Google Slides Renderer Image Issue\n\n  The fundamental problem is in the image handling workflow between the JSON generation and the Google Slides rendering:\n\n  1. Missing Image Upload Step: The Google Slides renderer (google_slides_renderer.py) is trying to use direct image URLs (like example.com) rather than uploading local images to\n  litterbox.catbox.moe.\n  2. Inconsistent Path Handling: When parsing slide data, the renderer doesn't have a clear strategy for extracting image/diagram paths. While the PPTX renderer has robust code to find local image\n  paths from various fields (local_image_path, local_diagram_path), the Google Slides renderer doesn't fully implement this logic.\n  3. No Upload Integration: The Google Slides renderer lacks integration with the litterbox upload functionality that works in your shell scripts.\n  4. Architecture Issue: The current architecture doesn't have a dedicated \"asset management\" step that happens before rendering. Each renderer is handling its own image processing instead of having\n  a centralized service handle this.\n\n  Missing Intermediate Step - Asset Processing Service\n\n  You're right that we need an intermediate step in the DDD architecture between JSON generation and rendering. The current process flow is:\n\n  Content â†’ Content Analyzer â†’ JSON â†’ Direct Rendering (PPTX or Google Slides)\n\n  The improved architecture should be:\n\n  Content â†’ Content Analyzer â†’ JSON â†’ Asset Processing Service â†’ Renderers\n\n  The Asset Processing Service would:\n\n  1. Extract all asset references from the JSON (images, diagrams)\n  2. Process and generate any diagrams from diagram content\n  3. Upload all assets to litterbox.catbox.moe (or another hosting service)\n  4. Update the JSON with the correct remote URLs\n  5. Pass the updated JSON to the renderers\n\n  This would ensure both the PPTX and Google Slides renderers have consistent access to online images.\n\n  Image/Diagram Upload Process\n\n  The current issue with image uploading happens because:\n\n  1. Your shell scripts (upload_and_fix_images.py, etc.) handle the litterbox uploading but aren't integrated into the core rendering flow\n  2. The Google Slides renderer attempts to use image URLs directly rather than downloading/uploading them\n  3. The litterbox upload code exists but isn't being called at the right point in the process\n\n  Here's what's happening now:\n\n  1. Diagrams are generated as local files (in images/ directory)\n  2. JSON contains references to these local files or diagram content\n  3. PPTX renderer can handle local files directly\n  4. Google Slides renderer needs online URLs but doesn't handle the upload itself\n\n  Solution Architecture\n\n  You need a new AssetManager service class in your DDD structure:\n\n  makeslides/\n    â”œâ”€â”€ services/\n    â”‚   â”œâ”€â”€ content_analyzer.py  # Existing\n    â”‚   â”œâ”€â”€ asset_manager.py     # New service\n    â”‚   â””â”€â”€ renderer_service.py  # Existing\n    â”œâ”€â”€ renderers/\n    â”‚   â”œâ”€â”€ factory.py           # Existing\n    â”‚   â”œâ”€â”€ pptx_renderer.py     # Existing\n    â”‚   â””â”€â”€ google_slides_renderer.py # Existing\n\n  The AssetManager would be responsible for:\n  1. Extracting all image/diagram references from presentation data\n  2. Rendering diagrams from diagram content\n  3. Uploading all assets to litterbox\n  4. Updating the presentation data with remote URLs\n\n  The controller would then call this service before passing the data to renderers:\n\n  # In controller.py\n  presentation_dict = self._presentation_to_dict(presentation)\n\n  # NEW: Process assets (diagrams and images)\n  asset_manager = AssetManager()\n  presentation_dict = asset_manager.process_assets(presentation_dict)\n\n  # Now render with the updated presentation data\n  renderer = create_renderer(output_format=output_format, ...)\n  result = renderer.render(presentation_dict, output_path)\n\n  This keeps each service focused on its specific responsibility and ensures consistent asset handling across different renderers."
          }
        ],
        "files": [
          {
            "file_name": "paste.txt"
          }
        ]
      }
    },
    {
      "id": "4dbc701c-3051-46ca-b03b-7848f5e5f1f3",
      "role": "assistant",
      "content": "Looking at the code and the user's diagnosis, I can see several issues:\n\n1. **Google Slides Renderer Image Issues:**\n   - The `_upload_slide_image_to_litterbox` method exists but is looking for images in various fields like `image_url`, `local_image_path`, etc.\n   - The method tries to find generated diagram files using patterns like `images/test_fix_workflow_slide{slide_num}_{diagram_type}.png`\n   - But there's no guarantee these files exist or were generated\n   - The `_upload_to_litterbox` method uses curl to upload to litterbox, but it's only called if a local image file is found\n\n2. **Architecture Issues:**\n   - The current flow is: Content â†’ Content Analyzer â†’ JSON â†’ Direct Rendering\n   - The Google Slides renderer is trying to do too much: find images, upload them, AND render slides\n   - There's no centralized asset management\n   - The diagram rendering logic is separate (in `diagrams/renderer.py`) but not integrated into the main flow\n\n3. **Missing Integration:**\n   - The `diagrams/renderer.py` has logic to render Mermaid diagrams from JSON, but it's not being called in the main controller flow\n   - The JSON might contain `diagram_content` and `diagram_type` but no actual image files are generated from this\n   - The asset manager that exists (`asset_manager.py`) is not being used in the main flow\n\n4. **DDD Structure Issues:**\n   - The renderer is handling asset processing, which should be a separate concern\n   - We need a clear separation between:\n     - Content Analysis (generates JSON with content/diagram specs)\n     - Asset Processing (generates diagrams, uploads assets, updates JSON with URLs)  \n     - Rendering (creates presentations using the processed JSON)\n\nThe user's diagnosis is spot on. We need an intermediate Asset Processing Service that:\n1. Takes the raw JSON from content analysis\n2. Generates any diagrams from `diagram_content` \n3. Uploads all assets (images, diagrams) to litterbox\n4. Updates the JSON with remote URLs\n5. Passes clean JSON to renderers\n\nLet me design a clean architecture:\n\n```\nContent â†’ ContentAnalyzer â†’ Raw JSON â†’ AssetProcessor â†’ Processed JSON â†’ Renderer\n```\n\nThe AssetProcessor would:\n1. Scan JSON for diagram_content fields\n2. Generate diagrams using the existing diagram renderer\n3. Scan for local image paths  \n4. Upload all assets to litterbox\n5. Update JSON with litterbox URLs\n6. Return processed JSON\n\nThis keeps each service focused on one responsibility.\n\nI'll need to create/modify:\n1. `services/asset_processor.py` - New service for asset processing\n2. Update `core/controller.py` - Add asset processing step\n3. Update `google_slides_renderer.py` - Remove asset processing logic, just use URLs\n4. Update `services/renderer_service.py` - Clean up responsibilities\n\nLet me think through the flow:\n\n1. User provides content\n2. ContentAnalyzer creates JSON with titles, content, diagram_content, layout info\n3. AssetProcessor takes this JSON and:\n   - For each slide with diagram_content: generates diagram image file\n   - For each slide with local image references: finds the files\n   - Uploads all found images to litterbox\n   - Updates the slide's image_url field with litterbox URL\n4. Renderer gets clean JSON with remote URLs and just renders\n\nThis is much cleaner and follows DDD principles better.Looking at your code and diagnosis, you've identified the core architectural problem perfectly. Let me break down what's happening and propose a clean solution.\n\n## Diagnosis of Current Issues\n\n### Google Slides Renderer Problems\n1. **Doing Too Much**: The renderer is trying to find images, generate diagrams, upload to litterbox, AND render slides - violating single responsibility principle\n2. **Inconsistent Asset Discovery**: It's guessing at file paths with patterns like `images/test_fix_workflow_slide{slide_num}_{diagram_type}.png` but these files may not exist\n3. **Missing Diagram Generation**: The JSON contains `diagram_content` but no actual image files are generated from this content\n4. **Upload Timing**: It only uploads to litterbox if it happens to find a local file, but diagram generation isn't integrated\n\n### Architecture Issues\nYour current flow is: **Content â†’ ContentAnalyzer â†’ JSON â†’ Direct Rendering**\n\nBut you need: **Content â†’ ContentAnalyzer â†’ Raw JSON â†’ AssetProcessor â†’ Processed JSON â†’ Renderer**\n\nThe missing AssetProcessor would:\n1. Scan JSON for `diagram_content` fields and generate actual diagram images\n2. Find and collect all local image references  \n3. Upload everything to litterbox\n4. Update JSON with clean remote URLs\n5. Pass processed JSON to renderers\n\n## Proposed Clean Architecture\n\nYou're absolutely right that we need an intermediate service. Here's the clean DDD approach:\n```\nViewing artifacts created via the Analysis Tool web feature preview isnâ€™t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isnâ€™t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isnâ€™t yet supported on mobile.\n```\n\n\n```\nViewing artifacts created via the Analysis Tool web feature preview isnâ€™t yet supported on mobile.\n```\n\n\n\n## Summary\n\nYour diagnosis was absolutely correct. The Google Slides renderer was trying to do too much - finding images, generating diagrams, uploading to litterbox, AND rendering slides. This violated the single responsibility principle and created a tangled mess.\n\n## The Clean Solution\n\n**New Architecture Flow:**\n```\nContent â†’ ContentAnalyzer â†’ Raw JSON â†’ AssetProcessor â†’ Processed JSON â†’ Renderer\n```\n\n### Key Changes:\n\n1. **New AssetProcessor Service** (`services/asset_processor.py`):\n   - Scans JSON for `diagram_content` and generates actual PNG files\n   - Finds all local image references\n   - Uploads everything to litterbox with retry logic\n   - Updates JSON with clean remote URLs\n   - Returns processed JSON ready for rendering\n\n2. **Updated Controller** (`core/controller.py`):\n   - Adds asset processing step between content analysis and rendering\n   - Clean separation of concerns\n\n3. **Cleaned Google Slides Renderer** (`renderers/google_slides_renderer.py`):\n   - Removed all asset processing logic\n   - Only handles rendering slides with pre-processed remote URLs\n   - Much simpler and focused\n\n4. **Enhanced Shared Helpers** (`shared/__init__.py`):\n   - Robust litterbox upload function with retry logic\n   - Used by AssetProcessor for consistent uploads\n\n### Why This Works:\n\n- **Single Responsibility**: Each service has one clear job\n- **Clean Dependencies**: Renderers just render, processors just process\n- **Reusable**: Both PPTX and Google Slides get the same processed assets\n- **Testable**: Each component can be tested independently\n- **Maintainable**: Changes to asset handling don't affect rendering logic\n\nThe key insight is that asset processing (diagram generation + uploads) is a separate domain concern from presentation rendering. By extracting it into its own service, we get cleaner code that's easier to debug and extend.\n\nThis approach is like separating a kitchen's prep work from cooking - the prep chef handles all the ingredient preparation, then hands clean, ready-to-use ingredients to the cook. Much cleaner than having the cook also chop vegetables while trying to manage the stove!",
      "created_at": "2025-05-22T15:22:16.882151Z",
      "sequence_order": 1,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-22T15:16:57.865133Z",
            "stop_timestamp": "2025-05-22T15:17:19.324567Z",
            "flags": null,
            "type": "thinking",
            "thinking": "Looking at the code and the user's diagnosis, I can see several issues:\n\n1. **Google Slides Renderer Image Issues:**\n   - The `_upload_slide_image_to_litterbox` method exists but is looking for images in various fields like `image_url`, `local_image_path`, etc.\n   - The method tries to find generated diagram files using patterns like `images/test_fix_workflow_slide{slide_num}_{diagram_type}.png`\n   - But there's no guarantee these files exist or were generated\n   - The `_upload_to_litterbox` method uses curl to upload to litterbox, but it's only called if a local image file is found\n\n2. **Architecture Issues:**\n   - The current flow is: Content â†’ Content Analyzer â†’ JSON â†’ Direct Rendering\n   - The Google Slides renderer is trying to do too much: find images, upload them, AND render slides\n   - There's no centralized asset management\n   - The diagram rendering logic is separate (in `diagrams/renderer.py`) but not integrated into the main flow\n\n3. **Missing Integration:**\n   - The `diagrams/renderer.py` has logic to render Mermaid diagrams from JSON, but it's not being called in the main controller flow\n   - The JSON might contain `diagram_content` and `diagram_type` but no actual image files are generated from this\n   - The asset manager that exists (`asset_manager.py`) is not being used in the main flow\n\n4. **DDD Structure Issues:**\n   - The renderer is handling asset processing, which should be a separate concern\n   - We need a clear separation between:\n     - Content Analysis (generates JSON with content/diagram specs)\n     - Asset Processing (generates diagrams, uploads assets, updates JSON with URLs)  \n     - Rendering (creates presentations using the processed JSON)\n\nThe user's diagnosis is spot on. We need an intermediate Asset Processing Service that:\n1. Takes the raw JSON from content analysis\n2. Generates any diagrams from `diagram_content` \n3. Uploads all assets (images, diagrams) to litterbox\n4. Updates the JSON with remote URLs\n5. Passes clean JSON to renderers\n\nLet me design a clean architecture:\n\n```\nContent â†’ ContentAnalyzer â†’ Raw JSON â†’ AssetProcessor â†’ Processed JSON â†’ Renderer\n```\n\nThe AssetProcessor would:\n1. Scan JSON for diagram_content fields\n2. Generate diagrams using the existing diagram renderer\n3. Scan for local image paths  \n4. Upload all assets to litterbox\n5. Update JSON with litterbox URLs\n6. Return processed JSON\n\nThis keeps each service focused on one responsibility.\n\nI'll need to create/modify:\n1. `services/asset_processor.py` - New service for asset processing\n2. Update `core/controller.py` - Add asset processing step\n3. Update `google_slides_renderer.py` - Remove asset processing logic, just use URLs\n4. Update `services/renderer_service.py` - Clean up responsibilities\n\nLet me think through the flow:\n\n1. User provides content\n2. ContentAnalyzer creates JSON with titles, content, diagram_content, layout info\n3. AssetProcessor takes this JSON and:\n   - For each slide with diagram_content: generates diagram image file\n   - For each slide with local image references: finds the files\n   - Uploads all found images to litterbox\n   - Updates the slide's image_url field with litterbox URL\n4. Renderer gets clean JSON with remote URLs and just renders\n\nThis is much cleaner and follows DDD principles better.",
            "summaries": [
              {
                "summary": "Thinking about diagnosing Google Slides renderer code complexity and image upload issues"
              },
              {
                "summary": "Diagnosing Google Slides renderer image upload method issues"
              },
              {
                "summary": "Architecting asset processing service for clean diagram generation"
              },
              {
                "summary": "Architected comprehensive asset processing service for rendering clarity"
              }
            ],
            "cut_off": false
          },
          {
            "start_timestamp": "2025-05-22T15:17:19.767969Z",
            "stop_timestamp": "2025-05-22T15:17:27.463121Z",
            "flags": null,
            "type": "text",
            "text": "Looking at your code and diagnosis, you've identified the core architectural problem perfectly. Let me break down what's happening and propose a clean solution.\n\n## Diagnosis of Current Issues\n\n### Google Slides Renderer Problems\n1. **Doing Too Much**: The renderer is trying to find images, generate diagrams, upload to litterbox, AND render slides - violating single responsibility principle\n2. **Inconsistent Asset Discovery**: It's guessing at file paths with patterns like `images/test_fix_workflow_slide{slide_num}_{diagram_type}.png` but these files may not exist\n3. **Missing Diagram Generation**: The JSON contains `diagram_content` but no actual image files are generated from this content\n4. **Upload Timing**: It only uploads to litterbox if it happens to find a local file, but diagram generation isn't integrated\n\n### Architecture Issues\nYour current flow is: **Content â†’ ContentAnalyzer â†’ JSON â†’ Direct Rendering**\n\nBut you need: **Content â†’ ContentAnalyzer â†’ Raw JSON â†’ AssetProcessor â†’ Processed JSON â†’ Renderer**\n\nThe missing AssetProcessor would:\n1. Scan JSON for `diagram_content` fields and generate actual diagram images\n2. Find and collect all local image references  \n3. Upload everything to litterbox\n4. Update JSON with clean remote URLs\n5. Pass processed JSON to renderers\n\n## Proposed Clean Architecture\n\nYou're absolutely right that we need an intermediate service. Here's the clean DDD approach:",
            "citations": []
          },
          {
            "start_timestamp": "2025-05-22T15:17:27.905056Z",
            "stop_timestamp": "2025-05-22T15:18:11.785331Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "asset_processor",
              "type": "application/vnd.ant.code",
              "title": "Asset Processor Service",
              "command": "create",
              "content": "# makeslides/services/asset_processor.py\n\nimport os\nimport logging\nimport subprocess\nimport tempfile\nimport hashlib\nfrom pathlib import Path\nfrom typing import Dict, Any, List, Optional, Tuple\nfrom ..diagrams.renderer import render_mermaid\nfrom ..shared import litterbox_upload\n\nlogger = logging.getLogger(__name__)\n\nclass AssetProcessor:\n    \"\"\"\n    Processes all assets (diagrams, images) for presentations.\n    \n    Responsibilities:\n    1. Generate diagrams from diagram_content\n    2. Upload all assets to litterbox\n    3. Update JSON with remote URLs\n    4. Return clean JSON for renderers\n    \"\"\"\n    \n    def __init__(self):\n        self.temp_dir = None\n        self.processed_assets = {}  # Cache to avoid duplicate uploads\n    \n    def process_presentation_assets(self, presentation_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Process all assets in a presentation and return updated JSON with remote URLs.\n        \n        Args:\n            presentation_data: Raw presentation JSON from content analyzer\n            \n        Returns:\n            Updated presentation data with remote asset URLs\n        \"\"\"\n        logger.info(\"Processing presentation assets...\")\n        \n        # Create temp directory for asset processing\n        self.temp_dir = Path(tempfile.mkdtemp(prefix=\"makeslides_assets_\"))\n        \n        try:\n            # Extract slides data  \n            slides = presentation_data.get(\"slides\", [])\n            if not slides:\n                logger.warning(\"No slides found in presentation data\")\n                return presentation_data\n            \n            # Process each slide's assets\n            for i, slide in enumerate(slides):\n                logger.debug(f\"Processing assets for slide {i+1}\")\n                self._process_slide_assets(slide, i+1)\n            \n            logger.info(f\"Successfully processed assets for {len(slides)} slides\")\n            return presentation_data\n            \n        except Exception as e:\n            logger.error(f\"Error processing presentation assets: {e}\")\n            raise\n        finally:\n            # Clean up temp directory\n            if self.temp_dir and self.temp_dir.exists():\n                import shutil\n                shutil.rmtree(self.temp_dir, ignore_errors=True)\n    \n    def _process_slide_assets(self, slide: Dict[str, Any], slide_number: int):\n        \"\"\"Process assets for a single slide.\"\"\"\n        \n        # 1. Generate diagram if needed\n        if slide.get(\"diagram_content\") and slide.get(\"diagram_type\"):\n            diagram_url = self._generate_and_upload_diagram(slide, slide_number)\n            if diagram_url:\n                slide[\"image_url\"] = diagram_url\n                logger.info(f\"Slide {slide_number}: Generated diagram and uploaded to {diagram_url}\")\n        \n        # 2. Process existing image references\n        elif slide.get(\"image_url\"):\n            image_url = slide[\"image_url\"]\n            \n            # If it's a local file, upload it\n            if not image_url.startswith((\"http://\", \"https://\")):\n                uploaded_url = self._upload_local_image(image_url)\n                if uploaded_url:\n                    slide[\"image_url\"] = uploaded_url\n                    logger.info(f\"Slide {slide_number}: Uploaded local image to {uploaded_url}\")\n        \n        # 3. Process other image fields\n        for field in [\"local_image_path\", \"local_diagram_path\"]:\n            if slide.get(field):\n                uploaded_url = self._upload_local_image(slide[field])\n                if uploaded_url:\n                    slide[\"image_url\"] = uploaded_url\n                    logger.info(f\"Slide {slide_number}: Uploaded {field} to {uploaded_url}\")\n                    break\n    \n    def _generate_and_upload_diagram(self, slide: Dict[str, Any], slide_number: int) -> Optional[str]:\n        \"\"\"Generate diagram from content and upload to litterbox.\"\"\"\n        try:\n            diagram_content = slide.get(\"diagram_content\")\n            diagram_type = slide.get(\"diagram_type\", \"flowchart\")\n            \n            if not diagram_content:\n                return None\n            \n            # Generate unique filename\n            content_hash = hashlib.md5(diagram_content.encode()).hexdigest()[:8]\n            filename = f\"slide_{slide_number}_{diagram_type}_{content_hash}\"\n            \n            # Check cache first\n            if content_hash in self.processed_assets:\n                return self.processed_assets[content_hash]\n            \n            # Generate diagram file\n            diagram_path = self._generate_diagram_file(\n                diagram_content, diagram_type, filename\n            )\n            \n            if diagram_path and diagram_path.exists():\n                # Upload to litterbox\n                uploaded_url = self._upload_to_litterbox(diagram_path)\n                if uploaded_url:\n                    self.processed_assets[content_hash] = uploaded_url\n                    return uploaded_url\n            \n            return None\n            \n        except Exception as e:\n            logger.error(f\"Error generating diagram for slide {slide_number}: {e}\")\n            return None\n    \n    def _generate_diagram_file(self, content: str, diagram_type: str, filename: str) -> Optional[Path]:\n        \"\"\"Generate diagram file using existing diagram renderer.\"\"\"\n        try:\n            # Create mermaid file\n            mmd_file = self.temp_dir / f\"{filename}.mmd\"\n            png_file = self.temp_dir / f\"{filename}.png\"\n            \n            # Write diagram content\n            with open(mmd_file, 'w', encoding='utf-8') as f:\n                f.write(content)\n            \n            # Use mermaid CLI to generate PNG\n            cmd = [\"mmdc\", \"-i\", str(mmd_file), \"-o\", str(png_file)]\n            \n            result = subprocess.run(\n                cmd, check=True, capture_output=True, text=True, timeout=30\n            )\n            \n            if png_file.exists() and png_file.stat().st_size > 0:\n                return png_file\n            else:\n                logger.warning(f\"Generated diagram file is empty: {png_file}\")\n                return None\n                \n        except subprocess.CalledProcessError as e:\n            logger.error(f\"Mermaid CLI error: {e.stderr}\")\n            return None\n        except Exception as e:\n            logger.error(f\"Error generating diagram file: {e}\")\n            return None\n    \n    def _upload_local_image(self, image_path: str) -> Optional[str]:\n        \"\"\"Upload a local image file to litterbox.\"\"\"\n        try:\n            path_obj = Path(image_path)\n            \n            # Try to find the file\n            if not path_obj.exists():\n                # Try relative to current directory\n                path_obj = Path.cwd() / image_path\n                if not path_obj.exists():\n                    logger.warning(f\"Image file not found: {image_path}\")\n                    return None\n            \n            # Check if already uploaded\n            file_hash = self._get_file_hash(path_obj)\n            if file_hash in self.processed_assets:\n                return self.processed_assets[file_hash]\n            \n            # Upload to litterbox\n            uploaded_url = self._upload_to_litterbox(path_obj)\n            if uploaded_url:\n                self.processed_assets[file_hash] = uploaded_url\n            \n            return uploaded_url\n            \n        except Exception as e:\n            logger.error(f\"Error uploading local image {image_path}: {e}\")\n            return None\n    \n    def _upload_to_litterbox(self, file_path: Path, max_retries: int = 3) -> Optional[str]:\n        \"\"\"Upload file to litterbox with retry logic.\"\"\"\n        for attempt in range(max_retries):\n            try:\n                logger.debug(f\"Uploading {file_path.name} to litterbox (attempt {attempt+1})\")\n                \n                # Use the shared litterbox upload function\n                url = litterbox_upload(file_path, expiry=\"24h\")\n                \n                if url and url.startswith(\"https://litter.catbox.moe/\"):\n                    logger.info(f\"âœ… Uploaded {file_path.name} -> {url}\")\n                    return url\n                else:\n                    logger.warning(f\"Invalid litterbox response: {url}\")\n                    \n            except Exception as e:\n                logger.warning(f\"Upload attempt {attempt+1} failed: {e}\")\n                if attempt < max_retries - 1:\n                    import time\n                    time.sleep(2 ** attempt)  # Exponential backoff\n        \n        logger.error(f\"Failed to upload {file_path} after {max_retries} attempts\")\n        return None\n    \n    def _get_file_hash(self, file_path: Path) -> str:\n        \"\"\"Get hash of file for caching purposes.\"\"\"\n        try:\n            with open(file_path, 'rb') as f:\n                return hashlib.md5(f.read()).hexdigest()[:8]\n        except Exception:\n            # Fallback to path-based hash\n            return hashlib.md5(str(file_path).encode()).hexdigest()[:8]",
              "language": "python",
              "version_uuid": "dac4fc85-ef2f-471e-b200-881faaed75c0"
            },
            "message": "artifacts",
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "aef31343-53ef-42d1-a08c-7ae4230fb429"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-05-22T15:18:25.791740Z",
            "stop_timestamp": "2025-05-22T15:19:03.484608Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "updated_controller",
              "type": "application/vnd.ant.code",
              "title": "Updated Controller with Asset Processing",
              "command": "create",
              "content": "# makeslides/core/controller.py\n\nimport os\nimport logging\nimport json\nimport yaml\nfrom typing import Dict, Any, Optional\nfrom pathlib import Path\nfrom ..renderers.factory import create_renderer\nfrom ..services.content_analyzer import ClaudeContentAnalyzer\nfrom ..services.asset_processor import AssetProcessor\n\nlogger = logging.getLogger(__name__)\n\nclass SlidesController:\n    \"\"\"Main controller for the slide generation process\"\"\"\n    \n    def __init__(self, config: Optional[Dict[str, Any]] = None, use_extended_thinking: bool = False):\n        \"\"\"Initialize the slides controller\n        \n        Args:\n            config: Configuration options\n            use_extended_thinking: Whether to use Claude's extended thinking\n        \"\"\"\n        self.config = config or self._load_default_config()\n        self.api_key = self.config.get(\"api_key\") or os.environ.get(\"ANTHROPIC_API_KEY\")\n        \n        if not self.api_key:\n            raise ValueError(\"Anthropic API key not provided and ANTHROPIC_API_KEY environment variable not set\")\n        \n        # Initialize services\n        self.content_analyzer = ClaudeContentAnalyzer(api_key=self.api_key, use_extended_thinking=use_extended_thinking)\n        self.asset_processor = AssetProcessor()\n    \n    def _load_default_config(self) -> Dict[str, Any]:\n        \"\"\"Load configuration from config.yaml if available\"\"\"\n        config_path = Path(\"config.yaml\")\n        if config_path.exists():\n            try:\n                with open(config_path, 'r') as f:\n                    config = yaml.safe_load(f)\n                return config\n            except Exception as e:\n                logger.warning(f\"Error loading config.yaml: {e}\")\n        \n        # Default configuration\n        return {\n            \"output\": {\n                \"default_format\": \"google_slides\",\n                \"formats\": {\n                    \"google_slides\": {\n                        \"credentials_path\": \"~/.makeslides/credentials.json\",\n                        \"token_path\": \"~/.makeslides/token.json\"\n                    },\n                    \"pptx\": {\n                        \"template_path\": None,\n                        \"theme\": \"default\"\n                    }\n                }\n            }\n        }\n    \n    def create_presentation(self, content: str, output_format: Optional[str] = None, \n                           output_path: Optional[str] = None, theme: Optional[Any] = None,\n                           template_path: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Create a presentation from content\n        \n        Args:\n            content: Input content (markdown, text, etc.)\n            output_format: Output format (\"pptx\" or \"google_slides\")\n            output_path: Path to save output\n            theme: Theme configuration\n            template_path: Path to template file\n            \n        Returns:\n            Result information including output path, success status, etc.\n        \"\"\"\n        try:\n            # 1. Determine output format\n            if not output_format:\n                output_format = self.config.get(\"output\", {}).get(\"default_format\", \"google_slides\")\n            \n            print(f\"Creating {output_format} presentation...\")\n            \n            # 2. Analyze content and create presentation structure\n            logger.info(\"Step 1: Analyzing content and generating presentation structure...\")\n            presentation = self.content_analyzer.analyze(content)\n            \n            if not presentation:\n                return {\"success\": False, \"error\": \"Failed to analyze content\"}\n            \n            # 3. Convert presentation to dictionary for processing\n            presentation_dict = self._presentation_to_dict(presentation)\n            \n            # 4. NEW: Process all assets (diagrams, images)\n            logger.info(\"Step 2: Processing assets (diagrams and images)...\")\n            presentation_dict = self.asset_processor.process_presentation_assets(presentation_dict)\n            \n            # 5. Determine output path if not provided\n            if not output_path:\n                if output_format.lower() == \"pptx\":\n                    output_path = \"presentation.pptx\"\n                else:\n                    output_path = \"presentation_url.txt\"  # Will contain URL for Google Slides\n            \n            # 6. Get format-specific configuration\n            format_config = self.config.get(\"output\", {}).get(\"formats\", {}).get(output_format, {})\n            \n            # 7. Create renderer for requested format\n            renderer = create_renderer(\n                output_format=output_format,\n                template_path=template_path or format_config.get(\"template_path\"),\n                theme=theme or format_config.get(\"theme\"),\n                credentials_path=format_config.get(\"credentials_path\"),\n                token_path=format_config.get(\"token_path\"),\n                debug=True\n            )\n            \n            # 8. Render presentation with processed assets\n            logger.info(f\"Step 3: Rendering presentation to {output_format}...\")\n            result = renderer.render(presentation_dict, output_path)\n            \n            if not result:\n                return {\"success\": False, \"error\": f\"Failed to render {output_format} presentation\"}\n            \n            # 9. Save intermediate JSON with processed assets\n            if output_format == \"pptx\" and (\".json\" not in output_path):\n                json_path = output_path.replace(\".pptx\", \".json\")\n                with open(json_path, \"w\", encoding=\"utf-8\") as f:\n                    json.dump(presentation_dict, f, indent=2, ensure_ascii=False)\n            else:\n                json_path = output_path  # fallback if already .json\n                \n            # 10. Return results\n            return {\n                \"success\": True,\n                \"output_path\": output_path,\n                \"output_format\": output_format,\n                \"slide_count\": len(presentation.slides),\n                \"presentation_title\": presentation.title,\n                \"presentation_url\": result if isinstance(result, str) else None,\n                \"intermediate_json_path\": json_path,\n                \"presentation_json\": presentation_dict  # Include processed JSON\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error creating presentation: {e}\")\n            return {\"success\": False, \"error\": str(e)}\n    \n    def _presentation_to_dict(self, presentation) -> Dict[str, Any]:\n        \"\"\"Convert a Presentation object to a dictionary\"\"\"\n        presentation_dict = None\n        if hasattr(presentation, \"dict\"):\n            presentation_dict = presentation.dict()\n        elif hasattr(presentation, \"model_dump\"):\n            presentation_dict = presentation.model_dump()\n        else:\n            # Manual conversion\n            presentation_dict = {\n                \"title\": presentation.title,\n                \"author\": getattr(presentation, 'author', None),\n                \"slides\": []\n            }\n            \n            for slide in presentation.slides:\n                slide_dict = {\n                    \"title\": slide.title,\n                    \"content\": slide.content,\n                    \"layout\": slide.layout,\n                    \"notes\": slide.notes,\n                    \"facilitator_notes\": getattr(slide, 'facilitator_notes', slide.notes)\n                }\n                # Add any extra attributes\n                for attr in dir(slide):\n                    if not attr.startswith('_') and attr not in slide_dict:\n                        value = getattr(slide, attr)\n                        if not callable(value):\n                            slide_dict[attr] = value\n                \n                presentation_dict[\"slides\"].append(slide_dict)\n        \n        return presentation_dict",
              "language": "python",
              "version_uuid": "48d940ad-fae0-4d56-b1a8-d5cb636b19eb"
            },
            "message": "artifacts",
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "95133966-5e27-4f8b-b070-d6e77ac22182"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-05-22T15:19:09.636413Z",
            "stop_timestamp": "2025-05-22T15:21:27.833906Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "clean_google_slides_renderer",
              "type": "application/vnd.ant.code",
              "title": "Cleaned Google Slides Renderer",
              "command": "create",
              "content": "import os\nimport json\nimport logging\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, List, Tuple\nfrom googleapiclient.discovery import build\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom google.auth.transport.requests import Request\nfrom ..domain.models import SlideTheme, ThemePresets\n\nlogger = logging.getLogger(__name__)\n\nSCOPES = ['https://www.googleapis.com/auth/presentations',\n          'https://www.googleapis.com/auth/drive']\n\nclass GoogleSlidesRenderer:\n    \"\"\"\n    Clean Google Slides renderer focused only on rendering.\n    \n    Assets (images, diagrams) should already be processed and contain remote URLs.\n    This renderer just creates slides and inserts content.\n    \"\"\"\n    \n    def __init__(self, credentials_path: Optional[str] = None, token_path: Optional[str] = None,\n                 theme: Optional[Any] = None, debug: bool = False):\n        self.credentials_path = credentials_path or os.path.join(\n            os.path.expanduser(\"~\"), \".makeslides\", \"credentials.json\"\n        )\n        self.token_path = token_path or os.path.join(\n            os.path.expanduser(\"~\"), \".makeslides\", \"token.json\"\n        )\n        self.debug = debug\n\n        os.makedirs(os.path.dirname(self.token_path), exist_ok=True)\n\n        if isinstance(theme, SlideTheme):\n            self.theme = theme\n        elif isinstance(theme, dict):\n            self.theme = SlideTheme.from_dict(theme)\n        else:\n            self.theme = ThemePresets.default()\n\n        self.slides_service = None\n        self.drive_service = None\n        self.presentation_id = None\n\n    def _initialize_services(self) -> bool:\n        \"\"\"Initialize Google API services.\"\"\"\n        try:\n            creds = None\n            if os.path.exists(self.token_path):\n                creds = Credentials.from_authorized_user_info(\n                    json.loads(Path(self.token_path).read_text()), SCOPES\n                )\n\n            if not creds or not creds.valid:\n                if creds and creds.expired and creds.refresh_token:\n                    creds.refresh(Request())\n                else:\n                    if not os.path.exists(self.credentials_path):\n                        logger.error(f\"Credentials file not found: {self.credentials_path}\")\n                        return False\n                    flow = InstalledAppFlow.from_client_secrets_file(\n                        self.credentials_path, SCOPES\n                    )\n                    creds = flow.run_local_server(port=0)\n                with open(self.token_path, 'w') as token:\n                    token.write(creds.to_json())\n\n            self.slides_service = build('slides', 'v1', credentials=creds)\n            self.drive_service = build('drive', 'v3', credentials=creds)\n            return True\n        except Exception as e:\n            logger.error(f\"Error initializing Google services: {e}\")\n            return False\n\n    def render(self, presentation_data: Dict[str, Any], output_path: Optional[str] = None) -> Optional[str]:\n        \"\"\"\n        Render presentation to Google Slides.\n        \n        Args:\n            presentation_data: Presentation data with processed assets (remote URLs)\n            output_path: Optional path to save URL\n            \n        Returns:\n            Google Slides URL or None if failed\n        \"\"\"\n        if not self._initialize_services():\n            return None\n            \n        try:\n            # Create presentation\n            title = presentation_data.get(\"title\", \"Generated Presentation\")\n            presentation = self.slides_service.presentations().create(\n                body={\"title\": title}\n            ).execute()\n\n            self.presentation_id = presentation.get('presentationId')\n            logger.info(f\"Created new presentation with ID: {self.presentation_id}\")\n\n            # Get slides data\n            slides_data = presentation_data.get(\"slides\", [])\n            if not slides_data and isinstance(presentation_data, list):\n                slides_data = presentation_data\n\n            # Delete default slide\n            self._delete_default_slide()\n\n            # Create slides\n            for i, slide_data in enumerate(slides_data):\n                try:\n                    slide_title = slide_data.get('title', f'Slide {i+1}')\n                    layout = slide_data.get('layout', 'TITLE_AND_CONTENT')\n                    print(f\"      {i+1:2d}. {slide_title[:40]}... ({layout})\")\n                    \n                    self._create_slide_with_layout(slide_data, i+1)\n                    \n                except Exception as e:\n                    logger.error(f\"Error creating slide {i+1}: {e}\")\n                    self._create_fallback_slide(slide_data, i+1)\n\n            # Return presentation URL\n            presentation_url = f\"https://docs.google.com/presentation/d/{self.presentation_id}/edit\"\n            \n            if output_path:\n                with open(output_path, 'w') as f:\n                    f.write(presentation_url)\n                    \n            print(f\"\\nðŸŽ‰ SUCCESS! Your presentation is available at:\\n   {presentation_url}\")\n            return presentation_url\n            \n        except Exception as e:\n            logger.error(f\"Error creating Google Slides presentation: {e}\")\n            if self.debug:\n                import traceback\n                logger.error(f\"Full traceback: {traceback.format_exc()}\")\n            return None\n\n    def _delete_default_slide(self):\n        \"\"\"Delete the default slide that comes with new presentations.\"\"\"\n        try:\n            presentation = self.slides_service.presentations().get(\n                presentationId=self.presentation_id\n            ).execute()\n            \n            default_slide_ids = [slide.get('objectId') for slide in presentation.get('slides', [])]\n            \n            if default_slide_ids:\n                requests = []\n                for slide_id in default_slide_ids:\n                    requests.append({'deleteObject': {'objectId': slide_id}})\n                \n                self.slides_service.presentations().batchUpdate(\n                    presentationId=self.presentation_id,\n                    body={'requests': requests}\n                ).execute()\n        except Exception as e:\n            logger.warning(f\"Could not delete default slide: {e}\")\n\n    def _create_slide_with_layout(self, slide_data: Dict[str, Any], slide_number: int):\n        \"\"\"Create slide with appropriate layout.\"\"\"\n        layout = slide_data.get(\"layout\", \"TITLE_AND_CONTENT\")\n        \n        # Route to appropriate slide creator based on layout\n        if layout in [\"TWO_COLUMNS\", \"COMPARISON\"]:\n            self._create_two_column_slide(slide_data, slide_number)\n        elif layout == \"BIG_NUMBER\":\n            self._create_big_number_slide(slide_data, slide_number)\n        elif layout == \"QUOTE\":\n            self._create_quote_slide(slide_data, slide_number)\n        elif layout == \"TITLE_SLIDE\":\n            self._create_title_slide(slide_data, slide_number)\n        elif layout == \"IMAGE_WITH_CAPTION\":\n            self._create_image_slide(slide_data, slide_number)\n        else:\n            # Default: standard content slide\n            self._create_standard_slide(slide_data, slide_number)\n\n    def _create_two_column_slide(self, slide_data: Dict[str, Any], slide_number: int):\n        \"\"\"Create two-column slide.\"\"\"\n        slide_id = f\"slide_{slide_number}\"\n        \n        # Create slide with two-column layout\n        self._execute_requests([{\n            'createSlide': {\n                'objectId': slide_id,\n                'slideLayoutReference': {\n                    'predefinedLayout': \"TITLE_AND_TWO_COLUMNS\"\n                }\n            }\n        }])\n\n        # Get slide structure\n        slide = self._get_slide(slide_id)\n        placeholder_map = self._map_placeholders(slide)\n        \n        print(f\"         ðŸ“Š Found placeholders: {list(placeholder_map.keys())}\")\n\n        # Prepare content\n        title = slide_data.get(\"title\", \"\")\n        content = slide_data.get(\"content\", \"\")\n        left_content, right_content = self._split_content_for_columns(content)\n        \n        print(f\"         ðŸ“Š Left: {left_content[:30] if left_content else 'empty'}... | Right: {right_content[:30] if right_content else 'empty'}...\")\n\n        # Build requests\n        requests = []\n\n        # Add title\n        if title and \"TITLE\" in placeholder_map:\n            requests.extend(self._create_text_requests(placeholder_map[\"TITLE\"], title, \"title\"))\n\n        # Add left column\n        if left_content and \"BODY_0\" in placeholder_map:\n            requests.extend(self._create_text_requests(placeholder_map[\"BODY_0\"], left_content, \"body\"))\n        elif left_content and \"BODY\" in placeholder_map:\n            requests.extend(self._create_text_requests(placeholder_map[\"BODY\"], left_content, \"body\"))\n\n        # Add right column\n        if right_content and \"BODY_1\" in placeholder_map:\n            requests.extend(self._create_text_requests(placeholder_map[\"BODY_1\"], right_content, \"body\"))\n        elif right_content:\n            # Find second body placeholder\n            body_keys = [k for k in placeholder_map.keys() if k.startswith(\"BODY\")]\n            if len(body_keys) > 1:\n                requests.extend(self._create_text_requests(placeholder_map[body_keys[1]], right_content, \"body\"))\n\n        # Add image if present (processed assets should have remote URLs)\n        if slide_data.get(\"image_url\"):\n            requests.append(self._create_image_request(slide_id, slide_data[\"image_url\"]))\n\n        # Execute all requests\n        if requests:\n            self._execute_requests(requests)\n\n        # Add speaker notes\n        self._add_speaker_notes(slide_data, slide_id)\n\n    def _create_standard_slide(self, slide_data: Dict[str, Any], slide_number: int):\n        \"\"\"Create standard content slide.\"\"\"\n        slide_id = f\"slide_{slide_number}\"\n        \n        # Create slide\n        self._execute_requests([{\n            'createSlide': {\n                'objectId': slide_id,\n                'slideLayoutReference': {\n                    'predefinedLayout': \"TITLE_AND_BODY\"\n                }\n            }\n        }])\n\n        slide = self._get_slide(slide_id)\n        placeholder_map = self._map_placeholders(slide)\n        requests = []\n\n        # Add title and content\n        title = slide_data.get(\"title\", \"\")\n        if title and \"TITLE\" in placeholder_map:\n            requests.extend(self._create_text_requests(placeholder_map[\"TITLE\"], title, \"title\"))\n\n        content = slide_data.get(\"content\", \"\")\n        if content and \"BODY\" in placeholder_map:\n            requests.extend(self._create_text_requests(placeholder_map[\"BODY\"], content, \"body\"))\n\n        # Add image if present (should already be remote URL from asset processor)\n        if slide_data.get(\"image_url\"):\n            requests.append(self._create_image_request(slide_id, slide_data[\"image_url\"]))\n\n        if requests:\n            self._execute_requests(requests)\n\n        self._add_speaker_notes(slide_data, slide_id)\n\n    def _create_big_number_slide(self, slide_data: Dict[str, Any], slide_number: int):\n        \"\"\"Create big number slide.\"\"\"\n        slide_id = f\"slide_{slide_number}\"\n        \n        self._execute_requests([{\n            'createSlide': {\n                'objectId': slide_id,\n                'slideLayoutReference': {\n                    'predefinedLayout': \"SECTION_HEADER\"\n                }\n            }\n        }])\n\n        slide = self._get_slide(slide_id)\n        placeholder_map = self._map_placeholders(slide)\n        requests = []\n\n        # Big number as title\n        big_number = slide_data.get(\"title\", \"100%\")\n        if big_number and \"TITLE\" in placeholder_map:\n            requests.extend(self._create_text_requests(placeholder_map[\"TITLE\"], big_number, \"big_number\"))\n\n        # Description as subtitle\n        description = slide_data.get(\"content\", \"\")\n        if description and \"SUBTITLE\" in placeholder_map:\n            requests.extend(self._create_text_requests(placeholder_map[\"SUBTITLE\"], description, \"body\"))\n\n        if slide_data.get(\"image_url\"):\n            requests.append(self._create_image_request(slide_id, slide_data[\"image_url\"]))\n\n        if requests:\n            self._execute_requests(requests)\n\n        self._add_speaker_notes(slide_data, slide_id)\n\n    def _create_quote_slide(self, slide_data: Dict[str, Any], slide_number: int):\n        \"\"\"Create quote slide.\"\"\"\n        slide_id = f\"slide_{slide_number}\"\n        \n        self._execute_requests([{\n            'createSlide': {\n                'objectId': slide_id,\n                'slideLayoutReference': {\n                    'predefinedLayout': \"TITLE_AND_BODY\"\n                }\n            }\n        }])\n\n        slide = self._get_slide(slide_id)\n        placeholder_map = self._map_placeholders(slide)\n        requests = []\n\n        # Parse quote content\n        content = slide_data.get(\"content\", \"\")\n        quote_text, attribution = self._parse_quote_content(content)\n\n        # Add quote as body text\n        if quote_text and \"BODY\" in placeholder_map:\n            formatted_quote = f'\"{quote_text}\"\\n\\n{attribution}' if attribution else f'\"{quote_text}\"'\n            requests.extend(self._create_text_requests(placeholder_map[\"BODY\"], formatted_quote, \"quote\"))\n\n        if requests:\n            self._execute_requests(requests)\n\n        self._add_speaker_notes(slide_data, slide_id)\n\n    def _create_title_slide(self, slide_data: Dict[str, Any], slide_number: int):\n        \"\"\"Create title slide.\"\"\"\n        slide_id = f\"slide_{slide_number}\"\n        \n        self._execute_requests([{\n            'createSlide': {\n                'objectId': slide_id,\n                'slideLayoutReference': {\n                    'predefinedLayout': \"TITLE\"\n                }\n            }\n        }])\n\n        slide = self._get_slide(slide_id)\n        placeholder_map = self._map_placeholders(slide)\n        requests = []\n\n        title = slide_data.get(\"title\", \"\")\n        if title and \"TITLE\" in placeholder_map:\n            requests.extend(self._create_text_requests(placeholder_map[\"TITLE\"], title, \"title\"))\n\n        subtitle = slide_data.get(\"content\", \"\")\n        if subtitle and \"SUBTITLE\" in placeholder_map:\n            requests.extend(self._create_text_requests(placeholder_map[\"SUBTITLE\"], subtitle, \"subtitle\"))\n\n        if slide_data.get(\"image_url\"):\n            requests.append(self._create_image_request(slide_id, slide_data[\"image_url\"]))\n\n        if requests:\n            self._execute_requests(requests)\n\n        self._add_speaker_notes(slide_data, slide_id)\n\n    def _create_image_slide(self, slide_data: Dict[str, Any], slide_number: int):\n        \"\"\"Create image slide with caption.\"\"\"\n        slide_id = f\"slide_{slide_number}\"\n        \n        self._execute_requests([{\n            'createSlide': {\n                'objectId': slide_id,\n                'slideLayoutReference': {\n                    'predefinedLayout': \"CAPTION_ONLY\"\n                }\n            }\n        }])\n\n        slide = self._get_slide(slide_id)\n        placeholder_map = self._map_placeholders(slide)\n        requests = []\n\n        # Add title\n        title = slide_data.get(\"title\", \"\")\n        if title and \"TITLE\" in placeholder_map:\n            requests.extend(self._create_text_requests(placeholder_map[\"TITLE\"], title, \"title\"))\n\n        # Add caption\n        caption = slide_data.get(\"content\", \"\")\n        if caption and \"BODY\" in placeholder_map:\n            requests.extend(self._create_text_requests(placeholder_map[\"BODY\"], caption, \"body\"))\n\n        # Add image (should be remote URL from asset processor)\n        if slide_data.get(\"image_url\"):\n            requests.append(self._create_image_request(slide_id, slide_data[\"image_url\"]))\n\n        if requests:\n            self._execute_requests(requests)\n\n        self._add_speaker_notes(slide_data, slide_id)\n\n    def _create_fallback_slide(self, slide_data: Dict[str, Any], slide_number: int):\n        \"\"\"Create fallback slide when main creation fails.\"\"\"\n        try:\n            slide_id = f\"slide_{slide_number}\"\n            \n            self._execute_requests([{\n                'createSlide': {\n                    'objectId': slide_id,\n                    'slideLayoutReference': {\n                        'predefinedLayout': \"TITLE_AND_BODY\"\n                    }\n                }\n            }])\n\n            slide = self._get_slide(slide_id)\n            placeholder_map = self._map_placeholders(slide)\n            requests = []\n\n            title = slide_data.get(\"title\", f\"Slide {slide_number}\")\n            if \"TITLE\" in placeholder_map:\n                requests.extend(self._create_text_requests(placeholder_map[\"TITLE\"], title, \"title\"))\n\n            content = slide_data.get(\"content\", \"Content could not be formatted properly.\")\n            if \"BODY\" in placeholder_map:\n                requests.extend(self._create_text_requests(placeholder_map[\"BODY\"], content[:300], \"body\"))\n\n            if requests:\n                self._execute_requests(requests)\n\n            print(f\"      âš ï¸ Created fallback slide {slide_number}\")\n        except Exception as e:\n            logger.error(f\"Even fallback slide creation failed: {e}\")\n\n    # Helper methods\n\n    def _execute_requests(self, requests: List[Dict[str, Any]]):\n        \"\"\"Execute batch of requests.\"\"\"\n        if requests:\n            self.slides_service.presentations().batchUpdate(\n                presentationId=self.presentation_id,\n                body={'requests': requests}\n            ).execute()\n\n    def _get_slide(self, slide_id: str) -> Dict[str, Any]:\n        \"\"\"Get slide by ID.\"\"\"\n        return self.slides_service.presentations().pages().get(\n            presentationId=self.presentation_id,\n            pageObjectId=slide_id\n        ).execute()\n\n    def _map_placeholders(self, slide) -> Dict[str, str]:\n        \"\"\"Map placeholders correctly, handling multiple BODY placeholders.\"\"\"\n        placeholder_map = {}\n        body_count = 0\n        \n        for element in slide.get(\"pageElements\", []):\n            shape = element.get(\"shape\", {})\n            placeholder = shape.get(\"placeholder\")\n            if placeholder:\n                placeholder_type = placeholder.get(\"type\")\n                object_id = element[\"objectId\"]\n                \n                if placeholder_type == \"BODY\":\n                    # Handle multiple body placeholders for two-column layouts\n                    if body_count == 0:\n                        placeholder_map[\"BODY\"] = object_id\n                        placeholder_map[\"BODY_0\"] = object_id\n                    else:\n                        placeholder_map[f\"BODY_{body_count}\"] = object_id\n                    body_count += 1\n                else:\n                    placeholder_map[placeholder_type] = object_id\n        \n        return placeholder_map\n\n    def _split_content_for_columns(self, content: str) -> Tuple[str, str]:\n        \"\"\"Split content into two columns.\"\"\"\n        if not content:\n            return \"\", \"\"\n        \n        # If content contains |, split on it\n        if '|' in content:\n            parts = content.split('|', 1)\n            left = parts[0].strip()\n            right = parts[1].strip() if len(parts) > 1 else \"\"\n            return left, right\n        \n        # Try to split content intelligently\n        lines = [line.strip() for line in content.split('\\n') if line.strip()]\n        \n        if len(lines) <= 2:\n            return content, \"\"\n        \n        # Split at roughly half, preferring bullet point boundaries\n        midpoint = len(lines) // 2\n        \n        # Look for good split point (bullet points, headings)\n        for i in range(max(1, midpoint-2), min(len(lines), midpoint+3)):\n            if i < len(lines) and lines[i].startswith(('â€¢ ', '- ', '* ', '## ', '### ')):\n                return '\\n'.join(lines[:i]), '\\n'.join(lines[i:])\n        \n        # Default split\n        return '\\n'.join(lines[:midpoint]), '\\n'.join(lines[midpoint:])\n\n    def _create_image_request(self, slide_id: str, image_url: str) -> Dict[str, Any]:\n        \"\"\"Create image insertion request for remote URL.\"\"\"\n        return {\n            'createImage': {\n                'objectId': f\"image_{slide_id}\",\n                'url': image_url,\n                'elementProperties': {\n                    'pageObjectId': slide_id,\n                    'size': {\n                        'height': {'magnitude': 300, 'unit': 'PT'},\n                        'width': {'magnitude': 400, 'unit': 'PT'}\n                    },\n                    'transform': {\n                        'scaleX': 1,\n                        'scaleY': 1,\n                        'translateX': 300,\n                        'translateY': 150,\n                        'unit': 'PT'\n                    }\n                }\n            }\n        }\n\n    def _create_text_requests(self, object_id: str, text: str, style_type: str) -> List[Dict[str, Any]]:\n        \"\"\"Create text insertion and styling requests.\"\"\"\n        requests = []\n        \n        # Insert text\n        requests.append({\n            'insertText': {\n                'objectId': object_id,\n                'insertionIndex': 0,\n                'text': text\n            }\n        })\n\n        # Apply styling based on type\n        if style_type == \"title\":\n            requests.append(self._create_title_style_request(object_id))\n        elif style_type == \"subtitle\":\n            requests.append(self._create_subtitle_style_request(object_id))\n        elif style_type == \"big_number\":\n            requests.append(self._create_big_number_style_request(object_id))\n        elif style_type == \"quote\":\n            requests.append(self._create_quote_style_request(object_id))\n        else:  # body\n            requests.append(self._create_body_style_request(object_id))\n            \n            # Add bullet formatting if content has bullets\n            if self._has_bullets(text):\n                requests.append({\n                    'createParagraphBullets': {\n                        'objectId': object_id,\n                        'textRange': {'type': 'ALL'},\n                        'bulletPreset': 'BULLET_DISC_CIRCLE_SQUARE'\n                    }\n                })\n\n        return requests\n\n    def _has_bullets(self, text: str) -> bool:\n        \"\"\"Check if text contains bullet points.\"\"\"\n        lines = text.split('\\n')\n        return any(line.strip().startswith(('â€¢ ', '- ', '* ')) for line in lines)\n\n    def _create_title_style_request(self, object_id: str) -> Dict[str, Any]:\n        \"\"\"Create title styling request.\"\"\"\n        return {\n            'updateTextStyle': {\n                'objectId': object_id,\n                'textRange': {'type': 'ALL'},\n                'fields': 'fontFamily,fontSize,bold,foregroundColor',\n                'style': {\n                    'fontFamily': self.theme.text_styles.title.family,\n                    'fontSize': {'magnitude': self.theme.text_styles.title.size, 'unit': 'PT'},\n                    'bold': self.theme.text_styles.title.bold,\n                    'foregroundColor': {\n                        'opaqueColor': {\n                            'rgbColor': self.theme.colors.dark1.to_rgb_dict()\n                        }\n                    }\n                }\n            }\n        }\n\n    def _create_subtitle_style_request(self, object_id: str) -> Dict[str, Any]:\n        \"\"\"Create subtitle styling request.\"\"\"\n        return {\n            'updateTextStyle': {\n                'objectId': object_id,\n                'textRange': {'type': 'ALL'},\n                'fields': 'fontFamily,fontSize,foregroundColor',\n                'style': {\n                    'fontFamily': self.theme.text_styles.subtitle.family,\n                    'fontSize': {'magnitude': self.theme.text_styles.subtitle.size, 'unit': 'PT'},\n                    'foregroundColor': {\n                        'opaqueColor': {\n                            'rgbColor': self.theme.colors.dark1.to_rgb_dict()\n                        }\n                    }\n                }\n            }\n        }\n\n    def _create_big_number_style_request(self, object_id: str) -> Dict[str, Any]:\n        \"\"\"Create big number styling request.\"\"\"\n        return {\n            'updateTextStyle': {\n                'objectId': object_id,\n                'textRange': {'type': 'ALL'},\n                'fields': 'fontFamily,fontSize,bold,foregroundColor',\n                'style': {\n                    'fontFamily': self.theme.text_styles.title.family,\n                    'fontSize': {'magnitude': 64, 'unit': 'PT'},\n                    'bold': True,\n                    'foregroundColor': {\n                        'opaqueColor': {\n                            'rgbColor': self.theme.colors.accent1.to_rgb_dict()\n                        }\n                    }\n                }\n            }\n        }\n\n    def _create_quote_style_request(self, object_id: str) -> Dict[str, Any]:\n        \"\"\"Create quote styling request.\"\"\"\n        return {\n            'updateTextStyle': {\n                'objectId': object_id,\n                'textRange': {'type': 'ALL'},\n                'fields': 'fontFamily,fontSize,italic,foregroundColor',\n                'style': {\n                    'fontFamily': self.theme.text_styles.body.family,\n                    'fontSize': {'magnitude': 24, 'unit': 'PT'},\n                    'italic': True,\n                    'foregroundColor': {\n                        'opaqueColor': {\n                            'rgbColor': self.theme.colors.accent1.to_rgb_dict()\n                        }\n                    }\n                }\n            }\n        }\n\n    def _create_body_style_request(self, object_id: str) -> Dict[str, Any]:\n        \"\"\"Create body text styling request.\"\"\"\n        return {\n            'updateTextStyle': {\n                'objectId': object_id,\n                'textRange': {'type': 'ALL'},\n                'fields': 'fontFamily,fontSize,foregroundColor',\n                'style': {\n                    'fontFamily': self.theme.text_styles.body.family,\n                    'fontSize': {'magnitude': self.theme.text_styles.body.size, 'unit': 'PT'},\n                    'foregroundColor': {\n                        'opaqueColor': {\n                            'rgbColor': self.theme.colors.dark1.to_rgb_dict()\n                        }\n                    }\n                }\n            }\n        }\n\n    def _parse_quote_content(self, content: str) -> Tuple[str, str]:\n        \"\"\"Parse quote content to separate quote and attribution.\"\"\"\n        lines = [line.strip() for line in content.split('\\n') if line.strip()]\n        \n        quote_lines = []\n        attribution = \"\"\n        \n        for line in lines:\n            if line.startswith('â€”') or line.startswith('- '):\n                attribution = line\n            else:\n                quote_lines.append(line.strip('\"'))\n        \n        return ' '.join(quote_lines), attribution\n\n    def _add_speaker_notes(self, slide_data: Dict[str, Any], slide_id: str) -> None:\n        \"\"\"Add speaker notes to a slide.\"\"\"\n        # Check for various note fields\n        notes_text = \"\"\n        \n        # Check common note field names\n        for field in [\"notes\", \"facilitator_notes\", \"speaker_notes\"]:\n            if field in slide_data and slide_data[field]:\n                notes_text = slide_data[field]\n                break\n        \n        if not notes_text:\n            return\n            \n        try:\n            # Get the slide to find its notes slide\n            slide = self._get_slide(slide_id)\n            \n            # Get the notes slide ID\n            notes_slide_id = slide.get('slideProperties', {}).get('notesPage', {}).get('objectId')\n            \n            if not notes_slide_id:\n                logger.warning(f\"No notes slide found for slide {slide_id}\")\n                return\n            \n            # Get the notes slide to find the text placeholder\n            notes_slide = self._get_slide(notes_slide_id)\n            \n            # Find the notes text placeholder\n            notes_placeholder_id = None\n            for element in notes_slide.get(\"pageElements\", []):\n                shape = element.get(\"shape\", {})\n                placeholder = shape.get(\"placeholder\")\n                if placeholder and placeholder.get(\"type\") == \"BODY\":\n                    notes_placeholder_id = element[\"objectId\"]\n                    break\n            \n            if not notes_placeholder_id:\n                logger.warning(f\"No notes text placeholder found for slide {slide_id}\")\n                return\n            \n            # Add the notes text\n            self._execute_requests([{\n                'insertText': {\n                    'objectId': notes_placeholder_id,\n                    'insertionIndex': 0,\n                    'text': notes_text\n                }\n            }])\n            \n            print(f\"         ðŸ“ Added speaker notes\")\n            \n        except Exception as e:\n            logger.error(f\"Error adding speaker notes to slide {slide_id}: {e}\")",
              "language": "python",
              "version_uuid": "328d9e73-cd95-46a6-9bf7-588c6a128e38"
            },
            "message": "artifacts",
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "d16af559-54a1-448b-9980-764efd04c7e6"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-05-22T15:21:38.361841Z",
            "stop_timestamp": "2025-05-22T15:21:57.365583Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "updated_shared_helpers",
              "type": "application/vnd.ant.code",
              "title": "Updated Shared Helpers",
              "command": "create",
              "content": "# makeslides/shared/__init__.py\n\"\"\"\nShared helpers: logging, retry, subprocess, litterbox upload\n\"\"\"\nimport logging, os, subprocess, time, requests\nfrom functools import wraps\nfrom pathlib import Path\nfrom typing import Callable, TypeVar\n\nT = TypeVar('T')\n\nLOGLEVEL = os.getenv('MAKESLIDES_LOGLEVEL', 'INFO').upper()\nlogging.basicConfig(level=LOGLEVEL,\n                    format='%(asctime)s | %(levelname)-8s | %(name)s | %(message)s',\n                    datefmt='%Y-%m-%d %H:%M:%S')\nlog = logging.getLogger('makeslides')\n\ndef retry(attempts:int=3, delay:float=1.0, backoff:float=2.0, allowed=(Exception,)):\n    def decorator(fn:Callable[...,T])->Callable[...,T]:\n        @wraps(fn)\n        def wrapper(*args, **kwargs):\n            _delay=delay\n            for i in range(attempts):\n                try:\n                    return fn(*args, **kwargs)\n                except allowed as exc:\n                    if i==attempts-1:\n                        raise\n                    log.warning('%s failed (%s). retry %d/%d', fn.__name__, exc, i+1, attempts-1)\n                    time.sleep(_delay)\n                    _delay*=backoff\n        return wrapper\n    return decorator\n\ndef run(cmd, check=True, capture=True):\n    if isinstance(cmd,str):\n        cmd=cmd.split()\n    log.debug('Running: %s', ' '.join(cmd))\n    res=subprocess.run(cmd, check=check, capture_output=capture, text=True)\n    return res.stdout.strip() if capture else ''\n\n@retry(attempts=3, delay=1.0, backoff=2.0, allowed=(Exception,))\ndef litterbox_upload(path: str | Path, expiry: str = '24h') -> str:\n    \"\"\"\n    Upload file to litterbox.catbox.moe with retry logic.\n    \n    Args:\n        path: Path to file to upload\n        expiry: Expiry time (24h, 1h, etc.)\n        \n    Returns:\n        URL of uploaded file\n        \n    Raises:\n        Exception: If upload fails after retries\n    \"\"\"\n    path = Path(path)\n    \n    if not path.exists():\n        raise FileNotFoundError(f\"File not found: {path}\")\n    \n    log.debug(f'Uploading {path.name} to litterbox...')\n    \n    with path.open('rb') as fh:\n        resp = requests.post(\n            'https://litterbox.catbox.moe/resources/internals/api.php',\n            data={'reqtype':'fileupload', 'time':expiry},\n            files={'fileToUpload': fh},\n            timeout=30\n        )\n    \n    resp.raise_for_status()\n    url = resp.text.strip()\n    \n    if not url.startswith('https://litter.catbox.moe'):\n        raise ValueError(f'Unexpected litterbox response: {url}')\n    \n    log.info('Uploaded %s -> %s', path.name, url)\n    return url",
              "language": "python",
              "version_uuid": "984a9d91-c1c1-4d12-84e9-86d15f56aab6"
            },
            "message": "artifacts",
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "66edbe79-ee45-40f6-9041-d4c51b97aae0"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-05-22T15:22:03.864596Z",
            "stop_timestamp": "2025-05-22T15:22:16.792554Z",
            "flags": null,
            "type": "text",
            "text": "\n\n## Summary\n\nYour diagnosis was absolutely correct. The Google Slides renderer was trying to do too much - finding images, generating diagrams, uploading to litterbox, AND rendering slides. This violated the single responsibility principle and created a tangled mess.\n\n## The Clean Solution\n\n**New Architecture Flow:**\n```\nContent â†’ ContentAnalyzer â†’ Raw JSON â†’ AssetProcessor â†’ Processed JSON â†’ Renderer\n```\n\n### Key Changes:\n\n1. **New AssetProcessor Service** (`services/asset_processor.py`):\n   - Scans JSON for `diagram_content` and generates actual PNG files\n   - Finds all local image references\n   - Uploads everything to litterbox with retry logic\n   - Updates JSON with clean remote URLs\n   - Returns processed JSON ready for rendering\n\n2. **Updated Controller** (`core/controller.py`):\n   - Adds asset processing step between content analysis and rendering\n   - Clean separation of concerns\n\n3. **Cleaned Google Slides Renderer** (`renderers/google_slides_renderer.py`):\n   - Removed all asset processing logic\n   - Only handles rendering slides with pre-processed remote URLs\n   - Much simpler and focused\n\n4. **Enhanced Shared Helpers** (`shared/__init__.py`):\n   - Robust litterbox upload function with retry logic\n   - Used by AssetProcessor for consistent uploads\n\n### Why This Works:\n\n- **Single Responsibility**: Each service has one clear job\n- **Clean Dependencies**: Renderers just render, processors just process\n- **Reusable**: Both PPTX and Google Slides get the same processed assets\n- **Testable**: Each component can be tested independently\n- **Maintainable**: Changes to asset handling don't affect rendering logic\n\nThe key insight is that asset processing (diagram generation + uploads) is a separate domain concern from presentation rendering. By extracting it into its own service, we get cleaner code that's easier to debug and extend.\n\nThis approach is like separating a kitchen's prep work from cooking - the prep chef handles all the ingredient preparation, then hands clean, ready-to-use ingredients to the cook. Much cleaner than having the cook also chop vegetables while trying to manage the stove!",
            "citations": []
          }
        ],
        "updated_at": "2025-05-22T15:22:16.882151Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "9c3725df-9d38-42db-b598-23e57daf7c78",
      "role": "human",
      "content": "Do i need all these files, did we duplicate any of the features? \nCan you fix the image and diagram section for the pptx renderer?\nCan you also tell me how to clean, build and run our application? Maybe generate some diagrams showing how things work with our DDD setup, I'm not so familiar yet and need documentation",
      "created_at": "2025-05-22T15:26:18.184352Z",
      "sequence_order": 2,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-22T15:26:18.165560Z",
            "stop_timestamp": "2025-05-22T15:26:18.165560Z",
            "flags": null,
            "type": "text",
            "text": "Do i need all these files, did we duplicate any of the features? \nCan you fix the image and diagram section for the pptx renderer?\nCan you also tell me how to clean, build and run our application? Maybe generate some diagrams showing how things work with our DDD setup, I'm not so familiar yet and need documentation",
            "citations": []
          }
        ],
        "updated_at": "2025-05-22T15:26:18.184352Z",
        "attachments": [
          {
            "file_name": "__main__.py",
            "file_size": 2980,
            "file_type": "",
            "extracted_content": "# makeslides/__main__.py\n\nimport argparse\nimport os\nimport sys\nimport json\nfrom pathlib import Path\nfrom makeslides.core.controller import SlidesController\nfrom makeslides.domain.models import ThemePresets\nfrom makeslides.diagrams.renderer import render_diagrams_from_json\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=\"Run MakeSlides pipeline\")\n    parser.add_argument(\"--input\", help=\"Markdown or text file with content\")\n    parser.add_argument(\"--output\", default=None, help=\"Output file path for presentation\")\n    parser.add_argument(\"--format\", choices=[\"pptx\", \"google_slides\"], default=\"pptx\")\n    parser.add_argument(\"--theme\", choices=[\"default\", \"dark\", \"minimalist\", \"vibrant\"], default=\"default\")\n    parser.add_argument(\"--thinking\", action=\"store_true\", help=\"Enable Claude's extended thinking mode\")\n    parser.add_argument(\"--save-json\", action=\"store_true\", help=\"Save intermediate JSON to file\")\n    parser.add_argument(\"--render-diagrams\", action=\"store_true\", help=\"Render Mermaid diagrams to images\")\n    parser.add_argument(\"--save-intermediate\", action=\"store_true\", help=\"Save intermediate content and JSON\")\n    parser.add_argument(\"--content-file\", help=\"Custom content file instead of positional input\")\n    return parser.parse_args()\n\ndef main():\n    args = parse_args()\n    if args.content_file:\n        with open(args.content_file, \"r\", encoding=\"utf-8\") as f:\n            content = f.read()\n    else:\n        with open(args.input, \"r\", encoding=\"utf-8\") as f:\n            content = f.read()\n\n    theme_map = {\n        \"default\": ThemePresets.default(),\n        \"dark\": ThemePresets.dark(),\n        \"minimalist\": ThemePresets.minimalist(),\n        \"vibrant\": ThemePresets.vibrant(),\n    }\n    theme = theme_map[args.theme]\n\n    controller = SlidesController(use_extended_thinking=args.thinking)\n    result = controller.create_presentation(\n        content=content,\n        output_format=args.format,\n        output_path=args.output,\n        theme=theme\n    )\n\n    if not result.get(\"success\"):\n        print(f\"âŒ Failed: {result.get('error')}\")\n        sys.exit(1)\n\n    print(f\"âœ… Created presentation at {result['output_path']}\")\n\n    # Save intermediate JSON if available\n    if args.save_json and \"presentation_json\" in result:\n        json_path = Path(args.output or \"output.pptx\").with_suffix(\".json\")\n        with open(json_path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(result[\"presentation_json\"], f, indent=2, ensure_ascii=False)\n        print(f\"ðŸ’¾ Saved intermediate JSON to {json_path}\")\n\n    # Render diagrams if requested\n    if args.render_diagrams and result.get(\"success\") and \"output_path\" in result:\n        output_json = result.get(\"intermediate_json_path\")\n        if output_json and os.path.exists(output_json):\n            render_diagrams_from_json(output_json)\n        else:\n            print(\"âš ï¸ No valid JSON path found for diagram rendering\")\n\nif __name__ == \"__main__\":\n    main()\n"
          },
          {
            "file_name": "pptx_renderer.py",
            "file_size": 27809,
            "file_type": "",
            "extracted_content": "from pptx import Presentation\nfrom pptx.util import Inches, Pt\nfrom pptx.enum.text import PP_ALIGN, MSO_VERTICAL_ANCHOR\nfrom pptx.enum.shapes import MSO_SHAPE_TYPE\nfrom pptx.dml.color import RGBColor\nfrom pathlib import Path\nimport logging\nimport os\nfrom typing import Dict, Any, Optional, List, Tuple\n\nlogger = logging.getLogger(__name__)\n\nclass PptxRenderer:\n    \"\"\"PPTX renderer that creates valid PowerPoint files\"\"\"\n    \n    def __init__(self, template_path: Optional[str] = None, theme: Optional[Any] = None):\n        \"\"\"Initialize the renderer with safe defaults\"\"\"\n        self.template_path = template_path\n        self.theme = self._create_safe_theme(theme)\n        \n    def _create_safe_theme(self, theme: Any) -> Dict[str, Any]:\n        \"\"\"Create a safe theme that won't cause errors\"\"\"\n        # Always return a simple, safe theme structure\n        return {\n            \"colors\": {\n                \"primary\": \"4472C4\",      # Blue\n                \"secondary\": \"ED7D31\",    # Orange  \n                \"text\": \"000000\",         # Black\n                \"background\": \"FFFFFF\",   # White\n                \"accent\": \"70AD47\"        # Green\n            },\n            \"fonts\": {\n                \"title\": {\"name\": \"Calibri\", \"size\": 32, \"bold\": True},\n                \"subtitle\": {\"name\": \"Calibri\", \"size\": 24, \"bold\": False}, \n                \"body\": {\"name\": \"Calibri\", \"size\": 16, \"bold\": False},\n                \"header\": {\"name\": \"Calibri\", \"size\": 18, \"bold\": True}\n            }\n        }\n    \n    def render(self, presentation_data: Dict[str, Any], output_path: str) -> bool:\n        \"\"\"Render presentation to a valid PPTX file\"\"\"\n        try:\n            print(f\"   ðŸ”§ Creating PPTX presentation...\")\n            \n            # Create presentation - always use blank to avoid template issues\n            prs = Presentation()\n            \n            # Set basic properties safely\n            try:\n                prs.core_properties.title = presentation_data.get(\"title\", \"Presentation\")[:100]  # Limit length\n                if \"author\" in presentation_data:\n                    prs.core_properties.author = str(presentation_data[\"author\"])[:50]\n            except Exception as e:\n                logger.warning(f\"Could not set presentation properties: {e}\")\n            \n            # Get slides data\n            slides_data = presentation_data.get(\"slides\", [])\n            if not slides_data:\n                logger.error(\"No slides data found\")\n                return False\n            \n            print(f\"   ðŸ“„ Processing {len(slides_data)} slides...\")\n            \n            # Process each slide with error isolation\n            for i, slide_data in enumerate(slides_data):\n                try:\n                    slide_title = slide_data.get('title', f'Slide {i+1}')\n                    layout_name = slide_data.get('layout', 'TITLE_AND_CONTENT')\n                    print(f\"      {i+1:2d}. {slide_title[:40]}... ({layout_name})\")\n                    \n                    self._create_slide_safely(prs, slide_data, i+1)\n                    \n                except Exception as e:\n                    logger.error(f\"Error creating slide {i+1}: {e}\")\n                    # Create a fallback slide so presentation isn't broken\n                    self._create_fallback_slide(prs, slide_data, i+1)\n            \n            # Ensure output directory exists\n            output_dir = os.path.dirname(output_path)\n            if output_dir:\n                os.makedirs(output_dir, exist_ok=True)\n            \n            # Save presentation\n            prs.save(output_path)\n            print(f\"   âœ… Saved valid PPTX: {os.path.basename(output_path)}\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Critical error in PPTX generation: {e}\")\n            return False\n    \n    def _create_slide_safely(self, prs: Presentation, slide_data: Dict[str, Any], slide_number: int):\n        \"\"\"Create a slide with safe error handling\"\"\"\n        layout = slide_data.get(\"layout\", \"TITLE_AND_CONTENT\")\n        \n        # Route to appropriate slide creator\n        if layout in [\"TWO_COLUMNS\", \"COMPARISON\"]:\n            self._create_two_column_slide(prs, slide_data)\n        elif layout == \"BIG_NUMBER\":\n            self._create_big_number_slide(prs, slide_data)\n        elif layout == \"QUOTE\":\n            self._create_quote_slide(prs, slide_data)\n        elif layout == \"TITLE_SLIDE\":\n            self._create_title_slide(prs, slide_data)\n        elif layout == \"IMAGE_WITH_CAPTION\":\n            self._create_image_slide(prs, slide_data)\n        else:\n            # Default: standard content slide\n            self._create_content_slide(prs, slide_data)\n    \n    def _create_two_column_slide(self, prs: Presentation, slide_data: Dict[str, Any]):\n        \"\"\"Create two-column slide with proper | parsing - FIXED\"\"\"\n        # Use blank layout for full control\n        slide_layout = prs.slide_layouts[6]  # Blank\n        slide = prs.slides.add_slide(slide_layout)\n        \n        # Add title safely\n        title = slide_data.get(\"title\", \"\")\n        if title:\n            title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.2), Inches(9), Inches(1))\n            title_frame = title_box.text_frame\n            title_frame.text = title\n            title_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n            self._apply_font_safely(title_frame.paragraphs[0], \"title\")\n        \n        # Parse content into columns - FIXED\n        content = slide_data.get(\"content\", \"\")\n        left_content, right_content = self._parse_two_columns_fixed(content)\n        \n        print(f\"         ðŸ“Š Left: {left_content[:30]}... | Right: {right_content[:30]}...\")\n        \n        # Create left column\n        if left_content:\n            left_box = slide.shapes.add_textbox(Inches(0.5), Inches(1.5), Inches(4.2), Inches(5.5))\n            self._add_text_content_fixed(left_box.text_frame, left_content)\n        \n        # Create right column - FIXED: Ensure right content is always added\n        if right_content:\n            right_box = slide.shapes.add_textbox(Inches(5.3), Inches(1.5), Inches(4.2), Inches(5.5))\n            self._add_text_content_fixed(right_box.text_frame, right_content)\n        elif left_content:  # If no right content, make left column full width\n            left_box = slide.shapes.add_textbox(Inches(0.5), Inches(1.5), Inches(9), Inches(5.5))\n            self._add_text_content_fixed(left_box.text_frame, left_content)\n        \n        # Add subtle divider line if both columns exist\n        if left_content and right_content:\n            try:\n                line = slide.shapes.add_connector(1, Inches(5), Inches(1.3), Inches(5), Inches(7))\n                line.line.color.rgb = RGBColor(220, 220, 220)\n                line.line.width = Pt(1)\n            except:\n                pass  # Don't fail slide if line can't be added\n        \n        # Add visuals and notes\n        self._add_visuals_safely(slide, slide_data)\n        self._add_notes_safely(slide, slide_data)\n    \n    def _parse_two_columns_fixed(self, content: str) -> Tuple[str, str]:\n        \"\"\"Parse content with | separator - FIXED version\"\"\"\n        if not content:\n            return \"\", \"\"\n        \n        # If content contains |, split on it\n        if '|' in content:\n            parts = content.split('|', 1)  # Split on first | only\n            left = parts[0].strip()\n            right = parts[1].strip() if len(parts) > 1 else \"\"\n            return left, right\n        \n        # If no |, try to split content intelligently\n        lines = content.split('\\n')\n        clean_lines = [line.strip() for line in lines if line.strip()]\n        \n        if len(clean_lines) <= 2:\n            # Too few lines to split\n            return content, \"\"\n        \n        # Split roughly in half, but prefer to split at bullet points\n        midpoint = len(clean_lines) // 2\n        \n        # Look for a good split point near the middle\n        for i in range(max(1, midpoint-2), min(len(clean_lines)-1, midpoint+3)):\n            if clean_lines[i].startswith(('â€¢ ', '- ', '* ', '1. ', '2. ', '3. ')):\n                left_lines = clean_lines[:i]\n                right_lines = clean_lines[i:]\n                return '\\n'.join(left_lines), '\\n'.join(right_lines)\n        \n        # Default split at midpoint\n        left_lines = clean_lines[:midpoint]\n        right_lines = clean_lines[midpoint:]\n        return '\\n'.join(left_lines), '\\n'.join(right_lines)\n    \n    def _add_text_content_fixed(self, text_frame, content: str):\n        \"\"\"Add formatted text content safely - FIXED bullet point handling\"\"\"\n        if not content:\n            return\n        \n        try:\n            text_frame.clear()\n            \n            # Split content into lines and process each\n            lines = content.split('\\n')\n            first_paragraph = True\n            \n            for line in lines:\n                line = line.strip()\n                if not line:\n                    continue\n                \n                # Create paragraph\n                if first_paragraph:\n                    p = text_frame.paragraphs[0]\n                    first_paragraph = False\n                else:\n                    p = text_frame.add_paragraph()\n                \n                # Detect and handle bullet points - FIXED\n                if line.startswith(('â€¢ ', '- ', '* ')):\n                    # Remove bullet character and set PowerPoint bullet\n                    p.text = line[2:].strip()\n                    p.level = 0\n                    \n                    # Explicitly set bullet style - FIXED\n                    try:\n                        p.bullet = True\n                        # Set bullet character explicitly\n                        if hasattr(p, '_p') and hasattr(p._p, 'pPr'):\n                            # This ensures the bullet actually appears\n                            bullet_pr = p._p.get_or_add_pPr()\n                            bullet_pr.get_or_add_buChar().set('char', 'â€¢')\n                    except Exception as e:\n                        logger.debug(f\"Could not set bullet style: {e}\")\n                        # Fallback: just add bullet character manually\n                        p.text = f\"â€¢ {p.text}\"\n                        \n                elif line.startswith(('  â€¢ ', '  - ', '  * ', '    â€¢ ', '    - ', '    * ')):\n                    # Sub-bullet (indented)\n                    clean_text = line.lstrip(' â€¢-*').strip()\n                    p.text = clean_text\n                    p.level = 1\n                    \n                    try:\n                        p.bullet = True\n                        if hasattr(p, '_p') and hasattr(p._p, 'pPr'):\n                            bullet_pr = p._p.get_or_add_pPr()\n                            bullet_pr.get_or_add_buChar().set('char', 'â—¦')\n                    except Exception as e:\n                        logger.debug(f\"Could not set sub-bullet style: {e}\")\n                        p.text = f\"  â—¦ {p.text}\"\n                        \n                elif line.startswith(('1. ', '2. ', '3. ', '4. ', '5. ')):\n                    # Numbered list\n                    p.text = line[3:].strip()\n                    p.level = 0\n                    try:\n                        p.bullet = True\n                        # Set numbered bullet style\n                        if hasattr(p, '_p') and hasattr(p._p, 'pPr'):\n                            bullet_pr = p._p.get_or_add_pPr()\n                            # For numbered lists, we'll keep the number\n                            p.bullet = False\n                            p.text = line  # Keep original with number\n                    except Exception as e:\n                        logger.debug(f\"Could not set numbered style: {e}\")\n                        p.text = line  # Keep original\n                        \n                else:\n                    # Regular text\n                    p.text = line\n                    p.level = 0\n                \n                # Apply formatting based on content type\n                if line.isupper() and len(line) < 20:\n                    self._apply_font_safely(p, \"header\")\n                else:\n                    self._apply_font_safely(p, \"body\")\n                    \n        except Exception as e:\n            logger.warning(f\"Error adding text content: {e}\")\n            # Fallback: just add plain text with manual bullets\n            try:\n                text_frame.clear()\n                # Add content with manual bullet formatting\n                fixed_content = self._fix_bullets_manually(content)\n                text_frame.text = fixed_content\n            except:\n                pass\n    \n    def _fix_bullets_manually(self, content: str) -> str:\n        \"\"\"Manually fix bullet formatting as fallback\"\"\"\n        lines = content.split('\\n')\n        fixed_lines = []\n        \n        for line in lines:\n            line = line.strip()\n            if not line:\n                continue\n                \n            # Ensure bullet points have proper characters\n            if line.startswith(('- ', '* ')):\n                fixed_lines.append(f\"â€¢ {line[2:].strip()}\")\n            elif line.startswith(('  - ', '  * ')):\n                fixed_lines.append(f\"  â—¦ {line.strip()[2:].strip()}\")\n            else:\n                fixed_lines.append(line)\n        \n        return '\\n'.join(fixed_lines)\n    \n    def _create_big_number_slide(self, prs: Presentation, slide_data: Dict[str, Any]):\n        \"\"\"Create big number emphasis slide\"\"\"\n        slide_layout = prs.slide_layouts[6]  # Blank\n        slide = prs.slides.add_slide(slide_layout)\n        \n        # Get the big number (usually the title)\n        big_number = slide_data.get(\"title\", \"100%\")\n        description = slide_data.get(\"content\", \"\")\n        \n        # Add big number\n        number_box = slide.shapes.add_textbox(Inches(1), Inches(2), Inches(8), Inches(2.5))\n        number_frame = number_box.text_frame\n        number_frame.text = big_number\n        number_para = number_frame.paragraphs[0]\n        number_para.alignment = PP_ALIGN.CENTER\n        \n        # Make it big and bold\n        for run in number_para.runs:\n            run.font.size = Pt(64)\n            run.font.bold = True\n            run.font.color.rgb = self._get_color(\"primary\")\n        \n        # Add description\n        if description:\n            desc_box = slide.shapes.add_textbox(Inches(1), Inches(4.8), Inches(8), Inches(2))\n            desc_frame = desc_box.text_frame\n            desc_frame.text = description\n            desc_para = desc_frame.paragraphs[0]\n            desc_para.alignment = PP_ALIGN.CENTER\n            self._apply_font_safely(desc_para, \"body\")\n        \n        self._add_notes_safely(slide, slide_data)\n    \n    def _create_quote_slide(self, prs: Presentation, slide_data: Dict[str, Any]):\n        \"\"\"Create quote slide with attribution\"\"\"\n        slide_layout = prs.slide_layouts[6]  # Blank\n        slide = prs.slides.add_slide(slide_layout)\n        \n        content = slide_data.get(\"content\", \"\")\n        quote_text, attribution = self._parse_quote(content)\n        \n        # Add quote\n        if quote_text:\n            quote_box = slide.shapes.add_textbox(Inches(1), Inches(2), Inches(8), Inches(3.5))\n            quote_frame = quote_box.text_frame\n            quote_frame.text = f'\"{quote_text}\"'\n            quote_para = quote_frame.paragraphs[0]\n            quote_para.alignment = PP_ALIGN.CENTER\n            \n            for run in quote_para.runs:\n                run.font.size = Pt(24)\n                run.font.italic = True\n                run.font.color.rgb = self._get_color(\"primary\")\n        \n        # Add attribution\n        if attribution:\n            attr_box = slide.shapes.add_textbox(Inches(1), Inches(5.8), Inches(8), Inches(1))\n            attr_frame = attr_box.text_frame\n            attr_frame.text = attribution\n            attr_para = attr_frame.paragraphs[0]\n            attr_para.alignment = PP_ALIGN.CENTER\n            self._apply_font_safely(attr_para, \"body\")\n        \n        self._add_notes_safely(slide, slide_data)\n    \n    def _parse_quote(self, content: str) -> Tuple[str, str]:\n        \"\"\"Parse quote and attribution from content\"\"\"\n        lines = [line.strip() for line in content.split('\\n') if line.strip()]\n        \n        quote_lines = []\n        attribution = \"\"\n        \n        for line in lines:\n            if line.startswith('â€”') or line.startswith('- '):\n                attribution = line\n            elif line and not line.startswith('\"'):\n                quote_lines.append(line.strip('\"'))\n        \n        quote_text = ' '.join(quote_lines)\n        return quote_text, attribution\n    \n    def _create_title_slide(self, prs: Presentation, slide_data: Dict[str, Any]):\n        \"\"\"Create title slide\"\"\"\n        slide_layout = prs.slide_layouts[0]  # Title slide\n        slide = prs.slides.add_slide(slide_layout)\n        \n        # Set title\n        title = slide_data.get(\"title\", \"Presentation\")\n        if hasattr(slide.shapes, 'title') and slide.shapes.title:\n            slide.shapes.title.text = title\n            self._apply_font_safely(slide.shapes.title.text_frame.paragraphs[0], \"title\")\n        \n        # Set subtitle\n        subtitle = slide_data.get(\"subtitle\", slide_data.get(\"content\", \"\"))\n        if subtitle:\n            for shape in slide.placeholders:\n                if shape.placeholder_format.type == 2:  # Subtitle\n                    shape.text = subtitle\n                    self._apply_font_safely(shape.text_frame.paragraphs[0], \"subtitle\")\n                    break\n        \n        self._add_visuals_safely_fixed(slide, slide_data)\n        self._add_notes_safely(slide, slide_data)\n    \n    def _create_image_slide(self, prs: Presentation, slide_data: Dict[str, Any]):\n        \"\"\"Create slide with image and caption\"\"\"\n        slide_layout = prs.slide_layouts[6]  # Blank\n        slide = prs.slides.add_slide(slide_layout)\n        \n        # Add title\n        title = slide_data.get(\"title\", \"\")\n        if title:\n            title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.2), Inches(9), Inches(0.8))\n            title_frame = title_box.text_frame\n            title_frame.text = title\n            title_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n            self._apply_font_safely(title_frame.paragraphs[0], \"title\")\n        \n        # Add visuals (image/diagram)\n        visual_added = self._add_visuals_safely_fixed(slide, slide_data, main_area=True)\n        \n        # Add content/caption\n        content = slide_data.get(\"content\", \"\")\n        if content:\n            caption_y = Inches(6) if visual_added else Inches(2)\n            caption_box = slide.shapes.add_textbox(Inches(1), caption_y, Inches(8), Inches(1.5))\n            self._add_text_content_fixed(caption_box.text_frame, content)\n        \n        self._add_notes_safely(slide, slide_data)\n    \n    def _create_content_slide(self, prs: Presentation, slide_data: Dict[str, Any]):\n        \"\"\"Create standard content slide\"\"\"\n        slide_layout = prs.slide_layouts[1]  # Title and content\n        slide = prs.slides.add_slide(slide_layout)\n        \n        # Set title\n        title = slide_data.get(\"title\", \"\")\n        if title and hasattr(slide.shapes, 'title') and slide.shapes.title:\n            slide.shapes.title.text = title\n            self._apply_font_safely(slide.shapes.title.text_frame.paragraphs[0], \"title\")\n        \n        # Add content\n        content = slide_data.get(\"content\", \"\")\n        if content:\n            # Find content placeholder\n            content_placeholder = None\n            for shape in slide.placeholders:\n                if shape.placeholder_format.type == 1:  # Body\n                    content_placeholder = shape\n                    break\n            \n            if content_placeholder:\n                self._add_text_content_fixed(content_placeholder.text_frame, content)\n            else:\n                # Fallback: create text box\n                content_box = slide.shapes.add_textbox(Inches(0.5), Inches(1.5), Inches(6), Inches(5))\n                self._add_text_content_fixed(content_box.text_frame, content)\n        \n        # Add visuals in side area\n        self._add_visuals_safely_fixed(slide, slide_data, side_area=True)\n        self._add_notes_safely(slide, slide_data)\n    \n    def _add_visuals_safely_fixed(self, slide, slide_data: Dict[str, Any], main_area: bool = False, side_area: bool = False) -> bool:\n        \"\"\"Add images and diagrams safely - FIXED version\"\"\"\n        visual_added = False\n        \n        try:\n            # Determine positioning\n            if main_area:\n                x, y, w, h = Inches(1.5), Inches(1.2), Inches(7), Inches(4.5)\n            elif side_area:\n                x, y, w, h = Inches(6.5), Inches(1.5), Inches(3), Inches(3)\n            else:\n                x, y, w, h = Inches(7), Inches(2), Inches(2.5), Inches(2)\n            \n            # Try multiple image path variations - FIXED\n            image_paths_to_try = []\n            \n            # Add diagram paths\n            if slide_data.get('diagram_content'):\n                slide_num = slide_data.get('slide_number', 1)\n                diagram_type = slide_data.get('diagram_type', 'flowchart')\n                base_names = ['test_fix_workflow', 'slides', 'presentation']\n                \n                for base_name in base_names:\n                    for ext in ['.png', '.svg']:\n                        image_paths_to_try.extend([\n                            f\"images/{base_name}_slide{slide_num}_{diagram_type}{ext}\",\n                            f\"images/{base_name}_slide{slide_num}{ext}\",\n                            f\"images/slide{slide_num}_{diagram_type}{ext}\",\n                            f\"images/slide{slide_num}{ext}\"\n                        ])\n            \n            # Add explicit image paths\n            if slide_data.get('image_url'):\n                image_paths_to_try.append(slide_data['image_url'])\n            \n            if slide_data.get('local_image_path'):\n                image_paths_to_try.append(slide_data['local_image_path'])\n                \n            if slide_data.get('local_diagram_path'):\n                image_paths_to_try.append(slide_data['local_diagram_path'])\n            \n            # Try each path until one works\n            for image_path in image_paths_to_try:\n                if not image_path:\n                    continue\n                    \n                # Convert to Path object for easier handling\n                path_obj = Path(image_path)\n                \n                # Try the path as-is first\n                if path_obj.exists():\n                    try:\n                        slide.shapes.add_picture(str(path_obj), x, y, w, h)\n                        print(f\"         ðŸ–¼ï¸ Added image: {path_obj.name}\")\n                        visual_added = True\n                        break\n                    except Exception as e:\n                        logger.debug(f\"Failed to add image {path_obj}: {e}\")\n                        continue\n                \n                # If not found, try relative to current directory\n                if not path_obj.is_absolute():\n                    current_dir_path = Path.cwd() / path_obj\n                    if current_dir_path.exists():\n                        try:\n                            slide.shapes.add_picture(str(current_dir_path), x, y, w, h)\n                            print(f\"         ðŸ–¼ï¸ Added image: {current_dir_path.name}\")\n                            visual_added = True\n                            break\n                        except Exception as e:\n                            logger.debug(f\"Failed to add image {current_dir_path}: {e}\")\n                            continue\n            \n            if not visual_added and image_paths_to_try:\n                print(f\"         âš ï¸ No images found from {len(image_paths_to_try)} attempted paths\")\n                for path in image_paths_to_try[:3]:  # Show first 3 attempted paths\n                    print(f\"             - {path}\")\n                    \n        except Exception as e:\n            logger.warning(f\"Error adding visuals: {e}\")\n        \n        return visual_added\n    \n    def _add_notes_safely(self, slide, slide_data: Dict[str, Any]):\n        \"\"\"Add speaker notes safely\"\"\"\n        try:\n            notes_text = (slide_data.get(\"facilitator_notes\", \"\") or \n                         slide_data.get(\"notes\", \"\"))\n            \n            if notes_text:\n                try:\n                    # Access notes slide properly\n                    notes_slide = slide.notes_slide\n                    if hasattr(notes_slide, 'notes_text_frame'):\n                        notes_slide.notes_text_frame.text = notes_text[:1000]\n                        print(f\"         ðŸ“ Added speaker notes\")\n                except Exception as e:\n                    logger.warning(f\"Could not add speaker notes: {e}\")\n        except Exception as e:\n            logger.warning(f\"Could not access speaker notes: {e}\")\n\n    def _apply_font_safely(self, paragraph, font_type: str):\n        \"\"\"Apply font formatting safely\"\"\"\n        try:\n            font_config = self.theme[\"fonts\"].get(font_type, self.theme[\"fonts\"][\"body\"])\n            \n            for run in paragraph.runs:\n                if run.text.strip():  # Only format runs with text\n                    try:\n                        run.font.name = font_config[\"name\"]\n                        run.font.size = Pt(font_config[\"size\"])\n                        run.font.bold = font_config.get(\"bold\", False)\n                        \n                        # Apply color based on font type\n                        if font_type == \"title\":\n                            run.font.color.rgb = self._get_color(\"primary\")\n                        else:\n                            run.font.color.rgb = self._get_color(\"text\")\n                    except:\n                        pass  # Don't fail if individual formatting fails\n                        \n        except Exception as e:\n            logger.warning(f\"Font formatting error: {e}\")\n    \n    def _get_color(self, color_name: str) -> RGBColor:\n        \"\"\"Get color safely\"\"\"\n        try:\n            hex_color = self.theme[\"colors\"].get(color_name, \"000000\")\n            if hex_color.startswith(\"#\"):\n                hex_color = hex_color[1:]\n            \n            r = int(hex_color[0:2], 16)\n            g = int(hex_color[2:4], 16) \n            b = int(hex_color[4:6], 16)\n            return RGBColor(r, g, b)\n        except:\n            return RGBColor(0, 0, 0)  # Default to black\n    \n    def _create_fallback_slide(self, prs: Presentation, slide_data: Dict[str, Any], slide_number: int):\n        \"\"\"Create a simple fallback slide when main creation fails\"\"\"\n        try:\n            slide_layout = prs.slide_layouts[1]  # Title and content\n            slide = prs.slides.add_slide(slide_layout)\n            \n            # Basic title\n            title = slide_data.get(\"title\", f\"Slide {slide_number}\")\n            if hasattr(slide.shapes, 'title') and slide.shapes.title:\n                slide.shapes.title.text = title\n            \n            # Basic content\n            content = slide_data.get(\"content\", \"Content could not be formatted properly.\")\n            for shape in slide.placeholders:\n                if shape.placeholder_format.type == 1:  # Body\n                    shape.text = content[:300]  # Limit length\n                    break\n                    \n            print(f\"      âš ï¸ Created fallback slide {slide_number}\")\n            \n        except Exception as e:\n            logger.error(f\"Even fallback slide creation failed: {e}\")"
          },
          {
            "file_name": "__init__.py",
            "file_size": 0,
            "file_type": "",
            "extracted_content": ""
          },
          {
            "file_name": "visual_reviewer.py",
            "file_size": 10291,
            "file_type": "",
            "extracted_content": "import os\nimport tempfile\nimport base64\nimport logging\nimport anthropic\nfrom typing import Dict, Any, List\nfrom pathlib import Path\nimport subprocess\nfrom io import BytesIO\nfrom PIL import Image\n\nlogger = logging.getLogger(__name__)\n\nclass VisualReviewer:\n    \"\"\"Reviews presentation visuals using Claude's vision capabilities\"\"\"\n    \n    def __init__(self, api_key: Optional[str] = None):\n        \"\"\"Initialize the visual reviewer\n        \n        Args:\n            api_key: Anthropic API key (optional, defaults to env var)\n        \"\"\"\n        self.api_key = api_key or os.environ.get(\"ANTHROPIC_API_KEY\")\n        if not self.api_key:\n            raise ValueError(\"Anthropic API key not provided and ANTHROPIC_API_KEY environment variable not set\")\n        \n        self.client = anthropic.Anthropic(api_key=self.api_key)\n    \n    def review_pptx(self, pptx_path: str) -> Dict[str, Any]:\n        \"\"\"Review a PowerPoint presentation\n        \n        Args:\n            pptx_path: Path to PPTX file\n            \n        Returns:\n            Review results\n        \"\"\"\n        # Extract slides as images\n        slide_images = self._extract_slides_from_pptx(pptx_path)\n        \n        if not slide_images:\n            logger.error(\"Failed to extract slides from PowerPoint\")\n            return {\"success\": False, \"error\": \"Failed to extract slides\"}\n        \n        # Review each slide\n        review_results = []\n        \n        for i, image_data in enumerate(slide_images):\n            try:\n                # Review individual slide\n                slide_review = self._review_single_slide(image_data, slide_number=i+1)\n                review_results.append(slide_review)\n                \n            except Exception as e:\n                logger.error(f\"Error reviewing slide {i+1}: {e}\")\n                review_results.append({\n                    \"slide_number\": i+1,\n                    \"success\": False,\n                    \"error\": str(e)\n                })\n        \n        # Generate overall review\n        overall_review = self._generate_overall_review(review_results)\n        \n        return {\n            \"success\": True,\n            \"overall_review\": overall_review,\n            \"slide_reviews\": review_results\n        }\n    \n    def _extract_slides_from_pptx(self, pptx_path: str) -> List[bytes]:\n        \"\"\"Extract slides as images from a PowerPoint file\n        \n        Args:\n            pptx_path: Path to PPTX file\n            \n        Returns:\n            List of image data (bytes)\n        \"\"\"\n        slides = []\n        \n        try:\n            # Create a temporary directory to store slide images\n            with tempfile.TemporaryDirectory() as temp_dir:\n                # Use LibreOffice to convert PPTX to images\n                # Note: This requires LibreOffice to be installed\n                try:\n                    cmd = [\n                        \"libreoffice\", \"--headless\", \"--convert-to\", \"png\",\n                        \"--outdir\", temp_dir, pptx_path\n                    ]\n                    subprocess.run(cmd, check=True, capture_output=True)\n                except subprocess.CalledProcessError:\n                    logger.warning(\"LibreOffice conversion failed, trying alternative method\")\n                    \n                    # Alternative: Use python-pptx to extract slides\n                    # This is less accurate but doesn't require external dependencies\n                    from pptx import Presentation\n                    from pptx.enum.shapes import MSO_SHAPE_TYPE\n                    \n                    prs = Presentation(pptx_path)\n                    for i, slide in enumerate(prs.slides):\n                        # Create a blank image\n                        img = Image.new('RGB', (960, 540), (255, 255, 255))\n                        \n                        # Save the blank image with slide number\n                        img_path = os.path.join(temp_dir, f\"slide_{i+1:02d}.png\")\n                        img.save(img_path)\n                \n                # Read generated images\n                for file in sorted(os.listdir(temp_dir)):\n                    if file.endswith(\".png\"):\n                        file_path = os.path.join(temp_dir, file)\n                        with open(file_path, \"rb\") as f:\n                            slides.append(f.read())\n        \n        except Exception as e:\n            logger.error(f\"Error extracting slides: {e}\")\n        \n        return slides\n    \n    def _review_single_slide(self, image_data: bytes, slide_number: int) -> Dict[str, Any]:\n        \"\"\"Review a single slide\n        \n        Args:\n            image_data: Slide image data\n            slide_number: Slide number\n            \n        Returns:\n            Review result\n        \"\"\"\n        # Convert image to base64\n        base64_image = base64.b64encode(image_data).decode(\"utf-8\")\n        \n        # Prepare message for Claude\n        messages = [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"image\",\n                        \"source\": {\n                            \"type\": \"base64\",\n                            \"media_type\": \"image/png\",\n                            \"data\": base64_image\n                        }\n                    },\n                    {\n                        \"type\": \"text\",\n                        \"text\": f\"\"\"Please review this presentation slide (Slide {slide_number}) and provide feedback on:\n1. Visual design and layout\n2. Content clarity and organization\n3. Use of text (amount, size, readability)\n4. Use of visuals (images, diagrams, charts)\n5. Specific improvements that could be made\n\nFormat your response as a JSON object with the following keys:\n- rating: A score from 1-10 rating the overall slide quality\n- strengths: Array of 2-3 key strengths of the slide\n- weaknesses: Array of 2-3 areas that need improvement\n- recommendations: Array of 3-5 specific, actionable improvements\n\"\"\"\n                    }\n                ]\n            }\n        ]\n        \n        # Send request to Claude\n        response = self.client.messages.create(\n            model=\"claude-3-7-sonnet-20250219\",\n            max_tokens=1500,\n            system=\"You are a presentation design expert providing helpful and constructive feedback. Focus on specific, actionable advice. Return valid JSON only, with no surrounding explanation.\",\n            messages=messages\n        )\n        \n        # Parse response\n        response_text = response.content[0].text\n        \n        # Extract JSON from response\n        import re\n        import json\n        \n        json_pattern = r\"```(?:json)?\\s*([\\s\\S]*?)\\s*```\"\n        json_match = re.search(json_pattern, response_text)\n        \n        if json_match:\n            review_json = json_match.group(1)\n        else:\n            review_json = response_text\n        \n        try:\n            review_data = json.loads(review_json)\n            review_data[\"slide_number\"] = slide_number\n            review_data[\"success\"] = True\n            return review_data\n        except json.JSONDecodeError:\n            logger.error(f\"Failed to parse JSON from Claude response for slide {slide_number}\")\n            return {\n                \"slide_number\": slide_number,\n                \"success\": False,\n                \"error\": \"Failed to parse review data\",\n                \"raw_response\": response_text\n            }\n    \n    def _generate_overall_review(self, slide_reviews: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Generate an overall review of the presentation\n        \n        Args:\n            slide_reviews: List of individual slide reviews\n            \n        Returns:\n            Overall review\n        \"\"\"\n        # Prepare summary of slide reviews for Claude\n        successful_reviews = [r for r in slide_reviews if r.get(\"success\", False)]\n        \n        if not successful_reviews:\n            return {\n                \"overall_rating\": 0,\n                \"summary\": \"Unable to generate overall review due to failed slide reviews.\",\n                \"key_issues\": [],\n                \"key_strengths\": [],\n                \"recommendations\": []\n            }\n        \n        # Calculate average rating\n        ratings = [r.get(\"rating\", 0) for r in successful_reviews]\n        avg_rating = sum(ratings) / len(ratings) if ratings else 0\n        \n        # Collect all strengths and weaknesses\n        all_strengths = []\n        all_weaknesses = []\n        \n        for review in successful_reviews:\n            all_strengths.extend(review.get(\"strengths\", []))\n            all_weaknesses.extend(review.get(\"weaknesses\", []))\n        \n        # Identify common themes\n        from collections import Counter\n        \n        # Custom function to find similar items\n        def find_similar(items):\n            # Simple approach: group by common keywords\n            keywords = {}\n            for item in items:\n                words = set(w.lower() for w in item.split() if len(w) > 3)\n                for word in words:\n                    if word not in keywords:\n                        keywords[word] = []\n                    keywords[word].append(item)\n            \n            # Return groups with multiple items\n            return [group for group in keywords.values() if len(group) > 1]\n        \n        common_strengths = find_similar(all_strengths)\n        common_weaknesses = find_similar(all_weaknesses)\n        \n        # Generate overall recommendations\n        overall_recommendations = []\n        if common_weaknesses:\n            for group in common_weaknesses[:3]:  # Top 3 weakness groups\n                if group:\n                    overall_recommendations.append(f\"Improve {group[0].lower()}\")\n        \n        return {\n            \"overall_rating\": round(avg_rating, 1),\n            \"summary\": f\"Presentation has an average slide rating of {round(avg_rating, 1)}/10 across {len(successful_reviews)} slides.\",\n            \"key_issues\": [group[0] for group in common_weaknesses[:3] if group],\n            \"key_strengths\": [group[0] for group in common_strengths[:3] if group],\n            \"recommendations\": overall_recommendations\n        }\n5. Main Controller Class\nNow, let's create a central controller that ties everything together:"
          },
          {
            "file_name": "asset_processor.py",
            "file_size": 9050,
            "file_type": "",
            "extracted_content": "# makeslides/services/asset_processor.py\n\nimport os\nimport logging\nimport subprocess\nimport tempfile\nimport hashlib\nfrom pathlib import Path\nfrom typing import Dict, Any, List, Optional, Tuple\nfrom ..diagrams.renderer import render_mermaid\nfrom ..shared import litterbox_upload\n\nlogger = logging.getLogger(__name__)\n\nclass AssetProcessor:\n    \"\"\"\n    Processes all assets (diagrams, images) for presentations.\n    \n    Responsibilities:\n    1. Generate diagrams from diagram_content\n    2. Upload all assets to litterbox\n    3. Update JSON with remote URLs\n    4. Return clean JSON for renderers\n    \"\"\"\n    \n    def __init__(self):\n        self.temp_dir = None\n        self.processed_assets = {}  # Cache to avoid duplicate uploads\n    \n    def process_presentation_assets(self, presentation_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Process all assets in a presentation and return updated JSON with remote URLs.\n        \n        Args:\n            presentation_data: Raw presentation JSON from content analyzer\n            \n        Returns:\n            Updated presentation data with remote asset URLs\n        \"\"\"\n        logger.info(\"Processing presentation assets...\")\n        \n        # Create temp directory for asset processing\n        self.temp_dir = Path(tempfile.mkdtemp(prefix=\"makeslides_assets_\"))\n        \n        try:\n            # Extract slides data  \n            slides = presentation_data.get(\"slides\", [])\n            if not slides:\n                logger.warning(\"No slides found in presentation data\")\n                return presentation_data\n            \n            # Process each slide's assets\n            for i, slide in enumerate(slides):\n                logger.debug(f\"Processing assets for slide {i+1}\")\n                self._process_slide_assets(slide, i+1)\n            \n            logger.info(f\"Successfully processed assets for {len(slides)} slides\")\n            return presentation_data\n            \n        except Exception as e:\n            logger.error(f\"Error processing presentation assets: {e}\")\n            raise\n        finally:\n            # Clean up temp directory\n            if self.temp_dir and self.temp_dir.exists():\n                import shutil\n                shutil.rmtree(self.temp_dir, ignore_errors=True)\n    \n    def _process_slide_assets(self, slide: Dict[str, Any], slide_number: int):\n        \"\"\"Process assets for a single slide.\"\"\"\n        \n        # 1. Generate diagram if needed\n        if slide.get(\"diagram_content\") and slide.get(\"diagram_type\"):\n            diagram_url = self._generate_and_upload_diagram(slide, slide_number)\n            if diagram_url:\n                slide[\"image_url\"] = diagram_url\n                logger.info(f\"Slide {slide_number}: Generated diagram and uploaded to {diagram_url}\")\n        \n        # 2. Process existing image references\n        elif slide.get(\"image_url\"):\n            image_url = slide[\"image_url\"]\n            \n            # If it's a local file, upload it\n            if not image_url.startswith((\"http://\", \"https://\")):\n                uploaded_url = self._upload_local_image(image_url)\n                if uploaded_url:\n                    slide[\"image_url\"] = uploaded_url\n                    logger.info(f\"Slide {slide_number}: Uploaded local image to {uploaded_url}\")\n        \n        # 3. Process other image fields\n        for field in [\"local_image_path\", \"local_diagram_path\"]:\n            if slide.get(field):\n                uploaded_url = self._upload_local_image(slide[field])\n                if uploaded_url:\n                    slide[\"image_url\"] = uploaded_url\n                    logger.info(f\"Slide {slide_number}: Uploaded {field} to {uploaded_url}\")\n                    break\n    \n    def _generate_and_upload_diagram(self, slide: Dict[str, Any], slide_number: int) -> Optional[str]:\n        \"\"\"Generate diagram from content and upload to litterbox.\"\"\"\n        try:\n            diagram_content = slide.get(\"diagram_content\")\n            diagram_type = slide.get(\"diagram_type\", \"flowchart\")\n            \n            if not diagram_content:\n                return None\n            \n            # Generate unique filename\n            content_hash = hashlib.md5(diagram_content.encode()).hexdigest()[:8]\n            filename = f\"slide_{slide_number}_{diagram_type}_{content_hash}\"\n            \n            # Check cache first\n            if content_hash in self.processed_assets:\n                return self.processed_assets[content_hash]\n            \n            # Generate diagram file\n            diagram_path = self._generate_diagram_file(\n                diagram_content, diagram_type, filename\n            )\n            \n            if diagram_path and diagram_path.exists():\n                # Upload to litterbox\n                uploaded_url = self._upload_to_litterbox(diagram_path)\n                if uploaded_url:\n                    self.processed_assets[content_hash] = uploaded_url\n                    return uploaded_url\n            \n            return None\n            \n        except Exception as e:\n            logger.error(f\"Error generating diagram for slide {slide_number}: {e}\")\n            return None\n    \n    def _generate_diagram_file(self, content: str, diagram_type: str, filename: str) -> Optional[Path]:\n        \"\"\"Generate diagram file using existing diagram renderer.\"\"\"\n        try:\n            # Create mermaid file\n            mmd_file = self.temp_dir / f\"{filename}.mmd\"\n            png_file = self.temp_dir / f\"{filename}.png\"\n            \n            # Write diagram content\n            with open(mmd_file, 'w', encoding='utf-8') as f:\n                f.write(content)\n            \n            # Use mermaid CLI to generate PNG\n            cmd = [\"mmdc\", \"-i\", str(mmd_file), \"-o\", str(png_file)]\n            \n            result = subprocess.run(\n                cmd, check=True, capture_output=True, text=True, timeout=30\n            )\n            \n            if png_file.exists() and png_file.stat().st_size > 0:\n                return png_file\n            else:\n                logger.warning(f\"Generated diagram file is empty: {png_file}\")\n                return None\n                \n        except subprocess.CalledProcessError as e:\n            logger.error(f\"Mermaid CLI error: {e.stderr}\")\n            return None\n        except Exception as e:\n            logger.error(f\"Error generating diagram file: {e}\")\n            return None\n    \n    def _upload_local_image(self, image_path: str) -> Optional[str]:\n        \"\"\"Upload a local image file to litterbox.\"\"\"\n        try:\n            path_obj = Path(image_path)\n            \n            # Try to find the file\n            if not path_obj.exists():\n                # Try relative to current directory\n                path_obj = Path.cwd() / image_path\n                if not path_obj.exists():\n                    logger.warning(f\"Image file not found: {image_path}\")\n                    return None\n            \n            # Check if already uploaded\n            file_hash = self._get_file_hash(path_obj)\n            if file_hash in self.processed_assets:\n                return self.processed_assets[file_hash]\n            \n            # Upload to litterbox\n            uploaded_url = self._upload_to_litterbox(path_obj)\n            if uploaded_url:\n                self.processed_assets[file_hash] = uploaded_url\n            \n            return uploaded_url\n            \n        except Exception as e:\n            logger.error(f\"Error uploading local image {image_path}: {e}\")\n            return None\n    \n    def _upload_to_litterbox(self, file_path: Path, max_retries: int = 3) -> Optional[str]:\n        \"\"\"Upload file to litterbox with retry logic.\"\"\"\n        for attempt in range(max_retries):\n            try:\n                logger.debug(f\"Uploading {file_path.name} to litterbox (attempt {attempt+1})\")\n                \n                # Use the shared litterbox upload function\n                url = litterbox_upload(file_path, expiry=\"24h\")\n                \n                if url and url.startswith(\"https://litter.catbox.moe/\"):\n                    logger.info(f\"âœ… Uploaded {file_path.name} -> {url}\")\n                    return url\n                else:\n                    logger.warning(f\"Invalid litterbox response: {url}\")\n                    \n            except Exception as e:\n                logger.warning(f\"Upload attempt {attempt+1} failed: {e}\")\n                if attempt < max_retries - 1:\n                    import time\n                    time.sleep(2 ** attempt)  # Exponential backoff\n        \n        logger.error(f\"Failed to upload {file_path} after {max_retries} attempts\")\n        return None\n    \n    def _get_file_hash(self, file_path: Path) -> str:\n        \"\"\"Get hash of file for caching purposes.\"\"\"\n        try:\n            with open(file_path, 'rb') as f:\n                return hashlib.md5(f.read()).hexdigest()[:8]\n        except Exception:\n            # Fallback to path-based hash\n            return hashlib.md5(str(file_path).encode()).hexdigest()[:8]"
          },
          {
            "file_name": "content_analyzer.py",
            "file_size": 7801,
            "file_type": "",
            "extracted_content": "# makeslides/services/content_analyzer.py\n\nimport logging\nimport json\nimport re\nimport os\nimport time\nfrom typing import Dict, Any, Optional\nfrom colorama import init, Fore, Style\nimport anthropic\nfrom anthropic.types import ContentBlockDeltaEvent\n\nfrom ..domain.interfaces import ContentAnalyzerInterface\nfrom ..domain.models import Presentation, Slide\n\ninit()\nlogger = logging.getLogger(__name__)\n\nclass ClaudeContentAnalyzer(ContentAnalyzerInterface):\n    def __init__(self, api_key: Optional[str] = None, use_extended_thinking: bool = False):\n        self.api_key = api_key or os.environ.get(\"ANTHROPIC_API_KEY\")\n        if not self.api_key:\n            raise ValueError(\"Anthropic API key not provided and ANTHROPIC_API_KEY environment variable not set\")\n        self.client = anthropic.Anthropic(api_key=self.api_key)\n        self.use_extended_thinking = use_extended_thinking\n\n    def analyze(self, content: str) -> Presentation:\n        print(f\"\\n{Fore.CYAN}ðŸ“Š ANALYZING CONTENT FOR PRESENTATION{Style.RESET_ALL}\")\n        print(f\"{Fore.YELLOW}Content length: {len(content)} characters{Style.RESET_ALL}\")\n        start_time = time.time()\n        prompt = self._build_analysis_prompt(content)\n\n        try:\n            result = (\n                self._analyze_with_streaming_thinking(prompt)\n                if self.use_extended_thinking\n                else self._analyze_standard(prompt)\n            )\n            elapsed = time.time() - start_time\n            print(f\"\\n{Fore.GREEN}âœ… Analysis completed in {elapsed:.2f} seconds{Style.RESET_ALL}\")\n            print(f\"{Fore.CYAN}Generated {len(result.slides)} slides for '{result.title}'{Style.RESET_ALL}\")\n            self._merge_blocks_into_content(result)\n            return result\n        except Exception as e:\n            elapsed = time.time() - start_time\n            print(f\"\\n{Fore.RED}âŒ Analysis failed after {elapsed:.2f} seconds: {str(e)}{Style.RESET_ALL}\")\n            logger.error(f\"Error analyzing content: {e}\")\n            raise\n\n    def _merge_blocks_into_content(self, presentation: Presentation):\n        for slide in presentation.slides:\n            lines = []\n            if hasattr(slide, 'blocks') and slide.blocks:\n                for block in slide.blocks:\n                    if block.get(\"type\") == \"bullets\":\n                        for item in block.get(\"items\", []):\n                            lines.append(f\"- {item.get('content', '')}\")\n                            for sub in item.get(\"sub_bullets\", []):\n                                lines.append(f\"  - {sub.get('content', '')}\")\n                    elif block.get(\"type\") == \"text\":\n                        lines.append(block.get(\"content\", \"\"))\n                    elif block.get(\"type\") == \"columns\":\n                        left = block.get(\"left\", \"\")\n                        right = block.get(\"right\", \"\")\n                        lines.append(f\"{left} | {right}\")\n            if lines:\n                slide.content = \"\\n\".join(lines)\n\n    def _analyze_standard(self, prompt: str) -> Presentation:\n        print(f\"{Fore.YELLOW}Sending request to Claude...{Style.RESET_ALL}\")\n        response = self.client.messages.create(\n            model=\"claude-3-7-sonnet-20250219\",\n            max_tokens=4096,\n            system=\"You are an expert presentation designer. Return only valid JSON.\",\n            messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        response_text = self._extract_text(response.content)\n        print(f\"{Fore.YELLOW}Parsing presentation data...{Style.RESET_ALL}\")\n        return self._parse_presentation(response_text)\n\n    def _analyze_with_streaming_thinking(self, prompt: str) -> Presentation:\n        thinking_log_path = \"thinking.log\"\n        print(f\"{Fore.YELLOW}Starting streaming session with Claude...{Style.RESET_ALL}\")\n        print(f\"{Fore.BLUE}Thinking logs will be saved to: {thinking_log_path}{Style.RESET_ALL}\")\n        response_text = \"\"\n        thinking_chars = 0\n        response_chars = 0\n\n        with open(thinking_log_path, \"w\") as log_file:\n            with self.client.messages.stream(\n                model=\"claude-3-7-sonnet-20250219\",\n                max_tokens=20000,\n                thinking={\"type\": \"enabled\", \"budget_tokens\": 1024},\n                system=\"You are an expert presentation designer. Return only valid JSON.\",\n                messages=[{\"role\": \"user\", \"content\": prompt}]\n            ) as stream:\n                print(f\"\\n{Fore.CYAN}ðŸ”„ Claude is thinking...{Style.RESET_ALL}\\n\")\n                for event in stream:\n                    if event.type == \"content_block_delta\" and isinstance(event, ContentBlockDeltaEvent):\n                        if getattr(event.delta, \"type\", \"\") == \"thinking_delta\":\n                            thinking = getattr(event.delta, \"thinking\", \"\")\n                            thinking_chars += len(thinking)\n                            print(f\"{Fore.YELLOW}ðŸ§  {thinking}{Style.RESET_ALL}\", end=\"\", flush=True)\n                            log_file.write(thinking)\n                        elif getattr(event.delta, \"type\", \"\") == \"text_delta\":\n                            delta_text = event.delta.text\n                            response_chars += len(delta_text)\n                            print(f\"{Fore.GREEN}{delta_text}{Style.RESET_ALL}\", end=\"\", flush=True)\n                            response_text += delta_text\n        print(f\"\\n{Fore.YELLOW}Received {response_chars} chars of output and {thinking_chars} chars of thinking{Style.RESET_ALL}\")\n        print(f\"{Fore.YELLOW}Parsing presentation data...{Style.RESET_ALL}\")\n        return self._parse_presentation(response_text)\n\n    def _parse_presentation(self, text: str) -> Presentation:\n        try:\n            data = self._extract_json(text)\n            return Presentation.from_dict(data)\n        except Exception as e:\n            print(f\"{Fore.RED}âŒ Error parsing presentation: {str(e)}{Style.RESET_ALL}\")\n            raise\n\n    def _extract_text(self, content: list) -> str:\n        for block in content:\n            if block.type == \"text\":\n                return block.text\n        raise ValueError(\"No text block found in response.\")\n\n    def _extract_json(self, text: str) -> Dict[str, Any]:\n        pattern = r'```(?:json)?\\s*([\\s\\S]*?)\\s*```'\n        match = re.search(pattern, text)\n        if match:\n            try:\n                return json.loads(match.group(1))\n            except json.JSONDecodeError:\n                pass\n        return json.loads(text)\n\n    def refine(self, presentation: Presentation) -> Presentation:\n        return presentation\n\n    def _build_analysis_prompt(self, content: str) -> str:\n        return f\"\"\"Please analyze the following content and create a comprehensive presentation structure.\n\nThe presentation should include:\n1. An appropriate title\n2. Section headers\n3. Logical flow of slides\n4. Appropriate layout for each slide\n5. Rich content: text, bullet points, visual suggestions\n\nCONTENT:\n{content}\n\nReturn JSON:\n{{\n  \"title\": \"...\",\n  \"author\": \"...\",\n  \"slides\": [\n    {{\n      \"title\": \"...\",\n      \"content\": \"...\",  // This field is required!\n      \"layout\": \"TITLE_AND_CONTENT\",\n      \"blocks\": [\n        {{\n          \"type\": \"bullets\",\n          \"items\": [{{\"content\": \"...\", \"sub_bullets\": [{{\"content\": \"...\"}}]}}]\n        }},\n        {{\n          \"type\": \"image\",\n          \"source\": \"https://example.com/image.jpg\",\n          \"caption\": \"...\",\n          \"position\": {{\"horizontal\": \"CENTER\", \"vertical\": \"MIDDLE\"}}\n        }}\n      ],\n      \"notes\": \"...\"\n    }}\n  ]\n}}\n\nIMPORTANT: Each slide MUST include a 'content' field that contains the main text content for the slide.\nValid layouts: TITLE_ONLY, SECTION_HEADER, TWO_COLUMNS, COMPARISON, BIG_NUMBER, QUOTE, IMAGE_ONLY, IMAGE_WITH_CAPTION, BLANK.\n\"\"\""
          },
          {
            "file_name": "renderer_service.py",
            "file_size": 5085,
            "file_type": "",
            "extracted_content": "import logging\nfrom typing import Dict, Any, Optional\nfrom ..domain.models import Presentation\nfrom ..renderers.factory import create_renderer\n\nlogger = logging.getLogger(__name__)\n\nclass RendererService:\n    \"\"\"Service for rendering presentations\"\"\"\n    \n    def render_presentation(\n        self,\n        presentation: Presentation,\n        output_format: str,\n        output_path: str,\n        template_path: Optional[str] = None,\n        theme: Optional[Dict[str, Any]] = None\n    ) -> Dict[str, Any]:\n        \"\"\"Render a presentation to the specified format\"\"\"\n        try:\n            # Create renderer\n            renderer = create_renderer(\n                output_format=output_format,\n                template_path=template_path,\n                theme=theme\n            )\n            \n            # Convert domain model to dictionary\n            presentation_dict = self._presentation_to_dict(presentation)\n            \n            # Render presentation\n            logger.info(f\"Rendering presentation to {output_format}...\")\n            result = renderer.render(presentation_dict, output_path)\n            \n            if not result:\n                return {\"success\": False, \"error\": f\"Failed to render {output_format} presentation\"}\n            \n            return {\n                \"success\": True,\n                \"output_path\": output_path,\n                \"output_format\": output_format,\n                \"presentation_url\": result if isinstance(result, str) else None\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error rendering presentation: {e}\")\n            return {\"success\": False, \"error\": str(e)}\n    \n    def _presentation_to_dict(self, presentation: Presentation) -> Dict[str, Any]:\n        \"\"\"Convert a Presentation object to a dictionary for renderer compatibility - FIXED\"\"\"\n        try:\n            # Try Pydantic methods first\n            if hasattr(presentation, \"model_dump\"):\n                return presentation.model_dump()\n            elif hasattr(presentation, \"dict\"):\n                return presentation.dict()\n            \n            # Manual conversion as fallback\n            presentation_dict = {\n                \"title\": getattr(presentation, 'title', 'Presentation'),\n                \"author\": getattr(presentation, 'author', None),\n                \"slides\": []\n            }\n            \n            # Convert slides\n            slides = getattr(presentation, 'slides', [])\n            for i, slide in enumerate(slides):\n                slide_dict = {\n                    \"slide_number\": getattr(slide, 'slide_number', i + 1),\n                    \"title\": getattr(slide, 'title', ''),\n                    \"content\": getattr(slide, 'content', ''),\n                    \"layout\": getattr(slide, 'layout', 'TITLE_AND_CONTENT'),\n                    \"notes\": getattr(slide, 'notes', ''),\n                    \"facilitator_notes\": getattr(slide, 'facilitator_notes', getattr(slide, 'notes', ''))\n                }\n                \n                # Add optional fields that might exist\n                optional_fields = [\n                    'subtitle', 'image_url', 'image_description', 'diagram_type', \n                    'diagram_content', 'chart_type', 'blocks', 'start_time', \n                    'end_time', 'materials', 'worksheet', 'improvements',\n                    'local_image_path', 'local_diagram_path'\n                ]\n                \n                for field in optional_fields:\n                    if hasattr(slide, field):\n                        try:\n                            value = getattr(slide, field)\n                            if value is not None:\n                                slide_dict[field] = value\n                        except:\n                            pass  # Skip if attribute can't be accessed\n                \n                # Handle extra attributes from JSON\n                if hasattr(slide, '__dict__'):\n                    for key, value in slide.__dict__.items():\n                        if (not key.startswith('_') and \n                            key not in slide_dict and\n                            isinstance(value, (str, int, float, bool, list, dict, type(None)))):\n                            slide_dict[key] = value\n                \n                presentation_dict[\"slides\"].append(slide_dict)\n            \n            return presentation_dict\n            \n        except Exception as e:\n            logger.error(f\"Error converting presentation to dict: {e}\")\n            # Return minimal fallback structure\n            return {\n                \"title\": \"Error Processing Presentation\",\n                \"author\": None,\n                \"slides\": [\n                    {\n                        \"slide_number\": 1,\n                        \"title\": \"Processing Error\",\n                        \"content\": f\"Failed to convert presentation: {str(e)}\",\n                        \"layout\": \"TITLE_AND_CONTENT\",\n                        \"notes\": \"\",\n                        \"facilitator_notes\": \"\"\n                    }\n                ]\n            }"
          },
          {
            "file_name": "review_service.py",
            "file_size": 1279,
            "file_type": "",
            "extracted_content": "import logging\nimport os\nfrom typing import Dict, Any, Optional\nfrom ..domain.interfaces import ReviewerInterface\n\nlogger = logging.getLogger(__name__)\n\nclass PresentationReviewer(ReviewerInterface):\n    \"\"\"Service for reviewing presentations\"\"\"\n    \n    def __init__(self, api_key: Optional[str] = None):\n        \"\"\"Initialize the presentation reviewer\"\"\"\n        self.api_key = api_key or os.environ.get(\"ANTHROPIC_API_KEY\")\n        if not self.api_key:\n            raise ValueError(\"Anthropic API key not provided and ANTHROPIC_API_KEY environment variable not set\")\n    \n    def review(self, presentation_path: str) -> Dict[str, Any]:\n        \"\"\"Review a presentation and provide feedback\"\"\"\n        try:\n            # Import the visual reviewer\n            from ..review.visual_reviewer import VisualReviewer\n            \n            # Create reviewer\n            reviewer = VisualReviewer(api_key=self.api_key)\n            \n            # Review the presentation\n            review_results = reviewer.review_pptx(presentation_path)\n            \n            return review_results\n        except Exception as e:\n            logger.error(f\"Error reviewing presentation: {e}\")\n            return {\n                \"success\": False,\n                \"error\": str(e)\n            }\n"
          },
          {
            "file_name": "__init__.py",
            "file_size": 0,
            "file_type": "",
            "extracted_content": ""
          },
          {
            "file_name": "builder.py",
            "file_size": 17336,
            "file_type": "",
            "extracted_content": "#!/usr/bin/env python3\n\"\"\"Create Google Slides from markdown using md2gslides.\n\nThis script takes markdown files generated from JSON slides data and\nuses the md2gslides npm package to create Google Slides presentations.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, subprocess, tempfile\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any\nimport re\nimport shutil\n\nLOGGER = logging.getLogger(\"build_with_md2gslides\")\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Generate Google Slides from markdown\")\n    p.add_argument(\"markdown\", help=\"Markdown file or directory of markdown files\")\n    p.add_argument(\"--title-prefix\", default=\"\", help=\"Prefix for presentation titles\")\n    p.add_argument(\"--style\", default=\"github\", help=\"Syntax highlighting style\")\n    p.add_argument(\"--use-fileio\", action=\"store_true\", help=\"Allow uploading to file.io for images\")\n    p.add_argument(\"--output-file\", default=None, help=\"File to save presentation URLs\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    p.add_argument(\"--debug\", action=\"store_true\", help=\"Show debug info and display markdown before sending\")\n    p.add_argument(\"--append\", default=None, help=\"Append to existing presentation ID\")\n    p.add_argument(\"--erase\", action=\"store_true\", help=\"Erase existing slides when using --append\")\n    p.add_argument(\"--verify-npm\", action=\"store_true\", help=\"Verify npm and md2gslides are installed\")\n    p.add_argument(\"--fix-format\", action=\"store_true\", help=\"Fix common markdown formatting issues\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef verify_installation() -> bool:\n    \"\"\"Verify that npm and md2gslides are installed.\"\"\"\n    try:\n        npm_version = subprocess.run([\"npm\", \"--version\"], capture_output=True, check=True, text=True)\n        LOGGER.info(f\"npm version: {npm_version.stdout.strip()}\")\n        \n        # Try to install md2gslides if not already installed\n        try:\n            result = subprocess.run([\"md2gslides\", \"--version\"], capture_output=True, text=True)\n            LOGGER.info(f\"md2gslides version: {result.stdout.strip()}\")\n        except (subprocess.CalledProcessError, FileNotFoundError):\n            LOGGER.warning(\"md2gslides not found, attempting to install it...\")\n            try:\n                install_result = subprocess.run([\"npm\", \"install\", \"-g\", \"md2gslides\"], \n                                               capture_output=True, check=True, text=True)\n                LOGGER.info(\"md2gslides installed successfully\")\n            except subprocess.CalledProcessError as e:\n                LOGGER.error(f\"Failed to install md2gslides: {e.stderr}\")\n                return False\n        \n        # Check for client_id.json\n        home_dir = Path.home()\n        client_id_path = home_dir / \".md2googleslides\" / \"client_id.json\"\n        if not client_id_path.exists():\n            LOGGER.warning(\"client_id.json not found at ~/.md2googleslides/client_id.json\")\n            LOGGER.warning(\"You may need to set up Google API credentials.\")\n            LOGGER.warning(\"See: https://github.com/googleworkspace/md2googleslides#installation-and-usage\")\n            \n            # Create the directory if it doesn't exist\n            client_id_dir = client_id_path.parent\n            client_id_dir.mkdir(parents=True, exist_ok=True)\n            \n            LOGGER.warning(f\"Directory created at {client_id_dir}\")\n            LOGGER.warning(\"Please follow these steps to set up Google API credentials:\")\n            LOGGER.warning(\"1. Go to https://console.developers.google.com\")\n            LOGGER.warning(\"2. Create a new project or select an existing one\")\n            LOGGER.warning(\"3. Enable the Google Slides API in the API Library\")\n            LOGGER.warning(\"4. Go to Credentials page and click '+ Create credentials'\")\n            LOGGER.warning(\"5. Select 'OAuth client ID' and 'Desktop Application'\")\n            LOGGER.warning(f\"6. Download the JSON file and save it as 'client_id.json' in {client_id_dir}\")\n        \n        return True\n    \n    except subprocess.CalledProcessError as e:\n        LOGGER.error(f\"Error checking installation: {e}\")\n        return False\n    \n    except FileNotFoundError:\n        LOGGER.error(\"npm not found. Please install Node.js and npm first.\")\n        return False\n\n\ndef fix_markdown_format(content: str) -> str:\n    \"\"\"Fix common markdown formatting issues that cause md2gslides to fail.\"\"\"\n    # Ensure proper slide separators\n    if \"---\" not in content:\n        LOGGER.info(\"Adding slide separators to markdown\")\n        lines = content.split(\"\\n\")\n        fixed_lines = []\n        \n        # Add separator before each heading if missing\n        in_first_slide = True\n        for i, line in enumerate(lines):\n            if line.startswith(\"#\") and not in_first_slide:\n                if i > 0 and not lines[i-1].startswith(\"---\"):\n                    fixed_lines.append(\"---\")\n            elif line.startswith(\"#\"):\n                in_first_slide = False\n                \n            fixed_lines.append(line)\n        \n        content = \"\\n\".join(fixed_lines)\n    \n    # Ensure each slide has a title (header)\n    sections = content.split(\"---\")\n    fixed_sections = []\n    \n    for i, section in enumerate(sections):\n        section = section.strip()\n        if section and not re.search(r'^#\\s+.+', section, re.MULTILINE):\n            LOGGER.info(f\"Adding missing header to slide {i+1}\")\n            section = f\"# Slide {i+1}\\n\\n{section}\"\n        \n        fixed_sections.append(section)\n    \n    fixed_content = \"---\\n\\n\".join(fixed_sections)\n    if not fixed_content.startswith(\"---\"):\n        fixed_content = fixed_content.lstrip(\"---\").strip()\n    \n    # Fix image paths\n    # Just a placeholder, add specific image path fixing if needed\n    \n    return fixed_content\n\n\ndef validate_markdown(markdown_path: Path, debug: bool = False, fix_format: bool = False) -> bool:\n    \"\"\"Validate markdown file for compatibility with md2gslides.\"\"\"\n    try:\n        content = markdown_path.read_text(encoding=\"utf-8\")\n        \n        # Check for common issues\n        if not content.strip():\n            LOGGER.error(f\"{markdown_path} is empty\")\n            return False\n        \n        needs_fixing = False\n        \n        # Check for slide separators\n        if \"---\" not in content and content.strip().count(\"\\n\") > 5:\n            LOGGER.warning(f\"{markdown_path} is missing slide separators (---)\")\n            needs_fixing = True\n        \n        # Check for headers\n        if not re.search(r'^#\\s+.+', content, re.MULTILINE):\n            LOGGER.warning(f\"{markdown_path} is missing slide headers (# Title)\")\n            needs_fixing = True\n        \n        # Check for image paths\n        image_paths = re.findall(r'!\\[.*?\\]\\((.*?)\\)', content)\n        for path in image_paths:\n            if path.startswith(\"http\"):\n                continue\n                \n            img_path = Path(path)\n            if not img_path.is_absolute():\n                # Try relative to the markdown file\n                img_path = markdown_path.parent / img_path\n                \n            if not img_path.exists():\n                LOGGER.warning(f\"Image path may be invalid: {path}\")\n        \n        # Fix markdown if requested and needed\n        if fix_format and needs_fixing:\n            LOGGER.info(f\"Fixing markdown format for {markdown_path}\")\n            fixed_content = fix_markdown_format(content)\n            \n            # Create backup of original file\n            backup_path = markdown_path.with_suffix(\".md.bak\")\n            shutil.copy2(markdown_path, backup_path)\n            LOGGER.info(f\"Created backup of original markdown at {backup_path}\")\n            \n            # Write fixed content\n            markdown_path.write_text(fixed_content, encoding=\"utf-8\")\n            content = fixed_content\n            LOGGER.info(f\"Fixed markdown formatting in {markdown_path}\")\n        \n        if debug:\n            LOGGER.info(f\"\\n---- Markdown Content ----\\n{content}\\n-------------------------\")\n            # Don't prompt for input to allow for automation\n            LOGGER.info(\"Continuing with md2gslides automatically...\")\n        \n        return True\n        \n    except Exception as e:\n        LOGGER.error(f\"Error validating markdown {markdown_path}: {e}\")\n        return False\n\n\ndef run_md2gslides(markdown_path: Path, title_prefix: str = \"\", style: str = \"github\", \n                 use_fileio: bool = False, append_id: Optional[str] = None, \n                 erase: bool = False, debug: bool = False) -> Optional[str]:\n    \"\"\"Run md2gslides to create a Google Slides presentation.\"\"\"\n    \n    # Validate the markdown\n    if not validate_markdown(markdown_path, debug):\n        return None\n    \n    # Build the command\n    cmd = [\"md2gslides\"]\n    \n    # Ensure md2gslides command exists\n    try:\n        # Check if md2gslides is in PATH\n        md2gslides_path = shutil.which(\"md2gslides\")\n        if md2gslides_path:\n            cmd = [md2gslides_path]\n        else:\n            # Try global npm installation\n            cmd = [\"npx\", \"md2gslides\"]\n    except Exception as e:\n        LOGGER.error(f\"Error finding md2gslides command: {e}\")\n        return None\n    \n    # Add the title\n    title = f\"{title_prefix}{markdown_path.stem}\"\n    cmd.extend([\"--title\", title])\n    \n    # Add optional arguments\n    if style:\n        cmd.extend([\"--style\", style])\n    \n    if use_fileio:\n        cmd.append(\"--use-fileio\")\n    \n    if append_id:\n        cmd.extend([\"--append\", append_id])\n        \n        if erase:\n            cmd.append(\"--erase\")\n    \n    # Add the markdown file\n    cmd.append(str(markdown_path))\n    \n    # Run the command\n    LOGGER.info(f\"Running command: {' '.join(cmd)}\")\n    try:\n        # Create a temporary file to capture the output\n        with tempfile.NamedTemporaryFile(mode='w+', encoding='utf-8', delete=False) as tmp:\n            result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n            \n            # Parse the output to get the URL\n            for line in result.stdout.splitlines():\n                if \"https://docs.google.com/presentation\" in line:\n                    url = line.strip()\n                    LOGGER.info(f\"Created presentation: {url}\")\n                    return url\n            \n            # If we can't find a URL, write the output to a file and return None\n            tmp.write(result.stdout)\n            LOGGER.warning(f\"Could not find presentation URL in output. Output saved to {tmp.name}\")\n            if debug:\n                LOGGER.info(f\"Output:\\n{result.stdout}\")\n            \n            return None\n        \n    except subprocess.CalledProcessError as e:\n        LOGGER.error(f\"Error running md2gslides: {e}\")\n        LOGGER.error(f\"stdout: {e.stdout}\")\n        LOGGER.error(f\"stderr: {e.stderr}\")\n        \n        # Try to extract useful error messages\n        error_lines = e.stderr.splitlines()\n        for line in error_lines:\n            if \"Error:\" in line or \"TypeError:\" in line or \"SyntaxError:\" in line:\n                LOGGER.error(f\"Error message: {line}\")\n        \n        return None\n\n\ndef process_markdown_file(markdown_path: Path, title_prefix: str = \"\", style: str = \"github\", \n                       use_fileio: bool = False, output_file: Optional[Path] = None,\n                       append_id: Optional[str] = None, erase: bool = False,\n                       debug: bool = False, fix_format: bool = False) -> Optional[str]:\n    \"\"\"Process a single markdown file.\"\"\"\n    LOGGER.info(f\"Processing markdown file: {markdown_path}\")\n    \n    # Validate and potentially fix the markdown\n    if not validate_markdown(markdown_path, debug, fix_format):\n        LOGGER.error(f\"Markdown validation failed for {markdown_path}\")\n        return None\n    \n    # Run md2gslides\n    url = run_md2gslides(markdown_path, title_prefix, style, use_fileio, append_id, erase, debug)\n    \n    # Save the URL to the output file\n    if url and output_file:\n        try:\n            with open(output_file, 'a', encoding='utf-8') as f:\n                f.write(f\"{markdown_path.stem}: {url}\\n\")\n        except Exception as e:\n            LOGGER.error(f\"Error writing to output file {output_file}: {e}\")\n    \n    return url\n\n\ndef process_directory(markdown_dir: Path, title_prefix: str = \"\", style: str = \"github\", \n                    use_fileio: bool = False, output_file: Optional[Path] = None,\n                    append_id: Optional[str] = None, erase: bool = False,\n                    debug: bool = False, fix_format: bool = False) -> List[str]:\n    \"\"\"Process all markdown files in a directory.\"\"\"\n    LOGGER.info(f\"Processing all markdown files in {markdown_dir}\")\n    \n    # Find all markdown files\n    markdown_files = list(markdown_dir.glob(\"*.md\"))\n    if not markdown_files:\n        LOGGER.error(f\"No markdown files found in {markdown_dir}\")\n        return []\n    \n    LOGGER.info(f\"Found {len(markdown_files)} markdown files to process\")\n    \n    # Process each file\n    results = []\n    for markdown_path in sorted(markdown_files):\n        try:\n            url = process_markdown_file(\n                markdown_path, title_prefix, style, use_fileio, \n                output_file, append_id, erase, debug, fix_format\n            )\n            if url:\n                results.append(url)\n        except Exception as e:\n            LOGGER.error(f\"Failed to process {markdown_path}: {e}\")\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Verify installation if requested\n    if args.verify_npm:\n        if not verify_installation():\n            LOGGER.error(\"Installation verification failed. Please install Node.js, npm, and md2gslides.\")\n            LOGGER.info(\"To install md2gslides: npm install -g md2gslides\")\n            sys.exit(1)\n    \n    # Validate the path\n    markdown_path = Path(args.markdown)\n    if not markdown_path.exists():\n        LOGGER.error(f\"{markdown_path} not found\")\n        \n        # Check if there's a file with slides_ prefix\n        parent_dir = markdown_path.parent\n        basename = markdown_path.stem\n        \n        # Try with slides_ prefix\n        alt_path = parent_dir / f\"slides_{basename}.md\"\n        if alt_path.exists():\n            LOGGER.info(f\"Found alternative path: {alt_path}\")\n            markdown_path = alt_path\n        else:\n            # Look for any markdown file with similar name\n            potential_files = list(parent_dir.glob(f\"*{basename}*.md\"))\n            if potential_files:\n                LOGGER.info(f\"Found potential alternatives: {[p.name for p in potential_files]}\")\n                markdown_path = potential_files[0]\n                LOGGER.info(f\"Using {markdown_path}\")\n            else:\n                LOGGER.error(\"No alternative markdown files found\")\n                sys.exit(1)\n    \n    # Determine output file\n    output_file = Path(args.output_file) if args.output_file else None\n    \n    # If output file is specified, clear it\n    if output_file:\n        try:\n            output_file.parent.mkdir(parents=True, exist_ok=True)\n            with open(output_file, 'w', encoding='utf-8') as f:\n                f.write(f\"Presentations generated from {markdown_path}\\n\")\n        except Exception as e:\n            LOGGER.error(f\"Error creating output file {output_file}: {e}\")\n            output_file = None\n    \n    # Process files\n    try:\n        if markdown_path.is_dir():\n            results = process_directory(\n                markdown_path, args.title_prefix, args.style, args.use_fileio, \n                output_file, args.append, args.erase, args.debug, args.fix_format\n            )\n            if results:\n                LOGGER.info(f\"Created {len(results)} presentations\")\n                if output_file:\n                    LOGGER.info(f\"Presentation URLs saved to {output_file}\")\n            else:\n                LOGGER.warning(\"No presentations were created\")\n                sys.exit(1)\n        else:\n            url = process_markdown_file(\n                markdown_path, args.title_prefix, args.style, args.use_fileio, \n                output_file, args.append, args.erase, args.debug, args.fix_format\n            )\n            if not url:\n                LOGGER.error(\"Failed to create presentation\")\n                sys.exit(1)\n    except Exception as e:\n        LOGGER.error(f\"Processing failed: {e}\", exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n\ndef build(markdown_path: Path, mode: str = \"gslides\", **kwargs):\n    \"\"\"Build slides. mode='gslides' (default) uses md2gslides; mode='pptx' uses python-pptx.\"\"\"\n    if mode == \"pptx\":\n        from .pptx_builder import build_pptx\n        return build_pptx(markdown_path, kwargs.get(\"out\"))\n    else:\n        # fallback to existing md2gslides run\n        return run_md2gslides(markdown_path, kwargs.get(\"title\"))\n"
          },
          {
            "file_name": "pptx_builder.py",
            "file_size": 2206,
            "file_type": "",
            "extracted_content": "from pathlib import Path\nfrom pptx import Presentation\nfrom pptx.util import Inches, Pt\nfrom pptx.enum.text import PP_ALIGN\nfrom markdown import markdown\nfrom bs4 import BeautifulSoup\n\ndef md_to_html(md_text: str) -> str:\n    return markdown(md_text, extensions=[\"fenced_code\", \"tables\", \"nl2br\"])\n\ndef add_text_slide(prs, title, html, layout_idx=1):\n    slide_layout = prs.slide_layouts[layout_idx]\n    slide = prs.slides.add_slide(slide_layout)\n    title_placeholder = slide.shapes.title\n    body_placeholder = slide.shapes.placeholders[1]\n\n    title_placeholder.text = title\n    tf = body_placeholder.text_frame\n    tf.word_wrap = True\n\n    soup = BeautifulSoup(html, \"html.parser\")\n    tf.clear()\n    for p in soup.find_all(\"p\"):\n        para = tf.add_paragraph()\n        para.text = p.get_text(\" \", strip=True)\n        para.font.size = Pt(18)\n        para.level = 0\n\ndef add_image_slide(prs, title, img_path, layout_idx=5):\n    slide_layout = prs.slide_layouts[layout_idx]\n    slide = prs.slides.add_slide(slide_layout)\n    slide.shapes.title.text = title\n    left = Inches(1)\n    top = Inches(1.5)\n    slide.shapes.add_picture(img_path, left, top, width=Inches(8))\n\ndef build_pptx(markdown_path: Path, pptx_path: Path):\n    prs = Presentation()\n    current_title = \"Untitled\"\n    slide_md = []\n    for line in markdown_path.read_text().splitlines():\n        if line.startswith(\"# \"):\n            if slide_md:\n                add_text_slide(prs, current_title, md_to_html(\"\\\\n\".join(slide_md)))\n                slide_md = []\n            current_title = line.lstrip(\"# \").strip()\n        elif line.startswith(\"![](\"):\n            img = line.split(\"(\", 1)[1].rstrip(\")\")\n            add_image_slide(prs, current_title, img)\n            slide_md = []\n        else:\n            slide_md.append(line)\n    if slide_md:\n        add_text_slide(prs, current_title, md_to_html(\"\\\\n\".join(slide_md)))\n    prs.save(pptx_path)\n    print(f\"âœ… Wrote {pptx_path}\")\n\ndef cli_entry():\n    import argparse\n    p = argparse.ArgumentParser()\n    p.add_argument(\"markdown\", type=str)\n    p.add_argument(\"--out\", type=str, default=\"slides.pptx\")\n    args = p.parse_args()\n    build_pptx(Path(args.markdown), Path(args.out))"
          },
          {
            "file_name": "__init__.py",
            "file_size": 0,
            "file_type": "",
            "extracted_content": ""
          },
          {
            "file_name": "asset_manager.py",
            "file_size": 22207,
            "file_type": "",
            "extracted_content": "# /makeslides/assets/asset_manager.py\n#!/usr/bin/env python3\n\"\"\"\nAsset Manager for MakeSlides\n\nThis script provides centralized management for all assets (images, diagrams)\nused in the slide creation process. It maintains a cache of assets to avoid\nredundant downloads and generation.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, shutil, hashlib\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Tuple\nimport requests\nimport time\n\nLOGGER = logging.getLogger(\"asset_manager\")\n\n# Default paths\nDEFAULT_CACHE_DIR = Path.home() / \".makeslides\" / \"assets\"\nDEFAULT_CACHE_FILE = DEFAULT_CACHE_DIR / \"asset_cache.json\"\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Manage assets for MakeSlides\")\n    \n    # Command subparsers\n    subparsers = p.add_subparsers(dest=\"command\", help=\"Command to execute\")\n    \n    # Get image command\n    get_img = subparsers.add_parser(\"get-image\", help=\"Get or cache an image\")\n    get_img.add_argument(\"url\", help=\"URL of the image to get\")\n    get_img.add_argument(\"--category\", help=\"Category for the image (e.g., 'solar', 'training')\")\n    get_img.add_argument(\"--local-path\", help=\"Optional local path to store/copy the image\")\n    \n    # Get diagram command\n    get_diag = subparsers.add_parser(\"get-diagram\", help=\"Get or cache a diagram\")\n    get_diag.add_argument(\"content\", help=\"Mermaid content of the diagram\")\n    get_diag.add_argument(\"--type\", default=\"flowchart\", help=\"Type of diagram\")\n    get_diag.add_argument(\"--local-path\", help=\"Optional local path to store the diagram\")\n    \n    # List assets command\n    list_cmd = subparsers.add_parser(\"list\", help=\"List all cached assets\")\n    list_cmd.add_argument(\"--category\", help=\"Filter by category\")\n    list_cmd.add_argument(\"--type\", help=\"Filter by asset type (image/diagram)\")\n    \n    # Clean cache command\n    clean_cmd = subparsers.add_parser(\"clean\", help=\"Clean the asset cache\")\n    clean_cmd.add_argument(\"--remove-unused\", action=\"store_true\", help=\"Remove unused assets\")\n    clean_cmd.add_argument(\"--days\", type=int, default=30, help=\"Remove assets older than X days\")\n    \n    # Update JSON command\n    update_cmd = subparsers.add_parser(\"update-json\", help=\"Update JSON files with asset paths\")\n    update_cmd.add_argument(\"json_file\", help=\"JSON file to update\")\n    update_cmd.add_argument(\"--output\", help=\"Output file (default: overwrite input)\")\n    \n    # Common arguments\n    p.add_argument(\"--cache-dir\", default=DEFAULT_CACHE_DIR, help=\"Cache directory\")\n    p.add_argument(\"--cache-file\", default=DEFAULT_CACHE_FILE, help=\"Cache file\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    \n    return p.parse_args()\n\ndef setup_logging(level: str):\n    \"\"\"Configure logging.\"\"\"\n    logging.basicConfig(\n        level=getattr(logging, level),\n        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n        handlers=[logging.StreamHandler(sys.stdout)]\n    )\n\nclass AssetManager:\n    \"\"\"Manages assets (images, diagrams) for slide creation.\"\"\"\n    \n    def __init__(self, cache_dir: Path, cache_file: Path):\n        \"\"\"Initialize the asset manager.\n        \n        Args:\n            cache_dir: Directory to store cached assets\n            cache_file: File to store cache metadata\n        \"\"\"\n        self.cache_dir = cache_dir\n        self.images_dir = cache_dir / \"images\"\n        self.diagrams_dir = cache_dir / \"diagrams\"\n        self.cache_file = cache_file\n        \n        # Create directories if they don't exist\n        self.cache_dir.mkdir(parents=True, exist_ok=True)\n        self.images_dir.mkdir(exist_ok=True)\n        self.diagrams_dir.mkdir(exist_ok=True)\n        \n        # Load cache\n        self.cache = self._load_cache()\n    \n    def _load_cache(self) -> Dict[str, Any]:\n        \"\"\"Load the asset cache from disk.\"\"\"\n        if not self.cache_file.exists():\n            LOGGER.info(f\"Cache file not found at {self.cache_file}. Creating new cache.\")\n            return {\n                \"images\": {},\n                \"diagrams\": {},\n                \"last_updated\": time.time()\n            }\n        \n        try:\n            with open(self.cache_file, 'r') as f:\n                cache = json.load(f)\n            LOGGER.debug(f\"Loaded cache with {len(cache.get('images', {}))} images and {len(cache.get('diagrams', {}))} diagrams\")\n            return cache\n        except Exception as e:\n            LOGGER.warning(f\"Error loading cache: {e}. Creating new cache.\")\n            return {\n                \"images\": {},\n                \"diagrams\": {},\n                \"last_updated\": time.time()\n            }\n    \n    def _save_cache(self):\n        \"\"\"Save the asset cache to disk.\"\"\"\n        self.cache[\"last_updated\"] = time.time()\n        try:\n            with open(self.cache_file, 'w') as f:\n                json.dump(self.cache, f, indent=2)\n            LOGGER.debug(f\"Saved cache to {self.cache_file}\")\n        except Exception as e:\n            LOGGER.error(f\"Error saving cache: {e}\")\n    \n    def get_image(self, url: str, category: Optional[str] = None, local_path: Optional[Path] = None) -> Path:\n        \"\"\"Get or cache an image.\n        \n        Args:\n            url: URL of the image\n            category: Category for the image (e.g., 'solar', 'training')\n            local_path: Optional local path to store/copy the image\n            \n        Returns:\n            Path to the cached image\n        \"\"\"\n        # Generate a hash for the URL\n        url_hash = hashlib.md5(url.encode()).hexdigest()[:10]\n        \n        # Check if image is already in cache\n        if url in self.cache[\"images\"]:\n            cached_path = Path(self.cache[\"images\"][url][\"path\"])\n            if cached_path.exists():\n                LOGGER.info(f\"Using cached image for {url}\")\n                \n                # If local_path is provided, copy the image\n                if local_path:\n                    local_path = Path(local_path)\n                    local_path.parent.mkdir(parents=True, exist_ok=True)\n                    shutil.copy2(cached_path, local_path)\n                    LOGGER.debug(f\"Copied cached image to {local_path}\")\n                    return local_path\n                \n                return cached_path\n        \n        # Image not in cache or file missing, download it\n        LOGGER.info(f\"Downloading image from {url}\")\n        \n        try:\n            # Determine file extension from URL\n            ext = Path(url).suffix\n            if not ext:\n                ext = \".jpg\"  # Default to jpg if no extension\n            \n            # Create filename and path\n            filename = f\"img_{url_hash}{ext}\"\n            img_path = self.images_dir / filename\n            \n            # Download the image\n            response = requests.get(url, stream=True, timeout=10)\n            response.raise_for_status()\n            \n            with open(img_path, 'wb') as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    f.write(chunk)\n            \n            # Update cache\n            self.cache[\"images\"][url] = {\n                \"path\": str(img_path),\n                \"category\": category,\n                \"hash\": url_hash,\n                \"timestamp\": time.time()\n            }\n            self._save_cache()\n            \n            # If local_path is provided, copy the image\n            if local_path:\n                local_path = Path(local_path)\n                local_path.parent.mkdir(parents=True, exist_ok=True)\n                shutil.copy2(img_path, local_path)\n                LOGGER.debug(f\"Copied downloaded image to {local_path}\")\n                return local_path\n            \n            return img_path\n            \n        except Exception as e:\n            LOGGER.error(f\"Error downloading image from {url}: {e}\")\n            raise\n    \n    def get_diagram(self, content: str, diagram_type: str = \"flowchart\", local_path: Optional[Path] = None) -> Optional[Path]:\n        \"\"\"Get or cache a diagram.\n        \n        Args:\n            content: Mermaid content of the diagram\n            diagram_type: Type of diagram (e.g., 'flowchart', 'mindmap')\n            local_path: Optional local path to store the diagram\n            \n        Returns:\n            Path to the cached diagram or None if not found\n        \"\"\"\n        # Generate a hash for the content\n        content_hash = hashlib.md5(content.encode()).hexdigest()[:10]\n        \n        # Check if diagram is already in cache\n        if content_hash in self.cache[\"diagrams\"]:\n            cached_info = self.cache[\"diagrams\"][content_hash]\n            cached_path = Path(cached_info[\"path\"])\n            \n            if cached_path.exists():\n                LOGGER.info(f\"Using cached diagram for hash {content_hash}\")\n                \n                # If local_path is provided, copy the diagram\n                if local_path:\n                    local_path = Path(local_path)\n                    local_path.parent.mkdir(parents=True, exist_ok=True)\n                    shutil.copy2(cached_path, local_path)\n                    \n                    # Also copy SVG if it exists\n                    svg_path = cached_path.with_suffix(\".svg\")\n                    if svg_path.exists():\n                        local_svg_path = local_path.with_suffix(\".svg\")\n                        shutil.copy2(svg_path, local_svg_path)\n                        LOGGER.debug(f\"Copied cached SVG to {local_svg_path}\")\n                    \n                    LOGGER.debug(f\"Copied cached diagram to {local_path}\")\n                    return local_path\n                \n                return cached_path\n        \n        # If we're just checking and not generating, return None\n        if local_path is None:\n            LOGGER.info(f\"Diagram {content_hash} not found in cache\")\n            return None\n        \n        # If local_path is provided, assume it's a newly generated diagram we want to cache\n        if local_path:\n            local_path = Path(local_path)\n            if local_path.exists():\n                # Create cached copy\n                cached_filename = f\"diagram_{content_hash}{local_path.suffix}\"\n                cached_path = self.diagrams_dir / cached_filename\n                \n                # Copy to cache\n                shutil.copy2(local_path, cached_path)\n                LOGGER.info(f\"Cached new diagram as {cached_path}\")\n                \n                # Also copy SVG if it exists\n                local_svg_path = local_path.with_suffix(\".svg\")\n                if local_svg_path.exists():\n                    cached_svg_path = cached_path.with_suffix(\".svg\")\n                    shutil.copy2(local_svg_path, cached_svg_path)\n                    LOGGER.debug(f\"Cached SVG as {cached_svg_path}\")\n                \n                # Update cache\n                self.cache[\"diagrams\"][content_hash] = {\n                    \"path\": str(cached_path),\n                    \"type\": diagram_type,\n                    \"hash\": content_hash,\n                    \"timestamp\": time.time()\n                }\n                self._save_cache()\n                \n                return local_path\n        \n        LOGGER.error(f\"No local path provided for diagram {content_hash}\")\n        return None\n    \n    def list_assets(self, category: Optional[str] = None, asset_type: Optional[str] = None) -> Dict[str, List[Dict[str, Any]]]:\n        \"\"\"List all cached assets, optionally filtered by category or type.\n        \n        Args:\n            category: Filter by category\n            asset_type: Filter by asset type (image/diagram)\n            \n        Returns:\n            Dictionary with lists of assets\n        \"\"\"\n        result = {\"images\": [], \"diagrams\": []}\n        \n        # Filter images\n        if asset_type is None or asset_type == \"image\":\n            for url, info in self.cache[\"images\"].items():\n                if category is None or info.get(\"category\") == category:\n                    asset_path = Path(info[\"path\"])\n                    if asset_path.exists():\n                        result[\"images\"].append({\n                            \"url\": url,\n                            \"path\": info[\"path\"],\n                            \"category\": info.get(\"category\"),\n                            \"timestamp\": info.get(\"timestamp\", 0)\n                        })\n        \n        # Filter diagrams\n        if asset_type is None or asset_type == \"diagram\":\n            for content_hash, info in self.cache[\"diagrams\"].items():\n                asset_path = Path(info[\"path\"])\n                if asset_path.exists():\n                    result[\"diagrams\"].append({\n                        \"hash\": content_hash,\n                        \"path\": info[\"path\"],\n                        \"type\": info.get(\"type\"),\n                        \"timestamp\": info.get(\"timestamp\", 0)\n                    })\n        \n        return result\n    \n    def clean_cache(self, remove_unused: bool = False, days: int = 30) -> Tuple[int, int]:\n        \"\"\"Clean the asset cache.\n        \n        Args:\n            remove_unused: Whether to remove unused assets\n            days: Remove assets older than X days\n            \n        Returns:\n            Tuple of (images_removed, diagrams_removed)\n        \"\"\"\n        now = time.time()\n        threshold = now - (days * 86400)  # Convert days to seconds\n        \n        images_removed = 0\n        diagrams_removed = 0\n        \n        # Clean images\n        images_to_remove = []\n        for url, info in self.cache[\"images\"].items():\n            if remove_unused or info.get(\"timestamp\", 0) < threshold:\n                try:\n                    path = Path(info[\"path\"])\n                    if path.exists():\n                        path.unlink()\n                        images_removed += 1\n                    images_to_remove.append(url)\n                except Exception as e:\n                    LOGGER.warning(f\"Error removing image {url}: {e}\")\n        \n        # Remove from cache\n        for url in images_to_remove:\n            del self.cache[\"images\"][url]\n        \n        # Clean diagrams\n        diagrams_to_remove = []\n        for content_hash, info in self.cache[\"diagrams\"].items():\n            if remove_unused or info.get(\"timestamp\", 0) < threshold:\n                try:\n                    path = Path(info[\"path\"])\n                    if path.exists():\n                        path.unlink()\n                        # Also remove SVG if it exists\n                        svg_path = path.with_suffix(\".svg\")\n                        if svg_path.exists():\n                            svg_path.unlink()\n                        diagrams_removed += 1\n                    diagrams_to_remove.append(content_hash)\n                except Exception as e:\n                    LOGGER.warning(f\"Error removing diagram {content_hash}: {e}\")\n        \n        # Remove from cache\n        for content_hash in diagrams_to_remove:\n            del self.cache[\"diagrams\"][content_hash]\n        \n        # Save cache\n        self._save_cache()\n        \n        return images_removed, diagrams_removed\n    \n    def update_json(self, json_path: Path, output_path: Optional[Path] = None) -> int:\n        \"\"\"Update a slides JSON file with cached asset paths.\n        \n        Args:\n            json_path: Path to the JSON file\n            output_path: Optional output path (default: overwrite input)\n            \n        Returns:\n            Number of assets updated\n        \"\"\"\n        try:\n            with open(json_path, 'r') as f:\n                slides_data = json.load(f)\n        except Exception as e:\n            LOGGER.error(f\"Error loading JSON from {json_path}: {e}\")\n            return 0\n        \n        # Check if it's an object with a slides array\n        if isinstance(slides_data, dict) and \"slides\" in slides_data:\n            slides = slides_data[\"slides\"]\n        elif isinstance(slides_data, list):\n            slides = slides_data\n        else:\n            LOGGER.error(f\"Unexpected JSON structure in {json_path}\")\n            return 0\n        \n        assets_updated = 0\n        \n        # Update each slide\n        for slide in slides:\n            # Update image URLs\n            image_url = slide.get(\"image_url\")\n            if image_url and image_url.startswith(\"http\"):\n                try:\n                    # Check if the image is in the cache\n                    if image_url in self.cache[\"images\"]:\n                        cached_path = Path(self.cache[\"images\"][image_url][\"path\"])\n                        if cached_path.exists():\n                            # Use relative path from JSON file to cached image\n                            try:\n                                json_dir = json_path.parent\n                                rel_path = cached_path.relative_to(json_dir)\n                                slide[\"image_url\"] = str(rel_path)\n                                assets_updated += 1\n                                LOGGER.debug(f\"Updated image URL to {rel_path}\")\n                            except ValueError:\n                                # If the cached path is not relative to the JSON file,\n                                # download and cache it in the same directory\n                                new_path = json_dir / \"images\" / cached_path.name\n                                new_path.parent.mkdir(parents=True, exist_ok=True)\n                                shutil.copy2(cached_path, new_path)\n                                rel_path = new_path.relative_to(json_dir)\n                                slide[\"image_url\"] = str(rel_path)\n                                assets_updated += 1\n                                LOGGER.debug(f\"Copied image to {rel_path}\")\n                    else:\n                        # Download and cache the image\n                        img_dir = json_path.parent / \"images\"\n                        img_dir.mkdir(parents=True, exist_ok=True)\n                        img_file = img_dir / f\"img_{hashlib.md5(image_url.encode()).hexdigest()[:10]}.jpg\"\n                        cached_path = self.get_image(image_url, local_path=img_file)\n                        rel_path = cached_path.relative_to(json_path.parent)\n                        slide[\"image_url\"] = str(rel_path)\n                        assets_updated += 1\n                        LOGGER.debug(f\"Downloaded and cached image to {rel_path}\")\n                except Exception as e:\n                    LOGGER.warning(f\"Error updating image URL {image_url}: {e}\")\n            \n            # Cache diagram content\n            diagram_content = slide.get(\"diagram_content\")\n            diagram_type = slide.get(\"diagram_type\")\n            \n            if diagram_content and diagram_type:\n                content_hash = hashlib.md5(diagram_content.encode()).hexdigest()[:10]\n                if content_hash in self.cache[\"diagrams\"]:\n                    # Diagram already in cache, nothing to do\n                    pass\n                else:\n                    # Check if diagram files exist\n                    json_dir = json_path.parent\n                    img_url = slide.get(\"image_url\")\n                    \n                    if img_url and not img_url.startswith(\"http\"):\n                        img_path = json_dir / img_url\n                        if img_path.exists():\n                            # Cache the existing diagram\n                            self.get_diagram(diagram_content, diagram_type, local_path=img_path)\n                            assets_updated += 1\n                            LOGGER.debug(f\"Cached existing diagram from {img_path}\")\n        \n        # Save the updated JSON\n        if output_path:\n            out_path = Path(output_path)\n        else:\n            out_path = json_path\n        \n        try:\n            if isinstance(slides_data, dict) and \"slides\" in slides_data:\n                slides_data[\"slides\"] = slides\n                with open(out_path, 'w') as f:\n                    json.dump(slides_data, f, indent=2)\n            else:\n                with open(out_path, 'w') as f:\n                    json.dump(slides, f, indent=2)\n            \n            LOGGER.info(f\"Updated {assets_updated} assets in {out_path}\")\n        except Exception as e:\n            LOGGER.error(f\"Error saving updated JSON: {e}\")\n        \n        return assets_updated\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level)\n    \n    # Create asset manager\n    cache_dir = Path(args.cache_dir)\n    cache_file = Path(args.cache_file)\n    manager = AssetManager(cache_dir, cache_file)\n    \n    # Execute command\n    if args.command == \"get-image\":\n        local_path = Path(args.local_path) if args.local_path else None\n        path = manager.get_image(args.url, args.category, local_path)\n        print(f\"Image cached at: {path}\")\n    \n    elif args.command == \"get-diagram\":\n        local_path = Path(args.local_path) if args.local_path else None\n        path = manager.get_diagram(args.content, args.type, local_path)\n        if path:\n            print(f\"Diagram cached at: {path}\")\n        else:\n            print(\"Diagram not found in cache and no local path provided\")\n    \n    elif args.command == \"list\":\n        assets = manager.list_assets(args.category, args.type)\n        print(\"\\nImages:\")\n        for img in assets[\"images\"]:\n            print(f\"  - {img['url']} -> {img['path']}\")\n        \n        print(\"\\nDiagrams:\")\n        for diag in assets[\"diagrams\"]:\n            print(f\"  - {diag['hash']} ({diag['type']}) -> {diag['path']}\")\n    \n    elif args.command == \"clean\":\n        images, diagrams = manager.clean_cache(args.remove_unused, args.days)\n        print(f\"Removed {images} images and {diagrams} diagrams from cache\")\n    \n    elif args.command == \"update-json\":\n        json_path = Path(args.json_file)\n        output_path = Path(args.output) if args.output else None\n        assets_updated = manager.update_json(json_path, output_path)\n        print(f\"Updated {assets_updated} assets in {json_path}\")\n    \n    else:\n        print(\"No command specified. Use --help for usage information.\")\n\nif __name__ == \"__main__\":\n    main()\n"
          }
        ],
        "files": [
          {
            "file_name": "__main__.py"
          },
          {
            "file_name": "pptx_renderer.py"
          },
          {
            "file_name": "__init__.py"
          },
          {
            "file_name": "visual_reviewer.py"
          },
          {
            "file_name": "asset_processor.py"
          },
          {
            "file_name": "content_analyzer.py"
          },
          {
            "file_name": "renderer_service.py"
          },
          {
            "file_name": "review_service.py"
          },
          {
            "file_name": "__init__.py"
          },
          {
            "file_name": "builder.py"
          },
          {
            "file_name": "pptx_builder.py"
          },
          {
            "file_name": "__init__.py"
          },
          {
            "file_name": "asset_manager.py"
          }
        ]
      }
    },
    {
      "id": "dbf53765-b2a6-4ca3-a114-79880a4e1305",
      "role": "assistant",
      "content": "Let me analyze the provided files to see if there are duplicates and what needs to be cleaned up, then address the PPTX renderer image/diagram issues, and provide documentation.\n\nLooking at the files:\n\n1. **Duplicates/Overlaps I see:**\n   - `asset_manager.py` (in assets/) - this seems to be a standalone asset management tool\n   - `asset_processor.py` (in services/) - this is the service we created for processing assets in the DDD architecture\n   - These have similar functionality but serve different purposes - asset_manager is more of a CLI tool, asset_processor is the service\n\n2. **PPTX Renderer Issues:**\n   Looking at the PPTX renderer, I see it's trying to find images with hardcoded patterns like:\n   ```python\n   image_paths_to_try.extend([\n       f\"images/{base_name}_slide{slide_num}_{diagram_type}{ext}\",\n       f\"images/{base_name}_slide{slide_num}{ext}\",\n       f\"images/slide{slide_num}_{diagram_type}{ext}\",\n       f\"images/slide{slide_num}{ext}\"\n   ])\n   ```\n   \n   But with our new architecture, the AssetProcessor should have already processed all assets and updated the JSON with remote URLs for Google Slides, or local paths for PPTX. The PPTX renderer should just use the `image_url` field that's been processed.\n\n3. **Files we need:**\n   - Core DDD files: models.py, interfaces.py, controller.py\n   - Services: content_analyzer.py, asset_processor.py (keep this one), renderer_service.py (though this might be redundant)\n   - Renderers: factory.py, google_slides_renderer.py, pptx_renderer.py\n   - Shared: __init__.py with litterbox_upload\n   - Entry points: __main__.py\n\n4. **Files we might not need or can simplify:**\n   - asset_manager.py - this is a separate CLI tool, we could keep it but it's not essential for the core workflow\n   - builder.py, pptx_builder.py - these seem to be older implementations\n   - Some of the other utility files\n\nLet me provide a clean analysis and fixes.Looking at your files, you have some duplication and the PPTX renderer needs fixing. Let me break this down:\n\n## Duplicate/Redundant Files\n\n**Files to Keep (Core DDD Architecture):**\n- `domain/models.py` - Core domain models âœ…\n- `domain/interfaces.py` - Domain interfaces âœ…\n- `core/controller.py` - Main controller âœ…\n- `services/content_analyzer.py` - Content analysis service âœ…\n- `services/asset_processor.py` - Asset processing service âœ…\n- `renderers/factory.py` - Renderer factory âœ…\n- `renderers/google_slides_renderer.py` - Google Slides renderer âœ…\n- `renderers/pptx_renderer.py` - PPTX renderer (needs fixing) âœ…\n- `shared/__init__.py` - Shared utilities âœ…\n- `__main__.py` - Entry point âœ…\n\n**Files that are Redundant/Old:**\n- `services/renderer_service.py` - This duplicates what the controller does\n- `assets/asset_manager.py` - Separate CLI tool, not needed for core workflow\n- `markdown/builder.py` - Old implementation approach\n- `markdown/pptx_builder.py` - Old implementation approach\n\n## Fixed PPTX Renderer\n\nThe PPTX renderer was trying to guess image paths instead of using processed assets. Here's the fix:\n```\nViewing artifacts created via the Analysis Tool web feature preview isnâ€™t yet supported on mobile.\n```\n\n\n\n## Clean Build & Run Instructions\n```\nViewing artifacts created via the Analysis Tool web feature preview isnâ€™t yet supported on mobile.\n```\n\n\n\n## DDD Architecture Diagram\n```\nViewing artifacts created via the Analysis Tool web feature preview isnâ€™t yet supported on mobile.\n```\n\n\n\n## Summary\n\n**Files to Remove (Duplicates/Old):**\n- `services/renderer_service.py` - Controller handles this\n- `assets/asset_manager.py` - Separate CLI tool, not core workflow  \n- `markdown/builder.py` - Old approach\n- `markdown/pptx_builder.py` - Old approach\n\n**Key Fixes:**\n1. **PPTX Renderer**: Now properly uses processed assets from AssetProcessor instead of guessing file paths\n2. **Clean Architecture**: Follows DDD with proper separation of concerns\n3. **Asset Flow**: AssetProcessor handles all diagram generation and uploads before rendering\n\n**Build & Run:**\n```bash\n# Quick start\nexport ANTHROPIC_API_KEY=\"your-key\"\npython -m makeslides --input content.md --format pptx\n\n# With diagrams and debugging\npython -m makeslides --input content.md --format google_slides --thinking --save-json\n```\n\nThe architecture is now much cleaner - like having a well-organized kitchen where the prep chef (AssetProcessor) handles all ingredient preparation, then passes clean, ready-to-use ingredients to the specialist cooks (Renderers) who focus only on their specific cooking techniques. No more cooks trying to chop vegetables while managing their stoves!",
      "created_at": "2025-05-22T15:31:29.949715Z",
      "sequence_order": 3,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-22T15:26:37.862402Z",
            "stop_timestamp": "2025-05-22T15:26:52.345816Z",
            "flags": null,
            "type": "thinking",
            "thinking": "Let me analyze the provided files to see if there are duplicates and what needs to be cleaned up, then address the PPTX renderer image/diagram issues, and provide documentation.\n\nLooking at the files:\n\n1. **Duplicates/Overlaps I see:**\n   - `asset_manager.py` (in assets/) - this seems to be a standalone asset management tool\n   - `asset_processor.py` (in services/) - this is the service we created for processing assets in the DDD architecture\n   - These have similar functionality but serve different purposes - asset_manager is more of a CLI tool, asset_processor is the service\n\n2. **PPTX Renderer Issues:**\n   Looking at the PPTX renderer, I see it's trying to find images with hardcoded patterns like:\n   ```python\n   image_paths_to_try.extend([\n       f\"images/{base_name}_slide{slide_num}_{diagram_type}{ext}\",\n       f\"images/{base_name}_slide{slide_num}{ext}\",\n       f\"images/slide{slide_num}_{diagram_type}{ext}\",\n       f\"images/slide{slide_num}{ext}\"\n   ])\n   ```\n   \n   But with our new architecture, the AssetProcessor should have already processed all assets and updated the JSON with remote URLs for Google Slides, or local paths for PPTX. The PPTX renderer should just use the `image_url` field that's been processed.\n\n3. **Files we need:**\n   - Core DDD files: models.py, interfaces.py, controller.py\n   - Services: content_analyzer.py, asset_processor.py (keep this one), renderer_service.py (though this might be redundant)\n   - Renderers: factory.py, google_slides_renderer.py, pptx_renderer.py\n   - Shared: __init__.py with litterbox_upload\n   - Entry points: __main__.py\n\n4. **Files we might not need or can simplify:**\n   - asset_manager.py - this is a separate CLI tool, we could keep it but it's not essential for the core workflow\n   - builder.py, pptx_builder.py - these seem to be older implementations\n   - Some of the other utility files\n\nLet me provide a clean analysis and fixes.",
            "summaries": [
              {
                "summary": "Thinking about reviewing project files, documentation, and application setup processes"
              },
              {
                "summary": "Investigating file duplicates and planning documentation"
              },
              {
                "summary": "Analyzed project structure, identified redundancies, and proposed cleanup strategy."
              }
            ],
            "cut_off": false
          },
          {
            "start_timestamp": "2025-05-22T15:26:53.087919Z",
            "stop_timestamp": "2025-05-22T15:26:59.381101Z",
            "flags": null,
            "type": "text",
            "text": "Looking at your files, you have some duplication and the PPTX renderer needs fixing. Let me break this down:\n\n## Duplicate/Redundant Files\n\n**Files to Keep (Core DDD Architecture):**\n- `domain/models.py` - Core domain models âœ…\n- `domain/interfaces.py` - Domain interfaces âœ…\n- `core/controller.py` - Main controller âœ…\n- `services/content_analyzer.py` - Content analysis service âœ…\n- `services/asset_processor.py` - Asset processing service âœ…\n- `renderers/factory.py` - Renderer factory âœ…\n- `renderers/google_slides_renderer.py` - Google Slides renderer âœ…\n- `renderers/pptx_renderer.py` - PPTX renderer (needs fixing) âœ…\n- `shared/__init__.py` - Shared utilities âœ…\n- `__main__.py` - Entry point âœ…\n\n**Files that are Redundant/Old:**\n- `services/renderer_service.py` - This duplicates what the controller does\n- `assets/asset_manager.py` - Separate CLI tool, not needed for core workflow\n- `markdown/builder.py` - Old implementation approach\n- `markdown/pptx_builder.py` - Old implementation approach\n\n## Fixed PPTX Renderer\n\nThe PPTX renderer was trying to guess image paths instead of using processed assets. Here's the fix:",
            "citations": []
          },
          {
            "start_timestamp": "2025-05-22T15:27:00.104881Z",
            "stop_timestamp": "2025-05-22T15:29:01.776744Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "fixed_pptx_renderer",
              "type": "application/vnd.ant.code",
              "title": "Fixed PPTX Renderer",
              "command": "create",
              "content": "from pptx import Presentation\nfrom pptx.util import Inches, Pt\nfrom pptx.enum.text import PP_ALIGN, MSO_VERTICAL_ANCHOR\nfrom pptx.enum.shapes import MSO_SHAPE_TYPE\nfrom pptx.dml.color import RGBColor\nfrom pathlib import Path\nimport logging\nimport os\nimport requests\nimport tempfile\nfrom typing import Dict, Any, Optional, List, Tuple\n\nlogger = logging.getLogger(__name__)\n\nclass PptxRenderer:\n    \"\"\"PPTX renderer that creates valid PowerPoint files\"\"\"\n    \n    def __init__(self, template_path: Optional[str] = None, theme: Optional[Any] = None):\n        \"\"\"Initialize the renderer with safe defaults\"\"\"\n        self.template_path = template_path\n        self.theme = self._create_safe_theme(theme)\n        \n    def _create_safe_theme(self, theme: Any) -> Dict[str, Any]:\n        \"\"\"Create a safe theme that won't cause errors\"\"\"\n        return {\n            \"colors\": {\n                \"primary\": \"4472C4\",      # Blue\n                \"secondary\": \"ED7D31\",    # Orange  \n                \"text\": \"000000\",         # Black\n                \"background\": \"FFFFFF\",   # White\n                \"accent\": \"70AD47\"        # Green\n            },\n            \"fonts\": {\n                \"title\": {\"name\": \"Calibri\", \"size\": 32, \"bold\": True},\n                \"subtitle\": {\"name\": \"Calibri\", \"size\": 24, \"bold\": False}, \n                \"body\": {\"name\": \"Calibri\", \"size\": 16, \"bold\": False},\n                \"header\": {\"name\": \"Calibri\", \"size\": 18, \"bold\": True}\n            }\n        }\n    \n    def render(self, presentation_data: Dict[str, Any], output_path: str) -> bool:\n        \"\"\"Render presentation to a valid PPTX file\"\"\"\n        try:\n            print(f\"   ðŸ”§ Creating PPTX presentation...\")\n            \n            # Create presentation\n            prs = Presentation()\n            \n            # Set basic properties safely\n            try:\n                prs.core_properties.title = presentation_data.get(\"title\", \"Presentation\")[:100]\n                if \"author\" in presentation_data:\n                    prs.core_properties.author = str(presentation_data[\"author\"])[:50]\n            except Exception as e:\n                logger.warning(f\"Could not set presentation properties: {e}\")\n            \n            # Get slides data\n            slides_data = presentation_data.get(\"slides\", [])\n            if not slides_data:\n                logger.error(\"No slides data found\")\n                return False\n            \n            print(f\"   ðŸ“„ Processing {len(slides_data)} slides...\")\n            \n            # Process each slide with error isolation\n            for i, slide_data in enumerate(slides_data):\n                try:\n                    slide_title = slide_data.get('title', f'Slide {i+1}')\n                    layout_name = slide_data.get('layout', 'TITLE_AND_CONTENT')\n                    print(f\"      {i+1:2d}. {slide_title[:40]}... ({layout_name})\")\n                    \n                    self._create_slide_safely(prs, slide_data, i+1)\n                    \n                except Exception as e:\n                    logger.error(f\"Error creating slide {i+1}: {e}\")\n                    self._create_fallback_slide(prs, slide_data, i+1)\n            \n            # Ensure output directory exists\n            output_dir = os.path.dirname(output_path)\n            if output_dir:\n                os.makedirs(output_dir, exist_ok=True)\n            \n            # Save presentation\n            prs.save(output_path)\n            print(f\"   âœ… Saved valid PPTX: {os.path.basename(output_path)}\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Critical error in PPTX generation: {e}\")\n            return False\n    \n    def _create_slide_safely(self, prs: Presentation, slide_data: Dict[str, Any], slide_number: int):\n        \"\"\"Create a slide with safe error handling\"\"\"\n        layout = slide_data.get(\"layout\", \"TITLE_AND_CONTENT\")\n        \n        # Route to appropriate slide creator\n        if layout in [\"TWO_COLUMNS\", \"COMPARISON\"]:\n            self._create_two_column_slide(prs, slide_data)\n        elif layout == \"BIG_NUMBER\":\n            self._create_big_number_slide(prs, slide_data)\n        elif layout == \"QUOTE\":\n            self._create_quote_slide(prs, slide_data)\n        elif layout == \"TITLE_SLIDE\":\n            self._create_title_slide(prs, slide_data)\n        elif layout == \"IMAGE_WITH_CAPTION\":\n            self._create_image_slide(prs, slide_data)\n        else:\n            # Default: standard content slide\n            self._create_content_slide(prs, slide_data)\n    \n    def _create_two_column_slide(self, prs: Presentation, slide_data: Dict[str, Any]):\n        \"\"\"Create two-column slide with proper | parsing\"\"\"\n        slide_layout = prs.slide_layouts[6]  # Blank\n        slide = prs.slides.add_slide(slide_layout)\n        \n        # Add title safely\n        title = slide_data.get(\"title\", \"\")\n        if title:\n            title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.2), Inches(9), Inches(1))\n            title_frame = title_box.text_frame\n            title_frame.text = title\n            title_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n            self._apply_font_safely(title_frame.paragraphs[0], \"title\")\n        \n        # Parse content into columns\n        content = slide_data.get(\"content\", \"\")\n        left_content, right_content = self._parse_two_columns(content)\n        \n        print(f\"         ðŸ“Š Left: {left_content[:30]}... | Right: {right_content[:30]}...\")\n        \n        # Create columns\n        if left_content and right_content:\n            # Two columns\n            left_box = slide.shapes.add_textbox(Inches(0.5), Inches(1.5), Inches(4.2), Inches(5.5))\n            self._add_text_content(left_box.text_frame, left_content)\n            \n            right_box = slide.shapes.add_textbox(Inches(5.3), Inches(1.5), Inches(4.2), Inches(5.5))\n            self._add_text_content(right_box.text_frame, right_content)\n            \n            # Add divider line\n            try:\n                line = slide.shapes.add_connector(1, Inches(5), Inches(1.3), Inches(5), Inches(7))\n                line.line.color.rgb = RGBColor(220, 220, 220)\n                line.line.width = Pt(1)\n            except:\n                pass\n        elif left_content:\n            # Single column, full width\n            content_box = slide.shapes.add_textbox(Inches(0.5), Inches(1.5), Inches(9), Inches(5.5))\n            self._add_text_content(content_box.text_frame, left_content)\n        \n        # Add processed image/diagram - FIXED\n        self._add_processed_visual(slide, slide_data)\n        self._add_notes_safely(slide, slide_data)\n    \n    def _create_content_slide(self, prs: Presentation, slide_data: Dict[str, Any]):\n        \"\"\"Create standard content slide\"\"\"\n        slide_layout = prs.slide_layouts[1]  # Title and content\n        slide = prs.slides.add_slide(slide_layout)\n        \n        # Set title\n        title = slide_data.get(\"title\", \"\")\n        if title and hasattr(slide.shapes, 'title') and slide.shapes.title:\n            slide.shapes.title.text = title\n            self._apply_font_safely(slide.shapes.title.text_frame.paragraphs[0], \"title\")\n        \n        # Add content\n        content = slide_data.get(\"content\", \"\")\n        if content:\n            # Find content placeholder\n            content_placeholder = None\n            for shape in slide.placeholders:\n                if shape.placeholder_format.type == 1:  # Body\n                    content_placeholder = shape\n                    break\n            \n            if content_placeholder:\n                self._add_text_content(content_placeholder.text_frame, content)\n            else:\n                # Fallback: create text box\n                content_box = slide.shapes.add_textbox(Inches(0.5), Inches(1.5), Inches(6), Inches(5))\n                self._add_text_content(content_box.text_frame, content)\n        \n        # Add processed image/diagram - FIXED\n        self._add_processed_visual(slide, slide_data, side_area=True)\n        self._add_notes_safely(slide, slide_data)\n    \n    def _create_image_slide(self, prs: Presentation, slide_data: Dict[str, Any]):\n        \"\"\"Create slide with image and caption\"\"\"\n        slide_layout = prs.slide_layouts[6]  # Blank\n        slide = prs.slides.add_slide(slide_layout)\n        \n        # Add title\n        title = slide_data.get(\"title\", \"\")\n        if title:\n            title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.2), Inches(9), Inches(0.8))\n            title_frame = title_box.text_frame\n            title_frame.text = title\n            title_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n            self._apply_font_safely(title_frame.paragraphs[0], \"title\")\n        \n        # Add processed image/diagram - FIXED\n        visual_added = self._add_processed_visual(slide, slide_data, main_area=True)\n        \n        # Add content/caption\n        content = slide_data.get(\"content\", \"\")\n        if content:\n            caption_y = Inches(6) if visual_added else Inches(2)\n            caption_box = slide.shapes.add_textbox(Inches(1), caption_y, Inches(8), Inches(1.5))\n            self._add_text_content(caption_box.text_frame, content)\n        \n        self._add_notes_safely(slide, slide_data)\n    \n    def _create_big_number_slide(self, prs: Presentation, slide_data: Dict[str, Any]):\n        \"\"\"Create big number emphasis slide\"\"\"\n        slide_layout = prs.slide_layouts[6]  # Blank\n        slide = prs.slides.add_slide(slide_layout)\n        \n        big_number = slide_data.get(\"title\", \"100%\")\n        description = slide_data.get(\"content\", \"\")\n        \n        # Add big number\n        number_box = slide.shapes.add_textbox(Inches(1), Inches(2), Inches(8), Inches(2.5))\n        number_frame = number_box.text_frame\n        number_frame.text = big_number\n        number_para = number_frame.paragraphs[0]\n        number_para.alignment = PP_ALIGN.CENTER\n        \n        for run in number_para.runs:\n            run.font.size = Pt(64)\n            run.font.bold = True\n            run.font.color.rgb = self._get_color(\"primary\")\n        \n        # Add description\n        if description:\n            desc_box = slide.shapes.add_textbox(Inches(1), Inches(4.8), Inches(8), Inches(2))\n            desc_frame = desc_box.text_frame\n            desc_frame.text = description\n            desc_para = desc_frame.paragraphs[0]\n            desc_para.alignment = PP_ALIGN.CENTER\n            self._apply_font_safely(desc_para, \"body\")\n        \n        self._add_notes_safely(slide, slide_data)\n    \n    def _create_quote_slide(self, prs: Presentation, slide_data: Dict[str, Any]):\n        \"\"\"Create quote slide with attribution\"\"\"\n        slide_layout = prs.slide_layouts[6]  # Blank\n        slide = prs.slides.add_slide(slide_layout)\n        \n        content = slide_data.get(\"content\", \"\")\n        quote_text, attribution = self._parse_quote(content)\n        \n        if quote_text:\n            quote_box = slide.shapes.add_textbox(Inches(1), Inches(2), Inches(8), Inches(3.5))\n            quote_frame = quote_box.text_frame\n            quote_frame.text = f'\"{quote_text}\"'\n            quote_para = quote_frame.paragraphs[0]\n            quote_para.alignment = PP_ALIGN.CENTER\n            \n            for run in quote_para.runs:\n                run.font.size = Pt(24)\n                run.font.italic = True\n                run.font.color.rgb = self._get_color(\"primary\")\n        \n        if attribution:\n            attr_box = slide.shapes.add_textbox(Inches(1), Inches(5.8), Inches(8), Inches(1))\n            attr_frame = attr_box.text_frame\n            attr_frame.text = attribution\n            attr_para = attr_frame.paragraphs[0]\n            attr_para.alignment = PP_ALIGN.CENTER\n            self._apply_font_safely(attr_para, \"body\")\n        \n        self._add_notes_safely(slide, slide_data)\n    \n    def _create_title_slide(self, prs: Presentation, slide_data: Dict[str, Any]):\n        \"\"\"Create title slide\"\"\"\n        slide_layout = prs.slide_layouts[0]  # Title slide\n        slide = prs.slides.add_slide(slide_layout)\n        \n        title = slide_data.get(\"title\", \"Presentation\")\n        if hasattr(slide.shapes, 'title') and slide.shapes.title:\n            slide.shapes.title.text = title\n            self._apply_font_safely(slide.shapes.title.text_frame.paragraphs[0], \"title\")\n        \n        subtitle = slide_data.get(\"subtitle\", slide_data.get(\"content\", \"\"))\n        if subtitle:\n            for shape in slide.placeholders:\n                if shape.placeholder_format.type == 2:  # Subtitle\n                    shape.text = subtitle\n                    self._apply_font_safely(shape.text_frame.paragraphs[0], \"subtitle\")\n                    break\n        \n        self._add_processed_visual(slide, slide_data)\n        self._add_notes_safely(slide, slide_data)\n    \n    def _add_processed_visual(self, slide, slide_data: Dict[str, Any], main_area: bool = False, side_area: bool = False) -> bool:\n        \"\"\"Add processed visual (image/diagram) - FIXED to use asset processor results\"\"\"\n        visual_added = False\n        \n        # Determine positioning\n        if main_area:\n            x, y, w, h = Inches(1.5), Inches(1.2), Inches(7), Inches(4.5)\n        elif side_area:\n            x, y, w, h = Inches(6.5), Inches(1.5), Inches(3), Inches(3)\n        else:\n            x, y, w, h = Inches(7), Inches(2), Inches(2.5), Inches(2)\n        \n        # Get processed image URL from asset processor\n        image_url = slide_data.get(\"image_url\")\n        \n        if not image_url:\n            return False\n        \n        try:\n            # If it's a remote URL (from asset processor), download temporarily\n            if image_url.startswith((\"http://\", \"https://\")):\n                temp_path = self._download_temp_image(image_url)\n                if temp_path:\n                    slide.shapes.add_picture(str(temp_path), x, y, w, h)\n                    print(f\"         ðŸ–¼ï¸ Added remote image: {image_url}\")\n                    visual_added = True\n                    # Clean up temp file\n                    try:\n                        os.unlink(temp_path)\n                    except:\n                        pass\n            \n            # If it's a local path, use directly\n            else:\n                image_path = Path(image_url)\n                if image_path.exists():\n                    slide.shapes.add_picture(str(image_path), x, y, w, h)\n                    print(f\"         ðŸ–¼ï¸ Added local image: {image_path.name}\")\n                    visual_added = True\n                else:\n                    # Try relative to current directory\n                    current_dir_path = Path.cwd() / image_path\n                    if current_dir_path.exists():\n                        slide.shapes.add_picture(str(current_dir_path), x, y, w, h)\n                        print(f\"         ðŸ–¼ï¸ Added image: {current_dir_path.name}\")\n                        visual_added = True\n        \n        except Exception as e:\n            logger.warning(f\"Error adding visual: {e}\")\n        \n        return visual_added\n    \n    def _download_temp_image(self, url: str) -> Optional[Path]:\n        \"\"\"Download image to temporary file for PPTX embedding\"\"\"\n        try:\n            response = requests.get(url, timeout=10)\n            response.raise_for_status()\n            \n            # Create temp file with appropriate extension\n            suffix = \".png\"  # Default\n            if url.lower().endswith(('.jpg', '.jpeg')):\n                suffix = \".jpg\"\n            elif url.lower().endswith('.svg'):\n                suffix = \".svg\"\n            \n            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)\n            temp_file.write(response.content)\n            temp_file.close()\n            \n            return Path(temp_file.name)\n            \n        except Exception as e:\n            logger.error(f\"Error downloading image {url}: {e}\")\n            return None\n    \n    def _parse_two_columns(self, content: str) -> Tuple[str, str]:\n        \"\"\"Parse content with | separator\"\"\"\n        if not content:\n            return \"\", \"\"\n        \n        if '|' in content:\n            parts = content.split('|', 1)\n            left = parts[0].strip()\n            right = parts[1].strip() if len(parts) > 1 else \"\"\n            return left, right\n        \n        # Split intelligently\n        lines = content.split('\\n')\n        clean_lines = [line.strip() for line in lines if line.strip()]\n        \n        if len(clean_lines) <= 2:\n            return content, \"\"\n        \n        midpoint = len(clean_lines) // 2\n        \n        # Look for good split point\n        for i in range(max(1, midpoint-2), min(len(clean_lines)-1, midpoint+3)):\n            if clean_lines[i].startswith(('â€¢ ', '- ', '* ', '1. ', '2. ', '3. ')):\n                left_lines = clean_lines[:i]\n                right_lines = clean_lines[i:]\n                return '\\n'.join(left_lines), '\\n'.join(right_lines)\n        \n        # Default split\n        left_lines = clean_lines[:midpoint]\n        right_lines = clean_lines[midpoint:]\n        return '\\n'.join(left_lines), '\\n'.join(right_lines)\n    \n    def _add_text_content(self, text_frame, content: str):\n        \"\"\"Add formatted text content with proper bullet handling\"\"\"\n        if not content:\n            return\n        \n        try:\n            text_frame.clear()\n            lines = content.split('\\n')\n            first_paragraph = True\n            \n            for line in lines:\n                line = line.strip()\n                if not line:\n                    continue\n                \n                # Create paragraph\n                if first_paragraph:\n                    p = text_frame.paragraphs[0]\n                    first_paragraph = False\n                else:\n                    p = text_frame.add_paragraph()\n                \n                # Handle bullet points\n                if line.startswith(('â€¢ ', '- ', '* ')):\n                    p.text = line[2:].strip()\n                    p.level = 0\n                    try:\n                        p.bullet = True\n                    except:\n                        p.text = f\"â€¢ {p.text}\"\n                        \n                elif line.startswith(('  â€¢ ', '  - ', '  * ', '    â€¢ ', '    - ', '    * ')):\n                    clean_text = line.lstrip(' â€¢-*').strip()\n                    p.text = clean_text\n                    p.level = 1\n                    try:\n                        p.bullet = True\n                    except:\n                        p.text = f\"  â—¦ {p.text}\"\n                        \n                elif line.startswith(('1. ', '2. ', '3. ', '4. ', '5. ')):\n                    p.text = line\n                    p.level = 0\n                        \n                else:\n                    p.text = line\n                    p.level = 0\n                \n                # Apply formatting\n                if line.isupper() and len(line) < 20:\n                    self._apply_font_safely(p, \"header\")\n                else:\n                    self._apply_font_safely(p, \"body\")\n                    \n        except Exception as e:\n            logger.warning(f\"Error adding text content: {e}\")\n            try:\n                text_frame.clear()\n                text_frame.text = content\n            except:\n                pass\n    \n    def _parse_quote(self, content: str) -> Tuple[str, str]:\n        \"\"\"Parse quote and attribution from content\"\"\"\n        lines = [line.strip() for line in content.split('\\n') if line.strip()]\n        \n        quote_lines = []\n        attribution = \"\"\n        \n        for line in lines:\n            if line.startswith('â€”') or line.startswith('- '):\n                attribution = line\n            elif line and not line.startswith('\"'):\n                quote_lines.append(line.strip('\"'))\n        \n        quote_text = ' '.join(quote_lines)\n        return quote_text, attribution\n    \n    def _add_notes_safely(self, slide, slide_data: Dict[str, Any]):\n        \"\"\"Add speaker notes safely\"\"\"\n        try:\n            notes_text = (slide_data.get(\"facilitator_notes\", \"\") or \n                         slide_data.get(\"notes\", \"\"))\n            \n            if notes_text:\n                try:\n                    notes_slide = slide.notes_slide\n                    if hasattr(notes_slide, 'notes_text_frame'):\n                        notes_slide.notes_text_frame.text = notes_text[:1000]\n                        print(f\"         ðŸ“ Added speaker notes\")\n                except Exception as e:\n                    logger.warning(f\"Could not add speaker notes: {e}\")\n        except Exception as e:\n            logger.warning(f\"Could not access speaker notes: {e}\")\n\n    def _apply_font_safely(self, paragraph, font_type: str):\n        \"\"\"Apply font formatting safely\"\"\"\n        try:\n            font_config = self.theme[\"fonts\"].get(font_type, self.theme[\"fonts\"][\"body\"])\n            \n            for run in paragraph.runs:\n                if run.text.strip():\n                    try:\n                        run.font.name = font_config[\"name\"]\n                        run.font.size = Pt(font_config[\"size\"])\n                        run.font.bold = font_config.get(\"bold\", False)\n                        \n                        if font_type == \"title\":\n                            run.font.color.rgb = self._get_color(\"primary\")\n                        else:\n                            run.font.color.rgb = self._get_color(\"text\")\n                    except:\n                        pass\n                        \n        except Exception as e:\n            logger.warning(f\"Font formatting error: {e}\")\n    \n    def _get_color(self, color_name: str) -> RGBColor:\n        \"\"\"Get color safely\"\"\"\n        try:\n            hex_color = self.theme[\"colors\"].get(color_name, \"000000\")\n            if hex_color.startswith(\"#\"):\n                hex_color = hex_color[1:]\n            \n            r = int(hex_color[0:2], 16)\n            g = int(hex_color[2:4], 16) \n            b = int(hex_color[4:6], 16)\n            return RGBColor(r, g, b)\n        except:\n            return RGBColor(0, 0, 0)\n    \n    def _create_fallback_slide(self, prs: Presentation, slide_data: Dict[str, Any], slide_number: int):\n        \"\"\"Create a simple fallback slide when main creation fails\"\"\"\n        try:\n            slide_layout = prs.slide_layouts[1]\n            slide = prs.slides.add_slide(slide_layout)\n            \n            title = slide_data.get(\"title\", f\"Slide {slide_number}\")\n            if hasattr(slide.shapes, 'title') and slide.shapes.title:\n                slide.shapes.title.text = title\n            \n            content = slide_data.get(\"content\", \"Content could not be formatted properly.\")\n            for shape in slide.placeholders:\n                if shape.placeholder_format.type == 1:\n                    shape.text = content[:300]\n                    break\n                    \n            print(f\"      âš ï¸ Created fallback slide {slide_number}\")\n            \n        except Exception as e:\n            logger.error(f\"Even fallback slide creation failed: {e}\")",
              "language": "python",
              "version_uuid": "31684a2c-aff5-41f7-a92e-9a981fd13e15"
            },
            "message": "artifacts",
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "9dfe81eb-c5a2-4a2f-abaa-589d6c6f8d2c"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-05-22T15:29:17.552957Z",
            "stop_timestamp": "2025-05-22T15:29:17.887378Z",
            "flags": null,
            "type": "text",
            "text": "\n\n## Clean Build & Run Instructions",
            "citations": []
          },
          {
            "start_timestamp": "2025-05-22T15:29:18.464107Z",
            "stop_timestamp": "2025-05-22T15:30:13.050572Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "makeslides_guide",
              "type": "text/markdown",
              "title": "MakeSlides: Build & Run Guide",
              "command": "create",
              "content": "# MakeSlides: Build & Run Guide\n\n## Overview\n\nMakeSlides is a Domain-Driven Design (DDD) application that converts text content into professional presentations using AI. It follows clean architecture principles with separate layers for domain logic, services, and infrastructure.\n\n## Project Structure\n\n```\nmakeslides/\nâ”œâ”€â”€ domain/                 # Core business logic\nâ”‚   â”œâ”€â”€ models.py          # Domain entities (Presentation, Slide, Theme)\nâ”‚   â””â”€â”€ interfaces.py      # Domain interfaces/contracts\nâ”œâ”€â”€ services/              # Application services\nâ”‚   â”œâ”€â”€ content_analyzer.py # AI content analysis (Claude)\nâ”‚   â””â”€â”€ asset_processor.py  # Image/diagram processing\nâ”œâ”€â”€ renderers/             # Infrastructure layer\nâ”‚   â”œâ”€â”€ factory.py         # Renderer factory pattern\nâ”‚   â”œâ”€â”€ pptx_renderer.py   # PowerPoint output\nâ”‚   â””â”€â”€ google_slides_renderer.py # Google Slides output\nâ”œâ”€â”€ core/                  # Application coordination\nâ”‚   â””â”€â”€ controller.py      # Main controller (orchestrates services)\nâ”œâ”€â”€ shared/                # Shared utilities\nâ”‚   â””â”€â”€ __init__.py        # Common helpers (litterbox upload, etc.)\nâ””â”€â”€ __main__.py           # Entry point\n```\n\n## Architecture Flow\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                        MakeSlides Architecture                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Input Content (Markdown/Text)                                  â”‚\nâ”‚           â†“                                                     â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\nâ”‚  â”‚               SlidesController                          â”‚    â”‚\nâ”‚  â”‚                 (Orchestrator)                          â”‚    â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\nâ”‚                        â†“                                        â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\nâ”‚  â”‚            ContentAnalyzer Service                      â”‚    â”‚\nâ”‚  â”‚         (Claude AI â†’ Raw JSON Structure)               â”‚    â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\nâ”‚                        â†“                                        â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\nâ”‚  â”‚            AssetProcessor Service                       â”‚    â”‚\nâ”‚  â”‚    (Generate Diagrams â†’ Upload to Litterbox â†’          â”‚    â”‚\nâ”‚  â”‚              Update JSON with URLs)                    â”‚    â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\nâ”‚                        â†“                                        â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\nâ”‚  â”‚                Renderer Factory                         â”‚    â”‚\nâ”‚  â”‚         (Creates appropriate renderer)                  â”‚    â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\nâ”‚                â†“                               â†“                â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\nâ”‚  â”‚   PPTX Renderer     â”‚         â”‚ Google Slides Renderer  â”‚    â”‚\nâ”‚  â”‚  (Local files)      â”‚         â”‚   (Remote URLs)         â”‚    â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\nâ”‚                â†“                               â†“                â”‚\nâ”‚        presentation.pptx              Google Slides URL         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Installation & Setup\n\n### 1. Install Dependencies\n\n```bash\n# Core Python dependencies\npip install anthropic python-pptx google-auth google-auth-oauthlib google-auth-httplib2 \npip install google-api-python-client requests colorama pydantic pathlib typing-extensions\n\n# For diagram generation (optional)\nnpm install -g @mermaid-js/mermaid-cli\n\n# For Google Slides support\nnpm install -g md2gslides  # If using legacy md2gslides features\n```\n\n### 2. Set Environment Variables\n\n```bash\n# Required: Anthropic API key for Claude\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# Optional: Logging level\nexport MAKESLIDES_LOGLEVEL=\"INFO\"\n```\n\n### 3. Google Slides Setup (Optional)\n\nIf using Google Slides output:\n\n1. Go to [Google Cloud Console](https://console.cloud.google.com)\n2. Create new project or select existing\n3. Enable Google Slides API and Google Drive API\n4. Create OAuth 2.0 credentials (Desktop Application)\n5. Download credentials JSON\n6. Save as `~/.makeslides/credentials.json`\n\n## Usage\n\n### Basic Usage\n\n```bash\n# Create PowerPoint presentation\npython -m makeslides --input content.md --output presentation.pptx --format pptx\n\n# Create Google Slides presentation  \npython -m makeslides --input content.md --format google_slides\n\n# Use extended thinking mode for complex content\npython -m makeslides --input content.md --thinking --format pptx\n```\n\n### Advanced Usage\n\n```bash\n# Use custom theme\npython -m makeslides --input content.md --theme dark --format pptx\n\n# Save intermediate JSON for debugging\npython -m makeslides --input content.md --save-json --format pptx\n\n# Enable diagram rendering\npython -m makeslides --input content.md --render-diagrams --format google_slides\n```\n\n### Python API Usage\n\n```python\nfrom makeslides.core.controller import SlidesController\nfrom makeslides.domain.models import ThemePresets\n\n# Initialize controller\ncontroller = SlidesController(use_extended_thinking=True)\n\n# Create presentation\nwith open(\"content.md\", \"r\") as f:\n    content = f.read()\n\nresult = controller.create_presentation(\n    content=content,\n    output_format=\"pptx\",\n    output_path=\"my_presentation.pptx\",\n    theme=ThemePresets.dark()\n)\n\nif result[\"success\"]:\n    print(f\"Created: {result['output_path']}\")\nelse:\n    print(f\"Error: {result['error']}\")\n```\n\n## How It Works (DDD Perspective)\n\n### Domain Layer\n- **Models**: Core entities like `Presentation`, `Slide`, `SlideTheme`\n- **Interfaces**: Contracts that services must implement\n- **Pure business logic**: No external dependencies\n\n### Service Layer  \n- **ContentAnalyzer**: Uses Claude AI to analyze content and create presentation structure\n- **AssetProcessor**: Handles diagram generation and image uploads\n- **Business rules**: Orchestrates domain objects\n\n### Infrastructure Layer\n- **Renderers**: Convert domain objects to external formats (PPTX, Google Slides)\n- **External APIs**: Claude AI, Google APIs, Litterbox CDN\n- **Implementation details**: File I/O, network calls\n\n### Benefits of This Architecture\n\n1. **Separation of Concerns**: Each layer has a single responsibility\n2. **Testability**: Services can be mocked and tested independently\n3. **Flexibility**: Easy to add new output formats or AI providers\n4. **Maintainability**: Changes in one layer don't affect others\n\n## Development Workflow\n\n### 1. Clean Build\n\n```bash\n# Remove old artifacts\nrm -rf __pycache__ *.pyc thinking.log *.json *.pptx\n\n# Ensure dependencies are current\npip install -r requirements.txt\n```\n\n### 2. Run Tests\n\n```bash\n# Run a simple test\necho \"# Test Presentation\\n\\nThis is test content.\" > test.md\npython -m makeslides --input test.md --format pptx\n```\n\n### 3. Debug Issues\n\n```bash\n# Enable debug logging\nexport MAKESLIDES_LOGLEVEL=\"DEBUG\"\n\n# Save intermediate files\npython -m makeslides --input content.md --save-json --thinking\n```\n\n## File Cleanup\n\nRemove these redundant files:\n\n```bash\n# Remove duplicated/old files\nrm makeslides/services/renderer_service.py\nrm makeslides/assets/asset_manager.py  \nrm makeslides/markdown/builder.py\nrm makeslides/markdown/pptx_builder.py\n```\n\nKeep only the core DDD structure files listed in the project structure above.\n\n## Troubleshooting\n\n### Common Issues\n\n1. **\"No module named 'makeslides'\"**\n   - Run from parent directory: `python -m makeslides`\n   - Or install: `pip install -e .`\n\n2. **\"ANTHROPIC_API_KEY not set\"**\n   - Set environment variable: `export ANTHROPIC_API_KEY=\"your-key\"`\n\n3. **Google Slides auth errors**\n   - Check credentials file exists: `~/.makeslides/credentials.json`\n   - Ensure APIs are enabled in Google Cloud Console\n\n4. **Diagram generation fails**\n   - Install mermaid CLI: `npm install -g @mermaid-js/mermaid-cli`\n   - Check `mmdc --version` works\n\n### Debug Mode\n\n```bash\n# Full debug output\nMAKESLIDES_LOGLEVEL=DEBUG python -m makeslides --input content.md --thinking --save-json\n```\n\nThis will show:\n- Claude's thinking process\n- Asset processing steps  \n- Rendering details\n- Save intermediate JSON files for inspection\n\n## Next Steps\n\n1. **Add new output formats**: Create new renderer in `renderers/`\n2. **Add new AI providers**: Implement `ContentAnalyzerInterface`\n3. **Enhance themes**: Extend `SlideTheme` model\n4. **Add caching**: Implement asset caching service\n5. **Add templates**: Create template system for consistent layouts",
              "version_uuid": "6e3e0961-79f7-4199-8f75-c3313f7d7abc"
            },
            "message": "artifacts",
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "f00e5ba1-a9dc-4e6f-be8d-200cd43fa34e"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-05-22T15:30:18.814674Z",
            "stop_timestamp": "2025-05-22T15:30:19.156860Z",
            "flags": null,
            "type": "text",
            "text": "\n\n## DDD Architecture Diagram",
            "citations": []
          },
          {
            "start_timestamp": "2025-05-22T15:30:19.663687Z",
            "stop_timestamp": "2025-05-22T15:31:12.470093Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "ddd_architecture_diagram",
              "type": "image/svg+xml",
              "title": "DDD Architecture Diagram",
              "command": "create",
              "content": "<svg viewBox=\"0 0 800 600\" xmlns=\"http://www.w3.org/2000/svg\">\n  <!-- Title -->\n  <text x=\"400\" y=\"25\" text-anchor=\"middle\" font-size=\"18\" font-weight=\"bold\" fill=\"#333\">MakeSlides DDD Architecture</text>\n  \n  <!-- Domain Layer -->\n  <rect x=\"50\" y=\"50\" width=\"700\" height=\"120\" fill=\"#e8f4f8\" stroke=\"#4a90a4\" stroke-width=\"2\" rx=\"5\"/>\n  <text x=\"60\" y=\"70\" font-size=\"14\" font-weight=\"bold\" fill=\"#2c5aa0\">Domain Layer (Core Business Logic)</text>\n  \n  <!-- Domain Models -->\n  <rect x=\"70\" y=\"85\" width=\"140\" height=\"70\" fill=\"#ffffff\" stroke=\"#4a90a4\" stroke-width=\"1\" rx=\"3\"/>\n  <text x=\"140\" y=\"105\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"#333\">Models</text>\n  <text x=\"75\" y=\"125\" font-size=\"10\" fill=\"#666\">â€¢ Presentation</text>\n  <text x=\"75\" y=\"140\" font-size=\"10\" fill=\"#666\">â€¢ Slide</text>\n  <text x=\"75\" y=\"155\" font-size=\"10\" fill=\"#666\">â€¢ SlideTheme</text>\n  \n  <!-- Domain Interfaces -->\n  <rect x=\"230\" y=\"85\" width=\"140\" height=\"70\" fill=\"#ffffff\" stroke=\"#4a90a4\" stroke-width=\"1\" rx=\"3\"/>\n  <text x=\"300\" y=\"105\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"#333\">Interfaces</text>\n  <text x=\"235\" y=\"125\" font-size=\"10\" fill=\"#666\">â€¢ ContentAnalyzerInterface</text>\n  <text x=\"235\" y=\"140\" font-size=\"10\" fill=\"#666\">â€¢ RendererInterface</text>\n  <text x=\"235\" y=\"155\" font-size=\"10\" fill=\"#666\">â€¢ PresenterInterface</text>\n  \n  <!-- Service Layer -->\n  <rect x=\"50\" y=\"190\" width=\"700\" height=\"140\" fill=\"#f0f8e8\" stroke=\"#4a7c59\" stroke-width=\"2\" rx=\"5\"/>\n  <text x=\"60\" y=\"210\" font-size=\"14\" font-weight=\"bold\" fill=\"#2c5aa0\">Service Layer (Application Logic)</text>\n  \n  <!-- Controller -->\n  <rect x=\"70\" y=\"225\" width=\"140\" height=\"90\" fill=\"#ffffff\" stroke=\"#4a7c59\" stroke-width=\"1\" rx=\"3\"/>\n  <text x=\"140\" y=\"245\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"#333\">SlidesController</text>\n  <text x=\"75\" y=\"265\" font-size=\"10\" fill=\"#666\">â€¢ Orchestrates flow</text>\n  <text x=\"75\" y=\"280\" font-size=\"10\" fill=\"#666\">â€¢ Manages services</text>\n  <text x=\"75\" y=\"295\" font-size=\"10\" fill=\"#666\">â€¢ Handles errors</text>\n  <text x=\"75\" y=\"310\" font-size=\"10\" fill=\"#666\">â€¢ Returns results</text>\n  \n  <!-- Content Analyzer -->\n  <rect x=\"230\" y=\"225\" width=\"140\" height=\"90\" fill=\"#ffffff\" stroke=\"#4a7c59\" stroke-width=\"1\" rx=\"3\"/>\n  <text x=\"300\" y=\"245\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"#333\">ContentAnalyzer</text>\n  <text x=\"235\" y=\"265\" font-size=\"10\" fill=\"#666\">â€¢ Uses Claude AI</text>\n  <text x=\"235\" y=\"280\" font-size=\"10\" fill=\"#666\">â€¢ Analyzes content</text>\n  <text x=\"235\" y=\"295\" font-size=\"10\" fill=\"#666\">â€¢ Creates structure</text>\n  <text x=\"235\" y=\"310\" font-size=\"10\" fill=\"#666\">â€¢ Returns JSON</text>\n  \n  <!-- Asset Processor -->\n  <rect x=\"390\" y=\"225\" width=\"140\" height=\"90\" fill=\"#ffffff\" stroke=\"#4a7c59\" stroke-width=\"1\" rx=\"3\"/>\n  <text x=\"460\" y=\"245\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"#333\">AssetProcessor</text>\n  <text x=\"395\" y=\"265\" font-size=\"10\" fill=\"#666\">â€¢ Generates diagrams</text>\n  <text x=\"395\" y=\"280\" font-size=\"10\" fill=\"#666\">â€¢ Uploads to Litterbox</text>\n  <text x=\"395\" y=\"295\" font-size=\"10\" fill=\"#666\">â€¢ Updates JSON URLs</text>\n  <text x=\"395\" y=\"310\" font-size=\"10\" fill=\"#666\">â€¢ Handles caching</text>\n  \n  <!-- Infrastructure Layer -->\n  <rect x=\"50\" y=\"350\" width=\"700\" height=\"180\" fill=\"#fdf4e8\" stroke=\"#a47c4a\" stroke-width=\"2\" rx=\"5\"/>\n  <text x=\"60\" y=\"370\" font-size=\"14\" font-weight=\"bold\" fill=\"#2c5aa0\">Infrastructure Layer (External Integrations)</text>\n  \n  <!-- Renderer Factory -->\n  <rect x=\"70\" y=\"385\" width=\"140\" height=\"70\" fill=\"#ffffff\" stroke=\"#a47c4a\" stroke-width=\"1\" rx=\"3\"/>\n  <text x=\"140\" y=\"405\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"#333\">RendererFactory</text>\n  <text x=\"75\" y=\"425\" font-size=\"10\" fill=\"#666\">â€¢ Creates renderers</text>\n  <text x=\"75\" y=\"440\" font-size=\"10\" fill=\"#666\">â€¢ Factory pattern</text>\n  <text x=\"75\" y=\"455\" font-size=\"10\" fill=\"#666\">â€¢ Theme handling</text>\n  \n  <!-- PPTX Renderer -->\n  <rect x=\"230\" y=\"385\" width=\"140\" height=\"70\" fill=\"#ffffff\" stroke=\"#a47c4a\" stroke-width=\"1\" rx=\"3\"/>\n  <text x=\"300\" y=\"405\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"#333\">PptxRenderer</text>\n  <text x=\"235\" y=\"425\" font-size=\"10\" fill=\"#666\">â€¢ Uses python-pptx</text>\n  <text x=\"235\" y=\"440\" font-size=\"10\" fill=\"#666\">â€¢ Local images</text>\n  <text x=\"235\" y=\"455\" font-size=\"10\" fill=\"#666\">â€¢ File output</text>\n  \n  <!-- Google Slides Renderer -->\n  <rect x=\"390\" y=\"385\" width=\"140\" height=\"70\" fill=\"#ffffff\" stroke=\"#a47c4a\" stroke-width=\"1\" rx=\"3\"/>\n  <text x=\"460\" y=\"405\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"#333\">GoogleSlidesRenderer</text>\n  <text x=\"395\" y=\"425\" font-size=\"10\" fill=\"#666\">â€¢ Uses Google API</text>\n  <text x=\"395\" y=\"440\" font-size=\"10\" fill=\"#666\">â€¢ Remote images</text>\n  <text x=\"395\" y=\"455\" font-size=\"10\" fill=\"#666\">â€¢ URL output</text>\n  \n  <!-- External Services -->\n  <rect x=\"570\" y=\"385\" width=\"140\" height=\"130\" fill=\"#ffffff\" stroke=\"#a47c4a\" stroke-width=\"1\" rx=\"3\"/>\n  <text x=\"640\" y=\"405\" text-anchor=\"middle\" font-size=\"12\" font-weight=\"bold\" fill=\"#333\">External Services</text>\n  <text x=\"575\" y=\"425\" font-size=\"10\" fill=\"#666\">â€¢ Claude AI API</text>\n  <text x=\"575\" y=\"440\" font-size=\"10\" fill=\"#666\">â€¢ Google APIs</text>\n  <text x=\"575\" y=\"455\" font-size=\"10\" fill=\"#666\">â€¢ Litterbox CDN</text>\n  <text x=\"575\" y=\"470\" font-size=\"10\" fill=\"#666\">â€¢ Mermaid CLI</text>\n  <text x=\"575\" y=\"485\" font-size=\"10\" fill=\"#666\">â€¢ File System</text>\n  <text x=\"575\" y=\"500\" font-size=\"10\" fill=\"#666\">â€¢ Network APIs</text>\n  \n  <!-- Flow Arrows -->\n  <!-- Controller to Services -->\n  <path d=\"M 140 225 L 140 175\" stroke=\"#333\" stroke-width=\"2\" fill=\"none\" marker-end=\"url(#arrowhead)\"/>\n  <path d=\"M 210 270 L 230 270\" stroke=\"#333\" stroke-width=\"2\" fill=\"none\" marker-end=\"url(#arrowhead)\"/>\n  <path d=\"M 370 270 L 390 270\" stroke=\"#333\" stroke-width=\"2\" fill=\"none\" marker-end=\"url(#arrowhead)\"/>\n  \n  <!-- Services to Infrastructure -->\n  <path d=\"M 140 315 L 140 385\" stroke=\"#333\" stroke-width=\"2\" fill=\"none\" marker-end=\"url(#arrowhead)\"/>\n  <path d=\"M 210 420 L 230 420\" stroke=\"#333\" stroke-width=\"2\" fill=\"none\" marker-end=\"url(#arrowhead)\"/>\n  <path d=\"M 370 420 L 390 420\" stroke=\"#333\" stroke-width=\"2\" fill=\"none\" marker-end=\"url(#arrowhead)\"/>\n  \n  <!-- External connections -->\n  <path d=\"M 530 450 L 570 450\" stroke=\"#333\" stroke-width=\"2\" fill=\"none\" marker-end=\"url(#arrowhead)\"/>\n  \n  <!-- Data Flow Labels -->\n  <text x=\"150\" y=\"200\" text-anchor=\"middle\" font-size=\"10\" fill=\"#666\">manages</text>\n  <text x=\"220\" y=\"285\" text-anchor=\"middle\" font-size=\"10\" fill=\"#666\">analyze</text>\n  <text x=\"380\" y=\"285\" text-anchor=\"middle\" font-size=\"10\" fill=\"#666\">process</text>\n  <text x=\"150\" y=\"345\" text-anchor=\"middle\" font-size=\"10\" fill=\"#666\">create</text>\n  <text x=\"220\" y=\"435\" text-anchor=\"middle\" font-size=\"10\" fill=\"#666\">PPTX</text>\n  <text x=\"380\" y=\"435\" text-anchor=\"middle\" font-size=\"10\" fill=\"#666\">Slides</text>\n  <text x=\"550\" y=\"465\" text-anchor=\"middle\" font-size=\"10\" fill=\"#666\">API calls</text>\n  \n  <!-- Output -->\n  <rect x=\"250\" y=\"550\" width=\"300\" height=\"40\" fill=\"#e8f8e8\" stroke=\"#4a7c59\" stroke-width=\"2\" rx=\"5\"/>\n  <text x=\"400\" y=\"575\" text-anchor=\"middle\" font-size=\"14\" font-weight=\"bold\" fill=\"#2c5aa0\">Output: presentation.pptx OR Google Slides URL</text>\n  \n  <!-- Arrow from renderers to output -->\n  <path d=\"M 300 455 L 350 550\" stroke=\"#333\" stroke-width=\"2\" fill=\"none\" marker-end=\"url(#arrowhead)\"/>\n  <path d=\"M 460 455 L 450 550\" stroke=\"#333\" stroke-width=\"2\" fill=\"none\" marker-end=\"url(#arrowhead)\"/>\n  \n  <!-- Arrow marker definition -->\n  <defs>\n    <marker id=\"arrowhead\" markerWidth=\"10\" markerHeight=\"7\" \n            refX=\"9\" refY=\"3.5\" orient=\"auto\">\n      <polygon points=\"0 0, 10 3.5, 0 7\" fill=\"#333\"/>\n    </marker>\n  </defs>\n</svg>",
              "version_uuid": "122d6e31-bbf0-4e46-aff6-41d6088b28c2"
            },
            "message": "artifacts",
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "009adb8c-81a1-4c4a-b0c8-323935f18db6"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-05-22T15:31:19.789134Z",
            "stop_timestamp": "2025-05-22T15:31:29.849147Z",
            "flags": null,
            "type": "text",
            "text": "\n\n## Summary\n\n**Files to Remove (Duplicates/Old):**\n- `services/renderer_service.py` - Controller handles this\n- `assets/asset_manager.py` - Separate CLI tool, not core workflow  \n- `markdown/builder.py` - Old approach\n- `markdown/pptx_builder.py` - Old approach\n\n**Key Fixes:**\n1. **PPTX Renderer**: Now properly uses processed assets from AssetProcessor instead of guessing file paths\n2. **Clean Architecture**: Follows DDD with proper separation of concerns\n3. **Asset Flow**: AssetProcessor handles all diagram generation and uploads before rendering\n\n**Build & Run:**\n```bash\n# Quick start\nexport ANTHROPIC_API_KEY=\"your-key\"\npython -m makeslides --input content.md --format pptx\n\n# With diagrams and debugging\npython -m makeslides --input content.md --format google_slides --thinking --save-json\n```\n\nThe architecture is now much cleaner - like having a well-organized kitchen where the prep chef (AssetProcessor) handles all ingredient preparation, then passes clean, ready-to-use ingredients to the specialist cooks (Renderers) who focus only on their specific cooking techniques. No more cooks trying to chop vegetables while managing their stoves!",
            "citations": []
          }
        ],
        "updated_at": "2025-05-22T15:31:29.949715Z",
        "attachments": [],
        "files": []
      }
    }
  ]
}