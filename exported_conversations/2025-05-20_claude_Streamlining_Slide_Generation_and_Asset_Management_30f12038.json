{
  "id": "30f12038-f59f-4756-bdbd-0f0a8126b7c1",
  "source": "claude",
  "title": "Streamlining Slide Generation and Asset Management",
  "created_at": "2025-05-20T11:38:56.795204Z",
  "updated_at": "2025-05-20T11:46:13.945135Z",
  "summary": "",
  "message_count": 2,
  "messages": [
    {
      "id": "85f775af-6c1d-4aa4-801e-c7c58629cd5f",
      "role": "human",
      "content": "Why do we have generate slides as well as the magic slide.sh scritps?\nThe SVG production wasn't with mermaid, it was during rasterization - let's ignore that for now, perhaps let's take it out of our prompt and code in total **Image rasterization**\nSlides can also include generated images, using `$$$` fenced blocks for the data. Currently supported generated images are math expression (TeX and MathML) as well as SVG. Rasterized images are treated like local images are require opt-in to uploading images to a 3rd party service via the `--use-fileio` option.\nUsing TeX:\n\n```\n# How about some math?\n\n$$$ math\n\\cos (2\\theta) = \\cos^2 \\theta - \\sin^2 \\theta\n$$$\n\n```\n\nSVG\n\n```\n# Or some SVG?\n\n$$$ svg\n<svg xmlns=\"http://www.w3.org/2000/svg\"\n     xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n     viewBox=\"0 0 48 48\">\n  <defs>\n    <path id=\"a\" d=\"M44.5 20H24v8.5h11.8C34.7 33.9 30.1 37 24 37c-7.2 0-13-5.8-13-13s5.8-13 13-13c3.1 0 5.9 1.1 8.1 2.9l6.4-6.4C34.6 4.1 29.6 2 24 2 11.8 2 2 11.8 2 24s9.8 22 22 22c11 0 21-8 21-22 0-1.3-.2-2.7-.5-4z\"/>\n  </defs>\n  <clipPath id=\"b\">\n    <use xlink:href=\"#a\" overflow=\"visible\"/>\n  </clipPath>\n  <path clip-path=\"url(#b)\" fill=\"#EA4335\" d=\"M0 11l17 13 7-6.1L48 14V0H0z\"/>\n  <path clip-path=\"url(#b)\" fill=\"#34A853\" d=\"M0 37l30-23 7.9 1L48 0v48H0z\"/>\n  <path clip-path=\"url(#b)\" fill=\"#4285F4\" d=\"M48 48L17 24l-4-3 35-10z\"/>\n</svg>\n$$$\n\n```\n\nLike local images, generated images are temporarily served via file.io.\nPull requests for other image generators (e.g. mermaid, chartjs, etc.) are welcome!\n\nit says all this: except it doesn't really do that at all - the slides all look like this and the text inside the body doesn't have line breaks - no alternative layouts, no images generated, etc... \n\nShould we only use magic slides, review it all and assess for bugs, duplication, and ugly code, i want to have a folder where the files from upsplash are downloaded and a json to keep track of them, and the same folder should keep track of all the diagrams we made, why duplicate those too, you know. what's the best way to do this and streamline our work? \n\nWe're having an issue where magicSlide.sh makes slides that all look like this with no different templates, no images, and no diagrams and our diagrams were being created over and over 3 times and being slightly modified each time. I think we need a fresh look and a cleaner slate:",
      "created_at": "2025-05-20T11:40:27.097598Z",
      "sequence_order": 0,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-20T11:40:27.093090Z",
            "stop_timestamp": "2025-05-20T11:40:27.093090Z",
            "flags": null,
            "type": "text",
            "text": "Why do we have generate slides as well as the magic slide.sh scritps?\nThe SVG production wasn't with mermaid, it was during rasterization - let's ignore that for now, perhaps let's take it out of our prompt and code in total **Image rasterization**\nSlides can also include generated images, using `$$$` fenced blocks for the data. Currently supported generated images are math expression (TeX and MathML) as well as SVG. Rasterized images are treated like local images are require opt-in to uploading images to a 3rd party service via the `--use-fileio` option.\nUsing TeX:\n\n```\n# How about some math?\n\n$$$ math\n\\cos (2\\theta) = \\cos^2 \\theta - \\sin^2 \\theta\n$$$\n\n```\n\nSVG\n\n```\n# Or some SVG?\n\n$$$ svg\n<svg xmlns=\"http://www.w3.org/2000/svg\"\n     xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n     viewBox=\"0 0 48 48\">\n  <defs>\n    <path id=\"a\" d=\"M44.5 20H24v8.5h11.8C34.7 33.9 30.1 37 24 37c-7.2 0-13-5.8-13-13s5.8-13 13-13c3.1 0 5.9 1.1 8.1 2.9l6.4-6.4C34.6 4.1 29.6 2 24 2 11.8 2 2 11.8 2 24s9.8 22 22 22c11 0 21-8 21-22 0-1.3-.2-2.7-.5-4z\"/>\n  </defs>\n  <clipPath id=\"b\">\n    <use xlink:href=\"#a\" overflow=\"visible\"/>\n  </clipPath>\n  <path clip-path=\"url(#b)\" fill=\"#EA4335\" d=\"M0 11l17 13 7-6.1L48 14V0H0z\"/>\n  <path clip-path=\"url(#b)\" fill=\"#34A853\" d=\"M0 37l30-23 7.9 1L48 0v48H0z\"/>\n  <path clip-path=\"url(#b)\" fill=\"#4285F4\" d=\"M48 48L17 24l-4-3 35-10z\"/>\n</svg>\n$$$\n\n```\n\nLike local images, generated images are temporarily served via file.io.\nPull requests for other image generators (e.g. mermaid, chartjs, etc.) are welcome!\n\nit says all this: except it doesn't really do that at all - the slides all look like this and the text inside the body doesn't have line breaks - no alternative layouts, no images generated, etc... \n\nShould we only use magic slides, review it all and assess for bugs, duplication, and ugly code, i want to have a folder where the files from upsplash are downloaded and a json to keep track of them, and the same folder should keep track of all the diagrams we made, why duplicate those too, you know. what's the best way to do this and streamline our work? \n\nWe're having an issue where magicSlide.sh makes slides that all look like this with no different templates, no images, and no diagrams and our diagrams were being created over and over 3 times and being slightly modified each time. I think we need a fresh look and a cleaner slate:",
            "citations": []
          }
        ],
        "updated_at": "2025-05-20T11:40:27.097598Z",
        "attachments": [
          {
            "file_name": "generate_slides.sh",
            "file_size": 9595,
            "file_type": "text/x-sh",
            "extracted_content": "#!/bin/bash\n# generate_slides.sh - Generate visually appealing slides from facilitator guides\n# Usage: ./generate_slides.sh input.md [options]\n\nset -e  # Exit on error\n\n# Default options\nCONFIG=\"config.yaml\"\nMERMAID_CONFIG=\"mermaid-config.json\"\nLOG_LEVEL=\"INFO\"\nTITLE_PREFIX=\"\"\nSTYLE=\"github\"\nUSE_FILEIO=1\nCLAUDE_MODEL=\"claude-3-7-sonnet-20250219\"\nSTART_STEP=1  # Default start from beginning\n\n# Functions\nprint_usage() {\n  echo \"Usage: $0 <input.md or directory> [options]\"\n  echo \"Options:\"\n  echo \"  --config=FILE         YAML config file (default: config.yaml)\"\n  echo \"  --mermaid-config=FILE Mermaid config file (default: mermaid-config.json)\"\n  echo \"  --no-fileio           Don't use file.io for image uploads\"\n  echo \"  --title-prefix=TEXT   Add prefix to presentation titles\"\n  echo \"  --style=STYLE         Code highlighting style (default: github)\"\n  echo \"  --model=MODEL         Claude model (default: claude-3-7-sonnet-20250219)\"\n  echo \"  --log-level=LEVEL     Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)\"\n  echo \"  --start-step=NUM      Start from specific step (1-5, default: 1)\"\n  echo \"  --debug               Show debug info and verify npm installation\"\n  echo \"  --help                Show this help message\"\n}\n\n# Parse arguments\nINPUT=\"\"\nfor arg in \"$@\"; do\n  case $arg in\n    --config=*)\n      CONFIG=\"${arg#*=}\"\n      ;;\n    --mermaid-config=*)\n      MERMAID_CONFIG=\"${arg#*=}\"\n      ;;\n    --no-fileio)\n      USE_FILEIO=0\n      ;;\n    --title-prefix=*)\n      TITLE_PREFIX=\"${arg#*=}\"\n      ;;\n    --style=*)\n      STYLE=\"${arg#*=}\"\n      ;;\n    --model=*)\n      CLAUDE_MODEL=\"${arg#*=}\"\n      ;;\n    --log-level=*)\n      LOG_LEVEL=\"${arg#*=}\"\n      ;;\n    --start-step=*)\n      START_STEP=\"${arg#*=}\"\n      ;;\n    --debug)\n      LOG_LEVEL=\"DEBUG\"\n      VERIFY_NPM=1\n      ;;\n    --help)\n      print_usage\n      exit 0\n      ;;\n    -*)\n      echo \"Unknown option: $arg\"\n      print_usage\n      exit 1\n      ;;\n    *)\n      if [ -z \"$INPUT\" ]; then\n        INPUT=\"$arg\"\n      else\n        echo \"Multiple input files specified. Use only one.\"\n        print_usage\n        exit 1\n      fi\n      ;;\n  esac\ndone\n\n# Check for required input\nif [ -z \"$INPUT\" ]; then\n  echo \"Error: No input file or directory specified.\"\n  print_usage\n  exit 1\nfi\n\n# Check npm and md2gslides installation if requested\nif [ ${VERIFY_NPM:-0} -eq 1 ]; then\n  echo \"ðŸ” Checking node.js and md2gslides installation...\"\n  \n  # Check for npm\n  if ! command -v npm &> /dev/null; then\n    echo \"âŒ npm not found! Please install Node.js first.\"\n    echo \"Visit https://nodejs.org/ for installation instructions.\"\n    exit 1\n  fi\n  \n  echo \"âœ… npm is installed: $(npm --version)\"\n  \n  # Check for md2gslides\n  if ! command -v md2gslides &> /dev/null; then\n    echo \"âŒ md2gslides not found. Installing now...\"\n    npm install -g md2gslides\n    \n    if [ $? -ne 0 ]; then\n      echo \"âŒ Failed to install md2gslides. Please try manually:\"\n      echo \"npm install -g md2gslides\"\n      exit 1\n    fi\n  fi\n  \n  echo \"âœ… md2gslides is installed\"\n  \n  # Check for client_id.json\n  MD2G_DIR=\"$HOME/.md2googleslides\"\n  if [ ! -f \"$MD2G_DIR/client_id.json\" ]; then\n    echo \"âš ï¸  Warning: client_id.json not found at $MD2G_DIR/client_id.json\"\n    echo \"   You may need to set up Google API credentials.\"\n    mkdir -p \"$MD2G_DIR\"\n  else\n    echo \"âœ… Google API credentials found\"\n  fi\nfi\n\n# Determine input type\nif [ -d \"$INPUT\" ]; then\n  # Directory mode\n  echo \"ðŸ” Processing directory: $INPUT\"\n  WORKING_DIR=\"$INPUT\"\n  DIR_MODE=1\nelse\n  # Single file mode\n  echo \"ðŸ” Processing file: $INPUT\"\n  WORKING_DIR=\"$(dirname \"$INPUT\")\"\n  BASENAME=\"$(basename \"$INPUT\" .md)\"\n  BASENAME=\"${BASENAME%.txt}\"  # Also strip .txt if present\n  DIR_MODE=0\nfi\n\n# Create/verify necessary directories\nIMAGES_DIR=\"$WORKING_DIR/images\"\nmkdir -p \"$IMAGES_DIR\"\n\n# Function to check if step should be executed\nshould_run_step() {\n  local step=$1\n  if [ $step -ge $START_STEP ]; then\n    return 0  # True in bash\n  else\n    return 1  # False in bash\n  fi\n}\n\n# Create a progress file to track completed steps\nPROGRESS_FILE=\"$WORKING_DIR/.slide_progress\"\nif [ \"$START_STEP\" -eq 1 ]; then\n  # Starting fresh, remove any existing progress file\n  rm -f \"$PROGRESS_FILE\"\nfi\n\n# Create a function for each step that saves progress\nrun_step() {\n  local step_num=$1\n  local step_name=$2\n  local step_cmd=$3\n  \n  if should_run_step $step_num; then\n    echo \"Step $step_num/5: $step_name\"\n    \n    # Run the command\n    if eval \"$step_cmd\"; then\n      # Save progress\n      echo \"$step_num completed\" >> \"$PROGRESS_FILE\"\n      return 0\n    else\n      local exit_code=$?\n      echo \"âŒ Step $step_num failed with exit code $exit_code\"\n      echo \"To resume from this step, run with --start-step=$step_num\"\n      return $exit_code\n    fi\n  else\n    echo \"Skipping Step $step_num/5: $step_name (already completed)\"\n  fi\n}\n\n# Step 1: JSON Generation\nif [ $DIR_MODE -eq 1 ]; then\n  JSON_STEP=\"python guide_to_json.py \\\"$INPUT\\\" --config=\\\"$CONFIG\\\" --model=\\\"$CLAUDE_MODEL\\\" --log-level=\\\"$LOG_LEVEL\\\"\"\nelse\n  JSON_FILE=\"$WORKING_DIR/slides_$BASENAME.json\"\n  JSON_STEP=\"python guide_to_json.py \\\"$INPUT\\\" --config=\\\"$CONFIG\\\" --out=\\\"$JSON_FILE\\\" --model=\\\"$CLAUDE_MODEL\\\" --log-level=\\\"$LOG_LEVEL\\\"\"\nfi\nrun_step 1 \"ðŸ§  Converting to JSON with Claude...\" \"$JSON_STEP\" || exit $?\n\n# Step 2: Diagram Generation\nif [ $DIR_MODE -eq 1 ]; then\n  DIAGRAM_STEP=\"python diagrams_to_images.py \\\"$INPUT\\\" --mermaid-config=\\\"$MERMAID_CONFIG\\\" --output-dir=\\\"$IMAGES_DIR\\\" --log-level=\\\"$LOG_LEVEL\\\" --model=\\\"$CLAUDE_MODEL\\\" --preserve-all\"\nelse\n  DIAGRAM_STEP=\"python diagrams_to_images.py \\\"$JSON_FILE\\\" --mermaid-config=\\\"$MERMAID_CONFIG\\\" --output-dir=\\\"$IMAGES_DIR\\\" --log-level=\\\"$LOG_LEVEL\\\" --model=\\\"$CLAUDE_MODEL\\\" --preserve-all\"\nfi\nrun_step 2 \"ðŸ“Š Rendering diagrams...\" \"$DIAGRAM_STEP\" || exit $?\n\n# Step 3: CSV Generation\nif [ $DIR_MODE -eq 1 ]; then\n  CSV_STEP=\"python json_to_csv.py \\\"$INPUT\\\" --full --log-level=\\\"$LOG_LEVEL\\\"\"\nelse\n  CSV_STEP=\"python json_to_csv.py \\\"$JSON_FILE\\\" --full --log-level=\\\"$LOG_LEVEL\\\"\"\nfi\nrun_step 3 \"ðŸ“Š Generating CSV overview...\" \"$CSV_STEP\" || exit $?\n\n# Step 4: Markdown Generation\nif [ $DIR_MODE -eq 1 ]; then\n  MD_STEP=\"python json_to_markdown.py \\\"$INPUT\\\" --prefer-svg --log-level=\\\"$LOG_LEVEL\\\"\"\nelse\n  MD_STEP=\"python json_to_markdown.py \\\"$JSON_FILE\\\" --prefer-svg --log-level=\\\"$LOG_LEVEL\\\"\"\nfi\nrun_step 4 \"ðŸ“ Converting to markdown...\" \"$MD_STEP\" || exit $?\n\n# Store the markdown file path for the next step\nif [ $DIR_MODE -eq 1 ]; then\n  # Look for a file named after the directory (or slides_DIRBASE.md)\n  DIR_BASE=$(basename \"$INPUT\")\n  MD_FILE=\"$WORKING_DIR/$DIR_BASE.md\"\n  \n  # If not found, look for slides_*.md files\n  if [ ! -f \"$MD_FILE\" ]; then\n    MD_FILE=$(find \"$WORKING_DIR\" -maxdepth 1 -name \"slides_*.md\" | head -n 1)\n  fi\n  \n  # If still not found, find any .md file (except original source files)\n  if [ ! -f \"$MD_FILE\" ]; then\n    MD_FILE=$(find \"$WORKING_DIR\" -maxdepth 1 -name \"*.md\" -not -name \"day*.md\" | head -n 1)\n  fi\nelse\n  # For single file, first try with slides_ prefix\n  MD_FILE=\"$WORKING_DIR/slides_$BASENAME.md\"\n  \n  # If that doesn't exist, try without prefix\n  if [ ! -f \"$MD_FILE\" ]; then\n    MD_FILE=\"$WORKING_DIR/$BASENAME.md\"\n  fi\nfi\n\n# Check if markdown file exists\nif [ ! -f \"$MD_FILE\" ]; then\n  echo \"âŒ Error: Could not find generated markdown file!\"\n  echo \"Please check the output of Step 4 and specify the correct file path.\"\n  exit 1\nfi\n\necho \"ðŸ” Using markdown file: $MD_FILE\"\n\n# Step 5: Google Slides Generation\nFILEIO_ARG=\"\"\nif [ $USE_FILEIO -eq 1 ]; then\n  FILEIO_ARG=\"--use-fileio\"\nfi\n\nif [ $DIR_MODE -eq 1 ]; then\n  OUTPUT_FILE=\"$WORKING_DIR/presentations.txt\"\nelse\n  OUTPUT_FILE=\"$WORKING_DIR/${BASENAME}-presentation.txt\"\nfi\n\n# Define fixed command for slides generation\nSLIDES_STEP=\"python build_with_md2gslides.py \\\"$MD_FILE\\\" --title-prefix=\\\"$TITLE_PREFIX\\\" --style=\\\"$STYLE\\\" $FILEIO_ARG --log-level=\\\"$LOG_LEVEL\\\" --output-file=\\\"$OUTPUT_FILE\\\" --fix-format\"\n\nrun_step 5 \"ðŸŽ¯ Generating Google Slides...\" \"$SLIDES_STEP\" || {\n  echo \"âŒ Failed to create Google Slides presentation.\"\n  echo \"This might be due to issues with md2gslides or the markdown format.\"\n  echo \"\"\n  echo \"Here's the first 20 lines of the markdown file:\"\n  head -n 20 \"$MD_FILE\"\n  echo \"\"\n  echo \"Possible solutions:\"\n  echo \"1. Install md2gslides manually: npm install -g md2gslides\"\n  echo \"2. Set up Google API credentials (see md2gslides documentation)\"\n  echo \"3. Run with --debug flag to check installation and credentials\"\n  echo \"4. Try running md2gslides manually: md2gslides $MD_FILE --title \\\"$BASENAME\\\"\"\n  exit 1\n}\n\n# Print statistics and summary\necho \"âœ… All done! Your slides are ready.\"\necho \"ðŸ“‹ Presentation links saved to: $OUTPUT_FILE\"\n\n# Count layouts, images and diagrams in the JSON file\nif [ -f \"${JSON_FILE:-}\" ]; then\n  echo \"\"\n  echo \"ðŸ“Š Slide statistics:\"\n  \n  # Count total slides\n  TOTAL_SLIDES=$(grep -c \"\\\"slide_number\\\":\" \"$JSON_FILE\" || echo \"0\")\n  echo \"Total slides: $TOTAL_SLIDES\"\n  \n  # Count diagrams\n  DIAGRAMS=$(grep -c \"\\\"diagram_type\\\":\" \"$JSON_FILE\" | grep -v \"\\\"diagram_type\\\": null\" || echo \"0\")\n  echo \"Diagrams: $DIAGRAMS\"\n  \n  # Count images\n  IMAGES=$(grep -c \"\\\"image_url\\\":\" \"$JSON_FILE\" | grep -v \"\\\"image_url\\\": null\" || echo \"0\")\n  echo \"Images: $IMAGES\"\n  \n  # Count different layouts\n  echo \"\"\n  echo \"Layout variety:\"\n  grep -o \"\\\"layout\\\": \\\"[^\\\"]*\\\"\" \"$JSON_FILE\" | sort | uniq -c\nfi\n\necho \"\"\necho \"To view your presentation, open the link in the output file: $OUTPUT_FILE\""
          },
          {
            "file_name": "unsplash_cache.py",
            "file_size": 8043,
            "file_type": "",
            "extracted_content": "#!/usr/bin/env python3\n\"\"\"\nUnsplash Image Cache and Search Tool\n\nThis script manages a local cache of Unsplash images and provides search functionality\nto find appropriate images for different slide types. It reduces API calls by maintaining\na local database of previously fetched images.\n\"\"\"\nfrom __future__ import annotations\nimport argparse\nimport json\nimport logging\nimport os\nimport requests\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any\nimport random\n\nLOGGER = logging.getLogger(\"unsplash_image_cache\")\n\n# Default cache file location\nDEFAULT_CACHE_PATH = Path.home() / \".makeslides\" / \"unsplash_cache.json\"\n\n# Default Unsplash image URLs by category\nDEFAULT_IMAGES = {\n    \"solar\": [\n        \"https://images.unsplash.com/photo-1611744968035-b606937fdd8d\",\n        \"https://images.unsplash.com/photo-1521618755572-156ae0cdd74d\"\n    ],\n    \"installation\": [\n        \"https://images.unsplash.com/photo-1509391366360-2e959784a276\",\n        \"https://images.unsplash.com/photo-1602338038325-309fcb428972\"\n    ],\n    \"tools\": [\n        \"https://images.unsplash.com/photo-1581166397057-235af2b3c6dd\",\n        \"https://images.unsplash.com/photo-1564986410613-97e0b371efe5\"\n    ],\n    \"safety\": [\n        \"https://images.unsplash.com/photo-1578874691223-64558a3ca096\",\n        \"https://images.unsplash.com/photo-1504328345606-18bbc8c9d7d1\"\n    ],\n    \"training\": [\n        \"https://images.unsplash.com/photo-1524178232363-1fb2b075b655\",\n        \"https://images.unsplash.com/photo-1573497019418-b400bb3ab074\"\n    ],\n    \"break\": [\n        \"https://images.unsplash.com/photo-1510784722466-f2aa9c52fff6\",\n        \"https://images.unsplash.com/photo-1495474472287-4d71bcdd2085\"\n    ]\n}\n\n\ndef cli() -> argparse.Namespace:\n    \"\"\"Parse command line arguments.\"\"\"\n    p = argparse.ArgumentParser(description=\"Unsplash Image Cache and Search Tool\")\n    p.add_argument(\"--search\", help=\"Search for images by keyword\")\n    p.add_argument(\"--category\", help=\"Get image URLs from a predefined category\")\n    p.add_argument(\"--count\", type=int, default=1, help=\"Number of images to return\")\n    p.add_argument(\"--cache-path\", default=DEFAULT_CACHE_PATH, help=\"Path to cache file\")\n    p.add_argument(\"--update-cache\", action=\"store_true\", help=\"Force update of the cache\")\n    p.add_argument(\"--api-key\", help=\"Unsplash API access key (or use UNSPLASH_ACCESS_KEY env var)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--json-output\", action=\"store_true\", help=\"Output as JSON\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str):\n    \"\"\"Configure logging.\"\"\"\n    logging.basicConfig(\n        level=level,\n        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n        handlers=[logging.StreamHandler(sys.stdout)]\n    )\n\n\ndef load_cache(cache_path: Path) -> Dict[str, List[Dict[str, Any]]]:\n    \"\"\"Load the image cache from disk.\"\"\"\n    if not cache_path.exists():\n        LOGGER.info(f\"Cache file not found at {cache_path}. Creating new cache.\")\n        cache_path.parent.mkdir(parents=True, exist_ok=True)\n        return {}\n    \n    try:\n        with open(cache_path, 'r') as f:\n            cache = json.load(f)\n        LOGGER.debug(f\"Loaded cache with {len(cache)} keywords\")\n        return cache\n    except Exception as e:\n        LOGGER.warning(f\"Error loading cache: {e}. Creating new cache.\")\n        return {}\n\n\ndef save_cache(cache: Dict[str, List[Dict[str, Any]]], cache_path: Path):\n    \"\"\"Save the image cache to disk.\"\"\"\n    try:\n        with open(cache_path, 'w') as f:\n            json.dump(cache, f, indent=2)\n        LOGGER.debug(f\"Saved cache with {len(cache)} keywords to {cache_path}\")\n    except Exception as e:\n        LOGGER.error(f\"Error saving cache: {e}\")\n\n\ndef search_unsplash(query: str, api_key: str, per_page: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"Search Unsplash API for images matching the query.\"\"\"\n    url = \"https://api.unsplash.com/search/photos\"\n    headers = {\"Accept-Version\": \"v1\", \"Authorization\": f\"Client-ID {api_key}\"}\n    params = {\n        \"query\": query,\n        \"orientation\": \"landscape\",\n        \"per_page\": per_page,\n        \"content_filter\": \"high\"\n    }\n    \n    try:\n        response = requests.get(url, headers=headers, params=params)\n        data = response.json()\n        \n        if response.status_code != 200 or \"results\" not in data:\n            LOGGER.error(f\"Unsplash API error: {data}\")\n            return []\n        \n        results = []\n        for photo in data[\"results\"]:\n            results.append({\n                \"id\": photo[\"id\"],\n                \"description\": photo[\"alt_description\"] or photo[\"description\"] or query,\n                \"url\": photo[\"urls\"][\"full\"],\n                \"thumbnail\": photo[\"urls\"][\"small\"],\n                \"photographer\": photo[\"user\"][\"name\"],\n                \"photographer_url\": photo[\"user\"][\"links\"][\"html\"]\n            })\n        \n        LOGGER.info(f\"Found {len(results)} images for query '{query}'\")\n        return results\n    \n    except Exception as e:\n        LOGGER.error(f\"Error searching Unsplash: {e}\")\n        return []\n\n\ndef get_images_for_category(category: str, cache: Dict[str, List[Dict[str, Any]]], \n                          count: int = 1) -> List[str]:\n    \"\"\"Get image URLs for a predefined category from cache or defaults.\"\"\"\n    # First try the cache\n    if category in cache and cache[category]:\n        images = [img[\"url\"] for img in cache[category][:count]]\n        if len(images) >= count:\n            return images\n    \n    # Then try defaults\n    normalized_category = category.lower()\n    for cat, urls in DEFAULT_IMAGES.items():\n        if normalized_category in cat or cat in normalized_category:\n            return urls[:count]\n    \n    # Return first item from any category if no match\n    for urls in DEFAULT_IMAGES.values():\n        if urls:\n            return urls[:count]\n    \n    return []\n\n\ndef search_images(query: str, cache: Dict[str, List[Dict[str, Any]]], api_key: str = None, \n                count: int = 1, update_cache: bool = False) -> List[str]:\n    \"\"\"Search for images by keyword, using cache when possible.\"\"\"\n    # Check cache first unless update is forced\n    if not update_cache and query in cache and cache[query]:\n        LOGGER.info(f\"Using cached results for '{query}'\")\n        return [img[\"url\"] for img in cache[query][:count]]\n    \n    # If we need to search but have no API key, try to find similar categories\n    if not api_key:\n        LOGGER.warning(\"No API key provided. Searching only in cache and defaults.\")\n        return get_images_for_category(query, cache, count)\n    \n    # Search Unsplash\n    results = search_unsplash(query, api_key, per_page=10)\n    \n    # Update cache\n    if results:\n        cache[query] = results\n        \n    # Return requested number of URLs\n    return [img[\"url\"] for img in results[:count]]\n\n\ndef main():\n    \"\"\"Main function.\"\"\"\n    args = cli()\n    setup_logging(args.log_level)\n    \n    # Get API key from args or environment\n    api_key = args.api_key or os.environ.get(\"UNSPLASH_ACCESS_KEY\")\n    \n    # Convert cache path to Path object\n    cache_path = Path(args.cache_path)\n    \n    # Load cache\n    cache = load_cache(cache_path)\n    \n    # Process request\n    if args.search:\n        results = search_images(args.search, cache, api_key, args.count, args.update_cache)\n        \n        if args.json_output:\n            print(json.dumps(results))\n        else:\n            for url in results:\n                print(url)\n                \n        # Save updated cache\n        save_cache(cache, cache_path)\n        \n    elif args.category:\n        results = get_images_for_category(args.category, cache, args.count)\n        \n        if args.json_output:\n            print(json.dumps(results))\n        else:\n            for url in results:\n                print(url)\n    \n    else:\n        print(\"Please provide either --search or --category argument.\")\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()"
          },
          {
            "file_name": "config.yaml",
            "file_size": 9308,
            "file_type": "",
            "extracted_content": "name: facilitator-guide-to-json\ndescription: Converts training facilitator guides into structured JSON format for Marp slides using Claude's extended thinking\n\nprompt: |\n  You are an instructional-design expert creating Marp slides for the BEIT Solar Energy Training (Mosul, Iraq). I need you to deeply analyze the facilitator guide and convert it into comprehensive, well-structured JSON for slide generation.\n\n  ## Your Thinking Process\n\n  Take your time to think thoroughly about this task. You'll perform a multi-stage analysis of the facilitator guide before finalizing the JSON output:\n\n  1. First, thoroughly read and understand the full facilitator guide. Identify the overall structure, key learning objectives, main activities, and natural transitions where separate slides would be beneficial.\n\n  2. Create a mental outline of how this content should flow as a presentation. Think about the optimal slide sequence, focusing on learner engagement and knowledge retention. Consider the logical progression from title slides to objectives, content, activities, and conclusion.\n\n  3. For each potential slide, carefully consider:\n     - What core message or concept should this slide communicate?\n     - What visual elements (diagrams, images, SVGs) would enhance understanding?\n     - What facilitator notes would help the presenter deliver this content effectively?\n     - How much time should be allocated to this slide within the overall session?\n\n  CONTENT GUIDELINES:\n  - Extract key ideas from \"What to Say,\" \"Steps,\" and \"Common Q&A\" sections\n  - Include only financial examples that directly advance learning objectives\n  - Hide trainer guidance and timing tips in the facilitator_notes field\n  - Create realistic image_url placeholders that reflect slide content\n\n  4. Reflect on how to optimize each slide for adult learning principles - be concise, relevant, and visually supportive without overwhelming learners.\n\n  5. Structure your final JSON output meticulously, ensuring all fields have appropriate values and the entire array is valid, complete, and follows proper JSON syntax.\n\n  ## Visual Elements Guidelines\n\n  Enhance understanding by using the appropriate visual format for each slide type:\n\n  - **Processes or Workflows**: Create a flowchart diagram (diagram_type: \"flowchart\")\n  - **Cost Comparisons**: Use a pie chart diagram (diagram_type: \"pie\")\n  - **Component Relationships**: Use a class diagram (diagram_type: \"classDiagram\")\n  - **Concepts or Categories**: Use a mindmap diagram (diagram_type: \"mindmap\")\n  - **Schedules or Timelines**: Use a timeline diagram (diagram_type: \"timeline\")\n  - **Equipment or Installation**: Include a relevant image (image_url: from list below)\n  - **Theoretical Concepts**: Use a diagram to illustrate (appropriate diagram_type)\n  - **Activities/Breaks**: Include an appropriate image (image_url: from list below)\n\n  Available Image URLs:\n  * Solar Panels: https://images.unsplash.com/photo-1611744968035-b606937fdd8d\n  * Solar Installation: https://images.unsplash.com/photo-1521618755572-156ae0cdd74d\n  * Roof Installation: https://images.unsplash.com/photo-1509391366360-2e959784a276\n  * Solar Worker: https://images.unsplash.com/photo-1602338038325-309fcb428972\n  * Calculator: https://images.unsplash.com/photo-1564986410613-97e0b371efe5\n  * Maintenance: https://images.unsplash.com/photo-1504328345606-18bbc8c9d7d1\n  * Safety Equipment: https://images.unsplash.com/photo-1578874691223-64558a3ca096\n  * Tools: https://images.unsplash.com/photo-1581166397057-235af2b3c6dd\n  * Training: https://images.unsplash.com/photo-1524178232363-1fb2b075b655\n  * Discussion: https://images.unsplash.com/photo-1573497019418-b400bb3ab074\n  * Break Time: https://images.unsplash.com/photo-1510784722466-f2aa9c52fff6\n  * Coffee Break: https://images.unsplash.com/photo-1495474472287-4d71bcdd2085\n\n  ## Layout Selection Guidelines\n\n  Choose from these slide layouts based on content type:\n  - \"title\": For title slides and opening slides (map to TITLE)\n  - \"section\": For section dividers and topic transitions (map to SECTION_HEADER)\n  - \"content\": For regular content and bullet points (map to TITLE_AND_BODY)\n  - \"columns\": For comparing two concepts or image+text (map to TITLE_AND_TWO_COLUMNS)\n  - \"activity\": For workshop activities and exercises (map to TITLE_AND_BODY)\n  - \"main_point\": For emphasizing a key takeaway (map to MAIN_POINT)\n  - \"big_number\": For statistics and metrics (map to BIG_NUMBER)\n  - \"logistics\": For schedules and practical information (map to TITLE_AND_BODY)\n  - \"break\": For breaks and transitions (map to CAPTION with a nice image)\n  - \"closing\": For summary and conclusion slides (map to TITLE_AND_BODY)\n\n  ## Diagram Syntax Guidelines\n\n  * ALWAYS start diagram code with the diagram type followed by a SPACE then direction (e.g., \"flowchart TD\")\n  * For flowcharts, use \"flowchart TD\" (not \"graph td\")\n  * Ensure proper spacing in the syntax (e.g., \"A --> B\")\n  * Do not include extra spaces inside node brackets (use \"[Label]\", not \"[ Label ]\")\n  * Always use capital letters for directions (TD, LR, BT, RL)\n  * Keep diagrams simple with 15 or fewer nodes\n\n  ## Output Format Requirements\n\n  Return ONLY a valid JSON object with a `slides` key containing an array of slide objects. Each slide should be an object with these fields:\n  - slide_number: Sequential number starting from 1 (integer, not a string)\n  - title: Main slide title (string)\n  - content: Bullet points or main text content (â‰¤40 words, unless for activity instructions)\n  - layout: Layout type from options above (string) - VARIED AND DELIBERATE CHOICE\n  - image_url: URL to a real image from the verified list above (if applicable, otherwise null)\n  - diagram_type: Type of diagram (flowchart, mindmap, pie, etc. - if applicable, otherwise null)\n  - diagram_content: Mermaid syntax for the diagram (if applicable, otherwise null)\n  - facilitator_notes: Guidance for the presenter (string)\n  - start_time: Start time based on agenda (HH:MM format, 24-hour)\n  - end_time: End time based on agenda (HH:MM format, 24-hour)\n  - materials: Required materials for this section (string)\n  - worksheet: Worksheet details (if applicable, otherwise null)\n  - improvements: Suggestions for localization, engagement tips, or content enhancements (string)\n  - notes: Additional information (string)\n\n  ## JSON Validation Checklist\n\n  Before finalizing your output, verify that:\n  - The JSON object starts with `{` and ends with `}`\n  - The `\"slides\"` key contains a JSON array starting with `[` and ending with `]`\n  - All property names are in double quotes: \"property_name\"\n  - All string values are in double quotes: \"value\"\n  - Numbers have no quotes: 1, 2, 3\n  - Boolean values are lowercase without quotes: true, false\n  - null values are without quotes: null\n  - No trailing commas\n  - The entire JSON is valid and can be parsed with JSON.parse()\n\n  Your output must be a valid JSON **object** like this:\n\n  ```json\n  {\n    \"slides\": [ ... ]\n  }\n  ```\n  Return ONLY a valid JSON object with a `slides` key containing an array of slide objects. Each slide should be an object with these fields:\n  - slide_number: Sequential number starting from 1 (integer, not a string)\n  - title: Main slide title (string)\n  - content: Bullet points or main text content (â‰¤40 words, unless for activity instructions)\n  - layout: Layout type from options above (string) - VARIED AND DELIBERATE CHOICE\n  - image_url: URL to a real image from the verified list above (if applicable, otherwise null)\n  - diagram_type: Type of diagram (flowchart, mindmap, pie, etc. - if applicable, otherwise null)\n  - diagram_content: Mermaid syntax for the diagram (if applicable, otherwise null)\n  - facilitator_notes: Guidance for the presenter (string)\n  - start_time: Start time based on agenda (HH:MM format, 24-hour)\n  - end_time: End time based on agenda (HH:MM format, 24-hour)\n  - materials: Required materials for this section (string)\n  - worksheet: Worksheet details (if applicable, otherwise null)\n  - improvements: Suggestions for localization, engagement tips, or content enhancements (string)\n  - notes: Additional information (string)\n\n  Do not include any text or explanation. Just return a JSON object with a `slides` key containing the array of slide objects.\n\n  FACILITATOR GUIDE:\n  Please convert the following facilitator guide into a detailed JSON slides outline.\n\n  For each slide, identify:\n  1. A clear title (max 60 chars)\n  2. Bullet-point content (max 40 words per slide)\n  3. The most appropriate layout from: title, section, content, columns, activity, main_point, big_number, logistics, break, closing\n  4. Any diagrams that should be created (using mermaid syntax for flowcharts, mindmaps, or timelines)\n  5. Image descriptions for relevant visuals\n  6. Facilitator notes to help the presenter\n\n  Return the `slides` array wrapped in a valid JSON object, under the key `\"slides\"`.\n\nlayout_mappings:\n  \"title\": \"TITLE\"\n  \"section\": \"SECTION_HEADER\" \n  \"content\": \"TITLE_AND_BODY\"\n  \"columns\": \"TITLE_AND_TWO_COLUMNS\"\n  \"activity\": \"TITLE_AND_BODY\"\n  \"main_point\": \"MAIN_POINT\"\n  \"big_number\": \"BIG_NUMBER\"\n  \"logistics\": \"TITLE_AND_BODY\"\n  \"break\": \"CAPTION\"\n  \"closing\": \"TITLE_AND_BODY\"\n\nslide_defaults:\n  \"chart_type\": null\n  \"image_url\": null"
          },
          {
            "file_name": "diagrams_to_images.py",
            "file_size": 28182,
            "file_type": "",
            "extracted_content": "#!/usr/bin/env python3\n\"\"\"Render Mermaid diagrams to local image files with auto-conversion of plain text.\n\nSaves diagrams locally and updates the slides.json with relative file paths\ninstead of using external image hosting. Automatically converts plain text\nsequences to proper Mermaid syntax.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, subprocess, sys, time, hashlib\nfrom pathlib import Path\nfrom typing import Any, List, Optional, Tuple\nimport tempfile\nimport anthropic\nimport re\nimport shutil\n\nLOGGER = logging.getLogger(\"diagrams_to_images\")\nMERMAID_CMD = \"mmdc\"  # must be on PATH\n\n# Common diagram type mappings for fallbacks\nDIAGRAM_FALLBACKS = {\n    \"flowchart\": [\"flowchart TD\", \"flowchart LR\", \"flowchart RL\", \"mindmap\"],\n    \"mindmap\": [\"flowchart TD\", \"flowchart LR\", \"classDiagram\"],\n    \"pie\": [\"pie\", \"flowchart TD\"],\n    \"quadrantChart\": [\"quadrantChart\", \"flowchart\", \"classDiagram\"],\n    \"classDiagram\": [\"classDiagram\", \"flowchart TD\", \"mindmap\"],\n    \"timeline\": [\"timeline\", \"flowchart TD\"]\n}\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Render Mermaid diagrams to local files\")\n    p.add_argument(\"json\", help=\"slides.json to update (in-place) or directory of JSON files\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    p.add_argument(\"--output-dir\", default=None, help=\"Directory to save image files (default: same as slides.json)\")\n    p.add_argument(\"--mermaid-config\", default=\"mermaid-config.json\", help=\"Mermaid configuration file\")\n    p.add_argument(\"--model\", default=\"claude-3-7-sonnet-20250219\", help=\"Claude model to use for fixing diagrams\")\n    p.add_argument(\"--preserve-all\", action=\"store_true\", help=\"Keep all generated images, don't overwrite\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef is_valid_mermaid_syntax(src: str) -> bool:\n    \"\"\"Check if the diagram content has valid Mermaid syntax structure.\"\"\"\n    # Valid Mermaid diagrams usually start with a diagram type followed by direction\n    # e.g., \"flowchart TD\", \"mindmap\", \"classDiagram\", etc.\n    pattern = r'^(flowchart|mindmap|classDiagram|pie|quadrantChart|timeline|sequenceDiagram|stateDiagram-v2|gantt|journey|gitGraph)\\s*([A-Z]{2})?'\n    if re.match(pattern, src.strip()):\n        return True\n    \n    # Check if it contains any Mermaid-specific syntax\n    mermaid_syntax = ['-->', '-.->', '===>', '-->|', '-.->|', '==>|', '---|', '-.-|', '===|']\n    return any(token in src for token in mermaid_syntax)\n\n\ndef convert_text_to_mermaid(text: str, diagram_type: str) -> str:\n    \"\"\"Convert plain text to a proper Mermaid diagram syntax.\"\"\"\n    # Split on arrows, commas, periods, or other separators\n    steps = []\n    \n    # Check for arrow separators first\n    if 'â†’' in text or '->' in text or ',' in text:\n        # Split by arrows or commas\n        separators = ['â†’', '->', ',']\n        for sep in separators:\n            if sep in text:\n                steps = [step.strip() for step in text.split(sep)]\n                break\n    else:\n        # Split on periods or just use as single step\n        if '.' in text:\n            steps = [step.strip() for step in text.split('.') if step.strip()]\n        else:\n            steps = [text.strip()]\n    \n    # Generate appropriate Mermaid syntax based on the diagram type\n    if diagram_type.lower() == \"flowchart\":\n        result = \"flowchart TD\\n\"\n        for i, step in enumerate(steps):\n            node_id = chr(65 + i)  # A, B, C, ...\n            result += f\"    {node_id}[\\\"{step}\\\"]\\n\"\n        \n        # Add connections\n        for i in range(len(steps) - 1):\n            node1 = chr(65 + i)\n            node2 = chr(65 + i + 1)\n            result += f\"    {node1} --> {node2}\\n\"\n            \n    elif diagram_type.lower() == \"mindmap\":\n        result = \"mindmap\\n\"\n        result += f\"    root(({steps[0]}))\\n\"\n        \n        for i, step in enumerate(steps[1:], 1):\n            result += f\"        {step}\\n\"\n            \n    elif diagram_type.lower() == \"timeline\":\n        result = \"timeline\\n\"\n        result += \"    title Process Timeline\\n\"\n        \n        for step in steps:\n            result += f\"    section {step}\\n\"\n            \n    else:\n        # Default to flowchart if unsure\n        result = \"flowchart TD\\n\"\n        for i, step in enumerate(steps):\n            node_id = chr(65 + i)\n            result += f\"    {node_id}[\\\"{step}\\\"]\\n\"\n        \n        # Add connections\n        for i in range(len(steps) - 1):\n            node1 = chr(65 + i)\n            node2 = chr(65 + i + 1)\n            result += f\"    {node1} --> {node2}\\n\"\n    \n    return result\n\n\ndef fix_mermaid_with_claude(src: str, error_msg: str, client: anthropic.Anthropic, model: str) -> str:\n    \"\"\"Use Claude to fix Mermaid syntax errors.\"\"\"\n    prompt = f\"\"\"You are a Mermaid diagram expert. Fix the following Mermaid diagram that has syntax errors.\n\nError message:\n{error_msg}\n\nCurrent diagram:\n```\n{src}\n```\n\nPlease provide ONLY the fixed diagram code with no explanation or markdown formatting - just return the raw fixed Mermaid syntax.\nFollow these guidelines:\n- Ensure proper spacing in syntax (e.g., \"A --> B\")\n- No extra spaces inside node brackets (use \"[Label]\", not \"[ Label ]\")\n- Use capital letters for directions (TD, LR, BT, RL)\n- Keep diagrams simple with 15 or fewer nodes\n- Start with diagram type and direction (e.g., \"flowchart TD\")\n- ONLY use standard Mermaid types: flowchart, mindmap, pie, classDiagram, etc.\n- Do NOT create custom types like \"illustration\" or non-standard formats\n\"\"\"\n\n    try:\n        response = client.messages.create(\n            model=model,\n            max_tokens=1024,\n            temperature=0.0,\n            system=\"You are a diagram syntax expert who returns only fixed mermaid syntax - no explanations.\",\n            messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        fixed_src = response.content[0].text.strip()\n        \n        # Check if the response includes markdown formatting and remove it\n        if fixed_src.startswith(\"```\") and fixed_src.endswith(\"```\"):\n            fixed_src = fixed_src[3:-3].strip()\n            if fixed_src.startswith(\"mermaid\\n\"):\n                fixed_src = fixed_src[8:].strip()\n        \n        LOGGER.info(\"Claude fixed the Mermaid syntax issues\")\n        return fixed_src\n    except Exception as e:\n        LOGGER.error(\"Error using Claude to fix Mermaid: %s\", e)\n        return src  # Return original if Claude fails\n\n\ndef convert_plain_text_to_mermaid_with_claude(text: str, diagram_type: str, client: anthropic.Anthropic, model: str) -> str:\n    \"\"\"Use Claude to convert plain text to a proper Mermaid diagram.\"\"\"\n    prompt = f\"\"\"You are a Mermaid diagram expert. Convert this plain text description into a proper Mermaid diagram of type \"{diagram_type}\".\n\nPlain text:\n{text}\n\nPlease provide ONLY the Mermaid diagram code with no explanation or markdown formatting - just return the raw Mermaid syntax.\nFollow these guidelines:\n- Format as a proper {diagram_type} diagram\n- Start with diagram type (e.g., \"flowchart TD\" or \"mindmap\")\n- Keep it simple with max 15 nodes\n- Use proper Mermaid syntax with correct spacing\n- Make it visually clear and easy to understand\n- ONLY use standard Mermaid types (flowchart, mindmap, pie, classDiagram)\n- DO NOT create custom types like \"illustration\" or non-standard formats\n\"\"\"\n\n    try:\n        response = client.messages.create(\n            model=model,\n            max_tokens=1024,\n            temperature=0.0,\n            system=\"You are a diagram syntax expert who returns only Mermaid syntax - no explanations.\",\n            messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        converted_src = response.content[0].text.strip()\n        \n        # Check if the response includes markdown formatting and remove it\n        if converted_src.startswith(\"```\") and converted_src.endswith(\"```\"):\n            converted_src = converted_src[3:-3].strip()\n            if converted_src.startswith(\"mermaid\\n\"):\n                converted_src = converted_src[8:].strip()\n        \n        LOGGER.info(\"Claude converted plain text to Mermaid diagram\")\n        return converted_src\n    except Exception as e:\n        LOGGER.error(\"Error using Claude to convert text to Mermaid: %s\", e)\n        # Fallback to simple conversion\n        return convert_text_to_mermaid(text, diagram_type)\n\n\ndef suggest_alternative_diagram(src: str, diagram_type: str, client: anthropic.Anthropic, model: str) -> Tuple[str, str]:\n    \"\"\"Use Claude to suggest an alternative diagram type for the same content.\"\"\"\n    prompt = f\"\"\"You are a Mermaid diagram expert. This diagram of type \"{diagram_type}\" is failing to render. \nConvert it to a simpler alternative diagram type that conveys the same information.\n\nOriginal diagram:\n```\n{src}\n```\n\nPlease provide ONLY the converted diagram code with no explanation or markdown formatting.\nGood alternatives could be:\n- flowchart TD (top-down flowchart, the most reliable format)\n- flowchart LR (left-right flowchart)\n- classDiagram (for hierarchies, very reliable)\n- mindmap (for conceptual relationships)\n\nFocus on simplicity and reliability. Remove any fancy styling or complex features.\nONLY use standard Mermaid types (flowchart, mindmap, pie, classDiagram).\nDO NOT create custom types like \"illustration\" or non-standard formats.\n\"\"\"\n\n    try:\n        response = client.messages.create(\n            model=model,\n            max_tokens=1024,\n            temperature=0.0,\n            system=\"You are a diagram expert who returns only converted mermaid syntax - no explanations.\",\n            messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        converted_src = response.content[0].text.strip()\n        \n        # Check if the response includes markdown formatting and remove it\n        if converted_src.startswith(\"```\") and converted_src.endswith(\"```\"):\n            converted_src = converted_src[3:-3].strip()\n            if converted_src.startswith(\"mermaid\\n\"):\n                converted_src = converted_src[8:].strip()\n        \n        # Detect the new diagram type\n        new_type = converted_src.split(\" \")[0] if \" \" in converted_src else diagram_type\n        LOGGER.info(f\"Claude converted diagram from {diagram_type} to {new_type}\")\n        return converted_src, new_type\n    except Exception as e:\n        LOGGER.error(\"Error using Claude to convert diagram: %s\", e)\n        \n        # Fallback to a simpler diagram type without Claude\n        if diagram_type in DIAGRAM_FALLBACKS and len(DIAGRAM_FALLBACKS[diagram_type]) > 0:\n            new_type = DIAGRAM_FALLBACKS[diagram_type][0].split(\" \")[0]\n            LOGGER.info(f\"Falling back to {new_type} diagram type\")\n            return src.replace(diagram_type, DIAGRAM_FALLBACKS[diagram_type][0], 1), new_type\n        return src, diagram_type\n\n\ndef render_mermaid(src: str, output_dir: Path, config_path: Optional[Path], base_filename: str, slide_num: int, \n                   diagram_type: str, client: Optional[anthropic.Anthropic] = None, model: str = \"\", \n                   preserve_all: bool = False) -> Path:\n    \"\"\"Render mermaid diagram to PNG with auto-fixing.\n    \n    Args:\n        src: Mermaid diagram content\n        output_dir: Directory to save files\n        config_path: Path to mermaid config file\n        base_filename: Base filename (from guide file)\n        slide_num: Slide number\n        diagram_type: The type of diagram (flowchart, mindmap, etc.)\n        client: Anthropic client for Claude API\n        model: Claude model to use\n        preserve_all: Keep all generated versions with unique names\n        \n    Returns:\n        Path to the generated PNG file\n    \"\"\"\n    # Create content hash for uniqueness\n    content_hash = hashlib.md5(src.encode()).hexdigest()[:8]\n    \n    # Create filenames based on guide name, slide number, and content hash\n    if preserve_all:\n        # Include hash in filename to prevent overwriting\n        output_name = f\"{base_filename}_slide{slide_num}_{content_hash}\"\n    else:\n        output_name = f\"{base_filename}_slide{slide_num}\"\n    \n    mmd = output_dir / f\"{output_name}.mmd\"\n    png = output_dir / f\"{output_name}.png\"\n    \n    # Also create SVG version - FIX: removed -t svg param that was causing issues\n    svg = output_dir / f\"{output_name}.svg\"\n    \n    # Check if files already exist - if so, return them directly\n    if png.exists() and png.stat().st_size > 0:\n        LOGGER.info(f\"Diagram files already exist for slide {slide_num}, reusing them\")\n        return png\n    \n    # Check if the source is valid Mermaid syntax, if not convert it\n    if not is_valid_mermaid_syntax(src):\n        LOGGER.info(f\"Slide {slide_num}: Content doesn't appear to be valid Mermaid syntax. Converting...\")\n        if client:\n            # Use Claude to convert plain text to Mermaid\n            src = convert_plain_text_to_mermaid_with_claude(src, diagram_type, client, model)\n        else:\n            # Use simple rule-based conversion\n            src = convert_text_to_mermaid(src, diagram_type)\n        \n        LOGGER.debug(f\"Converted to Mermaid syntax:\\n{src}\")\n    \n    # Write mermaid content to file\n    mmd.write_text(src, encoding=\"utf-8\")\n    \n    # Build command with optional config - FIX: Simplified the commands\n    cmd = [MERMAID_CMD, \"-i\", str(mmd), \"-o\", str(png)]\n    if config_path and config_path.exists():\n        cmd.extend([\"-c\", str(config_path)])\n    \n    # Also generate SVG with another command - FIX: Removed the -t svg parameter\n    svg_cmd = [MERMAID_CMD, \"-i\", str(mmd), \"-o\", str(svg)]\n    if config_path and config_path.exists():\n        svg_cmd.extend([\"-c\", str(config_path)])\n    \n    LOGGER.debug(\"Running command: %s\", \" \".join(str(x) for x in cmd))\n    \n    # Try with original diagram\n    last_error = \"\"\n    current_src = src\n    current_type = diagram_type\n    \n    # Execute command with retry and auto-fixing\n    for attempt in range(3):\n        # Create version-specific files for each attempt if preserving all\n        if preserve_all and attempt > 0:\n            attempt_output = f\"{output_name}_attempt{attempt}\"\n            attempt_mmd = output_dir / f\"{attempt_output}.mmd\"\n            attempt_png = output_dir / f\"{attempt_output}.png\"\n            attempt_svg = output_dir / f\"{attempt_output}.svg\"\n            \n            # Write the current source to this attempt's file\n            attempt_mmd.write_text(current_src, encoding=\"utf-8\")\n            \n            # Update commands for this attempt\n            cmd = [MERMAID_CMD, \"-i\", str(attempt_mmd), \"-o\", str(attempt_png)]\n            svg_cmd = [MERMAID_CMD, \"-i\", str(attempt_mmd), \"-o\", str(attempt_svg)]\n            \n            if config_path and config_path.exists():\n                cmd.extend([\"-c\", str(config_path)])\n                svg_cmd.extend([\"-c\", str(config_path)])\n        else:\n            # Just use the original files for new attempts\n            attempt_png = png\n            attempt_svg = svg\n        \n        try:\n            LOGGER.debug(f\"Running command: {' '.join(str(x) for x in cmd)}\")\n            result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n            \n            if attempt_png.exists() and attempt_png.stat().st_size > 0:\n                # PNG generated successfully, try SVG too\n                try:\n                    LOGGER.debug(f\"Running SVG command: {' '.join(str(x) for x in svg_cmd)}\")\n                    svg_result = subprocess.run(svg_cmd, check=True, capture_output=True, text=True)\n                except Exception as e:\n                    LOGGER.warning(f\"SVG generation failed but PNG succeeded: {e}\")\n                \n                # If we're preserving all and this isn't the first attempt,\n                # copy the successful files to the original names\n                if preserve_all and attempt > 0:\n                    import shutil\n                    shutil.copy2(attempt_png, png)\n                    if attempt_svg.exists():\n                        shutil.copy2(attempt_svg, svg)\n                \n                # Return the original path regardless\n                LOGGER.info(f\"Successfully rendered diagram on attempt {attempt+1}\")\n                return png\n            \n            last_error = \"Empty output file\"\n            \n        except subprocess.CalledProcessError as e:\n            last_error = e.stderr if hasattr(e, 'stderr') else str(e)\n            LOGGER.warning(\"mermaid-cli error (attempt %d/3): %s\", attempt + 1, last_error)\n        \n        # If we get here, the diagram failed to render\n        if attempt == 0 and client:\n            # First failure: try to fix syntax with Claude\n            LOGGER.info(\"Attempting to fix diagram syntax with Claude\")\n            fixed_src = fix_mermaid_with_claude(current_src, last_error, client, model)\n            mmd.write_text(fixed_src, encoding=\"utf-8\")\n            current_src = fixed_src\n            time.sleep(1)\n            \n        elif attempt == 1 and client:\n            # Second failure: try converting to a different diagram type\n            LOGGER.info(\"Attempting to convert diagram type with Claude\")\n            converted_src, new_type = suggest_alternative_diagram(current_src, current_type, client, model)\n            mmd.write_text(converted_src, encoding=\"utf-8\")\n            current_src = converted_src\n            current_type = new_type\n            time.sleep(1)\n        else:\n            time.sleep(2)  # Just wait and retry with the same content\n    \n    # If we got here, all attempts failed - create a simple fallback diagram without using mermaid\n    LOGGER.error(f\"Failed to render mermaid diagram after 3 attempts for slide {slide_num}\")\n    \n    try:\n        # Create a basic image with text using PIL instead of Mermaid\n        try:\n            from PIL import Image, ImageDraw, ImageFont\n            \n            # Create a blank image\n            img = Image.new('RGB', (800, 400), color=(255, 255, 255))\n            d = ImageDraw.Draw(img)\n            \n            # Try to use a default font\n            try:\n                font = ImageFont.truetype(\"Arial\", 20)\n            except IOError:\n                font = ImageFont.load_default()\n            \n            # Add error text\n            d.text((50, 50), f\"Failed to render diagram for slide {slide_num}\", fill=(0, 0, 0), font=font)\n            d.text((50, 100), f\"Original diagram type: {diagram_type}\", fill=(0, 0, 0), font=font)\n            d.text((50, 150), \"Please simplify or check syntax\", fill=(0, 0, 0), font=font)\n            \n            # Save the image\n            img.save(png)\n            LOGGER.info(f\"Created fallback image with PIL for slide {slide_num}\")\n            return png\n            \n        except ImportError:\n            # If PIL is not available, create an empty file\n            with open(png, 'wb') as f:\n                f.write(b'')\n            LOGGER.info(f\"Created empty fallback image for slide {slide_num}\")\n            return png\n    except Exception as e:\n        LOGGER.error(f\"Failed to create fallback image: {e}\")\n    \n    # If absolutely everything fails, create an empty file\n    with open(png, 'wb') as f:\n        f.write(b'')\n    \n    return png\n\n\ndef get_base_filename(json_path: Path) -> str:\n    \"\"\"Extract base filename (without extension) from path.\"\"\"\n    return json_path.stem.replace('slides_', '')  # Remove 'slides_' prefix if present\n\n\ndef process_json_file(json_path: Path, output_dir: Optional[Path], config_path: Optional[Path], \n                     client: Optional[anthropic.Anthropic] = None, model: str = \"\", \n                     preserve_all: bool = False) -> int:\n    \"\"\"Process a single JSON file and render diagrams.\n    \n    Returns:\n        Number of diagrams processed\n    \"\"\"\n    LOGGER.info(\"Processing JSON file: %s\", json_path)\n    \n    # Load JSON data\n    try:\n        with open(json_path, 'r', encoding='utf-8') as f:\n            json_content = f.read()\n        \n        try:\n            slides_data = json.loads(json_content)\n            \n            # Check if it's an object with a slides array\n            if isinstance(slides_data, dict) and \"slides\" in slides_data:\n                slides = slides_data[\"slides\"]\n            elif isinstance(slides_data, list):\n                slides = slides_data\n            else:\n                LOGGER.error(\"Unexpected JSON structure: expected a slides array or an object with a slides key\")\n                return 0\n                \n        except json.JSONDecodeError as e:\n            LOGGER.error(\"Invalid JSON in %s: %s\", json_path, e)\n            return 0\n            \n    except Exception as e:\n        LOGGER.error(\"Failed to read %s: %s\", json_path, e)\n        return 0\n    \n    # Extract base filename\n    base_filename = get_base_filename(json_path)\n    \n    # Determine output directory\n    if output_dir:\n        diagram_dir = output_dir\n    else:\n        diagram_dir = json_path.parent / \"images\"\n    \n    # Create output directory if it doesn't exist\n    diagram_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Track already processed diagrams to avoid duplicates\n    processed = {}\n    \n    # Process all slides\n    changed = 0\n    for slide in slides:\n        if slide.get(\"diagram_type\") and slide.get(\"diagram_content\"):\n            try:\n                slide_num = slide.get(\"slide_number\", 0)\n                diagram_content = slide.get(\"diagram_content\", \"\")\n                \n                # Skip if this exact content has already been processed\n                content_hash = hashlib.md5(diagram_content.encode()).hexdigest()\n                if content_hash in processed:\n                    LOGGER.info(f\"Slide {slide_num}: Using previously generated diagram\")\n                    slide[\"image_url\"] = processed[content_hash]\n                    changed += 1\n                    continue\n                \n                # Get diagram type (default to flowchart if missing)\n                diagram_type = slide.get(\"diagram_type\", \"flowchart\")\n                \n                # Save original diagram for reference\n                orig_diagram_content = slide.get(\"diagram_content\")\n                \n                try:\n                    # Render diagram\n                    png_path = render_mermaid(\n                        slide[\"diagram_content\"], \n                        diagram_dir, \n                        config_path, \n                        base_filename, \n                        slide[\"slide_number\"],\n                        diagram_type,\n                        client,\n                        model,\n                        preserve_all\n                    )\n                    \n                    # Update JSON with relative path\n                    rel_path = png_path.relative_to(json_path.parent)\n                    slide[\"image_url\"] = str(rel_path)\n                    \n                    # Cache this result\n                    processed[content_hash] = str(rel_path)\n                    \n                    # If diagram was converted from plain text, update the diagram content in JSON\n                    mmd_file = diagram_dir / f\"{base_filename}_slide{slide['slide_number']}.mmd\"\n                    if mmd_file.exists():\n                        rendered_content = mmd_file.read_text(encoding='utf-8')\n                        if rendered_content != orig_diagram_content:\n                            slide[\"diagram_content\"] = rendered_content\n                            diagram_lines = rendered_content.strip().split('\\n')\n                            if diagram_lines and ' ' in diagram_lines[0]:\n                                slide[\"diagram_type\"] = diagram_lines[0].split(' ')[0]\n                    \n                    changed += 1\n                    LOGGER.info(\"Rendered diagram for slide %d â†’ %s\", slide[\"slide_number\"], rel_path)\n                \n                except Exception as e:\n                    LOGGER.error(\"Diagram for slide %d failed: %s\", slide[\"slide_number\"], e)\n                    # Continue with the next slide instead of failing the whole process\n                \n            except Exception as e:\n                LOGGER.error(\"Error processing slide %d: %s\", slide.get(\"slide_number\", \"unknown\"), e)\n    \n    # Save updated JSON back\n    if changed > 0:\n        try:\n            if isinstance(slides_data, dict) and \"slides\" in slides_data:\n                slides_data[\"slides\"] = slides\n                json_path.write_text(json.dumps(slides_data, indent=2, ensure_ascii=False))\n            else:\n                json_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n            LOGGER.info(\"%d diagrams processed; file updated: %s\", changed, json_path)\n        except Exception as e:\n            LOGGER.error(\"Failed to save updated JSON: %s\", e)\n    \n    return changed\n\n\ndef process_directory(json_dir: Path, output_dir: Optional[Path], config_path: Optional[Path],\n                     client: Optional[anthropic.Anthropic] = None, model: str = \"\",\n                     preserve_all: bool = False) -> int:\n    \"\"\"Process all JSON files in a directory.\"\"\"\n    LOGGER.info(\"Processing all JSON files in: %s\", json_dir)\n    \n    # Find all JSON files\n    json_files = list(json_dir.glob(\"slides_*.json\"))\n    if not json_files:\n        LOGGER.error(\"No slide JSON files found in %s\", json_dir)\n        return 0\n    \n    LOGGER.info(\"Found %d JSON files to process\", len(json_files))\n    \n    # Process each file\n    total_changed = 0\n    for json_path in json_files:\n        try:\n            # For directory processing, create subdirectory for each file's images\n            if output_dir:\n                file_output_dir = output_dir\n            else:\n                file_output_dir = json_dir / \"images\" / json_path.stem\n                file_output_dir.mkdir(parents=True, exist_ok=True)\n                \n            changed = process_json_file(json_path, file_output_dir, config_path, client, model, preserve_all)\n            total_changed += changed\n        except Exception as e:\n            LOGGER.error(\"Failed to process %s: %s\", json_path, e, exc_info=True)\n    \n    return total_changed\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    if output_dir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Check if mermaid config exists\n    config_path = Path(args.mermaid_config)\n    if not config_path.exists():\n        LOGGER.warning(\"Mermaid config file %s not found, using default\", config_path)\n        config_path = None\n    \n    # Initialize Claude client if needed\n    client = None\n    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n    if api_key:\n        try:\n            client = anthropic.Anthropic(api_key=api_key)\n            LOGGER.info(\"Initialized Claude client for diagram fixing\")\n        except Exception as e:\n            LOGGER.warning(\"Failed to initialize Claude client: %s\", e)\n    else:\n        LOGGER.warning(\"ANTHROPIC_API_KEY not set, Claude-assisted fixing unavailable\")\n    \n    # Process files\n    try:\n        if json_path.is_dir():\n            total_changed = process_directory(json_path, output_dir, config_path, client, args.model, args.preserve_all)\n            LOGGER.info(\"Total of %d diagrams processed across all files\", total_changed)\n        else:\n            process_json_file(json_path, output_dir, config_path, client, args.model, args.preserve_all)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()"
          },
          {
            "file_name": "magicSlide.sh",
            "file_size": 11576,
            "file_type": "text/x-sh",
            "extracted_content": "#!/bin/bash\n# magicSlide.sh - One-click slide generation from facilitator guides\n# Usage: ./magicSlide.sh input.md [options]\n#        ./magicSlide.sh directory/ [options]\n\n# Default options\nCONFIG=\"config.yaml\"\nMERMAID_CONFIG=\"mermaid-config.json\"\nLOG_LEVEL=\"INFO\"\nTITLE_PREFIX=\"\"\nSTYLE=\"github\"\nUSE_FILEIO=1\nCLAUDE_MODEL=\"claude-3-7-sonnet-20250219\"\nSTART_STEP=1  # Default start from beginning\nFULL_CSV=1    # Generate full CSV with all fields by default\nPRESERVE_DIAGRAMS=1  # Keep all diagram versions instead of overwriting\nDEBUG_MODE=0  # Display debug info\n\n# Functions\nprint_usage() {\n  echo \"Usage: $0 <input.md or directory> [options]\"\n  echo \"Options:\"\n  echo \"  --config=FILE         YAML config file (default: config.yaml)\"\n  echo \"  --mermaid-config=FILE Mermaid config file (default: mermaid-config.json)\"\n  echo \"  --no-fileio           Don't use file.io for image uploads\"\n  echo \"  --title-prefix=TEXT   Add prefix to presentation titles\"\n  echo \"  --style=STYLE         Code highlighting style (default: github)\"\n  echo \"  --model=MODEL         Claude model (default: claude-3-7-sonnet-20250219)\"\n  echo \"  --compact-csv         Generate compact CSV (fewer columns)\"\n  echo \"  --no-full-csv         Don't include diagram content in CSV\"\n  echo \"  --no-preserve         Don't preserve all diagram versions (overwrite existing)\"\n  echo \"  --log-level=LEVEL     Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)\"\n  echo \"  --start-step=NUM      Start from specific step (1-5, default: 1)\"\n  echo \"  --debug               Run in debug mode (verbose output, validate markdown)\"\n  echo \"  --verify-npm          Check if npm and md2gslides are installed\"\n  echo \"  --help                Show this help message\"\n}\n\n# Parse arguments\nINPUT=\"\"\nfor arg in \"$@\"; do\n  case $arg in\n    --config=*)\n      CONFIG=\"${arg#*=}\"\n      ;;\n    --mermaid-config=*)\n      MERMAID_CONFIG=\"${arg#*=}\"\n      ;;\n    --no-fileio)\n      USE_FILEIO=0\n      ;;\n    --title-prefix=*)\n      TITLE_PREFIX=\"${arg#*=}\"\n      ;;\n    --style=*)\n      STYLE=\"${arg#*=}\"\n      ;;\n    --model=*)\n      CLAUDE_MODEL=\"${arg#*=}\"\n      ;;\n    --compact-csv)\n      FULL_CSV=0\n      COMPACT_CSV=1\n      ;;\n    --no-full-csv)\n      FULL_CSV=0\n      ;;\n    --no-preserve)\n      PRESERVE_DIAGRAMS=0\n      ;;\n    --log-level=*)\n      LOG_LEVEL=\"${arg#*=}\"\n      ;;\n    --start-step=*)\n      START_STEP=\"${arg#*=}\"\n      ;;\n    --debug)\n      DEBUG_MODE=1\n      LOG_LEVEL=\"DEBUG\"\n      ;;\n    --verify-npm)\n      VERIFY_NPM=1\n      ;;\n    --help)\n      print_usage\n      exit 0\n      ;;\n    -*)\n      echo \"Unknown option: $arg\"\n      print_usage\n      exit 1\n      ;;\n    *)\n      if [ -z \"$INPUT\" ]; then\n        INPUT=\"$arg\"\n      else\n        echo \"Multiple input files specified. Use only one.\"\n        print_usage\n        exit 1\n      fi\n      ;;\n  esac\ndone\n\n# Check for required input\nif [ -z \"$INPUT\" ]; then\n  echo \"Error: No input file or directory specified.\"\n  print_usage\n  exit 1\nfi\n\n# Verify md2gslides installation early\nverify_md2gslides() {\n  echo \"ðŸ” Checking md2gslides installation...\"\n  if ! command -v npm &> /dev/null; then\n    echo \"âŒ npm could not be found. Please install Node.js first.\"\n    echo \"   Visit https://nodejs.org/ for installation instructions.\"\n    return 1\n  fi\n  \n  echo \"âœ… npm is installed: $(npm --version)\"\n  \n  if ! command -v md2gslides &> /dev/null; then\n    echo \"âŒ md2gslides could not be found. Installing it now...\"\n    npm install -g md2gslides\n    \n    if [ $? -ne 0 ]; then\n      echo \"âŒ Failed to install md2gslides. Please try manually:\"\n      echo \"   npm install -g md2gslides\"\n      return 1\n    fi\n  fi\n  \n  echo \"âœ… md2gslides is installed\"\n  \n  # Check for client_id.json\n  MD2G_DIR=\"$HOME/.md2googleslides\"\n  if [ ! -f \"$MD2G_DIR/client_id.json\" ]; then\n    echo \"âš ï¸  Warning: client_id.json not found at $MD2G_DIR/client_id.json\"\n    echo \"   You may need to set up Google API credentials.\"\n    echo \"   See: https://github.com/googleworkspace/md2googleslides#installation-and-usage\"\n    \n    # Create directory if it doesn't exist\n    mkdir -p \"$MD2G_DIR\"\n    \n    echo \"   Please follow these steps to set up Google API credentials:\"\n    echo \"   1. Go to https://console.developers.google.com\"\n    echo \"   2. Create a new project or select an existing one\"\n    echo \"   3. Enable the Google Slides API in the API Library\"\n    echo \"   4. Go to Credentials page and click '+ Create credentials'\"\n    echo \"   5. Select 'OAuth client ID' and 'Desktop Application'\"\n    echo \"   6. Download the JSON file and save it as 'client_id.json' in $MD2G_DIR\"\n    echo \"\"\n    echo \"   Do you want to continue without the credentials? (y/n)\"\n    read -r continue_without_creds\n    \n    if [[ $continue_without_creds != \"y\" && $continue_without_creds != \"Y\" ]]; then\n      echo \"Exiting. Please set up credentials and try again.\"\n      return 1\n    fi\n  else\n    echo \"âœ… Google API credentials found at $MD2G_DIR/client_id.json\"\n  fi\n  \n  return 0\n}\n\n# Check for md2gslides if requested or if starting from step 5\nif [ ${VERIFY_NPM:-0} -eq 1 ] || [ $START_STEP -eq 5 ]; then\n  verify_md2gslides || exit 1\nfi\n\n# Determine input type\nif [ -d \"$INPUT\" ]; then\n  # Directory mode\n  echo \"ðŸ” Processing directory: $INPUT\"\n  WORKING_DIR=\"$INPUT\"\n  DIR_MODE=1\nelse\n  # Single file mode\n  echo \"ðŸ” Processing file: $INPUT\"\n  WORKING_DIR=\"$(dirname \"$INPUT\")\"\n  BASENAME=\"$(basename \"$INPUT\" .md)\"\n  BASENAME=\"${BASENAME%.txt}\"  # Also strip .txt if present\n  DIR_MODE=0\nfi\n\n# Create/verify necessary directories\nIMAGES_DIR=\"$WORKING_DIR/images\"\nmkdir -p \"$IMAGES_DIR\"\n\n# Function to check if step should be executed\nshould_run_step() {\n  local step=$1\n  if [ $step -ge $START_STEP ]; then\n    return 0  # True in bash\n  else\n    return 1  # False in bash\n  fi\n}\n\n# Create a progress file to track completed steps\nPROGRESS_FILE=\"$WORKING_DIR/.magicslide_progress\"\nif [ \"$START_STEP\" -eq 1 ]; then\n  # Starting fresh, remove any existing progress file\n  rm -f \"$PROGRESS_FILE\"\nfi\n\n# Create a function for each step that saves progress\nrun_step() {\n  local step_num=$1\n  local step_name=$2\n  local step_cmd=$3\n  \n  if should_run_step $step_num; then\n    echo \"Step $step_num/5: $step_name\"\n    \n    # Run the command\n    if eval \"$step_cmd\"; then\n      # Save progress\n      echo \"$step_num completed\" >> \"$PROGRESS_FILE\"\n      return 0\n    else\n      local exit_code=$?\n      echo \"âŒ Step $step_num failed with exit code $exit_code\"\n      echo \"To resume from this step, run with --start-step=$step_num\"\n      return $exit_code\n    fi\n  else\n    echo \"Skipping Step $step_num/5: $step_name (already completed)\"\n  fi\n}\n\n# Step 1: JSON Generation\nif [ $DIR_MODE -eq 1 ]; then\n  JSON_STEP=\"python guide_to_json.py \\\"$INPUT\\\" --config=\\\"$CONFIG\\\" --model=\\\"$CLAUDE_MODEL\\\" --log-level=\\\"$LOG_LEVEL\\\"\"\nelse\n  JSON_FILE=\"$WORKING_DIR/slides_$BASENAME.json\"\n  JSON_STEP=\"python guide_to_json.py \\\"$INPUT\\\" --config=\\\"$CONFIG\\\" --out=\\\"$JSON_FILE\\\" --model=\\\"$CLAUDE_MODEL\\\" --log-level=\\\"$LOG_LEVEL\\\"\"\nfi\nrun_step 1 \"ðŸ§  Converting to JSON with Claude...\" \"$JSON_STEP\" || exit $?\n\n# Step 2: Diagram Generation\nPRESERVE_ARG=\"\"\nif [ $PRESERVE_DIAGRAMS -eq 1 ]; then\n  PRESERVE_ARG=\"--preserve-all\"\nfi\n\nif [ $DIR_MODE -eq 1 ]; then\n  DIAGRAM_STEP=\"python diagrams_to_images.py \\\"$INPUT\\\" --mermaid-config=\\\"$MERMAID_CONFIG\\\" --output-dir=\\\"$IMAGES_DIR\\\" --log-level=\\\"$LOG_LEVEL\\\" --model=\\\"$CLAUDE_MODEL\\\" $PRESERVE_ARG\"\nelse\n  DIAGRAM_STEP=\"python diagrams_to_images.py \\\"$JSON_FILE\\\" --mermaid-config=\\\"$MERMAID_CONFIG\\\" --output-dir=\\\"$IMAGES_DIR\\\" --log-level=\\\"$LOG_LEVEL\\\" --model=\\\"$CLAUDE_MODEL\\\" $PRESERVE_ARG\"\nfi\nrun_step 2 \"ðŸ“Š Rendering diagrams...\" \"$DIAGRAM_STEP\" || exit $?\n\n# Step 3: CSV Generation\nCSV_ARGS=\"\"\nif [ $FULL_CSV -eq 1 ]; then\n  CSV_ARGS=\"--full\"\nelif [ ${COMPACT_CSV:-0} -eq 1 ]; then\n  CSV_ARGS=\"--compact\"\nfi\n\nif [ $DIR_MODE -eq 1 ]; then\n  CSV_STEP=\"python json_to_csv.py \\\"$INPUT\\\" --log-level=\\\"$LOG_LEVEL\\\" $CSV_ARGS\"\nelse\n  CSV_STEP=\"python json_to_csv.py \\\"$JSON_FILE\\\" --log-level=\\\"$LOG_LEVEL\\\" $CSV_ARGS\"\nfi\nrun_step 3 \"ðŸ“Š Generating CSV overview...\" \"$CSV_STEP\" || exit $?\n\n# Step 4: Markdown Generation\nif [ $DIR_MODE -eq 1 ]; then\n  MD_STEP=\"python json_to_markdown.py \\\"$INPUT\\\" --prefer-svg --log-level=\\\"$LOG_LEVEL\\\"\"\nelse\n  MD_STEP=\"python json_to_markdown.py \\\"$JSON_FILE\\\" --prefer-svg --log-level=\\\"$LOG_LEVEL\\\"\"\nfi\nrun_step 4 \"ðŸ“ Converting to markdown...\" \"$MD_STEP\" || exit $?\n\n# Store markdown file paths (fixed to use correct naming)\nif [ $DIR_MODE -eq 1 ]; then\n  # Find all markdown files generated\n  MD_FILES=($WORKING_DIR/slides_*.md)\n  if [ ${#MD_FILES[@]} -eq 0 ]; then\n    echo \"âŒ No markdown files found in $WORKING_DIR\"\n    exit 1\n  fi\nelse\n  # Use the correct markdown file name with \"slides_\" prefix\n  MD_FILE=\"$WORKING_DIR/slides_$BASENAME.md\"\n  \n  # Double-check that the file exists\n  if [ ! -f \"$MD_FILE\" ]; then\n    echo \"âŒ Expected markdown file not found: $MD_FILE\"\n    echo \"Checking for alternative files...\"\n    \n    # Try without the \"slides_\" prefix as a fallback\n    ALT_FILE=\"$WORKING_DIR/$BASENAME.md\"\n    if [ -f \"$ALT_FILE\" ]; then\n      echo \"âœ… Found alternative markdown file: $ALT_FILE\"\n      MD_FILE=\"$ALT_FILE\"\n    else\n      # List all markdown files in the directory\n      echo \"Available markdown files:\"\n      find \"$WORKING_DIR\" -name \"*.md\" -type f | while read -r file; do\n        echo \"  - $(basename \"$file\")\"\n      done\n      \n      echo \"Please select which file to use or fix the naming in your scripts.\"\n      exit 1\n    fi\n  fi\nfi\n\n# Step 5: Google Slides Generation\nFILEIO_ARG=\"\"\nif [ $USE_FILEIO -eq 1 ]; then\n  FILEIO_ARG=\"--use-fileio\"\nfi\n\nDEBUG_ARG=\"\"\nif [ $DEBUG_MODE -eq 1 ]; then\n  DEBUG_ARG=\"--debug\"\nfi\n\nVERIFY_ARG=\"\"\nif [ ${VERIFY_NPM:-0} -eq 1 ]; then\n  VERIFY_ARG=\"--verify-npm\"\nfi\n\nif [ $DIR_MODE -eq 1 ]; then\n  # Process all markdown files\n  for md_file in \"${MD_FILES[@]}\"; do\n    echo \"Processing markdown file: $md_file\"\n    md_basename=$(basename \"$md_file\" .md)\n    output_file=\"$WORKING_DIR/${md_basename}-presentation.txt\"\n    \n    SLIDES_CMD=\"python build_with_md2gslides.py \\\"$md_file\\\" --title-prefix=\\\"$TITLE_PREFIX\\\" --style=\\\"$STYLE\\\" $FILEIO_ARG --log-level=\\\"$LOG_LEVEL\\\" --output-file=\\\"$output_file\\\" $DEBUG_ARG $VERIFY_ARG\"\n    echo \"Running: $SLIDES_CMD\"\n    eval \"$SLIDES_CMD\" || echo \"âš ï¸ Failed to create slides for $md_file\"\n  done\n  # Mark step as complete even if some files failed\n  echo \"5 completed\" >> \"$PROGRESS_FILE\"\nelse\n  # Process single markdown file\n  output_file=\"$WORKING_DIR/${BASENAME}-presentation.txt\"\n  SLIDES_STEP=\"python build_with_md2gslides.py \\\"$MD_FILE\\\" --title-prefix=\\\"$TITLE_PREFIX\\\" --style=\\\"$STYLE\\\" $FILEIO_ARG --log-level=\\\"$LOG_LEVEL\\\" --output-file=\\\"$output_file\\\" $DEBUG_ARG $VERIFY_ARG --fix-format\"\n\n  run_step 5 \"ðŸŽ¯ Generating Google Slides...\" \"$SLIDES_STEP\" || {\n    echo \"âŒ Failed to create Google Slides for $MD_FILE\"\n    echo \"Here's the content of the file to help diagnose:\"\n    head -n 20 \"$MD_FILE\"\n    exit 1\n  }\nfi\n\necho \"âœ… All done! Your slides are ready.\"\necho \"ðŸ“‹ Presentation links saved to the output text file.\"\necho \"ðŸ“Š CSV overview files have been generated for quick reference.\"\necho \"\"\necho \"If you still have issues with Google Slides generation, try:\"\necho \"  1. Run with --verify-npm to check Node.js installation\"\necho \"  2. Make sure md2gslides is installed: npm install -g md2gslides\"\necho \"  3. Run with --debug to see detailed output\"\necho \"  4. Check if your Google API credentials are set up correctly\""
          },
          {
            "file_name": "build_with_md2gslides.py",
            "file_size": 16855,
            "file_type": "",
            "extracted_content": "#!/usr/bin/env python3\n\"\"\"Create Google Slides from markdown using md2gslides.\n\nThis script takes markdown files generated from JSON slides data and\nuses the md2gslides npm package to create Google Slides presentations.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, subprocess, tempfile\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any\nimport re\nimport shutil\n\nLOGGER = logging.getLogger(\"build_with_md2gslides\")\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Generate Google Slides from markdown\")\n    p.add_argument(\"markdown\", help=\"Markdown file or directory of markdown files\")\n    p.add_argument(\"--title-prefix\", default=\"\", help=\"Prefix for presentation titles\")\n    p.add_argument(\"--style\", default=\"github\", help=\"Syntax highlighting style\")\n    p.add_argument(\"--use-fileio\", action=\"store_true\", help=\"Allow uploading to file.io for images\")\n    p.add_argument(\"--output-file\", default=None, help=\"File to save presentation URLs\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    p.add_argument(\"--debug\", action=\"store_true\", help=\"Show debug info and display markdown before sending\")\n    p.add_argument(\"--append\", default=None, help=\"Append to existing presentation ID\")\n    p.add_argument(\"--erase\", action=\"store_true\", help=\"Erase existing slides when using --append\")\n    p.add_argument(\"--verify-npm\", action=\"store_true\", help=\"Verify npm and md2gslides are installed\")\n    p.add_argument(\"--fix-format\", action=\"store_true\", help=\"Fix common markdown formatting issues\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef verify_installation() -> bool:\n    \"\"\"Verify that npm and md2gslides are installed.\"\"\"\n    try:\n        npm_version = subprocess.run([\"npm\", \"--version\"], capture_output=True, check=True, text=True)\n        LOGGER.info(f\"npm version: {npm_version.stdout.strip()}\")\n        \n        # Try to install md2gslides if not already installed\n        try:\n            result = subprocess.run([\"md2gslides\", \"--version\"], capture_output=True, text=True)\n            LOGGER.info(f\"md2gslides version: {result.stdout.strip()}\")\n        except (subprocess.CalledProcessError, FileNotFoundError):\n            LOGGER.warning(\"md2gslides not found, attempting to install it...\")\n            try:\n                install_result = subprocess.run([\"npm\", \"install\", \"-g\", \"md2gslides\"], \n                                               capture_output=True, check=True, text=True)\n                LOGGER.info(\"md2gslides installed successfully\")\n            except subprocess.CalledProcessError as e:\n                LOGGER.error(f\"Failed to install md2gslides: {e.stderr}\")\n                return False\n        \n        # Check for client_id.json\n        home_dir = Path.home()\n        client_id_path = home_dir / \".md2googleslides\" / \"client_id.json\"\n        if not client_id_path.exists():\n            LOGGER.warning(\"client_id.json not found at ~/.md2googleslides/client_id.json\")\n            LOGGER.warning(\"You may need to set up Google API credentials.\")\n            LOGGER.warning(\"See: https://github.com/googleworkspace/md2googleslides#installation-and-usage\")\n            \n            # Create the directory if it doesn't exist\n            client_id_dir = client_id_path.parent\n            client_id_dir.mkdir(parents=True, exist_ok=True)\n            \n            LOGGER.warning(f\"Directory created at {client_id_dir}\")\n            LOGGER.warning(\"Please follow these steps to set up Google API credentials:\")\n            LOGGER.warning(\"1. Go to https://console.developers.google.com\")\n            LOGGER.warning(\"2. Create a new project or select an existing one\")\n            LOGGER.warning(\"3. Enable the Google Slides API in the API Library\")\n            LOGGER.warning(\"4. Go to Credentials page and click '+ Create credentials'\")\n            LOGGER.warning(\"5. Select 'OAuth client ID' and 'Desktop Application'\")\n            LOGGER.warning(f\"6. Download the JSON file and save it as 'client_id.json' in {client_id_dir}\")\n        \n        return True\n    \n    except subprocess.CalledProcessError as e:\n        LOGGER.error(f\"Error checking installation: {e}\")\n        return False\n    \n    except FileNotFoundError:\n        LOGGER.error(\"npm not found. Please install Node.js and npm first.\")\n        return False\n\n\ndef fix_markdown_format(content: str) -> str:\n    \"\"\"Fix common markdown formatting issues that cause md2gslides to fail.\"\"\"\n    # Ensure proper slide separators\n    if \"---\" not in content:\n        LOGGER.info(\"Adding slide separators to markdown\")\n        lines = content.split(\"\\n\")\n        fixed_lines = []\n        \n        # Add separator before each heading if missing\n        in_first_slide = True\n        for i, line in enumerate(lines):\n            if line.startswith(\"#\") and not in_first_slide:\n                if i > 0 and not lines[i-1].startswith(\"---\"):\n                    fixed_lines.append(\"---\")\n            elif line.startswith(\"#\"):\n                in_first_slide = False\n                \n            fixed_lines.append(line)\n        \n        content = \"\\n\".join(fixed_lines)\n    \n    # Ensure each slide has a title (header)\n    sections = content.split(\"---\")\n    fixed_sections = []\n    \n    for i, section in enumerate(sections):\n        section = section.strip()\n        if section and not re.search(r'^#\\s+.+', section, re.MULTILINE):\n            LOGGER.info(f\"Adding missing header to slide {i+1}\")\n            section = f\"# Slide {i+1}\\n\\n{section}\"\n        \n        fixed_sections.append(section)\n    \n    fixed_content = \"---\\n\\n\".join(fixed_sections)\n    if not fixed_content.startswith(\"---\"):\n        fixed_content = fixed_content.lstrip(\"---\").strip()\n    \n    # Fix image paths\n    # Just a placeholder, add specific image path fixing if needed\n    \n    return fixed_content\n\n\ndef validate_markdown(markdown_path: Path, debug: bool = False, fix_format: bool = False) -> bool:\n    \"\"\"Validate markdown file for compatibility with md2gslides.\"\"\"\n    try:\n        content = markdown_path.read_text(encoding=\"utf-8\")\n        \n        # Check for common issues\n        if not content.strip():\n            LOGGER.error(f\"{markdown_path} is empty\")\n            return False\n        \n        needs_fixing = False\n        \n        # Check for slide separators\n        if \"---\" not in content and content.strip().count(\"\\n\") > 5:\n            LOGGER.warning(f\"{markdown_path} is missing slide separators (---)\")\n            needs_fixing = True\n        \n        # Check for headers\n        if not re.search(r'^#\\s+.+', content, re.MULTILINE):\n            LOGGER.warning(f\"{markdown_path} is missing slide headers (# Title)\")\n            needs_fixing = True\n        \n        # Check for image paths\n        image_paths = re.findall(r'!\\[.*?\\]\\((.*?)\\)', content)\n        for path in image_paths:\n            if path.startswith(\"http\"):\n                continue\n                \n            img_path = Path(path)\n            if not img_path.is_absolute():\n                # Try relative to the markdown file\n                img_path = markdown_path.parent / img_path\n                \n            if not img_path.exists():\n                LOGGER.warning(f\"Image path may be invalid: {path}\")\n        \n        # Fix markdown if requested and needed\n        if fix_format and needs_fixing:\n            LOGGER.info(f\"Fixing markdown format for {markdown_path}\")\n            fixed_content = fix_markdown_format(content)\n            \n            # Create backup of original file\n            backup_path = markdown_path.with_suffix(\".md.bak\")\n            shutil.copy2(markdown_path, backup_path)\n            LOGGER.info(f\"Created backup of original markdown at {backup_path}\")\n            \n            # Write fixed content\n            markdown_path.write_text(fixed_content, encoding=\"utf-8\")\n            content = fixed_content\n            LOGGER.info(f\"Fixed markdown formatting in {markdown_path}\")\n        \n        if debug:\n            LOGGER.info(f\"\\n---- Markdown Content ----\\n{content}\\n-------------------------\")\n            input(\"Press Enter to continue with md2gslides...\")\n        \n        return True\n        \n    except Exception as e:\n        LOGGER.error(f\"Error validating markdown {markdown_path}: {e}\")\n        return False\n\n\ndef run_md2gslides(markdown_path: Path, title_prefix: str = \"\", style: str = \"github\", \n                 use_fileio: bool = False, append_id: Optional[str] = None, \n                 erase: bool = False, debug: bool = False) -> Optional[str]:\n    \"\"\"Run md2gslides to create a Google Slides presentation.\"\"\"\n    \n    # Validate the markdown\n    if not validate_markdown(markdown_path, debug):\n        return None\n    \n    # Build the command\n    cmd = [\"md2gslides\"]\n    \n    # Ensure md2gslides command exists\n    try:\n        # Check if md2gslides is in PATH\n        md2gslides_path = shutil.which(\"md2gslides\")\n        if md2gslides_path:\n            cmd = [md2gslides_path]\n        else:\n            # Try global npm installation\n            cmd = [\"npx\", \"md2gslides\"]\n    except Exception as e:\n        LOGGER.error(f\"Error finding md2gslides command: {e}\")\n        return None\n    \n    # Add the title\n    title = f\"{title_prefix}{markdown_path.stem}\"\n    cmd.extend([\"--title\", title])\n    \n    # Add optional arguments\n    if style:\n        cmd.extend([\"--style\", style])\n    \n    if use_fileio:\n        cmd.append(\"--use-fileio\")\n    \n    if append_id:\n        cmd.extend([\"--append\", append_id])\n        \n        if erase:\n            cmd.append(\"--erase\")\n    \n    # Add the markdown file\n    cmd.append(str(markdown_path))\n    \n    # Run the command\n    LOGGER.info(f\"Running command: {' '.join(cmd)}\")\n    try:\n        # Create a temporary file to capture the output\n        with tempfile.NamedTemporaryFile(mode='w+', encoding='utf-8', delete=False) as tmp:\n            result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n            \n            # Parse the output to get the URL\n            for line in result.stdout.splitlines():\n                if \"https://docs.google.com/presentation\" in line:\n                    url = line.strip()\n                    LOGGER.info(f\"Created presentation: {url}\")\n                    return url\n            \n            # If we can't find a URL, write the output to a file and return None\n            tmp.write(result.stdout)\n            LOGGER.warning(f\"Could not find presentation URL in output. Output saved to {tmp.name}\")\n            if debug:\n                LOGGER.info(f\"Output:\\n{result.stdout}\")\n            \n            return None\n        \n    except subprocess.CalledProcessError as e:\n        LOGGER.error(f\"Error running md2gslides: {e}\")\n        LOGGER.error(f\"stdout: {e.stdout}\")\n        LOGGER.error(f\"stderr: {e.stderr}\")\n        \n        # Try to extract useful error messages\n        error_lines = e.stderr.splitlines()\n        for line in error_lines:\n            if \"Error:\" in line or \"TypeError:\" in line or \"SyntaxError:\" in line:\n                LOGGER.error(f\"Error message: {line}\")\n        \n        return None\n\n\ndef process_markdown_file(markdown_path: Path, title_prefix: str = \"\", style: str = \"github\", \n                       use_fileio: bool = False, output_file: Optional[Path] = None,\n                       append_id: Optional[str] = None, erase: bool = False,\n                       debug: bool = False, fix_format: bool = False) -> Optional[str]:\n    \"\"\"Process a single markdown file.\"\"\"\n    LOGGER.info(f\"Processing markdown file: {markdown_path}\")\n    \n    # Validate and potentially fix the markdown\n    if not validate_markdown(markdown_path, debug, fix_format):\n        LOGGER.error(f\"Markdown validation failed for {markdown_path}\")\n        return None\n    \n    # Run md2gslides\n    url = run_md2gslides(markdown_path, title_prefix, style, use_fileio, append_id, erase, debug)\n    \n    # Save the URL to the output file\n    if url and output_file:\n        try:\n            with open(output_file, 'a', encoding='utf-8') as f:\n                f.write(f\"{markdown_path.stem}: {url}\\n\")\n        except Exception as e:\n            LOGGER.error(f\"Error writing to output file {output_file}: {e}\")\n    \n    return url\n\n\ndef process_directory(markdown_dir: Path, title_prefix: str = \"\", style: str = \"github\", \n                    use_fileio: bool = False, output_file: Optional[Path] = None,\n                    append_id: Optional[str] = None, erase: bool = False,\n                    debug: bool = False, fix_format: bool = False) -> List[str]:\n    \"\"\"Process all markdown files in a directory.\"\"\"\n    LOGGER.info(f\"Processing all markdown files in {markdown_dir}\")\n    \n    # Find all markdown files\n    markdown_files = list(markdown_dir.glob(\"*.md\"))\n    if not markdown_files:\n        LOGGER.error(f\"No markdown files found in {markdown_dir}\")\n        return []\n    \n    LOGGER.info(f\"Found {len(markdown_files)} markdown files to process\")\n    \n    # Process each file\n    results = []\n    for markdown_path in sorted(markdown_files):\n        try:\n            url = process_markdown_file(\n                markdown_path, title_prefix, style, use_fileio, \n                output_file, append_id, erase, debug, fix_format\n            )\n            if url:\n                results.append(url)\n        except Exception as e:\n            LOGGER.error(f\"Failed to process {markdown_path}: {e}\")\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Verify installation if requested\n    if args.verify_npm:\n        if not verify_installation():\n            LOGGER.error(\"Installation verification failed. Please install Node.js, npm, and md2gslides.\")\n            LOGGER.info(\"To install md2gslides: npm install -g md2gslides\")\n            sys.exit(1)\n    \n    # Validate the path\n    markdown_path = Path(args.markdown)\n    if not markdown_path.exists():\n        LOGGER.error(f\"{markdown_path} not found\")\n        \n        # Check if there's a file with slides_ prefix\n        parent_dir = markdown_path.parent\n        basename = markdown_path.stem\n        \n        # Try with slides_ prefix\n        alt_path = parent_dir / f\"slides_{basename}.md\"\n        if alt_path.exists():\n            LOGGER.info(f\"Found alternative path: {alt_path}\")\n            markdown_path = alt_path\n        else:\n            # Look for any markdown file with similar name\n            potential_files = list(parent_dir.glob(f\"*{basename}*.md\"))\n            if potential_files:\n                LOGGER.info(f\"Found potential alternatives: {[p.name for p in potential_files]}\")\n                markdown_path = potential_files[0]\n                LOGGER.info(f\"Using {markdown_path}\")\n            else:\n                LOGGER.error(\"No alternative markdown files found\")\n                sys.exit(1)\n    \n    # Determine output file\n    output_file = Path(args.output_file) if args.output_file else None\n    \n    # If output file is specified, clear it\n    if output_file:\n        try:\n            output_file.parent.mkdir(parents=True, exist_ok=True)\n            with open(output_file, 'w', encoding='utf-8') as f:\n                f.write(f\"Presentations generated from {markdown_path}\\n\")\n        except Exception as e:\n            LOGGER.error(f\"Error creating output file {output_file}: {e}\")\n            output_file = None\n    \n    # Process files\n    try:\n        if markdown_path.is_dir():\n            results = process_directory(\n                markdown_path, args.title_prefix, args.style, args.use_fileio, \n                output_file, args.append, args.erase, args.debug, args.fix_format\n            )\n            if results:\n                LOGGER.info(f\"Created {len(results)} presentations\")\n                if output_file:\n                    LOGGER.info(f\"Presentation URLs saved to {output_file}\")\n            else:\n                LOGGER.warning(\"No presentations were created\")\n                sys.exit(1)\n        else:\n            url = process_markdown_file(\n                markdown_path, args.title_prefix, args.style, args.use_fileio, \n                output_file, args.append, args.erase, args.debug, args.fix_format\n            )\n            if not url:\n                LOGGER.error(\"Failed to create presentation\")\n                sys.exit(1)\n    except Exception as e:\n        LOGGER.error(f\"Processing failed: {e}\", exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()"
          },
          {
            "file_name": "json_to_csv.py",
            "file_size": 7145,
            "file_type": "",
            "extracted_content": "#!/usr/bin/env python3\n\"\"\"Convert slides.json to CSV for an overview of the day's curriculum.\n\nThis script converts JSON slide data to a CSV file, allowing for a quick overview\nof the presentation structure in a spreadsheet format.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, csv, json, logging, sys\nfrom pathlib import Path\nfrom typing import Dict, List, Any, Optional\nimport io\n\nLOGGER = logging.getLogger(\"json_to_csv\")\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Convert slides.json to CSV\")\n    p.add_argument(\"json\", help=\"slides.json file or directory of JSON files\")\n    p.add_argument(\"--output-dir\", default=None, help=\"Output directory for CSV files\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None, help=\"Write logs to file as well\")\n    p.add_argument(\"--compact\", action=\"store_true\", help=\"Create a compact CSV with fewer columns\")\n    p.add_argument(\"--full\", action=\"store_true\", help=\"Include all fields in the CSV, including diagram content\")\n    return p.parse_args()\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\ndef extract_slides_from_json(json_data: Any) -> List[Dict[str, Any]]:\n    \"\"\"Extract slides array from JSON data, handling different formats.\"\"\"\n    if isinstance(json_data, list):\n        # Already a list of slides\n        return json_data\n    elif isinstance(json_data, dict) and \"slides\" in json_data:\n        # Object with a slides key\n        return json_data[\"slides\"]\n    else:\n        LOGGER.warning(\"Unknown JSON structure, attempting to find slides array\")\n        # Try to find any array in the JSON\n        for key, value in json_data.items() if isinstance(json_data, dict) else []:\n            if isinstance(value, list) and len(value) > 0 and isinstance(value[0], dict):\n                LOGGER.info(f\"Found slides array under key '{key}'\")\n                return value\n        \n        raise ValueError(\"Could not find a slides array in the JSON data\")\n\ndef escape_csv_field(field: Any) -> str:\n    \"\"\"Safely escape and format a field for CSV.\"\"\"\n    if field is None:\n        return \"\"\n    \n    if not isinstance(field, str):\n        field = str(field)\n        \n    # Escape any newlines within the field for CSV compatibility\n    field = field.replace(\"\\n\", \"\\\\n\").replace(\"\\r\", \"\\\\r\")\n    \n    return field\n\ndef convert_json_to_csv(json_path: Path, output_dir: Optional[Path] = None, compact: bool = False, full: bool = False) -> Path:\n    \"\"\"Convert a single JSON file to CSV.\"\"\"\n    LOGGER.info(\"Converting %s to CSV\", json_path)\n    \n    # Define compact and full headers\n    compact_headers = [\"slide_number\", \"title\", \"layout\", \"start_time\", \"end_time\"]\n    \n    standard_headers = [\n        \"slide_number\", \"title\", \"layout\", \"content\", \"start_time\", \"end_time\", \n        \"materials\", \"facilitator_notes\", \"diagram_type\", \"image_url\"\n    ]\n    \n    full_headers = [\n        \"slide_number\", \"title\", \"layout\", \"content\", \"start_time\", \"end_time\", \n        \"materials\", \"facilitator_notes\", \"diagram_type\", \"diagram_content\", \n        \"image_description\", \"image_url\", \"worksheet\", \"improvements\", \"notes\"\n    ]\n    \n    # Select headers based on options\n    if compact:\n        headers = compact_headers\n    elif full:\n        headers = full_headers\n    else:\n        headers = standard_headers\n    \n    # Load JSON data\n    try:\n        json_data = json.loads(json_path.read_text(encoding='utf-8'))\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON in %s: %s\", json_path, e)\n        raise\n    \n    # Extract slides from the JSON structure\n    try:\n        slides = extract_slides_from_json(json_data)\n    except ValueError as e:\n        LOGGER.error(\"%s\", e)\n        raise\n    \n    # Determine output path\n    if output_dir:\n        output_path = output_dir / f\"{json_path.stem.replace('slides_', '')}_overview.csv\"\n    else:\n        output_path = json_path.with_name(f\"{json_path.stem.replace('slides_', '')}_overview.csv\")\n    \n    # Write to CSV using StringIO to handle escaping properly\n    try:\n        with open(output_path, 'w', newline='', encoding='utf-8') as f:\n            writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)\n            \n            # Write header\n            writer.writerow(headers)\n            \n            # Write data rows\n            for slide in slides:\n                row = []\n                for header in headers:\n                    value = slide.get(header, \"\")\n                    # Format the value based on type\n                    row.append(escape_csv_field(value))\n                writer.writerow(row)\n    except Exception as e:\n        LOGGER.error(f\"Failed to write CSV: {e}\")\n        raise\n    \n    LOGGER.info(\"Wrote CSV with %d rows to %s\", len(slides), output_path)\n    return output_path\n\ndef process_directory(json_dir: Path, output_dir: Optional[Path] = None, compact: bool = False, full: bool = False) -> List[Path]:\n    \"\"\"Process all JSON files in a directory.\"\"\"\n    LOGGER.info(\"Processing all JSON files in %s\", json_dir)\n    \n    # Find all JSON files\n    json_files = list(json_dir.glob(\"slides_*.json\"))\n    if not json_files:\n        LOGGER.error(\"No slide JSON files found in %s\", json_dir)\n        return []\n    \n    LOGGER.info(\"Found %d JSON files to process\", len(json_files))\n    \n    # Process each file\n    results = []\n    for json_path in json_files:\n        try:\n            csv_path = convert_json_to_csv(json_path, output_dir, compact, full)\n            results.append(csv_path)\n        except Exception as e:\n            LOGGER.error(\"Failed to convert %s: %s\", json_path, e, exc_info=True)\n    \n    return results\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    if output_dir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Process files\n    try:\n        if json_path.is_dir():\n            csv_files = process_directory(json_path, output_dir, args.compact, args.full)\n            if csv_files:\n                LOGGER.info(\"Converted %d JSON files to CSV\", len(csv_files))\n            else:\n                LOGGER.warning(\"No CSV files were generated\")\n                sys.exit(1)\n        else:\n            try:\n                convert_json_to_csv(json_path, output_dir, args.compact, args.full)\n            except Exception as e:\n                LOGGER.error(\"Failed to convert %s: %s\", json_path, e)\n                sys.exit(1)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()"
          },
          {
            "file_name": "guide_to_json.py",
            "file_size": 15057,
            "file_type": "",
            "extracted_content": "#!/usr/bin/env python3\n\"\"\"Convert a facilitator guide into slides.json using Claude 3.\n\nUsage:\n  python guide_to_json.py guide.md \\\n      --config config.yaml \\\n      --out slides.json \\\n      --log-level INFO \\\n      --log-file build.log\n      \n  # Process all markdown files in a folder:\n  python guide_to_json.py guides/ \\\n      --config config.yaml \\\n      --log-level INFO \\\n      --log-file build.log\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, time, yaml, re\nfrom pathlib import Path\nfrom typing import List, Dict, Any\nimport anthropic\n\nDEFAULT_OUT = \"slides.json\"\nDEFAULT_CONFIG = \"config.yaml\"\n\nLOGGER = logging.getLogger(\"guide_to_json\")\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"LLM â†’ JSON slide outline\")\n    p.add_argument(\"guide\", help=\"Facilitator guide (Markdown/text) or directory of guides\")\n    p.add_argument(\"--config\", default=DEFAULT_CONFIG, help=\"YAML config with prompt template and layout mappings\")\n    p.add_argument(\"--out\", default=None, help=\"Output JSON path (ignored if guide is a directory)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None, help=\"Write logs to file as well\")\n    p.add_argument(\"--model\", default=\"claude-3-7-sonnet-20250219\", help=\"Claude model to use\")\n    p.add_argument(\"--batch-size\", type=int, default=5, help=\"Number of files to process in parallel (batch mode)\")\n    p.add_argument(\"--force-json\", action=\"store_true\", help=\"Force JSON extraction even if response is not valid JSON\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers: list[logging.Handler] = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(\n        level=level,\n        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n        handlers=handlers,\n    )\n\n\ndef load_config(config_path: Path) -> Dict[str, Any]:\n    \"\"\"Load YAML configuration file with prompt template and layout mappings.\"\"\"\n    if not config_path.exists():\n        LOGGER.warning(\"Config file %s not found, using defaults\", config_path)\n        return {\n            \"prompt_template\": \"{{content}}\",\n            \"layout_mappings\": {},\n            \"slide_defaults\": {}\n        }\n    \n    with open(config_path, 'r') as f:\n        config = yaml.safe_load(f)\n    \n    # Ensure required keys exist\n    config.setdefault(\"prompt_template\", \"{{content}}\")\n    config.setdefault(\"layout_mappings\", {})\n    config.setdefault(\"slide_defaults\", {})\n    \n    return config\n\n\ndef build_prompt(template: str, guide_text: str) -> str:\n    \"\"\"Insert guide text into prompt template.\"\"\"\n    if \"{{content}}\" not in template:\n        LOGGER.error(\"Prompt template missing {{content}} placeholder\")\n        sys.exit(1)\n    return template.replace(\"{{content}}\", guide_text)\n\n\n# Insert missing keys and correct ordering\nORDER = [\n    \"slide_number\", \"title\", \"content\", \"layout\", \"chart_type\", \"diagram_type\", \"diagram_content\",\n    \"image_description\", \"image_url\", \"facilitator_notes\", \"start_time\", \"end_time\",\n    \"materials\", \"worksheet\", \"improvements\", \"notes\",\n]\n\n\ndef normalize(slides: list[dict], layout_mappings: Dict[str, str], slide_defaults: Dict[str, Any]) -> list[dict]:\n    \"\"\"Normalize slides by adding missing keys and applying layout mappings.\"\"\"\n    fixed = []\n    for idx, raw in enumerate(slides, 1):\n        # Apply defaults\n        for key, value in slide_defaults.items():\n            raw.setdefault(key, value)\n        \n        # Set slide number\n        raw.setdefault(\"slide_number\", idx)\n        \n        # Apply layout mapping if available\n        layout = raw.get(\"layout\")\n        if not layout:\n            # Determine layout based on content\n            if idx == 1:\n                raw[\"layout\"] = \"TITLE\"\n            elif raw.get(\"image_url\") or raw.get(\"diagram_type\"):\n                raw[\"layout\"] = \"TITLE_AND_TWO_COLUMNS\"\n            else:\n                raw[\"layout\"] = \"TITLE_AND_BODY\"\n        \n        # Apply custom layout mappings\n        if layout in layout_mappings:\n            raw[\"layout\"] = layout_mappings[layout]\n        \n        # Ensure all other keys exist\n        raw.setdefault(\"chart_type\", None)\n        raw.setdefault(\"image_description\", None)\n        raw.setdefault(\"image_url\", None)\n        for key in ORDER:\n            raw.setdefault(key, None)\n        \n        # Create ordered dictionary\n        fixed.append({k: raw.get(k) for k in ORDER})\n    \n    return fixed\n\n\ndef extract_json(text: str, force: bool = False) -> list:\n    \"\"\"Extract JSON array from text, even if surrounded by non-JSON content.\"\"\"\n    # Try to find a JSON array using regex\n    array_match = re.search(r'(\\[\\s*{.*}\\s*\\])', text, re.DOTALL)\n    if array_match:\n        try:\n            return json.loads(array_match.group(1))\n        except json.JSONDecodeError:\n            pass  # Fall through to other methods\n    \n    # Look for common JSON array start/end\n    start_idx = text.find('[')\n    end_idx = text.rfind(']')\n    \n    if start_idx != -1 and end_idx != -1 and start_idx < end_idx:\n        try:\n            return json.loads(text[start_idx:end_idx+1])\n        except json.JSONDecodeError:\n            pass  # Fall through to other methods\n    \n    # If force enabled, try to extract JSON objects and build an array\n    if force:\n        LOGGER.warning(\"Attempting to force JSON extraction from malformed response\")\n        objects = re.findall(r'{\\s*\"slide_number\"\\s*:.*?}', text, re.DOTALL)\n        if objects:\n            result = []\n            for obj_str in objects:\n                try:\n                    # Replace any trailing commas that would make the JSON invalid\n                    obj_str = re.sub(r',\\s*}', '}', obj_str)\n                    obj = json.loads(obj_str)\n                    result.append(obj)\n                except json.JSONDecodeError:\n                    continue\n            \n            if result:\n                LOGGER.info(f\"Successfully extracted {len(result)} slide objects\")\n                return result\n    \n    raise json.JSONDecodeError(\"Could not extract valid JSON from response\", text, 0)\n\n\ndef process_guide(guide_path: Path, config: Dict[str, Any], out_path: Path | None, model: str, client: anthropic.Anthropic, force_json: bool = False) -> Path:\n    \"\"\"Process a single guide file and return the output path.\"\"\"\n    LOGGER.info(\"Processing guide: %s\", guide_path)\n    \n    # Determine output path\n    if not out_path:\n        out_path = guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n    \n    # Read guide and build prompt\n    guide_txt = guide_path.read_text(encoding=\"utf-8\")\n    prompt = build_prompt(config[\"prompt_template\"], guide_txt)\n    \n    # Define tool for JSON extraction\n    tools = [\n        {\n            \"name\": \"generate_slides\",\n            \"description\": \"Generate slides from facilitator guide\",\n            \"input_schema\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"slides\": {\n                        \"type\": \"array\",\n                        \"items\": {\n                            \"type\": \"object\",\n                            \"properties\": {\n                                \"slide_number\": {\"type\": \"integer\"},\n                                \"title\": {\"type\": \"string\"},\n                                \"content\": {\"type\": \"string\"},\n                                \"layout\": {\"type\": \"string\"},\n                                \"chart_type\": {\"type\": [\"string\", \"null\"]},\n                                \"diagram_type\": {\"type\": [\"string\", \"null\"]},\n                                \"diagram_content\": {\"type\": [\"string\", \"null\"]},\n                                \"image_description\": {\"type\": [\"string\", \"null\"]},\n                                \"image_url\": {\"type\": [\"string\", \"null\"]},\n                                \"facilitator_notes\": {\"type\": [\"string\", \"null\"]},\n                                \"start_time\": {\"type\": [\"string\", \"null\"]},\n                                \"end_time\": {\"type\": [\"string\", \"null\"]},\n                                \"materials\": {\"type\": [\"string\", \"null\"]},\n                                \"worksheet\": {\"type\": [\"string\", \"null\"]},\n                                \"improvements\": {\"type\": [\"string\", \"null\"]},\n                                \"notes\": {\"type\": [\"string\", \"null\"]}\n                            },\n                            \"required\": [\"slide_number\", \"title\", \"content\", \"layout\"]\n                        }\n                    }\n                },\n                \"required\": [\"slides\"]\n            }\n\n        }\n    ]\n    \n    # Request Claude with retries\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            LOGGER.info(\"Requesting Claude (%s) for %s...\", model, guide_path.name)\n            \n            # Try with tools first\n            try:\n                rsp = client.messages.create(\n                    model=model,\n                    max_tokens=16_000,\n                    system=\"You are an expert at converting facilitator guides into well-structured slide content. Return valid JSON only.\",\n                    messages=[{\"role\": \"user\", \"content\": prompt}],\n                    tools=tools\n                )\n                \n                # Extract JSON from tool use\n                slides = None\n                for content in rsp.content:\n                    if hasattr(content, 'type') and content.type == \"tool_use\" and content.name == \"generate_slides\":\n                        slides = content.input[\"slides\"]\n                        break\n                \n                if slides:\n                    # Normalize and save\n                    slides = normalize(slides, config[\"layout_mappings\"], config[\"slide_defaults\"])\n                    out_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n                    LOGGER.info(\"Wrote %d slides â†’ %s\", len(slides), out_path)\n                    return out_path\n            except Exception as e:\n                LOGGER.warning(\"Tool-based approach failed: %s. Falling back to text extraction.\", e)\n            \n            # Fallback to traditional approach\n            rsp = client.messages.create(\n                model=model,\n                max_tokens=16_000,\n                system=\"Return JSON only. Your response should be a valid JSON array of slide objects, each with slide_number, title, content, and other fields.\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            )\n            \n            raw = rsp.content[0].text\n            \n            # Try to extract JSON from the response\n            try:\n                slides = extract_json(raw, force_json)\n            except json.JSONDecodeError as e:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Invalid JSON from Claude: %s, retrying in %d seconds...\", e, 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Invalid JSON from Claude after %d attempts: %s\", max_attempts, e)\n                    \n                    # Debug: Save the raw response to a file for inspection\n                    debug_path = out_path.with_suffix(\".debug.txt\")\n                    debug_path.write_text(raw)\n                    LOGGER.error(f\"Saved raw response to {debug_path} for debugging\")\n                    \n                    raise\n            \n            # Normalize and save\n            slides = normalize(slides, config[\"layout_mappings\"], config[\"slide_defaults\"])\n            out_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n            LOGGER.info(\"Wrote %d slides â†’ %s\", len(slides), out_path)\n            return out_path\n            \n        except (anthropic.APIError, anthropic.APITimeoutError, anthropic.APIConnectionError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"API error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                            attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)\n            else:\n                LOGGER.error(\"API error after %d attempts: %s\", max_attempts, e, exc_info=True)\n                raise\n    \n    raise RuntimeError(\"Failed to process guide, this should not happen\")  # Unreachable\n\n\ndef process_directory(guide_dir: Path, config: Dict[str, Any], model: str, batch_size: int, client: anthropic.Anthropic, force_json: bool = False) -> List[Path]:\n    \"\"\"Process all markdown files in a directory.\"\"\"\n    LOGGER.info(\"Processing all markdown files in: %s\", guide_dir)\n    \n    # Find all markdown and text files\n    md_files = list(guide_dir.glob(\"*.md\")) + list(guide_dir.glob(\"*.txt\"))\n    if not md_files:\n        LOGGER.error(\"No markdown or text files found in %s\", guide_dir)\n        sys.exit(1)\n    \n    LOGGER.info(\"Found %d files to process\", len(md_files))\n    \n    # Process files in batches to avoid overwhelming the API\n    results = []\n    for i in range(0, len(md_files), batch_size):\n        batch = md_files[i:i + batch_size]\n        LOGGER.info(\"Processing batch %d/%d (%d files)\", i // batch_size + 1, \n                   (len(md_files) + batch_size - 1) // batch_size, len(batch))\n        \n        for guide_path in batch:\n            try:\n                out_path = process_guide(guide_path, config, None, model, client, force_json)\n                results.append(out_path)\n            except Exception as e:\n                LOGGER.error(\"Failed to process %s: %s\", guide_path, e, exc_info=True)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n    if not api_key:\n        LOGGER.error(\"Set ANTHROPIC_API_KEY environment variable\")\n        sys.exit(1)\n\n    # Load configuration\n    config_path = Path(args.config)\n    config = load_config(config_path)\n    \n    # Validate paths\n    guide_path = Path(args.guide)\n    \n    if not guide_path.exists():\n        LOGGER.error(\"Guide path not found: %s\", guide_path)\n        sys.exit(1)\n    \n    # Initialize Claude client\n    client = anthropic.Anthropic(api_key=api_key)\n    \n    if guide_path.is_dir():\n        LOGGER.info(\"Directory mode: Processing all markdown files in %s\", guide_path)\n        if args.out:\n            LOGGER.warning(\"--out parameter ignored in directory mode\")\n        \n        # Process directory\n        process_directory(guide_path, config, args.model, args.batch_size, client, args.force_json)\n        \n    else:\n        # Single file mode\n        # Determine output path\n        out_path = Path(args.out) if args.out else guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n        \n        # Process single guide\n        process_guide(guide_path, config, out_path, args.model, client, args.force_json)\n\n\nif __name__ == \"__main__\":\n    main()"
          },
          {
            "file_name": "json_to_markdown.py",
            "file_size": 8803,
            "file_type": "",
            "extracted_content": "#!/usr/bin/env python3\n\"\"\"Convert slides.json to md2gslides compatible markdown files.\n\nThis script converts JSON slide data to markdown format compatible with md2gslides,\nallowing for generation of Google Slides presentations.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys\nfrom pathlib import Path\nfrom typing import Dict, List, Any, Optional\n\nLOGGER = logging.getLogger(\"json_to_markdown\")\n\n# Map of slide layouts to md2gslides format templates\nLAYOUT_TEMPLATES = {\n    \"TITLE\": {\n        \"template\": \"\"\"# {title}\n## {subtitle}\n\"\"\",\n        \"fields\": [\"title\", \"subtitle\"]\n    },\n    \"TITLE_AND_BODY\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"TITLE_AND_TWO_COLUMNS\": {\n        \"template\": \"\"\"# {title}\n\n{left_column}\n\n{{.column}}\n\n{right_column}\n\"\"\",\n        \"fields\": [\"title\", \"left_column\", \"right_column\"]\n    },\n    \"MAIN_POINT\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\"\"\",\n        \"fields\": [\"title\"]\n    },\n    \"SECTION_HEADER\": {\n        \"template\": \"\"\"# {title}\n\"\"\",\n        \"fields\": [\"title\"]\n    },\n    \"BIG_NUMBER\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"CAPTION\": {\n        \"template\": \"\"\"# {title}\n\n![]({image_url})\n\"\"\",\n        \"fields\": [\"title\", \"image_url\"]\n    },\n    \"BLANK\": {\n        \"template\": \"\"\"\n![]({image_url}){{.background}}\n\"\"\",\n        \"fields\": [\"image_url\"]\n    },\n    \"DEFAULT\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    }\n}\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Convert slides.json to md2gslides markdown\")\n    p.add_argument(\"json\", help=\"slides.json file or directory of JSON files\")\n    p.add_argument(\"--output-dir\", default=None, help=\"Output directory for markdown files\")\n    p.add_argument(\"--prefer-svg\", action=\"store_true\", help=\"Prefer SVG over PNG for diagrams\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef split_content_into_columns(content: str) -> tuple[str, str]:\n    \"\"\"Split content into two columns based on content length.\"\"\"\n    if not content:\n        return \"\", \"\"\n    \n    lines = content.split('\\n')\n    if len(lines) <= 1:\n        return content, \"\"\n    \n    midpoint = len(lines) // 2\n    left_column = '\\n'.join(lines[:midpoint])\n    right_column = '\\n'.join(lines[midpoint:])\n    \n    return left_column, right_column\n\n\ndef convert_to_svg_block(image_path: str, slide_num: int) -> str:\n    \"\"\"Convert image path to SVG block if it's an SVG file.\"\"\"\n    path = Path(image_path)\n    if path.suffix.lower() == '.svg' and path.exists():\n        try:\n            svg_content = path.read_text(encoding='utf-8')\n            return f\"\\n$$$ svg\\n{svg_content}\\n$$$\\n\"\n        except Exception as e:\n            LOGGER.warning(f\"Failed to read SVG file {path}: {e}\")\n            return f\"![](${image_path})\"\n    return f\"![](${image_path})\"\n\n\ndef format_slide(slide: Dict[str, Any], prefer_svg: bool = False) -> str:\n    \"\"\"Format a single slide as markdown based on its layout.\"\"\"\n    # Extract slide data\n    layout = slide.get(\"layout\", \"DEFAULT\")\n    \n    # Get layout template\n    template_info = LAYOUT_TEMPLATES.get(layout, LAYOUT_TEMPLATES[\"DEFAULT\"])\n    template = template_info[\"template\"]\n    \n    # Handle image URL\n    image_url = slide.get(\"image_url\", \"\")\n    if image_url:\n        # Check if there's an SVG version of the image\n        if prefer_svg and image_url.lower().endswith('.png'):\n            svg_path = image_url[:-4] + '.svg'\n            svg_path_obj = Path(svg_path)\n            if svg_path_obj.exists():\n                # Use SVG block instead of image reference\n                svg_content = svg_path_obj.read_text(encoding='utf-8')\n                image_block = f\"\\n$$$ svg\\n{svg_content}\\n$$$\\n\"\n            else:\n                image_block = f\"![]({image_url})\"\n        else:\n            image_block = f\"![]({image_url})\"\n    else:\n        image_block = \"\"\n    \n    # Create data dict for template\n    data = {\n        \"title\": slide.get(\"title\", \"\"),\n        \"subtitle\": slide.get(\"subtitle\", \"\"),\n        \"content\": slide.get(\"content\", \"\"),\n        \"image_url\": image_url\n    }\n    \n    # For two column layouts, split content and handle images\n    if layout == \"TITLE_AND_TWO_COLUMNS\":\n        left, right = split_content_into_columns(data[\"content\"])\n        data[\"left_column\"] = left\n        \n        # If there's an image, use it for the right column\n        if image_url:\n            if prefer_svg and image_url.lower().endswith('.png'):\n                svg_path = image_url[:-4] + '.svg'\n                svg_path_obj = Path(svg_path)\n                if svg_path_obj.exists():\n                    # Use SVG block instead of image reference\n                    svg_content = svg_path_obj.read_text(encoding='utf-8')\n                    data[\"right_column\"] = f\"\\n$$$ svg\\n{svg_content}\\n$$$\\n\"\n                else:\n                    data[\"right_column\"] = f\"![]({image_url})\"\n            else:\n                data[\"right_column\"] = f\"![]({image_url})\"\n        else:\n            data[\"right_column\"] = right\n    \n    # Add speaker notes if available\n    notes = slide.get(\"facilitator_notes\", \"\")\n    notes_section = f\"\\n\\n<!--\\n{notes}\\n-->\" if notes else \"\"\n    \n    # Format markdown\n    try:\n        md = template.format(**{k: v for k, v in data.items() if k in template_info[\"fields\"]})\n        return f\"---\\n\\n{md}{notes_section}\\n\"\n    except KeyError as e:\n        LOGGER.warning(f\"Missing field {e} for layout {layout}, using default\")\n        return f\"---\\n\\n# {data['title']}\\n\\n{data['content']}{notes_section}\\n\"\n\n\ndef convert_json_to_markdown(json_path: Path, output_dir: Optional[Path] = None, prefer_svg: bool = False) -> Path:\n    \"\"\"Convert a single JSON file to markdown.\"\"\"\n    LOGGER.info(\"Converting %s to markdown\", json_path)\n    \n    # Load JSON data\n    try:\n        slides = json.loads(json_path.read_text())\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON in %s: %s\", json_path, e)\n        raise\n    \n    # Create markdown\n    md_content = []\n    for slide in slides:\n        md_content.append(format_slide(slide, prefer_svg))\n    \n    # Join with newlines\n    markdown = \"\\n\".join(md_content)\n    \n    # Determine output path\n    if output_dir:\n        output_path = output_dir / f\"{json_path.stem.replace('slides_', '')}.md\"\n    else:\n        output_path = json_path.with_suffix(\".md\")\n    \n    # Write markdown file\n    output_path.write_text(markdown)\n    LOGGER.info(\"Wrote markdown to %s\", output_path)\n    \n    return output_path\n\n\ndef process_directory(json_dir: Path, output_dir: Optional[Path] = None, prefer_svg: bool = False) -> List[Path]:\n    \"\"\"Process all JSON files in a directory.\"\"\"\n    LOGGER.info(\"Processing all JSON files in %s\", json_dir)\n    \n    # Find all JSON files\n    json_files = list(json_dir.glob(\"slides_*.json\"))\n    if not json_files:\n        LOGGER.error(\"No slide JSON files found in %s\", json_dir)\n        return []\n    \n    LOGGER.info(\"Found %d JSON files to process\", len(json_files))\n    \n    # Process each file\n    results = []\n    for json_path in json_files:\n        try:\n            md_path = convert_json_to_markdown(json_path, output_dir, prefer_svg)\n            results.append(md_path)\n        except Exception as e:\n            LOGGER.error(\"Failed to convert %s: %s\", json_path, e, exc_info=True)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    if output_dir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Process files\n    try:\n        if json_path.is_dir():\n            md_files = process_directory(json_path, output_dir, args.prefer_svg)\n            LOGGER.info(\"Converted %d JSON files to markdown\", len(md_files))\n        else:\n            convert_json_to_markdown(json_path, output_dir, args.prefer_svg)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()"
          },
          {
            "file_name": "CLAUDE.md",
            "file_size": 5783,
            "file_type": "",
            "extracted_content": "# CLAUDE.md\n\nThis file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.\n\n## Project Overview\n\nMakeSlides is a CLI tool for converting training facilitator guides into Google Slides presentations. The workflow involves:\n\n1. Converting a facilitator guide document into a structured JSON file using Claude API\n2. Using the JSON data to generate a Google Slides presentation with locally stored images and diagrams\n\n## Architecture\n\nThe codebase consists of these main components:\n\n1. **Guide to JSON Processor (`guide_to_json.py`)** - Converts facilitator guides to structured JSON:\n   - Uses Claude API to analyze and structure guide content\n   - Extracts slide content, titles, diagrams, and metadata\n   - Normalizes output and validates JSON formatting\n   - Applies layout mappings and defaults\n\n2. **Diagram Generator (`diagrams_to_images.py`)** - Creates diagrams from Mermaid syntax:\n   - Validates and repairs common Mermaid syntax issues\n   - Generates PNG and SVG diagrams from Mermaid specifications\n   - Uses Claude API to fix syntax errors and convert text to diagrams\n   - Handles error cases with fallback diagrams\n\n3. **Markdown Generator (`json_to_markdown.py`)** - Converts JSON to markdown for slide creation:\n   - Processes JSON slide data into markdown slides\n   - Handles diagrams and images\n   - Creates content formatted specifically for md2gslides\n\n4. **Slides Generator (`build_with_md2gslides.py`)** - Creates Google Slides presentations:\n   - Uses md2gslides npm package to create presentations\n   - Validates markdown content\n   - Handles image and diagram embedding\n   - Provides detailed logging and error handling\n\n5. **Master Shell Script (`magicSlide.sh`)** - Coordinates the entire workflow:\n   - Orchestrates the 5-step process (JSON â†’ Diagrams â†’ CSV â†’ Markdown â†’ Slides)\n   - Provides CLI options for customization\n   - Handles both single file and directory mode\n   - Includes error handling and progress tracking\n\n## Commands\n\n### Basic Usage\n\n1. **Run the full pipeline**:\n   ```bash\n   ./magicSlide.sh guides/day2.md\n   ```\n\n2. **Run with additional options**:\n   ```bash\n   ./magicSlide.sh guides/day2.md --config=config.yaml --no-fileio --log-level=DEBUG\n   ```\n\n3. **Process all files in a directory**:\n   ```bash\n   ./magicSlide.sh guides/\n   ```\n\n### Individual Component Usage\n\n1. **Convert facilitator guide to JSON**:\n   ```bash\n   python guide_to_json.py guides/day2.md --config=config.yaml --out=slides_day2.json\n   ```\n\n2. **Render Mermaid diagrams to images**:\n   ```bash\n   python diagrams_to_images.py slides_day2.json --mermaid-config=mermaid-config.json\n   ```\n\n3. **Generate CSV overview**:\n   ```bash\n   python json_to_csv.py slides_day2.json --full\n   ```\n\n4. **Convert JSON to markdown**:\n   ```bash\n   python json_to_markdown.py slides_day2.json --prefer-svg\n   ```\n\n5. **Generate Google Slides from markdown**:\n   ```bash\n   python build_with_md2gslides.py day2.md --title-prefix=\"Solar Training: \" --style=github\n   ```\n\n### Test Commands\n\n1. **Generate a test diagram**:\n   ```bash\n   python diagrams_to_images.py --model=claude-3-7-sonnet-20250219 flowchart \"A[Start] --> B[End]\"\n   ```\n\n2. **Validate a JSON file**:\n   ```bash\n   python validate_json.py path/to/file.json output.json\n   ```\n\n## Configuration Files\n\n1. **config.yaml** - Contains the prompt template for Claude to process facilitator guides:\n   - Controls the prompt for LLM processing\n   - Defines layout mappings\n   - Sets slide defaults\n\n2. **mermaid-config.json** - Configuration for Mermaid diagram generation:\n   - Defines styling for diagrams\n   - Sets default theme and rendering options\n\n## Environment Setup\n\n1. **Python dependencies**:\n   - Anthropic API client for Claude interaction\n   - PyYAML for configuration parsing\n   - Additional utilities for file handling and processing\n\n2. **Node.js dependencies**:\n   - md2gslides npm package for Google Slides creation\n\n3. **Credentials**:\n   - Anthropic API key (set as environment variable ANTHROPIC_API_KEY)\n   - Google API credentials (client_secret.json renamed to credentials.json)\n\n## Workflow Details\n\n1. **Guide to JSON conversion**:\n   - Facilitator guide is processed using Claude API\n   - Structured JSON is created with slide content, layout, and metadata\n   - JSON is normalized and validated\n\n2. **Diagram generation**:\n   - Mermaid diagrams specified in JSON are rendered to PNG and SVG\n   - Claude API is used to fix syntax errors or convert plain text to diagrams\n   - Images are saved locally\n\n3. **CSV generation**:\n   - JSON is converted to CSV for easy content review\n   - Different levels of detail are available (full or compact)\n\n4. **Markdown generation**:\n   - JSON is converted to markdown for md2gslides\n   - Images and diagrams are incorporated\n   - Slide separators and formatting are added\n\n5. **Google Slides generation**:\n   - md2gslides creates Google Slides presentation\n   - Images and diagrams are embedded\n   - Presentation URL is saved for future reference\n\n## Troubleshooting\n\n1. **JSON Parsing Errors**:\n   - Check the raw LLM response in debug files\n   - Increase max_tokens in the Claude API call\n   - Try processing the guide in smaller sections\n\n2. **Diagram Generation Errors**:\n   - Ensure Mermaid syntax follows proper format\n   - Check that diagram type is supported\n   - Use the --preserve-all flag to keep all attempts for debugging\n\n3. **Google API Authentication**:\n   - Ensure credentials.json has proper Google OAuth2 credentials\n   - Follow authentication prompts when first running\n   - Check token.json for valid refresh tokens\n\n4. **General Issues**:\n   - Use --log-level=DEBUG for more detailed output\n   - Check that all dependencies are installed\n   - Validate input file formats"
          }
        ],
        "files": [
          {
            "file_name": "day5_overview.csv"
          },
          {
            "file_name": "CleanShot 20250520 at 13.40.182x.png"
          },
          {
            "file_name": "generate_slides.sh"
          },
          {
            "file_name": "unsplash_cache.py"
          },
          {
            "file_name": "config.yaml"
          },
          {
            "file_name": "diagrams_to_images.py"
          },
          {
            "file_name": "magicSlide.sh"
          },
          {
            "file_name": "build_with_md2gslides.py"
          },
          {
            "file_name": "json_to_csv.py"
          },
          {
            "file_name": "guide_to_json.py"
          },
          {
            "file_name": "json_to_markdown.py"
          },
          {
            "file_name": "CLAUDE.md"
          }
        ]
      }
    },
    {
      "id": "3eb5e241-2992-48fb-a6cf-9ce303e30aa2",
      "role": "assistant",
      "content": "Based on the extensive documentation you've provided and the issues you're describing, I'll analyze the current system and propose improvements to address the specific problems you're facing. Let me break this down:\n\n## Current Issues Identified\n1. **Duplicate script functionality**: Having both `generate_slides.sh` and `magicSlide.sh` scripts that seem to do similar things\n2. **SVG/image rendering problems**: SVG production issues during rasterization\n3. **Uniformity in slide appearance**: All slides look the same without different layouts, diagrams or images\n4. **Redundant diagram generation**: Diagrams being created 3 times with slight modifications each time\n5. **Asset management**: No centralized storage or tracking for Unsplash images and diagrams\n\n## Analysis of the Current Code Architecture\n\nFrom the provided files, the system has this basic workflow:\n1. `guide_to_json.py` - Converts facilitator guide to structured JSON using Claude\n2. `diagrams_to_images.py` - Renders Mermaid diagrams to images\n3. `json_to_csv.py` - Creates CSV overview of slides\n4. `json_to_markdown.py` - Converts JSON to markdown\n5. `build_with_md2gslides.py` - Uses md2gslides to create Google Slides\n6. Shell scripts (`generate_slides.sh` or `magicSlide.sh`) orchestrate this process\n\nThe system also has `unsplash_cache.py` for image management, but it appears this isn't fully integrated with the asset management process.\n\n## Root Causes of Issues\n\n1. **Layout problems**: The `json_to_markdown.py` script might not be correctly applying the layout templates defined in `LAYOUT_TEMPLATES` to generate varied slide layouts. It may be defaulting to one template.\n\n2. **Image integration**: There might be issues with how images from Unsplash are being referenced and integrated into slides.\n\n3. **Diagram repetition**: The `diagrams_to_images.py` script has a `--preserve-all` flag that keeps all versions of diagrams instead of overwriting them, which could be causing the repetition.\n\n4. **Asset management**: There's no centralized system for tracking and reusing images and diagrams.\n\n## Proposed Solution\n\nI'll outline a comprehensive approach to streamline the workflow, fix the issues, and improve the system overall.\n\nLet me break this down into specific areas that need improvement:\n\n1. **Script consolidation**\n2. **Asset management system**\n3. **Fixing layout application**\n4. **Improving image and diagram integration**\n5. **Reducing redundant processing**\n\nThis should address all the concerns you've raised.# MakeSlides System Analysis and Improvement Plan\n\nAfter reviewing your code repository, I understand the issues you're experiencing with redundancy, asset management, and layout problems. Here's a comprehensive analysis and improvement plan:\n\n## Current Issues\n\n1. **Duplicate functionality**: Both `generate_slides.sh` and `magicSlide.sh` do similar things\n2. **Asset duplication**: Diagrams being generated multiple times with slight modifications\n3. **Layout problems**: All slides using the same template despite different layouts in JSON\n4. **Image management**: No central storage for Unsplash images and diagrams\n5. **SVG handling**: Issues with SVG rendering and integration\n\n## Recommended Improvements\n\n### 1. Consolidate Scripts\n\nThe `magicSlide.sh` script is more feature-complete than `generate_slides.sh`. I recommend:\n\n```bash\n# Remove the duplicate script\nrm generate_slides.sh\n# Create a symbolic link if legacy scripts depend on it\nln -s magicSlide.sh generate_slides.sh\n```\n\n### 2. Implement Asset Management System\n\nCreate a centralized asset management system for both images and diagrams:\n```\nViewing artifacts created via the Analysis Tool web feature preview isnâ€™t yet supported on mobile.\n```\n\n\n\n### 3. Fix Layout Rendering in Markdown Generation\n\nLet's fix the `json_to_markdown.py` script to properly handle different layouts:\n```\nViewing artifacts created via the Analysis Tool web feature preview isnâ€™t yet supported on mobile.\n```\n\n\n\n### 4. Improve Diagram Generation with Deduplication\n\nLet's modify the diagrams_to_images.py script to use our new asset management system:\n```\nViewing artifacts created via the Analysis Tool web feature preview isnâ€™t yet supported on mobile.\n```\n\n\n\n### 5. Update Master Script to Use Asset Management\n\nLet's now update `magicSlide.sh` to work with our new improvements:\n```\nViewing artifacts created via the Analysis Tool web feature preview isnâ€™t yet supported on mobile.\n```\n\n",
      "created_at": "2025-05-20T11:45:38.307145Z",
      "sequence_order": 1,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-20T11:40:30.292386Z",
            "stop_timestamp": "2025-05-20T11:40:41.285588Z",
            "flags": null,
            "type": "thinking",
            "thinking": "Based on the extensive documentation you've provided and the issues you're describing, I'll analyze the current system and propose improvements to address the specific problems you're facing. Let me break this down:\n\n## Current Issues Identified\n1. **Duplicate script functionality**: Having both `generate_slides.sh` and `magicSlide.sh` scripts that seem to do similar things\n2. **SVG/image rendering problems**: SVG production issues during rasterization\n3. **Uniformity in slide appearance**: All slides look the same without different layouts, diagrams or images\n4. **Redundant diagram generation**: Diagrams being created 3 times with slight modifications each time\n5. **Asset management**: No centralized storage or tracking for Unsplash images and diagrams\n\n## Analysis of the Current Code Architecture\n\nFrom the provided files, the system has this basic workflow:\n1. `guide_to_json.py` - Converts facilitator guide to structured JSON using Claude\n2. `diagrams_to_images.py` - Renders Mermaid diagrams to images\n3. `json_to_csv.py` - Creates CSV overview of slides\n4. `json_to_markdown.py` - Converts JSON to markdown\n5. `build_with_md2gslides.py` - Uses md2gslides to create Google Slides\n6. Shell scripts (`generate_slides.sh` or `magicSlide.sh`) orchestrate this process\n\nThe system also has `unsplash_cache.py` for image management, but it appears this isn't fully integrated with the asset management process.\n\n## Root Causes of Issues\n\n1. **Layout problems**: The `json_to_markdown.py` script might not be correctly applying the layout templates defined in `LAYOUT_TEMPLATES` to generate varied slide layouts. It may be defaulting to one template.\n\n2. **Image integration**: There might be issues with how images from Unsplash are being referenced and integrated into slides.\n\n3. **Diagram repetition**: The `diagrams_to_images.py` script has a `--preserve-all` flag that keeps all versions of diagrams instead of overwriting them, which could be causing the repetition.\n\n4. **Asset management**: There's no centralized system for tracking and reusing images and diagrams.\n\n## Proposed Solution\n\nI'll outline a comprehensive approach to streamline the workflow, fix the issues, and improve the system overall.\n\nLet me break this down into specific areas that need improvement:\n\n1. **Script consolidation**\n2. **Asset management system**\n3. **Fixing layout application**\n4. **Improving image and diagram integration**\n5. **Reducing redundant processing**\n\nThis should address all the concerns you've raised.",
            "summaries": [
              {
                "summary": "Thinking about streamlining slide generation, image management, and reducing code duplication"
              },
              {
                "summary": "Analyzing system issues and proposing streamlined improvements"
              },
              {
                "summary": "Streamlining workflow, fixing issues, and improving slide generation system"
              },
              {
                "summary": "Dissected slide generation workflow, proposed comprehensive system overhaul."
              }
            ],
            "cut_off": false
          },
          {
            "start_timestamp": "2025-05-20T11:40:41.610903Z",
            "stop_timestamp": "2025-05-20T11:40:45.016928Z",
            "flags": null,
            "type": "text",
            "text": "# MakeSlides System Analysis and Improvement Plan\n\nAfter reviewing your code repository, I understand the issues you're experiencing with redundancy, asset management, and layout problems. Here's a comprehensive analysis and improvement plan:\n\n## Current Issues\n\n1. **Duplicate functionality**: Both `generate_slides.sh` and `magicSlide.sh` do similar things\n2. **Asset duplication**: Diagrams being generated multiple times with slight modifications\n3. **Layout problems**: All slides using the same template despite different layouts in JSON\n4. **Image management**: No central storage for Unsplash images and diagrams\n5. **SVG handling**: Issues with SVG rendering and integration\n\n## Recommended Improvements\n\n### 1. Consolidate Scripts\n\nThe `magicSlide.sh` script is more feature-complete than `generate_slides.sh`. I recommend:\n\n```bash\n# Remove the duplicate script\nrm generate_slides.sh\n# Create a symbolic link if legacy scripts depend on it\nln -s magicSlide.sh generate_slides.sh\n```\n\n### 2. Implement Asset Management System\n\nCreate a centralized asset management system for both images and diagrams:",
            "citations": []
          },
          {
            "start_timestamp": "2025-05-20T11:40:45.335383Z",
            "stop_timestamp": "2025-05-20T11:41:46.269145Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "asset-manager",
              "type": "application/vnd.ant.code",
              "title": "asset_manager.py",
              "command": "create",
              "content": "#!/usr/bin/env python3\n\"\"\"\nAsset Manager for MakeSlides\n\nThis script provides centralized management for all assets (images, diagrams)\nused in the slide creation process. It maintains a cache of assets to avoid\nredundant downloads and generation.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, shutil, hashlib\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Tuple\nimport requests\nimport time\n\nLOGGER = logging.getLogger(\"asset_manager\")\n\n# Default paths\nDEFAULT_CACHE_DIR = Path.home() / \".makeslides\" / \"assets\"\nDEFAULT_CACHE_FILE = DEFAULT_CACHE_DIR / \"asset_cache.json\"\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Manage assets for MakeSlides\")\n    \n    # Command subparsers\n    subparsers = p.add_subparsers(dest=\"command\", help=\"Command to execute\")\n    \n    # Get image command\n    get_img = subparsers.add_parser(\"get-image\", help=\"Get or cache an image\")\n    get_img.add_argument(\"url\", help=\"URL of the image to get\")\n    get_img.add_argument(\"--category\", help=\"Category for the image (e.g., 'solar', 'training')\")\n    get_img.add_argument(\"--local-path\", help=\"Optional local path to store/copy the image\")\n    \n    # Get diagram command\n    get_diag = subparsers.add_parser(\"get-diagram\", help=\"Get or cache a diagram\")\n    get_diag.add_argument(\"content\", help=\"Mermaid content of the diagram\")\n    get_diag.add_argument(\"--type\", default=\"flowchart\", help=\"Type of diagram\")\n    get_diag.add_argument(\"--local-path\", help=\"Optional local path to store the diagram\")\n    \n    # List assets command\n    list_cmd = subparsers.add_parser(\"list\", help=\"List all cached assets\")\n    list_cmd.add_argument(\"--category\", help=\"Filter by category\")\n    list_cmd.add_argument(\"--type\", help=\"Filter by asset type (image/diagram)\")\n    \n    # Clean cache command\n    clean_cmd = subparsers.add_parser(\"clean\", help=\"Clean the asset cache\")\n    clean_cmd.add_argument(\"--remove-unused\", action=\"store_true\", help=\"Remove unused assets\")\n    clean_cmd.add_argument(\"--days\", type=int, default=30, help=\"Remove assets older than X days\")\n    \n    # Update JSON command\n    update_cmd = subparsers.add_parser(\"update-json\", help=\"Update JSON files with asset paths\")\n    update_cmd.add_argument(\"json_file\", help=\"JSON file to update\")\n    update_cmd.add_argument(\"--output\", help=\"Output file (default: overwrite input)\")\n    \n    # Common arguments\n    p.add_argument(\"--cache-dir\", default=DEFAULT_CACHE_DIR, help=\"Cache directory\")\n    p.add_argument(\"--cache-file\", default=DEFAULT_CACHE_FILE, help=\"Cache file\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    \n    return p.parse_args()\n\ndef setup_logging(level: str):\n    \"\"\"Configure logging.\"\"\"\n    logging.basicConfig(\n        level=getattr(logging, level),\n        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n        handlers=[logging.StreamHandler(sys.stdout)]\n    )\n\nclass AssetManager:\n    \"\"\"Manages assets (images, diagrams) for slide creation.\"\"\"\n    \n    def __init__(self, cache_dir: Path, cache_file: Path):\n        \"\"\"Initialize the asset manager.\n        \n        Args:\n            cache_dir: Directory to store cached assets\n            cache_file: File to store cache metadata\n        \"\"\"\n        self.cache_dir = cache_dir\n        self.images_dir = cache_dir / \"images\"\n        self.diagrams_dir = cache_dir / \"diagrams\"\n        self.cache_file = cache_file\n        \n        # Create directories if they don't exist\n        self.cache_dir.mkdir(parents=True, exist_ok=True)\n        self.images_dir.mkdir(exist_ok=True)\n        self.diagrams_dir.mkdir(exist_ok=True)\n        \n        # Load cache\n        self.cache = self._load_cache()\n    \n    def _load_cache(self) -> Dict[str, Any]:\n        \"\"\"Load the asset cache from disk.\"\"\"\n        if not self.cache_file.exists():\n            LOGGER.info(f\"Cache file not found at {self.cache_file}. Creating new cache.\")\n            return {\n                \"images\": {},\n                \"diagrams\": {},\n                \"last_updated\": time.time()\n            }\n        \n        try:\n            with open(self.cache_file, 'r') as f:\n                cache = json.load(f)\n            LOGGER.debug(f\"Loaded cache with {len(cache.get('images', {}))} images and {len(cache.get('diagrams', {}))} diagrams\")\n            return cache\n        except Exception as e:\n            LOGGER.warning(f\"Error loading cache: {e}. Creating new cache.\")\n            return {\n                \"images\": {},\n                \"diagrams\": {},\n                \"last_updated\": time.time()\n            }\n    \n    def _save_cache(self):\n        \"\"\"Save the asset cache to disk.\"\"\"\n        self.cache[\"last_updated\"] = time.time()\n        try:\n            with open(self.cache_file, 'w') as f:\n                json.dump(self.cache, f, indent=2)\n            LOGGER.debug(f\"Saved cache to {self.cache_file}\")\n        except Exception as e:\n            LOGGER.error(f\"Error saving cache: {e}\")\n    \n    def get_image(self, url: str, category: Optional[str] = None, local_path: Optional[Path] = None) -> Path:\n        \"\"\"Get or cache an image.\n        \n        Args:\n            url: URL of the image\n            category: Category for the image (e.g., 'solar', 'training')\n            local_path: Optional local path to store/copy the image\n            \n        Returns:\n            Path to the cached image\n        \"\"\"\n        # Generate a hash for the URL\n        url_hash = hashlib.md5(url.encode()).hexdigest()[:10]\n        \n        # Check if image is already in cache\n        if url in self.cache[\"images\"]:\n            cached_path = Path(self.cache[\"images\"][url][\"path\"])\n            if cached_path.exists():\n                LOGGER.info(f\"Using cached image for {url}\")\n                \n                # If local_path is provided, copy the image\n                if local_path:\n                    local_path = Path(local_path)\n                    local_path.parent.mkdir(parents=True, exist_ok=True)\n                    shutil.copy2(cached_path, local_path)\n                    LOGGER.debug(f\"Copied cached image to {local_path}\")\n                    return local_path\n                \n                return cached_path\n        \n        # Image not in cache or file missing, download it\n        LOGGER.info(f\"Downloading image from {url}\")\n        \n        try:\n            # Determine file extension from URL\n            ext = Path(url).suffix\n            if not ext:\n                ext = \".jpg\"  # Default to jpg if no extension\n            \n            # Create filename and path\n            filename = f\"img_{url_hash}{ext}\"\n            img_path = self.images_dir / filename\n            \n            # Download the image\n            response = requests.get(url, stream=True, timeout=10)\n            response.raise_for_status()\n            \n            with open(img_path, 'wb') as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    f.write(chunk)\n            \n            # Update cache\n            self.cache[\"images\"][url] = {\n                \"path\": str(img_path),\n                \"category\": category,\n                \"hash\": url_hash,\n                \"timestamp\": time.time()\n            }\n            self._save_cache()\n            \n            # If local_path is provided, copy the image\n            if local_path:\n                local_path = Path(local_path)\n                local_path.parent.mkdir(parents=True, exist_ok=True)\n                shutil.copy2(img_path, local_path)\n                LOGGER.debug(f\"Copied downloaded image to {local_path}\")\n                return local_path\n            \n            return img_path\n            \n        except Exception as e:\n            LOGGER.error(f\"Error downloading image from {url}: {e}\")\n            raise\n    \n    def get_diagram(self, content: str, diagram_type: str = \"flowchart\", local_path: Optional[Path] = None) -> Optional[Path]:\n        \"\"\"Get or cache a diagram.\n        \n        Args:\n            content: Mermaid content of the diagram\n            diagram_type: Type of diagram (e.g., 'flowchart', 'mindmap')\n            local_path: Optional local path to store the diagram\n            \n        Returns:\n            Path to the cached diagram or None if not found\n        \"\"\"\n        # Generate a hash for the content\n        content_hash = hashlib.md5(content.encode()).hexdigest()[:10]\n        \n        # Check if diagram is already in cache\n        if content_hash in self.cache[\"diagrams\"]:\n            cached_info = self.cache[\"diagrams\"][content_hash]\n            cached_path = Path(cached_info[\"path\"])\n            \n            if cached_path.exists():\n                LOGGER.info(f\"Using cached diagram for hash {content_hash}\")\n                \n                # If local_path is provided, copy the diagram\n                if local_path:\n                    local_path = Path(local_path)\n                    local_path.parent.mkdir(parents=True, exist_ok=True)\n                    shutil.copy2(cached_path, local_path)\n                    \n                    # Also copy SVG if it exists\n                    svg_path = cached_path.with_suffix(\".svg\")\n                    if svg_path.exists():\n                        local_svg_path = local_path.with_suffix(\".svg\")\n                        shutil.copy2(svg_path, local_svg_path)\n                        LOGGER.debug(f\"Copied cached SVG to {local_svg_path}\")\n                    \n                    LOGGER.debug(f\"Copied cached diagram to {local_path}\")\n                    return local_path\n                \n                return cached_path\n        \n        # If we're just checking and not generating, return None\n        if local_path is None:\n            LOGGER.info(f\"Diagram {content_hash} not found in cache\")\n            return None\n        \n        # If local_path is provided, assume it's a newly generated diagram we want to cache\n        if local_path:\n            local_path = Path(local_path)\n            if local_path.exists():\n                # Create cached copy\n                cached_filename = f\"diagram_{content_hash}{local_path.suffix}\"\n                cached_path = self.diagrams_dir / cached_filename\n                \n                # Copy to cache\n                shutil.copy2(local_path, cached_path)\n                LOGGER.info(f\"Cached new diagram as {cached_path}\")\n                \n                # Also copy SVG if it exists\n                local_svg_path = local_path.with_suffix(\".svg\")\n                if local_svg_path.exists():\n                    cached_svg_path = cached_path.with_suffix(\".svg\")\n                    shutil.copy2(local_svg_path, cached_svg_path)\n                    LOGGER.debug(f\"Cached SVG as {cached_svg_path}\")\n                \n                # Update cache\n                self.cache[\"diagrams\"][content_hash] = {\n                    \"path\": str(cached_path),\n                    \"type\": diagram_type,\n                    \"hash\": content_hash,\n                    \"timestamp\": time.time()\n                }\n                self._save_cache()\n                \n                return local_path\n        \n        LOGGER.error(f\"No local path provided for diagram {content_hash}\")\n        return None\n    \n    def list_assets(self, category: Optional[str] = None, asset_type: Optional[str] = None) -> Dict[str, List[Dict[str, Any]]]:\n        \"\"\"List all cached assets, optionally filtered by category or type.\n        \n        Args:\n            category: Filter by category\n            asset_type: Filter by asset type (image/diagram)\n            \n        Returns:\n            Dictionary with lists of assets\n        \"\"\"\n        result = {\"images\": [], \"diagrams\": []}\n        \n        # Filter images\n        if asset_type is None or asset_type == \"image\":\n            for url, info in self.cache[\"images\"].items():\n                if category is None or info.get(\"category\") == category:\n                    asset_path = Path(info[\"path\"])\n                    if asset_path.exists():\n                        result[\"images\"].append({\n                            \"url\": url,\n                            \"path\": info[\"path\"],\n                            \"category\": info.get(\"category\"),\n                            \"timestamp\": info.get(\"timestamp\", 0)\n                        })\n        \n        # Filter diagrams\n        if asset_type is None or asset_type == \"diagram\":\n            for content_hash, info in self.cache[\"diagrams\"].items():\n                asset_path = Path(info[\"path\"])\n                if asset_path.exists():\n                    result[\"diagrams\"].append({\n                        \"hash\": content_hash,\n                        \"path\": info[\"path\"],\n                        \"type\": info.get(\"type\"),\n                        \"timestamp\": info.get(\"timestamp\", 0)\n                    })\n        \n        return result\n    \n    def clean_cache(self, remove_unused: bool = False, days: int = 30) -> Tuple[int, int]:\n        \"\"\"Clean the asset cache.\n        \n        Args:\n            remove_unused: Whether to remove unused assets\n            days: Remove assets older than X days\n            \n        Returns:\n            Tuple of (images_removed, diagrams_removed)\n        \"\"\"\n        now = time.time()\n        threshold = now - (days * 86400)  # Convert days to seconds\n        \n        images_removed = 0\n        diagrams_removed = 0\n        \n        # Clean images\n        images_to_remove = []\n        for url, info in self.cache[\"images\"].items():\n            if remove_unused or info.get(\"timestamp\", 0) < threshold:\n                try:\n                    path = Path(info[\"path\"])\n                    if path.exists():\n                        path.unlink()\n                        images_removed += 1\n                    images_to_remove.append(url)\n                except Exception as e:\n                    LOGGER.warning(f\"Error removing image {url}: {e}\")\n        \n        # Remove from cache\n        for url in images_to_remove:\n            del self.cache[\"images\"][url]\n        \n        # Clean diagrams\n        diagrams_to_remove = []\n        for content_hash, info in self.cache[\"diagrams\"].items():\n            if remove_unused or info.get(\"timestamp\", 0) < threshold:\n                try:\n                    path = Path(info[\"path\"])\n                    if path.exists():\n                        path.unlink()\n                        # Also remove SVG if it exists\n                        svg_path = path.with_suffix(\".svg\")\n                        if svg_path.exists():\n                            svg_path.unlink()\n                        diagrams_removed += 1\n                    diagrams_to_remove.append(content_hash)\n                except Exception as e:\n                    LOGGER.warning(f\"Error removing diagram {content_hash}: {e}\")\n        \n        # Remove from cache\n        for content_hash in diagrams_to_remove:\n            del self.cache[\"diagrams\"][content_hash]\n        \n        # Save cache\n        self._save_cache()\n        \n        return images_removed, diagrams_removed\n    \n    def update_json(self, json_path: Path, output_path: Optional[Path] = None) -> int:\n        \"\"\"Update a slides JSON file with cached asset paths.\n        \n        Args:\n            json_path: Path to the JSON file\n            output_path: Optional output path (default: overwrite input)\n            \n        Returns:\n            Number of assets updated\n        \"\"\"\n        try:\n            with open(json_path, 'r') as f:\n                slides_data = json.load(f)\n        except Exception as e:\n            LOGGER.error(f\"Error loading JSON from {json_path}: {e}\")\n            return 0\n        \n        # Check if it's an object with a slides array\n        if isinstance(slides_data, dict) and \"slides\" in slides_data:\n            slides = slides_data[\"slides\"]\n        elif isinstance(slides_data, list):\n            slides = slides_data\n        else:\n            LOGGER.error(f\"Unexpected JSON structure in {json_path}\")\n            return 0\n        \n        assets_updated = 0\n        \n        # Update each slide\n        for slide in slides:\n            # Update image URLs\n            image_url = slide.get(\"image_url\")\n            if image_url and image_url.startswith(\"http\"):\n                try:\n                    # Check if the image is in the cache\n                    if image_url in self.cache[\"images\"]:\n                        cached_path = Path(self.cache[\"images\"][image_url][\"path\"])\n                        if cached_path.exists():\n                            # Use relative path from JSON file to cached image\n                            try:\n                                json_dir = json_path.parent\n                                rel_path = cached_path.relative_to(json_dir)\n                                slide[\"image_url\"] = str(rel_path)\n                                assets_updated += 1\n                                LOGGER.debug(f\"Updated image URL to {rel_path}\")\n                            except ValueError:\n                                # If the cached path is not relative to the JSON file,\n                                # download and cache it in the same directory\n                                new_path = json_dir / \"images\" / cached_path.name\n                                new_path.parent.mkdir(parents=True, exist_ok=True)\n                                shutil.copy2(cached_path, new_path)\n                                rel_path = new_path.relative_to(json_dir)\n                                slide[\"image_url\"] = str(rel_path)\n                                assets_updated += 1\n                                LOGGER.debug(f\"Copied image to {rel_path}\")\n                    else:\n                        # Download and cache the image\n                        img_dir = json_path.parent / \"images\"\n                        img_dir.mkdir(parents=True, exist_ok=True)\n                        img_file = img_dir / f\"img_{hashlib.md5(image_url.encode()).hexdigest()[:10]}.jpg\"\n                        cached_path = self.get_image(image_url, local_path=img_file)\n                        rel_path = cached_path.relative_to(json_path.parent)\n                        slide[\"image_url\"] = str(rel_path)\n                        assets_updated += 1\n                        LOGGER.debug(f\"Downloaded and cached image to {rel_path}\")\n                except Exception as e:\n                    LOGGER.warning(f\"Error updating image URL {image_url}: {e}\")\n            \n            # Cache diagram content\n            diagram_content = slide.get(\"diagram_content\")\n            diagram_type = slide.get(\"diagram_type\")\n            \n            if diagram_content and diagram_type:\n                content_hash = hashlib.md5(diagram_content.encode()).hexdigest()[:10]\n                if content_hash in self.cache[\"diagrams\"]:\n                    # Diagram already in cache, nothing to do\n                    pass\n                else:\n                    # Check if diagram files exist\n                    json_dir = json_path.parent\n                    img_url = slide.get(\"image_url\")\n                    \n                    if img_url and not img_url.startswith(\"http\"):\n                        img_path = json_dir / img_url\n                        if img_path.exists():\n                            # Cache the existing diagram\n                            self.get_diagram(diagram_content, diagram_type, local_path=img_path)\n                            assets_updated += 1\n                            LOGGER.debug(f\"Cached existing diagram from {img_path}\")\n        \n        # Save the updated JSON\n        if output_path:\n            out_path = Path(output_path)\n        else:\n            out_path = json_path\n        \n        try:\n            if isinstance(slides_data, dict) and \"slides\" in slides_data:\n                slides_data[\"slides\"] = slides\n                with open(out_path, 'w') as f:\n                    json.dump(slides_data, f, indent=2)\n            else:\n                with open(out_path, 'w') as f:\n                    json.dump(slides, f, indent=2)\n            \n            LOGGER.info(f\"Updated {assets_updated} assets in {out_path}\")\n        except Exception as e:\n            LOGGER.error(f\"Error saving updated JSON: {e}\")\n        \n        return assets_updated\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level)\n    \n    # Create asset manager\n    cache_dir = Path(args.cache_dir)\n    cache_file = Path(args.cache_file)\n    manager = AssetManager(cache_dir, cache_file)\n    \n    # Execute command\n    if args.command == \"get-image\":\n        local_path = Path(args.local_path) if args.local_path else None\n        path = manager.get_image(args.url, args.category, local_path)\n        print(f\"Image cached at: {path}\")\n    \n    elif args.command == \"get-diagram\":\n        local_path = Path(args.local_path) if args.local_path else None\n        path = manager.get_diagram(args.content, args.type, local_path)\n        if path:\n            print(f\"Diagram cached at: {path}\")\n        else:\n            print(\"Diagram not found in cache and no local path provided\")\n    \n    elif args.command == \"list\":\n        assets = manager.list_assets(args.category, args.type)\n        print(\"\\nImages:\")\n        for img in assets[\"images\"]:\n            print(f\"  - {img['url']} -> {img['path']}\")\n        \n        print(\"\\nDiagrams:\")\n        for diag in assets[\"diagrams\"]:\n            print(f\"  - {diag['hash']} ({diag['type']}) -> {diag['path']}\")\n    \n    elif args.command == \"clean\":\n        images, diagrams = manager.clean_cache(args.remove_unused, args.days)\n        print(f\"Removed {images} images and {diagrams} diagrams from cache\")\n    \n    elif args.command == \"update-json\":\n        json_path = Path(args.json_file)\n        output_path = Path(args.output) if args.output else None\n        assets_updated = manager.update_json(json_path, output_path)\n        print(f\"Updated {assets_updated} assets in {json_path}\")\n    \n    else:\n        print(\"No command specified. Use --help for usage information.\")\n\nif __name__ == \"__main__\":\n    main()\n",
              "language": "python",
              "version_uuid": "d0c45a93-06e1-4dd9-bb8c-a93a22482ae0"
            },
            "message": "artifacts",
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "4cf7a1ed-6928-4761-8b1e-c71c461e269b"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-05-20T11:41:49.189332Z",
            "stop_timestamp": "2025-05-20T11:41:49.684715Z",
            "flags": null,
            "type": "text",
            "text": "\n\n### 3. Fix Layout Rendering in Markdown Generation\n\nLet's fix the `json_to_markdown.py` script to properly handle different layouts:",
            "citations": []
          },
          {
            "start_timestamp": "2025-05-20T11:41:49.873325Z",
            "stop_timestamp": "2025-05-20T11:42:39.380092Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "json-to-markdown-fix",
              "type": "application/vnd.ant.code",
              "title": "json_to_markdown.py (Improved)",
              "command": "create",
              "content": "#!/usr/bin/env python3\n\"\"\"Convert slides.json to md2gslides compatible markdown files.\n\nThis script converts JSON slide data to markdown format compatible with md2gslides,\nallowing for generation of Google Slides presentations with proper layouts.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, re\nfrom pathlib import Path\nfrom typing import Dict, List, Any, Optional\n\nLOGGER = logging.getLogger(\"json_to_markdown\")\n\n# Map of slide layouts to md2gslides format templates\nLAYOUT_TEMPLATES = {\n    \"TITLE\": {\n        \"template\": \"\"\"# {title}\n\n{subtitle}\n\"\"\",\n        \"fields\": [\"title\", \"subtitle\"]\n    },\n    \"TITLE_AND_BODY\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"TITLE_AND_TWO_COLUMNS\": {\n        \"template\": \"\"\"# {title}\n\n{left_column}\n\n{{.column}}\n\n{right_column}\n\"\"\",\n        \"fields\": [\"title\", \"left_column\", \"right_column\"]\n    },\n    \"MAIN_POINT\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\"\"\",\n        \"fields\": [\"title\"]\n    },\n    \"SECTION_HEADER\": {\n        \"template\": \"\"\"# {title} {{.section}}\n\"\"\",\n        \"fields\": [\"title\"]\n    },\n    \"BIG_NUMBER\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"CAPTION\": {\n        \"template\": \"\"\"# {title}\n\n![]({image_url})\n\"\"\",\n        \"fields\": [\"title\", \"image_url\"]\n    },\n    \"BLANK\": {\n        \"template\": \"\"\"# {title}\n\n![]({image_url}){{.background}}\n\"\"\",\n        \"fields\": [\"title\", \"image_url\"]\n    },\n    # Add mappings for custom layouts\n    \"title\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"section\": {\n        \"template\": \"\"\"# {title} {{.section}}\n\"\"\",\n        \"fields\": [\"title\"]\n    },\n    \"content\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"columns\": {\n        \"template\": \"\"\"# {title}\n\n{left_column}\n\n{{.column}}\n\n{right_column}\n\"\"\",\n        \"fields\": [\"title\", \"left_column\", \"right_column\"]\n    },\n    \"activity\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"main_point\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\"\"\",\n        \"fields\": [\"title\"]\n    },\n    \"big_number\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"logistics\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"break\": {\n        \"template\": \"\"\"# {title}\n\n![]({image_url})\n\"\"\",\n        \"fields\": [\"title\", \"image_url\"]\n    },\n    \"closing\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"DEFAULT\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    }\n}\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Convert slides.json to md2gslides markdown\")\n    p.add_argument(\"json\", help=\"slides.json file or directory of JSON files\")\n    p.add_argument(\"--output-dir\", default=None, help=\"Output directory for markdown files\")\n    p.add_argument(\"--prefer-svg\", action=\"store_true\", help=\"Prefer SVG over PNG for diagrams\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    p.add_argument(\"--debug\", action=\"store_true\", help=\"Print additional debug info about layouts\")\n    p.add_argument(\"--force-layouts\", action=\"store_true\", help=\"Force strict layout adherence\")\n    return p.parse_args()\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\ndef split_content_into_columns(content: str) -> tuple[str, str]:\n    \"\"\"Split content into two columns based on content length or bullet points.\"\"\"\n    if not content:\n        return \"\", \"\"\n    \n    # Check if there are bullet points\n    if re.search(r'^\\s*[-*]\\s+', content, re.MULTILINE):\n        lines = content.split('\\n')\n        bullet_indices = [i for i, line in enumerate(lines) if re.match(r'^\\s*[-*]\\s+', line)]\n        \n        if bullet_indices:\n            # Find the middle bullet point\n            midpoint_idx = len(bullet_indices) // 2\n            midpoint = bullet_indices[midpoint_idx]\n            \n            # Split at this bullet point\n            left_column = '\\n'.join(lines[:midpoint])\n            right_column = '\\n'.join(lines[midpoint:])\n            return left_column, right_column\n    \n    # Default to simple splitting\n    lines = content.split('\\n')\n    midpoint = len(lines) // 2\n    left_column = '\\n'.join(lines[:midpoint])\n    right_column = '\\n'.join(lines[midpoint:])\n    \n    return left_column, right_column\n\ndef format_svg_block(svg_path: Path) -> str:\n    \"\"\"Format an SVG file as a markdown SVG block.\"\"\"\n    try:\n        svg_content = svg_path.read_text(encoding='utf-8')\n        return f\"\\n$$$ svg\\n{svg_content}\\n$$$\\n\"\n    except Exception as e:\n        LOGGER.warning(f\"Failed to read SVG file {svg_path}: {e}\")\n        return f\"![]({svg_path})\"\n\ndef format_slide(slide: Dict[str, Any], prefer_svg: bool = False, debug: bool = False) -> str:\n    \"\"\"Format a single slide as markdown based on its layout.\"\"\"\n    # Extract slide data\n    layout = slide.get(\"layout\", \"DEFAULT\")\n    \n    if debug:\n        LOGGER.debug(f\"Processing slide {slide.get('slide_number', '?')} with layout: {layout}\")\n        LOGGER.debug(f\"Available layouts: {list(LAYOUT_TEMPLATES.keys())}\")\n    \n    # Get layout template\n    template_info = LAYOUT_TEMPLATES.get(layout, LAYOUT_TEMPLATES[\"DEFAULT\"])\n    if layout not in LAYOUT_TEMPLATES:\n        LOGGER.warning(f\"Unknown layout '{layout}' for slide {slide.get('slide_number', '?')}, using default\")\n    \n    template = template_info[\"template\"]\n    \n    # Create content with proper line breaks for bullets\n    content = slide.get(\"content\", \"\")\n    if content:\n        # Ensure bullet points have proper formatting\n        content = re.sub(r'^\\s*[-*]\\s+', '* ', content, flags=re.MULTILINE)\n        # Ensure proper line breaks\n        content = re.sub(r'([.!?])\\s+', r'\\1\\n', content)\n    \n    # Handle image URL\n    image_url = slide.get(\"image_url\", \"\")\n    if image_url:\n        # Check if there's an SVG version of the image\n        if prefer_svg and image_url.lower().endswith('.png'):\n            svg_path = image_url[:-4] + '.svg'\n            svg_path_obj = Path(svg_path)\n            if svg_path_obj.exists():\n                # Use SVG block instead of image reference\n                image_block = format_svg_block(svg_path_obj)\n            else:\n                image_block = f\"![]({image_url})\"\n        else:\n            image_block = f\"![]({image_url})\"\n    else:\n        image_block = \"\"\n    \n    # Create data dict for template\n    data = {\n        \"title\": slide.get(\"title\", \"\"),\n        \"subtitle\": slide.get(\"subtitle\", \"\"),\n        \"content\": content,\n        \"image_url\": image_url,\n        \"image_block\": image_block\n    }\n    \n    # For two column layouts, split content and handle images\n    if layout in [\"TITLE_AND_TWO_COLUMNS\", \"columns\"]:\n        left, right = split_content_into_columns(data[\"content\"])\n        data[\"left_column\"] = left\n        \n        # If there's an image, use it for the right column\n        if image_url:\n            if prefer_svg and image_url.lower().endswith('.png'):\n                svg_path = image_url[:-4] + '.svg'\n                svg_path_obj = Path(svg_path)\n                if svg_path_obj.exists():\n                    # Use SVG block instead of image reference\n                    data[\"right_column\"] = format_svg_block(svg_path_obj)\n                else:\n                    data[\"right_column\"] = f\"![]({image_url})\"\n            else:\n                data[\"right_column\"] = f\"![]({image_url})\"\n        else:\n            data[\"right_column\"] = right\n    \n    # Add speaker notes if available\n    notes = slide.get(\"facilitator_notes\", \"\")\n    notes_section = f\"\\n\\n<!--\\n{notes}\\n-->\" if notes else \"\"\n    \n    # Format markdown\n    try:\n        md = template.format(**{k: v for k, v in data.items() if k in template_info[\"fields\"]})\n        return f\"---\\n\\n{md}{notes_section}\\n\"\n    except KeyError as e:\n        LOGGER.warning(f\"Missing field {e} for layout {layout}, using default\")\n        return f\"---\\n\\n# {data['title']}\\n\\n{data['content']}{notes_section}\\n\"\n\ndef extract_slides_from_json(json_data: Any) -> List[Dict[str, Any]]:\n    \"\"\"Extract slides array from JSON data, handling different formats.\"\"\"\n    if isinstance(json_data, list):\n        # Already a list of slides\n        return json_data\n    elif isinstance(json_data, dict) and \"slides\" in json_data:\n        # Object with a slides key\n        return json_data[\"slides\"]\n    else:\n        LOGGER.warning(\"Unknown JSON structure, attempting to find slides array\")\n        # Try to find any array in the JSON\n        for key, value in json_data.items() if isinstance(json_data, dict) else []:\n            if isinstance(value, list) and len(value) > 0 and isinstance(value[0], dict):\n                LOGGER.info(f\"Found slides array under key '{key}'\")\n                return value\n        \n        raise ValueError(\"Could not find a slides array in the JSON data\")\n\ndef convert_json_to_markdown(json_path: Path, output_dir: Optional[Path] = None, \n                           prefer_svg: bool = False, debug: bool = False) -> Path:\n    \"\"\"Convert a single JSON file to markdown.\"\"\"\n    LOGGER.info(\"Converting %s to markdown\", json_path)\n    \n    # Load JSON data\n    try:\n        json_data = json.loads(json_path.read_text(encoding='utf-8'))\n        slides = extract_slides_from_json(json_data)\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON in %s: %s\", json_path, e)\n        raise\n    except ValueError as e:\n        LOGGER.error(\"%s\", e)\n        raise\n    \n    if debug:\n        LOGGER.debug(f\"Found {len(slides)} slides\")\n        layouts = {}\n        for slide in slides:\n            layout = slide.get(\"layout\", \"DEFAULT\")\n            layouts[layout] = layouts.get(layout, 0) + 1\n        LOGGER.debug(f\"Layout distribution: {layouts}\")\n    \n    # Create markdown\n    md_content = []\n    for i, slide in enumerate(slides):\n        try:\n            slide_md = format_slide(slide, prefer_svg, debug)\n            md_content.append(slide_md)\n        except Exception as e:\n            LOGGER.error(f\"Error formatting slide {i+1}: {e}\")\n            # Create simple fallback slide\n            title = slide.get(\"title\", f\"Slide {i+1}\")\n            content = slide.get(\"content\", \"\")\n            md_content.append(f\"---\\n\\n# {title}\\n\\n{content}\\n\")\n    \n    # Join with newlines\n    markdown = \"\\n\".join(md_content)\n    \n    # Determine output path\n    if output_dir:\n        output_path = output_dir / f\"slides_{json_path.stem.replace('slides_', '')}.md\"\n    else:\n        output_path = json_path.with_name(f\"slides_{json_path.stem.replace('slides_', '')}.md\")\n    \n    # Write markdown file\n    output_path.write_text(markdown, encoding='utf-8')\n    LOGGER.info(\"Wrote markdown to %s\", output_path)\n    \n    return output_path\n\ndef process_directory(json_dir: Path, output_dir: Optional[Path] = None, \n                    prefer_svg: bool = False, debug: bool = False) -> List[Path]:\n    \"\"\"Process all JSON files in a directory.\"\"\"\n    LOGGER.info(\"Processing all JSON files in %s\", json_dir)\n    \n    # Find all JSON files\n    json_files = list(json_dir.glob(\"slides_*.json\"))\n    if not json_files:\n        # Try without slides_ prefix\n        json_files = list(json_dir.glob(\"*.json\"))\n        if not json_files:\n            LOGGER.error(\"No slide JSON files found in %s\", json_dir)\n            return []\n    \n    LOGGER.info(\"Found %d JSON files to process\", len(json_files))\n    \n    # Process each file\n    results = []\n    for json_path in json_files:\n        try:\n            md_path = convert_json_to_markdown(json_path, output_dir, prefer_svg, debug)\n            results.append(md_path)\n        except Exception as e:\n            LOGGER.error(\"Failed to convert %s: %s\", json_path, e, exc_info=True)\n    \n    return results\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    if output_dir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Process files\n    try:\n        if json_path.is_dir():\n            md_files = process_directory(json_path, output_dir, args.prefer_svg, args.debug)\n            if md_files:\n                LOGGER.info(\"Converted %d JSON files to markdown\", len(md_files))\n            else:\n                LOGGER.warning(\"No markdown files were generated\")\n                sys.exit(1)\n        else:\n            convert_json_to_markdown(json_path, output_dir, args.prefer_svg, args.debug)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n",
              "language": "python",
              "version_uuid": "28d9a413-329e-44f4-9b49-477065eaaad1"
            },
            "message": "artifacts",
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "19aaa0f8-19c0-4540-988a-e199e645b0c3"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-05-20T11:42:41.486745Z",
            "stop_timestamp": "2025-05-20T11:42:42.561517Z",
            "flags": null,
            "type": "text",
            "text": "\n\n### 4. Improve Diagram Generation with Deduplication\n\nLet's modify the diagrams_to_images.py script to use our new asset management system:",
            "citations": []
          },
          {
            "start_timestamp": "2025-05-20T11:42:42.919649Z",
            "stop_timestamp": "2025-05-20T11:44:34.169589Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "diagrams-to-images-fix",
              "type": "application/vnd.ant.code",
              "title": "diagrams_to_images.py (Improved)",
              "command": "create",
              "content": "#!/usr/bin/env python3\n\"\"\"Render Mermaid diagrams to local image files with asset caching.\n\nSaves diagrams locally and updates the slides.json with relative file paths.\nUses the asset manager to avoid duplicating diagrams.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, subprocess, sys, time, hashlib\nfrom pathlib import Path\nfrom typing import Any, List, Optional, Tuple\nimport tempfile\nimport anthropic\nimport re\nimport shutil\n\nLOGGER = logging.getLogger(\"diagrams_to_images\")\nMERMAID_CMD = \"mmdc\"  # must be on PATH\n\n# Import asset manager\ntry:\n    from asset_manager import AssetManager\n    ASSET_MANAGER_AVAILABLE = True\nexcept ImportError:\n    LOGGER.warning(\"Asset manager not available. Diagrams will not be cached.\")\n    ASSET_MANAGER_AVAILABLE = False\n\n# Common diagram type mappings for fallbacks\nDIAGRAM_FALLBACKS = {\n    \"flowchart\": [\"flowchart TD\", \"flowchart LR\", \"flowchart RL\", \"mindmap\"],\n    \"mindmap\": [\"flowchart TD\", \"flowchart LR\", \"classDiagram\"],\n    \"pie\": [\"pie\", \"flowchart TD\"],\n    \"quadrantChart\": [\"quadrantChart\", \"flowchart\", \"classDiagram\"],\n    \"classDiagram\": [\"classDiagram\", \"flowchart TD\", \"mindmap\"],\n    \"timeline\": [\"timeline\", \"flowchart TD\"]\n}\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Render Mermaid diagrams to local files\")\n    p.add_argument(\"json\", help=\"slides.json to update (in-place) or directory of JSON files\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    p.add_argument(\"--output-dir\", default=None, help=\"Directory to save image files (default: same as slides.json)\")\n    p.add_argument(\"--mermaid-config\", default=\"mermaid-config.json\", help=\"Mermaid configuration file\")\n    p.add_argument(\"--model\", default=\"claude-3-7-sonnet-20250219\", help=\"Claude model to use for fixing diagrams\")\n    p.add_argument(\"--preserve-all\", action=\"store_true\", help=\"Keep all generated images, don't overwrite\")\n    p.add_argument(\"--use-asset-manager\", action=\"store_true\", help=\"Use asset manager for caching\")\n    p.add_argument(\"--assets-dir\", default=None, help=\"Directory for asset manager cache\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef is_valid_mermaid_syntax(src: str) -> bool:\n    \"\"\"Check if the diagram content has valid Mermaid syntax structure.\"\"\"\n    # Valid Mermaid diagrams usually start with a diagram type followed by direction\n    # e.g., \"flowchart TD\", \"mindmap\", \"classDiagram\", etc.\n    pattern = r'^(flowchart|mindmap|classDiagram|pie|quadrantChart|timeline|sequenceDiagram|stateDiagram-v2|gantt|journey|gitGraph)\\s*([A-Z]{2})?'\n    if re.match(pattern, src.strip()):\n        return True\n    \n    # Check if it contains any Mermaid-specific syntax\n    mermaid_syntax = ['-->', '-.->', '===>', '-->|', '-.->|', '==>|', '---|', '-.-|', '===|']\n    return any(token in src for token in mermaid_syntax)\n\n\ndef convert_text_to_mermaid(text: str, diagram_type: str) -> str:\n    \"\"\"Convert plain text to a proper Mermaid diagram syntax.\"\"\"\n    # Split on arrows, commas, periods, or other separators\n    steps = []\n    \n    # Check for arrow separators first\n    if 'â†’' in text or '->' in text or ',' in text:\n        # Split by arrows or commas\n        separators = ['â†’', '->', ',']\n        for sep in separators:\n            if sep in text:\n                steps = [step.strip() for step in text.split(sep)]\n                break\n    else:\n        # Split on periods or just use as single step\n        if '.' in text:\n            steps = [step.strip() for step in text.split('.') if step.strip()]\n        else:\n            steps = [text.strip()]\n    \n    # Generate appropriate Mermaid syntax based on the diagram type\n    if diagram_type.lower() == \"flowchart\":\n        result = \"flowchart TD\\n\"\n        for i, step in enumerate(steps):\n            node_id = chr(65 + i)  # A, B, C, ...\n            result += f\"    {node_id}[\\\"{step}\\\"]\\n\"\n        \n        # Add connections\n        for i in range(len(steps) - 1):\n            node1 = chr(65 + i)\n            node2 = chr(65 + i + 1)\n            result += f\"    {node1} --> {node2}\\n\"\n            \n    elif diagram_type.lower() == \"mindmap\":\n        result = \"mindmap\\n\"\n        result += f\"    root(({steps[0]}))\\n\"\n        \n        for i, step in enumerate(steps[1:], 1):\n            result += f\"        {step}\\n\"\n            \n    elif diagram_type.lower() == \"timeline\":\n        result = \"timeline\\n\"\n        result += \"    title Process Timeline\\n\"\n        \n        for step in steps:\n            result += f\"    section {step}\\n\"\n            \n    else:\n        # Default to flowchart if unsure\n        result = \"flowchart TD\\n\"\n        for i, step in enumerate(steps):\n            node_id = chr(65 + i)\n            result += f\"    {node_id}[\\\"{step}\\\"]\\n\"\n        \n        # Add connections\n        for i in range(len(steps) - 1):\n            node1 = chr(65 + i)\n            node2 = chr(65 + i + 1)\n            result += f\"    {node1} --> {node2}\\n\"\n    \n    return result\n\n\ndef fix_mermaid_with_claude(src: str, error_msg: str, client: anthropic.Anthropic, model: str) -> str:\n    \"\"\"Use Claude to fix Mermaid syntax errors.\"\"\"\n    prompt = f\"\"\"You are a Mermaid diagram expert. Fix the following Mermaid diagram that has syntax errors.\n\nError message:\n{error_msg}\n\nCurrent diagram:\n```\n{src}\n```\n\nPlease provide ONLY the fixed diagram code with no explanation or markdown formatting - just return the raw fixed Mermaid syntax.\nFollow these guidelines:\n- Ensure proper spacing in syntax (e.g., \"A --> B\")\n- No extra spaces inside node brackets (use \"[Label]\", not \"[ Label ]\")\n- Use capital letters for directions (TD, LR, BT, RL)\n- Keep diagrams simple with 15 or fewer nodes\n- Start with diagram type and direction (e.g., \"flowchart TD\")\n- ONLY use standard Mermaid types: flowchart, mindmap, pie, classDiagram, etc.\n- Do NOT create custom types like \"illustration\" or non-standard formats\n\"\"\"\n\n    try:\n        response = client.messages.create(\n            model=model,\n            max_tokens=1024,\n            temperature=0.0,\n            system=\"You are a diagram syntax expert who returns only fixed mermaid syntax - no explanations.\",\n            messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        fixed_src = response.content[0].text.strip()\n        \n        # Check if the response includes markdown formatting and remove it\n        if fixed_src.startswith(\"```\") and fixed_src.endswith(\"```\"):\n            fixed_src = fixed_src[3:-3].strip()\n            if fixed_src.startswith(\"mermaid\\n\"):\n                fixed_src = fixed_src[8:].strip()\n        \n        LOGGER.info(\"Claude fixed the Mermaid syntax issues\")\n        return fixed_src\n    except Exception as e:\n        LOGGER.error(\"Error using Claude to fix Mermaid: %s\", e)\n        return src  # Return original if Claude fails\n\n\ndef convert_plain_text_to_mermaid_with_claude(text: str, diagram_type: str, client: anthropic.Anthropic, model: str) -> str:\n    \"\"\"Use Claude to convert plain text to a proper Mermaid diagram.\"\"\"\n    prompt = f\"\"\"You are a Mermaid diagram expert. Convert this plain text description into a proper Mermaid diagram of type \"{diagram_type}\".\n\nPlain text:\n{text}\n\nPlease provide ONLY the Mermaid diagram code with no explanation or markdown formatting - just return the raw Mermaid syntax.\nFollow these guidelines:\n- Format as a proper {diagram_type} diagram\n- Start with diagram type (e.g., \"flowchart TD\" or \"mindmap\")\n- Keep it simple with max 15 nodes\n- Use proper Mermaid syntax with correct spacing\n- Make it visually clear and easy to understand\n- ONLY use standard Mermaid types (flowchart, mindmap, pie, classDiagram)\n- DO NOT create custom types like \"illustration\" or non-standard formats\n\"\"\"\n\n    try:\n        response = client.messages.create(\n            model=model,\n            max_tokens=1024,\n            temperature=0.0,\n            system=\"You are a diagram syntax expert who returns only Mermaid syntax - no explanations.\",\n            messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        converted_src = response.content[0].text.strip()\n        \n        # Check if the response includes markdown formatting and remove it\n        if converted_src.startswith(\"```\") and converted_src.endswith(\"```\"):\n            converted_src = converted_src[3:-3].strip()\n            if converted_src.startswith(\"mermaid\\n\"):\n                converted_src = converted_src[8:].strip()\n        \n        LOGGER.info(\"Claude converted plain text to Mermaid diagram\")\n        return converted_src\n    except Exception as e:\n        LOGGER.error(\"Error using Claude to convert text to Mermaid: %s\", e)\n        # Fallback to simple conversion\n        return convert_text_to_mermaid(text, diagram_type)\n\n\ndef suggest_alternative_diagram(src: str, diagram_type: str, client: anthropic.Anthropic, model: str) -> Tuple[str, str]:\n    \"\"\"Use Claude to suggest an alternative diagram type for the same content.\"\"\"\n    prompt = f\"\"\"You are a Mermaid diagram expert. This diagram of type \"{diagram_type}\" is failing to render. \nConvert it to a simpler alternative diagram type that conveys the same information.\n\nOriginal diagram:\n```\n{src}\n```\n\nPlease provide ONLY the converted diagram code with no explanation or markdown formatting.\nGood alternatives could be:\n- flowchart TD (top-down flowchart, the most reliable format)\n- flowchart LR (left-right flowchart)\n- classDiagram (for hierarchies, very reliable)\n- mindmap (for conceptual relationships)\n\nFocus on simplicity and reliability. Remove any fancy styling or complex features.\nONLY use standard Mermaid types (flowchart, mindmap, pie, classDiagram).\nDO NOT create custom types like \"illustration\" or non-standard formats.\n\"\"\"\n\n    try:\n        response = client.messages.create(\n            model=model,\n            max_tokens=1024,\n            temperature=0.0,\n            system=\"You are a diagram expert who returns only converted mermaid syntax - no explanations.\",\n            messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        converted_src = response.content[0].text.strip()\n        \n        # Check if the response includes markdown formatting and remove it\n        if converted_src.startswith(\"```\") and converted_src.endswith(\"```\"):\n            converted_src = converted_src[3:-3].strip()\n            if converted_src.startswith(\"mermaid\\n\"):\n                converted_src = converted_src[8:].strip()\n        \n        # Detect the new diagram type\n        new_type = converted_src.split(\" \")[0] if \" \" in converted_src else diagram_type\n        LOGGER.info(f\"Claude converted diagram from {diagram_type} to {new_type}\")\n        return converted_src, new_type\n    except Exception as e:\n        LOGGER.error(\"Error using Claude to convert diagram: %s\", e)\n        \n        # Fallback to a simpler diagram type without Claude\n        if diagram_type in DIAGRAM_FALLBACKS and len(DIAGRAM_FALLBACKS[diagram_type]) > 0:\n            new_type = DIAGRAM_FALLBACKS[diagram_type][0].split(\" \")[0]\n            LOGGER.info(f\"Falling back to {new_type} diagram type\")\n            return src.replace(diagram_type, DIAGRAM_FALLBACKS[diagram_type][0], 1), new_type\n        return src, diagram_type\n\n\ndef render_mermaid(\n    src: str, \n    output_dir: Path, \n    config_path: Optional[Path], \n    base_filename: str, \n    slide_num: int, \n    diagram_type: str, \n    client: Optional[anthropic.Anthropic] = None, \n    model: str = \"\", \n    preserve_all: bool = False,\n    asset_manager: Optional[Any] = None\n) -> Path:\n    \"\"\"Render mermaid diagram to PNG with auto-fixing and asset caching.\n    \n    Args:\n        src: Mermaid diagram content\n        output_dir: Directory to save files\n        config_path: Path to mermaid config file\n        base_filename: Base filename (from guide file)\n        slide_num: Slide number\n        diagram_type: The type of diagram (flowchart, mindmap, etc.)\n        client: Anthropic client for Claude API\n        model: Claude model to use\n        preserve_all: Keep all generated versions with unique names\n        asset_manager: Optional asset manager for caching\n        \n    Returns:\n        Path to the generated PNG file\n    \"\"\"\n    # Create content hash for uniqueness\n    content_hash = hashlib.md5(src.encode()).hexdigest()[:8]\n    \n    # First, check if the diagram is already in the asset manager cache\n    if asset_manager:\n        # Try to get the diagram from asset manager\n        cached_diagram = asset_manager.get_diagram(src, diagram_type)\n        if cached_diagram:\n            LOGGER.info(f\"Using cached diagram for slide {slide_num} from asset manager\")\n            \n            # Create local copy in the output directory\n            local_filename = f\"{base_filename}_slide{slide_num}\"\n            local_png = output_dir / f\"{local_filename}.png\"\n            local_svg = output_dir / f\"{local_filename}.svg\"\n            \n            # Copy PNG\n            shutil.copy2(cached_diagram, local_png)\n            \n            # Copy SVG if it exists\n            cached_svg = cached_diagram.with_suffix(\".svg\")\n            if cached_svg.exists():\n                shutil.copy2(cached_svg, local_svg)\n            \n            return local_png\n    \n    # Create filenames based on guide name, slide number, and content hash\n    if preserve_all:\n        # Include hash in filename to prevent overwriting\n        output_name = f\"{base_filename}_slide{slide_num}_{content_hash}\"\n    else:\n        output_name = f\"{base_filename}_slide{slide_num}\"\n    \n    mmd = output_dir / f\"{output_name}.mmd\"\n    png = output_dir / f\"{output_name}.png\"\n    \n    # Also create SVG version\n    svg = output_dir / f\"{output_name}.svg\"\n    \n    # Check if files already exist - if so, return them directly\n    if png.exists() and png.stat().st_size > 0:\n        LOGGER.info(f\"Diagram files already exist for slide {slide_num}, reusing them\")\n        return png\n    \n    # Check if the source is valid Mermaid syntax, if not convert it\n    if not is_valid_mermaid_syntax(src):\n        LOGGER.info(f\"Slide {slide_num}: Content doesn't appear to be valid Mermaid syntax. Converting...\")\n        if client:\n            # Use Claude to convert plain text to Mermaid\n            src = convert_plain_text_to_mermaid_with_claude(src, diagram_type, client, model)\n        else:\n            # Use simple rule-based conversion\n            src = convert_text_to_mermaid(src, diagram_type)\n        \n        LOGGER.debug(f\"Converted to Mermaid syntax:\\n{src}\")\n    \n    # Write mermaid content to file\n    mmd.write_text(src, encoding=\"utf-8\")\n    \n    # Build command with optional config\n    cmd = [MERMAID_CMD, \"-i\", str(mmd), \"-o\", str(png)]\n    if config_path and config_path.exists():\n        cmd.extend([\"-c\", str(config_path)])\n    \n    # Also generate SVG with another command\n    svg_cmd = [MERMAID_CMD, \"-i\", str(mmd), \"-o\", str(svg)]\n    if config_path and config_path.exists():\n        svg_cmd.extend([\"-c\", str(config_path)])\n    \n    LOGGER.debug(\"Running command: %s\", \" \".join(str(x) for x in cmd))\n    \n    # Try with original diagram\n    last_error = \"\"\n    current_src = src\n    current_type = diagram_type\n    \n    # Execute command with retry and auto-fixing\n    for attempt in range(3):\n        # Create version-specific files for each attempt if preserving all\n        if preserve_all and attempt > 0:\n            attempt_output = f\"{output_name}_attempt{attempt}\"\n            attempt_mmd = output_dir / f\"{attempt_output}.mmd\"\n            attempt_png = output_dir / f\"{attempt_output}.png\"\n            attempt_svg = output_dir / f\"{attempt_output}.svg\"\n            \n            # Write the current source to this attempt's file\n            attempt_mmd.write_text(current_src, encoding=\"utf-8\")\n            \n            # Update commands for this attempt\n            cmd = [MERMAID_CMD, \"-i\", str(attempt_mmd), \"-o\", str(attempt_png)]\n            svg_cmd = [MERMAID_CMD, \"-i\", str(attempt_mmd), \"-o\", str(attempt_svg)]\n            \n            if config_path and config_path.exists():\n                cmd.extend([\"-c\", str(config_path)])\n                svg_cmd.extend([\"-c\", str(config_path)])\n        else:\n            # Just use the original files for new attempts\n            attempt_png = png\n            attempt_svg = svg\n        \n        try:\n            LOGGER.debug(f\"Running command: {' '.join(str(x) for x in cmd)}\")\n            result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n            \n            if attempt_png.exists() and attempt_png.stat().st_size > 0:\n                # PNG generated successfully, try SVG too\n                try:\n                    LOGGER.debug(f\"Running SVG command: {' '.join(str(x) for x in svg_cmd)}\")\n                    svg_result = subprocess.run(svg_cmd, check=True, capture_output=True, text=True)\n                except Exception as e:\n                    LOGGER.warning(f\"SVG generation failed but PNG succeeded: {e}\")\n                \n                # If we're preserving all and this isn't the first attempt,\n                # copy the successful files to the original names\n                if preserve_all and attempt > 0:\n                    shutil.copy2(attempt_png, png)\n                    if attempt_svg.exists():\n                        shutil.copy2(attempt_svg, svg)\n                \n                # Cache the diagram in the asset manager if available\n                if asset_manager:\n                    asset_manager.get_diagram(src, diagram_type, local_path=png)\n                \n                # Return the original path regardless\n                LOGGER.info(f\"Successfully rendered diagram on attempt {attempt+1}\")\n                return png\n            \n            last_error = \"Empty output file\"\n            \n        except subprocess.CalledProcessError as e:\n            last_error = e.stderr if hasattr(e, 'stderr') else str(e)\n            LOGGER.warning(\"mermaid-cli error (attempt %d/3): %s\", attempt + 1, last_error)\n        \n        # If we get here, the diagram failed to render\n        if attempt == 0 and client:\n            # First failure: try to fix syntax with Claude\n            LOGGER.info(\"Attempting to fix diagram syntax with Claude\")\n            fixed_src = fix_mermaid_with_claude(current_src, last_error, client, model)\n            mmd.write_text(fixed_src, encoding=\"utf-8\")\n            current_src = fixed_src\n            time.sleep(1)\n            \n        elif attempt == 1 and client:\n            # Second failure: try converting to a different diagram type\n            LOGGER.info(\"Attempting to convert diagram type with Claude\")\n            converted_src, new_type = suggest_alternative_diagram(current_src, current_type, client, model)\n            mmd.write_text(converted_src, encoding=\"utf-8\")\n            current_src = converted_src\n            current_type = new_type\n            time.sleep(1)\n        else:\n            time.sleep(2)  # Just wait and retry with the same content\n    \n    # If we got here, all attempts failed - create a simple fallback diagram without using mermaid\n    LOGGER.error(f\"Failed to render mermaid diagram after 3 attempts for slide {slide_num}\")\n    \n    try:\n        # Create a basic image with text using PIL instead of Mermaid\n        try:\n            from PIL import Image, ImageDraw, ImageFont\n            \n            # Create a blank image\n            img = Image.new('RGB', (800, 400), color=(255, 255, 255))\n            d = ImageDraw.Draw(img)\n            \n            # Try to use a default font\n            try:\n                font = ImageFont.truetype(\"Arial\", 20)\n            except IOError:\n                font = ImageFont.load_default()\n            \n            # Add error text\n            d.text((50, 50), f\"Failed to render diagram for slide {slide_num}\", fill=(0, 0, 0), font=font)\n            d.text((50, 100), f\"Original diagram type: {diagram_type}\", fill=(0, 0, 0), font=font)\n            d.text((50, 150), \"Please simplify or check syntax\", fill=(0, 0, 0), font=font)\n            \n            # Save the image\n            img.save(png)\n            LOGGER.info(f\"Created fallback image with PIL for slide {slide_num}\")\n            return png\n            \n        except ImportError:\n            # If PIL is not available, create an empty file\n            with open(png, 'wb') as f:\n                f.write(b'')\n            LOGGER.info(f\"Created empty fallback image for slide {slide_num}\")\n            return png\n    except Exception as e:\n        LOGGER.error(f\"Failed to create fallback image: {e}\")\n    \n    # If absolutely everything fails, create an empty file\n    with open(png, 'wb') as f:\n        f.write(b'')\n    \n    return png\n\n\ndef get_base_filename(json_path: Path) -> str:\n    \"\"\"Extract base filename (without extension) from path.\"\"\"\n    return json_path.stem.replace('slides_', '')  # Remove 'slides_' prefix if present\n\n\ndef process_json_file(\n    json_path: Path, \n    output_dir: Optional[Path], \n    config_path: Optional[Path], \n    client: Optional[anthropic.Anthropic] = None, \n    model: str = \"\", \n    preserve_all: bool = False,\n    asset_manager: Optional[Any] = None\n) -> int:\n    \"\"\"Process a single JSON file and render diagrams.\n    \n    Returns:\n        Number of diagrams processed\n    \"\"\"\n    LOGGER.info(\"Processing JSON file: %s\", json_path)\n    \n    # Load JSON data\n    try:\n        with open(json_path, 'r', encoding='utf-8') as f:\n            json_content = f.read()\n        \n        try:\n            slides_data = json.loads(json_content)\n            \n            # Check if it's an object with a slides array\n            if isinstance(slides_data, dict) and \"slides\" in slides_data:\n                slides = slides_data[\"slides\"]\n            elif isinstance(slides_data, list):\n                slides = slides_data\n            else:\n                LOGGER.error(\"Unexpected JSON structure: expected a slides array or an object with a slides key\")\n                return 0\n                \n        except json.JSONDecodeError as e:\n            LOGGER.error(\"Invalid JSON in %s: %s\", json_path, e)\n            return 0\n            \n    except Exception as e:\n        LOGGER.error(\"Failed to read %s: %s\", json_path, e)\n        return 0\n    \n    # Extract base filename\n    base_filename = get_base_filename(json_path)\n    \n    # Determine output directory\n    if output_dir:\n        diagram_dir = output_dir\n    else:\n        diagram_dir = json_path.parent / \"images\"\n    \n    # Create output directory if it doesn't exist\n    diagram_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Track already processed diagrams to avoid duplicates\n    processed = {}\n    \n    # Process all slides\n    changed = 0\n    for slide in slides:\n        if slide.get(\"diagram_type\") and slide.get(\"diagram_content\"):\n            try:\n                slide_num = slide.get(\"slide_number\", 0)\n                diagram_content = slide.get(\"diagram_content\", \"\")\n                \n                # Skip if this exact content has already been processed\n                content_hash = hashlib.md5(diagram_content.encode()).hexdigest()\n                if content_hash in processed:\n                    LOGGER.info(f\"Slide {slide_num}: Using previously generated diagram\")\n                    slide[\"image_url\"] = processed[content_hash]\n                    changed += 1\n                    continue\n                \n                # Get diagram type (default to flowchart if missing)\n                diagram_type = slide.get(\"diagram_type\", \"flowchart\")\n                \n                # Save original diagram for reference\n                orig_diagram_content = slide.get(\"diagram_content\")\n                \n                try:\n                    # Render diagram\n                    png_path = render_mermaid(\n                        slide[\"diagram_content\"], \n                        diagram_dir, \n                        config_path, \n                        base_filename, \n                        slide[\"slide_number\"],\n                        diagram_type,\n                        client,\n                        model,\n                        preserve_all,\n                        asset_manager\n                    )\n                    \n                    # Update JSON with relative path\n                    rel_path = png_path.relative_to(json_path.parent)\n                    slide[\"image_url\"] = str(rel_path)\n                    \n                    # Cache this result\n                    processed[content_hash] = str(rel_path)\n                    \n                    # If diagram was converted from plain text, update the diagram content in JSON\n                    mmd_file = diagram_dir / f\"{base_filename}_slide{slide['slide_number']}.mmd\"\n                    if mmd_file.exists():\n                        rendered_content = mmd_file.read_text(encoding='utf-8')\n                        if rendered_content != orig_diagram_content:\n                            slide[\"diagram_content\"] = rendered_content\n                            diagram_lines = rendered_content.strip().split('\\n')\n                            if diagram_lines and ' ' in diagram_lines[0]:\n                                slide[\"diagram_type\"] = diagram_lines[0].split(' ')[0]\n                    \n                    changed += 1\n                    LOGGER.info(\"Rendered diagram for slide %d â†’ %s\", slide[\"slide_number\"], rel_path)\n                \n                except Exception as e:\n                    LOGGER.error(\"Diagram for slide %d failed: %s\", slide[\"slide_number\"], e)\n                    # Continue with the next slide instead of failing the whole process\n                \n            except Exception as e:\n                LOGGER.error(\"Error processing slide %d: %s\", slide.get(\"slide_number\", \"unknown\"), e)\n    \n    # Save updated JSON back\n    if changed > 0:\n        try:\n            if isinstance(slides_data, dict) and \"slides\" in slides_data:\n                slides_data[\"slides\"] = slides\n                json_path.write_text(json.dumps(slides_data, indent=2, ensure_ascii=False))\n            else:\n                json_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n            LOGGER.info(\"%d diagrams processed; file updated: %s\", changed, json_path)\n        except Exception as e:\n            LOGGER.error(\"Failed to save updated JSON: %s\", e)\n    \n    return changed\n\n\ndef process_directory(\n    json_dir: Path, \n    output_dir: Optional[Path], \n    config_path: Optional[Path],\n    client: Optional[anthropic.Anthropic] = None, \n    model: str = \"\",\n    preserve_all: bool = False,\n    asset_manager: Optional[Any] = None\n) -> int:\n    \"\"\"Process all JSON files in a directory.\"\"\"\n    LOGGER.info(\"Processing all JSON files in: %s\", json_dir)\n    \n    # Find all JSON files\n    json_files = list(json_dir.glob(\"slides_*.json\"))\n    if not json_files:\n        LOGGER.error(\"No slide JSON files found in %s\", json_dir)\n        return 0\n    \n    LOGGER.info(\"Found %d JSON files to process\", len(json_files))\n    \n    # Process each file\n    total_changed = 0\n    for json_path in json_files:\n        try:\n            # For directory processing, create subdirectory for each file's images\n            if output_dir:\n                file_output_dir = output_dir\n            else:\n                file_output_dir = json_dir / \"images\" / json_path.stem\n                file_output_dir.mkdir(parents=True, exist_ok=True)\n                \n            changed = process_json_file(\n                json_path, \n                file_output_dir, \n                config_path, \n                client, \n                model, \n                preserve_all,\n                asset_manager\n            )\n            total_changed += changed\n        except Exception as e:\n            LOGGER.error(\"Failed to process %s: %s\", json_path, e, exc_info=True)\n    \n    return total_changed\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    if output_dir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Check if mermaid config exists\n    config_path = Path(args.mermaid_config)\n    if not config_path.exists():\n        LOGGER.warning(\"Mermaid config file %s not found, using default\", config_path)\n        config_path = None\n    \n    # Initialize Claude client if needed\n    client = None\n    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n    if api_key:\n        try:\n            client = anthropic.Anthropic(api_key=api_key)\n            LOGGER.info(\"Initialized Claude client for diagram fixing\")\n        except Exception as e:\n            LOGGER.warning(\"Failed to initialize Claude client: %s\", e)\n    else:\n        LOGGER.warning(\"ANTHROPIC_API_KEY not set, Claude-assisted fixing unavailable\")\n    \n    # Initialize asset manager if requested\n    asset_manager = None\n    if args.use_asset_manager and ASSET_MANAGER_AVAILABLE:\n        try:\n            from asset_manager import AssetManager\n            assets_dir = Path(args.assets_dir) if args.assets_dir else Path.home() / \".makeslides\" / \"assets\"\n            cache_file = assets_dir / \"asset_cache.json\"\n            asset_manager = AssetManager(assets_dir, cache_file)\n            LOGGER.info(\"Initialized asset manager for diagram caching\")\n        except Exception as e:\n            LOGGER.warning(\"Failed to initialize asset manager: %s\", e)\n    \n    # Process files\n    try:\n        if json_path.is_dir():\n            total_changed = process_directory(\n                json_path, \n                output_dir, \n                config_path, \n                client, \n                args.model, \n                args.preserve_all,\n                asset_manager\n            )\n            LOGGER.info(\"Total of %d diagrams processed across all files\", total_changed)\n        else:\n            process_json_file(\n                json_path, \n                output_dir, \n                config_path, \n                client, \n                args.model, \n                args.preserve_all,\n                asset_manager\n            )\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n",
              "language": "python",
              "version_uuid": "32b6d2a6-75fb-4415-be89-e39130654170"
            },
            "message": "artifacts",
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "920d1262-b446-4444-acd2-134b23b00fe7"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-05-20T11:44:36.401067Z",
            "stop_timestamp": "2025-05-20T11:44:37.302329Z",
            "flags": null,
            "type": "text",
            "text": "\n\n### 5. Update Master Script to Use Asset Management\n\nLet's now update `magicSlide.sh` to work with our new improvements:",
            "citations": []
          },
          {
            "start_timestamp": "2025-05-20T11:44:37.518481Z",
            "stop_timestamp": "2025-05-20T11:45:37.978264Z",
            "flags": null,
            "type": "tool_use",
            "name": "artifacts",
            "input": {
              "id": "magicslide-fix",
              "type": "application/vnd.ant.code",
              "title": "magicSlide.sh (Improved)",
              "command": "create",
              "content": "#!/bin/bash\n# magicSlide.sh - One-click slide generation from facilitator guides\n# Usage: ./magicSlide.sh input.md [options]\n#        ./magicSlide.sh directory/ [options]\n\n# Default options\nCONFIG=\"config.yaml\"\nMERMAID_CONFIG=\"mermaid-config.json\"\nLOG_LEVEL=\"INFO\"\nTITLE_PREFIX=\"\"\nSTYLE=\"github\"\nUSE_FILEIO=1\nCLAUDE_MODEL=\"claude-3-7-sonnet-20250219\"\nSTART_STEP=1  # Default start from beginning\nFULL_CSV=1    # Generate full CSV with all fields by default\nPRESERVE_DIAGRAMS=0  # Don't keep multiple versions by default (use asset manager instead)\nDEBUG_MODE=0  # Display debug info\nUSE_ASSET_MANAGER=1  # Use asset manager by default\n\n# Define asset management directory\nASSET_DIR=\"$HOME/.makeslides/assets\"\n\n# Functions\nprint_usage() {\n  echo \"Usage: $0 <input.md or directory> [options]\"\n  echo \"Options:\"\n  echo \"  --config=FILE         YAML config file (default: config.yaml)\"\n  echo \"  --mermaid-config=FILE Mermaid config file (default: mermaid-config.json)\"\n  echo \"  --no-fileio           Don't use file.io for image uploads\"\n  echo \"  --title-prefix=TEXT   Add prefix to presentation titles\"\n  echo \"  --style=STYLE         Code highlighting style (default: github)\"\n  echo \"  --model=MODEL         Claude model (default: claude-3-7-sonnet-20250219)\"\n  echo \"  --compact-csv         Generate compact CSV (fewer columns)\"\n  echo \"  --no-full-csv         Don't include diagram content in CSV\"\n  echo \"  --preserve-diagrams   Preserve all diagram versions (default: use asset manager)\"\n  echo \"  --no-asset-manager    Don't use asset manager for caching\"\n  echo \"  --asset-dir=DIR       Directory for asset cache (default: ~/.makeslides/assets)\"\n  echo \"  --log-level=LEVEL     Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)\"\n  echo \"  --start-step=NUM      Start from specific step (1-5, default: 1)\"\n  echo \"  --debug               Run in debug mode (verbose output, validate markdown)\"\n  echo \"  --verify-npm          Check if npm and md2gslides are installed\"\n  echo \"  --help                Show this help message\"\n}\n\n# Parse arguments\nINPUT=\"\"\nfor arg in \"$@\"; do\n  case $arg in\n    --config=*)\n      CONFIG=\"${arg#*=}\"\n      ;;\n    --mermaid-config=*)\n      MERMAID_CONFIG=\"${arg#*=}\"\n      ;;\n    --no-fileio)\n      USE_FILEIO=0\n      ;;\n    --title-prefix=*)\n      TITLE_PREFIX=\"${arg#*=}\"\n      ;;\n    --style=*)\n      STYLE=\"${arg#*=}\"\n      ;;\n    --model=*)\n      CLAUDE_MODEL=\"${arg#*=}\"\n      ;;\n    --compact-csv)\n      FULL_CSV=0\n      COMPACT_CSV=1\n      ;;\n    --no-full-csv)\n      FULL_CSV=0\n      ;;\n    --preserve-diagrams)\n      PRESERVE_DIAGRAMS=1\n      ;;\n    --no-asset-manager)\n      USE_ASSET_MANAGER=0\n      ;;\n    --asset-dir=*)\n      ASSET_DIR=\"${arg#*=}\"\n      ;;\n    --log-level=*)\n      LOG_LEVEL=\"${arg#*=}\"\n      ;;\n    --start-step=*)\n      START_STEP=\"${arg#*=}\"\n      ;;\n    --debug)\n      DEBUG_MODE=1\n      LOG_LEVEL=\"DEBUG\"\n      ;;\n    --verify-npm)\n      VERIFY_NPM=1\n      ;;\n    --help)\n      print_usage\n      exit 0\n      ;;\n    -*)\n      echo \"Unknown option: $arg\"\n      print_usage\n      exit 1\n      ;;\n    *)\n      if [ -z \"$INPUT\" ]; then\n        INPUT=\"$arg\"\n      else\n        echo \"Multiple input files specified. Use only one.\"\n        print_usage\n        exit 1\n      fi\n      ;;\n  esac\ndone\n\n# Check for required input\nif [ -z \"$INPUT\" ]; then\n  echo \"Error: No input file or directory specified.\"\n  print_usage\n  exit 1\nfi\n\n# Check for asset manager\ncheck_asset_manager() {\n  if [ $USE_ASSET_MANAGER -eq 1 ]; then\n    if [ ! -f \"asset_manager.py\" ]; then\n      echo \"âš ï¸  Warning: asset_manager.py not found in the current directory.\"\n      echo \"   Asset manager will not be available for caching.\"\n      USE_ASSET_MANAGER=0\n    fi\n  fi\n}\n\n# Verify md2gslides installation early\nverify_md2gslides() {\n  echo \"ðŸ” Checking md2gslides installation...\"\n  if ! command -v npm &> /dev/null; then\n    echo \"âŒ npm could not be found. Please install Node.js first.\"\n    echo \"   Visit https://nodejs.org/ for installation instructions.\"\n    return 1\n  fi\n  \n  echo \"âœ… npm is installed: $(npm --version)\"\n  \n  if ! command -v md2gslides &> /dev/null; then\n    echo \"âŒ md2gslides could not be found. Installing it now...\"\n    npm install -g md2gslides\n    \n    if [ $? -ne 0 ]; then\n      echo \"âŒ Failed to install md2gslides. Please try manually:\"\n      echo \"   npm install -g md2gslides\"\n      return 1\n    fi\n  fi\n  \n  echo \"âœ… md2gslides is installed\"\n  \n  # Check for client_id.json\n  MD2G_DIR=\"$HOME/.md2googleslides\"\n  if [ ! -f \"$MD2G_DIR/client_id.json\" ]; then\n    echo \"âš ï¸  Warning: client_id.json not found at $MD2G_DIR/client_id.json\"\n    echo \"   You may need to set up Google API credentials.\"\n    echo \"   See: https://github.com/googleworkspace/md2googleslides#installation-and-usage\"\n    \n    # Create directory if it doesn't exist\n    mkdir -p \"$MD2G_DIR\"\n    \n    echo \"   Please follow these steps to set up Google API credentials:\"\n    echo \"   1. Go to https://console.developers.google.com\"\n    echo \"   2. Create a new project or select an existing one\"\n    echo \"   3. Enable the Google Slides API in the API Library\"\n    echo \"   4. Go to Credentials page and click '+ Create credentials'\"\n    echo \"   5. Select 'OAuth client ID' and 'Desktop Application'\"\n    echo \"   6. Download the JSON file and save it as 'client_id.json' in $MD2G_DIR\"\n    echo \"\"\n    echo \"   Do you want to continue without the credentials? (y/n)\"\n    read -r continue_without_creds\n    \n    if [[ $continue_without_creds != \"y\" && $continue_without_creds != \"Y\" ]]; then\n      echo \"Exiting. Please set up credentials and try again.\"\n      return 1\n    fi\n  else\n    echo \"âœ… Google API credentials found at $MD2G_DIR/client_id.json\"\n  fi\n  \n  return 0\n}\n\n# Ensure the asset directory exists\nmkdir -p \"$ASSET_DIR\"\n\n# Check for asset manager\ncheck_asset_manager\n\n# Check for md2gslides if requested or if starting from step 5\nif [ ${VERIFY_NPM:-0} -eq 1 ] || [ $START_STEP -eq 5 ]; then\n  verify_md2gslides || exit 1\nfi\n\n# Determine input type\nif [ -d \"$INPUT\" ]; then\n  # Directory mode\n  echo \"ðŸ” Processing directory: $INPUT\"\n  WORKING_DIR=\"$INPUT\"\n  DIR_MODE=1\nelse\n  # Single file mode\n  echo \"ðŸ” Processing file: $INPUT\"\n  WORKING_DIR=\"$(dirname \"$INPUT\")\"\n  BASENAME=\"$(basename \"$INPUT\" .md)\"\n  BASENAME=\"${BASENAME%.txt}\"  # Also strip .txt if present\n  DIR_MODE=0\nfi\n\n# Create/verify necessary directories\nIMAGES_DIR=\"$WORKING_DIR/images\"\nmkdir -p \"$IMAGES_DIR\"\n\n# Function to check if step should be executed\nshould_run_step() {\n  local step=$1\n  if [ $step -ge $START_STEP ]; then\n    return 0  # True in bash\n  else\n    return 1  # False in bash\n  fi\n}\n\n# Create a progress file to track completed steps\nPROGRESS_FILE=\"$WORKING_DIR/.magicslide_progress\"\nif [ \"$START_STEP\" -eq 1 ]; then\n  # Starting fresh, remove any existing progress file\n  rm -f \"$PROGRESS_FILE\"\nfi\n\n# Create a function for each step that saves progress\nrun_step() {\n  local step_num=$1\n  local step_name=$2\n  local step_cmd=$3\n  \n  if should_run_step $step_num; then\n    echo \"Step $step_num/5: $step_name\"\n    \n    # Run the command\n    if eval \"$step_cmd\"; then\n      # Save progress\n      echo \"$step_num completed\" >> \"$PROGRESS_FILE\"\n      return 0\n    else\n      local exit_code=$?\n      echo \"âŒ Step $step_num failed with exit code $exit_code\"\n      echo \"To resume from this step, run with --start-step=$step_num\"\n      return $exit_code\n    fi\n  else\n    echo \"Skipping Step $step_num/5: $step_name (already completed)\"\n  fi\n}\n\n# Step 1: JSON Generation\nif [ $DIR_MODE -eq 1 ]; then\n  JSON_STEP=\"python guide_to_json.py \\\"$INPUT\\\" --config=\\\"$CONFIG\\\" --model=\\\"$CLAUDE_MODEL\\\" --log-level=\\\"$LOG_LEVEL\\\"\"\nelse\n  JSON_FILE=\"$WORKING_DIR/slides_$BASENAME.json\"\n  JSON_STEP=\"python guide_to_json.py \\\"$INPUT\\\" --config=\\\"$CONFIG\\\" --out=\\\"$JSON_FILE\\\" --model=\\\"$CLAUDE_MODEL\\\" --log-level=\\\"$LOG_LEVEL\\\"\"\nfi\nrun_step 1 \"ðŸ§  Converting to JSON with Claude...\" \"$JSON_STEP\" || exit $?\n\n# Step 2: Diagram Generation\nPRESERVE_ARG=\"\"\nif [ $PRESERVE_DIAGRAMS -eq 1 ]; then\n  PRESERVE_ARG=\"--preserve-all\"\nfi\n\nASSET_MANAGER_ARG=\"\"\nif [ $USE_ASSET_MANAGER -eq 1 ]; then\n  ASSET_MANAGER_ARG=\"--use-asset-manager --assets-dir=\\\"$ASSET_DIR\\\"\"\nfi\n\nif [ $DIR_MODE -eq 1 ]; then\n  DIAGRAM_STEP=\"python diagrams_to_images.py \\\"$INPUT\\\" --mermaid-config=\\\"$MERMAID_CONFIG\\\" --output-dir=\\\"$IMAGES_DIR\\\" --log-level=\\\"$LOG_LEVEL\\\" --model=\\\"$CLAUDE_MODEL\\\" $PRESERVE_ARG $ASSET_MANAGER_ARG\"\nelse\n  DIAGRAM_STEP=\"python diagrams_to_images.py \\\"$JSON_FILE\\\" --mermaid-config=\\\"$MERMAID_CONFIG\\\" --output-dir=\\\"$IMAGES_DIR\\\" --log-level=\\\"$LOG_LEVEL\\\" --model=\\\"$CLAUDE_MODEL\\\" $PRESERVE_ARG $ASSET_MANAGER_ARG\"\nfi\nrun_step 2 \"ðŸ“Š Rendering diagrams...\" \"$DIAGRAM_STEP\" || exit $?\n\n# Step 3: CSV Generation\nCSV_ARGS=\"\"\nif [ $FULL_CSV -eq 1 ]; then\n  CSV_ARGS=\"--full\"\nelif [ ${COMPACT_CSV:-0} -eq 1 ]; then\n  CSV_ARGS=\"--compact\"\nfi\n\nif [ $DIR_MODE -eq 1 ]; then\n  CSV_STEP=\"python json_to_csv.py \\\"$INPUT\\\" --log-level=\\\"$LOG_LEVEL\\\" $CSV_ARGS\"\nelse\n  CSV_STEP=\"python json_to_csv.py \\\"$JSON_FILE\\\" --log-level=\\\"$LOG_LEVEL\\\" $CSV_ARGS\"\nfi\nrun_step 3 \"ðŸ“Š Generating CSV overview...\" \"$CSV_STEP\" || exit $?\n\n# Step 4: Markdown Generation\nDEBUG_ARGS=\"\"\nif [ $DEBUG_MODE -eq 1 ]; then\n  DEBUG_ARGS=\"--debug\"\nfi\n\nif [ $DIR_MODE -eq 1 ]; then\n  MD_STEP=\"python json_to_markdown.py \\\"$INPUT\\\" --prefer-svg --log-level=\\\"$LOG_LEVEL\\\" $DEBUG_ARGS\"\nelse\n  MD_STEP=\"python json_to_markdown.py \\\"$JSON_FILE\\\" --prefer-svg --log-level=\\\"$LOG_LEVEL\\\" $DEBUG_ARGS\"\nfi\nrun_step 4 \"ðŸ“ Converting to markdown...\" \"$MD_STEP\" || exit $?\n\n# Find markdown files (fixed to use correct naming with \"slides_\" prefix)\nif [ $DIR_MODE -eq 1 ]; then\n  # Find all markdown files generated\n  MD_FILES=($WORKING_DIR/slides_*.md)\n  if [ ${#MD_FILES[@]} -eq 0 ]; then\n    echo \"âŒ No markdown files found in $WORKING_DIR\"\n    # Try finding any markdown files as fallback\n    MD_FILES=($WORKING_DIR/*.md)\n    if [ ${#MD_FILES[@]} -eq 0 ]; then\n      echo \"âŒ No markdown files found at all. Cannot proceed.\"\n      exit 1\n    fi\n    echo \"âš ï¸ Using fallback markdown files without 'slides_' prefix\"\n  fi\nelse\n  # Use the correct markdown file name with \"slides_\" prefix\n  MD_FILE=\"$WORKING_DIR/slides_$BASENAME.md\"\n  \n  # Double-check that the file exists\n  if [ ! -f \"$MD_FILE\" ]; then\n    echo \"âŒ Expected markdown file not found: $MD_FILE\"\n    echo \"Checking for alternative files...\"\n    \n    # Try without the \"slides_\" prefix as a fallback\n    ALT_FILE=\"$WORKING_DIR/$BASENAME.md\"\n    if [ -f \"$ALT_FILE\" ]; then\n      echo \"âœ… Found alternative markdown file: $ALT_FILE\"\n      MD_FILE=\"$ALT_FILE\"\n    else\n      # List all markdown files in the directory\n      echo \"Available markdown files:\"\n      find \"$WORKING_DIR\" -name \"*.md\" -type f | while read -r file; do\n        echo \"  - $(basename \"$file\")\"\n      done\n      \n      echo \"Please select which file to use or fix the naming in your scripts.\"\n      exit 1\n    fi\n  fi\nfi\n\n# Step 5: Google Slides Generation\nFILEIO_ARG=\"\"\nif [ $USE_FILEIO -eq 1 ]; then\n  FILEIO_ARG=\"--use-fileio\"\nfi\n\nDEBUG_ARG=\"\"\nif [ $DEBUG_MODE -eq 1 ]; then\n  DEBUG_ARG=\"--debug\"\nfi\n\nVERIFY_ARG=\"\"\nif [ ${VERIFY_NPM:-0} -eq 1 ]; then\n  VERIFY_ARG=\"--verify-npm\"\nfi\n\nif [ $DIR_MODE -eq 1 ]; then\n  # Process all markdown files\n  for md_file in \"${MD_FILES[@]}\"; do\n    echo \"Processing markdown file: $md_file\"\n    md_basename=$(basename \"$md_file\" .md)\n    output_file=\"$WORKING_DIR/${md_basename}-presentation.txt\"\n    \n    SLIDES_CMD=\"python build_with_md2gslides.py \\\"$md_file\\\" --title-prefix=\\\"$TITLE_PREFIX\\\" --style=\\\"$STYLE\\\" $FILEIO_ARG --log-level=\\\"$LOG_LEVEL\\\" --output-file=\\\"$output_file\\\" $DEBUG_ARG $VERIFY_ARG --fix-format\"\n    echo \"Running: $SLIDES_CMD\"\n    eval \"$SLIDES_CMD\" || echo \"âš ï¸ Failed to create slides for $md_file\"\n  done\n  # Mark step as complete even if some files failed\n  echo \"5 completed\" >> \"$PROGRESS_FILE\"\nelse\n  # Process single markdown file\n  output_file=\"$WORKING_DIR/${BASENAME}-presentation.txt\"\n  SLIDES_STEP=\"python build_with_md2gslides.py \\\"$MD_FILE\\\" --title-prefix=\\\"$TITLE_PREFIX\\\" --style=\\\"$STYLE\\\" $FILEIO_ARG --log-level=\\\"$LOG_LEVEL\\\" --output-file=\\\"$output_file\\\" $DEBUG_ARG $VERIFY_ARG --fix-format\"\n\n  run_step 5 \"ðŸŽ¯ Generating Google Slides...\" \"$SLIDES_STEP\" || {\n    echo \"âŒ Failed to create Google Slides for $MD_FILE\"\n    echo \"Here's the first 20 lines of the markdown file to help diagnose:\"\n    head -n 20 \"$MD_FILE\"\n    exit 1\n  }\nfi\n\necho \"âœ… All done! Your slides are ready.\"\necho \"ðŸ“‹ Presentation links saved to the output text file.\"\necho \"ðŸ“Š CSV overview files have been generated for quick reference.\"\n\n# Print statistics if available\nif [ -f \"${JSON_FILE:-}\" ]; then\n  echo \"\"\n  echo \"ðŸ“Š Slide statistics:\"\n  \n  # Count total slides\n  TOTAL_SLIDES=$(grep -c \"\\\"slide_number\\\":\" \"$JSON_FILE\" || echo \"0\")\n  echo \"Total slides: $TOTAL_SLIDES\"\n  \n  # Count diagrams\n  DIAGRAMS=$(grep -c \"\\\"diagram_type\\\":\" \"$JSON_FILE\" | grep -v \"\\\"diagram_type\\\": null\" || echo \"0\")\n  echo \"Diagrams: $DIAGRAMS\"\n  \n  # Count images\n  IMAGES=$(grep -c \"\\\"image_url\\\":\" \"$JSON_FILE\" | grep -v \"\\\"image_url\\\": null\" || echo \"0\")\n  echo \"Images: $IMAGES\"\n  \n  # Count different layouts\n  echo \"\"\n  echo \"Layout variety:\"\n  grep -o \"\\\"layout\\\": \\\"[^\\\"]*\\\"\" \"$JSON_FILE\" | sort | uniq -c\nfi\n\necho \"\"\necho \"If you still have issues with Google Slides generation, try:\"\necho \"  1. Run with --verify-npm to check Node.js installation\"\necho \"  2. Make sure md2gslides is installed: npm install -g md2gslides\"\necho \"  3. Run with --debug to see detailed output\"\necho \"  4. Check if your Google API credentials are set up correctly\"\n",
              "language": "bash",
              "version_uuid": "f492b179-ed29-4d2f-b706-3fcf6e71c106"
            },
            "message": "artifacts",
            "integration_name": null,
            "integration_icon_url": null,
            "context": null,
            "display_content": null,
            "approval_options": null,
            "approval_key": null
          },
          {
            "start_timestamp": null,
            "stop_timestamp": null,
            "flags": null,
            "type": "tool_result",
            "name": "artifacts",
            "content": [
              {
                "type": "text",
                "text": "OK",
                "uuid": "43f4c8ff-bfa4-411e-8f58-1f7cca76206c"
              }
            ],
            "is_error": false,
            "message": null,
            "integration_name": null,
            "integration_icon_url": null,
            "display_content": null
          },
          {
            "start_timestamp": "2025-05-20T11:45:38.271730Z",
            "stop_timestamp": "2025-05-20T11:45:38.271730Z",
            "flags": null,
            "type": "text",
            "text": "",
            "citations": []
          }
        ],
        "updated_at": "2025-05-20T11:45:38.307145Z",
        "attachments": [],
        "files": []
      }
    }
  ]
}