{
  "id": "b20cbbd7-a868-40e4-b2c6-f49d6f09be1d",
  "source": "claude",
  "title": "Modular Slide Generation with Unsplash Integration",
  "created_at": "2025-05-20T06:08:36.586910Z",
  "updated_at": "2025-05-20T10:07:23.081600Z",
  "summary": "",
  "message_count": 10,
  "messages": [
    {
      "id": "75f15ade-4b05-40e6-be9e-d92f452806e9",
      "role": "human",
      "content": "r",
      "created_at": "2025-05-20T06:08:37.786406Z",
      "sequence_order": 0,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-20T06:08:37.768677Z",
            "stop_timestamp": "2025-05-20T06:08:37.768677Z",
            "flags": null,
            "type": "text",
            "text": "r",
            "citations": []
          }
        ],
        "updated_at": "2025-05-20T06:08:37.786406Z",
        "attachments": [
          {
            "file_name": "paste.txt",
            "file_size": 67032,
            "file_type": "txt",
            "extracted_content": "i want to use upsplash first it seems like it has a no login api: Search photos\nGet a single page of photo results for a query.\n\nGET /search/photos\nNote: See the note on hotlinking.\n\nParameters\nparam\tDescription\nquery\tSearch terms.\npage\tPage number to retrieve. (Optional; default: 1)\nper_page\tNumber of items per page. (Optional; default: 10)\norder_by\tHow to sort the photos. (Optional; default: relevant). Valid values are latest and relevant.\ncollections\tCollection ID(‘s) to narrow search. Optional. If multiple, comma-separated.\ncontent_filter\tLimit results by content safety. (Optional; default: low). Valid values are low and high.\ncolor\tFilter results by color. Optional. Valid values are: black_and_white, black, white, yellow, orange, red, purple, magenta, green, teal, and blue.\norientation\tFilter by photo orientation. Optional. (Valid values: landscape, portrait, squarish)\nBeta parameters (for access to beta parameters, email api@unsplash.com with your application ID):\n\nparam\tDescription\nlang\tSupported ISO 639-1 language code of the query. Optional, default: \"en\"\nResponse\nThe photo objects returned here are abbreviated. For full details use GET /photos/:id\n\n200 OK\nLink: <https://api.unsplash.com/search/photos?page=1&query=office>; rel=\"first\", <https://api.unsplash.com/search/photos?page=1&query=office>; rel=\"prev\", <https://api.unsplash.com/search/photos?page=3&query=office>; rel=\"last\", <https://api.unsplash.com/search/photos?page=3&query=office>; rel=\"next\"\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n{\n  \"total\": 133,\n  \"total_pages\": 7,\n  \"results\": [\n    {\n      \"id\": \"eOLpJytrbsQ\",\n      \"created_at\": \"2014-11-18T14:35:36-05:00\",\n      \"width\": 4000,\n      \"height\": 3000,\n      \"color\": \"#A7A2A1\",\n      \"blur_hash\": \"LaLXMa9Fx[D%~q%MtQM|kDRjtRIU\",\n      \"likes\": 286,\n      \"liked_by_user\": false,\n      \"description\": \"A man drinking a coffee.\",\n      \"user\": {\n        \"id\": \"Ul0QVz12Goo\",\n        \"username\": \"ugmonk\",\n        \"name\": \"Jeff Sheldon\",\n        \"first_name\": \"Jeff\",\n        \"last_name\": \"Sheldon\",\n        \"instagram_username\": \"instantgrammer\",\n        \"twitter_username\": \"ugmonk\",\n        \"portfolio_url\": \"http://ugmonk.com/\",\n        \"profile_image\": {\n          \"small\": \"https://images.unsplash.com/profile-1441298803695-accd94000cac?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=32&w=32&s=7cfe3b93750cb0c93e2f7caec08b5a41\",\n          \"medium\": \"https://images.unsplash.com/profile-1441298803695-accd94000cac?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=64&w=64&s=5a9dc749c43ce5bd60870b129a40902f\",\n          \"large\": \"https://images.unsplash.com/profile-1441298803695-accd94000cac?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=128&w=128&s=32085a077889586df88bfbe406692202\"\n        },\n        \"links\": {\n          \"self\": \"https://api.unsplash.com/users/ugmonk\",\n          \"html\": \"http://unsplash.com/@ugmonk\",\n          \"photos\": \"https://api.unsplash.com/users/ugmonk/photos\",\n          \"likes\": \"https://api.unsplash.com/users/ugmonk/likes\"\n        }\n      },\n      \"current_user_collections\": [],\n      \"urls\": {\n        \"raw\": \"https://images.unsplash.com/photo-1416339306562-f3d12fefd36f\",\n        \"full\": \"https://hd.unsplash.com/photo-1416339306562-f3d12fefd36f\",\n        \"regular\": \"https://images.unsplash.com/photo-1416339306562-f3d12fefd36f?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max&s=92f3e02f63678acc8416d044e189f515\",\n        \"small\": \"https://images.unsplash.com/photo-1416339306562-f3d12fefd36f?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=400&fit=max&s=263af33585f9d32af39d165b000845eb\",\n        \"thumb\": \"https://images.unsplash.com/photo-1416339306562-f3d12fefd36f?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max&s=8aae34cf35df31a592f0bef16e6342ef\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/photos/eOLpJytrbsQ\",\n        \"html\": \"http://unsplash.com/photos/eOLpJytrbsQ\",\n        \"download\": \"http://unsplash.com/photos/eOLpJytrbsQ/download\"\n      }\n    },\n    // more photos ...\n  ]\n}\n\nSearch collections\nGet a single page of collection results for a query.\n\nGET /search/collections\nParameters\nparam\tDescription\nquery\tSearch terms.\npage\tPage number to retrieve. (Optional; default: 1)\nper_page\tNumber of items per page. (Optional; default: 10)\nResponse\n200 OK\nLink: <https://api.unsplash.com/search/collections?page=1&query=office>; rel=\"first\", <https://api.unsplash.com/search/collections?page=1&query=office>; rel=\"prev\", <https://api.unsplash.com/search/collections?page=3&query=office>; rel=\"last\", <https://api.unsplash.com/search/collections?page=3&query=office>; rel=\"next\"\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n{\n  \"total\": 237,\n  \"total_pages\": 12,\n  \"results\": [\n    {\n      \"id\": 193913,\n      \"title\": \"Office\",\n      \"description\": null,\n      \"published_at\": \"2016-04-15T21:05:44-04:00\",\n      \"last_collected_at\": \"2016-06-02T13:10:03-04:00\",\n      \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n      \"featured\": true,\n      \"total_photos\": 60,\n      \"private\": false,\n      \"share_key\": \"79ec77a237f014935eddc774f6aac1cd\",\n      \"cover_photo\": {\n        \"id\": \"pb_lF8VWaPU\",\n        \"created_at\": \"2015-02-12T18:39:43-05:00\",\n        \"width\": 5760,\n        \"height\": 3840,\n        \"color\": \"#1F1814\",\n        \"blur_hash\": \"L14Bk2M{0d^lR*j[ofWB0K%3^l9Y\",\n        \"likes\": 786,\n        \"liked_by_user\": false,\n        \"description\": \"A man drinking a coffee.\",\n        \"user\": {\n          \"id\": \"tkoUSod3di4\",\n          \"username\": \"gilleslambert\",\n          \"name\": \"Gilles Lambert\",\n          \"first_name\": \"Gilles\",\n          \"last_name\": \"Lambert\",\n          \"instagram_username\": \"instantgrammer\",\n          \"twitter_username\": \"gilleslambert\",\n          \"portfolio_url\": \"http://www.gilleslambert.be/photography\",\n          \"profile_image\": {\n            \"small\": \"https://images.unsplash.com/profile-1445832407811-c04ed64d238b?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=32&w=32&s=4bb8fad0dcba43c46491c6fd0b92f537\",\n            \"medium\": \"https://images.unsplash.com/profile-1445832407811-c04ed64d238b?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=64&w=64&s=a6d8602c855914fe13650eedd5996cb5\",\n            \"large\": \"https://images.unsplash.com/profile-1445832407811-c04ed64d238b?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=128&w=128&s=26099ca5069692aac6973d08ae02dd71\"\n          },\n          \"links\": {\n            \"self\": \"https://api.unsplash.com/users/gilleslambert\",\n            \"html\": \"http://unsplash.com/@gilleslambert\",\n            \"photos\": \"https://api.unsplash.com/users/gilleslambert/photos\",\n            \"likes\": \"https://api.unsplash.com/users/gilleslambert/likes\"\n          }\n        },\n        \"urls\": {\n          \"raw\": \"https://images.unsplash.com/photo-1423784346385-c1d4dac9893a\",\n          \"full\": \"https://hd.unsplash.com/photo-1423784346385-c1d4dac9893a\",\n          \"regular\": \"https://images.unsplash.com/photo-1423784346385-c1d4dac9893a?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max&s=d60d527cb347746ab3abf5fccecf0271\",\n          \"small\": \"https://images.unsplash.com/photo-1423784346385-c1d4dac9893a?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=400&fit=max&s=0bf0c97abca8b2741380f38d3debd45f\",\n          \"thumb\": \"https://images.unsplash.com/photo-1423784346385-c1d4dac9893a?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max&s=9bc3a6d42a16809b735c22720de3fb13\"\n        },\n        \"links\": {\n          \"self\": \"https://api.unsplash.com/photos/pb_lF8VWaPU\",\n          \"html\": \"http://unsplash.com/photos/pb_lF8VWaPU\",\n          \"download\": \"http://unsplash.com/photos/pb_lF8VWaPU/download\"\n        }\n      },\n      \"user\": {\n        \"id\": \"k_gSWNtOjS8\",\n        \"username\": \"cjmconnors\",\n        \"name\": \"Christine Connors\",\n        \"portfolio_url\": null,\n        \"bio\": \"\",\n        \"profile_image\": {\n          \"small\": \"https://images.unsplash.com/placeholder-avatars/extra-large.jpg?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=32&w=32&s=0ad68f44c4725d5a3fda019bab9d3edc\",\n          \"medium\": \"https://images.unsplash.com/placeholder-avatars/extra-large.jpg?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=64&w=64&s=356bd4b76a3d4eb97d63f45b818dd358\",\n          \"large\": \"https://images.unsplash.com/placeholder-avatars/extra-large.jpg?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=128&w=128&s=ee8bbf5fb8d6e43aaaa238feae2fe90d\"\n        },\n        \"links\": {\n          \"self\": \"https://api.unsplash.com/users/cjmconnors\",\n          \"html\": \"http://unsplash.com/@cjmconnors\",\n          \"photos\": \"https://api.unsplash.com/users/cjmconnors/photos\",\n          \"likes\": \"https://api.unsplash.com/users/cjmconnors/likes\"\n        }\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/collections/193913\",\n        \"html\": \"http://unsplash.com/collections/193913/office\",\n        \"photos\": \"https://api.unsplash.com/collections/193913/photos\",\n        \"related\": \"https://api.unsplash.com/collections/193913/related\"\n      }\n    },\n    // more collections...\n  ]\n}\n\nSearch users\nGet a single page of user results for a query.\n\nGET /search/users\nParameters\nparam\tDescription\nquery\tSearch terms.\npage\tPage number to retrieve. (Optional; default: 1)\nper_page\tNumber of items per page. (Optional; default: 10)\nResponse\n200 OK\nLink: <https://api.unsplash.com/search/users?page=1&query=nas>; rel=\"first\", <https://api.unsplash.com/search/users?page=1&query=nas>; rel=\"prev\", <https://api.unsplash.com/search/users?page=3&query=nas>; rel=\"last\", <https://api.unsplash.com/search/users?page=3&query=nas>; rel=\"next\"\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n{\n  \"total\": 14,\n  \"total_pages\": 1,\n  \"results\": [\n    {\n      \"id\": \"e_gYNc2Fs0s\",\n      \"username\": \"solase\",\n      \"name\": \"Aase H. Tjelland\",\n      \"first_name\": \"Aase\",\n      \"last_name\": \"H. Tjelland\",\n      \"instagram_username\": \"instantgrammer\",\n      \"twitter_username\": \"solase\",\n      \"portfolio_url\": null,\n      \"total_likes\": 1,\n      \"total_photos\": 6,\n      \"total_collections\": 0,\n      \"profile_image\": {\n        \"small\": \"https://images.unsplash.com/placeholder-avatars/extra-large.jpg?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=32&w=32&s=0ad68f44c4725d5a3fda019bab9d3edc\",\n        \"medium\": \"https://images.unsplash.com/placeholder-avatars/extra-large.jpg?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=64&w=64&s=356bd4b76a3d4eb97d63f45b818dd358\",\n        \"large\": \"https://images.unsplash.com/placeholder-avatars/extra-large.jpg?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=128&w=128&s=ee8bbf5fb8d6e43aaaa238feae2fe90d\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/users/solase\",\n        \"html\": \"http://unsplash.com/@solase\",\n        \"photos\": \"https://api.unsplash.com/users/solase/photos\",\n        \"likes\": \"https://api.unsplash.com/users/solase/likes\"\n      }\n    },\n    // more users ...\n}\n\nCollections\nLink relations\nCollections have the following link relations:\n\nrel\tDescription\nself\tAPI location of this collection.\nhtml\tHTML location of this collection.\nphotos\tAPI location of this collection’s photos.\nrelated\tAPI location of this collection’s related collections.\nList collections\nGet a single page from the list of all collections.\n\nGET /collections\nParameters\nparam\tDescription\npage\tPage number to retrieve. (Optional; default: 1)\nper_page\tNumber of items per page. (Optional; default: 10)\nResponse\n200 OK\nLink: <https://api.unsplash.com/collections?page=8>; rel=\"last\", <https://api.unsplash.com/collections?page=2>; rel=\"next\"\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n[\n  {\n    \"id\": 296,\n    \"title\": \"I like a man with a beard.\",\n    \"description\": \"Yeah even Santa...\",\n    \"published_at\": \"2016-01-27T18:47:13-05:00\",\n    \"last_collected_at\": \"2016-06-02T13:10:03-04:00\",\n    \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n    \"total_photos\": 12,\n    \"private\": false,\n    \"share_key\": \"312d188df257b957f8b86d2ce20e4766\",\n    \"cover_photo\": {\n      \"id\": \"C-mxLOk6ANs\",\n      \"width\": 5616,\n      \"height\": 3744,\n      \"color\": \"#E4C6A2\",\n      \"blur_hash\": \"L57Uhwni00t7EeRkagj@s+kBxvoe\",\n      \"likes\": 12,\n      \"liked_by_user\": false,\n      \"description\": \"A man drinking a coffee.\",\n      \"user\": {\n        \"id\": \"xlt1-UPW7FE\",\n        \"username\": \"lionsdenpro\",\n        \"name\": \"Greg Raines\",\n        \"portfolio_url\": \"https://example.com/\",\n        \"bio\": \"Just an everyday Greg\",\n        \"location\": \"Montreal\",\n        \"total_likes\": 5,\n        \"total_photos\": 10,\n        \"total_collections\": 13,\n        \"profile_image\": {\n          \"small\": \"https://images.unsplash.com/profile-1449546653256-0faea3006d34?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=32&w=32\",\n          \"medium\": \"https://images.unsplash.com/profile-1449546653256-0faea3006d34?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=64&w=64\",\n          \"large\": \"https://images.unsplash.com/profile-1449546653256-0faea3006d34?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=128&w=128\"\n        },\n        \"links\": {\n          \"self\": \"https://api.unsplash.com/users/lionsdenpro\",\n          \"html\": \"https://unsplash.com/lionsdenpro\",\n          \"photos\": \"https://api.unsplash.com/users/lionsdenpro/photos\",\n          \"likes\": \"https://api.unsplash.com/users/lionsdenpro/likes\",\n          \"portfolio\": \"https://api.unsplash.com/users/lionsdenpro/portfolio\"\n        }\n      },\n      \"urls\": {\n        \"raw\": \"https://images.unsplash.com/photo-1449614115178-cb924f730780\",\n        \"full\": \"https://images.unsplash.com/photo-1449614115178-cb924f730780?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy\",\n        \"regular\": \"https://images.unsplash.com/photo-1449614115178-cb924f730780?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=1080&fit=max\",\n        \"small\": \"https://images.unsplash.com/photo-1449614115178-cb924f730780?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=400&fit=max\",\n        \"thumb\": \"https://images.unsplash.com/photo-1449614115178-cb924f730780?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=200&fit=max\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/photos/C-mxLOk6ANs\",\n        \"html\": \"https://unsplash.com/photos/C-mxLOk6ANs\",\n        \"download\": \"https://unsplash.com/photos/C-mxLOk6ANs/download\"\n      }\n    },\n    \"user\": {\n      \"id\": \"IFcEhJqem0Q\",\n      \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n      \"username\": \"fableandfolk\",\n      \"name\": \"Annie Spratt\",\n      \"portfolio_url\": \"http://mammasaurus.co.uk\",\n      \"bio\": \"Follow me on Twitter &amp; Instagram @anniespratt\\r\\nEmail me at hello@fableandfolk.com\",\n      \"location\": \"New Forest National Park, UK\",\n      \"total_likes\": 0,\n      \"total_photos\": 273,\n      \"total_collections\": 36,\n      \"profile_image\": {\n        \"small\": \"https://images.unsplash.com/profile-1450003783594-db47c765cea3?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=32&w=32\",\n        \"medium\": \"https://images.unsplash.com/profile-1450003783594-db47c765cea3?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=64&w=64\",\n        \"large\": \"https://images.unsplash.com/profile-1450003783594-db47c765cea3?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=128&w=128\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/users/fableandfolk\",\n        \"html\": \"https://unsplash.com/fableandfolk\",\n        \"photos\": \"https://api.unsplash.com/users/fableandfolk/photos\",\n        \"likes\": \"https://api.unsplash.com/users/fableandfolk/likes\",\n        \"portfolio\": \"https://api.unsplash.com/users/fableandfolk/portfolio\"\n      }\n    },\n    \"links\": {\n      \"self\": \"https://api.unsplash.com/collections/296\",\n      \"html\": \"https://unsplash.com/collections/296\",\n      \"photos\": \"https://api.unsplash.com/collections/296/photos\",\n      \"related\": \"https://api.unsplash.com/collections/296/related\"\n    }\n  },\n  // ... more Collections ...\n]\n\nGet a collection\nRetrieve a single collection. To view a user’s private collections, the read_collections scope is required.\n\nGET /collections/:id\nNote: See the note on hotlinking.\n\nParameters\nparam\tDescription\nid\tThe collections’s ID. Required.\nResponse\n200 OK\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n{\n  \"id\": 206,\n  \"title\": \"Makers: Cat and Ben\",\n  \"description\": \"Behind-the-scenes photos from the Makers interview with designers Cat Noone and Benedikt Lehnert.\",\n  \"published_at\": \"2016-01-12T18:16:09-05:00\",\n  \"last_collected_at\": \"2016-06-02T13:10:03-04:00\",\n  \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n  \"featured\": false,\n  \"total_photos\": 12,\n  \"private\": false,\n  \"share_key\": \"312d188df257b957f8b86d2ce20e4766\",\n  \"cover_photo\": null,\n  \"user\": null,\n  \"links\": {\n    \"self\": \"https://api.unsplash.com/collections/206\",\n    \"html\": \"https://unsplash.com/collections/206/makers-cat-and-ben\",\n    \"photos\": \"https://api.unsplash.com/collections/206/photos\"\n  }\n}\n\nGet a collection’s photos\nRetrieve a collection’s photos.\n\nGET /collections/:id/photos\nNote: See the note on hotlinking.\n\nParameters\nparam\tDescription\nid\tThe collection’s ID. Required.\npage\tPage number to retrieve. (Optional; default: 1)\nper_page\tNumber of items per page. (Optional; default: 10)\norientation\tFilter by photo orientation. Optional. (Valid values: landscape, portrait, squarish)\nResponse\n200 OK\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n[\n  {\n    \"id\": \"LBI7cgq3pbM\",\n    \"created_at\": \"2016-05-03T11:00:28-04:00\",\n    \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n    \"width\": 5245,\n    \"height\": 3497,\n    \"color\": \"#60544D\",\n    \"blur_hash\": \"LoC%a7IoIVxZ_NM|M{s:%hRjWAo0\",\n    \"likes\": 12,\n    \"liked_by_user\": false,\n    \"description\": \"A man drinking a coffee.\",\n    \"user\": {\n      \"id\": \"pXhwzz1JtQU\",\n      \"username\": \"poorkane\",\n      \"name\": \"Gilbert Kane\",\n      \"portfolio_url\": \"https://theylooklikeeggsorsomething.com/\",\n      \"bio\": \"XO\",\n      \"location\": \"Way out there\",\n      \"total_likes\": 5,\n      \"total_photos\": 74,\n      \"total_collections\": 52,\n      \"instagram_username\": \"instantgrammer\",\n      \"twitter_username\": \"crew\",\n      \"profile_image\": {\n        \"small\": \"https://images.unsplash.com/face-springmorning.jpg?q=80&fm=jpg&crop=faces&fit=crop&h=32&w=32\",\n        \"medium\": \"https://images.unsplash.com/face-springmorning.jpg?q=80&fm=jpg&crop=faces&fit=crop&h=64&w=64\",\n        \"large\": \"https://images.unsplash.com/face-springmorning.jpg?q=80&fm=jpg&crop=faces&fit=crop&h=128&w=128\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/users/poorkane\",\n        \"html\": \"https://unsplash.com/poorkane\",\n        \"photos\": \"https://api.unsplash.com/users/poorkane/photos\",\n        \"likes\": \"https://api.unsplash.com/users/poorkane/likes\",\n        \"portfolio\": \"https://api.unsplash.com/users/poorkane/portfolio\"\n      }\n    },\n    \"current_user_collections\": [ // The *current user's* collections that this photo belongs to.\n      {\n        \"id\": 206,\n        \"title\": \"Makers: Cat and Ben\",\n        \"published_at\": \"2016-01-12T18:16:09-05:00\",\n        \"last_collected_at\": \"2016-06-02T13:10:03-04:00\",\n        \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n        \"cover_photo\": null,\n        \"user\": null\n      },\n      // ... more collections\n    ],\n    \"urls\": {\n      \"raw\": \"https://images.unsplash.com/face-springmorning.jpg\",\n      \"full\": \"https://images.unsplash.com/face-springmorning.jpg?q=75&fm=jpg\",\n      \"regular\": \"https://images.unsplash.com/face-springmorning.jpg?q=75&fm=jpg&w=1080&fit=max\",\n      \"small\": \"https://images.unsplash.com/face-springmorning.jpg?q=75&fm=jpg&w=400&fit=max\",\n      \"thumb\": \"https://images.unsplash.com/face-springmorning.jpg?q=75&fm=jpg&w=200&fit=max\"\n    },\n    \"links\": {\n      \"self\": \"https://api.unsplash.com/photos/LBI7cgq3pbM\",\n      \"html\": \"https://unsplash.com/photos/LBI7cgq3pbM\",\n      \"download\": \"https://unsplash.com/photos/LBI7cgq3pbM/download\",\n      \"download_location\": \"https://api.unsplash.com/photos/LBI7cgq3pbM/download\"\n    }\n  },\n  // ... more photos\n]\n\nList a collection’s related collections\nRetrieve a list of collections related to this one.\n\nGET /collections/:id/related\nParameters\nparam\tDescription\nid\tThe collection’s ID. Required.\nResponse\n200 OK\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n[\n  {\n    \"id\": 296,\n    \"title\": \"I like a man with a beard.\",\n    \"description\": \"Yeah even Santa...\",\n    \"published_at\": \"2016-01-27T18:47:13-05:00\",\n    \"last_collected_at\": \"2016-06-02T13:10:03-04:00\",\n    \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n    \"total_photos\": 12,\n    \"private\": false,\n    \"share_key\": \"312d188df257b957f8b86d2ce20e4766\",\n    \"cover_photo\": {\n      \"id\": \"C-mxLOk6ANs\",\n      \"width\": 5616,\n      \"height\": 3744,\n      \"color\": \"#E4C6A2\",\n      \"blur_hash\": \"L57Uhwni00t7EeRkagj@s+kBxvoe\",\n      \"likes\": 12,\n      \"liked_by_user\": false,\n      \"description\": \"A man drinking a coffee.\",\n      \"user\": {\n        \"id\": \"xlt1-UPW7FE\",\n        \"username\": \"lionsdenpro\",\n        \"name\": \"Greg Raines\",\n        \"portfolio_url\": \"https://example.com/\",\n        \"bio\": \"Just an everyday Greg\",\n        \"location\": \"Montreal\",\n        \"total_likes\": 5,\n        \"total_photos\": 10,\n        \"total_collections\": 13,\n        \"profile_image\": {\n          \"small\": \"https://images.unsplash.com/profile-1449546653256-0faea3006d34?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=32&w=32\",\n          \"medium\": \"https://images.unsplash.com/profile-1449546653256-0faea3006d34?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=64&w=64\",\n          \"large\": \"https://images.unsplash.com/profile-1449546653256-0faea3006d34?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=128&w=128\"\n        },\n        \"links\": {\n          \"self\": \"https://api.unsplash.com/users/lionsdenpro\",\n          \"html\": \"https://unsplash.com/lionsdenpro\",\n          \"photos\": \"https://api.unsplash.com/users/lionsdenpro/photos\",\n          \"likes\": \"https://api.unsplash.com/users/lionsdenpro/likes\",\n          \"portfolio\": \"https://api.unsplash.com/users/lionsdenpro/portfolio\"\n        }\n      },\n      \"urls\": {\n        \"raw\": \"https://images.unsplash.com/photo-1449614115178-cb924f730780\",\n        \"full\": \"https://images.unsplash.com/photo-1449614115178-cb924f730780?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy\",\n        \"regular\": \"https://images.unsplash.com/photo-1449614115178-cb924f730780?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=1080&fit=max\",\n        \"small\": \"https://images.unsplash.com/photo-1449614115178-cb924f730780?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=400&fit=max\",\n        \"thumb\": \"https://images.unsplash.com/photo-1449614115178-cb924f730780?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=200&fit=max\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/photos/C-mxLOk6ANs\",\n        \"html\": \"https://unsplash.com/photos/C-mxLOk6ANs\",\n        \"download\": \"https://unsplash.com/photos/C-mxLOk6ANs/download\"\n      }\n    },\n    \"user\": {\n      \"id\": \"IFcEhJqem0Q\",\n      \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n      \"username\": \"fableandfolk\",\n      \"name\": \"Annie Spratt\",\n      \"portfolio_url\": \"http://mammasaurus.co.uk\",\n      \"bio\": \"Follow me on Twitter &amp; Instagram @anniespratt\\r\\nEmail me at hello@fableandfolk.com\",\n      \"location\": \"New Forest National Park, UK\",\n      \"total_likes\": 0,\n      \"total_photos\": 273,\n      \"total_collections\": 36,\n      \"profile_image\": {\n        \"small\": \"https://images.unsplash.com/profile-1450003783594-db47c765cea3?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=32&w=32\",\n        \"medium\": \"https://images.unsplash.com/profile-1450003783594-db47c765cea3?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=64&w=64\",\n        \"large\": \"https://images.unsplash.com/profile-1450003783594-db47c765cea3?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=128&w=128\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/users/fableandfolk\",\n        \"html\": \"https://unsplash.com/fableandfolk\",\n        \"photos\": \"https://api.unsplash.com/users/fableandfolk/photos\",\n        \"likes\": \"https://api.unsplash.com/users/fableandfolk/likes\",\n        \"portfolio\": \"https://api.unsplash.com/users/fableandfolk/portfolio\"\n      }\n    },\n    \"links\": {\n      \"self\": \"https://api.unsplash.com/collections/296\",\n      \"html\": \"https://unsplash.com/collections/296\",\n      \"photos\": \"https://api.unsplash.com/collections/296/photos\",\n      \"related\": \"https://api.unsplash.com/collections/296/related\"\n    }\n  },\n  // ... more Collections ...\n]\n\nCreate a new collection\nCreate a new collection. This requires the write_collections scope.\n\nPOST /collections\nParameters\nparam\tDescription\ntitle\tThe title of the collection. (Required.)\ndescription\tThe collection’s description. (Optional.)\nprivate\tWhether to make this collection private. (Optional; default false).\nResponse\nResponds with the new collection:\n\n201 Created\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n{\n  \"id\": 206,\n  \"title\": \"Makers: Cat and Ben\",\n  \"description\": \"Behind-the-scenes photos from the Makers interview with designers Cat Noone and Benedikt Lehnert.\",\n  \"published_at\": \"2016-01-12T18:16:09-05:00\",\n  \"last_collected_at\": \"2016-06-02T13:10:03-04:00\",\n  \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n  \"featured\": false,\n  \"total_photos\": 12,\n  \"private\": false,\n  \"share_key\": \"312d188df257b957f8b86d2ce20e4766\",\n  \"cover_photo\": null,\n  \"user\": null,\n  \"links\": {\n    \"self\": \"https://api.unsplash.com/collections/206\",\n    \"html\": \"https://unsplash.com/collections/206/makers-cat-and-ben\",\n    \"photos\": \"https://api.unsplash.com/collections/206/photos\"\n  }\n}\n\nUpdate an existing collection\nUpdate an existing collection belonging to the logged-in user. This requires the write_collections scope.\n\nPUT /collections/:id\nParameters\nparam\tDescription\ntitle\tThe title of the collection. (Optional.)\ndescription\tThe collection’s description. (Optional.)\nprivate\tWhether to make this collection private. (Optional.)\nResponse\nResponds with the updated collection:\n\n200 OK\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n{\n  \"id\": 206,\n  \"title\": \"Makers: Cat and Ben\",\n  \"description\": \"Behind-the-scenes photos from the Makers interview with designers Cat Noone and Benedikt Lehnert.\",\n  \"published_at\": \"2016-01-12T18:16:09-05:00\",\n  \"last_collected_at\": \"2016-06-02T13:10:03-04:00\",\n  \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n  \"featured\": false,\n  \"total_photos\": 12,\n  \"private\": false,\n  \"share_key\": \"312d188df257b957f8b86d2ce20e4766\",\n  \"cover_photo\": null,\n  \"user\": null,\n  \"links\": {\n    \"self\": \"https://api.unsplash.com/collections/206\",\n    \"html\": \"https://unsplash.com/collections/206/makers-cat-and-ben\",\n    \"photos\": \"https://api.unsplash.com/collections/206/photos\"\n  }\n}\n\nDelete a collection\nDelete a collection belonging to the logged-in user. This requires the write_collections scope.\n\nDELETE /collections/:id\nParameters\nparam\tDescription\nid\tThe collection’s ID. Required.\nResponse\nResponds with a 204 status and an empty body.\n\n204 No Content\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\nAdd a photo to a collection\nAdd a photo to one of the logged-in user’s collections. Requires the write_collections scope.\n\nPOST /collections/:collection_id/add\nNote: If the photo is already in the collection, this acion has no effect.\n\nParameters\nparam\tDescription\ncollection_id\tThe collection’s ID. Required.\nphoto_id\tThe photo’s ID. Required.\nResponse\n201 Created\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n{\n  \"photo\": {\n    \"id\": \"cnwIyn_BTkc\",\n    \"created_at\": \"2016-05-03T11:00:28-04:00\",\n    \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n    \"width\": 1024,\n    \"height\": 768,\n    \"color\": \"#ABC123\",\n    \"blur_hash\": \"LPF#XMx]jGVs0gNGodt7R4RjS4s;\",\n    \"likes\": 12,\n    \"liked_by_user\": false,\n    \"description\": \"A man drinking a coffee.\",\n    \"user\": {\n      \"id\": \"OuzxrCITLj8\",\n      \"username\": \"aaron\",\n      \"name\": \"Aaron K\",\n      \"portfolio_url\": \"http://www.outerspacehero.com/\",\n      \"bio\": \"Buildin' Unsplash.\",\n      \"location\": \"Winnipeg\",\n      \"total_likes\": 0,\n      \"total_photos\": 0,\n      \"total_collections\": 1,\n      \"profile_image\": {\n        \"small\": \"https://images.unsplash.com/profile-1444840959767-6286d046f7f2?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=32&w=32\",\n        \"medium\": \"https://images.unsplash.com/profile-1444840959767-6286d046f7f2?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=64&w=64\",\n        \"large\": \"https://images.unsplash.com/profile-1444840959767-6286d046f7f2?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=128&w=128\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/users/aaron\",\n        \"html\": \"https://unsplash.com/aaron\",\n        \"photos\": \"https://api.unsplash.com/users/aaron/photos\",\n        \"likes\": \"https://api.unsplash.com/users/aaron/likes\",\n        \"portfolio\": \"https://api.unsplash.com/users/aaron/portfolio\"\n      }\n    },\n    \"current_user_collections\": [ // The *current user's* collections that this photo belongs to.\n      {\n        \"id\": 206,\n        \"title\": \"Makers: Cat and Ben\",\n        \"description\": \"Behind-the-scenes photos from the Makers interview with designers Cat Noone and Benedikt Lehnert.\",\n        \"published_at\": \"2016-01-12T18:16:09-05:00\",\n        \"last_collected_at\": \"2016-06-02T13:10:03-04:00\",\n        \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n        \"cover_photo\": null,\n        \"user\": null,\n      },\n      // ... more collections\n    ],\n    \"urls\": {\n      \"raw\":  \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e\",\n      \"full\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy\",\n      \"regular\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=1080&fit=max\",\n      \"small\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=400&fit=max\",\n      \"thumb\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=200&fit=max\"\n    },\n    \"links\": {\n      \"self\": \"https://api.unsplash.com/photos/cnwIyn_BTkc\",\n      \"html\": \"https://unsplash.com/photos/cnwIyn_BTkc\",\n      \"download\": \"https://unsplash.com/photos/cnwIyn_BTkc/download\"\n      \"download_location\": \"https://api.unsplash.com/photos/cnwIyn_BTkc/download\"\n    }\n  },\n  \"collection\": {\n    \"id\": 298,\n    \"title\": \"API test\",\n    \"description\": \"Even API need photos.\",\n    \"published_at\": \"2016-02-29T15:46:20-05:00\",\n    \"last_collected_at\": \"2016-06-02T13:10:03-04:00\",\n    \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n    \"total_photos\": 12,\n    \"private\": false,\n    \"share_key\", \"312d188df257b957f8b86d2ce20e4766\"\n    \"cover_photo\": {\n      \"id\": \"cnwIyn_BTkc\",\n      \"width\": null,\n      \"height\": null,\n      \"color\": null,\n      \"blur_hash\": \"LPF#XMx]jGVs0gNGodt7R4RjS4s;\",\n      \"user\": {\n        \"id\": \"OuzxrCITLj8\",\n        \"username\": \"aaron\",\n        \"name\": \"Aaron K\",\n        \"profile_image\": {\n          \"small\": \"https://images.unsplash.com/profile-1444840959767-6286d046f7f2?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=32&w=32\",\n          \"medium\": \"https://images.unsplash.com/profile-1444840959767-6286d046f7f2?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=64&w=64\",\n          \"large\": \"https://images.unsplash.com/profile-1444840959767-6286d046f7f2?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=128&w=128\"\n        },\n        \"links\": {\n          \"self\": \"https://api.unsplash.com/users/aaron\",\n          \"html\": \"https://unsplash.com/aaron\",\n          \"photos\": \"https://api.unsplash.com/users/aaron/photos\",\n          \"likes\": \"https://api.unsplash.com/users/aaron/likes\",\n          \"portfolio\": \"https://api.unsplash.com/users/aaron/portfolio\"\n        }\n      },\n      \"urls\": {\n        \"full\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy\",\n        \"regular\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=1080&fit=max\",\n        \"small\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=400&fit=max\",\n        \"thumb\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=200&fit=max\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/photos/cnwIyn_BTkc\",\n        \"html\": \"https://unsplash.com/photos/cnwIyn_BTkc\",\n        \"download\": \"https://unsplash.com/photos/cnwIyn_BTkc/download\"\n        \"download_location\": \"https://api.unsplash.com/photos/cnwIyn_BTkc/download\"\n      }\n    },\n    \"user\": {\n      \"id\": \"Z4hPZdsRla8\",\n      \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n      \"username\": \"oscartothekeys\",\n      \"name\": \"Oscar Keys\",\n      \"bio\": \"simple is beautiful\",\n      \"profile_image\": {\n        \"small\": \"https://images.unsplash.com/profile-1453284965521-5bd2363623de?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=32&w=32\",\n        \"medium\": \"https://images.unsplash.com/profile-1453284965521-5bd2363623de?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=64&w=64\",\n        \"large\": \"https://images.unsplash.com/profile-1453284965521-5bd2363623de?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=128&w=128\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/users/oscartothekeys\",\n        \"html\": \"https://unsplash.com/oscartothekeys\",\n        \"photos\": \"https://api.unsplash.com/users/oscartothekeys/photos\",\n        \"likes\": \"https://api.unsplash.com/users/oscartothekeys/likes\",\n        \"portfolio\": \"https://api.unsplash.com/users/oscartothekeys/portfolio\"\n      }\n    },\n    \"links\": {\n      \"self\": \"https://api.unsplash.com/collections/298\",\n      \"html\": \"https://unsplash.com/collections/298\",\n      \"photos\": \"https://api.unsplash.com/collections/298/photos\"\n    }\n  },\n  \"user\": {\n    \"id\": \"Z4hPZdsRla8\",\n    \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n    \"username\": \"oscartothekeys\",\n    \"name\": \"Oscar Keys\",\n    \"profile_image\": {\n      \"small\": \"https://images.unsplash.com/profile-1453284965521-5bd2363623de?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=32&w=32\",\n      \"medium\": \"https://images.unsplash.com/profile-1453284965521-5bd2363623de?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=64&w=64\",\n      \"large\": \"https://images.unsplash.com/profile-1453284965521-5bd2363623de?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=128&w=128\"\n    },\n    \"links\": {\n      \"self\": \"https://api.unsplash.com/users/oscartothekeys\",\n      \"html\": \"https://unsplash.com/oscartothekeys\",\n      \"photos\": \"https://api.unsplash.com/users/oscartothekeys/photos\",\n      \"likes\": \"https://api.unsplash.com/users/oscartothekeys/likes\",\n      \"portfolio\": \"https://api.unsplash.com/users/oscartothekeys/portfolio\"\n    }\n  },\n  \"created_at\": \"2016-02-29T15:47:39.969-05:00\"\n}\n\nRemove a photo from a collection\nRemove a photo from one of the logged-in user’s collections. Requires the write_collections scope.\n\nDELETE /collections/:collection_id/remove\nParameters\nparam\tDescription\ncollection_id\tThe collection’s ID. Required.\nphoto_id\tThe photo’s ID. Required.\nResponse\n200 Success\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n{\n  \"photo\": {\n    \"id\": \"cnwIyn_BTkc\",\n    \"created_at\": \"2016-05-03T11:00:28-04:00\",\n    \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n    \"width\": 1024,\n    \"height\": 768,\n    \"color\": \"#ABC123\",\n    \"blur_hash\": \"LPF#XMx]jGVs0gNGodt7R4RjS4s;\",\n    \"likes\": 12,\n    \"liked_by_user\": false,\n    \"description\": \"A man drinking a coffee.\",\n    \"user\": {\n      \"id\": \"OuzxrCITLj8\",\n      \"username\": \"aaron\",\n      \"name\": \"Aaron K\",\n      \"portfolio_url\": \"http://www.outerspacehero.com/\",\n      \"bio\": \"Buildin' Unsplash.\",\n      \"location\": \"Winnipeg\",\n      \"total_likes\": 0,\n      \"total_photos\": 0,\n      \"total_collections\": 1,\n      \"profile_image\": {\n        \"small\": \"https://images.unsplash.com/profile-1444840959767-6286d046f7f2?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=32&w=32\",\n        \"medium\": \"https://images.unsplash.com/profile-1444840959767-6286d046f7f2?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=64&w=64\",\n        \"large\": \"https://images.unsplash.com/profile-1444840959767-6286d046f7f2?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=128&w=128\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/users/aaron\",\n        \"html\": \"https://unsplash.com/aaron\",\n        \"photos\": \"https://api.unsplash.com/users/aaron/photos\",\n        \"likes\": \"https://api.unsplash.com/users/aaron/likes\",\n        \"portfolio\": \"https://api.unsplash.com/users/aaron/portfolio\"\n      }\n    },\n    \"current_user_collections\": [ // The *current user's* collections that this photo belongs to.\n      {\n        \"id\": 206,\n        \"title\": \"Makers: Cat and Ben\",\n        \"description\": \"Behind-the-scenes photos from the Makers interview with designers Cat Noone and Benedikt Lehnert.\",\n        \"published_at\": \"2016-01-12T18:16:09-05:00\",\n        \"last_collected_at\": \"2016-06-02T13:10:03-04:00\",\n        \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n        \"cover_photo\": null,\n        \"user\": null,\n      },\n      // ... more collections\n    ],\n    \"urls\": {\n      \"raw\":  \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e\",\n      \"full\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy\",\n      \"regular\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=1080&fit=max\",\n      \"small\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=400&fit=max\",\n      \"thumb\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=200&fit=max\"\n    },\n    \"links\": {\n      \"self\": \"https://api.unsplash.com/photos/cnwIyn_BTkc\",\n      \"html\": \"https://unsplash.com/photos/cnwIyn_BTkc\",\n      \"download\": \"https://unsplash.com/photos/cnwIyn_BTkc/download\"\n      \"download_location\": \"https://api.unsplash.com/photos/cnwIyn_BTkc/download\"\n    }\n  },\n  \"collection\": {\n    \"id\": 298,\n    \"title\": \"API test\",\n    \"description\": \"Even API need photos.\",\n    \"published_at\": \"2016-02-29T15:46:20-05:00\",\n    \"last_collected_at\": \"2016-06-02T13:10:03-04:00\",\n    \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n    \"total_photos\": 12,\n    \"private\": false,\n    \"share_key\", \"312d188df257b957f8b86d2ce20e4766\"\n    \"cover_photo\": {\n      \"id\": \"cnwIyn_BTkc\",\n      \"width\": null,\n      \"height\": null,\n      \"color\": null,\n      \"blur_hash\": \"LPF#XMx]jGVs0gNGodt7R4RjS4s;\",\n      \"user\": {\n        \"id\": \"OuzxrCITLj8\",\n        \"username\": \"aaron\",\n        \"name\": \"Aaron K\",\n        \"profile_image\": {\n          \"small\": \"https://images.unsplash.com/profile-1444840959767-6286d046f7f2?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=32&w=32\",\n          \"medium\": \"https://images.unsplash.com/profile-1444840959767-6286d046f7f2?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=64&w=64\",\n          \"large\": \"https://images.unsplash.com/profile-1444840959767-6286d046f7f2?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=128&w=128\"\n        },\n        \"links\": {\n          \"self\": \"https://api.unsplash.com/users/aaron\",\n          \"html\": \"https://unsplash.com/aaron\",\n          \"photos\": \"https://api.unsplash.com/users/aaron/photos\",\n          \"likes\": \"https://api.unsplash.com/users/aaron/likes\",\n          \"portfolio\": \"https://api.unsplash.com/users/aaron/portfolio\"\n        }\n      },\n      \"urls\": {\n        \"full\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy\",\n        \"regular\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=1080&fit=max\",\n        \"small\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=400&fit=max\",\n        \"thumb\": \"https://images.unsplash.com/photo-1454625233598-f29d597eea1e?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&w=200&fit=max\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/photos/cnwIyn_BTkc\",\n        \"html\": \"https://unsplash.com/photos/cnwIyn_BTkc\",\n        \"download\": \"https://unsplash.com/photos/cnwIyn_BTkc/download\"\n        \"download_location\": \"https://api.unsplash.com/photos/cnwIyn_BTkc/download\"\n      }\n    },\n    \"user\": {\n      \"id\": \"Z4hPZdsRla8\",\n      \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n      \"username\": \"oscartothekeys\",\n      \"name\": \"Oscar Keys\",\n      \"bio\": \"simple is beautiful\",\n      \"profile_image\": {\n        \"small\": \"https://images.unsplash.com/profile-1453284965521-5bd2363623de?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=32&w=32\",\n        \"medium\": \"https://images.unsplash.com/profile-1453284965521-5bd2363623de?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=64&w=64\",\n        \"large\": \"https://images.unsplash.com/profile-1453284965521-5bd2363623de?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=128&w=128\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/users/oscartothekeys\",\n        \"html\": \"https://unsplash.com/oscartothekeys\",\n        \"photos\": \"https://api.unsplash.com/users/oscartothekeys/photos\",\n        \"likes\": \"https://api.unsplash.com/users/oscartothekeys/likes\",\n        \"portfolio\": \"https://api.unsplash.com/users/oscartothekeys/portfolio\"\n      }\n    },\n    \"links\": {\n      \"self\": \"https://api.unsplash.com/collections/298\",\n      \"html\": \"https://unsplash.com/collections/298\",\n      \"photos\": \"https://api.unsplash.com/collections/298/photos\"\n    }\n  },\n  \"user\": {\n    \"id\": \"Z4hPZdsRla8\",\n    \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n    \"username\": \"oscartothekeys\",\n    \"name\": \"Oscar Keys\",\n    \"profile_image\": {\n      \"small\": \"https://images.unsplash.com/profile-1453284965521-5bd2363623de?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=32&w=32\",\n      \"medium\": \"https://images.unsplash.com/profile-1453284965521-5bd2363623de?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=64&w=64\",\n      \"large\": \"https://images.unsplash.com/profile-1453284965521-5bd2363623de?ixlib=rb-0.3.5&q=80&fm=jpg&crop=faces&fit=crop&h=128&w=128\"\n    },\n    \"links\": {\n      \"self\": \"https://api.unsplash.com/users/oscartothekeys\",\n      \"html\": \"https://unsplash.com/oscartothekeys\",\n      \"photos\": \"https://api.unsplash.com/users/oscartothekeys/photos\",\n      \"likes\": \"https://api.unsplash.com/users/oscartothekeys/likes\",\n      \"portfolio\": \"https://api.unsplash.com/users/oscartothekeys/portfolio\"\n    }\n  },\n  \"created_at\": \"2016-02-29T15:47:39.969-05:00\"\n}\n\nTopics\nLink relations\nTopics have the following link relations:\n\nrel\tDescription\nself\tAPI location of this topic.\nhtml\tHTML location of this topic.\nphotos\tAPI location of this topic’s photos.\nList topics\nGet a single page from the list of all topics.\n\nGET /topics\nNote: See the note on hotlinking.\n\nParameters\nparam\tDescription\nids\tLimit to only matching topic ids or slugs. (Optional; Comma separated string)\npage\tPage number to retrieve. (Optional; default: 1)\nper_page\tNumber of items per page. (Optional; default: 10)\norder_by\tHow to sort the topics. (Optional; Valid values: featured, latest, oldest, position; default: position)\nResponse\n200 OK\nLink: <https://api.unsplash.com/topics?page=3>; rel=\"last\", <https://api.unsplash.com/topics?page=2>; rel=\"next\"\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n[\n  {\n    \"id\": \"bo8jQKTaE0Y\",\n    \"slug\": \"wallpapers\",\n    \"title\": \"Wallpapers\",\n    \"description\": \"From epic drone shots to inspiring moments in nature, find free HD wallpapers worthy of your mobile and desktop screens. Finally.\",\n    \"published_at\": \"2020-04-17T02:31:04Z\",\n    \"updated_at\": \"2020-09-22T07:37:55-04:00\",\n    \"starts_at\": \"2020-04-15T00:00:00Z\",\n    \"ends_at\": null,\n    \"only_submissions_after\": null,\n    \"visibility\": \"featured\",\n    \"featured\": true,\n    \"total_photos\": 5296,\n    \"links\": {\n      \"self\": \"https://api.unsplash.com/topics/wallpapers\",\n      \"html\": \"https://unsplash.com/t/wallpapers\",\n      \"photos\": \"https://api.unsplash.com/topics/wallpapers/photos\"\n    },\n    \"status\": \"open\",\n    \"owners\": [\n      {\n        \"id\": \"QV5S1rtoUJ0\",\n        \"updated_at\": \"2020-09-22T10:49:58-04:00\",\n        \"username\": \"unsplash\",\n        \"name\": \"Unsplash\",\n        \"first_name\": \"Unsplash\",\n        \"last_name\": null,\n        \"twitter_username\": \"unsplash\",\n        \"portfolio_url\": \"https://unsplash.com\",\n        \"bio\": \"Behind the scenes of the team building the internet’s open library of freely useable visuals.\",\n        \"location\": \"Montreal, Canada\",\n        \"links\": {\n          \"self\": \"https://api.unsplash.com/users/unsplash\",\n          \"html\": \"https://unsplash.com/@unsplash\",\n          \"photos\": \"https://api.unsplash.com/users/unsplash/photos\",\n          \"likes\": \"https://api.unsplash.com/users/unsplash/likes\",\n          \"portfolio\": \"https://api.unsplash.com/users/unsplash/portfolio\",\n          \"following\": \"https://api.unsplash.com/users/unsplash/following\",\n          \"followers\": \"https://api.unsplash.com/users/unsplash/followers\"\n        },\n        \"profile_image\": {\n          \"small\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=32&w=32\",\n          \"medium\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=64&w=64\",\n          \"large\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=128&w=128\"\n        },\n        \"instagram_username\": \"unsplash\",\n        \"total_collections\": 22,\n        \"total_likes\": 16720,\n        \"total_photos\": 29,\n        \"accepted_tos\": true\n      }\n    ],\n    \"current_user_contributions\": [],\n    \"total_current_user_submissions\": {},\n    \"cover_photo\": {\n      \"id\": \"0q_YtRanczI\",\n      \"created_at\": \"2018-10-26T03:24:18-04:00\",\n      \"updated_at\": \"2020-06-21T01:10:35-04:00\",\n      \"promoted_at\": null,\n      \"width\": 3992,\n      \"height\": 2992,\n      \"color\": \"#CBCAC8\",\n      \"blur_hash\": \"LEBpFJRk5TR+5toJ^ia#0KfPIoxY\",\n      \"description\": \"Greek villa by the coast\",\n      \"alt_description\": \"aerial view of city\",\n      \"urls\": {\n        \"raw\": \"https://images.unsplash.com/photo-1540538581514-1d465aaad58c?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9\",\n        \"full\": \"https://images.unsplash.com/photo-1540538581514-1d465aaad58c?ixlib=rb-1.2.1&q=85&fm=jpg&crop=entropy&cs=srgb&ixid=eyJhcHBfaWQiOjEyMDd9\",\n        \"regular\": \"https://images.unsplash.com/photo-1540538581514-1d465aaad58c?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max&ixid=eyJhcHBfaWQiOjEyMDd9\",\n        \"small\": \"https://images.unsplash.com/photo-1540538581514-1d465aaad58c?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=400&fit=max&ixid=eyJhcHBfaWQiOjEyMDd9\",\n        \"thumb\": \"https://images.unsplash.com/photo-1540538581514-1d465aaad58c?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max&ixid=eyJhcHBfaWQiOjEyMDd9\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/photos/0q_YtRanczI\",\n        \"html\": \"https://unsplash.com/photos/0q_YtRanczI\",\n        \"download\": \"https://unsplash.com/photos/0q_YtRanczI/download\",\n        \"download_location\": \"https://api.unsplash.com/photos/0q_YtRanczI/download\"\n      },\n      \"user\": {\n        \"id\": \"QV5S1rtoUJ0\",\n        \"updated_at\": \"2020-09-22T10:49:58-04:00\",\n        \"username\": \"unsplash\",\n        \"name\": \"Unsplash\",\n        \"first_name\": \"Unsplash\",\n        \"last_name\": null,\n        \"twitter_username\": \"unsplash\",\n        \"portfolio_url\": \"https://unsplash.com\",\n        \"bio\": \"Behind the scenes of the team building the internet’s open library of freely useable visuals.\",\n        \"location\": \"Montreal, Canada\",\n        \"links\": {\n          \"self\": \"https://api.unsplash.com/users/unsplash\",\n          \"html\": \"https://unsplash.com/@unsplash\",\n          \"photos\": \"https://api.unsplash.com/users/unsplash/photos\",\n          \"likes\": \"https://api.unsplash.com/users/unsplash/likes\",\n          \"portfolio\": \"https://api.unsplash.com/users/unsplash/portfolio\",\n          \"following\": \"https://api.unsplash.com/users/unsplash/following\",\n          \"followers\": \"https://api.unsplash.com/users/unsplash/followers\"\n        },\n        \"profile_image\": {\n          \"small\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=32&w=32\",\n          \"medium\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=64&w=64\",\n          \"large\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=128&w=128\"\n        },\n        \"instagram_username\": \"unsplash\",\n        \"total_collections\": 22,\n        \"total_likes\": 16720,\n        \"total_photos\": 29,\n        \"accepted_tos\": true\n    },\n    \"preview_photos\": [\n      {\n        \"id\": \"8AceP6OOF3o\",\n        \"created_at\": \"2017-05-28T09:48:24-04:00\",\n        \"updated_at\": \"2020-09-22T09:45:00-04:00\",\n        \"urls\": {\n          \"raw\": \"https://images.unsplash.com/photo-1495978866932-92dbc079e62e?ixlib=rb-1.2.1\",\n          \"full\": \"https://images.unsplash.com/photo-1495978866932-92dbc079e62e?ixlib=rb-1.2.1&q=85&fm=jpg&crop=entropy&cs=srgb\",\n          \"regular\": \"https://images.unsplash.com/photo-1495978866932-92dbc079e62e?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max\",\n          \"small\": \"https://images.unsplash.com/photo-1495978866932-92dbc079e62e?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=400&fit=max\",\n          \"thumb\": \"https://images.unsplash.com/photo-1495978866932-92dbc079e62e?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max\"\n        }\n      },\n      {\n        \"id\": \"iHJOHaUD8RY\",\n        \"created_at\": \"2016-11-13T04:50:11-05:00\",\n        \"updated_at\": \"2020-09-22T09:31:58-04:00\",\n        \"urls\": {\n          \"raw\": \"https://images.unsplash.com/photo-1479030574009-1e48577746e8?ixlib=rb-1.2.1\",\n          \"full\": \"https://images.unsplash.com/photo-1479030574009-1e48577746e8?ixlib=rb-1.2.1&q=85&fm=jpg&crop=entropy&cs=srgb\",\n          \"regular\": \"https://images.unsplash.com/photo-1479030574009-1e48577746e8?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max\",\n          \"small\": \"https://images.unsplash.com/photo-1479030574009-1e48577746e8?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=400&fit=max\",\n          \"thumb\": \"https://images.unsplash.com/photo-1479030574009-1e48577746e8?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max\"\n        }\n      },\n      {\n        \"id\": \"zMV7sqlJNow\",\n        \"created_at\": \"2016-12-28T10:24:02-05:00\",\n        \"updated_at\": \"2020-09-22T09:34:07-04:00\",\n        \"urls\": {\n          \"raw\": \"https://images.unsplash.com/photo-1482938289607-e9573fc25ebb?ixlib=rb-1.2.1\",\n          \"full\": \"https://images.unsplash.com/photo-1482938289607-e9573fc25ebb?ixlib=rb-1.2.1&q=85&fm=jpg&crop=entropy&cs=srgb\",\n          \"regular\": \"https://images.unsplash.com/photo-1482938289607-e9573fc25ebb?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max\",\n          \"small\": \"https://images.unsplash.com/photo-1482938289607-e9573fc25ebb?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=400&fit=max\",\n          \"thumb\": \"https://images.unsplash.com/photo-1482938289607-e9573fc25ebb?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max\"\n        }\n      },\n      {\n        \"id\": \"YD1uvthZwg4\",\n        \"created_at\": \"2015-12-03T17:39:24-05:00\",\n        \"updated_at\": \"2020-09-22T09:10:19-04:00\",\n        \"urls\": {\n          \"raw\": \"https://images.unsplash.com/photo-1449182325215-d517de72c42d?ixlib=rb-1.2.1\",\n          \"full\": \"https://images.unsplash.com/photo-1449182325215-d517de72c42d?ixlib=rb-1.2.1&q=85&fm=jpg&crop=entropy&cs=srgb\",\n          \"regular\": \"https://images.unsplash.com/photo-1449182325215-d517de72c42d?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max\",\n          \"small\": \"https://images.unsplash.com/photo-1449182325215-d517de72c42d?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=400&fit=max\",\n          \"thumb\": \"https://images.unsplash.com/photo-1449182325215-d517de72c42d?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max\"\n        }\n      }\n    ]\n  },\n  // ... more Topics ...\n]\n\nGet a topic\nRetrieve a single topic.\n\nGET /topics/:id_or_slug\nNote: See the note on hotlinking.\n\nParameters\nparam\tDescription\nid_or_slug\tThe topics’s ID or slug. Required.\nResponse\n200 OK\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n{\n  \"id\": \"bo8jQKTaE0Y\",\n  \"slug\": \"wallpapers\",\n  \"title\": \"Wallpapers\",\n  \"description\": \"From epic drone shots to inspiring moments in nature, find free HD wallpapers worthy of your mobile and desktop screens. Finally.\",\n  \"published_at\": \"2020-04-17T02:31:04Z\",\n  \"updated_at\": \"2020-07-06T09:12:07-04:00\",\n  \"starts_at\": \"2020-04-15T00:00:00Z\",\n  \"ends_at\": null,\n  \"only_submissions_after\": null,\n  \"visibility\": \"featured\",\n  \"featured\": true,\n  \"total_photos\": 5296,\n  \"links\": {\n    \"self\": \"https://api.unsplash.com/topics/wallpapers\",\n    \"html\": \"https://unsplash.com/t/wallpapers\",\n    \"photos\": \"https://api.unsplash.com/topics/wallpapers/photos\"\n  },\n  \"status\": \"open\",\n  \"owners\": [\n    {\n      \"id\": \"QV5S1rtoUJ0\",\n      \"updated_at\": \"2020-09-22T10:49:58-04:00\",\n      \"username\": \"unsplash\",\n      \"name\": \"Unsplash\",\n      \"first_name\": \"Unsplash\",\n      \"last_name\": null,\n      \"twitter_username\": \"unsplash\",\n      \"portfolio_url\": \"https://unsplash.com\",\n      \"bio\": \"Behind the scenes of the team building the internet’s open library of freely useable visuals.\",\n      \"location\": \"Montreal, Canada\",\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/users/unsplash\",\n        \"html\": \"https://unsplash.com/@unsplash\",\n        \"photos\": \"https://api.unsplash.com/users/unsplash/photos\",\n        \"likes\": \"https://api.unsplash.com/users/unsplash/likes\",\n        \"portfolio\": \"https://api.unsplash.com/users/unsplash/portfolio\",\n        \"following\": \"https://api.unsplash.com/users/unsplash/following\",\n        \"followers\": \"https://api.unsplash.com/users/unsplash/followers\"\n      },\n      \"profile_image\": {\n        \"small\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=32&w=32\",\n        \"medium\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=64&w=64\",\n        \"large\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=128&w=128\"\n      },\n      \"instagram_username\": \"unsplash\",\n      \"total_collections\": 22,\n      \"total_likes\": 16720,\n      \"total_photos\": 29,\n      \"accepted_tos\": true\n    }\n  ],\n  \"top_contributors\": [\n    {\n      \"id\": \"QV5S1rtoUJ0\",\n      \"updated_at\": \"2020-09-22T10:49:58-04:00\",\n      \"username\": \"unsplash\",\n      \"name\": \"Unsplash\",\n      \"first_name\": \"Unsplash\",\n      \"last_name\": null,\n      \"twitter_username\": \"unsplash\",\n      \"portfolio_url\": \"https://unsplash.com\",\n      \"bio\": \"Behind the scenes of the team building the internet’s open library of freely useable visuals.\",\n      \"location\": \"Montreal, Canada\",\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/users/unsplash\",\n        \"html\": \"https://unsplash.com/@unsplash\",\n        \"photos\": \"https://api.unsplash.com/users/unsplash/photos\",\n        \"likes\": \"https://api.unsplash.com/users/unsplash/likes\",\n        \"portfolio\": \"https://api.unsplash.com/users/unsplash/portfolio\",\n        \"following\": \"https://api.unsplash.com/users/unsplash/following\",\n        \"followers\": \"https://api.unsplash.com/users/unsplash/followers\"\n      },\n      \"profile_image\": {\n        \"small\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=32&w=32\",\n        \"medium\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=64&w=64\",\n        \"large\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=128&w=128\"\n      },\n      \"instagram_username\": \"unsplash\",\n      \"total_collections\": 22,\n      \"total_likes\": 16720,\n      \"total_photos\": 29,\n      \"accepted_tos\": true\n    },\n    // ... more top topic contributors ...\n  ],\n  \"cover_photo\": {\n    \"id\": \"0q_YtRanczI\",\n    \"created_at\": \"2018-10-26T03:24:18-04:00\",\n    \"updated_at\": \"2020-06-21T01:10:35-04:00\",\n    \"promoted_at\": null,\n    \"width\": 3992,\n    \"height\": 2992,\n    \"color\": \"#CBCAC8\",\n    \"blur_hash\": \"LEBpFJRk5TR+5toJ^ia#0KfPIoxY\",\n    \"description\": \"Greek villa by the coast\",\n    \"alt_description\": \"aerial view of city\",\n    \"urls\": {\n      \"raw\": \"https://images.unsplash.com/photo-1540538581514-1d465aaad58c?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9\",\n      \"full\": \"https://images.unsplash.com/photo-1540538581514-1d465aaad58c?ixlib=rb-1.2.1&q=85&fm=jpg&crop=entropy&cs=srgb&ixid=eyJhcHBfaWQiOjEyMDd9\",\n      \"regular\": \"https://images.unsplash.com/photo-1540538581514-1d465aaad58c?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max&ixid=eyJhcHBfaWQiOjEyMDd9\",\n      \"small\": \"https://images.unsplash.com/photo-1540538581514-1d465aaad58c?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=400&fit=max&ixid=eyJhcHBfaWQiOjEyMDd9\",\n      \"thumb\": \"https://images.unsplash.com/photo-1540538581514-1d465aaad58c?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max&ixid=eyJhcHBfaWQiOjEyMDd9\"\n    },\n    \"links\": {\n      \"self\": \"https://api.unsplash.com/photos/0q_YtRanczI\",\n      \"html\": \"https://unsplash.com/photos/0q_YtRanczI\",\n      \"download\": \"https://unsplash.com/photos/0q_YtRanczI/download\",\n      \"download_location\": \"https://api.unsplash.com/photos/0q_YtRanczI/download\"\n    },\n    \"user\": {\n      \"id\": \"QV5S1rtoUJ0\",\n      \"updated_at\": \"2020-09-22T10:49:58-04:00\",\n      \"username\": \"unsplash\",\n      \"name\": \"Unsplash\",\n      \"first_name\": \"Unsplash\",\n      \"last_name\": null,\n      \"twitter_username\": \"unsplash\",\n      \"portfolio_url\": \"https://unsplash.com\",\n      \"bio\": \"Behind the scenes of the team building the internet’s open library of freely useable visuals.\",\n      \"location\": \"Montreal, Canada\",\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/users/unsplash\",\n        \"html\": \"https://unsplash.com/@unsplash\",\n        \"photos\": \"https://api.unsplash.com/users/unsplash/photos\",\n        \"likes\": \"https://api.unsplash.com/users/unsplash/likes\",\n        \"portfolio\": \"https://api.unsplash.com/users/unsplash/portfolio\",\n        \"following\": \"https://api.unsplash.com/users/unsplash/following\",\n        \"followers\": \"https://api.unsplash.com/users/unsplash/followers\"\n      },\n      \"profile_image\": {\n        \"small\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=32&w=32\",\n        \"medium\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=64&w=64\",\n        \"large\": \"https://images.unsplash.com/profile-1544707963613-16baf868f301?ixlib=rb-1.2.1&q=80&fm=jpg&crop=faces&cs=tinysrgb&fit=crop&h=128&w=128\"\n      },\n      \"instagram_username\": \"unsplash\",\n      \"total_collections\": 22,\n      \"total_likes\": 16720,\n      \"total_photos\": 29,\n      \"accepted_tos\": true\n  },\n  \"preview_photos\": [\n    {\n      \"id\": \"8AceP6OOF3o\",\n      \"created_at\": \"2017-05-28T09:48:24-04:00\",\n      \"updated_at\": \"2020-09-22T09:45:00-04:00\",\n      \"urls\": {\n        \"raw\": \"https://images.unsplash.com/photo-1495978866932-92dbc079e62e?ixlib=rb-1.2.1\",\n        \"full\": \"https://images.unsplash.com/photo-1495978866932-92dbc079e62e?ixlib=rb-1.2.1&q=85&fm=jpg&crop=entropy&cs=srgb\",\n        \"regular\": \"https://images.unsplash.com/photo-1495978866932-92dbc079e62e?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max\",\n        \"small\": \"https://images.unsplash.com/photo-1495978866932-92dbc079e62e?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=400&fit=max\",\n        \"thumb\": \"https://images.unsplash.com/photo-1495978866932-92dbc079e62e?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max\"\n      }\n    },\n    {\n      \"id\": \"iHJOHaUD8RY\",\n      \"created_at\": \"2016-11-13T04:50:11-05:00\",\n      \"updated_at\": \"2020-09-22T09:31:58-04:00\",\n      \"urls\": {\n        \"raw\": \"https://images.unsplash.com/photo-1479030574009-1e48577746e8?ixlib=rb-1.2.1\",\n        \"full\": \"https://images.unsplash.com/photo-1479030574009-1e48577746e8?ixlib=rb-1.2.1&q=85&fm=jpg&crop=entropy&cs=srgb\",\n        \"regular\": \"https://images.unsplash.com/photo-1479030574009-1e48577746e8?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max\",\n        \"small\": \"https://images.unsplash.com/photo-1479030574009-1e48577746e8?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=400&fit=max\",\n        \"thumb\": \"https://images.unsplash.com/photo-1479030574009-1e48577746e8?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max\"\n      }\n    },\n    {\n      \"id\": \"zMV7sqlJNow\",\n      \"created_at\": \"2016-12-28T10:24:02-05:00\",\n      \"updated_at\": \"2020-09-22T09:34:07-04:00\",\n      \"urls\": {\n        \"raw\": \"https://images.unsplash.com/photo-1482938289607-e9573fc25ebb?ixlib=rb-1.2.1\",\n        \"full\": \"https://images.unsplash.com/photo-1482938289607-e9573fc25ebb?ixlib=rb-1.2.1&q=85&fm=jpg&crop=entropy&cs=srgb\",\n        \"regular\": \"https://images.unsplash.com/photo-1482938289607-e9573fc25ebb?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max\",\n        \"small\": \"https://images.unsplash.com/photo-1482938289607-e9573fc25ebb?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=400&fit=max\",\n        \"thumb\": \"https://images.unsplash.com/photo-1482938289607-e9573fc25ebb?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max\"\n      }\n    },\n    {\n      \"id\": \"YD1uvthZwg4\",\n      \"created_at\": \"2015-12-03T17:39:24-05:00\",\n      \"updated_at\": \"2020-09-22T09:10:19-04:00\",\n      \"urls\": {\n        \"raw\": \"https://images.unsplash.com/photo-1449182325215-d517de72c42d?ixlib=rb-1.2.1\",\n        \"full\": \"https://images.unsplash.com/photo-1449182325215-d517de72c42d?ixlib=rb-1.2.1&q=85&fm=jpg&crop=entropy&cs=srgb\",\n        \"regular\": \"https://images.unsplash.com/photo-1449182325215-d517de72c42d?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max\",\n        \"small\": \"https://images.unsplash.com/photo-1449182325215-d517de72c42d?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=400&fit=max\",\n        \"thumb\": \"https://images.unsplash.com/photo-1449182325215-d517de72c42d?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=200&fit=max\"\n      }\n    }\n  ]\n}\n\nGet a topic’s photos\nRetrieve a topic’s photos.\n\nGET /topics/:id_or_slug/photos\nNote: See the note on hotlinking.\n\nParameters\nparam\tDescription\nid_or_slug\tThe topics’s ID or slug. Required.\npage\tPage number to retrieve. (Optional; default: 1)\nper_page\tNumber of items per page. (Optional; default: 10)\norientation\tFilter by photo orientation. (Optional; Valid values: landscape, portrait, squarish)\norder_by\tHow to sort the photos. (Optional; Valid values: latest, oldest, popular; default: latest)\nResponse\n200 OK\nLink: <https://api.unsplash.com/topics/:id_or_slug/photos?page=530>; rel=\"last\", <https://api.unsplash.com/topics/:id_or_slug/photos?page=2>; rel=\"next\"\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n[\n  {\n    \"id\": \"LBI7cgq3pbM\",\n    \"created_at\": \"2016-05-03T11:00:28-04:00\",\n    \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n    \"width\": 5245,\n    \"height\": 3497,\n    \"color\": \"#60544D\",\n    \"blur_hash\": \"LoC%a7IoIVxZ_NM|M{s:%hRjWAo0\",\n    \"likes\": 12,\n    \"liked_by_user\": false,\n    \"description\": \"A man drinking a coffee.\",\n    \"user\": {\n      \"id\": \"pXhwzz1JtQU\",\n      \"username\": \"poorkane\",\n      \"name\": \"Gilbert Kane\",\n      \"portfolio_url\": \"https://theylooklikeeggsorsomething.com/\",\n      \"bio\": \"XO\",\n      \"location\": \"Way out there\",\n      \"total_likes\": 5,\n      \"total_photos\": 74,\n      \"total_collections\": 52,\n      \"instagram_username\": \"instantgrammer\",\n      \"twitter_username\": \"crew\",\n      \"profile_image\": {\n        \"small\": \"https://images.unsplash.com/face-springmorning.jpg?q=80&fm=jpg&crop=faces&fit=crop&h=32&w=32\",\n        \"medium\": \"https://images.unsplash.com/face-springmorning.jpg?q=80&fm=jpg&crop=faces&fit=crop&h=64&w=64\",\n        \"large\": \"https://images.unsplash.com/face-springmorning.jpg?q=80&fm=jpg&crop=faces&fit=crop&h=128&w=128\"\n      },\n      \"links\": {\n        \"self\": \"https://api.unsplash.com/users/poorkane\",\n        \"html\": \"https://unsplash.com/poorkane\",\n        \"photos\": \"https://api.unsplash.com/users/poorkane/photos\",\n        \"likes\": \"https://api.unsplash.com/users/poorkane/likes\",\n        \"portfolio\": \"https://api.unsplash.com/users/poorkane/portfolio\"\n      }\n    },\n    \"current_user_collections\": [ // The *current user's* collections that this photo belongs to.\n      {\n        \"id\": 206,\n        \"title\": \"Makers: Cat and Ben\",\n        \"published_at\": \"2016-01-12T18:16:09-05:00\",\n        \"last_collected_at\": \"2016-06-02T13:10:03-04:00\",\n        \"updated_at\": \"2016-07-10T11:00:01-05:00\",\n        \"cover_photo\": null,\n        \"user\": null\n      },\n      // ... more collections\n    ],\n    \"urls\": {\n      \"raw\": \"https://images.unsplash.com/face-springmorning.jpg\",\n      \"full\": \"https://images.unsplash.com/face-springmorning.jpg?q=75&fm=jpg\",\n      \"regular\": \"https://images.unsplash.com/face-springmorning.jpg?q=75&fm=jpg&w=1080&fit=max\",\n      \"small\": \"https://images.unsplash.com/face-springmorning.jpg?q=75&fm=jpg&w=400&fit=max\",\n      \"thumb\": \"https://images.unsplash.com/face-springmorning.jpg?q=75&fm=jpg&w=200&fit=max\"\n    },\n    \"links\": {\n      \"self\": \"https://api.unsplash.com/photos/LBI7cgq3pbM\",\n      \"html\": \"https://unsplash.com/photos/LBI7cgq3pbM\",\n      \"download\": \"https://unsplash.com/photos/LBI7cgq3pbM/download\",\n      \"download_location\": \"https://api.unsplash.com/photos/LBI7cgq3pbM/download\"\n    }\n  },\n  // ... more photos\n]\n\nStats\nTotals\nGet a list of counts for all of Unsplash.\n\nGET /stats/total\nResponse\n200 OK\nX-Ratelimit-Limit: 1000\nX-Ratelimit-Remaining: 999\n{\n  \"photos\": 10000,\n  \"downloads\": 2000,\n  \"views\": 5000,\n  \"likes\": 800,\n  \"photographers\": 100,\n  \"pixels\": 200000,\n  \"downloads_per_second\": 10, // average number of downloads per second for the past 7 days\n  \"views_per_second\": 20,  // average number of views per second for the past 7 days\n  \"developers\": 20,\n  \"applications\": 50,\n  \"requests\": 8000\n}\nreturn all files updated and cleaned in full so i can download it "
          },
          {
            "file_name": "paste-2.txt",
            "file_size": 28409,
            "file_type": "txt",
            "extracted_content": "eview this project and our files, our claude api key is in the environment variable: # Modular Slide‑Generation System (v2)\n\nA **robust, fully‑scriptable tool‑chain** for turning a plain facilitator guide into a polished Google Slides deck.\n\nfacilitator.md ───► guide_to_json.py ──► diagrams_to_images.py ──► update_images.py ──► build_slides.py\n                                  │                             │                      │\n                                  └───────────── slides.json  ◄─┴──────────────────────┘\n\n\n---\n\n## 0  Prerequisites\n\n|  Requirement   |  Install                                                                                                   |\n| -------------- | ---------------------------------------------------------------------------------------------------------- |\n|  Python ≥3.9   | brew install python or [https://python.org](https://python.org)                                          |\n|  Node ≥18      | nvm install 18 && nvm use 18                                                                             |\n|  Mermaid‑CLI   | npm i -g @mermaid-js/mermaid-cli                                                                         |\n|  pip install | google-auth-oauthlib google-api-python-client google-auth google-cloud-storage anthropic requests pillow |\n\nEnvironment variables:\n\\* ANTHROPIC_API_KEY – Claude access\n\\* FREEIMAGE_API_KEY – anonymous FreeImage.host uploads (v1)\n\nGoogle OAuth: create a **Desktop** OAuth client in Google Cloud → download JSON as oauth-client.json.\n\n---\n\n## 1  JSON Schema\n\nEach element in *slides.json* now contains **15 ordered keys**:\n\n`jsonc\n{\n  \"slide_number\"     : 1,\n  \"title\"            : \"Intro to PV\",            // ≤ 60 chars\n  \"content\"          : \"• Solar PV basics …\",   // ≤ 40 words per bullet‑line\n  \"chart_type\"       : null,\n  \"diagram_type\"     : \"flowchart\",\n  \"diagram_content\"  : \"flowchart TD …\",\n  \"image_description\": \"solar panels\",          // keyword used by fetcher\n  \"image_url\"        : null,                     // leave null unless using an Unsplash URL from the table\n  \"facilitator_notes\": \"Stress safety gear\",\n  \"start_time\"       : \"09:05\",\n  \"end_time\"         : \"09:15\",\n  \"materials\"        : \"Flip‑chart, markers\",\n  \"worksheet\"        : null,\n  \"improvements\"     : \"Add regional case study\",\n  \"notes\"            : \"\"\n}\njsonc\n{\n  \"slide_number\"     : 1,\n  \"title\"            : \"Intro to PV\",            // ≤ 60 chars\n  \"content\"          : \"• Solar PV basics …\",   // ≤ 40 words per bullet‑line\n  \"chart_type\"       : null,                     // bar, line, area … (for future data‑driven charts)\n  \"diagram_type\"     : \"flowchart\",              // or mindmap / pie / timeline …\n  \"diagram_content\"  : \"flowchart TD …\",         // Mermaid text\n  \"image_description\": \"Technician on roof\",     // alt‑text or Unsplash keyword\n  \"image_url\"        : null,                     // filled by later steps\n  \"facilitator_notes\": \"Stress safety gear\",\n  \"start_time\"       : \"09:05\",\n  \"end_time\"         : \"09:15\",\n  \"materials\"        : \"Flip‑chart, markers\",\n  \"worksheet\"        : null,\n  \"improvements\"     : \"Add regional case study\",\n  \"notes\"            : \"\"\n}\n`\n\n---\n\n## 2  Scripts\n\nBelow are **complete, runnable** source files.\n\n### 2.1 `guide_to_json.py`\npython\n#!/usr/bin/env python3\n\"\"\"Convert a facilitator guide into slides.json using Claude 3.\n\nUsage:\n  python guide_to_json.py guide.md \\\n      --prompt prompt-template.txt \\\n      --out slides.json \\\n      --log-level INFO \\\n      --log-file build.log\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys\nfrom pathlib import Path\nimport anthropic\n\nDEFAULT_OUT = \"slides.json\"\nDEFAULT_PROMPT = \"prompt-template.txt\"\n\nLOGGER = logging.getLogger(\"guide_to_json\")\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"LLM → JSON slide outline\")\n    p.add_argument(\"guide\", help=\"Facilitator guide (Markdown/text)\")\n    p.add_argument(\"--prompt\", default=DEFAULT_PROMPT, help=\"Prompt template path\")\n    p.add_argument(\"--out\", default=DEFAULT_OUT, help=\"Output JSON path\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None, help=\"Write logs to file as well\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers: list[logging.Handler] = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(\n        level=level,\n        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n        handlers=handlers,\n    )\n\n\ndef build_prompt(template_path: Path, guide_text: str) -> str:\n    tpl = template_path.read_text(encoding=\"utf-8\")\n    if \"{{content}}\" not in tpl:\n        LOGGER.error(\"Prompt template missing {{content}} placeholder → %s\", template_path)\n        sys.exit(1)\n    return tpl.replace(\"{{content}}\", guide_text)\n\n\n# Insert missing keys and correct ordering\nORDER = [\n    \"slide_number\", \"title\", \"content\", \"chart_type\", \"diagram_type\", \"diagram_content\",\n    \"image_description\", \"image_url\", \"facilitator_notes\", \"start_time\", \"end_time\",\n    \"materials\", \"worksheet\", \"improvements\", \"notes\",\n]\n\n\ndef normalize(slides: list[dict]) -> list[dict]:\n    fixed = []\n    for idx, raw in enumerate(slides, 1):\n        raw.setdefault(\"slide_number\", idx)\n        raw.setdefault(\"chart_type\", None)\n        raw.setdefault(\"image_description\", None)\n        raw.setdefault(\"image_url\", None)\n        for key in ORDER:\n            raw.setdefault(key, None)\n        fixed.append({k: raw.get(k) for k in ORDER})\n    return fixed\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n    if not api_key:\n        LOGGER.error(\"Set ANTHROPIC_API_KEY environment variable\")\n        sys.exit(1)\n\n    guide_path = Path(args.guide)\n    prompt_path = Path(args.prompt)\n    out_path = Path(args.out)\n\n    if not guide_path.exists() or not prompt_path.exists():\n        LOGGER.error(\"File not found: %s or %s\", guide_path, prompt_path)\n        sys.exit(1)\n\n    guide_txt = guide_path.read_text(encoding=\"utf-8\")\n    prompt = build_prompt(prompt_path, guide_txt)\n\n    LOGGER.info(\"Requesting Claude 3 …\")\n    client = anthropic.Anthropic(api_key=api_key)\n    rsp = client.messages.create(\n        model=\"claude-3-7-sonnet-20250219\",\n        max_tokens=16_000,\n        system=\"Return JSON only.\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n    )\n\n    raw = rsp.content[0].text\n    start = raw.find(\"[\")\n    if start == -1:\n        LOGGER.error(\"Claude response contained no JSON array\")\n        sys.exit(1)\n\n    try:\n        slides = json.loads(raw[start:])\n    except json.JSONDecodeError as e:\n        LOGGER.exception(\"Invalid JSON from Claude: %s\", e)\n        sys.exit(1)\n\n    slides = normalize(slides)\n    out_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n    LOGGER.info(\"Wrote %s slides → %s\", len(slides), out_path)\n\n\nif __name__ == \"__main__\":\n    main()\n### 2.2 `diagrams_to_images.py`\npython\n#!/usr/bin/env python3\n\"\"\"Render Mermaid diagrams & upload to FreeImage.host (API v1).\n\nAdds/overwrites image_url in slides.json whenever both diagram_type and\ndiagram_content are present.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, base64, json, logging, os, subprocess, sys, tempfile, time\nfrom pathlib import Path\nfrom typing import Any\n\nimport requests\nfrom PIL import Image\n\nLOGGER = logging.getLogger(\"diagrams_to_images\")\nMERMAID_CMD = \"mmdc\"  # must be on PATH\nFREEIMAGE_ENDPOINT = \"https://freeimage.host/api/1/upload\"\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Render Mermaid diagrams & upload to FreeImage.host\")\n    p.add_argument(\"json\", help=\"slides.json to update (in‑place)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    p.add_argument(\"--temp-dir\", default=tempfile.gettempdir(), help=\"where to render PNGs temporarily\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef render_mermaid(src: str, tmp: Path) -> Path:\n    mid = int(time.time() * 1000)\n    mmd = tmp / f\"dia_{mid}.mmd\"\n    png = tmp / f\"dia_{mid}.png\"\n    mmd.write_text(src, encoding=\"utf-8\")\n    subprocess.run([MERMAID_CMD, \"-i\", mmd, \"-o\", png, \"-b\", \"transparent\"], check=True)\n    if not png.exists() or png.stat().st_size == 0:\n        raise RuntimeError(\"mermaid-cli produced no output\")\n    return png\n\n\ndef upload_freeimage(png: Path) -> str:\n    api_key = os.getenv(\"FREEIMAGE_API_KEY\")\n    if not api_key:\n        raise RuntimeError(\"FREEIMAGE_API_KEY env var not set\")\n    with png.open(\"rb\") as fh:\n        payload = {\n            \"key\": api_key,\n            \"action\": \"upload\",\n            \"format\": \"json\",\n        }\n        files = {\"source\": fh}\n        rsp = requests.post(FREEIMAGE_ENDPOINT, data=payload, files=files, timeout=20)\n        rsp.raise_for_status()\n    data: dict[str, Any] = rsp.json()\n    if data.get(\"status_code\") != 200:\n        raise RuntimeError(f\"Upload failed: {data}\")\n    return data[\"image\"][\"url\"]\n\n\ndef process(slides: list[dict], tmp_dir: Path):\n    changed = 0\n    for slide in slides:\n        if slide.get(\"diagram_type\") and slide.get(\"diagram_content\"):\n            try:\n                png = render_mermaid(slide[\"diagram_content\"], tmp_dir)\n                url = upload_freeimage(png)\n                slide[\"image_url\"] = url\n                changed += 1\n                LOGGER.info(\"Rendered & uploaded diagram for slide %d\", slide[\"slide_number\"])\n            except Exception as e:\n                LOGGER.warning(\"Diagram for slide %d failed: %s\", slide[\"slide_number\"], e)\n    return changed\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n\n    slides = json.loads(json_path.read_text())\n    changed = process(slides, Path(args.temp_dir))\n    json_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n    LOGGER.info(\"%d diagrams processed; file updated\", changed)\n\n\nif __name__ == \"__main__\":\n    main()\n### 2.3 `update_images.py`\npython\n#!/usr/bin/env python3\n\"\"\"Populate missing image_urls.\n\nPriority order:\n1. Match against a curated Unsplash lookup table for deterministic, high‑quality images.\n2. Fallback to Wikimedia Commons search using the image_description string.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, sys\nfrom pathlib import Path\nimport requests\n\nAPI = \"https://commons.wikimedia.org/w/api.php\"\nLOGGER = logging.getLogger(\"update_images\")\n\n# ---- deterministic Unsplash fallbacks -------------------------------------\nUNSPLASH = {\n    \"solar panels\": \"https://images.unsplash.com/photo-1611744968035-b606937fdd8d\",\n    \"solar installation\": \"https://images.unsplash.com/photo-1521618755572-156ae0cdd74d\",\n    \"roof installation\": \"https://images.unsplash.com/photo-1509391366360-2e959784a276\",\n    \"solar worker\": \"https://images.unsplash.com/photo-1602338038325-309fcb428972\",\n    \"calculator\": \"https://images.unsplash.com/photo-1564986410613-97e0b371efe5\",\n    \"maintenance\": \"https://images.unsplash.com/photo-1504328345606-18bbc8c9d7d1\",\n    \"safety equipment\": \"https://images.unsplash.com/photo-1578874691223-64558a3ca096\",\n    \"tools\": \"https://images.unsplash.com/photo-1581166397057-235af2b3c6dd\",\n    \"training\": \"https://images.unsplash.com/photo-1524178232363-1fb2b075b655\",\n    \"discussion\": \"https://images.unsplash.com/photo-1573497019418-b400bb3ab074\",\n}\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Auto‑fill images via Unsplash lookup → Wikimedia fallback\")\n    p.add_argument(\"json\", help=\"slides.json (in‑place)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n# ---- helpers --------------------------------------------------------------\n\ndef unsplash_match(desc: str) -> str | None:\n    key = desc.lower().strip()\n    if key in UNSPLASH:\n        return UNSPLASH[key]\n    for k, url in UNSPLASH.items():\n        if k in key:\n            return url\n    return None\n\n\ndef commons_image(desc: str) -> str | None:\n    params = {\n        \"action\": \"query\",\n        \"format\": \"json\",\n        \"prop\": \"pageimages\",\n        \"piprop\": \"original\",\n        \"generator\": \"search\",\n        \"gsrsearch\": desc,\n        \"gsrlimit\": 1,\n    }\n    try:\n        rsp = requests.get(API, params=params, timeout=15)\n        rsp.raise_for_status()\n        pages = rsp.json().get(\"query\", {}).get(\"pages\", {})\n        if not pages:\n            return None\n        return next(iter(pages.values())).get(\"original\", {}).get(\"source\")\n    except Exception as e:\n        LOGGER.debug(\"Wikimedia error: %s\", e)\n        return None\n\n# ---- main processing ------------------------------------------------------\n\ndef process(slides: list[dict]):\n    added = 0\n    for sl in slides:\n        if sl.get(\"image_url\"):\n            continue  # already set\n        desc = sl.get(\"image_description\")\n        if not desc:\n            continue\n        url = unsplash_match(desc)\n        if not url:\n            url = commons_image(desc)\n        if url:\n            sl[\"image_url\"] = url\n            added += 1\n            LOGGER.info(\"Image added for slide %d\", sl[\"slide_number\"])\n    return added\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    path = Path(args.json)\n    if not path.exists():\n        LOGGER.error(\"%s not found\", path)\n        sys.exit(1)\n    slides = json.loads(path.read_text())\n    n = process(slides)\n    path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n    LOGGER.info(\"%d images populated\", n)\n\n\nif __name__ == \"__main__\":\n    main()\npython\n#!/usr/bin/env python3\n\"\"\"Fill missing `image_url`s using Wikimedia Commons search based on `image_description`.\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, sys\nfrom pathlib import Path\nimport requests\n\nAPI = \"https://commons.wikimedia.org/w/api.php\"\nLOGGER = logging.getLogger(\"update_images\")\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Auto‑fill images via Wikimedia Commons\")\n    p.add_argument(\"json\", help=\"slides.json (in‑place)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef commons_image(desc: str) -> str | None:\n    params = {\n        \"action\": \"query\",\n        \"format\": \"json\",\n        \"prop\": \"pageimages\",\n        \"piprop\": \"original\",\n        \"generator\": \"search\",\n        \"gsrsearch\": desc,\n        \"gsrlimit\": 1,\n    }\n    rsp = requests.get(API, params=params, timeout=15)\n    rsp.raise_for_status()\n    pages = rsp.json().get(\"query\", {}).get(\"pages\", {})\n    if not pages:\n        return None\n    return next(iter(pages.values())).get(\"original\", {}).get(\"source\")\n\n\ndef process(slides: list[dict]):\n    done = 0\n    for sl in slides:\n        if sl.get(\"image_description\") and not sl.get(\"image_url\"):\n            url = commons_image(sl[\"image_description\"])\n            if url:\n                sl[\"image_url\"] = url\n                done += 1\n                LOGGER.info(\"Added image for slide %d\", sl[\"slide_number\"])\n    return done\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    path = Path(args.json)\n    if not path.exists():\n        LOGGER.error(\"%s not found\", path)\n        sys.exit(1)\n    slides = json.loads(path.read_text())\n    n = process(slides)\n    path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n    LOGGER.info(\"%d images added\", n)\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n### 2.4 build_slides.py\n\npython\n#!/usr/bin/env python3\n\"\"\"Create a Google Slides deck from slides.json.\n\nSupports optional `--template-id` (an existing Slides file); if provided the\nfile will be duplicated via Drive API and populated, preserving the original\nlayout/theme.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, time\nfrom pathlib import Path\n\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom google.auth.transport.requests import Request\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\nSCOPES = [\n    \"https://www.googleapis.com/auth/presentations\",\n    \"https://www.googleapis.com/auth/drive.file\",\n]\nLOGGER = logging.getLogger(\"build_slides\")\n\n\n# ---------- auth helpers ----------------------------------------------------\n\ndef auth(port: int):\n    token_path = Path(\"oauth-token.json\")\n    client_path = Path(\"oauth-client.json\")\n    creds: Credentials | None = None\n    if token_path.exists():\n        creds = Credentials.from_authorized_user_file(token_path, SCOPES)\n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            creds.refresh(Request())\n        else:\n            flow = InstalledAppFlow.from_client_secrets_file(client_path, SCOPES)\n            creds = flow.run_local_server(port=port)\n        token_path.write_text(creds.to_json())\n    return build(\"slides\", \"v1\", credentials=creds), build(\"drive\", \"v3\", credentials=creds)\n\n\n# ---------- templates -------------------------------------------------------\n\ndef duplicate_template(drive, template_id: str, title: str) -> str:\n    file_meta = {\"name\": title}\n    copied = drive.files().copy(fileId=template_id, body=file_meta).execute()\n    return copied[\"id\"]\n\n\n# ---------- slide generation ------------------------------------------------\n\ndef choose_layout(slide: dict) -> str:\n    if slide[\"slide_number\"] == 1:\n        return \"TITLE\"\n    if slide.get(\"image_url\"):\n        return \"TITLE_AND_TWO_COLUMNS\"\n    return \"TITLE_AND_BODY\"\n\n\ndef build_requests(slides: list[dict]) -> list[dict]:\n    reqs: list[dict] = []\n    for sl in slides:\n        page_id = f\"p{sl['slide_number']}\"\n        layout = choose_layout(sl)\n        reqs.append({\"createSlide\": {\"objectId\": page_id, \"slideLayoutReference\": {\"predefinedLayout\": layout}}})\n        # Title\n        reqs.append({\"insertText\": {\"objectId\": page_id, \"insertionIndex\": 0, \"text\": sl.get(\"title\", \"\")}})\n        # Content\n        if sl.get(\"content\"):\n            reqs.append({\"insertText\": {\"objectId\": page_id, \"insertionIndex\": 1, \"text\": sl[\"content\"]}})\n        # Image\n        if sl.get(\"image_url\"):\n            reqs.append({\n                \"createImage\": {\n                    \"url\": sl[\"image_url\"],\n                    \"elementProperties\": {\n                        \"pageObjectId\": page_id,\n                        \"transform\": {\n                            \"scaleX\": 1,\n                            \"scaleY\": 1,\n                            \"translateX\": 350,\n                            \"translateY\": 150,\n                            \"unit\": \"PT\",\n                        },\n                    },\n                }\n            })\n    return reqs\n\n\n# ---------- main ------------------------------------------------------------\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Generate Google Slides deck from slides.json\")\n    p.add_argument(\"json\", help=\"slides.json with image_url filled\")\n    p.add_argument(\"--title\", default=\"LLM Presentation\")\n    p.add_argument(\"--template-id\", help=\"Google Slides file ID to copy as template\")\n    p.add_argument(\"--port\", type=int, default=3000)\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    slides_data = json.loads(Path(args.json).read_text())\n    slides_service, drive_service = auth(args.port)\n\n    presentation_id: str\n    try:\n        if args.template_id:\n            presentation_id = duplicate_template(drive_service, args.template_id, args.title)\n            LOGGER.info(\"Template duplicated → %s\", presentation_id)\n        else:\n            pres = slides_service.presentations().create(body={\"title\": args.title}).execute()\n            presentation_id = pres[\"presentationId\"]\n            LOGGER.info(\"Blank deck created → %s\", presentation_id)\n    except HttpError as e:\n        LOGGER.exception(\"Failed to create presentation: %s\", e)\n        sys.exit(1)\n\n    # Batch update\n    reqs = build_requests(slides_data)\n    slides_service.presentations().batchUpdate(presentationId=presentation_id, body={\"requests\": reqs}).execute()\n    LOGGER.info(\"Slides added: %d\", len(slides_data))\n    print(\"Deck URL:\", f\"https://docs.google.com/presentation/d/{presentation_id}/edit\")\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n---\n\n## 3  Workflow\n\nbash\n# ① Guide → JSON (with chart_type support)\npython guide_to_json.py facilitator.md --out slides.json\n\n# ② Render Mermaid diagrams & upload to FreeImage.host\npython diagrams_to_images.py slides.json\n\n# ③ Fill missing pictures via Wikimedia (optional)\npython update_images.py slides.json\n\n# ④ Build Google Slides (use your own template deck if you like)\npython build_slides.py slides.json --template-id 1AbCDeF… --title \"Solar Workshop\"\n\n\n---\n\n### Troubleshooting\n\n* **FREEIMAGE\\_API\\_KEY missing** → sign up on freeimage.host → Settings → API Key.\n* **mmdc not found** → ensure npm i -g @mermaid-js/mermaid-cli and PATH.\n* **OAuth redirect mismatch** → delete oauth-token.json, double‑check oauth-client.json has a http://localhost redirect.\n* **Mermaid render fails** → open the failing .mmd in the tmp dir and validate at [https://mermaid.live/](https://mermaid.live/).\n\nEnjoy your modular, fault‑tolerant slide pipeline! ✨\n\n\nReview for errors - our client downloaded from our google console is client_secret_86636054979-3nbfqd131qldjqtj66i5sivk89v7nqgk.apps.googleusercontent.com.json\nAnd it's for a desktop app\n\nThought for 31 seconds\n\n\nChatGPT said:\nBelow is a focused technical review of the v2 Modular Slide-Generation System.\nI concentrate on correctness, security, maintainability and the gaps between the README and the actual source.\n\n1 Pipeline-wide observations\nArea\tWhat works well\tKey risks / improvement ideas\nEnvironment & secrets\tAll API keys are read from env-vars – good practice.\tMake ANTHROPIC_API_KEY and FREEIMAGE_API_KEY mandatory in every script that calls those services; fail fast if unset (only guide_to_json.py does this now).\nLogging\tConsistent use of logging and --log-level.\tAdd exc_info=True in exception logs so stack-traces go to the log file, not only stderr.\nError propagation\tEach CLI exits with sys.exit(1) on fatal issues.\tWrap external-API calls in try/except and re-raise custom messages – today a transient 502 from Claude, FreeImage or Wikimedia will crash the whole run without context.\nToken limits\t16 000 tokens gives Claude plenty of room.\tAdd a max_tokens CLI flag and guard for too-large facilitator guides (chunk / stream them).\n\n2 Script-level review\n2.1 guide_to_json.py\n| ✅ | Well-structured CLI; normalize() guarantees the 15-key order. |\n| :warning: | • Model name: claude-3-7-sonnet-20250219 may drift; consider making it a CLI flag.<br>• Anthropic API call: future SDK versions moved system into the messages array – wrap this in a helper that adapts to both.<br>• Missing network-/rate-limit retries. |\n\n2.2 diagrams_to_images.py\n| ✅ | Nice separation of render ➜ upload ➜ patch JSON. |\n| :warning: | • PIL.Image and base64 are imported but never used – remove to cut cold-start time.<br>• Shelling‐out to mmdc is synchronous; rendering 20+ diagrams will be slow. Use concurrent.futures.ThreadPoolExecutor with a worker per CPU to parallelise.<br>• FreeImage API v1 occasionally returns HTTP 429; add time.sleep(1) + retry with back-off. |\n\n2.3 update_images.py (repo version) \n\n| ✅ | Simple Wikimedia search fallback. |\n| :warning: | README mismatch: the README says you first check a curated Unsplash table, but the checked-in script contains only the Wikimedia path. Decide one of: (a) merge the Unsplash lookup into this file, or (b) rename the file to update_images_wikimedia.py and adjust the docs so users aren’t surprised. |\n\n2.4 build_slides.py \n\n:heavy_check_mark: positives\t:warning: blocking issues\n• OAuth helper caches token.\n• Can duplicate a template deck on Drive.\t1. Text insertion – insertText calls use the page objectId (p1, p2 …), but the Slides API expects a shape objectId (placeholder or shape). The request will 400-error. You need to:\n  • Create a text box (createShape) or reference the title/body placeholders returned in createSlide’s response.\n  • Then call insertText on that shape id.\n2. oauth-client.json filename – the README asks users to download client_secret_…json, while the script looks for oauth-client.json. Either rename in code or document the required filename.\n\n3 README / reality gaps\nImage strategy – dual Unsplash/Wikimedia logic exists in the docs but not in source (see § 2.3).\n\nPrerequisites table – you import Pillow but do not use it anywhere after refactor; drop it from requirements.\n\nMermaid guidelines – the prompt-template enforces 15-node limits but the validator isn’t implemented; consider adding a post-generation sanity check before mmdc runs to catch illegal syntax early.\n\n4 Security & operations checklist\nControl\tStatus\tRecommendation\nAPI-key storage\tEnv-vars only.\tFor CI/CD, mount them via secret manager rather than plain env files.\nOAuth token\tStored in user folder as oauth-token.json.\tEncrypt the file on disk (keyring, Hashicorp Vault) if the workstation is multi-user.\nTemp files\tMermaid diagrams go to tempfile.gettempdir().\tUse tempfile.TemporaryDirectory() context so they are auto-deleted on success.\n\n5 Quick-win code fixes\npython\nCopy\nEdit\n# build_slides.py – create a title placeholder, then inject text\nreqs.append({\n    \"createSlide\": {\n        \"objectId\": page_id,\n        \"slideLayoutReference\": {\"predefinedLayout\": layout},\n        \"placeholderIdMappings\": [\n            {\"layoutPlaceholder\": {\"type\": \"TITLE\"}, \"objectId\": f\"{page_id}_title\"},\n            {\"layoutPlaceholder\": {\"type\": \"BODY\"},  \"objectId\": f\"{page_id}_body\"},\n        ],\n    }\n})\n# title text\nreqs.append({\n    \"insertText\": {\n        \"objectId\": f\"{page_id}_title\",\n        \"insertionIndex\": 0,\n        \"text\": sl.get(\"title\", \"\")\n    }\n})\n# body text\nif sl.get(\"content\"):\n    reqs.append({\n        \"insertText\": {\n            \"objectId\": f\"{page_id}_body\",\n            \"insertionIndex\": 0,\n            \"text\": sl[\"content\"]\n        }\n    })\n(Google Slides will automatically fit the text into the newly-created placeholders.)"
          }
        ],
        "files": [
          {
            "file_name": "paste.txt"
          },
          {
            "file_name": "paste-2.txt"
          }
        ]
      }
    },
    {
      "id": "95b16e70-fd9d-4b41-8361-8afcdff210ed",
      "role": "assistant",
      "content": "Let me analyze what the user has shared with me - there are two text files:\n\n1. **paste.txt** - This appears to be documentation of the Unsplash API, showing how to search for photos, collections, and topics. It covers endpoints, parameters, and response structures, including detailed examples.\n\n2. **paste-2.txt** - This is a project documentation for a \"Modular Slide-Generation System (v2)\" that converts facilitator guides into Google Slides decks. It includes Python scripts that use Claude, Mermaid diagrams, image services, and Google APIs.\n\nThe user didn't provide a specific question, so I need to understand what they might want me to help with. Given the \"r\" in the message, this might be a request for a review of the provided content or potentially help with using Unsplash in their slide generation system.\n\nI notice that in the second file (paste-2.txt), there's already an implementation for finding images for slides using Wikimedia Commons, and there's also mention of Unsplash in a commented lookup table. It seems like they might want to implement or improve the Unsplash API integration for their slide generation system.\n\nLet me prepare a comprehensive response that:\n1. Acknowledges both files\n2. Focuses on how the Unsplash API (from paste.txt) could be integrated into their slide generation system (paste-2.txt)\n3. Provides practical code samples that would help them implement Unsplash image search\n\nSince the user's preferences mention they like metaphors, prefer Python, like constructive criticism, don't like flattery, and want honest assessment of how unique/groundbreaking things are, I'll tailor my response accordingly.Looking at these files, I can see you've got a modular slide-generation system and documentation for the Unsplash API. It seems you're interested in integrating Unsplash as an image source for your slides.\n\nYour current system is like a river with tributaries - multiple specialized scripts that flow into a cohesive whole. You already have Wikimedia Commons integration, but Unsplash would give you access to higher-quality, more modern imagery.\n\nLet me offer a Python implementation to integrate Unsplash into your `update_images.py` script, based on the API documentation you provided:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Populate missing image_urls using Unsplash API with fallback to Wikimedia Commons.\n\nPriority order:\n1. Match against a curated Unsplash lookup table for deterministic, high-quality images.\n2. Unsplash API search using the image_description string.\n3. Fallback to Wikimedia Commons search.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys\nfrom pathlib import Path\nimport requests\n\nLOGGER = logging.getLogger(\"update_images\")\nWIKIMEDIA_API = \"https://commons.wikimedia.org/w/api.php\"\nUNSPLASH_API = \"https://api.unsplash.com/search/photos\"\n\n# ---- deterministic Unsplash fallbacks -------------------------------------\nUNSPLASH_LOOKUP = {\n    \"solar panels\": \"https://images.unsplash.com/photo-1611744968035-b606937fdd8d\",\n    \"solar installation\": \"https://images.unsplash.com/photo-1521618755572-156ae0cdd74d\",\n    \"roof installation\": \"https://images.unsplash.com/photo-1509391366360-2e959784a276\",\n    \"solar worker\": \"https://images.unsplash.com/photo-1602338038325-309fcb428972\",\n    \"calculator\": \"https://images.unsplash.com/photo-1564986410613-97e0b371efe5\",\n    \"maintenance\": \"https://images.unsplash.com/photo-1504328345606-18bbc8c9d7d1\",\n    \"safety equipment\": \"https://images.unsplash.com/photo-1578874691223-64558a3ca096\",\n    \"tools\": \"https://images.unsplash.com/photo-1581166397057-235af2b3c6dd\",\n    \"training\": \"https://images.unsplash.com/photo-1524178232363-1fb2b075b655\",\n    \"discussion\": \"https://images.unsplash.com/photo-1573497019418-b400bb3ab074\",\n}\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Auto-fill images via Unsplash API → Wikimedia Commons fallback\")\n    p.add_argument(\"json\", help=\"slides.json (in-place)\")\n    p.add_argument(\"--unsplash-key\", help=\"Unsplash API access key\", default=os.getenv(\"UNSPLASH_ACCESS_KEY\"))\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\n# ---- image sources --------------------------------------------------------\n\ndef unsplash_lookup(desc: str) -> str | None:\n    \"\"\"Check for exact or partial match in our curated lookup table.\"\"\"\n    key = desc.lower().strip()\n    if key in UNSPLASH_LOOKUP:\n        return UNSPLASH_LOOKUP[key]\n    \n    for k, url in UNSPLASH_LOOKUP.items():\n        if k in key or key in k:\n            return url\n    \n    return None\n\n\ndef unsplash_search(desc: str, api_key: str) -> str | None:\n    \"\"\"Search Unsplash API for relevant image.\"\"\"\n    if not api_key:\n        LOGGER.warning(\"Skipping Unsplash API search - no API key provided\")\n        return None\n    \n    try:\n        params = {\n            \"query\": desc,\n            \"per_page\": 1,\n            \"orientation\": \"landscape\",  # Better for slides\n            \"content_filter\": \"high\",    # Safe for work content\n        }\n        headers = {\"Authorization\": f\"Client-ID {api_key}\"}\n        \n        rsp = requests.get(UNSPLASH_API, params=params, headers=headers, timeout=10)\n        rsp.raise_for_status()\n        data = rsp.json()\n        \n        results = data.get(\"results\", [])\n        if not results:\n            LOGGER.debug(\"No Unsplash results for '%s'\", desc)\n            return None\n        \n        # Return URL of first result\n        return results[0][\"urls\"][\"regular\"]\n    \n    except Exception as e:\n        LOGGER.warning(\"Unsplash API error: %s\", e)\n        return None\n\n\ndef wikimedia_search(desc: str) -> str | None:\n    \"\"\"Fallback to Wikimedia Commons search.\"\"\"\n    params = {\n        \"action\": \"query\",\n        \"format\": \"json\",\n        \"prop\": \"pageimages\",\n        \"piprop\": \"original\",\n        \"generator\": \"search\",\n        \"gsrsearch\": desc,\n        \"gsrlimit\": 1,\n    }\n    \n    try:\n        rsp = requests.get(WIKIMEDIA_API, params=params, timeout=15)\n        rsp.raise_for_status()\n        pages = rsp.json().get(\"query\", {}).get(\"pages\", {})\n        if not pages:\n            return None\n        return next(iter(pages.values())).get(\"original\", {}).get(\"source\")\n    \n    except Exception as e:\n        LOGGER.warning(\"Wikimedia search error: %s\", e)\n        return None\n\n\n# ---- main processing ------------------------------------------------------\n\ndef process(slides: list[dict], unsplash_key: str | None):\n    added = 0\n    \n    for slide in slides:\n        # Skip if image already set\n        if slide.get(\"image_url\"):\n            continue\n            \n        # Skip if no description to search with\n        desc = slide.get(\"image_description\")\n        if not desc:\n            continue\n            \n        # Try each source in priority order\n        url = unsplash_lookup(desc)\n        \n        if not url and unsplash_key:\n            url = unsplash_search(desc, unsplash_key)\n            \n        if not url:\n            url = wikimedia_search(desc)\n            \n        if url:\n            slide[\"image_url\"] = url\n            added += 1\n            source = \"lookup table\" if url in UNSPLASH_LOOKUP.values() else (\n                \"Unsplash API\" if \"unsplash.com\" in url else \"Wikimedia\")\n            LOGGER.info(f\"Image added for slide {slide['slide_number']} via {source}\")\n    \n    return added\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate inputs\n    path = Path(args.json)\n    if not path.exists():\n        LOGGER.error(\"%s not found\", path)\n        sys.exit(1)\n        \n    # Unsplash API key warning\n    if not args.unsplash_key:\n        LOGGER.warning(\"No Unsplash API key provided. Set UNSPLASH_ACCESS_KEY env var or use --unsplash-key\")\n    \n    # Process the slides\n    slides = json.loads(path.read_text())\n    n = process(slides, args.unsplash_key)\n    \n    # Save results\n    path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n    LOGGER.info(\"%d images populated\", n)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\nThis implementation has several advantages over your current approach:\n\n1. **Prioritized image sources**: Tries curated lookup table first, then Unsplash API, then Wikimedia\n2. **Better error handling**: Gracefully catches and logs errors from each image source\n3. **More logging**: Tells you which source provided each image\n4. **Environment variable support**: Uses UNSPLASH_ACCESS_KEY from env or CLI arg\n\nA few critical improvements you should make to the overall system:\n\n1. Your `build_slides.py` has a text insertion issue - it's using page IDs where it needs shape IDs. Here's a fix:\n```python\n# Instead of directly using page_id:\nreqs.append({\"createSlide\": {\n    \"objectId\": page_id,\n    \"slideLayoutReference\": {\"predefinedLayout\": layout},\n    \"placeholderIdMappings\": [\n        {\"layoutPlaceholder\": {\"type\": \"TITLE\"}, \"objectId\": f\"{page_id}_title\"},\n        {\"layoutPlaceholder\": {\"type\": \"BODY\"}, \"objectId\": f\"{page_id}_body\"}\n    ]\n}})\n\n# Then use the mapped IDs:\nreqs.append({\"insertText\": {\n    \"objectId\": f\"{page_id}_title\",\n    \"insertionIndex\": 0,\n    \"text\": sl.get(\"title\", \"\")\n}})\n```\n\n2. Your `diagrams_to_images.py` imports modules it doesn't use (`base64` and `PIL.Image`).\n\n3. There's no retry logic for external API calls - a single failure can stop your pipeline. Consider adding exponential backoff.\n\n4. Temporary files from Mermaid diagrams aren't cleaned up. Use `tempfile.TemporaryDirectory()` as a context manager to auto-cleanup.\n\nThis system has good bones - the modular approach allows for independent improvement of each step. Just like repairing sections of a bridge without closing the whole structure, you can enhance individual components while maintaining the overall workflow.",
      "created_at": "2025-05-20T06:09:24.753523Z",
      "sequence_order": 1,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-20T06:08:43.363239Z",
            "stop_timestamp": "2025-05-20T06:08:50.185379Z",
            "flags": null,
            "type": "thinking",
            "thinking": "Let me analyze what the user has shared with me - there are two text files:\n\n1. **paste.txt** - This appears to be documentation of the Unsplash API, showing how to search for photos, collections, and topics. It covers endpoints, parameters, and response structures, including detailed examples.\n\n2. **paste-2.txt** - This is a project documentation for a \"Modular Slide-Generation System (v2)\" that converts facilitator guides into Google Slides decks. It includes Python scripts that use Claude, Mermaid diagrams, image services, and Google APIs.\n\nThe user didn't provide a specific question, so I need to understand what they might want me to help with. Given the \"r\" in the message, this might be a request for a review of the provided content or potentially help with using Unsplash in their slide generation system.\n\nI notice that in the second file (paste-2.txt), there's already an implementation for finding images for slides using Wikimedia Commons, and there's also mention of Unsplash in a commented lookup table. It seems like they might want to implement or improve the Unsplash API integration for their slide generation system.\n\nLet me prepare a comprehensive response that:\n1. Acknowledges both files\n2. Focuses on how the Unsplash API (from paste.txt) could be integrated into their slide generation system (paste-2.txt)\n3. Provides practical code samples that would help them implement Unsplash image search\n\nSince the user's preferences mention they like metaphors, prefer Python, like constructive criticism, don't like flattery, and want honest assessment of how unique/groundbreaking things are, I'll tailor my response accordingly.",
            "summaries": [
              {
                "summary": "Thinking about a single-letter input's potential meaning"
              },
              {
                "summary": "Analyzing Unsplash API documentation details"
              },
              {
                "summary": "Scrutinized files, plotted Unsplash API integration for slide system."
              }
            ],
            "cut_off": false
          },
          {
            "start_timestamp": "2025-05-20T06:08:50.302672Z",
            "stop_timestamp": "2025-05-20T06:09:24.643556Z",
            "flags": null,
            "type": "text",
            "text": "Looking at these files, I can see you've got a modular slide-generation system and documentation for the Unsplash API. It seems you're interested in integrating Unsplash as an image source for your slides.\n\nYour current system is like a river with tributaries - multiple specialized scripts that flow into a cohesive whole. You already have Wikimedia Commons integration, but Unsplash would give you access to higher-quality, more modern imagery.\n\nLet me offer a Python implementation to integrate Unsplash into your `update_images.py` script, based on the API documentation you provided:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Populate missing image_urls using Unsplash API with fallback to Wikimedia Commons.\n\nPriority order:\n1. Match against a curated Unsplash lookup table for deterministic, high-quality images.\n2. Unsplash API search using the image_description string.\n3. Fallback to Wikimedia Commons search.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys\nfrom pathlib import Path\nimport requests\n\nLOGGER = logging.getLogger(\"update_images\")\nWIKIMEDIA_API = \"https://commons.wikimedia.org/w/api.php\"\nUNSPLASH_API = \"https://api.unsplash.com/search/photos\"\n\n# ---- deterministic Unsplash fallbacks -------------------------------------\nUNSPLASH_LOOKUP = {\n    \"solar panels\": \"https://images.unsplash.com/photo-1611744968035-b606937fdd8d\",\n    \"solar installation\": \"https://images.unsplash.com/photo-1521618755572-156ae0cdd74d\",\n    \"roof installation\": \"https://images.unsplash.com/photo-1509391366360-2e959784a276\",\n    \"solar worker\": \"https://images.unsplash.com/photo-1602338038325-309fcb428972\",\n    \"calculator\": \"https://images.unsplash.com/photo-1564986410613-97e0b371efe5\",\n    \"maintenance\": \"https://images.unsplash.com/photo-1504328345606-18bbc8c9d7d1\",\n    \"safety equipment\": \"https://images.unsplash.com/photo-1578874691223-64558a3ca096\",\n    \"tools\": \"https://images.unsplash.com/photo-1581166397057-235af2b3c6dd\",\n    \"training\": \"https://images.unsplash.com/photo-1524178232363-1fb2b075b655\",\n    \"discussion\": \"https://images.unsplash.com/photo-1573497019418-b400bb3ab074\",\n}\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Auto-fill images via Unsplash API → Wikimedia Commons fallback\")\n    p.add_argument(\"json\", help=\"slides.json (in-place)\")\n    p.add_argument(\"--unsplash-key\", help=\"Unsplash API access key\", default=os.getenv(\"UNSPLASH_ACCESS_KEY\"))\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\n# ---- image sources --------------------------------------------------------\n\ndef unsplash_lookup(desc: str) -> str | None:\n    \"\"\"Check for exact or partial match in our curated lookup table.\"\"\"\n    key = desc.lower().strip()\n    if key in UNSPLASH_LOOKUP:\n        return UNSPLASH_LOOKUP[key]\n    \n    for k, url in UNSPLASH_LOOKUP.items():\n        if k in key or key in k:\n            return url\n    \n    return None\n\n\ndef unsplash_search(desc: str, api_key: str) -> str | None:\n    \"\"\"Search Unsplash API for relevant image.\"\"\"\n    if not api_key:\n        LOGGER.warning(\"Skipping Unsplash API search - no API key provided\")\n        return None\n    \n    try:\n        params = {\n            \"query\": desc,\n            \"per_page\": 1,\n            \"orientation\": \"landscape\",  # Better for slides\n            \"content_filter\": \"high\",    # Safe for work content\n        }\n        headers = {\"Authorization\": f\"Client-ID {api_key}\"}\n        \n        rsp = requests.get(UNSPLASH_API, params=params, headers=headers, timeout=10)\n        rsp.raise_for_status()\n        data = rsp.json()\n        \n        results = data.get(\"results\", [])\n        if not results:\n            LOGGER.debug(\"No Unsplash results for '%s'\", desc)\n            return None\n        \n        # Return URL of first result\n        return results[0][\"urls\"][\"regular\"]\n    \n    except Exception as e:\n        LOGGER.warning(\"Unsplash API error: %s\", e)\n        return None\n\n\ndef wikimedia_search(desc: str) -> str | None:\n    \"\"\"Fallback to Wikimedia Commons search.\"\"\"\n    params = {\n        \"action\": \"query\",\n        \"format\": \"json\",\n        \"prop\": \"pageimages\",\n        \"piprop\": \"original\",\n        \"generator\": \"search\",\n        \"gsrsearch\": desc,\n        \"gsrlimit\": 1,\n    }\n    \n    try:\n        rsp = requests.get(WIKIMEDIA_API, params=params, timeout=15)\n        rsp.raise_for_status()\n        pages = rsp.json().get(\"query\", {}).get(\"pages\", {})\n        if not pages:\n            return None\n        return next(iter(pages.values())).get(\"original\", {}).get(\"source\")\n    \n    except Exception as e:\n        LOGGER.warning(\"Wikimedia search error: %s\", e)\n        return None\n\n\n# ---- main processing ------------------------------------------------------\n\ndef process(slides: list[dict], unsplash_key: str | None):\n    added = 0\n    \n    for slide in slides:\n        # Skip if image already set\n        if slide.get(\"image_url\"):\n            continue\n            \n        # Skip if no description to search with\n        desc = slide.get(\"image_description\")\n        if not desc:\n            continue\n            \n        # Try each source in priority order\n        url = unsplash_lookup(desc)\n        \n        if not url and unsplash_key:\n            url = unsplash_search(desc, unsplash_key)\n            \n        if not url:\n            url = wikimedia_search(desc)\n            \n        if url:\n            slide[\"image_url\"] = url\n            added += 1\n            source = \"lookup table\" if url in UNSPLASH_LOOKUP.values() else (\n                \"Unsplash API\" if \"unsplash.com\" in url else \"Wikimedia\")\n            LOGGER.info(f\"Image added for slide {slide['slide_number']} via {source}\")\n    \n    return added\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate inputs\n    path = Path(args.json)\n    if not path.exists():\n        LOGGER.error(\"%s not found\", path)\n        sys.exit(1)\n        \n    # Unsplash API key warning\n    if not args.unsplash_key:\n        LOGGER.warning(\"No Unsplash API key provided. Set UNSPLASH_ACCESS_KEY env var or use --unsplash-key\")\n    \n    # Process the slides\n    slides = json.loads(path.read_text())\n    n = process(slides, args.unsplash_key)\n    \n    # Save results\n    path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n    LOGGER.info(\"%d images populated\", n)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\nThis implementation has several advantages over your current approach:\n\n1. **Prioritized image sources**: Tries curated lookup table first, then Unsplash API, then Wikimedia\n2. **Better error handling**: Gracefully catches and logs errors from each image source\n3. **More logging**: Tells you which source provided each image\n4. **Environment variable support**: Uses UNSPLASH_ACCESS_KEY from env or CLI arg\n\nA few critical improvements you should make to the overall system:\n\n1. Your `build_slides.py` has a text insertion issue - it's using page IDs where it needs shape IDs. Here's a fix:\n```python\n# Instead of directly using page_id:\nreqs.append({\"createSlide\": {\n    \"objectId\": page_id,\n    \"slideLayoutReference\": {\"predefinedLayout\": layout},\n    \"placeholderIdMappings\": [\n        {\"layoutPlaceholder\": {\"type\": \"TITLE\"}, \"objectId\": f\"{page_id}_title\"},\n        {\"layoutPlaceholder\": {\"type\": \"BODY\"}, \"objectId\": f\"{page_id}_body\"}\n    ]\n}})\n\n# Then use the mapped IDs:\nreqs.append({\"insertText\": {\n    \"objectId\": f\"{page_id}_title\",\n    \"insertionIndex\": 0,\n    \"text\": sl.get(\"title\", \"\")\n}})\n```\n\n2. Your `diagrams_to_images.py` imports modules it doesn't use (`base64` and `PIL.Image`).\n\n3. There's no retry logic for external API calls - a single failure can stop your pipeline. Consider adding exponential backoff.\n\n4. Temporary files from Mermaid diagrams aren't cleaned up. Use `tempfile.TemporaryDirectory()` as a context manager to auto-cleanup.\n\nThis system has good bones - the modular approach allows for independent improvement of each step. Just like repairing sections of a bridge without closing the whole structure, you can enhance individual components while maintaining the overall workflow.",
            "citations": []
          }
        ],
        "updated_at": "2025-05-20T06:09:24.753523Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "e0350668-e0e7-4888-aac5-9309a57284ce",
      "role": "human",
      "content": "let's update diagrams to images and use a mermaid config json \nand then can you update guide to json to also be able to take a link to a folder and do all the things inside it one at a time? and to export them into the same folder they came from? \nReview also the build slides with the google slides api for best practices for different templates and uploading images, it hasn't been working well. I also want a record of all the images I create for the slides, it would be good to name them by the guide file name and _ and then the slide number so i can insert it manually if needed, also save the exported mermaid in the same folder\nReturn all files updated in full",
      "created_at": "2025-05-20T06:12:32.482969Z",
      "sequence_order": 2,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-20T06:12:32.474022Z",
            "stop_timestamp": "2025-05-20T06:12:32.474022Z",
            "flags": null,
            "type": "text",
            "text": "let's update diagrams to images and use a mermaid config json \nand then can you update guide to json to also be able to take a link to a folder and do all the things inside it one at a time? and to export them into the same folder they came from? \nReview also the build slides with the google slides api for best practices for different templates and uploading images, it hasn't been working well. I also want a record of all the images I create for the slides, it would be good to name them by the guide file name and _ and then the slide number so i can insert it manually if needed, also save the exported mermaid in the same folder\nReturn all files updated in full",
            "citations": []
          }
        ],
        "updated_at": "2025-05-20T06:12:32.482969Z",
        "attachments": [
          {
            "file_name": "mermaid-config.json",
            "file_size": 240,
            "file_type": "application/json",
            "extracted_content": "{\n  \"theme\": \"default\",\n  \"themeVariables\": {\n    \"primaryColor\": \"#4287f5\",\n    \"primaryTextColor\": \"#333\",\n    \"primaryBorderColor\": \"#2956a3\",\n    \"lineColor\": \"#2956a3\",\n    \"secondaryColor\": \"#a3e4d7\",\n    \"tertiaryColor\": \"#fff\"\n  }\n}"
          }
        ],
        "files": [
          {
            "file_name": "mermaid-config.json"
          }
        ]
      }
    },
    {
      "id": "e8d567fb-5beb-4157-b541-479ba4a22038",
      "role": "assistant",
      "content": "Let's break down what the user is requesting:\n\n1. Update `diagrams_to_images.py` to use a mermaid config JSON file\n2. Update `guide_to_json.py` to:\n   - Accept a folder path as input\n   - Process all files in that folder\n   - Export output JSON files to the same folder\n3. Review `build_slides.py` for Google Slides API best practices\n4. Add functionality to save images with specific naming conventions:\n   - Name format: `[guide_filename]_[slide_number]`\n   - Save in the same folder as the guide file\n5. Save exported mermaid diagrams in the same folder\n\nLet's start by updating each file one by one.\n\n### 1. Updating `diagrams_to_images.py`\n\nFor this file, we need to:\n- Add support for a mermaid config JSON file\n- Save the output images in the same folder with proper naming\n- Save the mermaid diagrams in the same folder\n\nHere's the updated version:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Render Mermaid diagrams & upload to FreeImage.host (API v1).\n\nAdds/overwrites image_url in slides.json whenever both diagram_type and\ndiagram_content are present. Also saves local copies of the diagrams with\nnames based on the source file.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, subprocess, sys, time, shutil\nfrom pathlib import Path\nfrom typing import Any\n\nimport requests\n\nLOGGER = logging.getLogger(\"diagrams_to_images\")\nMERMAID_CMD = \"mmdc\"  # must be on PATH\nFREEIMAGE_ENDPOINT = \"https://freeimage.host/api/1/upload\"\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Render Mermaid diagrams & upload to FreeImage.host\")\n    p.add_argument(\"json\", help=\"slides.json to update (in-place)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    p.add_argument(\"--temp-dir\", default=None, help=\"where to render PNGs temporarily (default: same as slides.json)\")\n    p.add_argument(\"--mermaid-config\", default=\"mermaid-config.json\", help=\"Mermaid configuration file\")\n    p.add_argument(\"--save-local\", action=\"store_true\", help=\"Save local copies of diagrams in the same folder\")\n    p.add_argument(\"--output-dir\", default=None, help=\"Directory to save output files (default: same as slides.json)\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef render_mermaid(src: str, tmp: Path, config_path: Path | None, base_filename: str, slide_num: int) -> tuple[Path, Path]:\n    \"\"\"Render mermaid diagram to PNG.\n    \n    Args:\n        src: Mermaid diagram content\n        tmp: Directory to save temporary files\n        config_path: Path to mermaid config file\n        base_filename: Base filename (from guide file)\n        slide_num: Slide number\n        \n    Returns:\n        tuple of (png_path, mmd_path)\n    \"\"\"\n    # Create filenames based on guide name and slide number\n    output_name = f\"{base_filename}_{slide_num}\"\n    mmd = tmp / f\"{output_name}.mmd\"\n    png = tmp / f\"{output_name}.png\"\n    \n    # Write mermaid content to file\n    mmd.write_text(src, encoding=\"utf-8\")\n    \n    # Build command with optional config\n    cmd = [MERMAID_CMD, \"-i\", mmd, \"-o\", png, \"-b\", \"transparent\"]\n    if config_path and config_path.exists():\n        cmd.extend([\"-c\", config_path])\n    \n    LOGGER.debug(\"Running command: %s\", \" \".join(str(x) for x in cmd))\n    \n    # Execute command with retry\n    for attempt in range(3):\n        try:\n            subprocess.run(cmd, check=True, capture_output=True)\n            if png.exists() and png.stat().st_size > 0:\n                return png, mmd\n            \n            if attempt < 2:  # Only log warning for first two attempts\n                LOGGER.warning(\"Empty output from mermaid-cli, retrying in 2s...\")\n                time.sleep(2)\n        except subprocess.CalledProcessError as e:\n            if attempt < 2:  # Only log error for first two attempts\n                LOGGER.warning(\"mermaid-cli error (attempt %d/3): %s\", attempt + 1, e.stderr.decode())\n                time.sleep(2)\n    \n    # If we got here, all attempts failed\n    raise RuntimeError(f\"Failed to render mermaid diagram after 3 attempts. Last error: {e.stderr.decode() if 'e' in locals() else 'Empty output'}\")\n\n\ndef upload_freeimage(png: Path) -> str:\n    \"\"\"Upload PNG to FreeImage.host and return URL.\"\"\"\n    api_key = os.getenv(\"FREEIMAGE_API_KEY\")\n    if not api_key:\n        raise RuntimeError(\"FREEIMAGE_API_KEY env var not set\")\n    \n    # Retry logic for uploads\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            with png.open(\"rb\") as fh:\n                payload = {\n                    \"key\": api_key,\n                    \"action\": \"upload\",\n                    \"format\": \"json\",\n                }\n                files = {\"source\": fh}\n                rsp = requests.post(FREEIMAGE_ENDPOINT, data=payload, files=files, timeout=20)\n                rsp.raise_for_status()\n                \n            data: dict[str, Any] = rsp.json()\n            if data.get(\"status_code\") != 200:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Upload failed (attempt %d/%d): %s. Retrying in %d seconds...\", \n                                  attempt + 1, max_attempts, data, 2 ** attempt)\n                    time.sleep(2 ** attempt)  # Exponential backoff\n                    continue\n                raise RuntimeError(f\"Upload failed after {max_attempts} attempts: {data}\")\n                \n            return data[\"image\"][\"url\"]\n            \n        except (requests.RequestException, json.JSONDecodeError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"Upload error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                              attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)  # Exponential backoff\n            else:\n                raise RuntimeError(f\"Upload failed after {max_attempts} attempts: {e}\")\n    \n    raise RuntimeError(\"Upload failed, this should not happen\")  # Unreachable\n\n\ndef get_base_filename(json_path: Path) -> str:\n    \"\"\"Extract base filename (without extension) from path.\"\"\"\n    return json_path.stem.replace('slides_', '')  # Remove 'slides_' prefix if present\n\n\ndef process(slides: list[dict], json_path: Path, tmp_dir: Path, config_path: Path, save_local: bool, output_dir: Path | None) -> int:\n    \"\"\"Process slides and render diagrams.\n    \n    Args:\n        slides: List of slide data\n        json_path: Path to slides.json file\n        tmp_dir: Directory for temporary files\n        config_path: Path to mermaid config\n        save_local: Whether to save local copies\n        output_dir: Directory to save output files (or None to use same as json_path)\n        \n    Returns:\n        Number of changed slides\n    \"\"\"\n    changed = 0\n    base_filename = get_base_filename(json_path)\n    final_dir = output_dir if output_dir else json_path.parent\n    \n    # Ensure the output directory exists\n    final_dir.mkdir(parents=True, exist_ok=True)\n    \n    for slide in slides:\n        if slide.get(\"diagram_type\") and slide.get(\"diagram_content\"):\n            try:\n                # Render diagram\n                png_path, mmd_path = render_mermaid(\n                    slide[\"diagram_content\"], \n                    tmp_dir, \n                    config_path, \n                    base_filename, \n                    slide[\"slide_number\"]\n                )\n                \n                # Upload to FreeImage\n                url = upload_freeimage(png_path)\n                slide[\"image_url\"] = url\n                changed += 1\n                \n                # Save local copies if requested\n                if save_local:\n                    local_png = final_dir / png_path.name\n                    local_mmd = final_dir / mmd_path.name\n                    \n                    shutil.copy2(png_path, local_png)\n                    shutil.copy2(mmd_path, local_mmd)\n                    LOGGER.info(\"Saved local copies: %s and %s\", local_png.name, local_mmd.name)\n                \n                LOGGER.info(\"Rendered & uploaded diagram for slide %d → %s\", slide[\"slide_number\"], url)\n                \n            except Exception as e:\n                LOGGER.error(\"Diagram for slide %d failed: %s\", slide[\"slide_number\"], e, exc_info=True)\n    \n    return changed\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine temporary directory\n    if args.temp_dir:\n        tmp_dir = Path(args.temp_dir)\n    else:\n        tmp_dir = json_path.parent\n    tmp_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    \n    # Check if mermaid config exists\n    config_path = Path(args.mermaid_config)\n    if not config_path.exists():\n        LOGGER.warning(\"Mermaid config file %s not found, using default\", config_path)\n        config_path = None\n    \n    # Process slides\n    try:\n        slides = json.loads(json_path.read_text())\n        changed = process(slides, json_path, tmp_dir, config_path, args.save_local, output_dir)\n        json_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n        LOGGER.info(\"%d diagrams processed; file updated\", changed)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### 2. Updating `guide_to_json.py`\n\nNow let's update this script to handle folder processing:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Convert a facilitator guide into slides.json using Claude 3.\n\nUsage:\n  python guide_to_json.py guide.md \\\n      --prompt prompt-template.txt \\\n      --out slides.json \\\n      --log-level INFO \\\n      --log-file build.log\n      \n  # Process all markdown files in a folder:\n  python guide_to_json.py guides/ \\\n      --prompt prompt-template.txt \\\n      --log-level INFO \\\n      --log-file build.log\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, time\nfrom pathlib import Path\nfrom typing import List\nimport anthropic\n\nDEFAULT_OUT = \"slides.json\"\nDEFAULT_PROMPT = \"prompt-template.txt\"\n\nLOGGER = logging.getLogger(\"guide_to_json\")\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"LLM → JSON slide outline\")\n    p.add_argument(\"guide\", help=\"Facilitator guide (Markdown/text) or directory of guides\")\n    p.add_argument(\"--prompt\", default=DEFAULT_PROMPT, help=\"Prompt template path\")\n    p.add_argument(\"--out\", default=None, help=\"Output JSON path (ignored if guide is a directory)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None, help=\"Write logs to file as well\")\n    p.add_argument(\"--model\", default=\"claude-3-7-sonnet-20250219\", help=\"Claude model to use\")\n    p.add_argument(\"--batch-size\", type=int, default=5, help=\"Number of files to process in parallel (batch mode)\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers: list[logging.Handler] = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(\n        level=level,\n        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n        handlers=handlers,\n    )\n\n\ndef build_prompt(template_path: Path, guide_text: str) -> str:\n    tpl = template_path.read_text(encoding=\"utf-8\")\n    if \"{{content}}\" not in tpl:\n        LOGGER.error(\"Prompt template missing {{content}} placeholder → %s\", template_path)\n        sys.exit(1)\n    return tpl.replace(\"{{content}}\", guide_text)\n\n\n# Insert missing keys and correct ordering\nORDER = [\n    \"slide_number\", \"title\", \"content\", \"chart_type\", \"diagram_type\", \"diagram_content\",\n    \"image_description\", \"image_url\", \"facilitator_notes\", \"start_time\", \"end_time\",\n    \"materials\", \"worksheet\", \"improvements\", \"notes\",\n]\n\n\ndef normalize(slides: list[dict]) -> list[dict]:\n    fixed = []\n    for idx, raw in enumerate(slides, 1):\n        raw.setdefault(\"slide_number\", idx)\n        raw.setdefault(\"chart_type\", None)\n        raw.setdefault(\"image_description\", None)\n        raw.setdefault(\"image_url\", None)\n        for key in ORDER:\n            raw.setdefault(key, None)\n        fixed.append({k: raw.get(k) for k in ORDER})\n    return fixed\n\n\ndef process_guide(guide_path: Path, prompt_template: Path, out_path: Path | None, model: str, client: anthropic.Anthropic) -> Path:\n    \"\"\"Process a single guide file and return the output path.\"\"\"\n    LOGGER.info(\"Processing guide: %s\", guide_path)\n    \n    # Determine output path\n    if not out_path:\n        out_path = guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n    \n    # Read guide and build prompt\n    guide_txt = guide_path.read_text(encoding=\"utf-8\")\n    prompt = build_prompt(prompt_template, guide_txt)\n    \n    # Request Claude with retries\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            LOGGER.info(\"Requesting Claude (%s) for %s...\", model, guide_path.name)\n            rsp = client.messages.create(\n                model=model,\n                max_tokens=16_000,\n                system=\"Return JSON only.\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            )\n            \n            raw = rsp.content[0].text\n            start = raw.find(\"[\")\n            if start == -1:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Claude response contained no JSON array, retrying in %d seconds...\", 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Claude response contained no JSON array after %d attempts\", max_attempts)\n                    raise ValueError(\"Claude response contained no JSON array\")\n            \n            try:\n                slides = json.loads(raw[start:])\n            except json.JSONDecodeError as e:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Invalid JSON from Claude: %s, retrying in %d seconds...\", e, 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Invalid JSON from Claude after %d attempts: %s\", max_attempts, e)\n                    raise\n            \n            # Normalize and save\n            slides = normalize(slides)\n            out_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n            LOGGER.info(\"Wrote %d slides → %s\", len(slides), out_path)\n            return out_path\n            \n        except (anthropic.APIError, anthropic.APITimeoutError, anthropic.APIConnectionError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"API error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                            attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)\n            else:\n                LOGGER.error(\"API error after %d attempts: %s\", max_attempts, e, exc_info=True)\n                raise\n    \n    raise RuntimeError(\"Failed to process guide, this should not happen\")  # Unreachable\n\n\ndef process_directory(guide_dir: Path, prompt_template: Path, model: str, batch_size: int, client: anthropic.Anthropic) -> List[Path]:\n    \"\"\"Process all markdown files in a directory.\"\"\"\n    LOGGER.info(\"Processing all markdown files in: %s\", guide_dir)\n    \n    # Find all markdown files\n    md_files = list(guide_dir.glob(\"*.md\"))\n    if not md_files:\n        LOGGER.error(\"No markdown files found in %s\", guide_dir)\n        sys.exit(1)\n    \n    LOGGER.info(\"Found %d markdown files to process\", len(md_files))\n    \n    # Process files in batches to avoid overwhelming the API\n    results = []\n    for i in range(0, len(md_files), batch_size):\n        batch = md_files[i:i + batch_size]\n        LOGGER.info(\"Processing batch %d/%d (%d files)\", i // batch_size + 1, \n                   (len(md_files) + batch_size - 1) // batch_size, len(batch))\n        \n        for guide_path in batch:\n            try:\n                out_path = process_guide(guide_path, prompt_template, None, model, client)\n                results.append(out_path)\n            except Exception as e:\n                LOGGER.error(\"Failed to process %s: %s\", guide_path, e, exc_info=True)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n    if not api_key:\n        LOGGER.error(\"Set ANTHROPIC_API_KEY environment variable\")\n        sys.exit(1)\n\n    # Validate paths\n    guide_path = Path(args.guide)\n    prompt_path = Path(args.prompt)\n    \n    if not prompt_path.exists():\n        LOGGER.error(\"Prompt template not found: %s\", prompt_path)\n        sys.exit(1)\n    \n    if guide_path.is_dir():\n        LOGGER.info(\"Directory mode: Processing all markdown files in %s\", guide_path)\n        if args.out:\n            LOGGER.warning(\"--out parameter ignored in directory mode\")\n        \n        # Initialize Claude client\n        client = anthropic.Anthropic(api_key=api_key)\n        \n        # Process directory\n        process_directory(guide_path, prompt_path, args.model, args.batch_size, client)\n        \n    else:\n        # Single file mode\n        if not guide_path.exists():\n            LOGGER.error(\"Guide file not found: %s\", guide_path)\n            sys.exit(1)\n        \n        # Determine output path\n        out_path = Path(args.out) if args.out else guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n        \n        # Initialize Claude client\n        client = anthropic.Anthropic(api_key=api_key)\n        \n        # Process single guide\n        process_guide(guide_path, prompt_path, out_path, args.model, client)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### 3. Reviewing and updating `build_slides.py`\n\nLet's review and update the build_slides.py script to work better with the Google Slides API:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Create a Google Slides deck from slides.json.\n\nSupports optional `--template-id` (an existing Slides file); if provided the\nfile will be duplicated via Drive API and populated, preserving the original\nlayout/theme.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, time\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Any\nfrom urllib.parse import urlparse\n\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom google.auth.transport.requests import Request\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\nSCOPES = [\n    \"https://www.googleapis.com/auth/presentations\",\n    \"https://www.googleapis.com/auth/drive.file\",\n]\nLOGGER = logging.getLogger(\"build_slides\")\n\n# Default slide layouts and their placeholder types\nLAYOUT_PLACEHOLDERS = {\n    \"TITLE\": [\"TITLE\"],\n    \"TITLE_AND_BODY\": [\"TITLE\", \"BODY\"],\n    \"TITLE_AND_TWO_COLUMNS\": [\"TITLE\", \"BODY\", \"BODY_2\"],\n    \"TITLE_ONLY\": [\"TITLE\"],\n    \"SECTION_HEADER\": [\"TITLE\", \"SUBTITLE\"],\n    \"MAIN_POINT\": [\"TITLE\", \"BODY\"],\n    \"CAPTION\": [\"TITLE\", \"SUBTITLE\"],\n    \"BLANK\": [],\n}\n\n# ---------- auth helpers ----------------------------------------------------\n\ndef auth(port: int) -> Tuple[Any, Any]:\n    \"\"\"Authenticate with Google and return Slides and Drive services.\"\"\"\n    token_path = Path(\"oauth-token.json\")\n    client_path = Path(\"oauth-client.json\")\n    \n    # Try to find client secret file with alternative names\n    if not client_path.exists():\n        # Look for client_secret_*.json files\n        client_secrets = list(Path().glob(\"client_secret_*.json\"))\n        if client_secrets:\n            client_path = client_secrets[0]\n            LOGGER.info(\"Using client secret file: %s\", client_path)\n    \n    creds: Credentials | None = None\n    if token_path.exists():\n        creds = Credentials.from_authorized_user_file(token_path, SCOPES)\n    \n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            try:\n                creds.refresh(Request())\n            except Exception as e:\n                LOGGER.warning(\"Failed to refresh token: %s\", e)\n                creds = None\n        \n        if not creds:\n            if not client_path.exists():\n                LOGGER.error(\"OAuth client file not found: %s\", client_path)\n                LOGGER.error(\"Download client_secret_*.json from Google Cloud Console\")\n                sys.exit(1)\n            \n            flow = InstalledAppFlow.from_client_secrets_file(client_path, SCOPES)\n            creds = flow.run_local_server(port=port)\n        \n        token_path.write_text(creds.to_json())\n    \n    slides_service = build(\"slides\", \"v1\", credentials=creds)\n    drive_service = build(\"drive\", \"v3\", credentials=creds)\n    return slides_service, drive_service\n\n\n# ---------- template handling -----------------------------------------------\n\ndef duplicate_template(drive, template_id: str, title: str) -> str:\n    \"\"\"Create a copy of a template presentation and return its ID.\"\"\"\n    file_meta = {\"name\": title}\n    try:\n        copied = drive.files().copy(fileId=template_id, body=file_meta).execute()\n        return copied[\"id\"]\n    except HttpError as e:\n        if e.status_code == 404:\n            LOGGER.error(\"Template presentation not found (ID: %s)\", template_id)\n        else:\n            LOGGER.error(\"Failed to copy template: %s\", e)\n        raise\n\n\ndef get_slide_layouts(slides_service, presentation_id: str) -> Dict[str, Dict]:\n    \"\"\"Get available slide layouts and their placeholders in the presentation.\"\"\"\n    try:\n        presentation = slides_service.presentations().get(presentationId=presentation_id).execute()\n        \n        layouts = {}\n        # Find all slide layouts in the presentation masters\n        for master in presentation.get(\"masters\", []):\n            for layout in master.get(\"layouts\", []):\n                layout_name = layout.get(\"layoutProperties\", {}).get(\"displayName\", \"\").upper()\n                if not layout_name:\n                    continue\n                \n                # Extract placeholders\n                placeholders = {}\n                for placeholder in layout.get(\"pageElements\", []):\n                    if \"shape\" in placeholder and \"placeholder\" in placeholder[\"shape\"]:\n                        placeholder_id = placeholder.get(\"objectId\", \"\")\n                        placeholder_type = placeholder[\"shape\"][\"placeholder\"].get(\"type\", \"\")\n                        placeholders[placeholder_type] = placeholder_id\n                \n                layouts[layout_name] = {\n                    \"layout_id\": layout.get(\"objectId\", \"\"),\n                    \"placeholders\": placeholders\n                }\n        \n        return layouts\n    \n    except HttpError as e:\n        LOGGER.error(\"Failed to get slide layouts: %s\", e)\n        raise\n\n\n# ---------- slide generation ------------------------------------------------\n\ndef choose_layout(slide: dict) -> str:\n    \"\"\"Choose the best layout for a slide based on its content.\"\"\"\n    if slide.get(\"slide_number\") == 1:\n        return \"TITLE\"\n    \n    has_image = bool(slide.get(\"image_url\"))\n    has_content = bool(slide.get(\"content\"))\n    \n    if has_image and has_content:\n        return \"TITLE_AND_TWO_COLUMNS\"\n    elif has_image and not has_content:\n        return \"CAPTION\"  # Image with title\n    elif has_content:\n        return \"TITLE_AND_BODY\"\n    else:\n        return \"TITLE_ONLY\"\n\n\ndef extract_image_filename(url: str) -> str:\n    \"\"\"Extract image filename from URL for local file matching.\"\"\"\n    parsed = urlparse(url)\n    path = parsed.path\n    filename = os.path.basename(path)\n    # Remove any query parameters from the filename\n    filename = filename.split('?')[0]\n    return filename\n\n\ndef build_requests(slides: list[dict], custom_layouts: Dict = None) -> list[dict]:\n    \"\"\"Build slide creation and content requests.\"\"\"\n    reqs: list[dict] = []\n    \n    # Delete the default slide if we're adding our own\n    reqs.append({\"deleteObject\": {\"objectId\": \"p\"}})\n    \n    for sl in slides:\n        page_id = f\"p{sl['slide_number']}\"\n        layout = choose_layout(sl)\n        \n        # Prepare placeholders\n        placeholder_mappings = []\n        placeholders = LAYOUT_PLACEHOLDERS.get(layout, [])\n        for i, placeholder_type in enumerate(placeholders):\n            placeholder_id = f\"{page_id}_{placeholder_type.lower()}\"\n            placeholder_mappings.append({\n                \"layoutPlaceholder\": {\"type\": placeholder_type},\n                \"objectId\": placeholder_id\n            })\n        \n        # Create slide with layout and placeholders\n        reqs.append({\n            \"createSlide\": {\n                \"objectId\": page_id,\n                \"slideLayoutReference\": {\"predefinedLayout\": layout},\n                \"placeholderIdMappings\": placeholder_mappings\n            }\n        })\n        \n        # Add title\n        if \"title\" in sl and sl[\"title\"]:\n            title_id = f\"{page_id}_title\"\n            reqs.append({\n                \"insertText\": {\n                    \"objectId\": title_id,\n                    \"insertionIndex\": 0,\n                    \"text\": sl[\"title\"]\n                }\n            })\n        \n        # Add content to body placeholder if available\n        if \"content\" in sl and sl[\"content\"]:\n            body_id = f\"{page_id}_body\"\n            reqs.append({\n                \"insertText\": {\n                    \"objectId\": body_id,\n                    \"insertionIndex\": 0,\n                    \"text\": sl[\"content\"]\n                }\n            })\n        \n        # Add image\n        if \"image_url\" in sl and sl[\"image_url\"]:\n            # If using a two-column layout, put image in second column\n            if layout == \"TITLE_AND_TWO_COLUMNS\":\n                image_container = f\"{page_id}_body_2\"\n                reqs.append({\n                    \"createImage\": {\n                        \"url\": sl[\"image_url\"],\n                        \"elementProperties\": {\n                            \"pageObjectId\": page_id,\n                            \"size\": {\n                                \"width\": {\"magnitude\": 350, \"unit\": \"PT\"},\n                                \"height\": {\"magnitude\": 250, \"unit\": \"PT\"}\n                            },\n                            \"transform\": {\n                                \"scaleX\": 1,\n                                \"scaleY\": 1,\n                                \"translateX\": 400,  # Right side of slide\n                                \"translateY\": 150,\n                                \"unit\": \"PT\"\n                            }\n                        }\n                    }\n                })\n            else:\n                # For other layouts, center the image\n                reqs.append({\n                    \"createImage\": {\n                        \"url\": sl[\"image_url\"],\n                        \"elementProperties\": {\n                            \"pageObjectId\": page_id,\n                            \"size\": {\n                                \"width\": {\"magnitude\": 400, \"unit\": \"PT\"},\n                                \"height\": {\"magnitude\": 300, \"unit\": \"PT\"}\n                            },\n                            \"transform\": {\n                                \"scaleX\": 1,\n                                \"scaleY\": 1,\n                                \"translateX\": 150,  # Centered\n                                \"translateY\": 150,\n                                \"unit\": \"PT\"\n                            }\n                        }\n                    }\n                })\n        \n        # If there are facilitator notes, add them as speaker notes\n        if \"facilitator_notes\" in sl and sl[\"facilitator_notes\"]:\n            reqs.append({\n                \"insertText\": {\n                    \"objectId\": f\"{page_id}_speaker_notes\",\n                    \"text\": sl[\"facilitator_notes\"]\n                }\n            })\n    \n    return reqs\n\n\n# ---------- batch processing ------------------------------------------------\n\ndef process_batch(reqs: List[Dict], slides_service, presentation_id: str, batch_size: int = 20) -> List[Dict]:\n    \"\"\"Process requests in batches to avoid API limits.\"\"\"\n    results = []\n    for i in range(0, len(reqs), batch_size):\n        batch = reqs[i:i + batch_size]\n        LOGGER.info(\"Processing batch %d/%d (%d requests)\", \n                    i // batch_size + 1, \n                    (len(reqs) + batch_size - 1) // batch_size, \n                    len(batch))\n        \n        try:\n            result = slides_service.presentations().batchUpdate(\n                presentationId=presentation_id, \n                body={\"requests\": batch}\n            ).execute()\n            results.append(result)\n            \n            # Avoid rate limits\n            if i + batch_size < len(reqs):\n                time.sleep(1)\n                \n        except HttpError as e:\n            LOGGER.error(\"Batch update failed: %s\", e)\n            if e.status_code == 429:  # Too Many Requests\n                LOGGER.info(\"Hit rate limit, waiting 10 seconds before retrying...\")\n                time.sleep(10)\n                # Retry this batch\n                try:\n                    result = slides_service.presentations().batchUpdate(\n                        presentationId=presentation_id, \n                        body={\"requests\": batch}\n                    ).execute()\n                    results.append(result)\n                except HttpError as e2:\n                    LOGGER.error(\"Retry failed: %s\", e2)\n                    raise\n            else:\n                raise\n    \n    return results\n\n\n# ---------- main ------------------------------------------------------------\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Generate Google Slides deck from slides.json\")\n    p.add_argument(\"json\", help=\"slides.json with image_url filled\")\n    p.add_argument(\"--title\", default=None, help=\"Presentation title (default: based on input filename)\")\n    p.add_argument(\"--template-id\", help=\"Google Slides file ID to copy as template\")\n    p.add_argument(\"--port\", type=int, default=8080, help=\"Port for OAuth flow\")\n    p.add_argument(\"--batch-size\", type=int, default=20, help=\"Number of requests per batch\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    # Validate input JSON\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"JSON file not found: %s\", json_path)\n        sys.exit(1)\n    \n    try:\n        slides_data = json.loads(json_path.read_text())\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON: %s\", e)\n        sys.exit(1)\n    \n    # Determine presentation title\n    if args.title:\n        title = args.title\n    else:\n        # Base title on input filename\n        base_name = json_path.stem\n        if base_name.startswith(\"slides_\"):\n            base_name = base_name[7:]  # Remove \"slides_\" prefix\n        title = f\"{base_name.replace('_', ' ').title()} Presentation\"\n    \n    # Authenticate with Google\n    try:\n        slides_service, drive_service = auth(args.port)\n    except Exception as e:\n        LOGGER.error(\"Authentication failed: %s\", e)\n        sys.exit(1)\n\n    # Create or copy presentation\n    presentation_id: str\n    try:\n        if args.template_id:\n            presentation_id = duplicate_template(drive_service, args.template_id, title)\n            LOGGER.info(\"Template duplicated → %s\", presentation_id)\n        else:\n            pres = slides_service.presentations().create(body={\"title\": title}).execute()\n            presentation_id = pres[\"presentationId\"]\n            LOGGER.info(\"Blank deck created → %s\", presentation_id)\n    except HttpError as e:\n        LOGGER.error(\"Failed to create presentation: %s\", e)\n        sys.exit(1)\n\n    # Build and process requests\n    try:\n        reqs = build_requests(slides_data)\n        LOGGER.info(\"Built %d requests\", len(reqs))\n        \n        results = process_batch(reqs, slides_service, presentation_id, args.batch_size)\n        LOGGER.info(\"Slides added: %d\", len(slides_data))\n        \n        # Get the presentation URL\n        presentation_url = f\"https://docs.google.com/presentation/d/{presentation_id}/edit\"\n        print(\"\\nDeck URL:\", presentation_url)\n        \n        # Attempt to open in browser\n        import webbrowser\n        webbrowser.open(presentation_url)\n        \n    except Exception as e:\n        LOGGER.error(\"Failed to update presentation: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\nThese updated scripts should address all the user's requirements:\n\n1. `diagrams_to_images.py` now:\n   - Supports using a mermaid config JSON file\n   - Saves local copies of mermaid diagrams with the guide filename and slide number\n   - Includes retry logic for API calls\n   - Uses better error handling\n\n2. `guide_to_json.py` now:\n   - Can process a directory of markdown files\n   - Outputs JSON files in the same folder as input files\n   - Has improved error handling and retries\n   - Makes the Claude model configurable\n\n3. `build_slides.py` now:\n   - Has improved handling of different slide layouts\n   - Better manages the placement of images\n   - Supports speaker notes\n   - Includes batch processing to avoid API limits\n   - Has improved error handling\n   - Tries to find the client secret file with different naming patterns\n\nThese changes should make the slide generation pipeline more robust and address the issues the user was experiencing with Google Slides API integration.I'll update these files to enhance your slide generation system, incorporating the Mermaid config file and adding support for batch processing directories.\n\n## 1. Updated `diagrams_to_images.py`\n\n```python\n#!/usr/bin/env python3\n\"\"\"Render Mermaid diagrams & upload to FreeImage.host (API v1).\n\nAdds/overwrites image_url in slides.json whenever both diagram_type and\ndiagram_content are present. Also saves local copies of the diagrams with\nnames based on the source file.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, subprocess, sys, time, shutil\nfrom pathlib import Path\nfrom typing import Any\n\nimport requests\n\nLOGGER = logging.getLogger(\"diagrams_to_images\")\nMERMAID_CMD = \"mmdc\"  # must be on PATH\nFREEIMAGE_ENDPOINT = \"https://freeimage.host/api/1/upload\"\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Render Mermaid diagrams & upload to FreeImage.host\")\n    p.add_argument(\"json\", help=\"slides.json to update (in-place)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    p.add_argument(\"--temp-dir\", default=None, help=\"where to render PNGs temporarily (default: same as slides.json)\")\n    p.add_argument(\"--mermaid-config\", default=\"mermaid-config.json\", help=\"Mermaid configuration file\")\n    p.add_argument(\"--save-local\", action=\"store_true\", help=\"Save local copies of diagrams in the same folder\")\n    p.add_argument(\"--output-dir\", default=None, help=\"Directory to save output files (default: same as slides.json)\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef render_mermaid(src: str, tmp: Path, config_path: Path | None, base_filename: str, slide_num: int) -> tuple[Path, Path]:\n    \"\"\"Render mermaid diagram to PNG.\n    \n    Args:\n        src: Mermaid diagram content\n        tmp: Directory to save temporary files\n        config_path: Path to mermaid config file\n        base_filename: Base filename (from guide file)\n        slide_num: Slide number\n        \n    Returns:\n        tuple of (png_path, mmd_path)\n    \"\"\"\n    # Create filenames based on guide name and slide number\n    output_name = f\"{base_filename}_{slide_num}\"\n    mmd = tmp / f\"{output_name}.mmd\"\n    png = tmp / f\"{output_name}.png\"\n    \n    # Write mermaid content to file\n    mmd.write_text(src, encoding=\"utf-8\")\n    \n    # Build command with optional config\n    cmd = [MERMAID_CMD, \"-i\", mmd, \"-o\", png, \"-b\", \"transparent\"]\n    if config_path and config_path.exists():\n        cmd.extend([\"-c\", config_path])\n    \n    LOGGER.debug(\"Running command: %s\", \" \".join(str(x) for x in cmd))\n    \n    # Execute command with retry\n    for attempt in range(3):\n        try:\n            subprocess.run(cmd, check=True, capture_output=True)\n            if png.exists() and png.stat().st_size > 0:\n                return png, mmd\n            \n            if attempt < 2:  # Only log warning for first two attempts\n                LOGGER.warning(\"Empty output from mermaid-cli, retrying in 2s...\")\n                time.sleep(2)\n        except subprocess.CalledProcessError as e:\n            if attempt < 2:  # Only log error for first two attempts\n                LOGGER.warning(\"mermaid-cli error (attempt %d/3): %s\", attempt + 1, e.stderr.decode())\n                time.sleep(2)\n    \n    # If we got here, all attempts failed\n    raise RuntimeError(f\"Failed to render mermaid diagram after 3 attempts. Last error: {e.stderr.decode() if 'e' in locals() else 'Empty output'}\")\n\n\ndef upload_freeimage(png: Path) -> str:\n    \"\"\"Upload PNG to FreeImage.host and return URL.\"\"\"\n    api_key = os.getenv(\"FREEIMAGE_API_KEY\")\n    if not api_key:\n        raise RuntimeError(\"FREEIMAGE_API_KEY env var not set\")\n    \n    # Retry logic for uploads\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            with png.open(\"rb\") as fh:\n                payload = {\n                    \"key\": api_key,\n                    \"action\": \"upload\",\n                    \"format\": \"json\",\n                }\n                files = {\"source\": fh}\n                rsp = requests.post(FREEIMAGE_ENDPOINT, data=payload, files=files, timeout=20)\n                rsp.raise_for_status()\n                \n            data: dict[str, Any] = rsp.json()\n            if data.get(\"status_code\") != 200:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Upload failed (attempt %d/%d): %s. Retrying in %d seconds...\", \n                                  attempt + 1, max_attempts, data, 2 ** attempt)\n                    time.sleep(2 ** attempt)  # Exponential backoff\n                    continue\n                raise RuntimeError(f\"Upload failed after {max_attempts} attempts: {data}\")\n                \n            return data[\"image\"][\"url\"]\n            \n        except (requests.RequestException, json.JSONDecodeError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"Upload error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                              attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)  # Exponential backoff\n            else:\n                raise RuntimeError(f\"Upload failed after {max_attempts} attempts: {e}\")\n    \n    raise RuntimeError(\"Upload failed, this should not happen\")  # Unreachable\n\n\ndef get_base_filename(json_path: Path) -> str:\n    \"\"\"Extract base filename (without extension) from path.\"\"\"\n    return json_path.stem.replace('slides_', '')  # Remove 'slides_' prefix if present\n\n\ndef process(slides: list[dict], json_path: Path, tmp_dir: Path, config_path: Path, save_local: bool, output_dir: Path | None) -> int:\n    \"\"\"Process slides and render diagrams.\n    \n    Args:\n        slides: List of slide data\n        json_path: Path to slides.json file\n        tmp_dir: Directory for temporary files\n        config_path: Path to mermaid config\n        save_local: Whether to save local copies\n        output_dir: Directory to save output files (or None to use same as json_path)\n        \n    Returns:\n        Number of changed slides\n    \"\"\"\n    changed = 0\n    base_filename = get_base_filename(json_path)\n    final_dir = output_dir if output_dir else json_path.parent\n    \n    # Ensure the output directory exists\n    final_dir.mkdir(parents=True, exist_ok=True)\n    \n    for slide in slides:\n        if slide.get(\"diagram_type\") and slide.get(\"diagram_content\"):\n            try:\n                # Render diagram\n                png_path, mmd_path = render_mermaid(\n                    slide[\"diagram_content\"], \n                    tmp_dir, \n                    config_path, \n                    base_filename, \n                    slide[\"slide_number\"]\n                )\n                \n                # Upload to FreeImage\n                url = upload_freeimage(png_path)\n                slide[\"image_url\"] = url\n                changed += 1\n                \n                # Save local copies if requested\n                if save_local:\n                    local_png = final_dir / png_path.name\n                    local_mmd = final_dir / mmd_path.name\n                    \n                    shutil.copy2(png_path, local_png)\n                    shutil.copy2(mmd_path, local_mmd)\n                    LOGGER.info(\"Saved local copies: %s and %s\", local_png.name, local_mmd.name)\n                \n                LOGGER.info(\"Rendered & uploaded diagram for slide %d → %s\", slide[\"slide_number\"], url)\n                \n            except Exception as e:\n                LOGGER.error(\"Diagram for slide %d failed: %s\", slide[\"slide_number\"], e, exc_info=True)\n    \n    return changed\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine temporary directory\n    if args.temp_dir:\n        tmp_dir = Path(args.temp_dir)\n    else:\n        tmp_dir = json_path.parent\n    tmp_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    \n    # Check if mermaid config exists\n    config_path = Path(args.mermaid_config)\n    if not config_path.exists():\n        LOGGER.warning(\"Mermaid config file %s not found, using default\", config_path)\n        config_path = None\n    \n    # Process slides\n    try:\n        slides = json.loads(json_path.read_text())\n        changed = process(slides, json_path, tmp_dir, config_path, args.save_local, output_dir)\n        json_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n        LOGGER.info(\"%d diagrams processed; file updated\", changed)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 2. Updated `guide_to_json.py`\n\n```python\n#!/usr/bin/env python3\n\"\"\"Convert a facilitator guide into slides.json using Claude 3.\n\nUsage:\n  python guide_to_json.py guide.md \\\n      --prompt prompt-template.txt \\\n      --out slides.json \\\n      --log-level INFO \\\n      --log-file build.log\n      \n  # Process all markdown files in a folder:\n  python guide_to_json.py guides/ \\\n      --prompt prompt-template.txt \\\n      --log-level INFO \\\n      --log-file build.log\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, time\nfrom pathlib import Path\nfrom typing import List\nimport anthropic\n\nDEFAULT_OUT = \"slides.json\"\nDEFAULT_PROMPT = \"prompt-template.txt\"\n\nLOGGER = logging.getLogger(\"guide_to_json\")\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"LLM → JSON slide outline\")\n    p.add_argument(\"guide\", help=\"Facilitator guide (Markdown/text) or directory of guides\")\n    p.add_argument(\"--prompt\", default=DEFAULT_PROMPT, help=\"Prompt template path\")\n    p.add_argument(\"--out\", default=None, help=\"Output JSON path (ignored if guide is a directory)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None, help=\"Write logs to file as well\")\n    p.add_argument(\"--model\", default=\"claude-3-7-sonnet-20250219\", help=\"Claude model to use\")\n    p.add_argument(\"--batch-size\", type=int, default=5, help=\"Number of files to process in parallel (batch mode)\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers: list[logging.Handler] = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(\n        level=level,\n        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n        handlers=handlers,\n    )\n\n\ndef build_prompt(template_path: Path, guide_text: str) -> str:\n    tpl = template_path.read_text(encoding=\"utf-8\")\n    if \"{{content}}\" not in tpl:\n        LOGGER.error(\"Prompt template missing {{content}} placeholder → %s\", template_path)\n        sys.exit(1)\n    return tpl.replace(\"{{content}}\", guide_text)\n\n\n# Insert missing keys and correct ordering\nORDER = [\n    \"slide_number\", \"title\", \"content\", \"chart_type\", \"diagram_type\", \"diagram_content\",\n    \"image_description\", \"image_url\", \"facilitator_notes\", \"start_time\", \"end_time\",\n    \"materials\", \"worksheet\", \"improvements\", \"notes\",\n]\n\n\ndef normalize(slides: list[dict]) -> list[dict]:\n    fixed = []\n    for idx, raw in enumerate(slides, 1):\n        raw.setdefault(\"slide_number\", idx)\n        raw.setdefault(\"chart_type\", None)\n        raw.setdefault(\"image_description\", None)\n        raw.setdefault(\"image_url\", None)\n        for key in ORDER:\n            raw.setdefault(key, None)\n        fixed.append({k: raw.get(k) for k in ORDER})\n    return fixed\n\n\ndef process_guide(guide_path: Path, prompt_template: Path, out_path: Path | None, model: str, client: anthropic.Anthropic) -> Path:\n    \"\"\"Process a single guide file and return the output path.\"\"\"\n    LOGGER.info(\"Processing guide: %s\", guide_path)\n    \n    # Determine output path\n    if not out_path:\n        out_path = guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n    \n    # Read guide and build prompt\n    guide_txt = guide_path.read_text(encoding=\"utf-8\")\n    prompt = build_prompt(prompt_template, guide_txt)\n    \n    # Request Claude with retries\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            LOGGER.info(\"Requesting Claude (%s) for %s...\", model, guide_path.name)\n            rsp = client.messages.create(\n                model=model,\n                max_tokens=16_000,\n                system=\"Return JSON only.\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            )\n            \n            raw = rsp.content[0].text\n            start = raw.find(\"[\")\n            if start == -1:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Claude response contained no JSON array, retrying in %d seconds...\", 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Claude response contained no JSON array after %d attempts\", max_attempts)\n                    raise ValueError(\"Claude response contained no JSON array\")\n            \n            try:\n                slides = json.loads(raw[start:])\n            except json.JSONDecodeError as e:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Invalid JSON from Claude: %s, retrying in %d seconds...\", e, 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Invalid JSON from Claude after %d attempts: %s\", max_attempts, e)\n                    raise\n            \n            # Normalize and save\n            slides = normalize(slides)\n            out_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n            LOGGER.info(\"Wrote %d slides → %s\", len(slides), out_path)\n            return out_path\n            \n        except (anthropic.APIError, anthropic.APITimeoutError, anthropic.APIConnectionError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"API error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                            attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)\n            else:\n                LOGGER.error(\"API error after %d attempts: %s\", max_attempts, e, exc_info=True)\n                raise\n    \n    raise RuntimeError(\"Failed to process guide, this should not happen\")  # Unreachable\n\n\ndef process_directory(guide_dir: Path, prompt_template: Path, model: str, batch_size: int, client: anthropic.Anthropic) -> List[Path]:\n    \"\"\"Process all markdown files in a directory.\"\"\"\n    LOGGER.info(\"Processing all markdown files in: %s\", guide_dir)\n    \n    # Find all markdown files\n    md_files = list(guide_dir.glob(\"*.md\"))\n    if not md_files:\n        LOGGER.error(\"No markdown files found in %s\", guide_dir)\n        sys.exit(1)\n    \n    LOGGER.info(\"Found %d markdown files to process\", len(md_files))\n    \n    # Process files in batches to avoid overwhelming the API\n    results = []\n    for i in range(0, len(md_files), batch_size):\n        batch = md_files[i:i + batch_size]\n        LOGGER.info(\"Processing batch %d/%d (%d files)\", i // batch_size + 1, \n                   (len(md_files) + batch_size - 1) // batch_size, len(batch))\n        \n        for guide_path in batch:\n            try:\n                out_path = process_guide(guide_path, prompt_template, None, model, client)\n                results.append(out_path)\n            except Exception as e:\n                LOGGER.error(\"Failed to process %s: %s\", guide_path, e, exc_info=True)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n    if not api_key:\n        LOGGER.error(\"Set ANTHROPIC_API_KEY environment variable\")\n        sys.exit(1)\n\n    # Validate paths\n    guide_path = Path(args.guide)\n    prompt_path = Path(args.prompt)\n    \n    if not prompt_path.exists():\n        LOGGER.error(\"Prompt template not found: %s\", prompt_path)\n        sys.exit(1)\n    \n    if guide_path.is_dir():\n        LOGGER.info(\"Directory mode: Processing all markdown files in %s\", guide_path)\n        if args.out:\n            LOGGER.warning(\"--out parameter ignored in directory mode\")\n        \n        # Initialize Claude client\n        client = anthropic.Anthropic(api_key=api_key)\n        \n        # Process directory\n        process_directory(guide_path, prompt_path, args.model, args.batch_size, client)\n        \n    else:\n        # Single file mode\n        if not guide_path.exists():\n            LOGGER.error(\"Guide file not found: %s\", guide_path)\n            sys.exit(1)\n        \n        # Determine output path\n        out_path = Path(args.out) if args.out else guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n        \n        # Initialize Claude client\n        client = anthropic.Anthropic(api_key=api_key)\n        \n        # Process single guide\n        process_guide(guide_path, prompt_path, out_path, args.model, client)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 3. Improved `build_slides.py`\n\n```python\n#!/usr/bin/env python3\n\"\"\"Create a Google Slides deck from slides.json.\n\nSupports optional `--template-id` (an existing Slides file); if provided the\nfile will be duplicated via Drive API and populated, preserving the original\nlayout/theme.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, time\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Any\nfrom urllib.parse import urlparse\n\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom google.auth.transport.requests import Request\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\nSCOPES = [\n    \"https://www.googleapis.com/auth/presentations\",\n    \"https://www.googleapis.com/auth/drive.file\",\n]\nLOGGER = logging.getLogger(\"build_slides\")\n\n# Default slide layouts and their placeholder types\nLAYOUT_PLACEHOLDERS = {\n    \"TITLE\": [\"TITLE\", \"SUBTITLE\"],\n    \"TITLE_AND_BODY\": [\"TITLE\", \"BODY\"],\n    \"TITLE_AND_TWO_COLUMNS\": [\"TITLE\", \"BODY\", \"BODY_2\"],\n    \"TITLE_ONLY\": [\"TITLE\"],\n    \"SECTION_HEADER\": [\"TITLE\", \"SUBTITLE\"],\n    \"MAIN_POINT\": [\"TITLE\", \"BODY\"],\n    \"CAPTION\": [\"TITLE\", \"SUBTITLE\"],\n    \"BLANK\": [],\n}\n\n# ---------- auth helpers ----------------------------------------------------\n\ndef auth(port: int) -> Tuple[Any, Any]:\n    \"\"\"Authenticate with Google and return Slides and Drive services.\"\"\"\n    token_path = Path(\"oauth-token.json\")\n    client_path = Path(\"oauth-client.json\")\n    \n    # Try to find client secret file with alternative names\n    if not client_path.exists():\n        # Look for client_secret_*.json files\n        client_secrets = list(Path().glob(\"client_secret_*.json\"))\n        if client_secrets:\n            client_path = client_secrets[0]\n            LOGGER.info(\"Using client secret file: %s\", client_path)\n    \n    creds: Credentials | None = None\n    if token_path.exists():\n        creds = Credentials.from_authorized_user_file(token_path, SCOPES)\n    \n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            try:\n                creds.refresh(Request())\n            except Exception as e:\n                LOGGER.warning(\"Failed to refresh token: %s\", e)\n                creds = None\n        \n        if not creds:\n            if not client_path.exists():\n                LOGGER.error(\"OAuth client file not found: %s\", client_path)\n                LOGGER.error(\"Download client_secret_*.json from Google Cloud Console\")\n                sys.exit(1)\n            \n            flow = InstalledAppFlow.from_client_secrets_file(client_path, SCOPES)\n            creds = flow.run_local_server(port=port)\n        \n        token_path.write_text(creds.to_json())\n    \n    slides_service = build(\"slides\", \"v1\", credentials=creds)\n    drive_service = build(\"drive\", \"v3\", credentials=creds)\n    return slides_service, drive_service\n\n\n# ---------- template handling -----------------------------------------------\n\ndef duplicate_template(drive, template_id: str, title: str) -> str:\n    \"\"\"Create a copy of a template presentation and return its ID.\"\"\"\n    file_meta = {\"name\": title}\n    try:\n        copied = drive.files().copy(fileId=template_id, body=file_meta).execute()\n        return copied[\"id\"]\n    except HttpError as e:\n        if e.status_code == 404:\n            LOGGER.error(\"Template presentation not found (ID: %s)\", template_id)\n        else:\n            LOGGER.error(\"Failed to copy template: %s\", e)\n        raise\n\n\ndef get_slide_layouts(slides_service, presentation_id: str) -> Dict[str, Dict]:\n    \"\"\"Get available slide layouts and their placeholders in the presentation.\"\"\"\n    try:\n        presentation = slides_service.presentations().get(presentationId=presentation_id).execute()\n        \n        layouts = {}\n        # Find all slide layouts in the presentation masters\n        for master in presentation.get(\"masters\", []):\n            for layout in master.get(\"layouts\", []):\n                layout_name = layout.get(\"layoutProperties\", {}).get(\"displayName\", \"\").upper()\n                if not layout_name:\n                    continue\n                \n                # Extract placeholders\n                placeholders = {}\n                for placeholder in layout.get(\"pageElements\", []):\n                    if \"shape\" in placeholder and \"placeholder\" in placeholder[\"shape\"]:\n                        placeholder_id = placeholder.get(\"objectId\", \"\")\n                        placeholder_type = placeholder[\"shape\"][\"placeholder\"].get(\"type\", \"\")\n                        placeholders[placeholder_type] = placeholder_id\n                \n                layouts[layout_name] = {\n                    \"layout_id\": layout.get(\"objectId\", \"\"),\n                    \"placeholders\": placeholders\n                }\n        \n        return layouts\n    \n    except HttpError as e:\n        LOGGER.error(\"Failed to get slide layouts: %s\", e)\n        raise\n\n\n# ---------- slide generation ------------------------------------------------\n\ndef choose_layout(slide: dict) -> str:\n    \"\"\"Choose the best layout for a slide based on its content.\"\"\"\n    if slide.get(\"slide_number\") == 1:\n        return \"TITLE\"\n    \n    has_image = bool(slide.get(\"image_url\"))\n    has_content = bool(slide.get(\"content\"))\n    \n    if has_image and has_content:\n        return \"TITLE_AND_TWO_COLUMNS\"\n    elif has_image and not has_content:\n        return \"CAPTION\"  # Image with title\n    elif has_content:\n        return \"TITLE_AND_BODY\"\n    else:\n        return \"TITLE_ONLY\"\n\n\ndef extract_image_filename(url: str) -> str:\n    \"\"\"Extract image filename from URL for local file matching.\"\"\"\n    parsed = urlparse(url)\n    path = parsed.path\n    filename = os.path.basename(path)\n    # Remove any query parameters from the filename\n    filename = filename.split('?')[0]\n    return filename\n\n\ndef build_requests(slides: list[dict], custom_layouts: Dict = None) -> list[dict]:\n    \"\"\"Build slide creation and content requests.\"\"\"\n    reqs: list[dict] = []\n    \n    # Delete the default slide if we're adding our own\n    reqs.append({\"deleteObject\": {\"objectId\": \"p\"}})\n    \n    for sl in slides:\n        page_id = f\"p{sl['slide_number']}\"\n        layout = choose_layout(sl)\n        \n        # Prepare placeholders\n        placeholder_mappings = []\n        placeholders = LAYOUT_PLACEHOLDERS.get(layout, [])\n        for i, placeholder_type in enumerate(placeholders):\n            placeholder_id = f\"{page_id}_{placeholder_type.lower()}\"\n            placeholder_mappings.append({\n                \"layoutPlaceholder\": {\"type\": placeholder_type},\n                \"objectId\": placeholder_id\n            })\n        \n        # Create slide with layout and placeholders\n        reqs.append({\n            \"createSlide\": {\n                \"objectId\": page_id,\n                \"slideLayoutReference\": {\"predefinedLayout\": layout},\n                \"placeholderIdMappings\": placeholder_mappings\n            }\n        })\n        \n        # Add title\n        if \"title\" in sl and sl[\"title\"]:\n            title_id = f\"{page_id}_title\"\n            reqs.append({\n                \"insertText\": {\n                    \"objectId\": title_id,\n                    \"insertionIndex\": 0,\n                    \"text\": sl[\"title\"]\n                }\n            })\n        \n        # Add content to body placeholder if available\n        if \"content\" in sl and sl[\"content\"]:\n            body_id = f\"{page_id}_body\"\n            reqs.append({\n                \"insertText\": {\n                    \"objectId\": body_id,\n                    \"insertionIndex\": 0,\n                    \"text\": sl[\"content\"]\n                }\n            })\n        \n        # Add image\n        if \"image_url\" in sl and sl[\"image_url\"]:\n            # If using a two-column layout, put image in second column\n            if layout == \"TITLE_AND_TWO_COLUMNS\":\n                image_container = f\"{page_id}_body_2\"\n                reqs.append({\n                    \"createImage\": {\n                        \"url\": sl[\"image_url\"],\n                        \"elementProperties\": {\n                            \"pageObjectId\": page_id,\n                            \"size\": {\n                                \"width\": {\"magnitude\": 350, \"unit\": \"PT\"},\n                                \"height\": {\"magnitude\": 250, \"unit\": \"PT\"}\n                            },\n                            \"transform\": {\n                                \"scaleX\": 1,\n                                \"scaleY\": 1,\n                                \"translateX\": 400,  # Right side of slide\n                                \"translateY\": 150,\n                                \"unit\": \"PT\"\n                            }\n                        }\n                    }\n                })\n            else:\n                # For other layouts, center the image\n                reqs.append({\n                    \"createImage\": {\n                        \"url\": sl[\"image_url\"],\n                        \"elementProperties\": {\n                            \"pageObjectId\": page_id,\n                            \"size\": {\n                                \"width\": {\"magnitude\": 400, \"unit\": \"PT\"},\n                                \"height\": {\"magnitude\": 300, \"unit\": \"PT\"}\n                            },\n                            \"transform\": {\n                                \"scaleX\": 1,\n                                \"scaleY\": 1,\n                                \"translateX\": 150,  # Centered\n                                \"translateY\": 150,\n                                \"unit\": \"PT\"\n                            }\n                        }\n                    }\n                })\n        \n        # If there are facilitator notes, add them as speaker notes\n        if \"facilitator_notes\" in sl and sl[\"facilitator_notes\"]:\n            reqs.append({\n                \"insertText\": {\n                    \"objectId\": f\"{page_id}\",\n                    \"insertionIndex\": 0,\n                    \"text\": sl[\"facilitator_notes\"]\n                }\n            })\n    \n    return reqs\n\n\n# ---------- batch processing ------------------------------------------------\n\ndef process_batch(reqs: List[Dict], slides_service, presentation_id: str, batch_size: int = 20) -> List[Dict]:\n    \"\"\"Process requests in batches to avoid API limits.\"\"\"\n    results = []\n    for i in range(0, len(reqs), batch_size):\n        batch = reqs[i:i + batch_size]\n        LOGGER.info(\"Processing batch %d/%d (%d requests)\", \n                    i // batch_size + 1, \n                    (len(reqs) + batch_size - 1) // batch_size, \n                    len(batch))\n        \n        try:\n            result = slides_service.presentations().batchUpdate(\n                presentationId=presentation_id, \n                body={\"requests\": batch}\n            ).execute()\n            results.append(result)\n            \n            # Avoid rate limits\n            if i + batch_size < len(reqs):\n                time.sleep(1)\n                \n        except HttpError as e:\n            LOGGER.error(\"Batch update failed: %s\", e)\n            if e.status_code == 429:  # Too Many Requests\n                LOGGER.info(\"Hit rate limit, waiting 10 seconds before retrying...\")\n                time.sleep(10)\n                # Retry this batch\n                try:\n                    result = slides_service.presentations().batchUpdate(\n                        presentationId=presentation_id, \n                        body={\"requests\": batch}\n                    ).execute()\n                    results.append(result)\n                except HttpError as e2:\n                    LOGGER.error(\"Retry failed: %s\", e2)\n                    raise\n            else:\n                raise\n    \n    return results\n\n\n# ---------- main ------------------------------------------------------------\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Generate Google Slides deck from slides.json\")\n    p.add_argument(\"json\", help=\"slides.json with image_url filled\")\n    p.add_argument(\"--title\", default=None, help=\"Presentation title (default: based on input filename)\")\n    p.add_argument(\"--template-id\", help=\"Google Slides file ID to copy as template\")\n    p.add_argument(\"--port\", type=int, default=8080, help=\"Port for OAuth flow\")\n    p.add_argument(\"--batch-size\", type=int, default=20, help=\"Number of requests per batch\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    # Validate input JSON\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"JSON file not found: %s\", json_path)\n        sys.exit(1)\n    \n    try:\n        slides_data = json.loads(json_path.read_text())\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON: %s\", e)\n        sys.exit(1)\n    \n    # Determine presentation title\n    if args.title:\n        title = args.title\n    else:\n        # Base title on input filename\n        base_name = json_path.stem\n        if base_name.startswith(\"slides_\"):\n            base_name = base_name[7:]  # Remove \"slides_\" prefix\n        title = f\"{base_name.replace('_', ' ').title()} Presentation\"\n    \n    # Authenticate with Google\n    try:\n        slides_service, drive_service = auth(args.port)\n    except Exception as e:\n        LOGGER.error(\"Authentication failed: %s\", e)\n        sys.exit(1)\n\n    # Create or copy presentation\n    presentation_id: str\n    try:\n        if args.template_id:\n            presentation_id = duplicate_template(drive_service, args.template_id, title)\n            LOGGER.info(\"Template duplicated → %s\", presentation_id)\n        else:\n            pres = slides_service.presentations().create(body={\"title\": title}).execute()\n            presentation_id = pres[\"presentationId\"]\n            LOGGER.info(\"Blank deck created → %s\", presentation_id)\n    except HttpError as e:\n        LOGGER.error(\"Failed to create presentation: %s\", e)\n        sys.exit(1)\n\n    # Build and process requests\n    try:\n        reqs = build_requests(slides_data)\n        LOGGER.info(\"Built %d requests\", len(reqs))\n        \n        results = process_batch(reqs, slides_service, presentation_id, args.batch_size)\n        LOGGER.info(\"Slides added: %d\", len(slides_data))\n        \n        # Get the presentation URL\n        presentation_url = f\"https://docs.google.com/presentation/d/{presentation_id}/edit\"\n        print(\"\\nDeck URL:\", presentation_url)\n        \n        # Attempt to open in browser\n        import webbrowser\n        webbrowser.open(presentation_url)\n        \n    except Exception as e:\n        LOGGER.error(\"Failed to update presentation: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## Key Improvements\n\n### 1. In `diagrams_to_images.py`:\n- Added support for Mermaid config JSON\n- Save local copies of both .mmd and .png files based on the guide filename and slide number\n- Added retry logic with exponential backoff\n- Added more robust error handling\n- Configurable output directory\n\n### 2. In `guide_to_json.py`:\n- Added directory processing capability\n- Output JSON files to the same folder as input files\n- Added retry logic for API calls\n- Made Claude model configurable\n- Better error handling with specific error messages\n\n### 3. In `build_slides.py`:\n- Fixed the critical issue with placeholder management\n- Better handles different slide layouts\n- Automatically detects client_secret_*.json files\n- Added speaker notes support\n- Improved image placement based on slide layout\n- Added batch processing to avoid API rate limits\n- Intelligent naming of slides based on input file\n\n## Usage Examples\n\n### Process a directory of guides and generate slides:\n\n```bash\n# Step 1: Process all MD files in a directory\npython guide_to_json.py guides/ --prompt prompt-template.txt --log-level INFO\n\n# Step 2: Process diagrams with mermaid config and save local copies\npython diagrams_to_images.py guides/slides_workshop.json --mermaid-config mermaid-config.json --save-local\n\n# Step 3: Build slides with Google Slides\npython build_slides.py guides/slides_workshop.json --template-id YOUR_TEMPLATE_ID\n```\n\nThese improved scripts should make your slide generation pipeline much more robust while keeping all generated assets properly organized and named. The improvements address the Google Slides API issues that were causing problems with inserting content and images.",
      "created_at": "2025-05-20T06:16:33.514117Z",
      "sequence_order": 3,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-20T06:12:34.277668Z",
            "stop_timestamp": "2025-05-20T06:14:26.095722Z",
            "flags": null,
            "type": "thinking",
            "thinking": "Let's break down what the user is requesting:\n\n1. Update `diagrams_to_images.py` to use a mermaid config JSON file\n2. Update `guide_to_json.py` to:\n   - Accept a folder path as input\n   - Process all files in that folder\n   - Export output JSON files to the same folder\n3. Review `build_slides.py` for Google Slides API best practices\n4. Add functionality to save images with specific naming conventions:\n   - Name format: `[guide_filename]_[slide_number]`\n   - Save in the same folder as the guide file\n5. Save exported mermaid diagrams in the same folder\n\nLet's start by updating each file one by one.\n\n### 1. Updating `diagrams_to_images.py`\n\nFor this file, we need to:\n- Add support for a mermaid config JSON file\n- Save the output images in the same folder with proper naming\n- Save the mermaid diagrams in the same folder\n\nHere's the updated version:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Render Mermaid diagrams & upload to FreeImage.host (API v1).\n\nAdds/overwrites image_url in slides.json whenever both diagram_type and\ndiagram_content are present. Also saves local copies of the diagrams with\nnames based on the source file.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, subprocess, sys, time, shutil\nfrom pathlib import Path\nfrom typing import Any\n\nimport requests\n\nLOGGER = logging.getLogger(\"diagrams_to_images\")\nMERMAID_CMD = \"mmdc\"  # must be on PATH\nFREEIMAGE_ENDPOINT = \"https://freeimage.host/api/1/upload\"\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Render Mermaid diagrams & upload to FreeImage.host\")\n    p.add_argument(\"json\", help=\"slides.json to update (in-place)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    p.add_argument(\"--temp-dir\", default=None, help=\"where to render PNGs temporarily (default: same as slides.json)\")\n    p.add_argument(\"--mermaid-config\", default=\"mermaid-config.json\", help=\"Mermaid configuration file\")\n    p.add_argument(\"--save-local\", action=\"store_true\", help=\"Save local copies of diagrams in the same folder\")\n    p.add_argument(\"--output-dir\", default=None, help=\"Directory to save output files (default: same as slides.json)\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef render_mermaid(src: str, tmp: Path, config_path: Path | None, base_filename: str, slide_num: int) -> tuple[Path, Path]:\n    \"\"\"Render mermaid diagram to PNG.\n    \n    Args:\n        src: Mermaid diagram content\n        tmp: Directory to save temporary files\n        config_path: Path to mermaid config file\n        base_filename: Base filename (from guide file)\n        slide_num: Slide number\n        \n    Returns:\n        tuple of (png_path, mmd_path)\n    \"\"\"\n    # Create filenames based on guide name and slide number\n    output_name = f\"{base_filename}_{slide_num}\"\n    mmd = tmp / f\"{output_name}.mmd\"\n    png = tmp / f\"{output_name}.png\"\n    \n    # Write mermaid content to file\n    mmd.write_text(src, encoding=\"utf-8\")\n    \n    # Build command with optional config\n    cmd = [MERMAID_CMD, \"-i\", mmd, \"-o\", png, \"-b\", \"transparent\"]\n    if config_path and config_path.exists():\n        cmd.extend([\"-c\", config_path])\n    \n    LOGGER.debug(\"Running command: %s\", \" \".join(str(x) for x in cmd))\n    \n    # Execute command with retry\n    for attempt in range(3):\n        try:\n            subprocess.run(cmd, check=True, capture_output=True)\n            if png.exists() and png.stat().st_size > 0:\n                return png, mmd\n            \n            if attempt < 2:  # Only log warning for first two attempts\n                LOGGER.warning(\"Empty output from mermaid-cli, retrying in 2s...\")\n                time.sleep(2)\n        except subprocess.CalledProcessError as e:\n            if attempt < 2:  # Only log error for first two attempts\n                LOGGER.warning(\"mermaid-cli error (attempt %d/3): %s\", attempt + 1, e.stderr.decode())\n                time.sleep(2)\n    \n    # If we got here, all attempts failed\n    raise RuntimeError(f\"Failed to render mermaid diagram after 3 attempts. Last error: {e.stderr.decode() if 'e' in locals() else 'Empty output'}\")\n\n\ndef upload_freeimage(png: Path) -> str:\n    \"\"\"Upload PNG to FreeImage.host and return URL.\"\"\"\n    api_key = os.getenv(\"FREEIMAGE_API_KEY\")\n    if not api_key:\n        raise RuntimeError(\"FREEIMAGE_API_KEY env var not set\")\n    \n    # Retry logic for uploads\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            with png.open(\"rb\") as fh:\n                payload = {\n                    \"key\": api_key,\n                    \"action\": \"upload\",\n                    \"format\": \"json\",\n                }\n                files = {\"source\": fh}\n                rsp = requests.post(FREEIMAGE_ENDPOINT, data=payload, files=files, timeout=20)\n                rsp.raise_for_status()\n                \n            data: dict[str, Any] = rsp.json()\n            if data.get(\"status_code\") != 200:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Upload failed (attempt %d/%d): %s. Retrying in %d seconds...\", \n                                  attempt + 1, max_attempts, data, 2 ** attempt)\n                    time.sleep(2 ** attempt)  # Exponential backoff\n                    continue\n                raise RuntimeError(f\"Upload failed after {max_attempts} attempts: {data}\")\n                \n            return data[\"image\"][\"url\"]\n            \n        except (requests.RequestException, json.JSONDecodeError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"Upload error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                              attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)  # Exponential backoff\n            else:\n                raise RuntimeError(f\"Upload failed after {max_attempts} attempts: {e}\")\n    \n    raise RuntimeError(\"Upload failed, this should not happen\")  # Unreachable\n\n\ndef get_base_filename(json_path: Path) -> str:\n    \"\"\"Extract base filename (without extension) from path.\"\"\"\n    return json_path.stem.replace('slides_', '')  # Remove 'slides_' prefix if present\n\n\ndef process(slides: list[dict], json_path: Path, tmp_dir: Path, config_path: Path, save_local: bool, output_dir: Path | None) -> int:\n    \"\"\"Process slides and render diagrams.\n    \n    Args:\n        slides: List of slide data\n        json_path: Path to slides.json file\n        tmp_dir: Directory for temporary files\n        config_path: Path to mermaid config\n        save_local: Whether to save local copies\n        output_dir: Directory to save output files (or None to use same as json_path)\n        \n    Returns:\n        Number of changed slides\n    \"\"\"\n    changed = 0\n    base_filename = get_base_filename(json_path)\n    final_dir = output_dir if output_dir else json_path.parent\n    \n    # Ensure the output directory exists\n    final_dir.mkdir(parents=True, exist_ok=True)\n    \n    for slide in slides:\n        if slide.get(\"diagram_type\") and slide.get(\"diagram_content\"):\n            try:\n                # Render diagram\n                png_path, mmd_path = render_mermaid(\n                    slide[\"diagram_content\"], \n                    tmp_dir, \n                    config_path, \n                    base_filename, \n                    slide[\"slide_number\"]\n                )\n                \n                # Upload to FreeImage\n                url = upload_freeimage(png_path)\n                slide[\"image_url\"] = url\n                changed += 1\n                \n                # Save local copies if requested\n                if save_local:\n                    local_png = final_dir / png_path.name\n                    local_mmd = final_dir / mmd_path.name\n                    \n                    shutil.copy2(png_path, local_png)\n                    shutil.copy2(mmd_path, local_mmd)\n                    LOGGER.info(\"Saved local copies: %s and %s\", local_png.name, local_mmd.name)\n                \n                LOGGER.info(\"Rendered & uploaded diagram for slide %d → %s\", slide[\"slide_number\"], url)\n                \n            except Exception as e:\n                LOGGER.error(\"Diagram for slide %d failed: %s\", slide[\"slide_number\"], e, exc_info=True)\n    \n    return changed\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine temporary directory\n    if args.temp_dir:\n        tmp_dir = Path(args.temp_dir)\n    else:\n        tmp_dir = json_path.parent\n    tmp_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    \n    # Check if mermaid config exists\n    config_path = Path(args.mermaid_config)\n    if not config_path.exists():\n        LOGGER.warning(\"Mermaid config file %s not found, using default\", config_path)\n        config_path = None\n    \n    # Process slides\n    try:\n        slides = json.loads(json_path.read_text())\n        changed = process(slides, json_path, tmp_dir, config_path, args.save_local, output_dir)\n        json_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n        LOGGER.info(\"%d diagrams processed; file updated\", changed)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### 2. Updating `guide_to_json.py`\n\nNow let's update this script to handle folder processing:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Convert a facilitator guide into slides.json using Claude 3.\n\nUsage:\n  python guide_to_json.py guide.md \\\n      --prompt prompt-template.txt \\\n      --out slides.json \\\n      --log-level INFO \\\n      --log-file build.log\n      \n  # Process all markdown files in a folder:\n  python guide_to_json.py guides/ \\\n      --prompt prompt-template.txt \\\n      --log-level INFO \\\n      --log-file build.log\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, time\nfrom pathlib import Path\nfrom typing import List\nimport anthropic\n\nDEFAULT_OUT = \"slides.json\"\nDEFAULT_PROMPT = \"prompt-template.txt\"\n\nLOGGER = logging.getLogger(\"guide_to_json\")\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"LLM → JSON slide outline\")\n    p.add_argument(\"guide\", help=\"Facilitator guide (Markdown/text) or directory of guides\")\n    p.add_argument(\"--prompt\", default=DEFAULT_PROMPT, help=\"Prompt template path\")\n    p.add_argument(\"--out\", default=None, help=\"Output JSON path (ignored if guide is a directory)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None, help=\"Write logs to file as well\")\n    p.add_argument(\"--model\", default=\"claude-3-7-sonnet-20250219\", help=\"Claude model to use\")\n    p.add_argument(\"--batch-size\", type=int, default=5, help=\"Number of files to process in parallel (batch mode)\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers: list[logging.Handler] = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(\n        level=level,\n        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n        handlers=handlers,\n    )\n\n\ndef build_prompt(template_path: Path, guide_text: str) -> str:\n    tpl = template_path.read_text(encoding=\"utf-8\")\n    if \"{{content}}\" not in tpl:\n        LOGGER.error(\"Prompt template missing {{content}} placeholder → %s\", template_path)\n        sys.exit(1)\n    return tpl.replace(\"{{content}}\", guide_text)\n\n\n# Insert missing keys and correct ordering\nORDER = [\n    \"slide_number\", \"title\", \"content\", \"chart_type\", \"diagram_type\", \"diagram_content\",\n    \"image_description\", \"image_url\", \"facilitator_notes\", \"start_time\", \"end_time\",\n    \"materials\", \"worksheet\", \"improvements\", \"notes\",\n]\n\n\ndef normalize(slides: list[dict]) -> list[dict]:\n    fixed = []\n    for idx, raw in enumerate(slides, 1):\n        raw.setdefault(\"slide_number\", idx)\n        raw.setdefault(\"chart_type\", None)\n        raw.setdefault(\"image_description\", None)\n        raw.setdefault(\"image_url\", None)\n        for key in ORDER:\n            raw.setdefault(key, None)\n        fixed.append({k: raw.get(k) for k in ORDER})\n    return fixed\n\n\ndef process_guide(guide_path: Path, prompt_template: Path, out_path: Path | None, model: str, client: anthropic.Anthropic) -> Path:\n    \"\"\"Process a single guide file and return the output path.\"\"\"\n    LOGGER.info(\"Processing guide: %s\", guide_path)\n    \n    # Determine output path\n    if not out_path:\n        out_path = guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n    \n    # Read guide and build prompt\n    guide_txt = guide_path.read_text(encoding=\"utf-8\")\n    prompt = build_prompt(prompt_template, guide_txt)\n    \n    # Request Claude with retries\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            LOGGER.info(\"Requesting Claude (%s) for %s...\", model, guide_path.name)\n            rsp = client.messages.create(\n                model=model,\n                max_tokens=16_000,\n                system=\"Return JSON only.\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            )\n            \n            raw = rsp.content[0].text\n            start = raw.find(\"[\")\n            if start == -1:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Claude response contained no JSON array, retrying in %d seconds...\", 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Claude response contained no JSON array after %d attempts\", max_attempts)\n                    raise ValueError(\"Claude response contained no JSON array\")\n            \n            try:\n                slides = json.loads(raw[start:])\n            except json.JSONDecodeError as e:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Invalid JSON from Claude: %s, retrying in %d seconds...\", e, 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Invalid JSON from Claude after %d attempts: %s\", max_attempts, e)\n                    raise\n            \n            # Normalize and save\n            slides = normalize(slides)\n            out_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n            LOGGER.info(\"Wrote %d slides → %s\", len(slides), out_path)\n            return out_path\n            \n        except (anthropic.APIError, anthropic.APITimeoutError, anthropic.APIConnectionError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"API error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                            attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)\n            else:\n                LOGGER.error(\"API error after %d attempts: %s\", max_attempts, e, exc_info=True)\n                raise\n    \n    raise RuntimeError(\"Failed to process guide, this should not happen\")  # Unreachable\n\n\ndef process_directory(guide_dir: Path, prompt_template: Path, model: str, batch_size: int, client: anthropic.Anthropic) -> List[Path]:\n    \"\"\"Process all markdown files in a directory.\"\"\"\n    LOGGER.info(\"Processing all markdown files in: %s\", guide_dir)\n    \n    # Find all markdown files\n    md_files = list(guide_dir.glob(\"*.md\"))\n    if not md_files:\n        LOGGER.error(\"No markdown files found in %s\", guide_dir)\n        sys.exit(1)\n    \n    LOGGER.info(\"Found %d markdown files to process\", len(md_files))\n    \n    # Process files in batches to avoid overwhelming the API\n    results = []\n    for i in range(0, len(md_files), batch_size):\n        batch = md_files[i:i + batch_size]\n        LOGGER.info(\"Processing batch %d/%d (%d files)\", i // batch_size + 1, \n                   (len(md_files) + batch_size - 1) // batch_size, len(batch))\n        \n        for guide_path in batch:\n            try:\n                out_path = process_guide(guide_path, prompt_template, None, model, client)\n                results.append(out_path)\n            except Exception as e:\n                LOGGER.error(\"Failed to process %s: %s\", guide_path, e, exc_info=True)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n    if not api_key:\n        LOGGER.error(\"Set ANTHROPIC_API_KEY environment variable\")\n        sys.exit(1)\n\n    # Validate paths\n    guide_path = Path(args.guide)\n    prompt_path = Path(args.prompt)\n    \n    if not prompt_path.exists():\n        LOGGER.error(\"Prompt template not found: %s\", prompt_path)\n        sys.exit(1)\n    \n    if guide_path.is_dir():\n        LOGGER.info(\"Directory mode: Processing all markdown files in %s\", guide_path)\n        if args.out:\n            LOGGER.warning(\"--out parameter ignored in directory mode\")\n        \n        # Initialize Claude client\n        client = anthropic.Anthropic(api_key=api_key)\n        \n        # Process directory\n        process_directory(guide_path, prompt_path, args.model, args.batch_size, client)\n        \n    else:\n        # Single file mode\n        if not guide_path.exists():\n            LOGGER.error(\"Guide file not found: %s\", guide_path)\n            sys.exit(1)\n        \n        # Determine output path\n        out_path = Path(args.out) if args.out else guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n        \n        # Initialize Claude client\n        client = anthropic.Anthropic(api_key=api_key)\n        \n        # Process single guide\n        process_guide(guide_path, prompt_path, out_path, args.model, client)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### 3. Reviewing and updating `build_slides.py`\n\nLet's review and update the build_slides.py script to work better with the Google Slides API:\n\n```python\n#!/usr/bin/env python3\n\"\"\"Create a Google Slides deck from slides.json.\n\nSupports optional `--template-id` (an existing Slides file); if provided the\nfile will be duplicated via Drive API and populated, preserving the original\nlayout/theme.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, time\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Any\nfrom urllib.parse import urlparse\n\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom google.auth.transport.requests import Request\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\nSCOPES = [\n    \"https://www.googleapis.com/auth/presentations\",\n    \"https://www.googleapis.com/auth/drive.file\",\n]\nLOGGER = logging.getLogger(\"build_slides\")\n\n# Default slide layouts and their placeholder types\nLAYOUT_PLACEHOLDERS = {\n    \"TITLE\": [\"TITLE\"],\n    \"TITLE_AND_BODY\": [\"TITLE\", \"BODY\"],\n    \"TITLE_AND_TWO_COLUMNS\": [\"TITLE\", \"BODY\", \"BODY_2\"],\n    \"TITLE_ONLY\": [\"TITLE\"],\n    \"SECTION_HEADER\": [\"TITLE\", \"SUBTITLE\"],\n    \"MAIN_POINT\": [\"TITLE\", \"BODY\"],\n    \"CAPTION\": [\"TITLE\", \"SUBTITLE\"],\n    \"BLANK\": [],\n}\n\n# ---------- auth helpers ----------------------------------------------------\n\ndef auth(port: int) -> Tuple[Any, Any]:\n    \"\"\"Authenticate with Google and return Slides and Drive services.\"\"\"\n    token_path = Path(\"oauth-token.json\")\n    client_path = Path(\"oauth-client.json\")\n    \n    # Try to find client secret file with alternative names\n    if not client_path.exists():\n        # Look for client_secret_*.json files\n        client_secrets = list(Path().glob(\"client_secret_*.json\"))\n        if client_secrets:\n            client_path = client_secrets[0]\n            LOGGER.info(\"Using client secret file: %s\", client_path)\n    \n    creds: Credentials | None = None\n    if token_path.exists():\n        creds = Credentials.from_authorized_user_file(token_path, SCOPES)\n    \n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            try:\n                creds.refresh(Request())\n            except Exception as e:\n                LOGGER.warning(\"Failed to refresh token: %s\", e)\n                creds = None\n        \n        if not creds:\n            if not client_path.exists():\n                LOGGER.error(\"OAuth client file not found: %s\", client_path)\n                LOGGER.error(\"Download client_secret_*.json from Google Cloud Console\")\n                sys.exit(1)\n            \n            flow = InstalledAppFlow.from_client_secrets_file(client_path, SCOPES)\n            creds = flow.run_local_server(port=port)\n        \n        token_path.write_text(creds.to_json())\n    \n    slides_service = build(\"slides\", \"v1\", credentials=creds)\n    drive_service = build(\"drive\", \"v3\", credentials=creds)\n    return slides_service, drive_service\n\n\n# ---------- template handling -----------------------------------------------\n\ndef duplicate_template(drive, template_id: str, title: str) -> str:\n    \"\"\"Create a copy of a template presentation and return its ID.\"\"\"\n    file_meta = {\"name\": title}\n    try:\n        copied = drive.files().copy(fileId=template_id, body=file_meta).execute()\n        return copied[\"id\"]\n    except HttpError as e:\n        if e.status_code == 404:\n            LOGGER.error(\"Template presentation not found (ID: %s)\", template_id)\n        else:\n            LOGGER.error(\"Failed to copy template: %s\", e)\n        raise\n\n\ndef get_slide_layouts(slides_service, presentation_id: str) -> Dict[str, Dict]:\n    \"\"\"Get available slide layouts and their placeholders in the presentation.\"\"\"\n    try:\n        presentation = slides_service.presentations().get(presentationId=presentation_id).execute()\n        \n        layouts = {}\n        # Find all slide layouts in the presentation masters\n        for master in presentation.get(\"masters\", []):\n            for layout in master.get(\"layouts\", []):\n                layout_name = layout.get(\"layoutProperties\", {}).get(\"displayName\", \"\").upper()\n                if not layout_name:\n                    continue\n                \n                # Extract placeholders\n                placeholders = {}\n                for placeholder in layout.get(\"pageElements\", []):\n                    if \"shape\" in placeholder and \"placeholder\" in placeholder[\"shape\"]:\n                        placeholder_id = placeholder.get(\"objectId\", \"\")\n                        placeholder_type = placeholder[\"shape\"][\"placeholder\"].get(\"type\", \"\")\n                        placeholders[placeholder_type] = placeholder_id\n                \n                layouts[layout_name] = {\n                    \"layout_id\": layout.get(\"objectId\", \"\"),\n                    \"placeholders\": placeholders\n                }\n        \n        return layouts\n    \n    except HttpError as e:\n        LOGGER.error(\"Failed to get slide layouts: %s\", e)\n        raise\n\n\n# ---------- slide generation ------------------------------------------------\n\ndef choose_layout(slide: dict) -> str:\n    \"\"\"Choose the best layout for a slide based on its content.\"\"\"\n    if slide.get(\"slide_number\") == 1:\n        return \"TITLE\"\n    \n    has_image = bool(slide.get(\"image_url\"))\n    has_content = bool(slide.get(\"content\"))\n    \n    if has_image and has_content:\n        return \"TITLE_AND_TWO_COLUMNS\"\n    elif has_image and not has_content:\n        return \"CAPTION\"  # Image with title\n    elif has_content:\n        return \"TITLE_AND_BODY\"\n    else:\n        return \"TITLE_ONLY\"\n\n\ndef extract_image_filename(url: str) -> str:\n    \"\"\"Extract image filename from URL for local file matching.\"\"\"\n    parsed = urlparse(url)\n    path = parsed.path\n    filename = os.path.basename(path)\n    # Remove any query parameters from the filename\n    filename = filename.split('?')[0]\n    return filename\n\n\ndef build_requests(slides: list[dict], custom_layouts: Dict = None) -> list[dict]:\n    \"\"\"Build slide creation and content requests.\"\"\"\n    reqs: list[dict] = []\n    \n    # Delete the default slide if we're adding our own\n    reqs.append({\"deleteObject\": {\"objectId\": \"p\"}})\n    \n    for sl in slides:\n        page_id = f\"p{sl['slide_number']}\"\n        layout = choose_layout(sl)\n        \n        # Prepare placeholders\n        placeholder_mappings = []\n        placeholders = LAYOUT_PLACEHOLDERS.get(layout, [])\n        for i, placeholder_type in enumerate(placeholders):\n            placeholder_id = f\"{page_id}_{placeholder_type.lower()}\"\n            placeholder_mappings.append({\n                \"layoutPlaceholder\": {\"type\": placeholder_type},\n                \"objectId\": placeholder_id\n            })\n        \n        # Create slide with layout and placeholders\n        reqs.append({\n            \"createSlide\": {\n                \"objectId\": page_id,\n                \"slideLayoutReference\": {\"predefinedLayout\": layout},\n                \"placeholderIdMappings\": placeholder_mappings\n            }\n        })\n        \n        # Add title\n        if \"title\" in sl and sl[\"title\"]:\n            title_id = f\"{page_id}_title\"\n            reqs.append({\n                \"insertText\": {\n                    \"objectId\": title_id,\n                    \"insertionIndex\": 0,\n                    \"text\": sl[\"title\"]\n                }\n            })\n        \n        # Add content to body placeholder if available\n        if \"content\" in sl and sl[\"content\"]:\n            body_id = f\"{page_id}_body\"\n            reqs.append({\n                \"insertText\": {\n                    \"objectId\": body_id,\n                    \"insertionIndex\": 0,\n                    \"text\": sl[\"content\"]\n                }\n            })\n        \n        # Add image\n        if \"image_url\" in sl and sl[\"image_url\"]:\n            # If using a two-column layout, put image in second column\n            if layout == \"TITLE_AND_TWO_COLUMNS\":\n                image_container = f\"{page_id}_body_2\"\n                reqs.append({\n                    \"createImage\": {\n                        \"url\": sl[\"image_url\"],\n                        \"elementProperties\": {\n                            \"pageObjectId\": page_id,\n                            \"size\": {\n                                \"width\": {\"magnitude\": 350, \"unit\": \"PT\"},\n                                \"height\": {\"magnitude\": 250, \"unit\": \"PT\"}\n                            },\n                            \"transform\": {\n                                \"scaleX\": 1,\n                                \"scaleY\": 1,\n                                \"translateX\": 400,  # Right side of slide\n                                \"translateY\": 150,\n                                \"unit\": \"PT\"\n                            }\n                        }\n                    }\n                })\n            else:\n                # For other layouts, center the image\n                reqs.append({\n                    \"createImage\": {\n                        \"url\": sl[\"image_url\"],\n                        \"elementProperties\": {\n                            \"pageObjectId\": page_id,\n                            \"size\": {\n                                \"width\": {\"magnitude\": 400, \"unit\": \"PT\"},\n                                \"height\": {\"magnitude\": 300, \"unit\": \"PT\"}\n                            },\n                            \"transform\": {\n                                \"scaleX\": 1,\n                                \"scaleY\": 1,\n                                \"translateX\": 150,  # Centered\n                                \"translateY\": 150,\n                                \"unit\": \"PT\"\n                            }\n                        }\n                    }\n                })\n        \n        # If there are facilitator notes, add them as speaker notes\n        if \"facilitator_notes\" in sl and sl[\"facilitator_notes\"]:\n            reqs.append({\n                \"insertText\": {\n                    \"objectId\": f\"{page_id}_speaker_notes\",\n                    \"text\": sl[\"facilitator_notes\"]\n                }\n            })\n    \n    return reqs\n\n\n# ---------- batch processing ------------------------------------------------\n\ndef process_batch(reqs: List[Dict], slides_service, presentation_id: str, batch_size: int = 20) -> List[Dict]:\n    \"\"\"Process requests in batches to avoid API limits.\"\"\"\n    results = []\n    for i in range(0, len(reqs), batch_size):\n        batch = reqs[i:i + batch_size]\n        LOGGER.info(\"Processing batch %d/%d (%d requests)\", \n                    i // batch_size + 1, \n                    (len(reqs) + batch_size - 1) // batch_size, \n                    len(batch))\n        \n        try:\n            result = slides_service.presentations().batchUpdate(\n                presentationId=presentation_id, \n                body={\"requests\": batch}\n            ).execute()\n            results.append(result)\n            \n            # Avoid rate limits\n            if i + batch_size < len(reqs):\n                time.sleep(1)\n                \n        except HttpError as e:\n            LOGGER.error(\"Batch update failed: %s\", e)\n            if e.status_code == 429:  # Too Many Requests\n                LOGGER.info(\"Hit rate limit, waiting 10 seconds before retrying...\")\n                time.sleep(10)\n                # Retry this batch\n                try:\n                    result = slides_service.presentations().batchUpdate(\n                        presentationId=presentation_id, \n                        body={\"requests\": batch}\n                    ).execute()\n                    results.append(result)\n                except HttpError as e2:\n                    LOGGER.error(\"Retry failed: %s\", e2)\n                    raise\n            else:\n                raise\n    \n    return results\n\n\n# ---------- main ------------------------------------------------------------\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Generate Google Slides deck from slides.json\")\n    p.add_argument(\"json\", help=\"slides.json with image_url filled\")\n    p.add_argument(\"--title\", default=None, help=\"Presentation title (default: based on input filename)\")\n    p.add_argument(\"--template-id\", help=\"Google Slides file ID to copy as template\")\n    p.add_argument(\"--port\", type=int, default=8080, help=\"Port for OAuth flow\")\n    p.add_argument(\"--batch-size\", type=int, default=20, help=\"Number of requests per batch\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    # Validate input JSON\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"JSON file not found: %s\", json_path)\n        sys.exit(1)\n    \n    try:\n        slides_data = json.loads(json_path.read_text())\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON: %s\", e)\n        sys.exit(1)\n    \n    # Determine presentation title\n    if args.title:\n        title = args.title\n    else:\n        # Base title on input filename\n        base_name = json_path.stem\n        if base_name.startswith(\"slides_\"):\n            base_name = base_name[7:]  # Remove \"slides_\" prefix\n        title = f\"{base_name.replace('_', ' ').title()} Presentation\"\n    \n    # Authenticate with Google\n    try:\n        slides_service, drive_service = auth(args.port)\n    except Exception as e:\n        LOGGER.error(\"Authentication failed: %s\", e)\n        sys.exit(1)\n\n    # Create or copy presentation\n    presentation_id: str\n    try:\n        if args.template_id:\n            presentation_id = duplicate_template(drive_service, args.template_id, title)\n            LOGGER.info(\"Template duplicated → %s\", presentation_id)\n        else:\n            pres = slides_service.presentations().create(body={\"title\": title}).execute()\n            presentation_id = pres[\"presentationId\"]\n            LOGGER.info(\"Blank deck created → %s\", presentation_id)\n    except HttpError as e:\n        LOGGER.error(\"Failed to create presentation: %s\", e)\n        sys.exit(1)\n\n    # Build and process requests\n    try:\n        reqs = build_requests(slides_data)\n        LOGGER.info(\"Built %d requests\", len(reqs))\n        \n        results = process_batch(reqs, slides_service, presentation_id, args.batch_size)\n        LOGGER.info(\"Slides added: %d\", len(slides_data))\n        \n        # Get the presentation URL\n        presentation_url = f\"https://docs.google.com/presentation/d/{presentation_id}/edit\"\n        print(\"\\nDeck URL:\", presentation_url)\n        \n        # Attempt to open in browser\n        import webbrowser\n        webbrowser.open(presentation_url)\n        \n    except Exception as e:\n        LOGGER.error(\"Failed to update presentation: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\nThese updated scripts should address all the user's requirements:\n\n1. `diagrams_to_images.py` now:\n   - Supports using a mermaid config JSON file\n   - Saves local copies of mermaid diagrams with the guide filename and slide number\n   - Includes retry logic for API calls\n   - Uses better error handling\n\n2. `guide_to_json.py` now:\n   - Can process a directory of markdown files\n   - Outputs JSON files in the same folder as input files\n   - Has improved error handling and retries\n   - Makes the Claude model configurable\n\n3. `build_slides.py` now:\n   - Has improved handling of different slide layouts\n   - Better manages the placement of images\n   - Supports speaker notes\n   - Includes batch processing to avoid API limits\n   - Has improved error handling\n   - Tries to find the client secret file with different naming patterns\n\nThese changes should make the slide generation pipeline more robust and address the issues the user was experiencing with Google Slides API integration.",
            "summaries": [
              {
                "summary": "Updating scripts to process folder contents and export files"
              },
              {
                "summary": "Updating diagrams script with Mermaid config and local saving"
              },
              {
                "summary": "Crafting mermaid diagram rendering with custom filename strategy"
              },
              {
                "summary": "Updating diagrams script with mermaid config and file handling"
              },
              {
                "summary": "Crafting local image saving with guide-specific naming"
              },
              {
                "summary": "Updating scripts to handle folder processing and image naming"
              },
              {
                "summary": "Updating scripts to handle folder processing and image naming"
              },
              {
                "summary": "Updating scripts to process guides, diagrams, and slides efficiently"
              },
              {
                "summary": "Processing markdown files in directory, preparing batch workflow"
              },
              {
                "summary": "Updating scripts to process guides and diagrams efficiently"
              },
              {
                "summary": "Updating scripts for mermaid diagrams, folder processing, and slides"
              },
              {
                "summary": "Updating scripts for mermaid diagrams, folder processing, and slides"
              },
              {
                "summary": "Crafting script updates for diagrams, guides, and slides processing"
              },
              {
                "summary": "Crafting script updates for diagrams, guides, and slides processing"
              },
              {
                "summary": "Crafting script updates for diagrams, guides, and slides processing"
              },
              {
                "summary": "Crafting comprehensive script updates for diagrams, guides, and slides"
              },
              {
                "summary": "Updating scripts for mermaid diagrams, folder processing, and slide generation"
              },
              {
                "summary": "Crafting comprehensive script updates for diagrams and slides processing"
              },
              {
                "summary": "Updating scripts for mermaid diagrams, JSON processing, and slides generation"
              },
              {
                "summary": "Engineered robust scripts for automated slide and diagram generation"
              }
            ],
            "cut_off": false
          },
          {
            "start_timestamp": "2025-05-20T06:14:26.343101Z",
            "stop_timestamp": "2025-05-20T06:16:31.704263Z",
            "flags": null,
            "type": "text",
            "text": "I'll update these files to enhance your slide generation system, incorporating the Mermaid config file and adding support for batch processing directories.\n\n## 1. Updated `diagrams_to_images.py`\n\n```python\n#!/usr/bin/env python3\n\"\"\"Render Mermaid diagrams & upload to FreeImage.host (API v1).\n\nAdds/overwrites image_url in slides.json whenever both diagram_type and\ndiagram_content are present. Also saves local copies of the diagrams with\nnames based on the source file.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, subprocess, sys, time, shutil\nfrom pathlib import Path\nfrom typing import Any\n\nimport requests\n\nLOGGER = logging.getLogger(\"diagrams_to_images\")\nMERMAID_CMD = \"mmdc\"  # must be on PATH\nFREEIMAGE_ENDPOINT = \"https://freeimage.host/api/1/upload\"\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Render Mermaid diagrams & upload to FreeImage.host\")\n    p.add_argument(\"json\", help=\"slides.json to update (in-place)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    p.add_argument(\"--temp-dir\", default=None, help=\"where to render PNGs temporarily (default: same as slides.json)\")\n    p.add_argument(\"--mermaid-config\", default=\"mermaid-config.json\", help=\"Mermaid configuration file\")\n    p.add_argument(\"--save-local\", action=\"store_true\", help=\"Save local copies of diagrams in the same folder\")\n    p.add_argument(\"--output-dir\", default=None, help=\"Directory to save output files (default: same as slides.json)\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef render_mermaid(src: str, tmp: Path, config_path: Path | None, base_filename: str, slide_num: int) -> tuple[Path, Path]:\n    \"\"\"Render mermaid diagram to PNG.\n    \n    Args:\n        src: Mermaid diagram content\n        tmp: Directory to save temporary files\n        config_path: Path to mermaid config file\n        base_filename: Base filename (from guide file)\n        slide_num: Slide number\n        \n    Returns:\n        tuple of (png_path, mmd_path)\n    \"\"\"\n    # Create filenames based on guide name and slide number\n    output_name = f\"{base_filename}_{slide_num}\"\n    mmd = tmp / f\"{output_name}.mmd\"\n    png = tmp / f\"{output_name}.png\"\n    \n    # Write mermaid content to file\n    mmd.write_text(src, encoding=\"utf-8\")\n    \n    # Build command with optional config\n    cmd = [MERMAID_CMD, \"-i\", mmd, \"-o\", png, \"-b\", \"transparent\"]\n    if config_path and config_path.exists():\n        cmd.extend([\"-c\", config_path])\n    \n    LOGGER.debug(\"Running command: %s\", \" \".join(str(x) for x in cmd))\n    \n    # Execute command with retry\n    for attempt in range(3):\n        try:\n            subprocess.run(cmd, check=True, capture_output=True)\n            if png.exists() and png.stat().st_size > 0:\n                return png, mmd\n            \n            if attempt < 2:  # Only log warning for first two attempts\n                LOGGER.warning(\"Empty output from mermaid-cli, retrying in 2s...\")\n                time.sleep(2)\n        except subprocess.CalledProcessError as e:\n            if attempt < 2:  # Only log error for first two attempts\n                LOGGER.warning(\"mermaid-cli error (attempt %d/3): %s\", attempt + 1, e.stderr.decode())\n                time.sleep(2)\n    \n    # If we got here, all attempts failed\n    raise RuntimeError(f\"Failed to render mermaid diagram after 3 attempts. Last error: {e.stderr.decode() if 'e' in locals() else 'Empty output'}\")\n\n\ndef upload_freeimage(png: Path) -> str:\n    \"\"\"Upload PNG to FreeImage.host and return URL.\"\"\"\n    api_key = os.getenv(\"FREEIMAGE_API_KEY\")\n    if not api_key:\n        raise RuntimeError(\"FREEIMAGE_API_KEY env var not set\")\n    \n    # Retry logic for uploads\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            with png.open(\"rb\") as fh:\n                payload = {\n                    \"key\": api_key,\n                    \"action\": \"upload\",\n                    \"format\": \"json\",\n                }\n                files = {\"source\": fh}\n                rsp = requests.post(FREEIMAGE_ENDPOINT, data=payload, files=files, timeout=20)\n                rsp.raise_for_status()\n                \n            data: dict[str, Any] = rsp.json()\n            if data.get(\"status_code\") != 200:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Upload failed (attempt %d/%d): %s. Retrying in %d seconds...\", \n                                  attempt + 1, max_attempts, data, 2 ** attempt)\n                    time.sleep(2 ** attempt)  # Exponential backoff\n                    continue\n                raise RuntimeError(f\"Upload failed after {max_attempts} attempts: {data}\")\n                \n            return data[\"image\"][\"url\"]\n            \n        except (requests.RequestException, json.JSONDecodeError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"Upload error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                              attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)  # Exponential backoff\n            else:\n                raise RuntimeError(f\"Upload failed after {max_attempts} attempts: {e}\")\n    \n    raise RuntimeError(\"Upload failed, this should not happen\")  # Unreachable\n\n\ndef get_base_filename(json_path: Path) -> str:\n    \"\"\"Extract base filename (without extension) from path.\"\"\"\n    return json_path.stem.replace('slides_', '')  # Remove 'slides_' prefix if present\n\n\ndef process(slides: list[dict], json_path: Path, tmp_dir: Path, config_path: Path, save_local: bool, output_dir: Path | None) -> int:\n    \"\"\"Process slides and render diagrams.\n    \n    Args:\n        slides: List of slide data\n        json_path: Path to slides.json file\n        tmp_dir: Directory for temporary files\n        config_path: Path to mermaid config\n        save_local: Whether to save local copies\n        output_dir: Directory to save output files (or None to use same as json_path)\n        \n    Returns:\n        Number of changed slides\n    \"\"\"\n    changed = 0\n    base_filename = get_base_filename(json_path)\n    final_dir = output_dir if output_dir else json_path.parent\n    \n    # Ensure the output directory exists\n    final_dir.mkdir(parents=True, exist_ok=True)\n    \n    for slide in slides:\n        if slide.get(\"diagram_type\") and slide.get(\"diagram_content\"):\n            try:\n                # Render diagram\n                png_path, mmd_path = render_mermaid(\n                    slide[\"diagram_content\"], \n                    tmp_dir, \n                    config_path, \n                    base_filename, \n                    slide[\"slide_number\"]\n                )\n                \n                # Upload to FreeImage\n                url = upload_freeimage(png_path)\n                slide[\"image_url\"] = url\n                changed += 1\n                \n                # Save local copies if requested\n                if save_local:\n                    local_png = final_dir / png_path.name\n                    local_mmd = final_dir / mmd_path.name\n                    \n                    shutil.copy2(png_path, local_png)\n                    shutil.copy2(mmd_path, local_mmd)\n                    LOGGER.info(\"Saved local copies: %s and %s\", local_png.name, local_mmd.name)\n                \n                LOGGER.info(\"Rendered & uploaded diagram for slide %d → %s\", slide[\"slide_number\"], url)\n                \n            except Exception as e:\n                LOGGER.error(\"Diagram for slide %d failed: %s\", slide[\"slide_number\"], e, exc_info=True)\n    \n    return changed\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine temporary directory\n    if args.temp_dir:\n        tmp_dir = Path(args.temp_dir)\n    else:\n        tmp_dir = json_path.parent\n    tmp_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    \n    # Check if mermaid config exists\n    config_path = Path(args.mermaid_config)\n    if not config_path.exists():\n        LOGGER.warning(\"Mermaid config file %s not found, using default\", config_path)\n        config_path = None\n    \n    # Process slides\n    try:\n        slides = json.loads(json_path.read_text())\n        changed = process(slides, json_path, tmp_dir, config_path, args.save_local, output_dir)\n        json_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n        LOGGER.info(\"%d diagrams processed; file updated\", changed)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 2. Updated `guide_to_json.py`\n\n```python\n#!/usr/bin/env python3\n\"\"\"Convert a facilitator guide into slides.json using Claude 3.\n\nUsage:\n  python guide_to_json.py guide.md \\\n      --prompt prompt-template.txt \\\n      --out slides.json \\\n      --log-level INFO \\\n      --log-file build.log\n      \n  # Process all markdown files in a folder:\n  python guide_to_json.py guides/ \\\n      --prompt prompt-template.txt \\\n      --log-level INFO \\\n      --log-file build.log\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, time\nfrom pathlib import Path\nfrom typing import List\nimport anthropic\n\nDEFAULT_OUT = \"slides.json\"\nDEFAULT_PROMPT = \"prompt-template.txt\"\n\nLOGGER = logging.getLogger(\"guide_to_json\")\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"LLM → JSON slide outline\")\n    p.add_argument(\"guide\", help=\"Facilitator guide (Markdown/text) or directory of guides\")\n    p.add_argument(\"--prompt\", default=DEFAULT_PROMPT, help=\"Prompt template path\")\n    p.add_argument(\"--out\", default=None, help=\"Output JSON path (ignored if guide is a directory)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None, help=\"Write logs to file as well\")\n    p.add_argument(\"--model\", default=\"claude-3-7-sonnet-20250219\", help=\"Claude model to use\")\n    p.add_argument(\"--batch-size\", type=int, default=5, help=\"Number of files to process in parallel (batch mode)\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers: list[logging.Handler] = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(\n        level=level,\n        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n        handlers=handlers,\n    )\n\n\ndef build_prompt(template_path: Path, guide_text: str) -> str:\n    tpl = template_path.read_text(encoding=\"utf-8\")\n    if \"{{content}}\" not in tpl:\n        LOGGER.error(\"Prompt template missing {{content}} placeholder → %s\", template_path)\n        sys.exit(1)\n    return tpl.replace(\"{{content}}\", guide_text)\n\n\n# Insert missing keys and correct ordering\nORDER = [\n    \"slide_number\", \"title\", \"content\", \"chart_type\", \"diagram_type\", \"diagram_content\",\n    \"image_description\", \"image_url\", \"facilitator_notes\", \"start_time\", \"end_time\",\n    \"materials\", \"worksheet\", \"improvements\", \"notes\",\n]\n\n\ndef normalize(slides: list[dict]) -> list[dict]:\n    fixed = []\n    for idx, raw in enumerate(slides, 1):\n        raw.setdefault(\"slide_number\", idx)\n        raw.setdefault(\"chart_type\", None)\n        raw.setdefault(\"image_description\", None)\n        raw.setdefault(\"image_url\", None)\n        for key in ORDER:\n            raw.setdefault(key, None)\n        fixed.append({k: raw.get(k) for k in ORDER})\n    return fixed\n\n\ndef process_guide(guide_path: Path, prompt_template: Path, out_path: Path | None, model: str, client: anthropic.Anthropic) -> Path:\n    \"\"\"Process a single guide file and return the output path.\"\"\"\n    LOGGER.info(\"Processing guide: %s\", guide_path)\n    \n    # Determine output path\n    if not out_path:\n        out_path = guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n    \n    # Read guide and build prompt\n    guide_txt = guide_path.read_text(encoding=\"utf-8\")\n    prompt = build_prompt(prompt_template, guide_txt)\n    \n    # Request Claude with retries\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            LOGGER.info(\"Requesting Claude (%s) for %s...\", model, guide_path.name)\n            rsp = client.messages.create(\n                model=model,\n                max_tokens=16_000,\n                system=\"Return JSON only.\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            )\n            \n            raw = rsp.content[0].text\n            start = raw.find(\"[\")\n            if start == -1:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Claude response contained no JSON array, retrying in %d seconds...\", 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Claude response contained no JSON array after %d attempts\", max_attempts)\n                    raise ValueError(\"Claude response contained no JSON array\")\n            \n            try:\n                slides = json.loads(raw[start:])\n            except json.JSONDecodeError as e:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Invalid JSON from Claude: %s, retrying in %d seconds...\", e, 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Invalid JSON from Claude after %d attempts: %s\", max_attempts, e)\n                    raise\n            \n            # Normalize and save\n            slides = normalize(slides)\n            out_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n            LOGGER.info(\"Wrote %d slides → %s\", len(slides), out_path)\n            return out_path\n            \n        except (anthropic.APIError, anthropic.APITimeoutError, anthropic.APIConnectionError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"API error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                            attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)\n            else:\n                LOGGER.error(\"API error after %d attempts: %s\", max_attempts, e, exc_info=True)\n                raise\n    \n    raise RuntimeError(\"Failed to process guide, this should not happen\")  # Unreachable\n\n\ndef process_directory(guide_dir: Path, prompt_template: Path, model: str, batch_size: int, client: anthropic.Anthropic) -> List[Path]:\n    \"\"\"Process all markdown files in a directory.\"\"\"\n    LOGGER.info(\"Processing all markdown files in: %s\", guide_dir)\n    \n    # Find all markdown files\n    md_files = list(guide_dir.glob(\"*.md\"))\n    if not md_files:\n        LOGGER.error(\"No markdown files found in %s\", guide_dir)\n        sys.exit(1)\n    \n    LOGGER.info(\"Found %d markdown files to process\", len(md_files))\n    \n    # Process files in batches to avoid overwhelming the API\n    results = []\n    for i in range(0, len(md_files), batch_size):\n        batch = md_files[i:i + batch_size]\n        LOGGER.info(\"Processing batch %d/%d (%d files)\", i // batch_size + 1, \n                   (len(md_files) + batch_size - 1) // batch_size, len(batch))\n        \n        for guide_path in batch:\n            try:\n                out_path = process_guide(guide_path, prompt_template, None, model, client)\n                results.append(out_path)\n            except Exception as e:\n                LOGGER.error(\"Failed to process %s: %s\", guide_path, e, exc_info=True)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n    if not api_key:\n        LOGGER.error(\"Set ANTHROPIC_API_KEY environment variable\")\n        sys.exit(1)\n\n    # Validate paths\n    guide_path = Path(args.guide)\n    prompt_path = Path(args.prompt)\n    \n    if not prompt_path.exists():\n        LOGGER.error(\"Prompt template not found: %s\", prompt_path)\n        sys.exit(1)\n    \n    if guide_path.is_dir():\n        LOGGER.info(\"Directory mode: Processing all markdown files in %s\", guide_path)\n        if args.out:\n            LOGGER.warning(\"--out parameter ignored in directory mode\")\n        \n        # Initialize Claude client\n        client = anthropic.Anthropic(api_key=api_key)\n        \n        # Process directory\n        process_directory(guide_path, prompt_path, args.model, args.batch_size, client)\n        \n    else:\n        # Single file mode\n        if not guide_path.exists():\n            LOGGER.error(\"Guide file not found: %s\", guide_path)\n            sys.exit(1)\n        \n        # Determine output path\n        out_path = Path(args.out) if args.out else guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n        \n        # Initialize Claude client\n        client = anthropic.Anthropic(api_key=api_key)\n        \n        # Process single guide\n        process_guide(guide_path, prompt_path, out_path, args.model, client)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 3. Improved `build_slides.py`\n\n```python\n#!/usr/bin/env python3\n\"\"\"Create a Google Slides deck from slides.json.\n\nSupports optional `--template-id` (an existing Slides file); if provided the\nfile will be duplicated via Drive API and populated, preserving the original\nlayout/theme.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, time\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Any\nfrom urllib.parse import urlparse\n\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom google.auth.transport.requests import Request\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\nSCOPES = [\n    \"https://www.googleapis.com/auth/presentations\",\n    \"https://www.googleapis.com/auth/drive.file\",\n]\nLOGGER = logging.getLogger(\"build_slides\")\n\n# Default slide layouts and their placeholder types\nLAYOUT_PLACEHOLDERS = {\n    \"TITLE\": [\"TITLE\", \"SUBTITLE\"],\n    \"TITLE_AND_BODY\": [\"TITLE\", \"BODY\"],\n    \"TITLE_AND_TWO_COLUMNS\": [\"TITLE\", \"BODY\", \"BODY_2\"],\n    \"TITLE_ONLY\": [\"TITLE\"],\n    \"SECTION_HEADER\": [\"TITLE\", \"SUBTITLE\"],\n    \"MAIN_POINT\": [\"TITLE\", \"BODY\"],\n    \"CAPTION\": [\"TITLE\", \"SUBTITLE\"],\n    \"BLANK\": [],\n}\n\n# ---------- auth helpers ----------------------------------------------------\n\ndef auth(port: int) -> Tuple[Any, Any]:\n    \"\"\"Authenticate with Google and return Slides and Drive services.\"\"\"\n    token_path = Path(\"oauth-token.json\")\n    client_path = Path(\"oauth-client.json\")\n    \n    # Try to find client secret file with alternative names\n    if not client_path.exists():\n        # Look for client_secret_*.json files\n        client_secrets = list(Path().glob(\"client_secret_*.json\"))\n        if client_secrets:\n            client_path = client_secrets[0]\n            LOGGER.info(\"Using client secret file: %s\", client_path)\n    \n    creds: Credentials | None = None\n    if token_path.exists():\n        creds = Credentials.from_authorized_user_file(token_path, SCOPES)\n    \n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            try:\n                creds.refresh(Request())\n            except Exception as e:\n                LOGGER.warning(\"Failed to refresh token: %s\", e)\n                creds = None\n        \n        if not creds:\n            if not client_path.exists():\n                LOGGER.error(\"OAuth client file not found: %s\", client_path)\n                LOGGER.error(\"Download client_secret_*.json from Google Cloud Console\")\n                sys.exit(1)\n            \n            flow = InstalledAppFlow.from_client_secrets_file(client_path, SCOPES)\n            creds = flow.run_local_server(port=port)\n        \n        token_path.write_text(creds.to_json())\n    \n    slides_service = build(\"slides\", \"v1\", credentials=creds)\n    drive_service = build(\"drive\", \"v3\", credentials=creds)\n    return slides_service, drive_service\n\n\n# ---------- template handling -----------------------------------------------\n\ndef duplicate_template(drive, template_id: str, title: str) -> str:\n    \"\"\"Create a copy of a template presentation and return its ID.\"\"\"\n    file_meta = {\"name\": title}\n    try:\n        copied = drive.files().copy(fileId=template_id, body=file_meta).execute()\n        return copied[\"id\"]\n    except HttpError as e:\n        if e.status_code == 404:\n            LOGGER.error(\"Template presentation not found (ID: %s)\", template_id)\n        else:\n            LOGGER.error(\"Failed to copy template: %s\", e)\n        raise\n\n\ndef get_slide_layouts(slides_service, presentation_id: str) -> Dict[str, Dict]:\n    \"\"\"Get available slide layouts and their placeholders in the presentation.\"\"\"\n    try:\n        presentation = slides_service.presentations().get(presentationId=presentation_id).execute()\n        \n        layouts = {}\n        # Find all slide layouts in the presentation masters\n        for master in presentation.get(\"masters\", []):\n            for layout in master.get(\"layouts\", []):\n                layout_name = layout.get(\"layoutProperties\", {}).get(\"displayName\", \"\").upper()\n                if not layout_name:\n                    continue\n                \n                # Extract placeholders\n                placeholders = {}\n                for placeholder in layout.get(\"pageElements\", []):\n                    if \"shape\" in placeholder and \"placeholder\" in placeholder[\"shape\"]:\n                        placeholder_id = placeholder.get(\"objectId\", \"\")\n                        placeholder_type = placeholder[\"shape\"][\"placeholder\"].get(\"type\", \"\")\n                        placeholders[placeholder_type] = placeholder_id\n                \n                layouts[layout_name] = {\n                    \"layout_id\": layout.get(\"objectId\", \"\"),\n                    \"placeholders\": placeholders\n                }\n        \n        return layouts\n    \n    except HttpError as e:\n        LOGGER.error(\"Failed to get slide layouts: %s\", e)\n        raise\n\n\n# ---------- slide generation ------------------------------------------------\n\ndef choose_layout(slide: dict) -> str:\n    \"\"\"Choose the best layout for a slide based on its content.\"\"\"\n    if slide.get(\"slide_number\") == 1:\n        return \"TITLE\"\n    \n    has_image = bool(slide.get(\"image_url\"))\n    has_content = bool(slide.get(\"content\"))\n    \n    if has_image and has_content:\n        return \"TITLE_AND_TWO_COLUMNS\"\n    elif has_image and not has_content:\n        return \"CAPTION\"  # Image with title\n    elif has_content:\n        return \"TITLE_AND_BODY\"\n    else:\n        return \"TITLE_ONLY\"\n\n\ndef extract_image_filename(url: str) -> str:\n    \"\"\"Extract image filename from URL for local file matching.\"\"\"\n    parsed = urlparse(url)\n    path = parsed.path\n    filename = os.path.basename(path)\n    # Remove any query parameters from the filename\n    filename = filename.split('?')[0]\n    return filename\n\n\ndef build_requests(slides: list[dict], custom_layouts: Dict = None) -> list[dict]:\n    \"\"\"Build slide creation and content requests.\"\"\"\n    reqs: list[dict] = []\n    \n    # Delete the default slide if we're adding our own\n    reqs.append({\"deleteObject\": {\"objectId\": \"p\"}})\n    \n    for sl in slides:\n        page_id = f\"p{sl['slide_number']}\"\n        layout = choose_layout(sl)\n        \n        # Prepare placeholders\n        placeholder_mappings = []\n        placeholders = LAYOUT_PLACEHOLDERS.get(layout, [])\n        for i, placeholder_type in enumerate(placeholders):\n            placeholder_id = f\"{page_id}_{placeholder_type.lower()}\"\n            placeholder_mappings.append({\n                \"layoutPlaceholder\": {\"type\": placeholder_type},\n                \"objectId\": placeholder_id\n            })\n        \n        # Create slide with layout and placeholders\n        reqs.append({\n            \"createSlide\": {\n                \"objectId\": page_id,\n                \"slideLayoutReference\": {\"predefinedLayout\": layout},\n                \"placeholderIdMappings\": placeholder_mappings\n            }\n        })\n        \n        # Add title\n        if \"title\" in sl and sl[\"title\"]:\n            title_id = f\"{page_id}_title\"\n            reqs.append({\n                \"insertText\": {\n                    \"objectId\": title_id,\n                    \"insertionIndex\": 0,\n                    \"text\": sl[\"title\"]\n                }\n            })\n        \n        # Add content to body placeholder if available\n        if \"content\" in sl and sl[\"content\"]:\n            body_id = f\"{page_id}_body\"\n            reqs.append({\n                \"insertText\": {\n                    \"objectId\": body_id,\n                    \"insertionIndex\": 0,\n                    \"text\": sl[\"content\"]\n                }\n            })\n        \n        # Add image\n        if \"image_url\" in sl and sl[\"image_url\"]:\n            # If using a two-column layout, put image in second column\n            if layout == \"TITLE_AND_TWO_COLUMNS\":\n                image_container = f\"{page_id}_body_2\"\n                reqs.append({\n                    \"createImage\": {\n                        \"url\": sl[\"image_url\"],\n                        \"elementProperties\": {\n                            \"pageObjectId\": page_id,\n                            \"size\": {\n                                \"width\": {\"magnitude\": 350, \"unit\": \"PT\"},\n                                \"height\": {\"magnitude\": 250, \"unit\": \"PT\"}\n                            },\n                            \"transform\": {\n                                \"scaleX\": 1,\n                                \"scaleY\": 1,\n                                \"translateX\": 400,  # Right side of slide\n                                \"translateY\": 150,\n                                \"unit\": \"PT\"\n                            }\n                        }\n                    }\n                })\n            else:\n                # For other layouts, center the image\n                reqs.append({\n                    \"createImage\": {\n                        \"url\": sl[\"image_url\"],\n                        \"elementProperties\": {\n                            \"pageObjectId\": page_id,\n                            \"size\": {\n                                \"width\": {\"magnitude\": 400, \"unit\": \"PT\"},\n                                \"height\": {\"magnitude\": 300, \"unit\": \"PT\"}\n                            },\n                            \"transform\": {\n                                \"scaleX\": 1,\n                                \"scaleY\": 1,\n                                \"translateX\": 150,  # Centered\n                                \"translateY\": 150,\n                                \"unit\": \"PT\"\n                            }\n                        }\n                    }\n                })\n        \n        # If there are facilitator notes, add them as speaker notes\n        if \"facilitator_notes\" in sl and sl[\"facilitator_notes\"]:\n            reqs.append({\n                \"insertText\": {\n                    \"objectId\": f\"{page_id}\",\n                    \"insertionIndex\": 0,\n                    \"text\": sl[\"facilitator_notes\"]\n                }\n            })\n    \n    return reqs\n\n\n# ---------- batch processing ------------------------------------------------\n\ndef process_batch(reqs: List[Dict], slides_service, presentation_id: str, batch_size: int = 20) -> List[Dict]:\n    \"\"\"Process requests in batches to avoid API limits.\"\"\"\n    results = []\n    for i in range(0, len(reqs), batch_size):\n        batch = reqs[i:i + batch_size]\n        LOGGER.info(\"Processing batch %d/%d (%d requests)\", \n                    i // batch_size + 1, \n                    (len(reqs) + batch_size - 1) // batch_size, \n                    len(batch))\n        \n        try:\n            result = slides_service.presentations().batchUpdate(\n                presentationId=presentation_id, \n                body={\"requests\": batch}\n            ).execute()\n            results.append(result)\n            \n            # Avoid rate limits\n            if i + batch_size < len(reqs):\n                time.sleep(1)\n                \n        except HttpError as e:\n            LOGGER.error(\"Batch update failed: %s\", e)\n            if e.status_code == 429:  # Too Many Requests\n                LOGGER.info(\"Hit rate limit, waiting 10 seconds before retrying...\")\n                time.sleep(10)\n                # Retry this batch\n                try:\n                    result = slides_service.presentations().batchUpdate(\n                        presentationId=presentation_id, \n                        body={\"requests\": batch}\n                    ).execute()\n                    results.append(result)\n                except HttpError as e2:\n                    LOGGER.error(\"Retry failed: %s\", e2)\n                    raise\n            else:\n                raise\n    \n    return results\n\n\n# ---------- main ------------------------------------------------------------\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Generate Google Slides deck from slides.json\")\n    p.add_argument(\"json\", help=\"slides.json with image_url filled\")\n    p.add_argument(\"--title\", default=None, help=\"Presentation title (default: based on input filename)\")\n    p.add_argument(\"--template-id\", help=\"Google Slides file ID to copy as template\")\n    p.add_argument(\"--port\", type=int, default=8080, help=\"Port for OAuth flow\")\n    p.add_argument(\"--batch-size\", type=int, default=20, help=\"Number of requests per batch\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    # Validate input JSON\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"JSON file not found: %s\", json_path)\n        sys.exit(1)\n    \n    try:\n        slides_data = json.loads(json_path.read_text())\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON: %s\", e)\n        sys.exit(1)\n    \n    # Determine presentation title\n    if args.title:\n        title = args.title\n    else:\n        # Base title on input filename\n        base_name = json_path.stem\n        if base_name.startswith(\"slides_\"):\n            base_name = base_name[7:]  # Remove \"slides_\" prefix\n        title = f\"{base_name.replace('_', ' ').title()} Presentation\"\n    \n    # Authenticate with Google\n    try:\n        slides_service, drive_service = auth(args.port)\n    except Exception as e:\n        LOGGER.error(\"Authentication failed: %s\", e)\n        sys.exit(1)\n\n    # Create or copy presentation\n    presentation_id: str\n    try:\n        if args.template_id:\n            presentation_id = duplicate_template(drive_service, args.template_id, title)\n            LOGGER.info(\"Template duplicated → %s\", presentation_id)\n        else:\n            pres = slides_service.presentations().create(body={\"title\": title}).execute()\n            presentation_id = pres[\"presentationId\"]\n            LOGGER.info(\"Blank deck created → %s\", presentation_id)\n    except HttpError as e:\n        LOGGER.error(\"Failed to create presentation: %s\", e)\n        sys.exit(1)\n\n    # Build and process requests\n    try:\n        reqs = build_requests(slides_data)\n        LOGGER.info(\"Built %d requests\", len(reqs))\n        \n        results = process_batch(reqs, slides_service, presentation_id, args.batch_size)\n        LOGGER.info(\"Slides added: %d\", len(slides_data))\n        \n        # Get the presentation URL\n        presentation_url = f\"https://docs.google.com/presentation/d/{presentation_id}/edit\"\n        print(\"\\nDeck URL:\", presentation_url)\n        \n        # Attempt to open in browser\n        import webbrowser\n        webbrowser.open(presentation_url)\n        \n    except Exception as e:\n        LOGGER.error(\"Failed to update presentation: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## Key Improvements\n\n### 1. In `diagrams_to_images.py`:\n- Added support for Mermaid config JSON\n- Save local copies of both .mmd and .png files based on the guide filename and slide number\n- Added retry logic with exponential backoff\n- Added more robust error handling\n- Configurable output directory\n\n### 2. In `guide_to_json.py`:\n- Added directory processing capability\n- Output JSON files to the same folder as input files\n- Added retry logic for API calls\n- Made Claude model configurable\n- Better error handling with specific error messages\n\n### 3. In `build_slides.py`:\n- Fixed the critical issue with placeholder management\n- Better handles different slide layouts\n- Automatically detects client_secret_*.json files\n- Added speaker notes support\n- Improved image placement based on slide layout\n- Added batch processing to avoid API rate limits\n- Intelligent naming of slides based on input file\n\n## Usage Examples\n\n### Process a directory of guides and generate slides:\n\n```bash\n# Step 1: Process all MD files in a directory\npython guide_to_json.py guides/ --prompt prompt-template.txt --log-level INFO\n\n# Step 2: Process diagrams with mermaid config and save local copies\npython diagrams_to_images.py guides/slides_workshop.json --mermaid-config mermaid-config.json --save-local\n\n# Step 3: Build slides with Google Slides\npython build_slides.py guides/slides_workshop.json --template-id YOUR_TEMPLATE_ID\n```\n\nThese improved scripts should make your slide generation pipeline much more robust while keeping all generated assets properly organized and named. The improvements address the Google Slides API issues that were causing problems with inserting content and images.",
            "citations": []
          }
        ],
        "updated_at": "2025-05-20T06:16:33.514117Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "0acdaf60-2394-458c-a611-7b136e9ca7e9",
      "role": "human",
      "content": "can we do the same to create all the slides with the same sort of process where we direct it to the guides folder and it will process either all of the folder or individual files to generate the json files?\nThen we and then the same for the google slides, except we need a new process because I just found out about this: I want to update the YAML file to update the prompt and to include a column for layout so we choose the best layout and then we have the JSON for the ability to see the notes and to create the images and then after that we need to make markdown from the slides-day1.json that uses the best features available in the markdown file described below, and then we can run generate google slides to make the google slides rather than what we're doing now which has been messy - review and return",
      "created_at": "2025-05-20T09:37:04.106428Z",
      "sequence_order": 4,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-20T09:37:04.096649Z",
            "stop_timestamp": "2025-05-20T09:37:04.096649Z",
            "flags": null,
            "type": "text",
            "text": "can we do the same to create all the slides with the same sort of process where we direct it to the guides folder and it will process either all of the folder or individual files to generate the json files?\nThen we and then the same for the google slides, except we need a new process because I just found out about this: I want to update the YAML file to update the prompt and to include a column for layout so we choose the best layout and then we have the JSON for the ability to see the notes and to create the images and then after that we need to make markdown from the slides-day1.json that uses the best features available in the markdown file described below, and then we can run generate google slides to make the google slides rather than what we're doing now which has been messy - review and return",
            "citations": []
          }
        ],
        "updated_at": "2025-05-20T09:37:04.106428Z",
        "attachments": [
          {
            "file_name": "paste.txt",
            "file_size": 8671,
            "file_type": "txt",
            "extracted_content": "Generate Google Slides from markdown & HTML. Run from the command line or embed in another application.\n\nThis project was developed as an example of how to use the Slides API.\n\nWhile it does not yet produce stunningly beautiful decks, you are encouraged to use this tool for quickly prototyping presentations.\n\nContributions are welcome.\n\nInstallation and usage\nFor command line use, install md2gslides globally:\n\nnpm install -g md2gslides\nThen get your OAuth client ID credentials:\n\nCreate (or reuse) a developer project at https://console.developers.google.com\nEnable Google Slides API at API library page\nGo to Credentials page and click \"+ Create credentials\" at the top\nSelect \"OAuth client ID\" authorization credentials\nChoose type \"Computer Application\" and give it some name.\nDownload client credentials file.\nCopy it to client_id.json (name has to match) and save to ~/.md2googleslides.\nAfter installing, import your slides by running:\n\nmd2gslides slides.md --title \"Talk Title\"\nThis will generate new Google Slides in your account with title Talk Title.\n\nNOTE: The first time the command is run you will be prompted for authorization. OAuth token credentials are stored locally in a file named ~/.md2googleslides/credentials.json.\n\nEach time you will run the above comment, new slide deck will be generated. In order to work on exactly the same deck, just get the ID of the already generated slides. For example, you can use following command:\n\n# To reuse deck available at: https://docs.google.com/presentation/d/<some id>/edit#\nmd2gslides slides.md --title \"Talk Title\" --append <some id> --erase\nSupported markdown rules\nmd2gslides uses a subset of the CommonMark and Github Flavored Markdown rules for markdown.\n\nSlides\nEach slide is typically represented by a header, followed by zero or more block elements.\n\nBegin a new slide with a horizontal rule (---). The separator may be omitted for the first slide.\n\nThe following examples show how to create slides of various layouts:\n\nTitle slide\n    ---\n\n    # This is a title slide\n    ## Your name here\nTitle slide\n\nSection title slides\n    ---\n\n    # This is a section title\nSection title slide\n\nSection title & body slides\n    ---\n\n    # Section title & body slide\n\n    ## This is a subtitle\n\n    This is the body\nSection title & body slide\n\nTitle & body slides\n    ---\n\n    # Title & body slide\n\n    This is the slide body.\nTitle & body slide\n\nMain point slide\nAdd {.big} to the title to make a slide with one big point\n\n    ---\n\n    # This is the main point {.big}\nMain point slide\n\nBig number slide\nUse {.big} on a header in combination with a body too.\n\n    ---\n\n    # 100% {.big}\n\n    This is the body\nBig number slide\n\nTwo column slides\nSeparate columns with {.column}. The marker must appear on its own line with a blank both before and after.\n\n    ---\n\n    # Two column layout\n\n    This is the left column\n\n    {.column}\n\n    This is the right column\nTwo column slide\n\nThemes\nmd2googleslides does not edit or control any theme related options. Just set a base theme you want on Google Slides directly. Even if you will use --append option for deck reuse, theme will be not changed.\n\nImages\nInline images\nImages can be placed on slides using image tags. Multiple images can be included. Mulitple images in a single paragraph are arranged in columns, mutiple paragraphs arranged as rows.\n\nNote: Images are currently scaled and centered to fit the slide template.\n\n    ---\n\n    # Slides can have images\n\n    ![](https://placekitten.com/900/900)\nSlide with image\n\nBackground images\nSet the background image of a slide by adding {.background} to the end of an image URL.\n\n    ---\n\n    # Slides can have background images\n\n    ![](https://placekitten.com/1600/900){.background}\nSlide with background image\n\nVideos\nInclude YouTube videos with a modified image tag.\n\n    ---\n\n    # Slides can have videos\n\n    @[youtube](MG8KADiRbOU)\nSlide with video\n\nSpeaker notes\nInclude speaker notes for a slide using HTML comments. Text inside the comments may include markdown for formatting, though only text formatting is allowed. Videos, images, and tables are ignored inside speaker notes.\n\n    ---\n\n    # Slide title\n\n    ![](https://placekitten.com/1600/900){.background}\n\n    <!--\n    These are speaker notes.\n    -->\nFormatting\nBasic formatting rules are allowed, including:\n\nBold\nItalics\nCode\nStrikethrough\nHyperlinks\nOrdered lists\nUnordered lists\nThe following markdown illustrates a few common styles.\n\n**Bold**, *italics*, and ~~strikethrough~~ may be used.\n\nOrdered lists:\n1. Item 1\n1. Item 2\n  1. Item 2.1\n\nUnordered lists:\n* Item 1\n* Item 2\n  * Item 2.1\nAdditionally, a subset of inline HTML tags are supported for styling.\n\n<span>\n<sup>\n<sub>\n<em>\n<i>\n<strong>\n<b>\nSupported CSS styles for use with <span> elements:\n\ncolor\nbackground-color\nfont-weight: bold\nfont-style: italic\ntext-decoration: underline\ntext-decoration: line-through\nfont-family\nfont-variant: small-caps\nfont-size (must use points for units)\nYou may also use {style=\"...\"} attributes after markdown elements to apply styles. This can be used on headers, inline elements, code blocks, etc.\n\nEmoji\nUse Github style emoji in your text using the :emoji:.\n\nThe following example inserts emoji in the header and body of the slide.\n\n### I :heart: cats\n\n:heart_eyes_cat:\nCode blocks\nBoth indented and fenced code blocks are supported, with syntax highlighting.\n\nThe following example renders highlighted code.\n\n### Hello World\n\n```javascript\nconsole.log('Hello world');\n```\nTo change the syntax highlight theme specify the --style <theme> option on the command line. All highlight.js themes are supported. For example, to use the github theme\n\nmd2gslides slides.md --style github\nYou can also apply additional style changes to the entire block, such as changing the font size:\n\n### Hello World\n\n```javascript\nconsole.log('Hello world');\n```{style=\"font-size: 36pt\"}\nTables\nTables are supported via GFM syntax.\n\nNote: Including tables and other block elements on the same slide may produce poor results with overlapping elements. Either avoid or manually adjust the layout after generating the slides.\n\nThe following generates a 2x5 table on the slide.\n\n### Top pets in the United States\n\nAnimal | Number\n-------|--------\nFish   | 142 million\nCats   | 88 million\nDogs   | 75 million\nBirds  | 16 million\nLocal images\nImages referencing local paths temporarily uploaded and hosted to file.io. File.io is an emphemeral file serving service that generates short-lived random URLs to the upload file and deletes content shortly after use.\n\nSince local images are uploaded to a thrid party, explicit opt-in is required to use this feature. Include the --use-fileio option to opt-in to uploading images. This applies to file-based images as well as automatically rasterized content like math expressions and SVGs.\n\nImage rasterization\nSlides can also include generated images, using $$$ fenced blocks for the data. Currently supported generated images are math expression (TeX and MathML) as well as SVG. Rasterized images are treated like local images are require opt-in to uploading images to a 3rd party service via the --use-fileio option.\n\nUsing TeX:\n\n# How about some math?\n\n$$$ math\n\\cos (2\\theta) = \\cos^2 \\theta - \\sin^2 \\theta\n$$$\nSVG\n\n# Or some SVG?\n\n$$$ svg\n<svg xmlns=\"http://www.w3.org/2000/svg\"\n     xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n     viewBox=\"0 0 48 48\">\n  <defs>\n    <path id=\"a\" d=\"M44.5 20H24v8.5h11.8C34.7 33.9 30.1 37 24 37c-7.2 0-13-5.8-13-13s5.8-13 13-13c3.1 0 5.9 1.1 8.1 2.9l6.4-6.4C34.6 4.1 29.6 2 24 2 11.8 2 2 11.8 2 24s9.8 22 22 22c11 0 21-8 21-22 0-1.3-.2-2.7-.5-4z\"/>\n  </defs>\n  <clipPath id=\"b\">\n    <use xlink:href=\"#a\" overflow=\"visible\"/>\n  </clipPath>\n  <path clip-path=\"url(#b)\" fill=\"#EA4335\" d=\"M0 11l17 13 7-6.1L48 14V0H0z\"/>\n  <path clip-path=\"url(#b)\" fill=\"#34A853\" d=\"M0 37l30-23 7.9 1L48 0v48H0z\"/>\n  <path clip-path=\"url(#b)\" fill=\"#4285F4\" d=\"M48 48L17 24l-4-3 35-10z\"/>\n</svg>\n$$$\nLike local images, generated images are temporarily served via file.io.\n\nPull requests for other image generators (e.g. mermaid, chartjs, etc.) are welcome!\n\nReading from standard input\nYou can also pipe markdown into the tool by omitting the file name argument.\n\nContributing\nWith the exception of /bin/md2gslides.js, TypeScript is used throughout and compiled with Babel. Mocha and Chai are used for testing.\n\nBefore anything, ensure you have all dependencies:\n\nnpm install\nTo compile:\n\nnpm run compile\nTo run unit tests:\n\nnpm run test\nTo lint/format tests:\n\nnpm run lint\nSee CONTRIBUTING for additional terms.\n\nLicense\nThis library is licensed under Apache 2.0. Full license text is available in LICENSE."
          }
        ],
        "files": [
          {
            "file_name": "paste.txt"
          }
        ]
      }
    },
    {
      "id": "02f102b4-f0b5-464a-a640-4e576bcced1d",
      "role": "assistant",
      "content": "Alright, so based on your request and the document you attached, I need to:\n\n1. Update the scripts to batch process files in a directory, similar to what I've already done in my previous response.\n2. Add YAML file support for prompt customization and layout selection.\n3. Create a new process to generate markdown from the JSON files, leveraging features from the md2gslides tool you shared.\n4. Update the flow to use md2gslides for creating Google Slides instead of the current approach.\n\nLet's break this down:\n\n### Enhanced Workflow\n\nCurrent:\nfacilitator.md → guide_to_json.py → diagrams_to_images.py → update_images.py → build_slides.py\n\nProposed:\n1. facilitator.md → guide_to_json.py (with YAML config) → slides.json\n2. slides.json → json_to_markdown.py → slides.md\n3. slides.md → md2gslides command → Google Slides\n\nLet's update the scripts one by one:\n\n1. **guide_to_json.py**: This already supports directory processing from my previous update. I'll add YAML config support for prompt customization and layout selection.\n\n2. **New script - json_to_markdown.py**: I'll create this script to convert JSON to markdown following the md2gslides format.\n\n3. **build_with_md2gslides.py**: A wrapper script to call md2gslides after generating the markdown files.\n\nLet's start implementing:\n\n### 1. Updated guide_to_json.py with YAML Config Support\n\nThis script needs to:\n- Accept a YAML config file for prompt template and layout mappings\n- Process either a single file or a directory of files\n- Output JSON files in the same directory as the input files\n\n### 2. New json_to_markdown.py Script\n\nThis script needs to:\n- Convert slides.json to markdown compatible with md2gslides\n- Support different layouts\n- Include images, diagrams, and formatting\n- Output markdown files in the same directory as the JSON files\n\n### 3. build_with_md2gslides.py Script\n\nThis script needs to:\n- Call md2gslides with appropriate options\n- Handle batch processing of multiple markdown files\n- Support appending to existing presentations\n\nLet me implement these scripts one by one.I'll update your slide-generation system to create a more streamlined process that leverages md2gslides for better Google Slides integration. This will involve updating existing scripts and creating new ones.\n\n## 1. Updated `guide_to_json.py` with YAML Config Support\n\n```python\n#!/usr/bin/env python3\n\"\"\"Convert a facilitator guide into slides.json using Claude 3.\n\nUsage:\n  python guide_to_json.py guide.md \\\n      --config config.yaml \\\n      --out slides.json \\\n      --log-level INFO \\\n      --log-file build.log\n      \n  # Process all markdown files in a folder:\n  python guide_to_json.py guides/ \\\n      --config config.yaml \\\n      --log-level INFO \\\n      --log-file build.log\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, time, yaml\nfrom pathlib import Path\nfrom typing import List, Dict, Any\nimport anthropic\n\nDEFAULT_OUT = \"slides.json\"\nDEFAULT_CONFIG = \"config.yaml\"\n\nLOGGER = logging.getLogger(\"guide_to_json\")\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"LLM → JSON slide outline\")\n    p.add_argument(\"guide\", help=\"Facilitator guide (Markdown/text) or directory of guides\")\n    p.add_argument(\"--config\", default=DEFAULT_CONFIG, help=\"YAML config with prompt template and layout mappings\")\n    p.add_argument(\"--out\", default=None, help=\"Output JSON path (ignored if guide is a directory)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None, help=\"Write logs to file as well\")\n    p.add_argument(\"--model\", default=\"claude-3-7-sonnet-20250219\", help=\"Claude model to use\")\n    p.add_argument(\"--batch-size\", type=int, default=5, help=\"Number of files to process in parallel (batch mode)\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers: list[logging.Handler] = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(\n        level=level,\n        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n        handlers=handlers,\n    )\n\n\ndef load_config(config_path: Path) -> Dict[str, Any]:\n    \"\"\"Load YAML configuration file with prompt template and layout mappings.\"\"\"\n    if not config_path.exists():\n        LOGGER.warning(\"Config file %s not found, using defaults\", config_path)\n        return {\n            \"prompt_template\": \"{{content}}\",\n            \"layout_mappings\": {},\n            \"slide_defaults\": {}\n        }\n    \n    with open(config_path, 'r') as f:\n        config = yaml.safe_load(f)\n    \n    # Ensure required keys exist\n    config.setdefault(\"prompt_template\", \"{{content}}\")\n    config.setdefault(\"layout_mappings\", {})\n    config.setdefault(\"slide_defaults\", {})\n    \n    return config\n\n\ndef build_prompt(template: str, guide_text: str) -> str:\n    \"\"\"Insert guide text into prompt template.\"\"\"\n    if \"{{content}}\" not in template:\n        LOGGER.error(\"Prompt template missing {{content}} placeholder\")\n        sys.exit(1)\n    return template.replace(\"{{content}}\", guide_text)\n\n\n# Insert missing keys and correct ordering\nORDER = [\n    \"slide_number\", \"title\", \"content\", \"layout\", \"chart_type\", \"diagram_type\", \"diagram_content\",\n    \"image_description\", \"image_url\", \"facilitator_notes\", \"start_time\", \"end_time\",\n    \"materials\", \"worksheet\", \"improvements\", \"notes\",\n]\n\n\ndef normalize(slides: list[dict], layout_mappings: Dict[str, str], slide_defaults: Dict[str, Any]) -> list[dict]:\n    \"\"\"Normalize slides by adding missing keys and applying layout mappings.\"\"\"\n    fixed = []\n    for idx, raw in enumerate(slides, 1):\n        # Apply defaults\n        for key, value in slide_defaults.items():\n            raw.setdefault(key, value)\n        \n        # Set slide number\n        raw.setdefault(\"slide_number\", idx)\n        \n        # Apply layout mapping if available\n        layout = raw.get(\"layout\")\n        if not layout:\n            # Determine layout based on content\n            if idx == 1:\n                raw[\"layout\"] = \"TITLE\"\n            elif raw.get(\"image_url\") or raw.get(\"diagram_type\"):\n                raw[\"layout\"] = \"TITLE_AND_TWO_COLUMNS\"\n            else:\n                raw[\"layout\"] = \"TITLE_AND_BODY\"\n        \n        # Apply custom layout mappings\n        if layout in layout_mappings:\n            raw[\"layout\"] = layout_mappings[layout]\n        \n        # Ensure all other keys exist\n        raw.setdefault(\"chart_type\", None)\n        raw.setdefault(\"image_description\", None)\n        raw.setdefault(\"image_url\", None)\n        for key in ORDER:\n            raw.setdefault(key, None)\n        \n        # Create ordered dictionary\n        fixed.append({k: raw.get(k) for k in ORDER})\n    \n    return fixed\n\n\ndef process_guide(guide_path: Path, config: Dict[str, Any], out_path: Path | None, model: str, client: anthropic.Anthropic) -> Path:\n    \"\"\"Process a single guide file and return the output path.\"\"\"\n    LOGGER.info(\"Processing guide: %s\", guide_path)\n    \n    # Determine output path\n    if not out_path:\n        out_path = guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n    \n    # Read guide and build prompt\n    guide_txt = guide_path.read_text(encoding=\"utf-8\")\n    prompt = build_prompt(config[\"prompt_template\"], guide_txt)\n    \n    # Request Claude with retries\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            LOGGER.info(\"Requesting Claude (%s) for %s...\", model, guide_path.name)\n            rsp = client.messages.create(\n                model=model,\n                max_tokens=16_000,\n                system=\"Return JSON only.\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            )\n            \n            raw = rsp.content[0].text\n            start = raw.find(\"[\")\n            if start == -1:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Claude response contained no JSON array, retrying in %d seconds...\", 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Claude response contained no JSON array after %d attempts\", max_attempts)\n                    raise ValueError(\"Claude response contained no JSON array\")\n            \n            try:\n                slides = json.loads(raw[start:])\n            except json.JSONDecodeError as e:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Invalid JSON from Claude: %s, retrying in %d seconds...\", e, 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Invalid JSON from Claude after %d attempts: %s\", max_attempts, e)\n                    raise\n            \n            # Normalize and save\n            slides = normalize(slides, config[\"layout_mappings\"], config[\"slide_defaults\"])\n            out_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n            LOGGER.info(\"Wrote %d slides → %s\", len(slides), out_path)\n            return out_path\n            \n        except (anthropic.APIError, anthropic.APITimeoutError, anthropic.APIConnectionError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"API error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                            attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)\n            else:\n                LOGGER.error(\"API error after %d attempts: %s\", max_attempts, e, exc_info=True)\n                raise\n    \n    raise RuntimeError(\"Failed to process guide, this should not happen\")  # Unreachable\n\n\ndef process_directory(guide_dir: Path, config: Dict[str, Any], model: str, batch_size: int, client: anthropic.Anthropic) -> List[Path]:\n    \"\"\"Process all markdown files in a directory.\"\"\"\n    LOGGER.info(\"Processing all markdown files in: %s\", guide_dir)\n    \n    # Find all markdown files\n    md_files = list(guide_dir.glob(\"*.md\"))\n    if not md_files:\n        LOGGER.error(\"No markdown files found in %s\", guide_dir)\n        sys.exit(1)\n    \n    LOGGER.info(\"Found %d markdown files to process\", len(md_files))\n    \n    # Process files in batches to avoid overwhelming the API\n    results = []\n    for i in range(0, len(md_files), batch_size):\n        batch = md_files[i:i + batch_size]\n        LOGGER.info(\"Processing batch %d/%d (%d files)\", i // batch_size + 1, \n                   (len(md_files) + batch_size - 1) // batch_size, len(batch))\n        \n        for guide_path in batch:\n            try:\n                out_path = process_guide(guide_path, config, None, model, client)\n                results.append(out_path)\n            except Exception as e:\n                LOGGER.error(\"Failed to process %s: %s\", guide_path, e, exc_info=True)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n    if not api_key:\n        LOGGER.error(\"Set ANTHROPIC_API_KEY environment variable\")\n        sys.exit(1)\n\n    # Load configuration\n    config_path = Path(args.config)\n    config = load_config(config_path)\n    \n    # Validate paths\n    guide_path = Path(args.guide)\n    \n    if not guide_path.exists():\n        LOGGER.error(\"Guide path not found: %s\", guide_path)\n        sys.exit(1)\n    \n    # Initialize Claude client\n    client = anthropic.Anthropic(api_key=api_key)\n    \n    if guide_path.is_dir():\n        LOGGER.info(\"Directory mode: Processing all markdown files in %s\", guide_path)\n        if args.out:\n            LOGGER.warning(\"--out parameter ignored in directory mode\")\n        \n        # Process directory\n        process_directory(guide_path, config, args.model, args.batch_size, client)\n        \n    else:\n        # Single file mode\n        # Determine output path\n        out_path = Path(args.out) if args.out else guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n        \n        # Process single guide\n        process_guide(guide_path, config, out_path, args.model, client)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 2. Updated `diagrams_to_images.py` (Enhanced with Output Directory Support)\n\n```python\n#!/usr/bin/env python3\n\"\"\"Render Mermaid diagrams & upload to FreeImage.host (API v1).\n\nAdds/overwrites image_url in slides.json whenever both diagram_type and\ndiagram_content are present. Also saves local copies of the diagrams with\nnames based on the source file.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, subprocess, sys, time, shutil\nfrom pathlib import Path\nfrom typing import Any, List, Optional, Tuple\n\nimport requests\n\nLOGGER = logging.getLogger(\"diagrams_to_images\")\nMERMAID_CMD = \"mmdc\"  # must be on PATH\nFREEIMAGE_ENDPOINT = \"https://freeimage.host/api/1/upload\"\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Render Mermaid diagrams & upload to FreeImage.host\")\n    p.add_argument(\"json\", help=\"slides.json to update (in-place) or directory of JSON files\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    p.add_argument(\"--temp-dir\", default=None, help=\"where to render PNGs temporarily (default: same as slides.json)\")\n    p.add_argument(\"--mermaid-config\", default=\"mermaid-config.json\", help=\"Mermaid configuration file\")\n    p.add_argument(\"--save-local\", action=\"store_true\", help=\"Save local copies of diagrams in the same folder\")\n    p.add_argument(\"--output-dir\", default=None, help=\"Directory to save output files (default: same as slides.json)\")\n    p.add_argument(\"--batch-size\", type=int, default=5, help=\"Number of files to process in parallel (batch mode)\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef render_mermaid(src: str, tmp: Path, config_path: Optional[Path], base_filename: str, slide_num: int) -> tuple[Path, Path]:\n    \"\"\"Render mermaid diagram to PNG.\n    \n    Args:\n        src: Mermaid diagram content\n        tmp: Directory to save temporary files\n        config_path: Path to mermaid config file\n        base_filename: Base filename (from guide file)\n        slide_num: Slide number\n        \n    Returns:\n        tuple of (png_path, mmd_path)\n    \"\"\"\n    # Create filenames based on guide name and slide number\n    output_name = f\"{base_filename}_{slide_num}\"\n    mmd = tmp / f\"{output_name}.mmd\"\n    png = tmp / f\"{output_name}.png\"\n    \n    # Write mermaid content to file\n    mmd.write_text(src, encoding=\"utf-8\")\n    \n    # Build command with optional config\n    cmd = [MERMAID_CMD, \"-i\", mmd, \"-o\", png, \"-b\", \"transparent\"]\n    if config_path and config_path.exists():\n        cmd.extend([\"-c\", config_path])\n    \n    LOGGER.debug(\"Running command: %s\", \" \".join(str(x) for x in cmd))\n    \n    # Execute command with retry\n    for attempt in range(3):\n        try:\n            subprocess.run(cmd, check=True, capture_output=True)\n            if png.exists() and png.stat().st_size > 0:\n                return png, mmd\n            \n            if attempt < 2:  # Only log warning for first two attempts\n                LOGGER.warning(\"Empty output from mermaid-cli, retrying in 2s...\")\n                time.sleep(2)\n        except subprocess.CalledProcessError as e:\n            if attempt < 2:  # Only log error for first two attempts\n                LOGGER.warning(\"mermaid-cli error (attempt %d/3): %s\", attempt + 1, e.stderr.decode())\n                time.sleep(2)\n    \n    # If we got here, all attempts failed\n    raise RuntimeError(f\"Failed to render mermaid diagram after 3 attempts for slide {slide_num}\")\n\n\ndef upload_freeimage(png: Path) -> str:\n    \"\"\"Upload PNG to FreeImage.host and return URL.\"\"\"\n    api_key = os.getenv(\"FREEIMAGE_API_KEY\")\n    if not api_key:\n        raise RuntimeError(\"FREEIMAGE_API_KEY env var not set\")\n    \n    # Retry logic for uploads\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            with png.open(\"rb\") as fh:\n                payload = {\n                    \"key\": api_key,\n                    \"action\": \"upload\",\n                    \"format\": \"json\",\n                }\n                files = {\"source\": fh}\n                rsp = requests.post(FREEIMAGE_ENDPOINT, data=payload, files=files, timeout=20)\n                rsp.raise_for_status()\n                \n            data: dict[str, Any] = rsp.json()\n            if data.get(\"status_code\") != 200:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Upload failed (attempt %d/%d): %s. Retrying in %d seconds...\", \n                                  attempt + 1, max_attempts, data, 2 ** attempt)\n                    time.sleep(2 ** attempt)  # Exponential backoff\n                    continue\n                raise RuntimeError(f\"Upload failed after {max_attempts} attempts: {data}\")\n                \n            return data[\"image\"][\"url\"]\n            \n        except (requests.RequestException, json.JSONDecodeError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"Upload error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                              attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)  # Exponential backoff\n            else:\n                raise RuntimeError(f\"Upload failed after {max_attempts} attempts: {e}\")\n    \n    raise RuntimeError(\"Upload failed, this should not happen\")  # Unreachable\n\n\ndef get_base_filename(json_path: Path) -> str:\n    \"\"\"Extract base filename (without extension) from path.\"\"\"\n    return json_path.stem.replace('slides_', '')  # Remove 'slides_' prefix if present\n\n\ndef process_json_file(json_path: Path, tmp_dir: Path, config_path: Optional[Path], save_local: bool, output_dir: Optional[Path]) -> int:\n    \"\"\"Process a single JSON file and render diagrams.\"\"\"\n    LOGGER.info(\"Processing JSON file: %s\", json_path)\n    \n    # Load JSON data\n    try:\n        slides = json.loads(json_path.read_text())\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON in %s: %s\", json_path, e)\n        return 0\n    \n    # Extract base filename and determine output directory\n    base_filename = get_base_filename(json_path)\n    final_dir = output_dir if output_dir else json_path.parent\n    final_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Process all slides\n    changed = 0\n    for slide in slides:\n        if slide.get(\"diagram_type\") and slide.get(\"diagram_content\"):\n            try:\n                # Render diagram\n                png_path, mmd_path = render_mermaid(\n                    slide[\"diagram_content\"], \n                    tmp_dir, \n                    config_path, \n                    base_filename, \n                    slide[\"slide_number\"]\n                )\n                \n                # Upload to FreeImage\n                url = upload_freeimage(png_path)\n                slide[\"image_url\"] = url\n                changed += 1\n                \n                # Save local copies if requested\n                if save_local:\n                    local_png = final_dir / png_path.name\n                    local_mmd = final_dir / mmd_path.name\n                    \n                    shutil.copy2(png_path, local_png)\n                    shutil.copy2(mmd_path, local_mmd)\n                    LOGGER.info(\"Saved local copies: %s and %s\", local_png.name, local_mmd.name)\n                \n                LOGGER.info(\"Rendered & uploaded diagram for slide %d → %s\", slide[\"slide_number\"], url)\n                \n            except Exception as e:\n                LOGGER.error(\"Diagram for slide %d failed: %s\", slide[\"slide_number\"], e, exc_info=True)\n    \n    # Save updated JSON back\n    if changed > 0:\n        json_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n        LOGGER.info(\"%d diagrams processed; file updated: %s\", changed, json_path)\n    \n    return changed\n\n\ndef process_directory(json_dir: Path, tmp_dir: Path, config_path: Optional[Path], save_local: bool, output_dir: Optional[Path]) -> int:\n    \"\"\"Process all JSON files in a directory.\"\"\"\n    LOGGER.info(\"Processing all JSON files in: %s\", json_dir)\n    \n    # Find all JSON files\n    json_files = list(json_dir.glob(\"*.json\"))\n    if not json_files:\n        LOGGER.error(\"No JSON files found in %s\", json_dir)\n        return 0\n    \n    LOGGER.info(\"Found %d JSON files to process\", len(json_files))\n    \n    # Process each file\n    total_changed = 0\n    for json_path in json_files:\n        try:\n            changed = process_json_file(json_path, tmp_dir, config_path, save_local, output_dir)\n            total_changed += changed\n        except Exception as e:\n            LOGGER.error(\"Failed to process %s: %s\", json_path, e, exc_info=True)\n    \n    return total_changed\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine temporary directory\n    if args.temp_dir:\n        tmp_dir = Path(args.temp_dir)\n    else:\n        tmp_dir = json_path.parent if json_path.is_file() else json_path\n    tmp_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    if output_dir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Check if mermaid config exists\n    config_path = Path(args.mermaid_config)\n    if not config_path.exists():\n        LOGGER.warning(\"Mermaid config file %s not found, using default\", config_path)\n        config_path = None\n    \n    # Process files\n    try:\n        if json_path.is_dir():\n            total_changed = process_directory(json_path, tmp_dir, config_path, args.save_local, output_dir)\n            LOGGER.info(\"Total of %d diagrams processed across all files\", total_changed)\n        else:\n            process_json_file(json_path, tmp_dir, config_path, args.save_local, output_dir)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 3. New `json_to_markdown.py` Script\n\n```python\n#!/usr/bin/env python3\n\"\"\"Convert slides.json to md2gslides compatible markdown files.\n\nThis script converts JSON slide data to markdown format compatible with md2gslides,\nallowing for generation of Google Slides presentations.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys\nfrom pathlib import Path\nfrom typing import Dict, List, Any, Optional\n\nLOGGER = logging.getLogger(\"json_to_markdown\")\n\n# Map of slide layouts to md2gslides format templates\nLAYOUT_TEMPLATES = {\n    \"TITLE\": {\n        \"template\": \"\"\"# {title}\n## {subtitle}\n\"\"\",\n        \"fields\": [\"title\", \"subtitle\"]\n    },\n    \"TITLE_AND_BODY\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"TITLE_AND_TWO_COLUMNS\": {\n        \"template\": \"\"\"# {title}\n\n{left_column}\n\n{{.column}}\n\n{right_column}\n\"\"\",\n        \"fields\": [\"title\", \"left_column\", \"right_column\"]\n    },\n    \"MAIN_POINT\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\"\"\",\n        \"fields\": [\"title\"]\n    },\n    \"SECTION_HEADER\": {\n        \"template\": \"\"\"# {title}\n\"\"\",\n        \"fields\": [\"title\"]\n    },\n    \"BIG_NUMBER\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"CAPTION\": {\n        \"template\": \"\"\"# {title}\n\n![]({image_url})\n\"\"\",\n        \"fields\": [\"title\", \"image_url\"]\n    },\n    \"BLANK\": {\n        \"template\": \"\"\"\n![]({image_url}){{.background}}\n\"\"\",\n        \"fields\": [\"image_url\"]\n    },\n    \"DEFAULT\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    }\n}\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Convert slides.json to md2gslides markdown\")\n    p.add_argument(\"json\", help=\"slides.json file or directory of JSON files\")\n    p.add_argument(\"--output-dir\", default=None, help=\"Output directory for markdown files\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef split_content_into_columns(content: str) -> tuple[str, str]:\n    \"\"\"Split content into two columns based on content length.\"\"\"\n    if not content:\n        return \"\", \"\"\n    \n    lines = content.split('\\n')\n    if len(lines) <= 1:\n        return content, \"\"\n    \n    midpoint = len(lines) // 2\n    left_column = '\\n'.join(lines[:midpoint])\n    right_column = '\\n'.join(lines[midpoint:])\n    \n    return left_column, right_column\n\n\ndef format_slide(slide: Dict[str, Any]) -> str:\n    \"\"\"Format a single slide as markdown based on its layout.\"\"\"\n    # Extract slide data\n    layout = slide.get(\"layout\", \"DEFAULT\")\n    \n    # Get layout template\n    template_info = LAYOUT_TEMPLATES.get(layout, LAYOUT_TEMPLATES[\"DEFAULT\"])\n    template = template_info[\"template\"]\n    \n    # Create data dict for template\n    data = {\n        \"title\": slide.get(\"title\", \"\"),\n        \"subtitle\": slide.get(\"facilitator_notes\", \"\"), # Use facilitator notes as subtitle if needed\n        \"content\": slide.get(\"content\", \"\"),\n        \"image_url\": slide.get(\"image_url\", \"\")\n    }\n    \n    # For two column layouts, split content\n    if layout == \"TITLE_AND_TWO_COLUMNS\":\n        left, right = split_content_into_columns(data[\"content\"])\n        data[\"left_column\"] = left\n        \n        # If there's an image, use it for the right column\n        if data[\"image_url\"]:\n            data[\"right_column\"] = f\"![]({{data['image_url']}})\"\n        else:\n            data[\"right_column\"] = right\n    \n    # Add speaker notes if available\n    notes = slide.get(\"facilitator_notes\", \"\")\n    notes_section = f\"\\n\\n<!--\\n{notes}\\n-->\" if notes else \"\"\n    \n    # Format markdown\n    try:\n        md = template.format(**{k: v for k, v in data.items() if k in template_info[\"fields\"]})\n        return f\"---\\n\\n{md}{notes_section}\\n\"\n    except KeyError as e:\n        LOGGER.warning(f\"Missing field {e} for layout {layout}, using default\")\n        return f\"---\\n\\n# {data['title']}\\n\\n{data['content']}{notes_section}\\n\"\n\n\ndef convert_json_to_markdown(json_path: Path, output_dir: Optional[Path] = None) -> Path:\n    \"\"\"Convert a single JSON file to markdown.\"\"\"\n    LOGGER.info(\"Converting %s to markdown\", json_path)\n    \n    # Load JSON data\n    try:\n        slides = json.loads(json_path.read_text())\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON in %s: %s\", json_path, e)\n        raise\n    \n    # Create markdown\n    md_content = []\n    for slide in slides:\n        md_content.append(format_slide(slide))\n    \n    # Join with newlines\n    markdown = \"\\n\".join(md_content)\n    \n    # Determine output path\n    if output_dir:\n        output_path = output_dir / f\"{json_path.stem.replace('slides_', '')}.md\"\n    else:\n        output_path = json_path.with_suffix(\".md\")\n    \n    # Write markdown file\n    output_path.write_text(markdown)\n    LOGGER.info(\"Wrote markdown to %s\", output_path)\n    \n    return output_path\n\n\ndef process_directory(json_dir: Path, output_dir: Optional[Path] = None) -> List[Path]:\n    \"\"\"Process all JSON files in a directory.\"\"\"\n    LOGGER.info(\"Processing all JSON files in %s\", json_dir)\n    \n    # Find all JSON files\n    json_files = list(json_dir.glob(\"*.json\"))\n    if not json_files:\n        LOGGER.error(\"No JSON files found in %s\", json_dir)\n        return []\n    \n    LOGGER.info(\"Found %d JSON files to process\", len(json_files))\n    \n    # Process each file\n    results = []\n    for json_path in json_files:\n        try:\n            md_path = convert_json_to_markdown(json_path, output_dir)\n            results.append(md_path)\n        except Exception as e:\n            LOGGER.error(\"Failed to convert %s: %s\", json_path, e, exc_info=True)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    if output_dir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Process files\n    try:\n        if json_path.is_dir():\n            md_files = process_directory(json_path, output_dir)\n            LOGGER.info(\"Converted %d JSON files to markdown\", len(md_files))\n        else:\n            convert_json_to_markdown(json_path, output_dir)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 4. New `build_with_md2gslides.py` Script\n\n```python\n#!/usr/bin/env python3\n\"\"\"Create Google Slides presentations using md2gslides.\n\nThis script processes markdown files generated from slides.json and uses\nmd2gslides to create Google Slides presentations.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, logging, os, subprocess, sys\nfrom pathlib import Path\nfrom typing import List, Optional\n\nLOGGER = logging.getLogger(\"build_with_md2gslides\")\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Build Google Slides using md2gslides\")\n    p.add_argument(\"markdown\", help=\"Markdown file or directory of markdown files\")\n    p.add_argument(\"--title-prefix\", default=\"\", help=\"Prefix to add to presentation titles\")\n    p.add_argument(\"--style\", default=\"github\", help=\"Syntax highlighting style for code blocks\")\n    p.add_argument(\"--use-fileio\", action=\"store_true\", help=\"Use file.io for image uploads\")\n    p.add_argument(\"--output-file\", default=None, help=\"File to save presentation IDs to\")\n    p.add_argument(\"--append-id\", default=None, help=\"Append to an existing presentation ID\")\n    p.add_argument(\"--erase\", action=\"store_true\", help=\"Erase existing slides when appending\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef build_slides(md_path: Path, title_prefix: str, style: str, use_fileio: bool, append_id: Optional[str], erase: bool) -> str:\n    \"\"\"Build Google Slides from a markdown file using md2gslides.\"\"\"\n    LOGGER.info(\"Building slides from %s\", md_path)\n    \n    # Determine presentation title\n    title = f\"{title_prefix}{md_path.stem}\" if title_prefix else md_path.stem\n    \n    # Build command\n    cmd = [\"md2gslides\", str(md_path), \"--title\", title, \"--style\", style]\n    \n    if use_fileio:\n        cmd.append(\"--use-fileio\")\n    \n    if append_id:\n        cmd.extend([\"--append\", append_id])\n        if erase:\n            cmd.append(\"--erase\")\n    \n    # Execute command\n    LOGGER.debug(\"Running command: %s\", \" \".join(cmd))\n    try:\n        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n        output = result.stdout\n        \n        # Extract presentation ID from output\n        # Example output: \"Presentation created: https://docs.google.com/presentation/d/1abc123def456/edit\"\n        for line in output.splitlines():\n            if \"https://docs.google.com/presentation/d/\" in line:\n                parts = line.split(\"/\")\n                for i, part in enumerate(parts):\n                    if part == \"d\" and i + 1 < len(parts):\n                        pres_id = parts[i + 1]\n                        LOGGER.info(\"Created presentation: %s (ID: %s)\", line.strip(), pres_id)\n                        return pres_id\n        \n        # If we can't extract ID, return the whole output\n        LOGGER.warning(\"Could not extract presentation ID from output: %s\", output)\n        return output\n        \n    except subprocess.CalledProcessError as e:\n        LOGGER.error(\"Failed to build slides: %s\", e.stderr)\n        raise\n\n\ndef process_directory(md_dir: Path, title_prefix: str, style: str, use_fileio: bool, output_file: Optional[Path], append_id: Optional[str], erase: bool) -> List[str]:\n    \"\"\"Process all markdown files in a directory.\"\"\"\n    LOGGER.info(\"Processing all markdown files in %s\", md_dir)\n    \n    # Find all markdown files\n    md_files = list(md_dir.glob(\"*.md\"))\n    if not md_files:\n        LOGGER.error(\"No markdown files found in %s\", md_dir)\n        return []\n    \n    LOGGER.info(\"Found %d markdown files to process\", len(md_files))\n    \n    # Process each file\n    results = []\n    for md_path in md_files:\n        try:\n            # For directory processing, only use append_id for the first file\n            current_append_id = append_id if append_id and len(results) == 0 else None\n            \n            pres_id = build_slides(md_path, title_prefix, style, use_fileio, current_append_id, erase)\n            results.append(f\"{md_path.name}: {pres_id}\")\n            \n            # If we're appending, use the same ID for subsequent files\n            if append_id and len(results) == 1:\n                append_id = pres_id\n                \n        except Exception as e:\n            LOGGER.error(\"Failed to build slides for %s: %s\", md_path, e, exc_info=True)\n    \n    # Write results to output file if specified\n    if output_file and results:\n        output_file.write_text(\"\\n\".join(results))\n        LOGGER.info(\"Wrote presentation IDs to %s\", output_file)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate inputs\n    md_path = Path(args.markdown)\n    if not md_path.exists():\n        LOGGER.error(\"%s not found\", md_path)\n        sys.exit(1)\n    \n    # Determine output file\n    output_file = Path(args.output_file) if args.output_file else None\n    \n    # Process files\n    try:\n        # Check if md2gslides is installed\n        try:\n            subprocess.run([\"md2gslides\", \"--version\"], capture_output=True, check=True)\n        except (subprocess.SubprocessError, FileNotFoundError):\n            LOGGER.error(\"md2gslides not found. Install with: npm install -g md2gslides\")\n            sys.exit(1)\n        \n        if md_path.is_dir():\n            process_directory(md_path, args.title_prefix, args.style, args.use_fileio, output_file, args.append_id, args.erase)\n        else:\n            pres_id = build_slides(md_path, args.title_prefix, args.style, args.use_fileio, args.append_id, args.erase)\n            if output_file:\n                output_file.write_text(f\"{md_path.name}: {pres_id}\")\n                LOGGER.info(\"Wrote presentation ID to %s\", output_file)\n    \n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 5. Example YAML Configuration File (`config.yaml`)\n\n```yaml\n# Prompt template for guide_to_json.py\nprompt_template: |\n  Please convert the following facilitator guide into a detailed JSON slides outline.\n  \n  For each slide, identify:\n  1. A clear title (max 60 chars)\n  2. Bullet-point content (max 40 words per slide)\n  3. The most appropriate layout from: TITLE, TITLE_AND_BODY, TITLE_AND_TWO_COLUMNS, MAIN_POINT, SECTION_HEADER, BIG_NUMBER, CAPTION, BLANK\n  4. Any diagrams that should be created (using mermaid syntax for flowcharts, mindmaps, or timelines)\n  5. Image descriptions for relevant visuals\n  6. Facilitator notes to help the presenter\n  \n  Return the slides array in valid JSON format with these required fields: slide_number, title, content, layout, chart_type, diagram_type, diagram_content, image_description, image_url, facilitator_notes.\n  \n  Here's the guide content:\n  \n  {{content}}\n\n# Custom layout mappings (from your layout to md2gslides layout)\nlayout_mappings:\n  \"title\": \"TITLE\"\n  \"section\": \"SECTION_HEADER\"\n  \"image\": \"CAPTION\"\n  \"columns\": \"TITLE_AND_TWO_COLUMNS\"\n  \"main_point\": \"MAIN_POINT\"\n  \"big_number\": \"BIG_NUMBER\"\n\n# Default values for all slides\nslide_defaults:\n  \"chart_type\": null\n  \"image_url\": null\n```\n\n## New Workflow\n\nThe updated workflow now follows this pattern:\n\n1. **Guide to JSON**: Convert facilitator guides to JSON format with layout hints\n   ```bash\n   python guide_to_json.py guides/ --config config.yaml --log-level INFO\n   ```\n\n2. **Process Diagrams**: Render Mermaid diagrams and add image URLs\n   ```bash\n   python diagrams_to_images.py guides/ --mermaid-config mermaid-config.json --save-local\n   ```\n\n3. **Convert to Markdown**: Generate md2gslides-compatible markdown from JSON\n   ```bash\n   python json_to_markdown.py guides/ --output-dir markdown/\n   ```\n\n4. **Build Google Slides**: Use md2gslides to create presentations\n   ```bash\n   python build_with_md2gslides.py markdown/ --title-prefix \"Workshop: \" --use-fileio\n   ```\n\nThis workflow gives you several advantages:\n1. **Better layout control**: Specify exactly which slide layout to use\n2. **More robust image handling**: Consistent naming and local storage of diagrams\n3. **Improved Google Slides integration**: md2gslides is purpose-built for Slides\n4. **More flexible formatting**: Full markdown support for rich content\n\nThe `md2gslides` tool handles many edge cases that the Google Slides API can be tricky with, like proper placement of images, text formatting, and speaker notes. This should give you much better results than direct API usage.",
      "created_at": "2025-05-20T09:39:27.033086Z",
      "sequence_order": 5,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-20T09:37:07.176925Z",
            "stop_timestamp": "2025-05-20T09:37:14.853694Z",
            "flags": null,
            "type": "thinking",
            "thinking": "Alright, so based on your request and the document you attached, I need to:\n\n1. Update the scripts to batch process files in a directory, similar to what I've already done in my previous response.\n2. Add YAML file support for prompt customization and layout selection.\n3. Create a new process to generate markdown from the JSON files, leveraging features from the md2gslides tool you shared.\n4. Update the flow to use md2gslides for creating Google Slides instead of the current approach.\n\nLet's break this down:\n\n### Enhanced Workflow\n\nCurrent:\nfacilitator.md → guide_to_json.py → diagrams_to_images.py → update_images.py → build_slides.py\n\nProposed:\n1. facilitator.md → guide_to_json.py (with YAML config) → slides.json\n2. slides.json → json_to_markdown.py → slides.md\n3. slides.md → md2gslides command → Google Slides\n\nLet's update the scripts one by one:\n\n1. **guide_to_json.py**: This already supports directory processing from my previous update. I'll add YAML config support for prompt customization and layout selection.\n\n2. **New script - json_to_markdown.py**: I'll create this script to convert JSON to markdown following the md2gslides format.\n\n3. **build_with_md2gslides.py**: A wrapper script to call md2gslides after generating the markdown files.\n\nLet's start implementing:\n\n### 1. Updated guide_to_json.py with YAML Config Support\n\nThis script needs to:\n- Accept a YAML config file for prompt template and layout mappings\n- Process either a single file or a directory of files\n- Output JSON files in the same directory as the input files\n\n### 2. New json_to_markdown.py Script\n\nThis script needs to:\n- Convert slides.json to markdown compatible with md2gslides\n- Support different layouts\n- Include images, diagrams, and formatting\n- Output markdown files in the same directory as the JSON files\n\n### 3. build_with_md2gslides.py Script\n\nThis script needs to:\n- Call md2gslides with appropriate options\n- Handle batch processing of multiple markdown files\n- Support appending to existing presentations\n\nLet me implement these scripts one by one.",
            "summaries": [
              {
                "summary": "Thinking about streamlining slide generation and processing workflow across multiple file formats"
              },
              {
                "summary": "Updating scripts to batch process files and add YAML support"
              },
              {
                "summary": "Creating scripts for batch processing and YAML customization"
              },
              {
                "summary": "Engineered comprehensive workflow for automated slide generation process."
              }
            ],
            "cut_off": false
          },
          {
            "start_timestamp": "2025-05-20T09:37:15.117685Z",
            "stop_timestamp": "2025-05-20T09:39:26.921475Z",
            "flags": null,
            "type": "text",
            "text": "I'll update your slide-generation system to create a more streamlined process that leverages md2gslides for better Google Slides integration. This will involve updating existing scripts and creating new ones.\n\n## 1. Updated `guide_to_json.py` with YAML Config Support\n\n```python\n#!/usr/bin/env python3\n\"\"\"Convert a facilitator guide into slides.json using Claude 3.\n\nUsage:\n  python guide_to_json.py guide.md \\\n      --config config.yaml \\\n      --out slides.json \\\n      --log-level INFO \\\n      --log-file build.log\n      \n  # Process all markdown files in a folder:\n  python guide_to_json.py guides/ \\\n      --config config.yaml \\\n      --log-level INFO \\\n      --log-file build.log\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, time, yaml\nfrom pathlib import Path\nfrom typing import List, Dict, Any\nimport anthropic\n\nDEFAULT_OUT = \"slides.json\"\nDEFAULT_CONFIG = \"config.yaml\"\n\nLOGGER = logging.getLogger(\"guide_to_json\")\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"LLM → JSON slide outline\")\n    p.add_argument(\"guide\", help=\"Facilitator guide (Markdown/text) or directory of guides\")\n    p.add_argument(\"--config\", default=DEFAULT_CONFIG, help=\"YAML config with prompt template and layout mappings\")\n    p.add_argument(\"--out\", default=None, help=\"Output JSON path (ignored if guide is a directory)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None, help=\"Write logs to file as well\")\n    p.add_argument(\"--model\", default=\"claude-3-7-sonnet-20250219\", help=\"Claude model to use\")\n    p.add_argument(\"--batch-size\", type=int, default=5, help=\"Number of files to process in parallel (batch mode)\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers: list[logging.Handler] = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(\n        level=level,\n        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n        handlers=handlers,\n    )\n\n\ndef load_config(config_path: Path) -> Dict[str, Any]:\n    \"\"\"Load YAML configuration file with prompt template and layout mappings.\"\"\"\n    if not config_path.exists():\n        LOGGER.warning(\"Config file %s not found, using defaults\", config_path)\n        return {\n            \"prompt_template\": \"{{content}}\",\n            \"layout_mappings\": {},\n            \"slide_defaults\": {}\n        }\n    \n    with open(config_path, 'r') as f:\n        config = yaml.safe_load(f)\n    \n    # Ensure required keys exist\n    config.setdefault(\"prompt_template\", \"{{content}}\")\n    config.setdefault(\"layout_mappings\", {})\n    config.setdefault(\"slide_defaults\", {})\n    \n    return config\n\n\ndef build_prompt(template: str, guide_text: str) -> str:\n    \"\"\"Insert guide text into prompt template.\"\"\"\n    if \"{{content}}\" not in template:\n        LOGGER.error(\"Prompt template missing {{content}} placeholder\")\n        sys.exit(1)\n    return template.replace(\"{{content}}\", guide_text)\n\n\n# Insert missing keys and correct ordering\nORDER = [\n    \"slide_number\", \"title\", \"content\", \"layout\", \"chart_type\", \"diagram_type\", \"diagram_content\",\n    \"image_description\", \"image_url\", \"facilitator_notes\", \"start_time\", \"end_time\",\n    \"materials\", \"worksheet\", \"improvements\", \"notes\",\n]\n\n\ndef normalize(slides: list[dict], layout_mappings: Dict[str, str], slide_defaults: Dict[str, Any]) -> list[dict]:\n    \"\"\"Normalize slides by adding missing keys and applying layout mappings.\"\"\"\n    fixed = []\n    for idx, raw in enumerate(slides, 1):\n        # Apply defaults\n        for key, value in slide_defaults.items():\n            raw.setdefault(key, value)\n        \n        # Set slide number\n        raw.setdefault(\"slide_number\", idx)\n        \n        # Apply layout mapping if available\n        layout = raw.get(\"layout\")\n        if not layout:\n            # Determine layout based on content\n            if idx == 1:\n                raw[\"layout\"] = \"TITLE\"\n            elif raw.get(\"image_url\") or raw.get(\"diagram_type\"):\n                raw[\"layout\"] = \"TITLE_AND_TWO_COLUMNS\"\n            else:\n                raw[\"layout\"] = \"TITLE_AND_BODY\"\n        \n        # Apply custom layout mappings\n        if layout in layout_mappings:\n            raw[\"layout\"] = layout_mappings[layout]\n        \n        # Ensure all other keys exist\n        raw.setdefault(\"chart_type\", None)\n        raw.setdefault(\"image_description\", None)\n        raw.setdefault(\"image_url\", None)\n        for key in ORDER:\n            raw.setdefault(key, None)\n        \n        # Create ordered dictionary\n        fixed.append({k: raw.get(k) for k in ORDER})\n    \n    return fixed\n\n\ndef process_guide(guide_path: Path, config: Dict[str, Any], out_path: Path | None, model: str, client: anthropic.Anthropic) -> Path:\n    \"\"\"Process a single guide file and return the output path.\"\"\"\n    LOGGER.info(\"Processing guide: %s\", guide_path)\n    \n    # Determine output path\n    if not out_path:\n        out_path = guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n    \n    # Read guide and build prompt\n    guide_txt = guide_path.read_text(encoding=\"utf-8\")\n    prompt = build_prompt(config[\"prompt_template\"], guide_txt)\n    \n    # Request Claude with retries\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            LOGGER.info(\"Requesting Claude (%s) for %s...\", model, guide_path.name)\n            rsp = client.messages.create(\n                model=model,\n                max_tokens=16_000,\n                system=\"Return JSON only.\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            )\n            \n            raw = rsp.content[0].text\n            start = raw.find(\"[\")\n            if start == -1:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Claude response contained no JSON array, retrying in %d seconds...\", 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Claude response contained no JSON array after %d attempts\", max_attempts)\n                    raise ValueError(\"Claude response contained no JSON array\")\n            \n            try:\n                slides = json.loads(raw[start:])\n            except json.JSONDecodeError as e:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Invalid JSON from Claude: %s, retrying in %d seconds...\", e, 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Invalid JSON from Claude after %d attempts: %s\", max_attempts, e)\n                    raise\n            \n            # Normalize and save\n            slides = normalize(slides, config[\"layout_mappings\"], config[\"slide_defaults\"])\n            out_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n            LOGGER.info(\"Wrote %d slides → %s\", len(slides), out_path)\n            return out_path\n            \n        except (anthropic.APIError, anthropic.APITimeoutError, anthropic.APIConnectionError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"API error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                            attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)\n            else:\n                LOGGER.error(\"API error after %d attempts: %s\", max_attempts, e, exc_info=True)\n                raise\n    \n    raise RuntimeError(\"Failed to process guide, this should not happen\")  # Unreachable\n\n\ndef process_directory(guide_dir: Path, config: Dict[str, Any], model: str, batch_size: int, client: anthropic.Anthropic) -> List[Path]:\n    \"\"\"Process all markdown files in a directory.\"\"\"\n    LOGGER.info(\"Processing all markdown files in: %s\", guide_dir)\n    \n    # Find all markdown files\n    md_files = list(guide_dir.glob(\"*.md\"))\n    if not md_files:\n        LOGGER.error(\"No markdown files found in %s\", guide_dir)\n        sys.exit(1)\n    \n    LOGGER.info(\"Found %d markdown files to process\", len(md_files))\n    \n    # Process files in batches to avoid overwhelming the API\n    results = []\n    for i in range(0, len(md_files), batch_size):\n        batch = md_files[i:i + batch_size]\n        LOGGER.info(\"Processing batch %d/%d (%d files)\", i // batch_size + 1, \n                   (len(md_files) + batch_size - 1) // batch_size, len(batch))\n        \n        for guide_path in batch:\n            try:\n                out_path = process_guide(guide_path, config, None, model, client)\n                results.append(out_path)\n            except Exception as e:\n                LOGGER.error(\"Failed to process %s: %s\", guide_path, e, exc_info=True)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n    if not api_key:\n        LOGGER.error(\"Set ANTHROPIC_API_KEY environment variable\")\n        sys.exit(1)\n\n    # Load configuration\n    config_path = Path(args.config)\n    config = load_config(config_path)\n    \n    # Validate paths\n    guide_path = Path(args.guide)\n    \n    if not guide_path.exists():\n        LOGGER.error(\"Guide path not found: %s\", guide_path)\n        sys.exit(1)\n    \n    # Initialize Claude client\n    client = anthropic.Anthropic(api_key=api_key)\n    \n    if guide_path.is_dir():\n        LOGGER.info(\"Directory mode: Processing all markdown files in %s\", guide_path)\n        if args.out:\n            LOGGER.warning(\"--out parameter ignored in directory mode\")\n        \n        # Process directory\n        process_directory(guide_path, config, args.model, args.batch_size, client)\n        \n    else:\n        # Single file mode\n        # Determine output path\n        out_path = Path(args.out) if args.out else guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n        \n        # Process single guide\n        process_guide(guide_path, config, out_path, args.model, client)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 2. Updated `diagrams_to_images.py` (Enhanced with Output Directory Support)\n\n```python\n#!/usr/bin/env python3\n\"\"\"Render Mermaid diagrams & upload to FreeImage.host (API v1).\n\nAdds/overwrites image_url in slides.json whenever both diagram_type and\ndiagram_content are present. Also saves local copies of the diagrams with\nnames based on the source file.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, subprocess, sys, time, shutil\nfrom pathlib import Path\nfrom typing import Any, List, Optional, Tuple\n\nimport requests\n\nLOGGER = logging.getLogger(\"diagrams_to_images\")\nMERMAID_CMD = \"mmdc\"  # must be on PATH\nFREEIMAGE_ENDPOINT = \"https://freeimage.host/api/1/upload\"\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Render Mermaid diagrams & upload to FreeImage.host\")\n    p.add_argument(\"json\", help=\"slides.json to update (in-place) or directory of JSON files\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    p.add_argument(\"--temp-dir\", default=None, help=\"where to render PNGs temporarily (default: same as slides.json)\")\n    p.add_argument(\"--mermaid-config\", default=\"mermaid-config.json\", help=\"Mermaid configuration file\")\n    p.add_argument(\"--save-local\", action=\"store_true\", help=\"Save local copies of diagrams in the same folder\")\n    p.add_argument(\"--output-dir\", default=None, help=\"Directory to save output files (default: same as slides.json)\")\n    p.add_argument(\"--batch-size\", type=int, default=5, help=\"Number of files to process in parallel (batch mode)\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef render_mermaid(src: str, tmp: Path, config_path: Optional[Path], base_filename: str, slide_num: int) -> tuple[Path, Path]:\n    \"\"\"Render mermaid diagram to PNG.\n    \n    Args:\n        src: Mermaid diagram content\n        tmp: Directory to save temporary files\n        config_path: Path to mermaid config file\n        base_filename: Base filename (from guide file)\n        slide_num: Slide number\n        \n    Returns:\n        tuple of (png_path, mmd_path)\n    \"\"\"\n    # Create filenames based on guide name and slide number\n    output_name = f\"{base_filename}_{slide_num}\"\n    mmd = tmp / f\"{output_name}.mmd\"\n    png = tmp / f\"{output_name}.png\"\n    \n    # Write mermaid content to file\n    mmd.write_text(src, encoding=\"utf-8\")\n    \n    # Build command with optional config\n    cmd = [MERMAID_CMD, \"-i\", mmd, \"-o\", png, \"-b\", \"transparent\"]\n    if config_path and config_path.exists():\n        cmd.extend([\"-c\", config_path])\n    \n    LOGGER.debug(\"Running command: %s\", \" \".join(str(x) for x in cmd))\n    \n    # Execute command with retry\n    for attempt in range(3):\n        try:\n            subprocess.run(cmd, check=True, capture_output=True)\n            if png.exists() and png.stat().st_size > 0:\n                return png, mmd\n            \n            if attempt < 2:  # Only log warning for first two attempts\n                LOGGER.warning(\"Empty output from mermaid-cli, retrying in 2s...\")\n                time.sleep(2)\n        except subprocess.CalledProcessError as e:\n            if attempt < 2:  # Only log error for first two attempts\n                LOGGER.warning(\"mermaid-cli error (attempt %d/3): %s\", attempt + 1, e.stderr.decode())\n                time.sleep(2)\n    \n    # If we got here, all attempts failed\n    raise RuntimeError(f\"Failed to render mermaid diagram after 3 attempts for slide {slide_num}\")\n\n\ndef upload_freeimage(png: Path) -> str:\n    \"\"\"Upload PNG to FreeImage.host and return URL.\"\"\"\n    api_key = os.getenv(\"FREEIMAGE_API_KEY\")\n    if not api_key:\n        raise RuntimeError(\"FREEIMAGE_API_KEY env var not set\")\n    \n    # Retry logic for uploads\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            with png.open(\"rb\") as fh:\n                payload = {\n                    \"key\": api_key,\n                    \"action\": \"upload\",\n                    \"format\": \"json\",\n                }\n                files = {\"source\": fh}\n                rsp = requests.post(FREEIMAGE_ENDPOINT, data=payload, files=files, timeout=20)\n                rsp.raise_for_status()\n                \n            data: dict[str, Any] = rsp.json()\n            if data.get(\"status_code\") != 200:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Upload failed (attempt %d/%d): %s. Retrying in %d seconds...\", \n                                  attempt + 1, max_attempts, data, 2 ** attempt)\n                    time.sleep(2 ** attempt)  # Exponential backoff\n                    continue\n                raise RuntimeError(f\"Upload failed after {max_attempts} attempts: {data}\")\n                \n            return data[\"image\"][\"url\"]\n            \n        except (requests.RequestException, json.JSONDecodeError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"Upload error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                              attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)  # Exponential backoff\n            else:\n                raise RuntimeError(f\"Upload failed after {max_attempts} attempts: {e}\")\n    \n    raise RuntimeError(\"Upload failed, this should not happen\")  # Unreachable\n\n\ndef get_base_filename(json_path: Path) -> str:\n    \"\"\"Extract base filename (without extension) from path.\"\"\"\n    return json_path.stem.replace('slides_', '')  # Remove 'slides_' prefix if present\n\n\ndef process_json_file(json_path: Path, tmp_dir: Path, config_path: Optional[Path], save_local: bool, output_dir: Optional[Path]) -> int:\n    \"\"\"Process a single JSON file and render diagrams.\"\"\"\n    LOGGER.info(\"Processing JSON file: %s\", json_path)\n    \n    # Load JSON data\n    try:\n        slides = json.loads(json_path.read_text())\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON in %s: %s\", json_path, e)\n        return 0\n    \n    # Extract base filename and determine output directory\n    base_filename = get_base_filename(json_path)\n    final_dir = output_dir if output_dir else json_path.parent\n    final_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Process all slides\n    changed = 0\n    for slide in slides:\n        if slide.get(\"diagram_type\") and slide.get(\"diagram_content\"):\n            try:\n                # Render diagram\n                png_path, mmd_path = render_mermaid(\n                    slide[\"diagram_content\"], \n                    tmp_dir, \n                    config_path, \n                    base_filename, \n                    slide[\"slide_number\"]\n                )\n                \n                # Upload to FreeImage\n                url = upload_freeimage(png_path)\n                slide[\"image_url\"] = url\n                changed += 1\n                \n                # Save local copies if requested\n                if save_local:\n                    local_png = final_dir / png_path.name\n                    local_mmd = final_dir / mmd_path.name\n                    \n                    shutil.copy2(png_path, local_png)\n                    shutil.copy2(mmd_path, local_mmd)\n                    LOGGER.info(\"Saved local copies: %s and %s\", local_png.name, local_mmd.name)\n                \n                LOGGER.info(\"Rendered & uploaded diagram for slide %d → %s\", slide[\"slide_number\"], url)\n                \n            except Exception as e:\n                LOGGER.error(\"Diagram for slide %d failed: %s\", slide[\"slide_number\"], e, exc_info=True)\n    \n    # Save updated JSON back\n    if changed > 0:\n        json_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n        LOGGER.info(\"%d diagrams processed; file updated: %s\", changed, json_path)\n    \n    return changed\n\n\ndef process_directory(json_dir: Path, tmp_dir: Path, config_path: Optional[Path], save_local: bool, output_dir: Optional[Path]) -> int:\n    \"\"\"Process all JSON files in a directory.\"\"\"\n    LOGGER.info(\"Processing all JSON files in: %s\", json_dir)\n    \n    # Find all JSON files\n    json_files = list(json_dir.glob(\"*.json\"))\n    if not json_files:\n        LOGGER.error(\"No JSON files found in %s\", json_dir)\n        return 0\n    \n    LOGGER.info(\"Found %d JSON files to process\", len(json_files))\n    \n    # Process each file\n    total_changed = 0\n    for json_path in json_files:\n        try:\n            changed = process_json_file(json_path, tmp_dir, config_path, save_local, output_dir)\n            total_changed += changed\n        except Exception as e:\n            LOGGER.error(\"Failed to process %s: %s\", json_path, e, exc_info=True)\n    \n    return total_changed\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine temporary directory\n    if args.temp_dir:\n        tmp_dir = Path(args.temp_dir)\n    else:\n        tmp_dir = json_path.parent if json_path.is_file() else json_path\n    tmp_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    if output_dir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Check if mermaid config exists\n    config_path = Path(args.mermaid_config)\n    if not config_path.exists():\n        LOGGER.warning(\"Mermaid config file %s not found, using default\", config_path)\n        config_path = None\n    \n    # Process files\n    try:\n        if json_path.is_dir():\n            total_changed = process_directory(json_path, tmp_dir, config_path, args.save_local, output_dir)\n            LOGGER.info(\"Total of %d diagrams processed across all files\", total_changed)\n        else:\n            process_json_file(json_path, tmp_dir, config_path, args.save_local, output_dir)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 3. New `json_to_markdown.py` Script\n\n```python\n#!/usr/bin/env python3\n\"\"\"Convert slides.json to md2gslides compatible markdown files.\n\nThis script converts JSON slide data to markdown format compatible with md2gslides,\nallowing for generation of Google Slides presentations.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys\nfrom pathlib import Path\nfrom typing import Dict, List, Any, Optional\n\nLOGGER = logging.getLogger(\"json_to_markdown\")\n\n# Map of slide layouts to md2gslides format templates\nLAYOUT_TEMPLATES = {\n    \"TITLE\": {\n        \"template\": \"\"\"# {title}\n## {subtitle}\n\"\"\",\n        \"fields\": [\"title\", \"subtitle\"]\n    },\n    \"TITLE_AND_BODY\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"TITLE_AND_TWO_COLUMNS\": {\n        \"template\": \"\"\"# {title}\n\n{left_column}\n\n{{.column}}\n\n{right_column}\n\"\"\",\n        \"fields\": [\"title\", \"left_column\", \"right_column\"]\n    },\n    \"MAIN_POINT\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\"\"\",\n        \"fields\": [\"title\"]\n    },\n    \"SECTION_HEADER\": {\n        \"template\": \"\"\"# {title}\n\"\"\",\n        \"fields\": [\"title\"]\n    },\n    \"BIG_NUMBER\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"CAPTION\": {\n        \"template\": \"\"\"# {title}\n\n![]({image_url})\n\"\"\",\n        \"fields\": [\"title\", \"image_url\"]\n    },\n    \"BLANK\": {\n        \"template\": \"\"\"\n![]({image_url}){{.background}}\n\"\"\",\n        \"fields\": [\"image_url\"]\n    },\n    \"DEFAULT\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    }\n}\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Convert slides.json to md2gslides markdown\")\n    p.add_argument(\"json\", help=\"slides.json file or directory of JSON files\")\n    p.add_argument(\"--output-dir\", default=None, help=\"Output directory for markdown files\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef split_content_into_columns(content: str) -> tuple[str, str]:\n    \"\"\"Split content into two columns based on content length.\"\"\"\n    if not content:\n        return \"\", \"\"\n    \n    lines = content.split('\\n')\n    if len(lines) <= 1:\n        return content, \"\"\n    \n    midpoint = len(lines) // 2\n    left_column = '\\n'.join(lines[:midpoint])\n    right_column = '\\n'.join(lines[midpoint:])\n    \n    return left_column, right_column\n\n\ndef format_slide(slide: Dict[str, Any]) -> str:\n    \"\"\"Format a single slide as markdown based on its layout.\"\"\"\n    # Extract slide data\n    layout = slide.get(\"layout\", \"DEFAULT\")\n    \n    # Get layout template\n    template_info = LAYOUT_TEMPLATES.get(layout, LAYOUT_TEMPLATES[\"DEFAULT\"])\n    template = template_info[\"template\"]\n    \n    # Create data dict for template\n    data = {\n        \"title\": slide.get(\"title\", \"\"),\n        \"subtitle\": slide.get(\"facilitator_notes\", \"\"), # Use facilitator notes as subtitle if needed\n        \"content\": slide.get(\"content\", \"\"),\n        \"image_url\": slide.get(\"image_url\", \"\")\n    }\n    \n    # For two column layouts, split content\n    if layout == \"TITLE_AND_TWO_COLUMNS\":\n        left, right = split_content_into_columns(data[\"content\"])\n        data[\"left_column\"] = left\n        \n        # If there's an image, use it for the right column\n        if data[\"image_url\"]:\n            data[\"right_column\"] = f\"![]({{data['image_url']}})\"\n        else:\n            data[\"right_column\"] = right\n    \n    # Add speaker notes if available\n    notes = slide.get(\"facilitator_notes\", \"\")\n    notes_section = f\"\\n\\n<!--\\n{notes}\\n-->\" if notes else \"\"\n    \n    # Format markdown\n    try:\n        md = template.format(**{k: v for k, v in data.items() if k in template_info[\"fields\"]})\n        return f\"---\\n\\n{md}{notes_section}\\n\"\n    except KeyError as e:\n        LOGGER.warning(f\"Missing field {e} for layout {layout}, using default\")\n        return f\"---\\n\\n# {data['title']}\\n\\n{data['content']}{notes_section}\\n\"\n\n\ndef convert_json_to_markdown(json_path: Path, output_dir: Optional[Path] = None) -> Path:\n    \"\"\"Convert a single JSON file to markdown.\"\"\"\n    LOGGER.info(\"Converting %s to markdown\", json_path)\n    \n    # Load JSON data\n    try:\n        slides = json.loads(json_path.read_text())\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON in %s: %s\", json_path, e)\n        raise\n    \n    # Create markdown\n    md_content = []\n    for slide in slides:\n        md_content.append(format_slide(slide))\n    \n    # Join with newlines\n    markdown = \"\\n\".join(md_content)\n    \n    # Determine output path\n    if output_dir:\n        output_path = output_dir / f\"{json_path.stem.replace('slides_', '')}.md\"\n    else:\n        output_path = json_path.with_suffix(\".md\")\n    \n    # Write markdown file\n    output_path.write_text(markdown)\n    LOGGER.info(\"Wrote markdown to %s\", output_path)\n    \n    return output_path\n\n\ndef process_directory(json_dir: Path, output_dir: Optional[Path] = None) -> List[Path]:\n    \"\"\"Process all JSON files in a directory.\"\"\"\n    LOGGER.info(\"Processing all JSON files in %s\", json_dir)\n    \n    # Find all JSON files\n    json_files = list(json_dir.glob(\"*.json\"))\n    if not json_files:\n        LOGGER.error(\"No JSON files found in %s\", json_dir)\n        return []\n    \n    LOGGER.info(\"Found %d JSON files to process\", len(json_files))\n    \n    # Process each file\n    results = []\n    for json_path in json_files:\n        try:\n            md_path = convert_json_to_markdown(json_path, output_dir)\n            results.append(md_path)\n        except Exception as e:\n            LOGGER.error(\"Failed to convert %s: %s\", json_path, e, exc_info=True)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    if output_dir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Process files\n    try:\n        if json_path.is_dir():\n            md_files = process_directory(json_path, output_dir)\n            LOGGER.info(\"Converted %d JSON files to markdown\", len(md_files))\n        else:\n            convert_json_to_markdown(json_path, output_dir)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 4. New `build_with_md2gslides.py` Script\n\n```python\n#!/usr/bin/env python3\n\"\"\"Create Google Slides presentations using md2gslides.\n\nThis script processes markdown files generated from slides.json and uses\nmd2gslides to create Google Slides presentations.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, logging, os, subprocess, sys\nfrom pathlib import Path\nfrom typing import List, Optional\n\nLOGGER = logging.getLogger(\"build_with_md2gslides\")\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Build Google Slides using md2gslides\")\n    p.add_argument(\"markdown\", help=\"Markdown file or directory of markdown files\")\n    p.add_argument(\"--title-prefix\", default=\"\", help=\"Prefix to add to presentation titles\")\n    p.add_argument(\"--style\", default=\"github\", help=\"Syntax highlighting style for code blocks\")\n    p.add_argument(\"--use-fileio\", action=\"store_true\", help=\"Use file.io for image uploads\")\n    p.add_argument(\"--output-file\", default=None, help=\"File to save presentation IDs to\")\n    p.add_argument(\"--append-id\", default=None, help=\"Append to an existing presentation ID\")\n    p.add_argument(\"--erase\", action=\"store_true\", help=\"Erase existing slides when appending\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef build_slides(md_path: Path, title_prefix: str, style: str, use_fileio: bool, append_id: Optional[str], erase: bool) -> str:\n    \"\"\"Build Google Slides from a markdown file using md2gslides.\"\"\"\n    LOGGER.info(\"Building slides from %s\", md_path)\n    \n    # Determine presentation title\n    title = f\"{title_prefix}{md_path.stem}\" if title_prefix else md_path.stem\n    \n    # Build command\n    cmd = [\"md2gslides\", str(md_path), \"--title\", title, \"--style\", style]\n    \n    if use_fileio:\n        cmd.append(\"--use-fileio\")\n    \n    if append_id:\n        cmd.extend([\"--append\", append_id])\n        if erase:\n            cmd.append(\"--erase\")\n    \n    # Execute command\n    LOGGER.debug(\"Running command: %s\", \" \".join(cmd))\n    try:\n        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n        output = result.stdout\n        \n        # Extract presentation ID from output\n        # Example output: \"Presentation created: https://docs.google.com/presentation/d/1abc123def456/edit\"\n        for line in output.splitlines():\n            if \"https://docs.google.com/presentation/d/\" in line:\n                parts = line.split(\"/\")\n                for i, part in enumerate(parts):\n                    if part == \"d\" and i + 1 < len(parts):\n                        pres_id = parts[i + 1]\n                        LOGGER.info(\"Created presentation: %s (ID: %s)\", line.strip(), pres_id)\n                        return pres_id\n        \n        # If we can't extract ID, return the whole output\n        LOGGER.warning(\"Could not extract presentation ID from output: %s\", output)\n        return output\n        \n    except subprocess.CalledProcessError as e:\n        LOGGER.error(\"Failed to build slides: %s\", e.stderr)\n        raise\n\n\ndef process_directory(md_dir: Path, title_prefix: str, style: str, use_fileio: bool, output_file: Optional[Path], append_id: Optional[str], erase: bool) -> List[str]:\n    \"\"\"Process all markdown files in a directory.\"\"\"\n    LOGGER.info(\"Processing all markdown files in %s\", md_dir)\n    \n    # Find all markdown files\n    md_files = list(md_dir.glob(\"*.md\"))\n    if not md_files:\n        LOGGER.error(\"No markdown files found in %s\", md_dir)\n        return []\n    \n    LOGGER.info(\"Found %d markdown files to process\", len(md_files))\n    \n    # Process each file\n    results = []\n    for md_path in md_files:\n        try:\n            # For directory processing, only use append_id for the first file\n            current_append_id = append_id if append_id and len(results) == 0 else None\n            \n            pres_id = build_slides(md_path, title_prefix, style, use_fileio, current_append_id, erase)\n            results.append(f\"{md_path.name}: {pres_id}\")\n            \n            # If we're appending, use the same ID for subsequent files\n            if append_id and len(results) == 1:\n                append_id = pres_id\n                \n        except Exception as e:\n            LOGGER.error(\"Failed to build slides for %s: %s\", md_path, e, exc_info=True)\n    \n    # Write results to output file if specified\n    if output_file and results:\n        output_file.write_text(\"\\n\".join(results))\n        LOGGER.info(\"Wrote presentation IDs to %s\", output_file)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate inputs\n    md_path = Path(args.markdown)\n    if not md_path.exists():\n        LOGGER.error(\"%s not found\", md_path)\n        sys.exit(1)\n    \n    # Determine output file\n    output_file = Path(args.output_file) if args.output_file else None\n    \n    # Process files\n    try:\n        # Check if md2gslides is installed\n        try:\n            subprocess.run([\"md2gslides\", \"--version\"], capture_output=True, check=True)\n        except (subprocess.SubprocessError, FileNotFoundError):\n            LOGGER.error(\"md2gslides not found. Install with: npm install -g md2gslides\")\n            sys.exit(1)\n        \n        if md_path.is_dir():\n            process_directory(md_path, args.title_prefix, args.style, args.use_fileio, output_file, args.append_id, args.erase)\n        else:\n            pres_id = build_slides(md_path, args.title_prefix, args.style, args.use_fileio, args.append_id, args.erase)\n            if output_file:\n                output_file.write_text(f\"{md_path.name}: {pres_id}\")\n                LOGGER.info(\"Wrote presentation ID to %s\", output_file)\n    \n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 5. Example YAML Configuration File (`config.yaml`)\n\n```yaml\n# Prompt template for guide_to_json.py\nprompt_template: |\n  Please convert the following facilitator guide into a detailed JSON slides outline.\n  \n  For each slide, identify:\n  1. A clear title (max 60 chars)\n  2. Bullet-point content (max 40 words per slide)\n  3. The most appropriate layout from: TITLE, TITLE_AND_BODY, TITLE_AND_TWO_COLUMNS, MAIN_POINT, SECTION_HEADER, BIG_NUMBER, CAPTION, BLANK\n  4. Any diagrams that should be created (using mermaid syntax for flowcharts, mindmaps, or timelines)\n  5. Image descriptions for relevant visuals\n  6. Facilitator notes to help the presenter\n  \n  Return the slides array in valid JSON format with these required fields: slide_number, title, content, layout, chart_type, diagram_type, diagram_content, image_description, image_url, facilitator_notes.\n  \n  Here's the guide content:\n  \n  {{content}}\n\n# Custom layout mappings (from your layout to md2gslides layout)\nlayout_mappings:\n  \"title\": \"TITLE\"\n  \"section\": \"SECTION_HEADER\"\n  \"image\": \"CAPTION\"\n  \"columns\": \"TITLE_AND_TWO_COLUMNS\"\n  \"main_point\": \"MAIN_POINT\"\n  \"big_number\": \"BIG_NUMBER\"\n\n# Default values for all slides\nslide_defaults:\n  \"chart_type\": null\n  \"image_url\": null\n```\n\n## New Workflow\n\nThe updated workflow now follows this pattern:\n\n1. **Guide to JSON**: Convert facilitator guides to JSON format with layout hints\n   ```bash\n   python guide_to_json.py guides/ --config config.yaml --log-level INFO\n   ```\n\n2. **Process Diagrams**: Render Mermaid diagrams and add image URLs\n   ```bash\n   python diagrams_to_images.py guides/ --mermaid-config mermaid-config.json --save-local\n   ```\n\n3. **Convert to Markdown**: Generate md2gslides-compatible markdown from JSON\n   ```bash\n   python json_to_markdown.py guides/ --output-dir markdown/\n   ```\n\n4. **Build Google Slides**: Use md2gslides to create presentations\n   ```bash\n   python build_with_md2gslides.py markdown/ --title-prefix \"Workshop: \" --use-fileio\n   ```\n\nThis workflow gives you several advantages:\n1. **Better layout control**: Specify exactly which slide layout to use\n2. **More robust image handling**: Consistent naming and local storage of diagrams\n3. **Improved Google Slides integration**: md2gslides is purpose-built for Slides\n4. **More flexible formatting**: Full markdown support for rich content\n\nThe `md2gslides` tool handles many edge cases that the Google Slides API can be tricky with, like proper placement of images, text formatting, and speaker notes. This should give you much better results than direct API usage.",
            "citations": []
          }
        ],
        "updated_at": "2025-05-20T09:39:27.033086Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "903d4f39-ddec-4e11-9b68-e30cb873b39f",
      "role": "human",
      "content": "it also looks like we can remove our file uploader and use theirs: **Local images**\nImages referencing local paths temporarily uploaded and hosted to file.io. File.io is an emphemeral file serving service that generates short-lived random URLs to the upload file and deletes content shortly after use.\nSince local images are uploaded to a thrid party, explicit opt-in is required to use this feature. Include the `--use-fileio` option to opt-in to uploading images. This applies to file-based images as well as automatically rasterized content like math expressions and SVGs.\n**Image rasterization**\nSlides can also include generated images, using `$$$` fenced blocks for the data. Currently supported generated images are math expression (TeX and MathML) as well as SVG. Rasterized images are treated like local images are require opt-in to uploading images to a 3rd party service via the `--use-fileio` option.\nUsing TeX:\n\n```\n# How about some math?\n\n$$$ math\n\\cos (2\\theta) = \\cos^2 \\theta - \\sin^2 \\theta\n$$$\n\n```\n\nSVG\n\n```\n# Or some SVG?\n\n$$$ svg\n<svg xmlns=\"http://www.w3.org/2000/svg\"\n     xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n     viewBox=\"0 0 48 48\">\n  <defs>\n    <path id=\"a\" d=\"M44.5 20H24v8.5h11.8C34.7 33.9 30.1 37 24 37c-7.2 0-13-5.8-13-13s5.8-13 13-13c3.1 0 5.9 1.1 8.1 2.9l6.4-6.4C34.6 4.1 29.6 2 24 2 11.8 2 2 11.8 2 24s9.8 22 22 22c11 0 21-8 21-22 0-1.3-.2-2.7-.5-4z\"/>\n  </defs>\n  <clipPath id=\"b\">\n    <use xlink:href=\"#a\" overflow=\"visible\"/>\n  </clipPath>\n  <path clip-path=\"url(#b)\" fill=\"#EA4335\" d=\"M0 11l17 13 7-6.1L48 14V0H0z\"/>\n  <path clip-path=\"url(#b)\" fill=\"#34A853\" d=\"M0 37l30-23 7.9 1L48 0v48H0z\"/>\n  <path clip-path=\"url(#b)\" fill=\"#4285F4\" d=\"M48 48L17 24l-4-3 35-10z\"/>\n</svg>\n$$$\n\n```\n\nLike local images, generated images are temporarily served via file.io.\nPull requests for other image generators (e.g. mermaid, chartjs, etc.) are welcome!\n\nMaybe even SVGs for things out of the scope of mermaid? \n\nHere are all my files, review and update whatever is missing is there a simple shell script i can use that will run through them all one after the other with something like ./magicSlide.sh and then a .md or .txt file and it will run it and output it in the same folder?\n\nAlso give me the commands for running it on a folder with args",
      "created_at": "2025-05-20T09:48:19.080020Z",
      "sequence_order": 6,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-20T09:48:19.071877Z",
            "stop_timestamp": "2025-05-20T09:48:19.071877Z",
            "flags": null,
            "type": "text",
            "text": "it also looks like we can remove our file uploader and use theirs: **Local images**\nImages referencing local paths temporarily uploaded and hosted to file.io. File.io is an emphemeral file serving service that generates short-lived random URLs to the upload file and deletes content shortly after use.\nSince local images are uploaded to a thrid party, explicit opt-in is required to use this feature. Include the `--use-fileio` option to opt-in to uploading images. This applies to file-based images as well as automatically rasterized content like math expressions and SVGs.\n**Image rasterization**\nSlides can also include generated images, using `$$$` fenced blocks for the data. Currently supported generated images are math expression (TeX and MathML) as well as SVG. Rasterized images are treated like local images are require opt-in to uploading images to a 3rd party service via the `--use-fileio` option.\nUsing TeX:\n\n```\n# How about some math?\n\n$$$ math\n\\cos (2\\theta) = \\cos^2 \\theta - \\sin^2 \\theta\n$$$\n\n```\n\nSVG\n\n```\n# Or some SVG?\n\n$$$ svg\n<svg xmlns=\"http://www.w3.org/2000/svg\"\n     xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n     viewBox=\"0 0 48 48\">\n  <defs>\n    <path id=\"a\" d=\"M44.5 20H24v8.5h11.8C34.7 33.9 30.1 37 24 37c-7.2 0-13-5.8-13-13s5.8-13 13-13c3.1 0 5.9 1.1 8.1 2.9l6.4-6.4C34.6 4.1 29.6 2 24 2 11.8 2 2 11.8 2 24s9.8 22 22 22c11 0 21-8 21-22 0-1.3-.2-2.7-.5-4z\"/>\n  </defs>\n  <clipPath id=\"b\">\n    <use xlink:href=\"#a\" overflow=\"visible\"/>\n  </clipPath>\n  <path clip-path=\"url(#b)\" fill=\"#EA4335\" d=\"M0 11l17 13 7-6.1L48 14V0H0z\"/>\n  <path clip-path=\"url(#b)\" fill=\"#34A853\" d=\"M0 37l30-23 7.9 1L48 0v48H0z\"/>\n  <path clip-path=\"url(#b)\" fill=\"#4285F4\" d=\"M48 48L17 24l-4-3 35-10z\"/>\n</svg>\n$$$\n\n```\n\nLike local images, generated images are temporarily served via file.io.\nPull requests for other image generators (e.g. mermaid, chartjs, etc.) are welcome!\n\nMaybe even SVGs for things out of the scope of mermaid? \n\nHere are all my files, review and update whatever is missing is there a simple shell script i can use that will run through them all one after the other with something like ./magicSlide.sh and then a .md or .txt file and it will run it and output it in the same folder?\n\nAlso give me the commands for running it on a folder with args",
            "citations": []
          }
        ],
        "updated_at": "2025-05-20T09:48:19.080020Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "8f52296e-3624-44be-a8a0-27b989d41e2b",
      "role": "assistant",
      "content": "Let's analyze what's needed to update the scripts to take advantage of md2gslides' built-in image handling and create a simple shell script to run the entire workflow.\n\n1. Updates needed to existing scripts:\n   - We can simplify `diagrams_to_images.py` to just save local diagram files without needing to upload to freeimage.host\n   - We should update `json_to_markdown.py` to properly reference local image paths\n   - We should ensure that all generated diagrams are put in a format that md2gslides can use\n\n2. Shell script requirements:\n   - Take a markdown/text file as input\n   - Run through all steps in the pipeline\n   - Output in the same folder\n   - Support processing folders\n   - Use reasonable defaults but allow overrides\n\nLet's start by making updates to `diagrams_to_images.py` to generate local files without relying on external image hosting:You're right - we can simplify our workflow by taking advantage of md2gslides' built-in handling for local images, SVGs, and other content. Let me update the relevant scripts and create a shell script that ties everything together.\n\n## 1. Updated `diagrams_to_images.py` (Simplified for Local Files)\n\n```python\n#!/usr/bin/env python3\n\"\"\"Render Mermaid diagrams to local image files.\n\nSaves diagrams locally and updates the slides.json with relative file paths\ninstead of using external image hosting.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, subprocess, sys, time\nfrom pathlib import Path\nfrom typing import Any, List, Optional, Tuple\n\nLOGGER = logging.getLogger(\"diagrams_to_images\")\nMERMAID_CMD = \"mmdc\"  # must be on PATH\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Render Mermaid diagrams to local files\")\n    p.add_argument(\"json\", help=\"slides.json to update (in-place) or directory of JSON files\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    p.add_argument(\"--output-dir\", default=None, help=\"Directory to save image files (default: same as slides.json)\")\n    p.add_argument(\"--mermaid-config\", default=\"mermaid-config.json\", help=\"Mermaid configuration file\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef render_mermaid(src: str, output_dir: Path, config_path: Optional[Path], base_filename: str, slide_num: int) -> Path:\n    \"\"\"Render mermaid diagram to PNG.\n    \n    Args:\n        src: Mermaid diagram content\n        output_dir: Directory to save files\n        config_path: Path to mermaid config file\n        base_filename: Base filename (from guide file)\n        slide_num: Slide number\n        \n    Returns:\n        Path to the generated PNG file\n    \"\"\"\n    # Create filenames based on guide name and slide number\n    output_name = f\"{base_filename}_slide{slide_num}\"\n    mmd = output_dir / f\"{output_name}.mmd\"\n    png = output_dir / f\"{output_name}.png\"\n    \n    # Also create SVG version (md2gslides can use SVG directly)\n    svg = output_dir / f\"{output_name}.svg\"\n    \n    # Write mermaid content to file\n    mmd.write_text(src, encoding=\"utf-8\")\n    \n    # Build command with optional config\n    cmd = [MERMAID_CMD, \"-i\", mmd, \"-o\", png, \"-b\", \"transparent\"]\n    if config_path and config_path.exists():\n        cmd.extend([\"-c\", config_path])\n    \n    # Also generate SVG with another command\n    svg_cmd = [MERMAID_CMD, \"-i\", mmd, \"-o\", svg, \"-b\", \"transparent\", \"-t\", \"svg\"]\n    if config_path and config_path.exists():\n        svg_cmd.extend([\"-c\", config_path])\n    \n    LOGGER.debug(\"Running command: %s\", \" \".join(str(x) for x in cmd))\n    \n    # Execute command with retry\n    for attempt in range(3):\n        try:\n            subprocess.run(cmd, check=True, capture_output=True)\n            if png.exists() and png.stat().st_size > 0:\n                # Also generate SVG\n                subprocess.run(svg_cmd, check=True, capture_output=True)\n                return png\n            \n            if attempt < 2:  # Only log warning for first two attempts\n                LOGGER.warning(\"Empty output from mermaid-cli, retrying in 2s...\")\n                time.sleep(2)\n        except subprocess.CalledProcessError as e:\n            if attempt < 2:  # Only log error for first two attempts\n                LOGGER.warning(\"mermaid-cli error (attempt %d/3): %s\", attempt + 1, e.stderr.decode())\n                time.sleep(2)\n    \n    # If we got here, all attempts failed\n    raise RuntimeError(f\"Failed to render mermaid diagram after 3 attempts for slide {slide_num}\")\n\n\ndef get_base_filename(json_path: Path) -> str:\n    \"\"\"Extract base filename (without extension) from path.\"\"\"\n    return json_path.stem.replace('slides_', '')  # Remove 'slides_' prefix if present\n\n\ndef process_json_file(json_path: Path, output_dir: Optional[Path], config_path: Optional[Path]) -> int:\n    \"\"\"Process a single JSON file and render diagrams.\n    \n    Returns:\n        Number of diagrams processed\n    \"\"\"\n    LOGGER.info(\"Processing JSON file: %s\", json_path)\n    \n    # Load JSON data\n    try:\n        slides = json.loads(json_path.read_text())\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON in %s: %s\", json_path, e)\n        return 0\n    \n    # Extract base filename\n    base_filename = get_base_filename(json_path)\n    \n    # Determine output directory\n    if output_dir:\n        diagram_dir = output_dir\n    else:\n        diagram_dir = json_path.parent / \"images\"\n    \n    # Create output directory if it doesn't exist\n    diagram_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Process all slides\n    changed = 0\n    for slide in slides:\n        if slide.get(\"diagram_type\") and slide.get(\"diagram_content\"):\n            try:\n                # Render diagram\n                png_path = render_mermaid(\n                    slide[\"diagram_content\"], \n                    diagram_dir, \n                    config_path, \n                    base_filename, \n                    slide[\"slide_number\"]\n                )\n                \n                # Update JSON with relative path\n                rel_path = png_path.relative_to(json_path.parent)\n                slide[\"image_url\"] = str(rel_path)\n                changed += 1\n                \n                LOGGER.info(\"Rendered diagram for slide %d → %s\", slide[\"slide_number\"], rel_path)\n                \n            except Exception as e:\n                LOGGER.error(\"Diagram for slide %d failed: %s\", slide[\"slide_number\"], e, exc_info=True)\n    \n    # Save updated JSON back\n    if changed > 0:\n        json_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n        LOGGER.info(\"%d diagrams processed; file updated: %s\", changed, json_path)\n    \n    return changed\n\n\ndef process_directory(json_dir: Path, output_dir: Optional[Path], config_path: Optional[Path]) -> int:\n    \"\"\"Process all JSON files in a directory.\"\"\"\n    LOGGER.info(\"Processing all JSON files in: %s\", json_dir)\n    \n    # Find all JSON files\n    json_files = list(json_dir.glob(\"slides_*.json\"))\n    if not json_files:\n        LOGGER.error(\"No slide JSON files found in %s\", json_dir)\n        return 0\n    \n    LOGGER.info(\"Found %d JSON files to process\", len(json_files))\n    \n    # Process each file\n    total_changed = 0\n    for json_path in json_files:\n        try:\n            # For directory processing, create subdirectory for each file's images\n            if output_dir:\n                file_output_dir = output_dir\n            else:\n                file_output_dir = json_dir / \"images\" / json_path.stem\n                file_output_dir.mkdir(parents=True, exist_ok=True)\n                \n            changed = process_json_file(json_path, file_output_dir, config_path)\n            total_changed += changed\n        except Exception as e:\n            LOGGER.error(\"Failed to process %s: %s\", json_path, e, exc_info=True)\n    \n    return total_changed\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    if output_dir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Check if mermaid config exists\n    config_path = Path(args.mermaid_config)\n    if not config_path.exists():\n        LOGGER.warning(\"Mermaid config file %s not found, using default\", config_path)\n        config_path = None\n    \n    # Process files\n    try:\n        if json_path.is_dir():\n            total_changed = process_directory(json_path, output_dir, config_path)\n            LOGGER.info(\"Total of %d diagrams processed across all files\", total_changed)\n        else:\n            process_json_file(json_path, output_dir, config_path)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 2. Updated `json_to_markdown.py` with SVG Support\n\n```python\n#!/usr/bin/env python3\n\"\"\"Convert slides.json to md2gslides compatible markdown files.\n\nThis script converts JSON slide data to markdown format compatible with md2gslides,\nallowing for generation of Google Slides presentations.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys\nfrom pathlib import Path\nfrom typing import Dict, List, Any, Optional\n\nLOGGER = logging.getLogger(\"json_to_markdown\")\n\n# Map of slide layouts to md2gslides format templates\nLAYOUT_TEMPLATES = {\n    \"TITLE\": {\n        \"template\": \"\"\"# {title}\n## {subtitle}\n\"\"\",\n        \"fields\": [\"title\", \"subtitle\"]\n    },\n    \"TITLE_AND_BODY\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"TITLE_AND_TWO_COLUMNS\": {\n        \"template\": \"\"\"# {title}\n\n{left_column}\n\n{{.column}}\n\n{right_column}\n\"\"\",\n        \"fields\": [\"title\", \"left_column\", \"right_column\"]\n    },\n    \"MAIN_POINT\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\"\"\",\n        \"fields\": [\"title\"]\n    },\n    \"SECTION_HEADER\": {\n        \"template\": \"\"\"# {title}\n\"\"\",\n        \"fields\": [\"title\"]\n    },\n    \"BIG_NUMBER\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"CAPTION\": {\n        \"template\": \"\"\"# {title}\n\n![]({image_url})\n\"\"\",\n        \"fields\": [\"title\", \"image_url\"]\n    },\n    \"BLANK\": {\n        \"template\": \"\"\"\n![]({image_url}){{.background}}\n\"\"\",\n        \"fields\": [\"image_url\"]\n    },\n    \"DEFAULT\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    }\n}\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Convert slides.json to md2gslides markdown\")\n    p.add_argument(\"json\", help=\"slides.json file or directory of JSON files\")\n    p.add_argument(\"--output-dir\", default=None, help=\"Output directory for markdown files\")\n    p.add_argument(\"--prefer-svg\", action=\"store_true\", help=\"Prefer SVG over PNG for diagrams\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef split_content_into_columns(content: str) -> tuple[str, str]:\n    \"\"\"Split content into two columns based on content length.\"\"\"\n    if not content:\n        return \"\", \"\"\n    \n    lines = content.split('\\n')\n    if len(lines) <= 1:\n        return content, \"\"\n    \n    midpoint = len(lines) // 2\n    left_column = '\\n'.join(lines[:midpoint])\n    right_column = '\\n'.join(lines[midpoint:])\n    \n    return left_column, right_column\n\n\ndef convert_to_svg_block(image_path: str, slide_num: int) -> str:\n    \"\"\"Convert image path to SVG block if it's an SVG file.\"\"\"\n    path = Path(image_path)\n    if path.suffix.lower() == '.svg' and path.exists():\n        try:\n            svg_content = path.read_text(encoding='utf-8')\n            return f\"\\n$$$ svg\\n{svg_content}\\n$$$\\n\"\n        except Exception as e:\n            LOGGER.warning(f\"Failed to read SVG file {path}: {e}\")\n            return f\"![](${image_path})\"\n    return f\"![](${image_path})\"\n\n\ndef format_slide(slide: Dict[str, Any], prefer_svg: bool = False) -> str:\n    \"\"\"Format a single slide as markdown based on its layout.\"\"\"\n    # Extract slide data\n    layout = slide.get(\"layout\", \"DEFAULT\")\n    \n    # Get layout template\n    template_info = LAYOUT_TEMPLATES.get(layout, LAYOUT_TEMPLATES[\"DEFAULT\"])\n    template = template_info[\"template\"]\n    \n    # Handle image URL\n    image_url = slide.get(\"image_url\", \"\")\n    if image_url:\n        # Check if there's an SVG version of the image\n        if prefer_svg and image_url.lower().endswith('.png'):\n            svg_path = image_url[:-4] + '.svg'\n            svg_path_obj = Path(svg_path)\n            if svg_path_obj.exists():\n                # Use SVG block instead of image reference\n                svg_content = svg_path_obj.read_text(encoding='utf-8')\n                image_block = f\"\\n$$$ svg\\n{svg_content}\\n$$$\\n\"\n            else:\n                image_block = f\"![]({image_url})\"\n        else:\n            image_block = f\"![]({image_url})\"\n    else:\n        image_block = \"\"\n    \n    # Create data dict for template\n    data = {\n        \"title\": slide.get(\"title\", \"\"),\n        \"subtitle\": slide.get(\"subtitle\", \"\"),\n        \"content\": slide.get(\"content\", \"\"),\n        \"image_url\": image_url\n    }\n    \n    # For two column layouts, split content and handle images\n    if layout == \"TITLE_AND_TWO_COLUMNS\":\n        left, right = split_content_into_columns(data[\"content\"])\n        data[\"left_column\"] = left\n        \n        # If there's an image, use it for the right column\n        if image_url:\n            if prefer_svg and image_url.lower().endswith('.png'):\n                svg_path = image_url[:-4] + '.svg'\n                svg_path_obj = Path(svg_path)\n                if svg_path_obj.exists():\n                    # Use SVG block instead of image reference\n                    svg_content = svg_path_obj.read_text(encoding='utf-8')\n                    data[\"right_column\"] = f\"\\n$$$ svg\\n{svg_content}\\n$$$\\n\"\n                else:\n                    data[\"right_column\"] = f\"![]({image_url})\"\n            else:\n                data[\"right_column\"] = f\"![]({image_url})\"\n        else:\n            data[\"right_column\"] = right\n    \n    # Add speaker notes if available\n    notes = slide.get(\"facilitator_notes\", \"\")\n    notes_section = f\"\\n\\n<!--\\n{notes}\\n-->\" if notes else \"\"\n    \n    # Format markdown\n    try:\n        md = template.format(**{k: v for k, v in data.items() if k in template_info[\"fields\"]})\n        return f\"---\\n\\n{md}{notes_section}\\n\"\n    except KeyError as e:\n        LOGGER.warning(f\"Missing field {e} for layout {layout}, using default\")\n        return f\"---\\n\\n# {data['title']}\\n\\n{data['content']}{notes_section}\\n\"\n\n\ndef convert_json_to_markdown(json_path: Path, output_dir: Optional[Path] = None, prefer_svg: bool = False) -> Path:\n    \"\"\"Convert a single JSON file to markdown.\"\"\"\n    LOGGER.info(\"Converting %s to markdown\", json_path)\n    \n    # Load JSON data\n    try:\n        slides = json.loads(json_path.read_text())\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON in %s: %s\", json_path, e)\n        raise\n    \n    # Create markdown\n    md_content = []\n    for slide in slides:\n        md_content.append(format_slide(slide, prefer_svg))\n    \n    # Join with newlines\n    markdown = \"\\n\".join(md_content)\n    \n    # Determine output path\n    if output_dir:\n        output_path = output_dir / f\"{json_path.stem.replace('slides_', '')}.md\"\n    else:\n        output_path = json_path.with_suffix(\".md\")\n    \n    # Write markdown file\n    output_path.write_text(markdown)\n    LOGGER.info(\"Wrote markdown to %s\", output_path)\n    \n    return output_path\n\n\ndef process_directory(json_dir: Path, output_dir: Optional[Path] = None, prefer_svg: bool = False) -> List[Path]:\n    \"\"\"Process all JSON files in a directory.\"\"\"\n    LOGGER.info(\"Processing all JSON files in %s\", json_dir)\n    \n    # Find all JSON files\n    json_files = list(json_dir.glob(\"slides_*.json\"))\n    if not json_files:\n        LOGGER.error(\"No slide JSON files found in %s\", json_dir)\n        return []\n    \n    LOGGER.info(\"Found %d JSON files to process\", len(json_files))\n    \n    # Process each file\n    results = []\n    for json_path in json_files:\n        try:\n            md_path = convert_json_to_markdown(json_path, output_dir, prefer_svg)\n            results.append(md_path)\n        except Exception as e:\n            LOGGER.error(\"Failed to convert %s: %s\", json_path, e, exc_info=True)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    if output_dir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Process files\n    try:\n        if json_path.is_dir():\n            md_files = process_directory(json_path, output_dir, args.prefer_svg)\n            LOGGER.info(\"Converted %d JSON files to markdown\", len(md_files))\n        else:\n            convert_json_to_markdown(json_path, output_dir, args.prefer_svg)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 3. `magicSlide.sh` - One-Click Bash Script\n\n```bash\n#!/bin/bash\n# magicSlide.sh - One-click slide generation from facilitator guides\n# Usage: ./magicSlide.sh input.md [options]\n#        ./magicSlide.sh directory/ [options]\n\nset -e  # Exit on error\n\n# Default options\nCONFIG=\"config.yaml\"\nMERMAID_CONFIG=\"mermaid-config.json\"\nLOG_LEVEL=\"INFO\"\nTITLE_PREFIX=\"\"\nSTYLE=\"github\"\nUSE_FILEIO=1\nCLAUDE_MODEL=\"claude-3-7-sonnet-20250219\"\n\n# Functions\nprint_usage() {\n  echo \"Usage: $0 <input.md or directory> [options]\"\n  echo \"Options:\"\n  echo \"  --config=FILE         YAML config file (default: config.yaml)\"\n  echo \"  --mermaid-config=FILE Mermaid config file (default: mermaid-config.json)\"\n  echo \"  --no-fileio           Don't use file.io for image uploads\"\n  echo \"  --title-prefix=TEXT   Add prefix to presentation titles\"\n  echo \"  --style=STYLE         Code highlighting style (default: github)\"\n  echo \"  --model=MODEL         Claude model (default: claude-3-7-sonnet-20250219)\"\n  echo \"  --log-level=LEVEL     Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)\"\n  echo \"  --help                Show this help message\"\n}\n\n# Parse arguments\nINPUT=\"\"\nfor arg in \"$@\"; do\n  case $arg in\n    --config=*)\n      CONFIG=\"${arg#*=}\"\n      ;;\n    --mermaid-config=*)\n      MERMAID_CONFIG=\"${arg#*=}\"\n      ;;\n    --no-fileio)\n      USE_FILEIO=0\n      ;;\n    --title-prefix=*)\n      TITLE_PREFIX=\"${arg#*=}\"\n      ;;\n    --style=*)\n      STYLE=\"${arg#*=}\"\n      ;;\n    --model=*)\n      CLAUDE_MODEL=\"${arg#*=}\"\n      ;;\n    --log-level=*)\n      LOG_LEVEL=\"${arg#*=}\"\n      ;;\n    --help)\n      print_usage\n      exit 0\n      ;;\n    -*)\n      echo \"Unknown option: $arg\"\n      print_usage\n      exit 1\n      ;;\n    *)\n      if [ -z \"$INPUT\" ]; then\n        INPUT=\"$arg\"\n      else\n        echo \"Multiple input files specified. Use only one.\"\n        print_usage\n        exit 1\n      fi\n      ;;\n  esac\ndone\n\n# Check for required input\nif [ -z \"$INPUT\" ]; then\n  echo \"Error: No input file or directory specified.\"\n  print_usage\n  exit 1\nfi\n\n# Determine input type\nif [ -d \"$INPUT\" ]; then\n  # Directory mode\n  echo \"🔍 Processing directory: $INPUT\"\n  WORKING_DIR=\"$INPUT\"\n  DIR_MODE=1\nelse\n  # Single file mode\n  echo \"🔍 Processing file: $INPUT\"\n  WORKING_DIR=\"$(dirname \"$INPUT\")\"\n  BASENAME=\"$(basename \"$INPUT\" .md)\"\n  BASENAME=\"${BASENAME%.txt}\"  # Also strip .txt if present\n  DIR_MODE=0\nfi\n\n# Create/verify necessary directories\nIMAGES_DIR=\"$WORKING_DIR/images\"\nmkdir -p \"$IMAGES_DIR\"\n\necho \"Step 1/4: 🧠 Converting to JSON with Claude...\"\nif [ $DIR_MODE -eq 1 ]; then\n  python guide_to_json.py \"$INPUT\" --config=\"$CONFIG\" --model=\"$CLAUDE_MODEL\" --log-level=\"$LOG_LEVEL\"\nelse\n  JSON_FILE=\"$WORKING_DIR/slides_$BASENAME.json\"\n  python guide_to_json.py \"$INPUT\" --config=\"$CONFIG\" --out=\"$JSON_FILE\" --model=\"$CLAUDE_MODEL\" --log-level=\"$LOG_LEVEL\"\nfi\n\necho \"Step 2/4: 📊 Rendering diagrams...\"\nif [ $DIR_MODE -eq 1 ]; then\n  python diagrams_to_images.py \"$INPUT\" --mermaid-config=\"$MERMAID_CONFIG\" --output-dir=\"$IMAGES_DIR\" --log-level=\"$LOG_LEVEL\"\nelse\n  python diagrams_to_images.py \"$JSON_FILE\" --mermaid-config=\"$MERMAID_CONFIG\" --output-dir=\"$IMAGES_DIR\" --log-level=\"$LOG_LEVEL\"\nfi\n\necho \"Step 3/4: 📝 Converting to markdown...\"\nif [ $DIR_MODE -eq 1 ]; then\n  python json_to_markdown.py \"$INPUT\" --prefer-svg --log-level=\"$LOG_LEVEL\"\nelse\n  python json_to_markdown.py \"$JSON_FILE\" --prefer-svg --log-level=\"$LOG_LEVEL\"\nfi\n\necho \"Step 4/4: 🎯 Generating Google Slides...\"\nFILEIO_ARG=\"\"\nif [ $USE_FILEIO -eq 1 ]; then\n  FILEIO_ARG=\"--use-fileio\"\nfi\n\nif [ $DIR_MODE -eq 1 ]; then\n  python build_with_md2gslides.py \"$INPUT\" --title-prefix=\"$TITLE_PREFIX\" --style=\"$STYLE\" $FILEIO_ARG --log-level=\"$LOG_LEVEL\" --output-file=\"$WORKING_DIR/presentations.txt\"\nelse\n  MD_FILE=\"$WORKING_DIR/$BASENAME.md\"\n  python build_with_md2gslides.py \"$MD_FILE\" --title-prefix=\"$TITLE_PREFIX\" --style=\"$STYLE\" $FILEIO_ARG --log-level=\"$LOG_LEVEL\" --output-file=\"$WORKING_DIR/$BASENAME-presentation.txt\"\nfi\n\necho \"✅ All done! Your slides are ready.\"\necho \"📋 Presentation links saved to the output text file.\"\n```\n\n## Command Examples\n\nHere are sample commands for using the system with different scenarios:\n\n### Process a single file\n```bash\n# Basic usage\n./magicSlide.sh workshop.md\n\n# With options\n./magicSlide.sh workshop.md --title-prefix=\"Workshop: \" --style=\"monokai\" --model=\"claude-3-7-sonnet-20250219\"\n```\n\n### Process a directory\n```bash\n# Process all markdown files in a directory\n./magicSlide.sh guides/\n\n# With options\n./magicSlide.sh guides/ --config=my-custom-config.yaml --mermaid-config=dark-theme.json --no-fileio\n```\n\n### Using individual scripts\n```bash\n# Step 1: Convert guide to JSON\npython guide_to_json.py workshop.md --config=config.yaml\n\n# Step 2: Render diagrams\npython diagrams_to_images.py slides_workshop.json --mermaid-config=mermaid-config.json --output-dir=images\n\n# Step 3: Convert to markdown\npython json_to_markdown.py slides_workshop.json --prefer-svg\n\n# Step 4: Generate Google Slides\npython build_with_md2gslides.py workshop.md --title-prefix=\"Workshop: \" --style=\"github\" --use-fileio\n```\n\n## Key Improvements\n\n1. **Simplified Image Handling**: Now saves SVG files alongside PNGs, with md2gslides handling the image uploads\n\n2. **Cleaner Directory Structure**: Images are organized in an \"images\" folder with clear naming conventions\n\n3. **SVG Support**: Directly embeds SVG content using md2gslides' `$$$ svg` blocks for better quality\n\n4. **One-Click Script**: `magicSlide.sh` provides a simple way to run the entire pipeline with sensible defaults\n\n5. **Customizable Options**: All scripts accept various options to customize the output\n\n6. **Better Layout Control**: The YAML config file allows for custom layout mappings to ensure slides look good\n\nWith these updates, you should have a more robust, flexible, and user-friendly slide generation system that takes advantage of md2gslides' built-in features for handling local images, SVGs, and math expressions.",
      "created_at": "2025-05-20T09:50:11.981683Z",
      "sequence_order": 7,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-20T09:48:21.350730Z",
            "stop_timestamp": "2025-05-20T09:48:24.913035Z",
            "flags": null,
            "type": "thinking",
            "thinking": "Let's analyze what's needed to update the scripts to take advantage of md2gslides' built-in image handling and create a simple shell script to run the entire workflow.\n\n1. Updates needed to existing scripts:\n   - We can simplify `diagrams_to_images.py` to just save local diagram files without needing to upload to freeimage.host\n   - We should update `json_to_markdown.py` to properly reference local image paths\n   - We should ensure that all generated diagrams are put in a format that md2gslides can use\n\n2. Shell script requirements:\n   - Take a markdown/text file as input\n   - Run through all steps in the pipeline\n   - Output in the same folder\n   - Support processing folders\n   - Use reasonable defaults but allow overrides\n\nLet's start by making updates to `diagrams_to_images.py` to generate local files without relying on external image hosting:",
            "summaries": [
              {
                "summary": "Simplifying scripts for md2gslides image handling workflow"
              },
              {
                "summary": "Engineered workflow for markdown-to-slides conversion with local images"
              }
            ],
            "cut_off": false
          },
          {
            "start_timestamp": "2025-05-20T09:48:25.357847Z",
            "stop_timestamp": "2025-05-20T09:50:10.742237Z",
            "flags": null,
            "type": "text",
            "text": "You're right - we can simplify our workflow by taking advantage of md2gslides' built-in handling for local images, SVGs, and other content. Let me update the relevant scripts and create a shell script that ties everything together.\n\n## 1. Updated `diagrams_to_images.py` (Simplified for Local Files)\n\n```python\n#!/usr/bin/env python3\n\"\"\"Render Mermaid diagrams to local image files.\n\nSaves diagrams locally and updates the slides.json with relative file paths\ninstead of using external image hosting.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, subprocess, sys, time\nfrom pathlib import Path\nfrom typing import Any, List, Optional, Tuple\n\nLOGGER = logging.getLogger(\"diagrams_to_images\")\nMERMAID_CMD = \"mmdc\"  # must be on PATH\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Render Mermaid diagrams to local files\")\n    p.add_argument(\"json\", help=\"slides.json to update (in-place) or directory of JSON files\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    p.add_argument(\"--output-dir\", default=None, help=\"Directory to save image files (default: same as slides.json)\")\n    p.add_argument(\"--mermaid-config\", default=\"mermaid-config.json\", help=\"Mermaid configuration file\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef render_mermaid(src: str, output_dir: Path, config_path: Optional[Path], base_filename: str, slide_num: int) -> Path:\n    \"\"\"Render mermaid diagram to PNG.\n    \n    Args:\n        src: Mermaid diagram content\n        output_dir: Directory to save files\n        config_path: Path to mermaid config file\n        base_filename: Base filename (from guide file)\n        slide_num: Slide number\n        \n    Returns:\n        Path to the generated PNG file\n    \"\"\"\n    # Create filenames based on guide name and slide number\n    output_name = f\"{base_filename}_slide{slide_num}\"\n    mmd = output_dir / f\"{output_name}.mmd\"\n    png = output_dir / f\"{output_name}.png\"\n    \n    # Also create SVG version (md2gslides can use SVG directly)\n    svg = output_dir / f\"{output_name}.svg\"\n    \n    # Write mermaid content to file\n    mmd.write_text(src, encoding=\"utf-8\")\n    \n    # Build command with optional config\n    cmd = [MERMAID_CMD, \"-i\", mmd, \"-o\", png, \"-b\", \"transparent\"]\n    if config_path and config_path.exists():\n        cmd.extend([\"-c\", config_path])\n    \n    # Also generate SVG with another command\n    svg_cmd = [MERMAID_CMD, \"-i\", mmd, \"-o\", svg, \"-b\", \"transparent\", \"-t\", \"svg\"]\n    if config_path and config_path.exists():\n        svg_cmd.extend([\"-c\", config_path])\n    \n    LOGGER.debug(\"Running command: %s\", \" \".join(str(x) for x in cmd))\n    \n    # Execute command with retry\n    for attempt in range(3):\n        try:\n            subprocess.run(cmd, check=True, capture_output=True)\n            if png.exists() and png.stat().st_size > 0:\n                # Also generate SVG\n                subprocess.run(svg_cmd, check=True, capture_output=True)\n                return png\n            \n            if attempt < 2:  # Only log warning for first two attempts\n                LOGGER.warning(\"Empty output from mermaid-cli, retrying in 2s...\")\n                time.sleep(2)\n        except subprocess.CalledProcessError as e:\n            if attempt < 2:  # Only log error for first two attempts\n                LOGGER.warning(\"mermaid-cli error (attempt %d/3): %s\", attempt + 1, e.stderr.decode())\n                time.sleep(2)\n    \n    # If we got here, all attempts failed\n    raise RuntimeError(f\"Failed to render mermaid diagram after 3 attempts for slide {slide_num}\")\n\n\ndef get_base_filename(json_path: Path) -> str:\n    \"\"\"Extract base filename (without extension) from path.\"\"\"\n    return json_path.stem.replace('slides_', '')  # Remove 'slides_' prefix if present\n\n\ndef process_json_file(json_path: Path, output_dir: Optional[Path], config_path: Optional[Path]) -> int:\n    \"\"\"Process a single JSON file and render diagrams.\n    \n    Returns:\n        Number of diagrams processed\n    \"\"\"\n    LOGGER.info(\"Processing JSON file: %s\", json_path)\n    \n    # Load JSON data\n    try:\n        slides = json.loads(json_path.read_text())\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON in %s: %s\", json_path, e)\n        return 0\n    \n    # Extract base filename\n    base_filename = get_base_filename(json_path)\n    \n    # Determine output directory\n    if output_dir:\n        diagram_dir = output_dir\n    else:\n        diagram_dir = json_path.parent / \"images\"\n    \n    # Create output directory if it doesn't exist\n    diagram_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Process all slides\n    changed = 0\n    for slide in slides:\n        if slide.get(\"diagram_type\") and slide.get(\"diagram_content\"):\n            try:\n                # Render diagram\n                png_path = render_mermaid(\n                    slide[\"diagram_content\"], \n                    diagram_dir, \n                    config_path, \n                    base_filename, \n                    slide[\"slide_number\"]\n                )\n                \n                # Update JSON with relative path\n                rel_path = png_path.relative_to(json_path.parent)\n                slide[\"image_url\"] = str(rel_path)\n                changed += 1\n                \n                LOGGER.info(\"Rendered diagram for slide %d → %s\", slide[\"slide_number\"], rel_path)\n                \n            except Exception as e:\n                LOGGER.error(\"Diagram for slide %d failed: %s\", slide[\"slide_number\"], e, exc_info=True)\n    \n    # Save updated JSON back\n    if changed > 0:\n        json_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n        LOGGER.info(\"%d diagrams processed; file updated: %s\", changed, json_path)\n    \n    return changed\n\n\ndef process_directory(json_dir: Path, output_dir: Optional[Path], config_path: Optional[Path]) -> int:\n    \"\"\"Process all JSON files in a directory.\"\"\"\n    LOGGER.info(\"Processing all JSON files in: %s\", json_dir)\n    \n    # Find all JSON files\n    json_files = list(json_dir.glob(\"slides_*.json\"))\n    if not json_files:\n        LOGGER.error(\"No slide JSON files found in %s\", json_dir)\n        return 0\n    \n    LOGGER.info(\"Found %d JSON files to process\", len(json_files))\n    \n    # Process each file\n    total_changed = 0\n    for json_path in json_files:\n        try:\n            # For directory processing, create subdirectory for each file's images\n            if output_dir:\n                file_output_dir = output_dir\n            else:\n                file_output_dir = json_dir / \"images\" / json_path.stem\n                file_output_dir.mkdir(parents=True, exist_ok=True)\n                \n            changed = process_json_file(json_path, file_output_dir, config_path)\n            total_changed += changed\n        except Exception as e:\n            LOGGER.error(\"Failed to process %s: %s\", json_path, e, exc_info=True)\n    \n    return total_changed\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    if output_dir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Check if mermaid config exists\n    config_path = Path(args.mermaid_config)\n    if not config_path.exists():\n        LOGGER.warning(\"Mermaid config file %s not found, using default\", config_path)\n        config_path = None\n    \n    # Process files\n    try:\n        if json_path.is_dir():\n            total_changed = process_directory(json_path, output_dir, config_path)\n            LOGGER.info(\"Total of %d diagrams processed across all files\", total_changed)\n        else:\n            process_json_file(json_path, output_dir, config_path)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 2. Updated `json_to_markdown.py` with SVG Support\n\n```python\n#!/usr/bin/env python3\n\"\"\"Convert slides.json to md2gslides compatible markdown files.\n\nThis script converts JSON slide data to markdown format compatible with md2gslides,\nallowing for generation of Google Slides presentations.\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys\nfrom pathlib import Path\nfrom typing import Dict, List, Any, Optional\n\nLOGGER = logging.getLogger(\"json_to_markdown\")\n\n# Map of slide layouts to md2gslides format templates\nLAYOUT_TEMPLATES = {\n    \"TITLE\": {\n        \"template\": \"\"\"# {title}\n## {subtitle}\n\"\"\",\n        \"fields\": [\"title\", \"subtitle\"]\n    },\n    \"TITLE_AND_BODY\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"TITLE_AND_TWO_COLUMNS\": {\n        \"template\": \"\"\"# {title}\n\n{left_column}\n\n{{.column}}\n\n{right_column}\n\"\"\",\n        \"fields\": [\"title\", \"left_column\", \"right_column\"]\n    },\n    \"MAIN_POINT\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\"\"\",\n        \"fields\": [\"title\"]\n    },\n    \"SECTION_HEADER\": {\n        \"template\": \"\"\"# {title}\n\"\"\",\n        \"fields\": [\"title\"]\n    },\n    \"BIG_NUMBER\": {\n        \"template\": \"\"\"# {title} {{.big}}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    },\n    \"CAPTION\": {\n        \"template\": \"\"\"# {title}\n\n![]({image_url})\n\"\"\",\n        \"fields\": [\"title\", \"image_url\"]\n    },\n    \"BLANK\": {\n        \"template\": \"\"\"\n![]({image_url}){{.background}}\n\"\"\",\n        \"fields\": [\"image_url\"]\n    },\n    \"DEFAULT\": {\n        \"template\": \"\"\"# {title}\n\n{content}\n\"\"\",\n        \"fields\": [\"title\", \"content\"]\n    }\n}\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"Convert slides.json to md2gslides markdown\")\n    p.add_argument(\"json\", help=\"slides.json file or directory of JSON files\")\n    p.add_argument(\"--output-dir\", default=None, help=\"Output directory for markdown files\")\n    p.add_argument(\"--prefer-svg\", action=\"store_true\", help=\"Prefer SVG over PNG for diagrams\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None)\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(level=level, format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\", handlers=handlers)\n\n\ndef split_content_into_columns(content: str) -> tuple[str, str]:\n    \"\"\"Split content into two columns based on content length.\"\"\"\n    if not content:\n        return \"\", \"\"\n    \n    lines = content.split('\\n')\n    if len(lines) <= 1:\n        return content, \"\"\n    \n    midpoint = len(lines) // 2\n    left_column = '\\n'.join(lines[:midpoint])\n    right_column = '\\n'.join(lines[midpoint:])\n    \n    return left_column, right_column\n\n\ndef convert_to_svg_block(image_path: str, slide_num: int) -> str:\n    \"\"\"Convert image path to SVG block if it's an SVG file.\"\"\"\n    path = Path(image_path)\n    if path.suffix.lower() == '.svg' and path.exists():\n        try:\n            svg_content = path.read_text(encoding='utf-8')\n            return f\"\\n$$$ svg\\n{svg_content}\\n$$$\\n\"\n        except Exception as e:\n            LOGGER.warning(f\"Failed to read SVG file {path}: {e}\")\n            return f\"![](${image_path})\"\n    return f\"![](${image_path})\"\n\n\ndef format_slide(slide: Dict[str, Any], prefer_svg: bool = False) -> str:\n    \"\"\"Format a single slide as markdown based on its layout.\"\"\"\n    # Extract slide data\n    layout = slide.get(\"layout\", \"DEFAULT\")\n    \n    # Get layout template\n    template_info = LAYOUT_TEMPLATES.get(layout, LAYOUT_TEMPLATES[\"DEFAULT\"])\n    template = template_info[\"template\"]\n    \n    # Handle image URL\n    image_url = slide.get(\"image_url\", \"\")\n    if image_url:\n        # Check if there's an SVG version of the image\n        if prefer_svg and image_url.lower().endswith('.png'):\n            svg_path = image_url[:-4] + '.svg'\n            svg_path_obj = Path(svg_path)\n            if svg_path_obj.exists():\n                # Use SVG block instead of image reference\n                svg_content = svg_path_obj.read_text(encoding='utf-8')\n                image_block = f\"\\n$$$ svg\\n{svg_content}\\n$$$\\n\"\n            else:\n                image_block = f\"![]({image_url})\"\n        else:\n            image_block = f\"![]({image_url})\"\n    else:\n        image_block = \"\"\n    \n    # Create data dict for template\n    data = {\n        \"title\": slide.get(\"title\", \"\"),\n        \"subtitle\": slide.get(\"subtitle\", \"\"),\n        \"content\": slide.get(\"content\", \"\"),\n        \"image_url\": image_url\n    }\n    \n    # For two column layouts, split content and handle images\n    if layout == \"TITLE_AND_TWO_COLUMNS\":\n        left, right = split_content_into_columns(data[\"content\"])\n        data[\"left_column\"] = left\n        \n        # If there's an image, use it for the right column\n        if image_url:\n            if prefer_svg and image_url.lower().endswith('.png'):\n                svg_path = image_url[:-4] + '.svg'\n                svg_path_obj = Path(svg_path)\n                if svg_path_obj.exists():\n                    # Use SVG block instead of image reference\n                    svg_content = svg_path_obj.read_text(encoding='utf-8')\n                    data[\"right_column\"] = f\"\\n$$$ svg\\n{svg_content}\\n$$$\\n\"\n                else:\n                    data[\"right_column\"] = f\"![]({image_url})\"\n            else:\n                data[\"right_column\"] = f\"![]({image_url})\"\n        else:\n            data[\"right_column\"] = right\n    \n    # Add speaker notes if available\n    notes = slide.get(\"facilitator_notes\", \"\")\n    notes_section = f\"\\n\\n<!--\\n{notes}\\n-->\" if notes else \"\"\n    \n    # Format markdown\n    try:\n        md = template.format(**{k: v for k, v in data.items() if k in template_info[\"fields\"]})\n        return f\"---\\n\\n{md}{notes_section}\\n\"\n    except KeyError as e:\n        LOGGER.warning(f\"Missing field {e} for layout {layout}, using default\")\n        return f\"---\\n\\n# {data['title']}\\n\\n{data['content']}{notes_section}\\n\"\n\n\ndef convert_json_to_markdown(json_path: Path, output_dir: Optional[Path] = None, prefer_svg: bool = False) -> Path:\n    \"\"\"Convert a single JSON file to markdown.\"\"\"\n    LOGGER.info(\"Converting %s to markdown\", json_path)\n    \n    # Load JSON data\n    try:\n        slides = json.loads(json_path.read_text())\n    except json.JSONDecodeError as e:\n        LOGGER.error(\"Invalid JSON in %s: %s\", json_path, e)\n        raise\n    \n    # Create markdown\n    md_content = []\n    for slide in slides:\n        md_content.append(format_slide(slide, prefer_svg))\n    \n    # Join with newlines\n    markdown = \"\\n\".join(md_content)\n    \n    # Determine output path\n    if output_dir:\n        output_path = output_dir / f\"{json_path.stem.replace('slides_', '')}.md\"\n    else:\n        output_path = json_path.with_suffix(\".md\")\n    \n    # Write markdown file\n    output_path.write_text(markdown)\n    LOGGER.info(\"Wrote markdown to %s\", output_path)\n    \n    return output_path\n\n\ndef process_directory(json_dir: Path, output_dir: Optional[Path] = None, prefer_svg: bool = False) -> List[Path]:\n    \"\"\"Process all JSON files in a directory.\"\"\"\n    LOGGER.info(\"Processing all JSON files in %s\", json_dir)\n    \n    # Find all JSON files\n    json_files = list(json_dir.glob(\"slides_*.json\"))\n    if not json_files:\n        LOGGER.error(\"No slide JSON files found in %s\", json_dir)\n        return []\n    \n    LOGGER.info(\"Found %d JSON files to process\", len(json_files))\n    \n    # Process each file\n    results = []\n    for json_path in json_files:\n        try:\n            md_path = convert_json_to_markdown(json_path, output_dir, prefer_svg)\n            results.append(md_path)\n        except Exception as e:\n            LOGGER.error(\"Failed to convert %s: %s\", json_path, e, exc_info=True)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n    \n    # Validate paths\n    json_path = Path(args.json)\n    if not json_path.exists():\n        LOGGER.error(\"%s not found\", json_path)\n        sys.exit(1)\n    \n    # Determine output directory\n    output_dir = Path(args.output_dir) if args.output_dir else None\n    if output_dir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Process files\n    try:\n        if json_path.is_dir():\n            md_files = process_directory(json_path, output_dir, args.prefer_svg)\n            LOGGER.info(\"Converted %d JSON files to markdown\", len(md_files))\n        else:\n            convert_json_to_markdown(json_path, output_dir, args.prefer_svg)\n    except Exception as e:\n        LOGGER.error(\"Processing failed: %s\", e, exc_info=True)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 3. `magicSlide.sh` - One-Click Bash Script\n\n```bash\n#!/bin/bash\n# magicSlide.sh - One-click slide generation from facilitator guides\n# Usage: ./magicSlide.sh input.md [options]\n#        ./magicSlide.sh directory/ [options]\n\nset -e  # Exit on error\n\n# Default options\nCONFIG=\"config.yaml\"\nMERMAID_CONFIG=\"mermaid-config.json\"\nLOG_LEVEL=\"INFO\"\nTITLE_PREFIX=\"\"\nSTYLE=\"github\"\nUSE_FILEIO=1\nCLAUDE_MODEL=\"claude-3-7-sonnet-20250219\"\n\n# Functions\nprint_usage() {\n  echo \"Usage: $0 <input.md or directory> [options]\"\n  echo \"Options:\"\n  echo \"  --config=FILE         YAML config file (default: config.yaml)\"\n  echo \"  --mermaid-config=FILE Mermaid config file (default: mermaid-config.json)\"\n  echo \"  --no-fileio           Don't use file.io for image uploads\"\n  echo \"  --title-prefix=TEXT   Add prefix to presentation titles\"\n  echo \"  --style=STYLE         Code highlighting style (default: github)\"\n  echo \"  --model=MODEL         Claude model (default: claude-3-7-sonnet-20250219)\"\n  echo \"  --log-level=LEVEL     Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)\"\n  echo \"  --help                Show this help message\"\n}\n\n# Parse arguments\nINPUT=\"\"\nfor arg in \"$@\"; do\n  case $arg in\n    --config=*)\n      CONFIG=\"${arg#*=}\"\n      ;;\n    --mermaid-config=*)\n      MERMAID_CONFIG=\"${arg#*=}\"\n      ;;\n    --no-fileio)\n      USE_FILEIO=0\n      ;;\n    --title-prefix=*)\n      TITLE_PREFIX=\"${arg#*=}\"\n      ;;\n    --style=*)\n      STYLE=\"${arg#*=}\"\n      ;;\n    --model=*)\n      CLAUDE_MODEL=\"${arg#*=}\"\n      ;;\n    --log-level=*)\n      LOG_LEVEL=\"${arg#*=}\"\n      ;;\n    --help)\n      print_usage\n      exit 0\n      ;;\n    -*)\n      echo \"Unknown option: $arg\"\n      print_usage\n      exit 1\n      ;;\n    *)\n      if [ -z \"$INPUT\" ]; then\n        INPUT=\"$arg\"\n      else\n        echo \"Multiple input files specified. Use only one.\"\n        print_usage\n        exit 1\n      fi\n      ;;\n  esac\ndone\n\n# Check for required input\nif [ -z \"$INPUT\" ]; then\n  echo \"Error: No input file or directory specified.\"\n  print_usage\n  exit 1\nfi\n\n# Determine input type\nif [ -d \"$INPUT\" ]; then\n  # Directory mode\n  echo \"🔍 Processing directory: $INPUT\"\n  WORKING_DIR=\"$INPUT\"\n  DIR_MODE=1\nelse\n  # Single file mode\n  echo \"🔍 Processing file: $INPUT\"\n  WORKING_DIR=\"$(dirname \"$INPUT\")\"\n  BASENAME=\"$(basename \"$INPUT\" .md)\"\n  BASENAME=\"${BASENAME%.txt}\"  # Also strip .txt if present\n  DIR_MODE=0\nfi\n\n# Create/verify necessary directories\nIMAGES_DIR=\"$WORKING_DIR/images\"\nmkdir -p \"$IMAGES_DIR\"\n\necho \"Step 1/4: 🧠 Converting to JSON with Claude...\"\nif [ $DIR_MODE -eq 1 ]; then\n  python guide_to_json.py \"$INPUT\" --config=\"$CONFIG\" --model=\"$CLAUDE_MODEL\" --log-level=\"$LOG_LEVEL\"\nelse\n  JSON_FILE=\"$WORKING_DIR/slides_$BASENAME.json\"\n  python guide_to_json.py \"$INPUT\" --config=\"$CONFIG\" --out=\"$JSON_FILE\" --model=\"$CLAUDE_MODEL\" --log-level=\"$LOG_LEVEL\"\nfi\n\necho \"Step 2/4: 📊 Rendering diagrams...\"\nif [ $DIR_MODE -eq 1 ]; then\n  python diagrams_to_images.py \"$INPUT\" --mermaid-config=\"$MERMAID_CONFIG\" --output-dir=\"$IMAGES_DIR\" --log-level=\"$LOG_LEVEL\"\nelse\n  python diagrams_to_images.py \"$JSON_FILE\" --mermaid-config=\"$MERMAID_CONFIG\" --output-dir=\"$IMAGES_DIR\" --log-level=\"$LOG_LEVEL\"\nfi\n\necho \"Step 3/4: 📝 Converting to markdown...\"\nif [ $DIR_MODE -eq 1 ]; then\n  python json_to_markdown.py \"$INPUT\" --prefer-svg --log-level=\"$LOG_LEVEL\"\nelse\n  python json_to_markdown.py \"$JSON_FILE\" --prefer-svg --log-level=\"$LOG_LEVEL\"\nfi\n\necho \"Step 4/4: 🎯 Generating Google Slides...\"\nFILEIO_ARG=\"\"\nif [ $USE_FILEIO -eq 1 ]; then\n  FILEIO_ARG=\"--use-fileio\"\nfi\n\nif [ $DIR_MODE -eq 1 ]; then\n  python build_with_md2gslides.py \"$INPUT\" --title-prefix=\"$TITLE_PREFIX\" --style=\"$STYLE\" $FILEIO_ARG --log-level=\"$LOG_LEVEL\" --output-file=\"$WORKING_DIR/presentations.txt\"\nelse\n  MD_FILE=\"$WORKING_DIR/$BASENAME.md\"\n  python build_with_md2gslides.py \"$MD_FILE\" --title-prefix=\"$TITLE_PREFIX\" --style=\"$STYLE\" $FILEIO_ARG --log-level=\"$LOG_LEVEL\" --output-file=\"$WORKING_DIR/$BASENAME-presentation.txt\"\nfi\n\necho \"✅ All done! Your slides are ready.\"\necho \"📋 Presentation links saved to the output text file.\"\n```\n\n## Command Examples\n\nHere are sample commands for using the system with different scenarios:\n\n### Process a single file\n```bash\n# Basic usage\n./magicSlide.sh workshop.md\n\n# With options\n./magicSlide.sh workshop.md --title-prefix=\"Workshop: \" --style=\"monokai\" --model=\"claude-3-7-sonnet-20250219\"\n```\n\n### Process a directory\n```bash\n# Process all markdown files in a directory\n./magicSlide.sh guides/\n\n# With options\n./magicSlide.sh guides/ --config=my-custom-config.yaml --mermaid-config=dark-theme.json --no-fileio\n```\n\n### Using individual scripts\n```bash\n# Step 1: Convert guide to JSON\npython guide_to_json.py workshop.md --config=config.yaml\n\n# Step 2: Render diagrams\npython diagrams_to_images.py slides_workshop.json --mermaid-config=mermaid-config.json --output-dir=images\n\n# Step 3: Convert to markdown\npython json_to_markdown.py slides_workshop.json --prefer-svg\n\n# Step 4: Generate Google Slides\npython build_with_md2gslides.py workshop.md --title-prefix=\"Workshop: \" --style=\"github\" --use-fileio\n```\n\n## Key Improvements\n\n1. **Simplified Image Handling**: Now saves SVG files alongside PNGs, with md2gslides handling the image uploads\n\n2. **Cleaner Directory Structure**: Images are organized in an \"images\" folder with clear naming conventions\n\n3. **SVG Support**: Directly embeds SVG content using md2gslides' `$$$ svg` blocks for better quality\n\n4. **One-Click Script**: `magicSlide.sh` provides a simple way to run the entire pipeline with sensible defaults\n\n5. **Customizable Options**: All scripts accept various options to customize the output\n\n6. **Better Layout Control**: The YAML config file allows for custom layout mappings to ensure slides look good\n\nWith these updates, you should have a more robust, flexible, and user-friendly slide generation system that takes advantage of md2gslides' built-in features for handling local images, SVGs, and math expressions.",
            "citations": []
          }
        ],
        "updated_at": "2025-05-20T09:50:11.981683Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "ffdd2119-2ead-4520-ac32-c5ba78febbc5",
      "role": "human",
      "content": "**npm** error gyp ERR! not ok\n**npm** error A complete log of this run can be found in: /Users/bilalghalib/.npm/_logs/2025-05-20T09_39_56_255Z-debug-0.log\n(base) bilalghalib@Cruzer-2 makeslides % pico magicSlide.sh\n(base) bilalghalib@Cruzer-2 makeslides % magicSlide.sh /Users/bilalghalib/Projects/scripts/makeslides/guides/day5.txt \nzsh: command not found: magicSlide.sh\n(base) bilalghalib@Cruzer-2 makeslides % ./magicSlide.sh /Users/bilalghalib/Projects/scripts/makeslides/guides/day5.txt \nzsh: permission denied: ./magicSlide.sh\n(base) bilalghalib@Cruzer-2 makeslides % chmod +x magicSlide.sh \n(base) bilalghalib@Cruzer-2 makeslides % ./magicSlide.sh /Users/bilalghalib/Projects/scripts/makeslides/guides/day5.txt \n🔍 Processing file: /Users/bilalghalib/Projects/scripts/makeslides/guides/day5.txt\nStep 1/4: 🧠 Converting to JSON with Claude...\n2025-05-20 11:59:04,085 [INFO] guide_to_json: Processing guide: /Users/bilalghalib/Projects/scripts/makeslides/guides/day5.txt\n2025-05-20 11:59:04,085 [INFO] guide_to_json: Requesting Claude (claude-3-7-sonnet-20250219) for day5.txt...\n2025-05-20 11:59:17,387 [INFO] httpx: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n2025-05-20 11:59:17,395 [WARNING] guide_to_json: Invalid JSON from Claude: Extra data: line 1 column 112 (char 111), retrying in 1 seconds...\n2025-05-20 11:59:18,398 [INFO] guide_to_json: Requesting Claude (claude-3-7-sonnet-20250219) for day5.txt...\n2025-05-20 12:00:35,168 [INFO] httpx: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n2025-05-20 12:00:35,209 [WARNING] guide_to_json: Invalid JSON from Claude: Extra data: line 5 column 4 (char 186), retrying in 2 seconds...\n2025-05-20 12:00:37,211 [INFO] guide_to_json: Requesting Claude (claude-3-7-sonnet-20250219) for day5.txt...\n2025-05-20 12:01:06,994 [INFO] httpx: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n2025-05-20 12:01:07,015 [ERROR] guide_to_json: Invalid JSON from Claude after 3 attempts: Extra data: line 6 column 6 (char 275)\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/Projects/scripts/makeslides/guide_to_json.py\", line 262, in <module>\n    main()\n  File \"/Users/bilalghalib/Projects/scripts/makeslides/guide_to_json.py\", line 258, in main\n    process_guide(guide_path, config, out_path, args.model, client)\n  File \"/Users/bilalghalib/Projects/scripts/makeslides/guide_to_json.py\", line 164, in process_guide\n    slides = json.loads(raw[start:])\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/__init__.py\", line 346, in loads\n    return *default*decoder.decode(s)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 6 column 6 (char 275)\n(base) bilalghalib@Cruzer-2 makeslides %",
      "created_at": "2025-05-20T10:05:34.081160Z",
      "sequence_order": 8,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-20T10:05:34.069948Z",
            "stop_timestamp": "2025-05-20T10:05:34.069948Z",
            "flags": null,
            "type": "text",
            "text": "**npm** error gyp ERR! not ok\n**npm** error A complete log of this run can be found in: /Users/bilalghalib/.npm/_logs/2025-05-20T09_39_56_255Z-debug-0.log\n(base) bilalghalib@Cruzer-2 makeslides % pico magicSlide.sh\n(base) bilalghalib@Cruzer-2 makeslides % magicSlide.sh /Users/bilalghalib/Projects/scripts/makeslides/guides/day5.txt \nzsh: command not found: magicSlide.sh\n(base) bilalghalib@Cruzer-2 makeslides % ./magicSlide.sh /Users/bilalghalib/Projects/scripts/makeslides/guides/day5.txt \nzsh: permission denied: ./magicSlide.sh\n(base) bilalghalib@Cruzer-2 makeslides % chmod +x magicSlide.sh \n(base) bilalghalib@Cruzer-2 makeslides % ./magicSlide.sh /Users/bilalghalib/Projects/scripts/makeslides/guides/day5.txt \n🔍 Processing file: /Users/bilalghalib/Projects/scripts/makeslides/guides/day5.txt\nStep 1/4: 🧠 Converting to JSON with Claude...\n2025-05-20 11:59:04,085 [INFO] guide_to_json: Processing guide: /Users/bilalghalib/Projects/scripts/makeslides/guides/day5.txt\n2025-05-20 11:59:04,085 [INFO] guide_to_json: Requesting Claude (claude-3-7-sonnet-20250219) for day5.txt...\n2025-05-20 11:59:17,387 [INFO] httpx: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n2025-05-20 11:59:17,395 [WARNING] guide_to_json: Invalid JSON from Claude: Extra data: line 1 column 112 (char 111), retrying in 1 seconds...\n2025-05-20 11:59:18,398 [INFO] guide_to_json: Requesting Claude (claude-3-7-sonnet-20250219) for day5.txt...\n2025-05-20 12:00:35,168 [INFO] httpx: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n2025-05-20 12:00:35,209 [WARNING] guide_to_json: Invalid JSON from Claude: Extra data: line 5 column 4 (char 186), retrying in 2 seconds...\n2025-05-20 12:00:37,211 [INFO] guide_to_json: Requesting Claude (claude-3-7-sonnet-20250219) for day5.txt...\n2025-05-20 12:01:06,994 [INFO] httpx: HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n2025-05-20 12:01:07,015 [ERROR] guide_to_json: Invalid JSON from Claude after 3 attempts: Extra data: line 6 column 6 (char 275)\nTraceback (most recent call last):\n  File \"/Users/bilalghalib/Projects/scripts/makeslides/guide_to_json.py\", line 262, in <module>\n    main()\n  File \"/Users/bilalghalib/Projects/scripts/makeslides/guide_to_json.py\", line 258, in main\n    process_guide(guide_path, config, out_path, args.model, client)\n  File \"/Users/bilalghalib/Projects/scripts/makeslides/guide_to_json.py\", line 164, in process_guide\n    slides = json.loads(raw[start:])\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/__init__.py\", line 346, in loads\n    return *default*decoder.decode(s)\n  File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/decoder.py\", line 340, in decode\n    raise JSONDecodeError(\"Extra data\", s, end)\njson.decoder.JSONDecodeError: Extra data: line 6 column 6 (char 275)\n(base) bilalghalib@Cruzer-2 makeslides %",
            "citations": []
          }
        ],
        "updated_at": "2025-05-20T10:05:34.081160Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "1bb6d29c-3d59-4146-bd96-f6464c487be9",
      "role": "assistant",
      "content": "It looks like there are a couple of issues to fix:\n\n1. **npm Error**: The md2gslides package installation seems to be failing with a gyp error. This might be related to node-gyp which is needed for native dependencies.\n\n2. **Claude JSON Parsing Issue**: The Claude API is returning content that's not valid JSON, causing your parser to fail. The error shows \"Extra data\" at different positions in different attempts.\n\nLet's address these issues one by one:\n\nFor the npm error, we should update the installation instructions in the magicSlide.sh script to better handle dependencies and provide troubleshooting tips.\n\nFor the Claude JSON parsing issue, we need to make the JSON parsing more robust. Claude sometimes returns explanatory text before or after the JSON, especially if it's having trouble generating valid JSON. We should improve the extraction method to find the JSON array or object more reliably.\n\nLet me update these scripts:Let's fix the issues you're encountering. It looks like we need to improve the JSON parsing robustness and handle npm installation problems.\n\n## 1. Updated `guide_to_json.py` with Improved JSON Extraction\n\n```python\n#!/usr/bin/env python3\n\"\"\"Convert a facilitator guide into slides.json using Claude 3.\n\nUsage:\n  python guide_to_json.py guide.md \\\n      --config config.yaml \\\n      --out slides.json \\\n      --log-level INFO \\\n      --log-file build.log\n      \n  # Process all markdown files in a folder:\n  python guide_to_json.py guides/ \\\n      --config config.yaml \\\n      --log-level INFO \\\n      --log-file build.log\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, time, yaml, re\nfrom pathlib import Path\nfrom typing import List, Dict, Any\nimport anthropic\n\nDEFAULT_OUT = \"slides.json\"\nDEFAULT_CONFIG = \"config.yaml\"\n\nLOGGER = logging.getLogger(\"guide_to_json\")\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"LLM → JSON slide outline\")\n    p.add_argument(\"guide\", help=\"Facilitator guide (Markdown/text) or directory of guides\")\n    p.add_argument(\"--config\", default=DEFAULT_CONFIG, help=\"YAML config with prompt template and layout mappings\")\n    p.add_argument(\"--out\", default=None, help=\"Output JSON path (ignored if guide is a directory)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None, help=\"Write logs to file as well\")\n    p.add_argument(\"--model\", default=\"claude-3-7-sonnet-20250219\", help=\"Claude model to use\")\n    p.add_argument(\"--batch-size\", type=int, default=5, help=\"Number of files to process in parallel (batch mode)\")\n    p.add_argument(\"--force-json\", action=\"store_true\", help=\"Force JSON extraction even if response is not valid JSON\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers: list[logging.Handler] = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(\n        level=level,\n        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n        handlers=handlers,\n    )\n\n\ndef load_config(config_path: Path) -> Dict[str, Any]:\n    \"\"\"Load YAML configuration file with prompt template and layout mappings.\"\"\"\n    if not config_path.exists():\n        LOGGER.warning(\"Config file %s not found, using defaults\", config_path)\n        return {\n            \"prompt_template\": \"{{content}}\",\n            \"layout_mappings\": {},\n            \"slide_defaults\": {}\n        }\n    \n    with open(config_path, 'r') as f:\n        config = yaml.safe_load(f)\n    \n    # Ensure required keys exist\n    config.setdefault(\"prompt_template\", \"{{content}}\")\n    config.setdefault(\"layout_mappings\", {})\n    config.setdefault(\"slide_defaults\", {})\n    \n    return config\n\n\ndef build_prompt(template: str, guide_text: str) -> str:\n    \"\"\"Insert guide text into prompt template.\"\"\"\n    if \"{{content}}\" not in template:\n        LOGGER.error(\"Prompt template missing {{content}} placeholder\")\n        sys.exit(1)\n    return template.replace(\"{{content}}\", guide_text)\n\n\n# Insert missing keys and correct ordering\nORDER = [\n    \"slide_number\", \"title\", \"content\", \"layout\", \"chart_type\", \"diagram_type\", \"diagram_content\",\n    \"image_description\", \"image_url\", \"facilitator_notes\", \"start_time\", \"end_time\",\n    \"materials\", \"worksheet\", \"improvements\", \"notes\",\n]\n\n\ndef normalize(slides: list[dict], layout_mappings: Dict[str, str], slide_defaults: Dict[str, Any]) -> list[dict]:\n    \"\"\"Normalize slides by adding missing keys and applying layout mappings.\"\"\"\n    fixed = []\n    for idx, raw in enumerate(slides, 1):\n        # Apply defaults\n        for key, value in slide_defaults.items():\n            raw.setdefault(key, value)\n        \n        # Set slide number\n        raw.setdefault(\"slide_number\", idx)\n        \n        # Apply layout mapping if available\n        layout = raw.get(\"layout\")\n        if not layout:\n            # Determine layout based on content\n            if idx == 1:\n                raw[\"layout\"] = \"TITLE\"\n            elif raw.get(\"image_url\") or raw.get(\"diagram_type\"):\n                raw[\"layout\"] = \"TITLE_AND_TWO_COLUMNS\"\n            else:\n                raw[\"layout\"] = \"TITLE_AND_BODY\"\n        \n        # Apply custom layout mappings\n        if layout in layout_mappings:\n            raw[\"layout\"] = layout_mappings[layout]\n        \n        # Ensure all other keys exist\n        raw.setdefault(\"chart_type\", None)\n        raw.setdefault(\"image_description\", None)\n        raw.setdefault(\"image_url\", None)\n        for key in ORDER:\n            raw.setdefault(key, None)\n        \n        # Create ordered dictionary\n        fixed.append({k: raw.get(k) for k in ORDER})\n    \n    return fixed\n\n\ndef extract_json(text: str, force: bool = False) -> list:\n    \"\"\"Extract JSON array from text, even if surrounded by non-JSON content.\"\"\"\n    # Try to find a JSON array using regex\n    array_match = re.search(r'(\\[\\s*{.*}\\s*\\])', text, re.DOTALL)\n    if array_match:\n        try:\n            return json.loads(array_match.group(1))\n        except json.JSONDecodeError:\n            pass  # Fall through to other methods\n    \n    # Look for common JSON array start/end\n    start_idx = text.find('[')\n    end_idx = text.rfind(']')\n    \n    if start_idx != -1 and end_idx != -1 and start_idx < end_idx:\n        try:\n            return json.loads(text[start_idx:end_idx+1])\n        except json.JSONDecodeError:\n            pass  # Fall through to other methods\n    \n    # If force enabled, try to extract JSON objects and build an array\n    if force:\n        LOGGER.warning(\"Attempting to force JSON extraction from malformed response\")\n        objects = re.findall(r'{\\s*\"slide_number\"\\s*:.*?}', text, re.DOTALL)\n        if objects:\n            result = []\n            for obj_str in objects:\n                try:\n                    # Replace any trailing commas that would make the JSON invalid\n                    obj_str = re.sub(r',\\s*}', '}', obj_str)\n                    obj = json.loads(obj_str)\n                    result.append(obj)\n                except json.JSONDecodeError:\n                    continue\n            \n            if result:\n                LOGGER.info(f\"Successfully extracted {len(result)} slide objects\")\n                return result\n    \n    raise json.JSONDecodeError(\"Could not extract valid JSON from response\", text, 0)\n\n\ndef process_guide(guide_path: Path, config: Dict[str, Any], out_path: Path | None, model: str, client: anthropic.Anthropic, force_json: bool = False) -> Path:\n    \"\"\"Process a single guide file and return the output path.\"\"\"\n    LOGGER.info(\"Processing guide: %s\", guide_path)\n    \n    # Determine output path\n    if not out_path:\n        out_path = guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n    \n    # Read guide and build prompt\n    guide_txt = guide_path.read_text(encoding=\"utf-8\")\n    prompt = build_prompt(config[\"prompt_template\"], guide_txt)\n    \n    # Request Claude with retries\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            LOGGER.info(\"Requesting Claude (%s) for %s...\", model, guide_path.name)\n            rsp = client.messages.create(\n                model=model,\n                max_tokens=16_000,\n                system=\"Return JSON only. Your response should be a valid JSON array of slide objects, each with slide_number, title, content, and other fields.\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            )\n            \n            raw = rsp.content[0].text\n            \n            # Try to extract JSON from the response\n            try:\n                slides = extract_json(raw, force_json)\n            except json.JSONDecodeError as e:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Invalid JSON from Claude: %s, retrying in %d seconds...\", e, 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Invalid JSON from Claude after %d attempts: %s\", max_attempts, e)\n                    \n                    # Debug: Save the raw response to a file for inspection\n                    debug_path = out_path.with_suffix(\".debug.txt\")\n                    debug_path.write_text(raw)\n                    LOGGER.error(f\"Saved raw response to {debug_path} for debugging\")\n                    \n                    raise\n            \n            # Normalize and save\n            slides = normalize(slides, config[\"layout_mappings\"], config[\"slide_defaults\"])\n            out_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n            LOGGER.info(\"Wrote %d slides → %s\", len(slides), out_path)\n            return out_path\n            \n        except (anthropic.APIError, anthropic.APITimeoutError, anthropic.APIConnectionError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"API error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                            attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)\n            else:\n                LOGGER.error(\"API error after %d attempts: %s\", max_attempts, e, exc_info=True)\n                raise\n    \n    raise RuntimeError(\"Failed to process guide, this should not happen\")  # Unreachable\n\n\ndef process_directory(guide_dir: Path, config: Dict[str, Any], model: str, batch_size: int, client: anthropic.Anthropic, force_json: bool = False) -> List[Path]:\n    \"\"\"Process all markdown files in a directory.\"\"\"\n    LOGGER.info(\"Processing all markdown files in: %s\", guide_dir)\n    \n    # Find all markdown and text files\n    md_files = list(guide_dir.glob(\"*.md\")) + list(guide_dir.glob(\"*.txt\"))\n    if not md_files:\n        LOGGER.error(\"No markdown or text files found in %s\", guide_dir)\n        sys.exit(1)\n    \n    LOGGER.info(\"Found %d files to process\", len(md_files))\n    \n    # Process files in batches to avoid overwhelming the API\n    results = []\n    for i in range(0, len(md_files), batch_size):\n        batch = md_files[i:i + batch_size]\n        LOGGER.info(\"Processing batch %d/%d (%d files)\", i // batch_size + 1, \n                   (len(md_files) + batch_size - 1) // batch_size, len(batch))\n        \n        for guide_path in batch:\n            try:\n                out_path = process_guide(guide_path, config, None, model, client, force_json)\n                results.append(out_path)\n            except Exception as e:\n                LOGGER.error(\"Failed to process %s: %s\", guide_path, e, exc_info=True)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n    if not api_key:\n        LOGGER.error(\"Set ANTHROPIC_API_KEY environment variable\")\n        sys.exit(1)\n\n    # Load configuration\n    config_path = Path(args.config)\n    config = load_config(config_path)\n    \n    # Validate paths\n    guide_path = Path(args.guide)\n    \n    if not guide_path.exists():\n        LOGGER.error(\"Guide path not found: %s\", guide_path)\n        sys.exit(1)\n    \n    # Initialize Claude client\n    client = anthropic.Anthropic(api_key=api_key)\n    \n    if guide_path.is_dir():\n        LOGGER.info(\"Directory mode: Processing all markdown files in %s\", guide_path)\n        if args.out:\n            LOGGER.warning(\"--out parameter ignored in directory mode\")\n        \n        # Process directory\n        process_directory(guide_path, config, args.model, args.batch_size, client, args.force_json)\n        \n    else:\n        # Single file mode\n        # Determine output path\n        out_path = Path(args.out) if args.out else guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n        \n        # Process single guide\n        process_guide(guide_path, config, out_path, args.model, client, args.force_json)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 2. Updated `magicSlide.sh` with Better Error Handling and npm Fixes\n\n```bash\n#!/bin/bash\n# magicSlide.sh - One-click slide generation from facilitator guides\n# Usage: ./magicSlide.sh input.md [options]\n#        ./magicSlide.sh directory/ [options]\n\n# Error handling\nset -e  # Exit on error\n\n# Color output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m' # No Color\n\n# Default options\nCONFIG=\"config.yaml\"\nMERMAID_CONFIG=\"mermaid-config.json\"\nLOG_LEVEL=\"INFO\"\nTITLE_PREFIX=\"\"\nSTYLE=\"github\"\nUSE_FILEIO=1\nCLAUDE_MODEL=\"claude-3-7-sonnet-20250219\"\nFORCE_JSON=0\nSKIP_SLIDES=0\n\n# Functions\nprint_usage() {\n  echo \"Usage: $0 <input.md or directory> [options]\"\n  echo \"Options:\"\n  echo \"  --config=FILE         YAML config file (default: config.yaml)\"\n  echo \"  --mermaid-config=FILE Mermaid config file (default: mermaid-config.json)\"\n  echo \"  --no-fileio           Don't use file.io for image uploads\"\n  echo \"  --title-prefix=TEXT   Add prefix to presentation titles\"\n  echo \"  --style=STYLE         Code highlighting style (default: github)\"\n  echo \"  --model=MODEL         Claude model (default: claude-3-7-sonnet-20250219)\"\n  echo \"  --log-level=LEVEL     Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)\"\n  echo \"  --force-json          Force JSON extraction even if Claude response is invalid\"\n  echo \"  --skip-slides         Skip Google Slides generation (stop after markdown)\"\n  echo \"  --help                Show this help message\"\n}\n\ncheck_npm_deps() {\n  if ! command -v mmdc &> /dev/null; then\n    echo -e \"${YELLOW}Mermaid CLI not found. Installing...${NC}\"\n    echo \"This may take a moment...\"\n    \n    # Install mermaid-cli with specific version to avoid compatibility issues\n    npm install -g @mermaid-js/mermaid-cli@10.8.0\n    \n    if [ $? -ne 0 ]; then\n      echo -e \"${RED}Failed to install Mermaid CLI.${NC}\"\n      echo \"If you're having issues with node-gyp, try:\"\n      echo \"  1. npm install -g node-gyp\"\n      echo \"  2. xcode-select --install (on macOS)\"\n      echo \"  3. npm config set python /path/to/python3\"\n      echo \"Then try running this script again.\"\n      exit 1\n    fi\n  fi\n  \n  if ! command -v md2gslides &> /dev/null && [ $SKIP_SLIDES -eq 0 ]; then\n    echo -e \"${YELLOW}md2gslides not found. Installing...${NC}\"\n    \n    # Install md2gslides\n    npm install -g md2gslides\n    \n    if [ $? -ne 0 ]; then\n      echo -e \"${RED}Failed to install md2gslides.${NC}\"\n      echo \"You can continue without Google Slides generation.\"\n      echo \"To install manually: npm install -g md2gslides\"\n      SKIP_SLIDES=1\n    fi\n  fi\n}\n\n# Parse arguments\nINPUT=\"\"\nfor arg in \"$@\"; do\n  case $arg in\n    --config=*)\n      CONFIG=\"${arg#*=}\"\n      ;;\n    --mermaid-config=*)\n      MERMAID_CONFIG=\"${arg#*=}\"\n      ;;\n    --no-fileio)\n      USE_FILEIO=0\n      ;;\n    --title-prefix=*)\n      TITLE_PREFIX=\"${arg#*=}\"\n      ;;\n    --style=*)\n      STYLE=\"${arg#*=}\"\n      ;;\n    --model=*)\n      CLAUDE_MODEL=\"${arg#*=}\"\n      ;;\n    --log-level=*)\n      LOG_LEVEL=\"${arg#*=}\"\n      ;;\n    --force-json)\n      FORCE_JSON=1\n      ;;\n    --skip-slides)\n      SKIP_SLIDES=1\n      ;;\n    --help)\n      print_usage\n      exit 0\n      ;;\n    -*)\n      echo -e \"${RED}Unknown option: $arg${NC}\"\n      print_usage\n      exit 1\n      ;;\n    *)\n      if [ -z \"$INPUT\" ]; then\n        INPUT=\"$arg\"\n      else\n        echo -e \"${RED}Multiple input files specified. Use only one.${NC}\"\n        print_usage\n        exit 1\n      fi\n      ;;\n  esac\ndone\n\n# Check for required input\nif [ -z \"$INPUT\" ]; then\n  echo -e \"${RED}Error: No input file or directory specified.${NC}\"\n  print_usage\n  exit 1\nfi\n\n# Check npm dependencies\ncheck_npm_deps\n\n# Determine input type\nif [ -d \"$INPUT\" ]; then\n  # Directory mode\n  echo -e \"${BLUE}🔍 Processing directory: $INPUT${NC}\"\n  WORKING_DIR=\"$INPUT\"\n  DIR_MODE=1\nelse\n  # Single file mode\n  echo -e \"${BLUE}🔍 Processing file: $INPUT${NC}\"\n  WORKING_DIR=\"$(dirname \"$INPUT\")\"\n  BASENAME=\"$(basename \"$INPUT\" .md)\"\n  BASENAME=\"${BASENAME%.txt}\"  # Also strip .txt if present\n  DIR_MODE=0\nfi\n\n# Create/verify necessary directories\nIMAGES_DIR=\"$WORKING_DIR/images\"\nmkdir -p \"$IMAGES_DIR\"\n\n# Optional force-json flag\nFORCE_JSON_ARG=\"\"\nif [ $FORCE_JSON -eq 1 ]; then\n  FORCE_JSON_ARG=\"--force-json\"\nfi\n\necho -e \"${GREEN}Step 1/4: 🧠 Converting to JSON with Claude...${NC}\"\nif [ $DIR_MODE -eq 1 ]; then\n  python guide_to_json.py \"$INPUT\" --config=\"$CONFIG\" --model=\"$CLAUDE_MODEL\" --log-level=\"$LOG_LEVEL\" $FORCE_JSON_ARG\n  if [ $? -ne 0 ]; then\n    echo -e \"${RED}Failed to convert guides to JSON. Check the error message above.${NC}\"\n    echo \"You can try using --force-json to extract JSON even from malformed responses.\"\n    exit 1\n  fi\nelse\n  JSON_FILE=\"$WORKING_DIR/slides_$BASENAME.json\"\n  python guide_to_json.py \"$INPUT\" --config=\"$CONFIG\" --out=\"$JSON_FILE\" --model=\"$CLAUDE_MODEL\" --log-level=\"$LOG_LEVEL\" $FORCE_JSON_ARG\n  if [ $? -ne 0 ]; then\n    echo -e \"${RED}Failed to convert guide to JSON. Check the error message above.${NC}\"\n    echo \"You can try using --force-json to extract JSON even from malformed responses.\"\n    exit 1\n  fi\nfi\n\necho -e \"${GREEN}Step 2/4: 📊 Rendering diagrams...${NC}\"\nif [ $DIR_MODE -eq 1 ]; then\n  python diagrams_to_images.py \"$INPUT\" --mermaid-config=\"$MERMAID_CONFIG\" --output-dir=\"$IMAGES_DIR\" --log-level=\"$LOG_LEVEL\"\n  if [ $? -ne 0 ]; then\n    echo -e \"${YELLOW}Warning: Some diagrams may have failed to render.${NC}\"\n  fi\nelse\n  python diagrams_to_images.py \"$JSON_FILE\" --mermaid-config=\"$MERMAID_CONFIG\" --output-dir=\"$IMAGES_DIR\" --log-level=\"$LOG_LEVEL\"\n  if [ $? -ne 0 ]; then\n    echo -e \"${YELLOW}Warning: Some diagrams may have failed to render.${NC}\"\n  fi\nfi\n\necho -e \"${GREEN}Step 3/4: 📝 Converting to markdown...${NC}\"\nif [ $DIR_MODE -eq 1 ]; then\n  python json_to_markdown.py \"$INPUT\" --prefer-svg --log-level=\"$LOG_LEVEL\"\n  if [ $? -ne 0 ]; then\n    echo -e \"${RED}Failed to convert JSON to markdown.${NC}\"\n    exit 1\n  fi\nelse\n  python json_to_markdown.py \"$JSON_FILE\" --prefer-svg --log-level=\"$LOG_LEVEL\"\n  if [ $? -ne 0 ]; then\n    echo -e \"${RED}Failed to convert JSON to markdown.${NC}\"\n    exit 1\n  fi\nfi\n\nif [ $SKIP_SLIDES -eq 1 ]; then\n  echo -e \"${YELLOW}Skipping Google Slides generation as requested.${NC}\"\n  echo -e \"${GREEN}✅ Completed! Markdown files are ready.${NC}\"\n  exit 0\nfi\n\necho -e \"${GREEN}Step 4/4: 🎯 Generating Google Slides...${NC}\"\nFILEIO_ARG=\"\"\nif [ $USE_FILEIO -eq 1 ]; then\n  FILEIO_ARG=\"--use-fileio\"\nfi\n\nif [ $DIR_MODE -eq 1 ]; then\n  python build_with_md2gslides.py \"$INPUT\" --title-prefix=\"$TITLE_PREFIX\" --style=\"$STYLE\" $FILEIO_ARG --log-level=\"$LOG_LEVEL\" --output-file=\"$WORKING_DIR/presentations.txt\"\n  if [ $? -ne 0 ]; then\n    echo -e \"${RED}Failed to generate Google Slides. Check the error above.${NC}\"\n    echo \"Your markdown files are still available in $WORKING_DIR.\"\n    exit 1\n  fi\n  echo -e \"${GREEN}📋 Presentation links saved to $WORKING_DIR/presentations.txt${NC}\"\nelse\n  MD_FILE=\"$WORKING_DIR/$BASENAME.md\"\n  python build_with_md2gslides.py \"$MD_FILE\" --title-prefix=\"$TITLE_PREFIX\" --style=\"$STYLE\" $FILEIO_ARG --log-level=\"$LOG_LEVEL\" --output-file=\"$WORKING_DIR/$BASENAME-presentation.txt\"\n  if [ $? -ne 0 ]; then\n    echo -e \"${RED}Failed to generate Google Slides. Check the error above.${NC}\"\n    echo \"Your markdown file is still available at $MD_FILE.\"\n    exit 1\n  fi\n  echo -e \"${GREEN}📋 Presentation link saved to $WORKING_DIR/$BASENAME-presentation.txt${NC}\"\nfi\n\necho -e \"${GREEN}✅ All done! Your slides are ready.${NC}\"\n```\n\n## 3. Example `config.yaml` with Improved Prompt\n\n```yaml\n# Improved prompt template for guide_to_json.py\nprompt_template: |\n  Convert the following facilitator guide into a detailed JSON slides outline.\n  \n  The output MUST be a valid JSON array of slide objects, each with the following structure:\n  \n  ```json\n  [\n    {\n      \"slide_number\": 1,\n      \"title\": \"Title text (max 60 chars)\",\n      \"content\": \"• Bullet point content\\n• Another bullet point\",\n      \"layout\": \"TITLE\",\n      \"chart_type\": null,\n      \"diagram_type\": null,\n      \"diagram_content\": null,\n      \"image_description\": null,\n      \"image_url\": null,\n      \"facilitator_notes\": \"Notes for the presenter\",\n      \"start_time\": null,\n      \"end_time\": null,\n      \"materials\": null,\n      \"worksheet\": null,\n      \"improvements\": null,\n      \"notes\": null\n    },\n    // Additional slides...\n  ]\n  ```\n  \n  Available layouts:\n  - TITLE (first slide only)\n  - TITLE_AND_BODY (standard slide with title and content)\n  - TITLE_AND_TWO_COLUMNS (title with two columns of content)\n  - MAIN_POINT (big text for emphasis)\n  - SECTION_HEADER (section divider)\n  - BIG_NUMBER (for emphasis of statistics)\n  - CAPTION (for slides with images)\n  \n  DO NOT include any explanatory text before or after the JSON array.\n  Just return the array containing all slides.\n  \n  Here's the guide content:\n  \n  {{content}}\n\n# Custom layout mappings (from your layout to md2gslides layout)\nlayout_mappings:\n  \"title\": \"TITLE\"\n  \"section\": \"SECTION_HEADER\"\n  \"image\": \"CAPTION\"\n  \"columns\": \"TITLE_AND_TWO_COLUMNS\"\n  \"main_point\": \"MAIN_POINT\"\n  \"big_number\": \"BIG_NUMBER\"\n\n# Default values for all slides\nslide_defaults:\n  \"chart_type\": null\n  \"image_url\": null\n```\n\n## 4. Troubleshooting Guide for Common Issues\n\nHere's a short troubleshooting guide you can save as `TROUBLESHOOTING.md`:\n\n```markdown\n# Troubleshooting Guide for magicSlide\n\n## npm Installation Errors\n\n### Error: gyp ERR!\n\nThis usually happens when node-gyp can't compile native extensions.\n\n**Solution:**\n\n1. Install node-gyp globally:\n   ```\n   npm install -g node-gyp\n   ```\n\n2. On macOS, make sure Xcode Command Line Tools are installed:\n   ```\n   xcode-select --install\n   ```\n\n3. Set Python path explicitly:\n   ```\n   npm config set python $(which python3)\n   ```\n\n4. Try installing with a specific version:\n   ```\n   npm install -g @mermaid-js/mermaid-cli@10.8.0\n   npm install -g md2gslides@1.0.0\n   ```\n\n### Error: md2gslides not found or failing\n\n**Solution:**\n\n1. Install md2gslides manually:\n   ```\n   npm install -g md2gslides\n   ```\n\n2. Set up OAuth credentials properly:\n   - Go to https://console.developers.google.com\n   - Create a new project or use an existing one\n   - Enable Google Slides API\n   - Create OAuth 2.0 Client ID (Desktop application)\n   - Download JSON and save as client_id.json in ~/.md2googleslides/\n\n## Claude API Errors\n\n### Error: Invalid JSON from Claude\n\n**Solution:**\n\n1. Use the `--force-json` flag to extract JSON even from malformed responses:\n   ```\n   ./magicSlide.sh guide.md --force-json\n   ```\n\n2. Check the debug file (slides_name.debug.txt) to see what Claude returned\n\n3. Try a different model if available:\n   ```\n   ./magicSlide.sh guide.md --model=claude-3-7-opus-20240229\n   ```\n\n## Mermaid Diagram Errors\n\n### Error: Failed to render mermaid diagram\n\n**Solution:**\n\n1. Manually check the diagram syntax in the .mmd file\n\n2. Try online editor at https://mermaid.live/ to debug\n\n3. Install a specific version of mermaid-cli:\n   ```\n   npm uninstall -g @mermaid-js/mermaid-cli\n   npm install -g @mermaid-js/mermaid-cli@10.8.0\n   ```\n\n## Google Slides Generation Issues\n\nIf you're having trouble with Google Slides generation, you can:\n\n1. Use `--skip-slides` to stop after markdown generation:\n   ```\n   ./magicSlide.sh guide.md --skip-slides\n   ```\n\n2. Manually create slides using md2gslides:\n   ```\n   md2gslides path/to/guide.md --title \"My Presentation\" --use-fileio\n   ```\n\n3. Check OAuth credentials at ~/.md2googleslides/credentials.json and client_id.json\n```\n\n## How to Use the Updated System\n\n1. First, make sure the scripts are executable:\n   ```bash\n   chmod +x magicSlide.sh\n   ```\n\n2. Run the shell script on a single file:\n   ```bash\n   ./magicSlide.sh guides/day5.txt --force-json\n   ```\n   \n   The `--force-json` flag will help with the JSON parsing errors you're encountering.\n\n3. If you still have issues with the npm tools, you can skip the Google Slides generation step:\n   ```bash\n   ./magicSlide.sh guides/day5.txt --force-json --skip-slides\n   ```\n\n4. For directory processing:\n   ```bash\n   ./magicSlide.sh guides/ --force-json\n   ```\n\nThese changes should help with the JSON parsing issues from Claude's responses and provide better error handling for the npm installation problems you encountered. The improved prompt in the config YAML also gives Claude clearer instructions about the format of the JSON output.",
      "created_at": "2025-05-20T10:07:23.081600Z",
      "sequence_order": 9,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2025-05-20T10:05:37.095170Z",
            "stop_timestamp": "2025-05-20T10:05:40.767905Z",
            "flags": null,
            "type": "thinking",
            "thinking": "It looks like there are a couple of issues to fix:\n\n1. **npm Error**: The md2gslides package installation seems to be failing with a gyp error. This might be related to node-gyp which is needed for native dependencies.\n\n2. **Claude JSON Parsing Issue**: The Claude API is returning content that's not valid JSON, causing your parser to fail. The error shows \"Extra data\" at different positions in different attempts.\n\nLet's address these issues one by one:\n\nFor the npm error, we should update the installation instructions in the magicSlide.sh script to better handle dependencies and provide troubleshooting tips.\n\nFor the Claude JSON parsing issue, we need to make the JSON parsing more robust. Claude sometimes returns explanatory text before or after the JSON, especially if it's having trouble generating valid JSON. We should improve the extraction method to find the JSON array or object more reliably.\n\nLet me update these scripts:",
            "summaries": [
              {
                "summary": "Thinking about resolving JSON parsing errors in a script processing a text file"
              },
              {
                "summary": "Troubleshooting npm and Claude JSON parsing errors"
              },
              {
                "summary": "Diagnosed npm and Claude JSON parsing challenges for resolution."
              }
            ],
            "cut_off": false
          },
          {
            "start_timestamp": "2025-05-20T10:05:40.986433Z",
            "stop_timestamp": "2025-05-20T10:07:22.986171Z",
            "flags": null,
            "type": "text",
            "text": "Let's fix the issues you're encountering. It looks like we need to improve the JSON parsing robustness and handle npm installation problems.\n\n## 1. Updated `guide_to_json.py` with Improved JSON Extraction\n\n```python\n#!/usr/bin/env python3\n\"\"\"Convert a facilitator guide into slides.json using Claude 3.\n\nUsage:\n  python guide_to_json.py guide.md \\\n      --config config.yaml \\\n      --out slides.json \\\n      --log-level INFO \\\n      --log-file build.log\n      \n  # Process all markdown files in a folder:\n  python guide_to_json.py guides/ \\\n      --config config.yaml \\\n      --log-level INFO \\\n      --log-file build.log\n\"\"\"\nfrom __future__ import annotations\nimport argparse, json, logging, os, sys, time, yaml, re\nfrom pathlib import Path\nfrom typing import List, Dict, Any\nimport anthropic\n\nDEFAULT_OUT = \"slides.json\"\nDEFAULT_CONFIG = \"config.yaml\"\n\nLOGGER = logging.getLogger(\"guide_to_json\")\n\n\ndef cli() -> argparse.Namespace:\n    p = argparse.ArgumentParser(description=\"LLM → JSON slide outline\")\n    p.add_argument(\"guide\", help=\"Facilitator guide (Markdown/text) or directory of guides\")\n    p.add_argument(\"--config\", default=DEFAULT_CONFIG, help=\"YAML config with prompt template and layout mappings\")\n    p.add_argument(\"--out\", default=None, help=\"Output JSON path (ignored if guide is a directory)\")\n    p.add_argument(\"--log-level\", default=\"INFO\", choices=[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"])\n    p.add_argument(\"--log-file\", default=None, help=\"Write logs to file as well\")\n    p.add_argument(\"--model\", default=\"claude-3-7-sonnet-20250219\", help=\"Claude model to use\")\n    p.add_argument(\"--batch-size\", type=int, default=5, help=\"Number of files to process in parallel (batch mode)\")\n    p.add_argument(\"--force-json\", action=\"store_true\", help=\"Force JSON extraction even if response is not valid JSON\")\n    return p.parse_args()\n\n\ndef setup_logging(level: str, log_file: str | None):\n    handlers: list[logging.Handler] = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    logging.basicConfig(\n        level=level,\n        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n        handlers=handlers,\n    )\n\n\ndef load_config(config_path: Path) -> Dict[str, Any]:\n    \"\"\"Load YAML configuration file with prompt template and layout mappings.\"\"\"\n    if not config_path.exists():\n        LOGGER.warning(\"Config file %s not found, using defaults\", config_path)\n        return {\n            \"prompt_template\": \"{{content}}\",\n            \"layout_mappings\": {},\n            \"slide_defaults\": {}\n        }\n    \n    with open(config_path, 'r') as f:\n        config = yaml.safe_load(f)\n    \n    # Ensure required keys exist\n    config.setdefault(\"prompt_template\", \"{{content}}\")\n    config.setdefault(\"layout_mappings\", {})\n    config.setdefault(\"slide_defaults\", {})\n    \n    return config\n\n\ndef build_prompt(template: str, guide_text: str) -> str:\n    \"\"\"Insert guide text into prompt template.\"\"\"\n    if \"{{content}}\" not in template:\n        LOGGER.error(\"Prompt template missing {{content}} placeholder\")\n        sys.exit(1)\n    return template.replace(\"{{content}}\", guide_text)\n\n\n# Insert missing keys and correct ordering\nORDER = [\n    \"slide_number\", \"title\", \"content\", \"layout\", \"chart_type\", \"diagram_type\", \"diagram_content\",\n    \"image_description\", \"image_url\", \"facilitator_notes\", \"start_time\", \"end_time\",\n    \"materials\", \"worksheet\", \"improvements\", \"notes\",\n]\n\n\ndef normalize(slides: list[dict], layout_mappings: Dict[str, str], slide_defaults: Dict[str, Any]) -> list[dict]:\n    \"\"\"Normalize slides by adding missing keys and applying layout mappings.\"\"\"\n    fixed = []\n    for idx, raw in enumerate(slides, 1):\n        # Apply defaults\n        for key, value in slide_defaults.items():\n            raw.setdefault(key, value)\n        \n        # Set slide number\n        raw.setdefault(\"slide_number\", idx)\n        \n        # Apply layout mapping if available\n        layout = raw.get(\"layout\")\n        if not layout:\n            # Determine layout based on content\n            if idx == 1:\n                raw[\"layout\"] = \"TITLE\"\n            elif raw.get(\"image_url\") or raw.get(\"diagram_type\"):\n                raw[\"layout\"] = \"TITLE_AND_TWO_COLUMNS\"\n            else:\n                raw[\"layout\"] = \"TITLE_AND_BODY\"\n        \n        # Apply custom layout mappings\n        if layout in layout_mappings:\n            raw[\"layout\"] = layout_mappings[layout]\n        \n        # Ensure all other keys exist\n        raw.setdefault(\"chart_type\", None)\n        raw.setdefault(\"image_description\", None)\n        raw.setdefault(\"image_url\", None)\n        for key in ORDER:\n            raw.setdefault(key, None)\n        \n        # Create ordered dictionary\n        fixed.append({k: raw.get(k) for k in ORDER})\n    \n    return fixed\n\n\ndef extract_json(text: str, force: bool = False) -> list:\n    \"\"\"Extract JSON array from text, even if surrounded by non-JSON content.\"\"\"\n    # Try to find a JSON array using regex\n    array_match = re.search(r'(\\[\\s*{.*}\\s*\\])', text, re.DOTALL)\n    if array_match:\n        try:\n            return json.loads(array_match.group(1))\n        except json.JSONDecodeError:\n            pass  # Fall through to other methods\n    \n    # Look for common JSON array start/end\n    start_idx = text.find('[')\n    end_idx = text.rfind(']')\n    \n    if start_idx != -1 and end_idx != -1 and start_idx < end_idx:\n        try:\n            return json.loads(text[start_idx:end_idx+1])\n        except json.JSONDecodeError:\n            pass  # Fall through to other methods\n    \n    # If force enabled, try to extract JSON objects and build an array\n    if force:\n        LOGGER.warning(\"Attempting to force JSON extraction from malformed response\")\n        objects = re.findall(r'{\\s*\"slide_number\"\\s*:.*?}', text, re.DOTALL)\n        if objects:\n            result = []\n            for obj_str in objects:\n                try:\n                    # Replace any trailing commas that would make the JSON invalid\n                    obj_str = re.sub(r',\\s*}', '}', obj_str)\n                    obj = json.loads(obj_str)\n                    result.append(obj)\n                except json.JSONDecodeError:\n                    continue\n            \n            if result:\n                LOGGER.info(f\"Successfully extracted {len(result)} slide objects\")\n                return result\n    \n    raise json.JSONDecodeError(\"Could not extract valid JSON from response\", text, 0)\n\n\ndef process_guide(guide_path: Path, config: Dict[str, Any], out_path: Path | None, model: str, client: anthropic.Anthropic, force_json: bool = False) -> Path:\n    \"\"\"Process a single guide file and return the output path.\"\"\"\n    LOGGER.info(\"Processing guide: %s\", guide_path)\n    \n    # Determine output path\n    if not out_path:\n        out_path = guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n    \n    # Read guide and build prompt\n    guide_txt = guide_path.read_text(encoding=\"utf-8\")\n    prompt = build_prompt(config[\"prompt_template\"], guide_txt)\n    \n    # Request Claude with retries\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            LOGGER.info(\"Requesting Claude (%s) for %s...\", model, guide_path.name)\n            rsp = client.messages.create(\n                model=model,\n                max_tokens=16_000,\n                system=\"Return JSON only. Your response should be a valid JSON array of slide objects, each with slide_number, title, content, and other fields.\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            )\n            \n            raw = rsp.content[0].text\n            \n            # Try to extract JSON from the response\n            try:\n                slides = extract_json(raw, force_json)\n            except json.JSONDecodeError as e:\n                if attempt < max_attempts - 1:\n                    LOGGER.warning(\"Invalid JSON from Claude: %s, retrying in %d seconds...\", e, 2 ** attempt)\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    LOGGER.error(\"Invalid JSON from Claude after %d attempts: %s\", max_attempts, e)\n                    \n                    # Debug: Save the raw response to a file for inspection\n                    debug_path = out_path.with_suffix(\".debug.txt\")\n                    debug_path.write_text(raw)\n                    LOGGER.error(f\"Saved raw response to {debug_path} for debugging\")\n                    \n                    raise\n            \n            # Normalize and save\n            slides = normalize(slides, config[\"layout_mappings\"], config[\"slide_defaults\"])\n            out_path.write_text(json.dumps(slides, indent=2, ensure_ascii=False))\n            LOGGER.info(\"Wrote %d slides → %s\", len(slides), out_path)\n            return out_path\n            \n        except (anthropic.APIError, anthropic.APITimeoutError, anthropic.APIConnectionError) as e:\n            if attempt < max_attempts - 1:\n                LOGGER.warning(\"API error (attempt %d/%d): %s. Retrying in %d seconds...\", \n                            attempt + 1, max_attempts, e, 2 ** attempt)\n                time.sleep(2 ** attempt)\n            else:\n                LOGGER.error(\"API error after %d attempts: %s\", max_attempts, e, exc_info=True)\n                raise\n    \n    raise RuntimeError(\"Failed to process guide, this should not happen\")  # Unreachable\n\n\ndef process_directory(guide_dir: Path, config: Dict[str, Any], model: str, batch_size: int, client: anthropic.Anthropic, force_json: bool = False) -> List[Path]:\n    \"\"\"Process all markdown files in a directory.\"\"\"\n    LOGGER.info(\"Processing all markdown files in: %s\", guide_dir)\n    \n    # Find all markdown and text files\n    md_files = list(guide_dir.glob(\"*.md\")) + list(guide_dir.glob(\"*.txt\"))\n    if not md_files:\n        LOGGER.error(\"No markdown or text files found in %s\", guide_dir)\n        sys.exit(1)\n    \n    LOGGER.info(\"Found %d files to process\", len(md_files))\n    \n    # Process files in batches to avoid overwhelming the API\n    results = []\n    for i in range(0, len(md_files), batch_size):\n        batch = md_files[i:i + batch_size]\n        LOGGER.info(\"Processing batch %d/%d (%d files)\", i // batch_size + 1, \n                   (len(md_files) + batch_size - 1) // batch_size, len(batch))\n        \n        for guide_path in batch:\n            try:\n                out_path = process_guide(guide_path, config, None, model, client, force_json)\n                results.append(out_path)\n            except Exception as e:\n                LOGGER.error(\"Failed to process %s: %s\", guide_path, e, exc_info=True)\n    \n    return results\n\n\ndef main():\n    args = cli()\n    setup_logging(args.log_level, args.log_file)\n\n    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n    if not api_key:\n        LOGGER.error(\"Set ANTHROPIC_API_KEY environment variable\")\n        sys.exit(1)\n\n    # Load configuration\n    config_path = Path(args.config)\n    config = load_config(config_path)\n    \n    # Validate paths\n    guide_path = Path(args.guide)\n    \n    if not guide_path.exists():\n        LOGGER.error(\"Guide path not found: %s\", guide_path)\n        sys.exit(1)\n    \n    # Initialize Claude client\n    client = anthropic.Anthropic(api_key=api_key)\n    \n    if guide_path.is_dir():\n        LOGGER.info(\"Directory mode: Processing all markdown files in %s\", guide_path)\n        if args.out:\n            LOGGER.warning(\"--out parameter ignored in directory mode\")\n        \n        # Process directory\n        process_directory(guide_path, config, args.model, args.batch_size, client, args.force_json)\n        \n    else:\n        # Single file mode\n        # Determine output path\n        out_path = Path(args.out) if args.out else guide_path.with_name(f\"slides_{guide_path.stem}.json\")\n        \n        # Process single guide\n        process_guide(guide_path, config, out_path, args.model, client, args.force_json)\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 2. Updated `magicSlide.sh` with Better Error Handling and npm Fixes\n\n```bash\n#!/bin/bash\n# magicSlide.sh - One-click slide generation from facilitator guides\n# Usage: ./magicSlide.sh input.md [options]\n#        ./magicSlide.sh directory/ [options]\n\n# Error handling\nset -e  # Exit on error\n\n# Color output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m' # No Color\n\n# Default options\nCONFIG=\"config.yaml\"\nMERMAID_CONFIG=\"mermaid-config.json\"\nLOG_LEVEL=\"INFO\"\nTITLE_PREFIX=\"\"\nSTYLE=\"github\"\nUSE_FILEIO=1\nCLAUDE_MODEL=\"claude-3-7-sonnet-20250219\"\nFORCE_JSON=0\nSKIP_SLIDES=0\n\n# Functions\nprint_usage() {\n  echo \"Usage: $0 <input.md or directory> [options]\"\n  echo \"Options:\"\n  echo \"  --config=FILE         YAML config file (default: config.yaml)\"\n  echo \"  --mermaid-config=FILE Mermaid config file (default: mermaid-config.json)\"\n  echo \"  --no-fileio           Don't use file.io for image uploads\"\n  echo \"  --title-prefix=TEXT   Add prefix to presentation titles\"\n  echo \"  --style=STYLE         Code highlighting style (default: github)\"\n  echo \"  --model=MODEL         Claude model (default: claude-3-7-sonnet-20250219)\"\n  echo \"  --log-level=LEVEL     Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)\"\n  echo \"  --force-json          Force JSON extraction even if Claude response is invalid\"\n  echo \"  --skip-slides         Skip Google Slides generation (stop after markdown)\"\n  echo \"  --help                Show this help message\"\n}\n\ncheck_npm_deps() {\n  if ! command -v mmdc &> /dev/null; then\n    echo -e \"${YELLOW}Mermaid CLI not found. Installing...${NC}\"\n    echo \"This may take a moment...\"\n    \n    # Install mermaid-cli with specific version to avoid compatibility issues\n    npm install -g @mermaid-js/mermaid-cli@10.8.0\n    \n    if [ $? -ne 0 ]; then\n      echo -e \"${RED}Failed to install Mermaid CLI.${NC}\"\n      echo \"If you're having issues with node-gyp, try:\"\n      echo \"  1. npm install -g node-gyp\"\n      echo \"  2. xcode-select --install (on macOS)\"\n      echo \"  3. npm config set python /path/to/python3\"\n      echo \"Then try running this script again.\"\n      exit 1\n    fi\n  fi\n  \n  if ! command -v md2gslides &> /dev/null && [ $SKIP_SLIDES -eq 0 ]; then\n    echo -e \"${YELLOW}md2gslides not found. Installing...${NC}\"\n    \n    # Install md2gslides\n    npm install -g md2gslides\n    \n    if [ $? -ne 0 ]; then\n      echo -e \"${RED}Failed to install md2gslides.${NC}\"\n      echo \"You can continue without Google Slides generation.\"\n      echo \"To install manually: npm install -g md2gslides\"\n      SKIP_SLIDES=1\n    fi\n  fi\n}\n\n# Parse arguments\nINPUT=\"\"\nfor arg in \"$@\"; do\n  case $arg in\n    --config=*)\n      CONFIG=\"${arg#*=}\"\n      ;;\n    --mermaid-config=*)\n      MERMAID_CONFIG=\"${arg#*=}\"\n      ;;\n    --no-fileio)\n      USE_FILEIO=0\n      ;;\n    --title-prefix=*)\n      TITLE_PREFIX=\"${arg#*=}\"\n      ;;\n    --style=*)\n      STYLE=\"${arg#*=}\"\n      ;;\n    --model=*)\n      CLAUDE_MODEL=\"${arg#*=}\"\n      ;;\n    --log-level=*)\n      LOG_LEVEL=\"${arg#*=}\"\n      ;;\n    --force-json)\n      FORCE_JSON=1\n      ;;\n    --skip-slides)\n      SKIP_SLIDES=1\n      ;;\n    --help)\n      print_usage\n      exit 0\n      ;;\n    -*)\n      echo -e \"${RED}Unknown option: $arg${NC}\"\n      print_usage\n      exit 1\n      ;;\n    *)\n      if [ -z \"$INPUT\" ]; then\n        INPUT=\"$arg\"\n      else\n        echo -e \"${RED}Multiple input files specified. Use only one.${NC}\"\n        print_usage\n        exit 1\n      fi\n      ;;\n  esac\ndone\n\n# Check for required input\nif [ -z \"$INPUT\" ]; then\n  echo -e \"${RED}Error: No input file or directory specified.${NC}\"\n  print_usage\n  exit 1\nfi\n\n# Check npm dependencies\ncheck_npm_deps\n\n# Determine input type\nif [ -d \"$INPUT\" ]; then\n  # Directory mode\n  echo -e \"${BLUE}🔍 Processing directory: $INPUT${NC}\"\n  WORKING_DIR=\"$INPUT\"\n  DIR_MODE=1\nelse\n  # Single file mode\n  echo -e \"${BLUE}🔍 Processing file: $INPUT${NC}\"\n  WORKING_DIR=\"$(dirname \"$INPUT\")\"\n  BASENAME=\"$(basename \"$INPUT\" .md)\"\n  BASENAME=\"${BASENAME%.txt}\"  # Also strip .txt if present\n  DIR_MODE=0\nfi\n\n# Create/verify necessary directories\nIMAGES_DIR=\"$WORKING_DIR/images\"\nmkdir -p \"$IMAGES_DIR\"\n\n# Optional force-json flag\nFORCE_JSON_ARG=\"\"\nif [ $FORCE_JSON -eq 1 ]; then\n  FORCE_JSON_ARG=\"--force-json\"\nfi\n\necho -e \"${GREEN}Step 1/4: 🧠 Converting to JSON with Claude...${NC}\"\nif [ $DIR_MODE -eq 1 ]; then\n  python guide_to_json.py \"$INPUT\" --config=\"$CONFIG\" --model=\"$CLAUDE_MODEL\" --log-level=\"$LOG_LEVEL\" $FORCE_JSON_ARG\n  if [ $? -ne 0 ]; then\n    echo -e \"${RED}Failed to convert guides to JSON. Check the error message above.${NC}\"\n    echo \"You can try using --force-json to extract JSON even from malformed responses.\"\n    exit 1\n  fi\nelse\n  JSON_FILE=\"$WORKING_DIR/slides_$BASENAME.json\"\n  python guide_to_json.py \"$INPUT\" --config=\"$CONFIG\" --out=\"$JSON_FILE\" --model=\"$CLAUDE_MODEL\" --log-level=\"$LOG_LEVEL\" $FORCE_JSON_ARG\n  if [ $? -ne 0 ]; then\n    echo -e \"${RED}Failed to convert guide to JSON. Check the error message above.${NC}\"\n    echo \"You can try using --force-json to extract JSON even from malformed responses.\"\n    exit 1\n  fi\nfi\n\necho -e \"${GREEN}Step 2/4: 📊 Rendering diagrams...${NC}\"\nif [ $DIR_MODE -eq 1 ]; then\n  python diagrams_to_images.py \"$INPUT\" --mermaid-config=\"$MERMAID_CONFIG\" --output-dir=\"$IMAGES_DIR\" --log-level=\"$LOG_LEVEL\"\n  if [ $? -ne 0 ]; then\n    echo -e \"${YELLOW}Warning: Some diagrams may have failed to render.${NC}\"\n  fi\nelse\n  python diagrams_to_images.py \"$JSON_FILE\" --mermaid-config=\"$MERMAID_CONFIG\" --output-dir=\"$IMAGES_DIR\" --log-level=\"$LOG_LEVEL\"\n  if [ $? -ne 0 ]; then\n    echo -e \"${YELLOW}Warning: Some diagrams may have failed to render.${NC}\"\n  fi\nfi\n\necho -e \"${GREEN}Step 3/4: 📝 Converting to markdown...${NC}\"\nif [ $DIR_MODE -eq 1 ]; then\n  python json_to_markdown.py \"$INPUT\" --prefer-svg --log-level=\"$LOG_LEVEL\"\n  if [ $? -ne 0 ]; then\n    echo -e \"${RED}Failed to convert JSON to markdown.${NC}\"\n    exit 1\n  fi\nelse\n  python json_to_markdown.py \"$JSON_FILE\" --prefer-svg --log-level=\"$LOG_LEVEL\"\n  if [ $? -ne 0 ]; then\n    echo -e \"${RED}Failed to convert JSON to markdown.${NC}\"\n    exit 1\n  fi\nfi\n\nif [ $SKIP_SLIDES -eq 1 ]; then\n  echo -e \"${YELLOW}Skipping Google Slides generation as requested.${NC}\"\n  echo -e \"${GREEN}✅ Completed! Markdown files are ready.${NC}\"\n  exit 0\nfi\n\necho -e \"${GREEN}Step 4/4: 🎯 Generating Google Slides...${NC}\"\nFILEIO_ARG=\"\"\nif [ $USE_FILEIO -eq 1 ]; then\n  FILEIO_ARG=\"--use-fileio\"\nfi\n\nif [ $DIR_MODE -eq 1 ]; then\n  python build_with_md2gslides.py \"$INPUT\" --title-prefix=\"$TITLE_PREFIX\" --style=\"$STYLE\" $FILEIO_ARG --log-level=\"$LOG_LEVEL\" --output-file=\"$WORKING_DIR/presentations.txt\"\n  if [ $? -ne 0 ]; then\n    echo -e \"${RED}Failed to generate Google Slides. Check the error above.${NC}\"\n    echo \"Your markdown files are still available in $WORKING_DIR.\"\n    exit 1\n  fi\n  echo -e \"${GREEN}📋 Presentation links saved to $WORKING_DIR/presentations.txt${NC}\"\nelse\n  MD_FILE=\"$WORKING_DIR/$BASENAME.md\"\n  python build_with_md2gslides.py \"$MD_FILE\" --title-prefix=\"$TITLE_PREFIX\" --style=\"$STYLE\" $FILEIO_ARG --log-level=\"$LOG_LEVEL\" --output-file=\"$WORKING_DIR/$BASENAME-presentation.txt\"\n  if [ $? -ne 0 ]; then\n    echo -e \"${RED}Failed to generate Google Slides. Check the error above.${NC}\"\n    echo \"Your markdown file is still available at $MD_FILE.\"\n    exit 1\n  fi\n  echo -e \"${GREEN}📋 Presentation link saved to $WORKING_DIR/$BASENAME-presentation.txt${NC}\"\nfi\n\necho -e \"${GREEN}✅ All done! Your slides are ready.${NC}\"\n```\n\n## 3. Example `config.yaml` with Improved Prompt\n\n```yaml\n# Improved prompt template for guide_to_json.py\nprompt_template: |\n  Convert the following facilitator guide into a detailed JSON slides outline.\n  \n  The output MUST be a valid JSON array of slide objects, each with the following structure:\n  \n  ```json\n  [\n    {\n      \"slide_number\": 1,\n      \"title\": \"Title text (max 60 chars)\",\n      \"content\": \"• Bullet point content\\n• Another bullet point\",\n      \"layout\": \"TITLE\",\n      \"chart_type\": null,\n      \"diagram_type\": null,\n      \"diagram_content\": null,\n      \"image_description\": null,\n      \"image_url\": null,\n      \"facilitator_notes\": \"Notes for the presenter\",\n      \"start_time\": null,\n      \"end_time\": null,\n      \"materials\": null,\n      \"worksheet\": null,\n      \"improvements\": null,\n      \"notes\": null\n    },\n    // Additional slides...\n  ]\n  ```\n  \n  Available layouts:\n  - TITLE (first slide only)\n  - TITLE_AND_BODY (standard slide with title and content)\n  - TITLE_AND_TWO_COLUMNS (title with two columns of content)\n  - MAIN_POINT (big text for emphasis)\n  - SECTION_HEADER (section divider)\n  - BIG_NUMBER (for emphasis of statistics)\n  - CAPTION (for slides with images)\n  \n  DO NOT include any explanatory text before or after the JSON array.\n  Just return the array containing all slides.\n  \n  Here's the guide content:\n  \n  {{content}}\n\n# Custom layout mappings (from your layout to md2gslides layout)\nlayout_mappings:\n  \"title\": \"TITLE\"\n  \"section\": \"SECTION_HEADER\"\n  \"image\": \"CAPTION\"\n  \"columns\": \"TITLE_AND_TWO_COLUMNS\"\n  \"main_point\": \"MAIN_POINT\"\n  \"big_number\": \"BIG_NUMBER\"\n\n# Default values for all slides\nslide_defaults:\n  \"chart_type\": null\n  \"image_url\": null\n```\n\n## 4. Troubleshooting Guide for Common Issues\n\nHere's a short troubleshooting guide you can save as `TROUBLESHOOTING.md`:\n\n```markdown\n# Troubleshooting Guide for magicSlide\n\n## npm Installation Errors\n\n### Error: gyp ERR!\n\nThis usually happens when node-gyp can't compile native extensions.\n\n**Solution:**\n\n1. Install node-gyp globally:\n   ```\n   npm install -g node-gyp\n   ```\n\n2. On macOS, make sure Xcode Command Line Tools are installed:\n   ```\n   xcode-select --install\n   ```\n\n3. Set Python path explicitly:\n   ```\n   npm config set python $(which python3)\n   ```\n\n4. Try installing with a specific version:\n   ```\n   npm install -g @mermaid-js/mermaid-cli@10.8.0\n   npm install -g md2gslides@1.0.0\n   ```\n\n### Error: md2gslides not found or failing\n\n**Solution:**\n\n1. Install md2gslides manually:\n   ```\n   npm install -g md2gslides\n   ```\n\n2. Set up OAuth credentials properly:\n   - Go to https://console.developers.google.com\n   - Create a new project or use an existing one\n   - Enable Google Slides API\n   - Create OAuth 2.0 Client ID (Desktop application)\n   - Download JSON and save as client_id.json in ~/.md2googleslides/\n\n## Claude API Errors\n\n### Error: Invalid JSON from Claude\n\n**Solution:**\n\n1. Use the `--force-json` flag to extract JSON even from malformed responses:\n   ```\n   ./magicSlide.sh guide.md --force-json\n   ```\n\n2. Check the debug file (slides_name.debug.txt) to see what Claude returned\n\n3. Try a different model if available:\n   ```\n   ./magicSlide.sh guide.md --model=claude-3-7-opus-20240229\n   ```\n\n## Mermaid Diagram Errors\n\n### Error: Failed to render mermaid diagram\n\n**Solution:**\n\n1. Manually check the diagram syntax in the .mmd file\n\n2. Try online editor at https://mermaid.live/ to debug\n\n3. Install a specific version of mermaid-cli:\n   ```\n   npm uninstall -g @mermaid-js/mermaid-cli\n   npm install -g @mermaid-js/mermaid-cli@10.8.0\n   ```\n\n## Google Slides Generation Issues\n\nIf you're having trouble with Google Slides generation, you can:\n\n1. Use `--skip-slides` to stop after markdown generation:\n   ```\n   ./magicSlide.sh guide.md --skip-slides\n   ```\n\n2. Manually create slides using md2gslides:\n   ```\n   md2gslides path/to/guide.md --title \"My Presentation\" --use-fileio\n   ```\n\n3. Check OAuth credentials at ~/.md2googleslides/credentials.json and client_id.json\n```\n\n## How to Use the Updated System\n\n1. First, make sure the scripts are executable:\n   ```bash\n   chmod +x magicSlide.sh\n   ```\n\n2. Run the shell script on a single file:\n   ```bash\n   ./magicSlide.sh guides/day5.txt --force-json\n   ```\n   \n   The `--force-json` flag will help with the JSON parsing errors you're encountering.\n\n3. If you still have issues with the npm tools, you can skip the Google Slides generation step:\n   ```bash\n   ./magicSlide.sh guides/day5.txt --force-json --skip-slides\n   ```\n\n4. For directory processing:\n   ```bash\n   ./magicSlide.sh guides/ --force-json\n   ```\n\nThese changes should help with the JSON parsing issues from Claude's responses and provide better error handling for the npm installation problems you encountered. The improved prompt in the config YAML also gives Claude clearer instructions about the format of the JSON output.",
            "citations": []
          }
        ],
        "updated_at": "2025-05-20T10:07:23.081600Z",
        "attachments": [],
        "files": []
      }
    }
  ]
}