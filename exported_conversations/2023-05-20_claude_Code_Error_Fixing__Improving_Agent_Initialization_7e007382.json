{
  "id": "7e007382-3e6f-4dc8-ad82-bac72ff5fecb",
  "source": "claude",
  "title": "Code Error Fixing; Improving Agent Initialization",
  "created_at": "2023-05-20T16:51:06.542329Z",
  "updated_at": "2023-05-20T19:01:49.432032Z",
  "summary": "",
  "message_count": 36,
  "messages": [
    {
      "id": "b8de07ad-f21d-4fab-82ce-d58b1899220c",
      "role": "human",
      "content": "help me clean up this code I'm getting this error connection handler failed Traceback (most recent call last): File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler await self.ws\\_handler(self) File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 108, in handle\\_add\\_agents if isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]): AttributeError: 'ParliamentServer' object has no attribute 'agent\\_instance' here: From server.py class ParliamentServer: def **init**(self, host=\"localhost\", port=8080): self.host = host self.port = port self.parliament = None self.start\\_server = serve(self.chat, self.host, self.port) def configure\\_openai(self): async def chat(self, websocket, path): async for message in websocket: data = json.loads(message) action = data.get(\"action\") if action == SET\\_PARLIAMENT: await self.handle\\_set\\_parliament(websocket, data) elif action == SEND\\_MESSAGE: await self.handle\\_send\\_message(websocket, data) elif action == ADD\\_AGENTS: await self.handle\\_add\\_agents(websocket, data) elif action in \\[TYPING, STOPPED\\_TYPING\\]: await self.handle\\_typing(websocket, data) async def handle\\_typing(self, websocket, data): sender = data.get('sender') action = data.get('action') is\\_typing = action == TYPING self.parliament.set\\_typing\\_status(sender, is\\_typing) # Send the typing status update to other clients: await websocket.send(json.dumps({ \"action\": action, \"sender\": sender, \"is\\_typing\": is\\_typing })) async def handle\\_set\\_parliament(self, websocket, data): parliament\\_name = data.get(\"name\") if parliament\\_name: self.parliament = Parliament(parliament\\_name) async def handle\\_send\\_message(self, websocket, data): if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return sender = data.get(\"sender\") user\\_message = data.get(\"message\") timestamp = datetime.now() await websocket.send(json.dumps({ \"action\": RECEIVE\\_MESSAGE, \"message\": user\\_message, \"sender\": sender, \"timestamp\": timestamp.isoformat()})) await self.parliament.broadcast\\_message(user\\_message, sender, timestamp) # Sending agent info after broadcasting message agent\\_info = await self.parliament.get\\_agents\\_info() await websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info})) await self.update\\_queue(websocket) async def handle\\_add\\_agents(self, websocket, data): if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return agents\\_data = data.get(\"agents\") if not agents\\_data: await self.send\\_error(websocket, \"No agent data provided.\") return for agent\\_data in agents\\_data: agent\\_name = agent\\_data.get(\"name\") # Extract the name speaking\\_pressure\\_increment = int(agent\\_data.get(\"speaking\\_pressure\\_increment\")) other\\_agents = \", \".join(\\[agent\\['name'\\] for agent in agents\\_data if agent\\['name'\\] != agent\\_name\\]) initial\\_context = ( f\"Hello 00\" ) agent\\_type = agent\\_data.get(\"type\") agent\\_class = self.parliament.agent\\_types.get(agent\\_type) # Get OpenAIAgent or GPT4AllAgent agent\\_instance = agent\\_class(initial\\_context) # Properly instantiate the class if isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]): agent\\_instance = OpenAIAgent(initial\\_context) # Create the OpenAIAgent instance agent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket) self.parliament.add\\_agent(agent) # Pass the agent instance to add\\_agent else: return \"Sorry, I'm unable to generate a relevant response at this time.\" await self.send\\_error(websocket, f\"Unknown agent type: {agent\\_type}\") continue async def update\\_queue(self, websocket): if self.parliament: speaking\\_queue = self.parliament.get\\_speaking\\_queue() await websocket.send(json.dumps({\"action\": UPDATE\\_QUEUE, \"queue\": speaking\\_queue})) async def send\\_error(self, websocket, message): await websocket.send(json.dumps({\"action\": ERROR, \"message\": message})) def run(self): self.configure\\_openai() asyncio.get\\_event\\_loop().run\\_until\\_complete(self.start\\_server) asyncio.get\\_event\\_loop().run\\_forever() if **name** == \"\\_\\_main\\_\\_\": server = ParliamentServer() server.run() this is parliament.py: PRESSURE\\_INCREMENT\\_INTERVAL = 15 SPEAKING\\_PRESSURE\\_LIMIT = 100 BROADCAST\\_DELAY = 10 RELEVANCY\\_THRESHOLD = 100 STOPPED\\_TYPING = \"stopped\\_typing\" UPDATE\\_AGENTS = \"update\\_agents\" class Agent: def **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None): self.name = agent\\_name self.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment self.context = initial\\_context self.initial\\_context = initial\\_context self.speaking\\_pressure = speaking\\_pressure\\_increment self.tagged = False self.agent\\_type = agent\\_type self.agent\\_instance = agent\\_instance self.websocket = websocket self.parliament = parliament self.is\\_speaking = False self.relevancy\\_score = None def get\\_response(self, truncated\\_chat\\_history): agent\\_message = self.get\\_agent\\_message(truncated\\_chat\\_history) return agent\\_message def in\\_queue(self): return self.name in self.parliament.speaking\\_queue async def calculate\\_relevancy(self, chat\\_context): relevancy\\_score = 0 if self.relevancy\\_score is None or self.initial\\_context != chat\\_context: prompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\" response = openai.Completion.create( engine=\"text-davinci-001\", # or \"text-curie-002\" for Curie prompt=prompt, temperature=0.0, max\\_tokens=300 ) # Here we assume the model's response will be a single number. # The strip is used to remove any whitespace around the number stripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text) try: relevancy\\_score = int(stripped\\_response) except ValueError: relevancy\\_score = 0 else: time.sleep(.5) return relevancy\\_score def should\\_speak(self): return self.parliament.speaker\\_manager.should\\_speak(self) # Call parliament's speaker\\_manager async def increment\\_pressure(self): while True: self.speaking\\_pressure += self.speaking\\_pressure\\_increment async def get\\_agent\\_message(self, truncated\\_chat\\_history): \"\"\" Generate a message from this agent based on the current chat history. \"\"\" message = \"\" if isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]): response = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history) message = f\"{response}\" return message def in\\_queue(self): return self.name in self.parliament.speaking\\_queue.queue async def speak(self): truncated\\_chat\\_history = self.parliament.chat\\_history.truncated\\_chat\\_history if self.should\\_speak(): self.is\\_speaking = True await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name})) await self.websocket.send(json.dumps({\"action\": STOPPED\\_TYPING, \"sender\": self.name})) agent\\_message = await self.get\\_response(self.parliament.chat\\_history.truncated\\_chat\\_history) await self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name})) self.speaking\\_pressure = 0 self.is\\_speaking = False if self.in\\_queue(): self.parliament.speaking\\_queue.remove(self.name) def reset\\_pressure(self): self.speaking\\_pressure = 0 class Parliament: def **init**(self, name: str): self.name = name self.speaker\\_manager = SpeakerManager(self) self.agents = {} self.chat\\_history = ChatHistory() self.speaking\\_queue = \\[\\] self.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent} self.typing\\_status = {} def set\\_typing\\_status(self, agent\\_name: str, status: bool): self.typing\\_status\\[agent\\_name\\] = status def get\\_typing\\_status(self, agent\\_name: str): return self.typing\\_status.get(agent\\_name, False) async def broadcast\\_message(self, message, sender, timestamp): # Assign a value to first\\_agent\\_in\\_queue before using it first\\_agent\\_in\\_queue = self.speaking\\_queue\\[0\\] if self.speaking\\_queue else None if first\\_agent\\_in\\_queue and not self.get\\_typing\\_status(first\\_agent\\_in\\_queue): await self.agents\\[first\\_agent\\_in\\_queue\\].speak() self.chat\\_history.add(message, sender, timestamp) mentioned\\_agents = self.identify\\_and\\_tag\\_mentioned\\_agents(message) self.increment\\_speaking\\_pressure(mentioned\\_agents) await self.update\\_speaking\\_queue() for agent in self.agents.values(): if not self.get\\_typing\\_status(agent.name): await agent.speak() await asyncio.sleep(BROADCAST\\_DELAY) first\\_agent\\_in\\_queue = self.speaking\\_queue.pop(0) if self.speaking\\_queue else None if first\\_agent\\_in\\_queue and not self.get\\_typing\\_status(first\\_agent\\_in\\_queue): await self.agents\\[first\\_agent\\_in\\_queue\\].speak() def add\\_to\\_speaking\\_queue(self, agent): if agent.name not in self.speaking\\_queue: self.speaking\\_queue.append(agent) def increment\\_speaking\\_pressure(self, mentioned\\_agents): for agent in self.agents.values(): if agent.name not in mentioned\\_agents: agent.speaking\\_pressure += agent.speaking\\_pressure\\_increment def identify\\_and\\_tag\\_mentioned\\_agents(self, message): mentioned\\_agents = \\[\\] for agent\\_name in self.agents: if '@'+agent\\_name in message: mentioned\\_agents.append(agent\\_name) self.agents\\[agent\\_name\\].speaking\\_pressure = SPEAKING\\_PRESSURE\\_LIMIT self.agents\\[agent\\_name\\].tagged = True return mentioned\\_agents def get\\_speaking\\_queue(self): return self.speaking\\_queue def add\\_agent(self, agent: Agent): self.agents\\[agent.name\\] = agent self.typing\\_status\\[agent.name\\] = False def remove\\_agent(self, agent\\_name: str): if agent\\_name not in self.agents: raise ValueError(f\"Agent '{agent\\_name}' not found.\") del self.agents\\[agent\\_name\\] def get\\_agent(self, agent\\_name: str): if agent\\_name not in self.agents: raise ValueError(f\"Agent '{agent\\_name}' not found.\") return self.agents\\[agent\\_name\\] def add\\_to\\_chat\\_history(self, message, sender, timestamp): self.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp}) def add\\_tagged\\_agents\\_to\\_queue(self): for agent in self.agents.values(): if agent.tagged and agent.name not in self.speaking\\_queue.queue: self.speaking\\_queue.add(agent.name) agent.tagged = False agent.speaking\\_pressure = 0 # Reset speaking pressure def add\\_high\\_pressure\\_agents\\_to\\_queue(self): for agent in self.agents.values(): if agent.speaking\\_pressure > 100 and agent.name not in self.speaking\\_queue.queue: self.speaking\\_queue.add(agent.name) agent.speaking\\_pressure = 0 # Reset speaking pressure async def trigger\\_next\\_speaker(self): if self.speaking\\_queue: next\\_speaker\\_name = self.speaking\\_queue.pop(0) next\\_speaker = self.get\\_agent(next\\_speaker\\_name) response = await next\\_speaker.get\\_response(self.chat\\_history.truncated\\_chat\\_history) async def update\\_speaking\\_queue(self): \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\" most\\_relevant\\_agent = None highest\\_relevancy\\_score = -1 for agent in self.agents.values(): truncated\\_chat\\_history = self.chat\\_history.truncated\\_chat\\_history relevancy\\_score = await agent.calculate\\_relevancy(truncated\\_chat\\_history) if relevancy\\_score > highest\\_relevancy\\_score: highest\\_relevancy\\_score = relevancy\\_score most\\_relevant\\_agent = agent # Add the most relevant agent to the speaking queue if most\\_relevant\\_agent and self.speaking\\_queue.count(most\\_relevant\\_agent.name) == 0: self.speaking\\_queue.insert(0, most\\_relevant\\_agent.name) print(f\"Added agent {most\\_relevant\\_agent.name} to the front of the speaking queue. Current queue: {self.speaking\\_queue}\") self.add\\_tagged\\_agents\\_to\\_queue() self.add\\_high\\_pressure\\_agents\\_to\\_queue() await self.trigger\\_next\\_speaker() #def get\\_sorted\\_agents\\_based\\_on\\_relevancy(self): # return sorted(self.agents.values(), key=lambda agent: agent.calculate\\_relevancy(self.chat\\_history) if agent.calculate\\_relevancy(self.chat\\_history) is not None else 0, reverse=True) async def get\\_agents\\_info(self) -> List\\[dict\\]: agents\\_info = \\[\\] for agent\\_name, agent in self.agents.items(): agents\\_info.append({ \"name\": agent\\_name, \"speaking\\_pressure\": agent.speaking\\_pressure, \"speaking\\_pressure\\_increment\": agent.speaking\\_pressure\\_increment, \"context\": agent.context, \"agent\\_type\": agent.agent\\_type, \"relevancy\\_score\": agent.relevancy\\_score # Return the cached score }) return agents\\_info",
      "created_at": "2023-05-20T16:51:13.723236Z",
      "sequence_order": 0,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T16:51:13.723236Z",
            "stop_timestamp": "2023-05-20T16:51:13.723236Z",
            "flags": null,
            "type": "text",
            "text": "help me clean up this code I'm getting this error connection handler failed Traceback (most recent call last): File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler await self.ws\\_handler(self) File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 108, in handle\\_add\\_agents if isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]): AttributeError: 'ParliamentServer' object has no attribute 'agent\\_instance' here: From server.py class ParliamentServer: def **init**(self, host=\"localhost\", port=8080): self.host = host self.port = port self.parliament = None self.start\\_server = serve(self.chat, self.host, self.port) def configure\\_openai(self): async def chat(self, websocket, path): async for message in websocket: data = json.loads(message) action = data.get(\"action\") if action == SET\\_PARLIAMENT: await self.handle\\_set\\_parliament(websocket, data) elif action == SEND\\_MESSAGE: await self.handle\\_send\\_message(websocket, data) elif action == ADD\\_AGENTS: await self.handle\\_add\\_agents(websocket, data) elif action in \\[TYPING, STOPPED\\_TYPING\\]: await self.handle\\_typing(websocket, data) async def handle\\_typing(self, websocket, data): sender = data.get('sender') action = data.get('action') is\\_typing = action == TYPING self.parliament.set\\_typing\\_status(sender, is\\_typing) # Send the typing status update to other clients: await websocket.send(json.dumps({ \"action\": action, \"sender\": sender, \"is\\_typing\": is\\_typing })) async def handle\\_set\\_parliament(self, websocket, data): parliament\\_name = data.get(\"name\") if parliament\\_name: self.parliament = Parliament(parliament\\_name) async def handle\\_send\\_message(self, websocket, data): if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return sender = data.get(\"sender\") user\\_message = data.get(\"message\") timestamp = datetime.now() await websocket.send(json.dumps({ \"action\": RECEIVE\\_MESSAGE, \"message\": user\\_message, \"sender\": sender, \"timestamp\": timestamp.isoformat()})) await self.parliament.broadcast\\_message(user\\_message, sender, timestamp) # Sending agent info after broadcasting message agent\\_info = await self.parliament.get\\_agents\\_info() await websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info})) await self.update\\_queue(websocket) async def handle\\_add\\_agents(self, websocket, data): if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return agents\\_data = data.get(\"agents\") if not agents\\_data: await self.send\\_error(websocket, \"No agent data provided.\") return for agent\\_data in agents\\_data: agent\\_name = agent\\_data.get(\"name\") # Extract the name speaking\\_pressure\\_increment = int(agent\\_data.get(\"speaking\\_pressure\\_increment\")) other\\_agents = \", \".join(\\[agent\\['name'\\] for agent in agents\\_data if agent\\['name'\\] != agent\\_name\\]) initial\\_context = ( f\"Hello 00\" ) agent\\_type = agent\\_data.get(\"type\") agent\\_class = self.parliament.agent\\_types.get(agent\\_type) # Get OpenAIAgent or GPT4AllAgent agent\\_instance = agent\\_class(initial\\_context) # Properly instantiate the class if isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]): agent\\_instance = OpenAIAgent(initial\\_context) # Create the OpenAIAgent instance agent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket) self.parliament.add\\_agent(agent) # Pass the agent instance to add\\_agent else: return \"Sorry, I'm unable to generate a relevant response at this time.\" await self.send\\_error(websocket, f\"Unknown agent type: {agent\\_type}\") continue async def update\\_queue(self, websocket): if self.parliament: speaking\\_queue = self.parliament.get\\_speaking\\_queue() await websocket.send(json.dumps({\"action\": UPDATE\\_QUEUE, \"queue\": speaking\\_queue})) async def send\\_error(self, websocket, message): await websocket.send(json.dumps({\"action\": ERROR, \"message\": message})) def run(self): self.configure\\_openai() asyncio.get\\_event\\_loop().run\\_until\\_complete(self.start\\_server) asyncio.get\\_event\\_loop().run\\_forever() if **name** == \"\\_\\_main\\_\\_\": server = ParliamentServer() server.run() this is parliament.py: PRESSURE\\_INCREMENT\\_INTERVAL = 15 SPEAKING\\_PRESSURE\\_LIMIT = 100 BROADCAST\\_DELAY = 10 RELEVANCY\\_THRESHOLD = 100 STOPPED\\_TYPING = \"stopped\\_typing\" UPDATE\\_AGENTS = \"update\\_agents\" class Agent: def **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None): self.name = agent\\_name self.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment self.context = initial\\_context self.initial\\_context = initial\\_context self.speaking\\_pressure = speaking\\_pressure\\_increment self.tagged = False self.agent\\_type = agent\\_type self.agent\\_instance = agent\\_instance self.websocket = websocket self.parliament = parliament self.is\\_speaking = False self.relevancy\\_score = None def get\\_response(self, truncated\\_chat\\_history): agent\\_message = self.get\\_agent\\_message(truncated\\_chat\\_history) return agent\\_message def in\\_queue(self): return self.name in self.parliament.speaking\\_queue async def calculate\\_relevancy(self, chat\\_context): relevancy\\_score = 0 if self.relevancy\\_score is None or self.initial\\_context != chat\\_context: prompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\" response = openai.Completion.create( engine=\"text-davinci-001\", # or \"text-curie-002\" for Curie prompt=prompt, temperature=0.0, max\\_tokens=300 ) # Here we assume the model's response will be a single number. # The strip is used to remove any whitespace around the number stripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text) try: relevancy\\_score = int(stripped\\_response) except ValueError: relevancy\\_score = 0 else: time.sleep(.5) return relevancy\\_score def should\\_speak(self): return self.parliament.speaker\\_manager.should\\_speak(self) # Call parliament's speaker\\_manager async def increment\\_pressure(self): while True: self.speaking\\_pressure += self.speaking\\_pressure\\_increment async def get\\_agent\\_message(self, truncated\\_chat\\_history): \"\"\" Generate a message from this agent based on the current chat history. \"\"\" message = \"\" if isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]): response = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history) message = f\"{response}\" return message def in\\_queue(self): return self.name in self.parliament.speaking\\_queue.queue async def speak(self): truncated\\_chat\\_history = self.parliament.chat\\_history.truncated\\_chat\\_history if self.should\\_speak(): self.is\\_speaking = True await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name})) await self.websocket.send(json.dumps({\"action\": STOPPED\\_TYPING, \"sender\": self.name})) agent\\_message = await self.get\\_response(self.parliament.chat\\_history.truncated\\_chat\\_history) await self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name})) self.speaking\\_pressure = 0 self.is\\_speaking = False if self.in\\_queue(): self.parliament.speaking\\_queue.remove(self.name) def reset\\_pressure(self): self.speaking\\_pressure = 0 class Parliament: def **init**(self, name: str): self.name = name self.speaker\\_manager = SpeakerManager(self) self.agents = {} self.chat\\_history = ChatHistory() self.speaking\\_queue = \\[\\] self.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent} self.typing\\_status = {} def set\\_typing\\_status(self, agent\\_name: str, status: bool): self.typing\\_status\\[agent\\_name\\] = status def get\\_typing\\_status(self, agent\\_name: str): return self.typing\\_status.get(agent\\_name, False) async def broadcast\\_message(self, message, sender, timestamp): # Assign a value to first\\_agent\\_in\\_queue before using it first\\_agent\\_in\\_queue = self.speaking\\_queue\\[0\\] if self.speaking\\_queue else None if first\\_agent\\_in\\_queue and not self.get\\_typing\\_status(first\\_agent\\_in\\_queue): await self.agents\\[first\\_agent\\_in\\_queue\\].speak() self.chat\\_history.add(message, sender, timestamp) mentioned\\_agents = self.identify\\_and\\_tag\\_mentioned\\_agents(message) self.increment\\_speaking\\_pressure(mentioned\\_agents) await self.update\\_speaking\\_queue() for agent in self.agents.values(): if not self.get\\_typing\\_status(agent.name): await agent.speak() await asyncio.sleep(BROADCAST\\_DELAY) first\\_agent\\_in\\_queue = self.speaking\\_queue.pop(0) if self.speaking\\_queue else None if first\\_agent\\_in\\_queue and not self.get\\_typing\\_status(first\\_agent\\_in\\_queue): await self.agents\\[first\\_agent\\_in\\_queue\\].speak() def add\\_to\\_speaking\\_queue(self, agent): if agent.name not in self.speaking\\_queue: self.speaking\\_queue.append(agent) def increment\\_speaking\\_pressure(self, mentioned\\_agents): for agent in self.agents.values(): if agent.name not in mentioned\\_agents: agent.speaking\\_pressure += agent.speaking\\_pressure\\_increment def identify\\_and\\_tag\\_mentioned\\_agents(self, message): mentioned\\_agents = \\[\\] for agent\\_name in self.agents: if '@'+agent\\_name in message: mentioned\\_agents.append(agent\\_name) self.agents\\[agent\\_name\\].speaking\\_pressure = SPEAKING\\_PRESSURE\\_LIMIT self.agents\\[agent\\_name\\].tagged = True return mentioned\\_agents def get\\_speaking\\_queue(self): return self.speaking\\_queue def add\\_agent(self, agent: Agent): self.agents\\[agent.name\\] = agent self.typing\\_status\\[agent.name\\] = False def remove\\_agent(self, agent\\_name: str): if agent\\_name not in self.agents: raise ValueError(f\"Agent '{agent\\_name}' not found.\") del self.agents\\[agent\\_name\\] def get\\_agent(self, agent\\_name: str): if agent\\_name not in self.agents: raise ValueError(f\"Agent '{agent\\_name}' not found.\") return self.agents\\[agent\\_name\\] def add\\_to\\_chat\\_history(self, message, sender, timestamp): self.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp}) def add\\_tagged\\_agents\\_to\\_queue(self): for agent in self.agents.values(): if agent.tagged and agent.name not in self.speaking\\_queue.queue: self.speaking\\_queue.add(agent.name) agent.tagged = False agent.speaking\\_pressure = 0 # Reset speaking pressure def add\\_high\\_pressure\\_agents\\_to\\_queue(self): for agent in self.agents.values(): if agent.speaking\\_pressure > 100 and agent.name not in self.speaking\\_queue.queue: self.speaking\\_queue.add(agent.name) agent.speaking\\_pressure = 0 # Reset speaking pressure async def trigger\\_next\\_speaker(self): if self.speaking\\_queue: next\\_speaker\\_name = self.speaking\\_queue.pop(0) next\\_speaker = self.get\\_agent(next\\_speaker\\_name) response = await next\\_speaker.get\\_response(self.chat\\_history.truncated\\_chat\\_history) async def update\\_speaking\\_queue(self): \"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\" most\\_relevant\\_agent = None highest\\_relevancy\\_score = -1 for agent in self.agents.values(): truncated\\_chat\\_history = self.chat\\_history.truncated\\_chat\\_history relevancy\\_score = await agent.calculate\\_relevancy(truncated\\_chat\\_history) if relevancy\\_score > highest\\_relevancy\\_score: highest\\_relevancy\\_score = relevancy\\_score most\\_relevant\\_agent = agent # Add the most relevant agent to the speaking queue if most\\_relevant\\_agent and self.speaking\\_queue.count(most\\_relevant\\_agent.name) == 0: self.speaking\\_queue.insert(0, most\\_relevant\\_agent.name) print(f\"Added agent {most\\_relevant\\_agent.name} to the front of the speaking queue. Current queue: {self.speaking\\_queue}\") self.add\\_tagged\\_agents\\_to\\_queue() self.add\\_high\\_pressure\\_agents\\_to\\_queue() await self.trigger\\_next\\_speaker() #def get\\_sorted\\_agents\\_based\\_on\\_relevancy(self): # return sorted(self.agents.values(), key=lambda agent: agent.calculate\\_relevancy(self.chat\\_history) if agent.calculate\\_relevancy(self.chat\\_history) is not None else 0, reverse=True) async def get\\_agents\\_info(self) -> List\\[dict\\]: agents\\_info = \\[\\] for agent\\_name, agent in self.agents.items(): agents\\_info.append({ \"name\": agent\\_name, \"speaking\\_pressure\": agent.speaking\\_pressure, \"speaking\\_pressure\\_increment\": agent.speaking\\_pressure\\_increment, \"context\": agent.context, \"agent\\_type\": agent.agent\\_type, \"relevancy\\_score\": agent.relevancy\\_score # Return the cached score }) return agents\\_info",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T16:51:13.723236Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "eda2f879-5caa-48a9-9b96-f63e09f70364",
      "role": "assistant",
      "content": " Here are some things I noticed:\n\n1. The error is occurring because self.agent_instance is undefined. This is likely because the agent instance was not properly initialized for the given agent type. You'll need to add a check to properly instantiate the agent class for the given agent_type.\n\n2. The code is quite long and complex. I would suggest breaking it up into smaller, more focused functions and classes. Some suggestions:\n\n- Extract the Agent class into its own file. \n- Extract the chat history into its own ChatHistory class.\n- Extract the speaker manager into its own SpeakerManager class.\n\nThis will make the code more readable and maintainable.\n\n3. There is some duplicated logic that can be extracted, e.g. the logic to add agents to the speaking queue is duplicated in a few places. This can be extracted into a function.\n\n4. The variable names could be improved for clarity, e.g. first_agent_in_queue is not very descriptive. queue_head or next_speaker may be better.\n\n5. Some of the logic can be simplified. For example, the logic to get the agent response in Agent.speak() can be extracted into the get_response() method to avoid the nested if check.\n\n6. More type hints can be added for static type checking.\n\nHere is a revised version that addresses some of these points:\n\n```python\nfrom datetime import datetime \nimport json\nimport openai\n\nPRESSURE_INCREMENT_INTERVAL = 15 \nSPEAKING_PRESSURE_LIMIT = 100 \nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100 \nSTOPPED_TYPING = \"stopped_typing\" \nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    ...\n\nclass ChatHistory:\n    ...   \n\nclass SpeakerManager:\n    ...  \n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue: Deque = deque()\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {}\n\n    def add_agent(self, agent: Agent):\n        ...\n        \n    def set_typing_status(self, agent_name: str, status: bool):\n        ...  \n\n    async def get_response(self, agent_name: str) -> str:\n        agent = self.get_agent(agent_name)\n        return await agent.get_response(self.chat_history.truncated_chat_history)\n        \n    async def broadcast_message(self, message, sender, timestamp): \n        ...\n        queue_head = self.speaking_queue.popleft() if self.speaking_queue else None\n        if queue_head and not self.get_typing_status(queue_head):\n            await self.get_response(queue_head)  # Use extracted method\n        ...         \n```\n\nHope this helps! Let me know if you have any other questions.",
      "created_at": "2023-05-20T16:52:15.451118Z",
      "sequence_order": 1,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T16:52:15.451118Z",
            "stop_timestamp": "2023-05-20T16:52:15.451118Z",
            "flags": null,
            "type": "text",
            "text": " Here are some things I noticed:\n\n1. The error is occurring because self.agent_instance is undefined. This is likely because the agent instance was not properly initialized for the given agent type. You'll need to add a check to properly instantiate the agent class for the given agent_type.\n\n2. The code is quite long and complex. I would suggest breaking it up into smaller, more focused functions and classes. Some suggestions:\n\n- Extract the Agent class into its own file. \n- Extract the chat history into its own ChatHistory class.\n- Extract the speaker manager into its own SpeakerManager class.\n\nThis will make the code more readable and maintainable.\n\n3. There is some duplicated logic that can be extracted, e.g. the logic to add agents to the speaking queue is duplicated in a few places. This can be extracted into a function.\n\n4. The variable names could be improved for clarity, e.g. first_agent_in_queue is not very descriptive. queue_head or next_speaker may be better.\n\n5. Some of the logic can be simplified. For example, the logic to get the agent response in Agent.speak() can be extracted into the get_response() method to avoid the nested if check.\n\n6. More type hints can be added for static type checking.\n\nHere is a revised version that addresses some of these points:\n\n```python\nfrom datetime import datetime \nimport json\nimport openai\n\nPRESSURE_INCREMENT_INTERVAL = 15 \nSPEAKING_PRESSURE_LIMIT = 100 \nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100 \nSTOPPED_TYPING = \"stopped_typing\" \nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    ...\n\nclass ChatHistory:\n    ...   \n\nclass SpeakerManager:\n    ...  \n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue: Deque = deque()\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {}\n\n    def add_agent(self, agent: Agent):\n        ...\n        \n    def set_typing_status(self, agent_name: str, status: bool):\n        ...  \n\n    async def get_response(self, agent_name: str) -> str:\n        agent = self.get_agent(agent_name)\n        return await agent.get_response(self.chat_history.truncated_chat_history)\n        \n    async def broadcast_message(self, message, sender, timestamp): \n        ...\n        queue_head = self.speaking_queue.popleft() if self.speaking_queue else None\n        if queue_head and not self.get_typing_status(queue_head):\n            await self.get_response(queue_head)  # Use extracted method\n        ...         \n```\n\nHope this helps! Let me know if you have any other questions.",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T16:52:15.451118Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "2cc23c63-ea7e-4bc8-845f-1cabc1a53d99",
      "role": "human",
      "content": "I want to remove the concept of the queue from this code. Instead I want the code to update everyone's relevancy when the app first loads based on the parliament topic. And then I want the user to click reply in the right hand side where there is reply buttons near the relevancy percentage. Rather than this complicated queue I'd rather it be more user driven.",
      "created_at": "2023-05-20T17:08:58.597225Z",
      "sequence_order": 2,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:08:58.597225Z",
            "stop_timestamp": "2023-05-20T17:08:58.597225Z",
            "flags": null,
            "type": "text",
            "text": "I want to remove the concept of the queue from this code. Instead I want the code to update everyone's relevancy when the app first loads based on the parliament topic. And then I want the user to click reply in the right hand side where there is reply buttons near the relevancy percentage. Rather than this complicated queue I'd rather it be more user driven.",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:08:58.597225Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "a3a656af-101d-464c-a366-49420a4565df",
      "role": "assistant",
      "content": " That sounds like a good simplification. Here are some suggestions to implement that:\n\n1. Remove the speaking_queue attribute from Parliament. You no longer need it.\n\n2. Add a topic attribute to Parliament to store the current topic.\n\n3. On startup, calculate the relevancy of all agents based on the topic and store it on the agent. You can do this with:\n\n```python\nfor agent in self.agents.values():\n    relevancy = await agent.calculate_relevancy(self.topic)\n    agent.relevancy_score = relevancy \n```\n\n4. Add \"reply\" buttons next to each agent in the UI, with the relevancy score shown.\n\n5. When a \"reply\" button is clicked for an agent, simply call `await agent.speak()` to have that agent respond.\n\n6. You no longer need the logic to add agents to the speaking queue or pop from the queue. Remove all of that logic.\n\n7. The agents can still have their speaking pressure and get incremented when mentioned to indicate they are \"eager\" to speak next, but the actual speaking will be entirely based on the user clicking the reply buttons.\n\n8. You may want to add a timeout mechanism to have agents automatically respond after a period of no user input, to keep the conversation moving. But the primary driver of responses will be the user selecting agents to reply.\n\nThe updated logic could look something like this:\n\n```python\nclass Parliament:\n    def __init__(self):\n        self.topic = \"some topic\"\n        self.agents = {...}\n        \n    async def startup(self):\n        for agent in self.agents.values():\n            relevancy = await agent.calculate_relevancy(self.topic)\n            agent.relevancy_score = relevancy \n            \n    async def agent_reply(self, agent_name):\n        agent = self.get_agent(agent_name)\n        await agent.speak()  # Agent responds\n        \n    async def receive_user_message(self, message):\n        ...\n        # Increment speaking pressure but no queue\n        ...\n```\n\nLet me know if you have any other questions!",
      "created_at": "2023-05-20T17:09:16.111752Z",
      "sequence_order": 3,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:09:16.111752Z",
            "stop_timestamp": "2023-05-20T17:09:16.111752Z",
            "flags": null,
            "type": "text",
            "text": " That sounds like a good simplification. Here are some suggestions to implement that:\n\n1. Remove the speaking_queue attribute from Parliament. You no longer need it.\n\n2. Add a topic attribute to Parliament to store the current topic.\n\n3. On startup, calculate the relevancy of all agents based on the topic and store it on the agent. You can do this with:\n\n```python\nfor agent in self.agents.values():\n    relevancy = await agent.calculate_relevancy(self.topic)\n    agent.relevancy_score = relevancy \n```\n\n4. Add \"reply\" buttons next to each agent in the UI, with the relevancy score shown.\n\n5. When a \"reply\" button is clicked for an agent, simply call `await agent.speak()` to have that agent respond.\n\n6. You no longer need the logic to add agents to the speaking queue or pop from the queue. Remove all of that logic.\n\n7. The agents can still have their speaking pressure and get incremented when mentioned to indicate they are \"eager\" to speak next, but the actual speaking will be entirely based on the user clicking the reply buttons.\n\n8. You may want to add a timeout mechanism to have agents automatically respond after a period of no user input, to keep the conversation moving. But the primary driver of responses will be the user selecting agents to reply.\n\nThe updated logic could look something like this:\n\n```python\nclass Parliament:\n    def __init__(self):\n        self.topic = \"some topic\"\n        self.agents = {...}\n        \n    async def startup(self):\n        for agent in self.agents.values():\n            relevancy = await agent.calculate_relevancy(self.topic)\n            agent.relevancy_score = relevancy \n            \n    async def agent_reply(self, agent_name):\n        agent = self.get_agent(agent_name)\n        await agent.speak()  # Agent responds\n        \n    async def receive_user_message(self, message):\n        ...\n        # Increment speaking pressure but no queue\n        ...\n```\n\nLet me know if you have any other questions!",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:09:16.111752Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "0479f115-9298-48bd-891f-998e044c3bc6",
      "role": "human",
      "content": "Can you update this entire parliament.py file with those ideas and give it to me in one go?\n\nimport asyncio\n\nimport re\n\nimport random\n\nimport json\n\nimport openai\n\nfrom openai.error import RateLimitError\n\nimport time\n\nfrom typing import List\n\nfrom collections import deque\n\nPRESSURE\\_INCREMENT\\_INTERVAL = 15\n\nSPEAKING\\_PRESSURE\\_LIMIT = 100\n\nBROADCAST\\_DELAY = 10\n\nRELEVANCY\\_THRESHOLD = 100\n\nSTOPPED\\_TYPING = \"stopped\\_typing\"\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nclass Agent:\n\ndef **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None):\n\nself.name = agent\\_name\n\nself.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment\n\nself.context = initial\\_context\n\nself.initial\\_context = initial\\_context\n\nself.speaking\\_pressure = speaking\\_pressure\\_increment\n\nself.tagged = False\n\nself.agent\\_type = agent\\_type\n\nself.agent\\_instance = agent\\_instance\n\nself.websocket = websocket\n\nself.parliament = parliament\n\nself.is\\_speaking = False\n\nself.relevancy\\_score = None\n\ndef get\\_response(self, truncated\\_chat\\_history):\n\nagent\\_message = self.get\\_agent\\_message(truncated\\_chat\\_history)\n\nreturn agent\\_message\n\ndef in\\_queue(self):\n\nreturn self.name in self.parliament.speaking\\_queue\n\nasync def calculate\\_relevancy(self, chat\\_context):\n\nrelevancy\\_score = 0\n\nif self.relevancy\\_score is None or self.initial\\_context != chat\\_context:\n\nprint(\"Calculating relevancy...\")\n\nprompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n\nprint(f\"Prompt: {prompt}\")\n\nresponse = openai.Completion.create(\n\nengine=\"text-davinci-001\", # or \"text-curie-002\" for Curie\n\nprompt=prompt,\n\ntemperature=0.0,\n\nmax\\_tokens=300\n\n)\n\nprint(f\"Response: {response}\")\n\n\\# Here we assume the model's response will be a single number.\n\n\\# The strip is used to remove any whitespace around the number\n\nstripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text)\n\ntry:\n\nrelevancy\\_score = int(stripped\\_response)\n\nexcept ValueError:\n\nrelevancy\\_score = 0\n\nprint(f\"Relevancy score: {relevancy\\_score}\")\n\nelse:\n\nprint(\"Relevancy score already calculated.\")\n\ntime.sleep(.5)\n\nreturn relevancy\\_score\n\ndef should\\_speak(self):\n\nreturn self.parliament.speaker\\_manager.should\\_speak(self) # Call parliament's speaker\\_manager\n\nasync def increment\\_pressure(self):\n\nwhile True:\n\nself.speaking\\_pressure += self.speaking\\_pressure\\_increment\n\nasync def get\\_agent\\_message(self, truncated\\_chat\\_history):\n\n\"\"\"\n\nGenerate a message from this agent based on the current chat history.\n\n\"\"\"\n\nmessage = \"\"\n\nif isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]):\n\nresponse = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history)\n\nmessage = f\"{response}\"\n\nreturn message\n\ndef in\\_queue(self):\n\nreturn self.name in self.parliament.speaking\\_queue.queue\n\nasync def speak(self):\n\ntruncated\\_chat\\_history = self.parliament.chat\\_history.truncated\\_chat\\_history\n\nif self.should\\_speak():\n\nself.is\\_speaking = True\n\nawait self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n\nawait self.websocket.send(json.dumps({\"action\": STOPPED\\_TYPING, \"sender\": self.name}))\n\nagent\\_message = await self.get\\_response(self.parliament.chat\\_history.truncated\\_chat\\_history)\n\nawait self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name}))\n\nself.speaking\\_pressure = 0\n\nself.is\\_speaking = False\n\nif self.in\\_queue():\n\nself.parliament.speaking\\_queue.remove(self.name)\n\ndef reset\\_pressure(self):\n\nself.speaking\\_pressure = 0\n\nclass ChatHistory:\n\ndef **init**(self):\n\nself.chat\\_history = \\[\\]\n\nself.truncated\\_chat\\_history = \"\"\n\ndef add(self, message, sender, timestamp):\n\nself.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\nself.truncate\\_chat\\_history()\n\ndef truncate\\_chat\\_history(self, max\\_length=2000):\n\n\"\"\"\n\nTruncate the chat history to the last max\\_length characters.\n\n\"\"\"\n\nchat\\_history\\_str = '\\\\n'.join(\\[message\\[\"message\"\\] for message in self.chat\\_history\\])\n\nself.truncated\\_chat\\_history = chat\\_history\\_str\\[-max\\_length:\\]\n\ndef last\\_message(self):\n\nreturn self.chat\\_history\\[-1\\] if self.chat\\_history else None\n\nclass SpeakerManager:\n\ndef **init**(self, parliament):\n\nself.parliament = parliament\n\ndef should\\_speak(self, agent):\n\nreturn self.parliament.speaking\\_queue\\[0\\] == agent.name if self.parliament.speaking\\_queue else False\n\nclass OpenAIAgent:\n\ndef **init**(self, initial\\_context: str):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\"\n\nself.model = \"gpt-3.5-turbo\"\n\nself.initial\\_context = initial\\_context\n\ndef get\\_response(self, truncated\\_chat):\n\nsystem\\_msg = self.initial\\_context\n\nmessages=\\[\\]\n\nmessages.append({\"role\": \"assistant\", \"content\": truncated\\_chat})\n\nmax\\_retries = 3\n\nretry\\_delay = 5\n\nfor i in range(max\\_retries):\n\ntry:\n\n\\# Call the OpenAI API with the messages array\n\nresponse = openai.ChatCompletion.create(\n\nmodel=self.model,\n\nmessages=messages,\n\nmax\\_tokens=150,\n\ntemperature=0.5,\n\ntop\\_p=1,\n\nfrequency\\_penalty=0,\n\npresence\\_penalty=0,\n\n)\n\n\\# Extract and return the assistant's response from the API response\n\nagent\\_response = response.choices\\[0\\].message\\[\"content\"\\].strip()\n\nprint(f\" {agent\\_response}\") # Add logging\n\nreturn agent\\_response\n\nexcept RateLimitError as e:\n\nprint(f\"Rate limit error: {e}. Retrying in {retry\\_delay} seconds...\")\n\nif i < max\\_retries - 1: # Don't sleep on the last iteration\n\ntime.sleep(retry\\_delay)\n\nelse:\n\nraise\n\nreturn \"Sorry, I am unable to respond at the moment.\"\n\nclass GPT4AllAgent:\n\ndef **init**(self):\n\n\\# Download and set up the GPT4All model\n\nself.\\_initialize\\_gpt4all\\_model()\n\nself.\\_initialize\\_llm\\_chain()\n\ndef _initialize_gpt4all\\_model(self):\n\nlocal\\_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n\nPath(local\\_path).parent.mkdir(parents=True, exist\\_ok=True)\n\nurl = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n\nresponse = requests.get(url, stream=True)\n\nwith open(local\\_path, 'wb') as f:\n\nfor chunk in tqdm(response.iter\\_content(chunk\\_size=8192)):\n\nif chunk:\n\nf.write(chunk)\n\nself.model\\_path = local\\_path\n\ndef _initialize_llm\\_chain(self):\n\ntemplate = \"\"\"{chat\\_history}\n\nQuestion: {question}\n\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input\\_variables=\\[\"chat\\_history\", \"question\"\\])\n\ncallbacks = \\[StreamingStdOutCallbackHandler()\\]\n\nllm = GPT4All(model=self.model\\_path, callbacks=callbacks, verbose=True)\n\nself.llm\\_chain = LLMChain(prompt=prompt, llm=llm)\n\ndef get\\_response(self, chat\\_history, question):\n\nreturn self.llm\\_chain.run(chat\\_history=chat\\_history, question=question)\n\nclass Parliament:\n\ndef **init**(self, name: str):\n\nself.name = name\n\nself.speaker\\_manager = SpeakerManager(self)\n\nself.agents = {}\n\nself.chat\\_history = ChatHistory()\n\nself.speaking\\_queue = \\[\\]\n\nself.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n\nself.typing\\_status = {}\n\ndef set\\_typing\\_status(self, agent\\_name: str, status: bool):\n\nself.typing\\_status\\[agent\\_name\\] = status\n\ndef get\\_typing\\_status(self, agent\\_name: str):\n\nreturn self.typing\\_status.get(agent\\_name, False)\n\nasync def broadcast\\_message(self, message, sender, timestamp):\n\n\\# Assign a value to first\\_agent\\_in\\_queue before using it\n\nfirst\\_agent\\_in\\_queue = self.speaking\\_queue\\[0\\] if self.speaking\\_queue else None\n\nif first\\_agent\\_in\\_queue and not self.get\\_typing\\_status(first\\_agent\\_in\\_queue):\n\nawait self.agents\\[first\\_agent\\_in\\_queue\\].speak()\n\nself.chat\\_history.add(message, sender, timestamp)\n\nmentioned\\_agents = self.identify\\_and\\_tag\\_mentioned\\_agents(message)\n\nself.increment\\_speaking\\_pressure(mentioned\\_agents)\n\nawait self.update\\_speaking\\_queue()\n\nfor agent in self.agents.values():\n\nif not self.get\\_typing\\_status(agent.name):\n\nawait agent.speak()\n\nawait asyncio.sleep(BROADCAST\\_DELAY)\n\nfirst\\_agent\\_in\\_queue = self.speaking\\_queue.pop(0) if self.speaking\\_queue else None\n\nif first\\_agent\\_in\\_queue and not self.get\\_typing\\_status(first\\_agent\\_in\\_queue):\n\nawait self.agents\\[first\\_agent\\_in\\_queue\\].speak()\n\ndef add\\_to\\_speaking\\_queue(self, agent):\n\nif agent.name not in self.speaking\\_queue:\n\nself.speaking\\_queue.append(agent)\n\ndef increment\\_speaking\\_pressure(self, mentioned\\_agents):\n\nfor agent in self.agents.values():\n\nif agent.name not in mentioned\\_agents:\n\nagent.speaking\\_pressure += agent.speaking\\_pressure\\_increment\n\ndef identify\\_and\\_tag\\_mentioned\\_agents(self, message):\n\nmentioned\\_agents = \\[\\]\n\nfor agent\\_name in self.agents:\n\nif '@'+agent\\_name in message:\n\nmentioned\\_agents.append(agent\\_name)\n\nself.agents\\[agent\\_name\\].speaking\\_pressure = SPEAKING\\_PRESSURE\\_LIMIT\n\nself.agents\\[agent\\_name\\].tagged = True\n\nreturn mentioned\\_agents\n\ndef get\\_speaking\\_queue(self):\n\nreturn self.speaking\\_queue\n\ndef add\\_agent(self, agent: Agent):\n\nself.agents\\[agent.name\\] = agent\n\nself.typing\\_status\\[agent.name\\] = False\n\ndef remove\\_agent(self, agent\\_name: str):\n\nif agent\\_name not in self.agents:\n\nraise ValueError(f\"Agent '{agent\\_name}' not found.\")\n\ndel self.agents\\[agent\\_name\\]\n\ndef get\\_agent(self, agent\\_name: str):\n\nif agent\\_name not in self.agents:\n\nraise ValueError(f\"Agent '{agent\\_name}' not found.\")\n\nreturn self.agents\\[agent\\_name\\]\n\ndef add\\_to\\_chat\\_history(self, message, sender, timestamp):\n\nself.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\ndef add\\_tagged\\_agents\\_to\\_queue(self):\n\nfor agent in self.agents.values():\n\nif agent.tagged and agent.name not in self.speaking\\_queue.queue:\n\nself.speaking\\_queue.add(agent.name)\n\nagent.tagged = False\n\nagent.speaking\\_pressure = 0 # Reset speaking pressure\n\ndef add\\_high\\_pressure\\_agents\\_to\\_queue(self):\n\nfor agent in self.agents.values():\n\nif agent.speaking\\_pressure > 100 and agent.name not in self.speaking\\_queue.queue:\n\nself.speaking\\_queue.add(agent.name)\n\nagent.speaking\\_pressure = 0 # Reset speaking pressure\n\nasync def trigger\\_next\\_speaker(self):\n\nif self.speaking\\_queue:\n\nnext\\_speaker\\_name = self.speaking\\_queue.pop(0)\n\nnext\\_speaker = self.get\\_agent(next\\_speaker\\_name)\n\nresponse = next\\_speaker.get\\_response(self.chat\\_history.truncated\\_chat\\_history)\n\nprint(f\"The next speaker is: {next\\_speaker.name}\")\n\nprint(f\"Message: {response}\")\n\nasync def update\\_speaking\\_queue(self):\n\n\"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n\nmost\\_relevant\\_agent = None\n\nhighest\\_relevancy\\_score = -1\n\nfor agent in self.agents.values():\n\ntruncated\\_chat\\_history = self.chat\\_history.truncated\\_chat\\_history\n\nrelevancy\\_score = await agent.calculate\\_relevancy(truncated\\_chat\\_history)\n\nif relevancy\\_score > highest\\_relevancy\\_score:\n\nhighest\\_relevancy\\_score = relevancy\\_score\n\nmost\\_relevant\\_agent = agent\n\nprint(f\"Calculated relevancy for agent {agent.name}. Score: {relevancy\\_score}\")\n\n\\# Add the most relevant agent to the speaking queue\n\nif most\\_relevant\\_agent and self.speaking\\_queue.count(most\\_relevant\\_agent.name) == 0:\n\nself.speaking\\_queue.insert(0, most\\_relevant\\_agent.name)\n\nprint(f\"Added agent {most\\_relevant\\_agent.name} to the front of the speaking queue. Current queue: {self.speaking\\_queue}\")\n\nself.add\\_tagged\\_agents\\_to\\_queue()\n\nself.add\\_high\\_pressure\\_agents\\_to\\_queue()\n\nprint(f\"Triggering next speaker...\")\n\nawait self.trigger\\_next\\_speaker()\n\n#def get\\_sorted\\_agents\\_based\\_on\\_relevancy(self):\n\n\\# return sorted(self.agents.values(), key=lambda agent: agent.calculate\\_relevancy(self.chat\\_history) if agent.calculate\\_relevancy(self.chat\\_history) is not None else 0, reverse=True)\n\nasync def get\\_agents\\_info(self) -> List\\[dict\\]:\n\nagents\\_info = \\[\\]\n\nfor agent\\_name, agent in self.agents.items():\n\nagents\\_info.append({\n\n\"name\": agent\\_name,\n\n\"speaking\\_pressure\": agent.speaking\\_pressure,\n\n\"speaking\\_pressure\\_increment\": agent.speaking\\_pressure\\_increment,\n\n\"context\": agent.context,\n\n\"agent\\_type\": agent.agent\\_type,\n\n\"relevancy\\_score\": agent.relevancy\\_score # Return the cached score\n\n})\n\nreturn agents\\_info",
      "created_at": "2023-05-20T17:09:39.645394Z",
      "sequence_order": 4,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:09:39.645394Z",
            "stop_timestamp": "2023-05-20T17:09:39.645394Z",
            "flags": null,
            "type": "text",
            "text": "Can you update this entire parliament.py file with those ideas and give it to me in one go?\n\nimport asyncio\n\nimport re\n\nimport random\n\nimport json\n\nimport openai\n\nfrom openai.error import RateLimitError\n\nimport time\n\nfrom typing import List\n\nfrom collections import deque\n\nPRESSURE\\_INCREMENT\\_INTERVAL = 15\n\nSPEAKING\\_PRESSURE\\_LIMIT = 100\n\nBROADCAST\\_DELAY = 10\n\nRELEVANCY\\_THRESHOLD = 100\n\nSTOPPED\\_TYPING = \"stopped\\_typing\"\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nclass Agent:\n\ndef **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None):\n\nself.name = agent\\_name\n\nself.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment\n\nself.context = initial\\_context\n\nself.initial\\_context = initial\\_context\n\nself.speaking\\_pressure = speaking\\_pressure\\_increment\n\nself.tagged = False\n\nself.agent\\_type = agent\\_type\n\nself.agent\\_instance = agent\\_instance\n\nself.websocket = websocket\n\nself.parliament = parliament\n\nself.is\\_speaking = False\n\nself.relevancy\\_score = None\n\ndef get\\_response(self, truncated\\_chat\\_history):\n\nagent\\_message = self.get\\_agent\\_message(truncated\\_chat\\_history)\n\nreturn agent\\_message\n\ndef in\\_queue(self):\n\nreturn self.name in self.parliament.speaking\\_queue\n\nasync def calculate\\_relevancy(self, chat\\_context):\n\nrelevancy\\_score = 0\n\nif self.relevancy\\_score is None or self.initial\\_context != chat\\_context:\n\nprint(\"Calculating relevancy...\")\n\nprompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n\nprint(f\"Prompt: {prompt}\")\n\nresponse = openai.Completion.create(\n\nengine=\"text-davinci-001\", # or \"text-curie-002\" for Curie\n\nprompt=prompt,\n\ntemperature=0.0,\n\nmax\\_tokens=300\n\n)\n\nprint(f\"Response: {response}\")\n\n\\# Here we assume the model's response will be a single number.\n\n\\# The strip is used to remove any whitespace around the number\n\nstripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text)\n\ntry:\n\nrelevancy\\_score = int(stripped\\_response)\n\nexcept ValueError:\n\nrelevancy\\_score = 0\n\nprint(f\"Relevancy score: {relevancy\\_score}\")\n\nelse:\n\nprint(\"Relevancy score already calculated.\")\n\ntime.sleep(.5)\n\nreturn relevancy\\_score\n\ndef should\\_speak(self):\n\nreturn self.parliament.speaker\\_manager.should\\_speak(self) # Call parliament's speaker\\_manager\n\nasync def increment\\_pressure(self):\n\nwhile True:\n\nself.speaking\\_pressure += self.speaking\\_pressure\\_increment\n\nasync def get\\_agent\\_message(self, truncated\\_chat\\_history):\n\n\"\"\"\n\nGenerate a message from this agent based on the current chat history.\n\n\"\"\"\n\nmessage = \"\"\n\nif isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]):\n\nresponse = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history)\n\nmessage = f\"{response}\"\n\nreturn message\n\ndef in\\_queue(self):\n\nreturn self.name in self.parliament.speaking\\_queue.queue\n\nasync def speak(self):\n\ntruncated\\_chat\\_history = self.parliament.chat\\_history.truncated\\_chat\\_history\n\nif self.should\\_speak():\n\nself.is\\_speaking = True\n\nawait self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n\nawait self.websocket.send(json.dumps({\"action\": STOPPED\\_TYPING, \"sender\": self.name}))\n\nagent\\_message = await self.get\\_response(self.parliament.chat\\_history.truncated\\_chat\\_history)\n\nawait self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name}))\n\nself.speaking\\_pressure = 0\n\nself.is\\_speaking = False\n\nif self.in\\_queue():\n\nself.parliament.speaking\\_queue.remove(self.name)\n\ndef reset\\_pressure(self):\n\nself.speaking\\_pressure = 0\n\nclass ChatHistory:\n\ndef **init**(self):\n\nself.chat\\_history = \\[\\]\n\nself.truncated\\_chat\\_history = \"\"\n\ndef add(self, message, sender, timestamp):\n\nself.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\nself.truncate\\_chat\\_history()\n\ndef truncate\\_chat\\_history(self, max\\_length=2000):\n\n\"\"\"\n\nTruncate the chat history to the last max\\_length characters.\n\n\"\"\"\n\nchat\\_history\\_str = '\\\\n'.join(\\[message\\[\"message\"\\] for message in self.chat\\_history\\])\n\nself.truncated\\_chat\\_history = chat\\_history\\_str\\[-max\\_length:\\]\n\ndef last\\_message(self):\n\nreturn self.chat\\_history\\[-1\\] if self.chat\\_history else None\n\nclass SpeakerManager:\n\ndef **init**(self, parliament):\n\nself.parliament = parliament\n\ndef should\\_speak(self, agent):\n\nreturn self.parliament.speaking\\_queue\\[0\\] == agent.name if self.parliament.speaking\\_queue else False\n\nclass OpenAIAgent:\n\ndef **init**(self, initial\\_context: str):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\"\n\nself.model = \"gpt-3.5-turbo\"\n\nself.initial\\_context = initial\\_context\n\ndef get\\_response(self, truncated\\_chat):\n\nsystem\\_msg = self.initial\\_context\n\nmessages=\\[\\]\n\nmessages.append({\"role\": \"assistant\", \"content\": truncated\\_chat})\n\nmax\\_retries = 3\n\nretry\\_delay = 5\n\nfor i in range(max\\_retries):\n\ntry:\n\n\\# Call the OpenAI API with the messages array\n\nresponse = openai.ChatCompletion.create(\n\nmodel=self.model,\n\nmessages=messages,\n\nmax\\_tokens=150,\n\ntemperature=0.5,\n\ntop\\_p=1,\n\nfrequency\\_penalty=0,\n\npresence\\_penalty=0,\n\n)\n\n\\# Extract and return the assistant's response from the API response\n\nagent\\_response = response.choices\\[0\\].message\\[\"content\"\\].strip()\n\nprint(f\" {agent\\_response}\") # Add logging\n\nreturn agent\\_response\n\nexcept RateLimitError as e:\n\nprint(f\"Rate limit error: {e}. Retrying in {retry\\_delay} seconds...\")\n\nif i < max\\_retries - 1: # Don't sleep on the last iteration\n\ntime.sleep(retry\\_delay)\n\nelse:\n\nraise\n\nreturn \"Sorry, I am unable to respond at the moment.\"\n\nclass GPT4AllAgent:\n\ndef **init**(self):\n\n\\# Download and set up the GPT4All model\n\nself.\\_initialize\\_gpt4all\\_model()\n\nself.\\_initialize\\_llm\\_chain()\n\ndef _initialize_gpt4all\\_model(self):\n\nlocal\\_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n\nPath(local\\_path).parent.mkdir(parents=True, exist\\_ok=True)\n\nurl = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n\nresponse = requests.get(url, stream=True)\n\nwith open(local\\_path, 'wb') as f:\n\nfor chunk in tqdm(response.iter\\_content(chunk\\_size=8192)):\n\nif chunk:\n\nf.write(chunk)\n\nself.model\\_path = local\\_path\n\ndef _initialize_llm\\_chain(self):\n\ntemplate = \"\"\"{chat\\_history}\n\nQuestion: {question}\n\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input\\_variables=\\[\"chat\\_history\", \"question\"\\])\n\ncallbacks = \\[StreamingStdOutCallbackHandler()\\]\n\nllm = GPT4All(model=self.model\\_path, callbacks=callbacks, verbose=True)\n\nself.llm\\_chain = LLMChain(prompt=prompt, llm=llm)\n\ndef get\\_response(self, chat\\_history, question):\n\nreturn self.llm\\_chain.run(chat\\_history=chat\\_history, question=question)\n\nclass Parliament:\n\ndef **init**(self, name: str):\n\nself.name = name\n\nself.speaker\\_manager = SpeakerManager(self)\n\nself.agents = {}\n\nself.chat\\_history = ChatHistory()\n\nself.speaking\\_queue = \\[\\]\n\nself.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n\nself.typing\\_status = {}\n\ndef set\\_typing\\_status(self, agent\\_name: str, status: bool):\n\nself.typing\\_status\\[agent\\_name\\] = status\n\ndef get\\_typing\\_status(self, agent\\_name: str):\n\nreturn self.typing\\_status.get(agent\\_name, False)\n\nasync def broadcast\\_message(self, message, sender, timestamp):\n\n\\# Assign a value to first\\_agent\\_in\\_queue before using it\n\nfirst\\_agent\\_in\\_queue = self.speaking\\_queue\\[0\\] if self.speaking\\_queue else None\n\nif first\\_agent\\_in\\_queue and not self.get\\_typing\\_status(first\\_agent\\_in\\_queue):\n\nawait self.agents\\[first\\_agent\\_in\\_queue\\].speak()\n\nself.chat\\_history.add(message, sender, timestamp)\n\nmentioned\\_agents = self.identify\\_and\\_tag\\_mentioned\\_agents(message)\n\nself.increment\\_speaking\\_pressure(mentioned\\_agents)\n\nawait self.update\\_speaking\\_queue()\n\nfor agent in self.agents.values():\n\nif not self.get\\_typing\\_status(agent.name):\n\nawait agent.speak()\n\nawait asyncio.sleep(BROADCAST\\_DELAY)\n\nfirst\\_agent\\_in\\_queue = self.speaking\\_queue.pop(0) if self.speaking\\_queue else None\n\nif first\\_agent\\_in\\_queue and not self.get\\_typing\\_status(first\\_agent\\_in\\_queue):\n\nawait self.agents\\[first\\_agent\\_in\\_queue\\].speak()\n\ndef add\\_to\\_speaking\\_queue(self, agent):\n\nif agent.name not in self.speaking\\_queue:\n\nself.speaking\\_queue.append(agent)\n\ndef increment\\_speaking\\_pressure(self, mentioned\\_agents):\n\nfor agent in self.agents.values():\n\nif agent.name not in mentioned\\_agents:\n\nagent.speaking\\_pressure += agent.speaking\\_pressure\\_increment\n\ndef identify\\_and\\_tag\\_mentioned\\_agents(self, message):\n\nmentioned\\_agents = \\[\\]\n\nfor agent\\_name in self.agents:\n\nif '@'+agent\\_name in message:\n\nmentioned\\_agents.append(agent\\_name)\n\nself.agents\\[agent\\_name\\].speaking\\_pressure = SPEAKING\\_PRESSURE\\_LIMIT\n\nself.agents\\[agent\\_name\\].tagged = True\n\nreturn mentioned\\_agents\n\ndef get\\_speaking\\_queue(self):\n\nreturn self.speaking\\_queue\n\ndef add\\_agent(self, agent: Agent):\n\nself.agents\\[agent.name\\] = agent\n\nself.typing\\_status\\[agent.name\\] = False\n\ndef remove\\_agent(self, agent\\_name: str):\n\nif agent\\_name not in self.agents:\n\nraise ValueError(f\"Agent '{agent\\_name}' not found.\")\n\ndel self.agents\\[agent\\_name\\]\n\ndef get\\_agent(self, agent\\_name: str):\n\nif agent\\_name not in self.agents:\n\nraise ValueError(f\"Agent '{agent\\_name}' not found.\")\n\nreturn self.agents\\[agent\\_name\\]\n\ndef add\\_to\\_chat\\_history(self, message, sender, timestamp):\n\nself.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\ndef add\\_tagged\\_agents\\_to\\_queue(self):\n\nfor agent in self.agents.values():\n\nif agent.tagged and agent.name not in self.speaking\\_queue.queue:\n\nself.speaking\\_queue.add(agent.name)\n\nagent.tagged = False\n\nagent.speaking\\_pressure = 0 # Reset speaking pressure\n\ndef add\\_high\\_pressure\\_agents\\_to\\_queue(self):\n\nfor agent in self.agents.values():\n\nif agent.speaking\\_pressure > 100 and agent.name not in self.speaking\\_queue.queue:\n\nself.speaking\\_queue.add(agent.name)\n\nagent.speaking\\_pressure = 0 # Reset speaking pressure\n\nasync def trigger\\_next\\_speaker(self):\n\nif self.speaking\\_queue:\n\nnext\\_speaker\\_name = self.speaking\\_queue.pop(0)\n\nnext\\_speaker = self.get\\_agent(next\\_speaker\\_name)\n\nresponse = next\\_speaker.get\\_response(self.chat\\_history.truncated\\_chat\\_history)\n\nprint(f\"The next speaker is: {next\\_speaker.name}\")\n\nprint(f\"Message: {response}\")\n\nasync def update\\_speaking\\_queue(self):\n\n\"\"\"Update the speaking queue by calculating relevancy for each agent and adding the most relevant agents to the queue.\"\"\"\n\nmost\\_relevant\\_agent = None\n\nhighest\\_relevancy\\_score = -1\n\nfor agent in self.agents.values():\n\ntruncated\\_chat\\_history = self.chat\\_history.truncated\\_chat\\_history\n\nrelevancy\\_score = await agent.calculate\\_relevancy(truncated\\_chat\\_history)\n\nif relevancy\\_score > highest\\_relevancy\\_score:\n\nhighest\\_relevancy\\_score = relevancy\\_score\n\nmost\\_relevant\\_agent = agent\n\nprint(f\"Calculated relevancy for agent {agent.name}. Score: {relevancy\\_score}\")\n\n\\# Add the most relevant agent to the speaking queue\n\nif most\\_relevant\\_agent and self.speaking\\_queue.count(most\\_relevant\\_agent.name) == 0:\n\nself.speaking\\_queue.insert(0, most\\_relevant\\_agent.name)\n\nprint(f\"Added agent {most\\_relevant\\_agent.name} to the front of the speaking queue. Current queue: {self.speaking\\_queue}\")\n\nself.add\\_tagged\\_agents\\_to\\_queue()\n\nself.add\\_high\\_pressure\\_agents\\_to\\_queue()\n\nprint(f\"Triggering next speaker...\")\n\nawait self.trigger\\_next\\_speaker()\n\n#def get\\_sorted\\_agents\\_based\\_on\\_relevancy(self):\n\n\\# return sorted(self.agents.values(), key=lambda agent: agent.calculate\\_relevancy(self.chat\\_history) if agent.calculate\\_relevancy(self.chat\\_history) is not None else 0, reverse=True)\n\nasync def get\\_agents\\_info(self) -> List\\[dict\\]:\n\nagents\\_info = \\[\\]\n\nfor agent\\_name, agent in self.agents.items():\n\nagents\\_info.append({\n\n\"name\": agent\\_name,\n\n\"speaking\\_pressure\": agent.speaking\\_pressure,\n\n\"speaking\\_pressure\\_increment\": agent.speaking\\_pressure\\_increment,\n\n\"context\": agent.context,\n\n\"agent\\_type\": agent.agent\\_type,\n\n\"relevancy\\_score\": agent.relevancy\\_score # Return the cached score\n\n})\n\nreturn agents\\_info",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:09:39.645394Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "782aa904-ae90-48ca-b212-c9968389a017",
      "role": "assistant",
      "content": " Here is the updated parliament.py file:\n\n```python\nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15 \nSPEAKING_PRESSURE_LIMIT = 100  \nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        ...\n        \n    async def calculate_relevancy(self, chat_context):\n        ...\n        \n    def should_speak(self):\n        ... \n        \n    async def increment_pressure(self):\n        ...\n        \n    async def get_agent_message(self, truncated_chat_history):\n        ...\n        \n    def in_queue(self):\n        ...\n        \n    async def speak(self):\n        ...\n        \nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n        \n    def add(self, message, sender, timestamp):\n        ...\n        \n    def truncate_chat_history(self, max_length=2000):\n        ... \n        \n    def last_message(self):\n        ...\n        \nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n        \n    def should_speak(self, agent):\n        ...\n        \nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        ...\n        \n    def get_response(self, truncated_chat):\n        ...\n        \nclass GPT4AllAgent:\n    def __init__(self):\n        ...\n        \n    def _initialize_gpt4all_model(self):\n        ...\n        \n    def _initialize_llm_chain(self):\n        ...\n        \n    def get_response(self, chat_history, question):\n        ...\n        \nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.topic = \"some topic\"  # ADDED\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory() \n        self.speaking_queue = deque() \n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {}\n        \n    async def startup(self):  # ADDED\n        for agent in self.agents.values():\n            relevancy = await agent.calculate_relevancy(self.topic) # Use topic instead of chat context\n            agent.relevancy_score = relevancy  \n            \n    async def agent_reply(self, agent_name):  # ADDED\n        agent = self.get_agent(agent_name)\n        await agent.speak()  \n        \n    async def receive_user_message(self, message):\n        ...\n        # Increment speaking pressure but no queue\n        ...\n        \n    def set_typing_status(self, agent_name: str, status: bool):\n        ...  \n        \n    async def broadcast_message(self, message, sender, timestamp):\n        ...    \n        queue_head = None  # No longer used\n        ...\n        \n    def add_agent(self, agent: Agent):\n        ...\n        \n    def remove_agent(self, agent_name: str):\n        ...\n        \n    def get_agent(self, agent_name: str):\n        ...\n        \n    def add_to_chat_history(self, message, sender, timestamp):\n        ...\n        \n    def add_tagged_agents_to_queue(self):  # No longer used\n        ...\n        \n    def add_high_pressure_agents_to_queue(self):  # No longer used\n        ...\n        \n    async def trigger_next_speaker(self):  # No longer used\n        ...\n        \n    async def update_speaking_queue(self):  # No longer used\n        ...\n        \n    async def get_agents_info(self) -> List[dict]:\n        ...\n```\n\nThe main differences are:\n\n1. Added a topic attribute to store the conversation topic\n2. Added a startup method to calculate and cache all agent relevancy scores based on the topic \n3. Added an agent_reply method to have an agent respond when their \"reply\" button is clicked\n4. Removed the speaking queue and all related logic \n5. Simplified the broadcast_message method by removing the queue logic\n\nLet me know if you have any other questions!",
      "created_at": "2023-05-20T17:10:16.585291Z",
      "sequence_order": 5,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:10:16.585291Z",
            "stop_timestamp": "2023-05-20T17:10:16.585291Z",
            "flags": null,
            "type": "text",
            "text": " Here is the updated parliament.py file:\n\n```python\nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15 \nSPEAKING_PRESSURE_LIMIT = 100  \nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\"\nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        ...\n        \n    async def calculate_relevancy(self, chat_context):\n        ...\n        \n    def should_speak(self):\n        ... \n        \n    async def increment_pressure(self):\n        ...\n        \n    async def get_agent_message(self, truncated_chat_history):\n        ...\n        \n    def in_queue(self):\n        ...\n        \n    async def speak(self):\n        ...\n        \nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n        \n    def add(self, message, sender, timestamp):\n        ...\n        \n    def truncate_chat_history(self, max_length=2000):\n        ... \n        \n    def last_message(self):\n        ...\n        \nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n        \n    def should_speak(self, agent):\n        ...\n        \nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        ...\n        \n    def get_response(self, truncated_chat):\n        ...\n        \nclass GPT4AllAgent:\n    def __init__(self):\n        ...\n        \n    def _initialize_gpt4all_model(self):\n        ...\n        \n    def _initialize_llm_chain(self):\n        ...\n        \n    def get_response(self, chat_history, question):\n        ...\n        \nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.topic = \"some topic\"  # ADDED\n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory() \n        self.speaking_queue = deque() \n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {}\n        \n    async def startup(self):  # ADDED\n        for agent in self.agents.values():\n            relevancy = await agent.calculate_relevancy(self.topic) # Use topic instead of chat context\n            agent.relevancy_score = relevancy  \n            \n    async def agent_reply(self, agent_name):  # ADDED\n        agent = self.get_agent(agent_name)\n        await agent.speak()  \n        \n    async def receive_user_message(self, message):\n        ...\n        # Increment speaking pressure but no queue\n        ...\n        \n    def set_typing_status(self, agent_name: str, status: bool):\n        ...  \n        \n    async def broadcast_message(self, message, sender, timestamp):\n        ...    \n        queue_head = None  # No longer used\n        ...\n        \n    def add_agent(self, agent: Agent):\n        ...\n        \n    def remove_agent(self, agent_name: str):\n        ...\n        \n    def get_agent(self, agent_name: str):\n        ...\n        \n    def add_to_chat_history(self, message, sender, timestamp):\n        ...\n        \n    def add_tagged_agents_to_queue(self):  # No longer used\n        ...\n        \n    def add_high_pressure_agents_to_queue(self):  # No longer used\n        ...\n        \n    async def trigger_next_speaker(self):  # No longer used\n        ...\n        \n    async def update_speaking_queue(self):  # No longer used\n        ...\n        \n    async def get_agents_info(self) -> List[dict]:\n        ...\n```\n\nThe main differences are:\n\n1. Added a topic attribute to store the conversation topic\n2. Added a startup method to calculate and cache all agent relevancy scores based on the topic \n3. Added an agent_reply method to have an agent respond when their \"reply\" button is clicked\n4. Removed the speaking queue and all related logic \n5. Simplified the broadcast_message method by removing the queue logic\n\nLet me know if you have any other questions!",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:10:16.585291Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "54496ecf-e7a2-4817-b7de-35abd1ffbf2c",
      "role": "human",
      "content": "I want the entire file updated so I can just copy and paste.",
      "created_at": "2023-05-20T17:13:36.928662Z",
      "sequence_order": 6,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:13:36.928662Z",
            "stop_timestamp": "2023-05-20T17:13:36.928662Z",
            "flags": null,
            "type": "text",
            "text": "I want the entire file updated so I can just copy and paste.",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:13:36.928662Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "213493b6-c264-402b-a48e-54973762f6e7",
      "role": "assistant",
      "content": " Here is the full updated parliament.py file:\n\n```python\nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15  \nSPEAKING_PRESSURE_LIMIT = 100  \nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\" \nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.speaking_pressure = speaking_pressure_increment\n        self.tagged = False\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.is_speaking = False\n        self.relevancy_score = None\n        \n    def get_response(self, truncated_chat_history):\n        agent_message = self.get_agent_message(truncated_chat_history)\n        return agent_message\n        \n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue\n        \n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",  \n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300 \n            )\n            print(f\"Response: {response}\")\n            # Here we assume the model's response will be a single number.\n            # The strip is used to remove any whitespace around the number \n            stripped_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n        \n    def should_speak(self):\n        return self.parliament.speaker_manager.should_speak(self) \n        \n    async def increment_pressure(self):\n        while True:\n            self.speaking_pressure += self.speaking_pressure_increment\n            \n    async def get_agent_message(self, truncated_chat_history):\n        \"\"\"\n        Generate a message from this agent based on the current chat history.\n        \"\"\"\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history) \n            message = f\"{response}\"\n        return message\n        \n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue.queue\n        \n    async def speak(self):\n        truncated_chat_history = self.parliament.chat_history.truncated_chat_history\n        if self.should_speak():\n            self.is_speaking = True\n            await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n            await self.websocket.send(json.dumps({\"action\": STOPPED_TYPING, \"sender\": self.name}))\n            agent_message = await self.get_response(self.parliament.chat_history.truncated_chat_history)\n            await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n            self.speaking_pressure = 0\n        self.is_speaking = False\n            \n    def reset_pressure(self):\n        self.speaking_pressure = 0\n        \nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n        \n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender",
      "created_at": "2023-05-20T17:14:13.451314Z",
      "sequence_order": 7,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:14:13.451314Z",
            "stop_timestamp": "2023-05-20T17:14:13.451314Z",
            "flags": null,
            "type": "text",
            "text": " Here is the full updated parliament.py file:\n\n```python\nimport asyncio\nimport re\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15  \nSPEAKING_PRESSURE_LIMIT = 100  \nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\nSTOPPED_TYPING = \"stopped_typing\" \nUPDATE_AGENTS = \"update_agents\"\n\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.name = agent_name\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.speaking_pressure = speaking_pressure_increment\n        self.tagged = False\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.is_speaking = False\n        self.relevancy_score = None\n        \n    def get_response(self, truncated_chat_history):\n        agent_message = self.get_agent_message(truncated_chat_history)\n        return agent_message\n        \n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue\n        \n    async def calculate_relevancy(self, chat_context):\n        relevancy_score = 0\n        if self.relevancy_score is None or self.initial_context != chat_context:\n            print(\"Calculating relevancy...\")\n            prompt = f\"you are '{self.initial_context}' and you are being asked to respond to '{chat_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n            print(f\"Prompt: {prompt}\")\n            response = openai.Completion.create(\n                engine=\"text-davinci-001\",  \n                prompt=prompt,\n                temperature=0.0,\n                max_tokens=300 \n            )\n            print(f\"Response: {response}\")\n            # Here we assume the model's response will be a single number.\n            # The strip is used to remove any whitespace around the number \n            stripped_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices[0].text)\n            try:\n                relevancy_score = int(stripped_response)\n            except ValueError:\n                relevancy_score = 0\n            print(f\"Relevancy score: {relevancy_score}\")\n        else:\n            print(\"Relevancy score already calculated.\")\n        time.sleep(.5)\n        return relevancy_score\n        \n    def should_speak(self):\n        return self.parliament.speaker_manager.should_speak(self) \n        \n    async def increment_pressure(self):\n        while True:\n            self.speaking_pressure += self.speaking_pressure_increment\n            \n    async def get_agent_message(self, truncated_chat_history):\n        \"\"\"\n        Generate a message from this agent based on the current chat history.\n        \"\"\"\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = await self.agent_instance.get_response(truncated_chat_history) \n            message = f\"{response}\"\n        return message\n        \n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue.queue\n        \n    async def speak(self):\n        truncated_chat_history = self.parliament.chat_history.truncated_chat_history\n        if self.should_speak():\n            self.is_speaking = True\n            await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n            await self.websocket.send(json.dumps({\"action\": STOPPED_TYPING, \"sender\": self.name}))\n            agent_message = await self.get_response(self.parliament.chat_history.truncated_chat_history)\n            await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n            self.speaking_pressure = 0\n        self.is_speaking = False\n            \n    def reset_pressure(self):\n        self.speaking_pressure = 0\n        \nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = \"\"\n        \n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:14:13.451314Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "efede171-caf9-4f75-9d44-fb23f699854e",
      "role": "human",
      "content": "continue from chat history class\n\nclass ChatHistory: def **init**(self): self.chat\\_history = \\[\\] self.truncated\\_chat\\_history = \"\"",
      "created_at": "2023-05-20T17:14:26.369637Z",
      "sequence_order": 8,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:14:26.369637Z",
            "stop_timestamp": "2023-05-20T17:14:26.369637Z",
            "flags": null,
            "type": "text",
            "text": "continue from chat history class\n\nclass ChatHistory: def **init**(self): self.chat\\_history = \\[\\] self.truncated\\_chat\\_history = \"\"",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:14:26.369637Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "a722ee99-d1d5-4b46-be1f-60a7e0e5416c",
      "role": "assistant",
      "content": " def add(self, message, sender, timestamp): \n    self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n    self.truncate_chat_history()\n    \ndef truncate_chat_history(self, max_length=2000):\n    \"\"\"\n    Truncate the chat history to the last max_length characters.\n    \"\"\"\n    chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n    self.truncated_chat_history = chat_history_str[-max_length:]\n    \ndef last_message(self):\n    return self.chat_history[-1] if self.chat_history else None\n    \nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n        \n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n        \nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n        \n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages=[]\n        messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n        max_retries = 3\n        retry_delay = 5\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()  \n                print(f\" {agent_response}\") # Add logging\n                return agent_response\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1: # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n        \nclass GPT4AllAgent:\n    def __init__(self):\n        # Download and set up the GPT4All model\n        self._initialize_gpt4all_model()\n        self._initialize_llm_chain()\n        \n    def _initialize_gpt4all_model(self):\n        local_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n        url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n        response = requests.get(url, stream=True)\n        with open(local_path, 'wb') as f:\n            for chunk in tqdm(response.iter_content(chunk_size=8192)): \n                if chunk:\n                    f.write(chunk)\n        self.model_path = local_path\n        \n    def _initialize_llm_chain(self):\n        template = \"\"\"{chat_history}  \n                     \n                      Question: {question}  \n                      \n                      Answer: Let's think step by step.\"\"\"\n        prompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\n        callbacks = [StreamingStdOutCallbackHandler()]\n        llm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\n        self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n        \n    def get_response(self, chat_history, question):\n        return self.llm_chain.run(chat_history=chat_history, question=question)\n        \nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.topic = \"some topic\"  \n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()  \n        self.",
      "created_at": "2023-05-20T17:15:19.973959Z",
      "sequence_order": 9,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:15:19.973959Z",
            "stop_timestamp": "2023-05-20T17:15:19.973959Z",
            "flags": null,
            "type": "text",
            "text": " def add(self, message, sender, timestamp): \n    self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n    self.truncate_chat_history()\n    \ndef truncate_chat_history(self, max_length=2000):\n    \"\"\"\n    Truncate the chat history to the last max_length characters.\n    \"\"\"\n    chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n    self.truncated_chat_history = chat_history_str[-max_length:]\n    \ndef last_message(self):\n    return self.chat_history[-1] if self.chat_history else None\n    \nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n        \n    def should_speak(self, agent):\n        return self.parliament.speaking_queue[0] == agent.name if self.parliament.speaking_queue else False\n        \nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n        \n    def get_response(self, truncated_chat):\n        system_msg = self.initial_context\n        messages=[]\n        messages.append({\"role\": \"assistant\", \"content\": truncated_chat})\n        max_retries = 3\n        retry_delay = 5\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                agent_response = response.choices[0].message[\"content\"].strip()  \n                print(f\" {agent_response}\") # Add logging\n                return agent_response\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1: # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n        \nclass GPT4AllAgent:\n    def __init__(self):\n        # Download and set up the GPT4All model\n        self._initialize_gpt4all_model()\n        self._initialize_llm_chain()\n        \n    def _initialize_gpt4all_model(self):\n        local_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n        url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n        response = requests.get(url, stream=True)\n        with open(local_path, 'wb') as f:\n            for chunk in tqdm(response.iter_content(chunk_size=8192)): \n                if chunk:\n                    f.write(chunk)\n        self.model_path = local_path\n        \n    def _initialize_llm_chain(self):\n        template = \"\"\"{chat_history}  \n                     \n                      Question: {question}  \n                      \n                      Answer: Let's think step by step.\"\"\"\n        prompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\n        callbacks = [StreamingStdOutCallbackHandler()]\n        llm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\n        self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n        \n    def get_response(self, chat_history, question):\n        return self.llm_chain.run(chat_history=chat_history, question=question)\n        \nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.topic = \"some topic\"  \n        self.speaker_manager = SpeakerManager(self)\n        self.agents = {}\n        self.chat_history = ChatHistory()  \n        self.",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:15:19.973959Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "d270d52c-6be1-4acf-a85f-93b2aad9ddb3",
      "role": "human",
      "content": "connection handler failed Traceback (most recent call last): File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler await self.ws\\_handler(self) File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler return await cast( File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 39, in chat await self.handle\\_add\\_agents(websocket, data) File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 110, in handle\\_add\\_agents agent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket) TypeError: Agent.\\_\\_init\\_\\_() takes from 6 to 7 positional arguments but 8 were given parliament.py import asyncio import re import random import json import openai from openai.error import RateLimitError import time from typing import List from collections import deque PRESSURE\\_INCREMENT\\_INTERVAL = 15 SPEAKING\\_PRESSURE\\_LIMIT = 100 BROADCAST\\_DELAY = 10 RELEVANCY\\_THRESHOLD = 100 STOPPED\\_TYPING = \"stopped\\_typing\" UPDATE\\_AGENTS = \"update\\_agents\" class Agent: def **init**(self, parliament, agent\\_name, initial\\_context, agent\\_type, agent\\_instance, websocket=None): self.name = agent\\_name self.context = initial\\_context self.initial\\_context = initial\\_context self.agent\\_type = agent\\_type self.agent\\_instance = agent\\_instance self.websocket = websocket self.parliament = parliament self.relevancy\\_score = None async def calculate\\_relevancy(self, chat\\_context): relevancy\\_score = 0 if self.relevancy\\_score is None or self.initial\\_context != chat\\_context: print(\"Calculating relevancy...\") prompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\" print(f\"Prompt: {prompt}\") response = openai.Completion.create( engine=\"text-davinci-001\", prompt=prompt, temperature=0.0, max\\_tokens=300 ) print(f\"Response: {response}\") stripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text) try: relevancy\\_score = int(stripped\\_response) except ValueError: relevancy\\_score = 0 print(f\"Relevancy score: {relevancy\\_score}\") else: print(\"Relevancy score already calculated.\") time.sleep(.5) return relevancy\\_score async def get\\_agent\\_message(self, truncated\\_chat\\_history): message = \"\" if isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]): response = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history) message = f\"{response}\" return message async def respond(self): await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name})) await self.websocket.send(json.dumps({\"action\": \"stopped\\_typing\", \"sender\": self.name})) agent\\_message = await self.get\\_agent\\_message(self.parliament.chat\\_history.truncated\\_chat\\_history) await self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name})) def reset\\_relevancy\\_score(self): self.relevancy\\_score = None class ChatHistory: def **init**(self): self.chat\\_history = \\[\\] self.truncated\\_chat\\_history = \"\" def add(self, message, sender, timestamp): self.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp}) self.truncate\\_chat\\_history() def truncate\\_chat\\_history(self, max\\_length=2000): chat\\_history\\_str = '\\\\n'.join(\\[message\\[\"message\"\\] for message in self.chat\\_history\\]) self.truncated\\_chat\\_history = chat\\_history\\_str\\[-max\\_length:\\] def get\\_latest\\_message(self): return self.chat\\_history\\[-1\\] if self.chat\\_history else None class SpeakerManager: def **init**(self, parliament): self.parliament = parliament def should\\_speak(self, agent): return self.parliament.speaking\\_queue\\[0\\] == agent.name if self.parliament.speaking\\_queue else False class OpenAIAgent: def **init**(self, initial\\_context: str): openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\" openai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\" self.model = \"gpt-3.5-turbo\" self.initial\\_context = initial\\_context def get\\_response(self, truncated\\_chat): system\\_msg = self.initial\\_context messages=\\[\\] messages.append({\"role\": \"assistant\", \"content\": truncated\\_chat}) max\\_retries = 3 retry\\_delay = 5 for i in range(max\\_retries): try: # Call the OpenAI API with the messages array response = openai.ChatCompletion.create( model=self.model, messages=messages, max\\_tokens=150, temperature=0.5, top\\_p=1, frequency\\_penalty=0, presence\\_penalty=0, ) # Extract and return the assistant's response from the API response agent\\_response = response.choices\\[0\\].message\\[\"content\"\\].strip() print(f\" {agent\\_response}\") # Add logging return agent\\_response except RateLimitError as e: print(f\"Rate limit error: {e}. Retrying in {retry\\_delay} seconds...\") if i < max\\_retries - 1: # Don't sleep on the last iteration time.sleep(retry\\_delay) else: raise return \"Sorry, I am unable to respond at the moment.\" class GPT4AllAgent: def **init**(self): # Download and set up the GPT4All model self.\\_initialize\\_gpt4all\\_model() self.\\_initialize\\_llm\\_chain() def _initialize_gpt4all\\_model(self): local\\_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\" Path(local\\_path).parent.mkdir(parents=True, exist\\_ok=True) url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin' response = requests.get(url, stream=True) with open(local\\_path, 'wb') as f: for chunk in tqdm(response.iter\\_content(chunk\\_size=8192)): if chunk: f.write(chunk) self.model\\_path = local\\_path def _initialize_llm\\_chain(self): template = \"\"\"{chat\\_history} Question: {question} Answer: Let's think step by step.\"\"\" prompt = PromptTemplate(template=template, input\\_variables=\\[\"chat\\_history\", \"question\"\\]) callbacks = \\[StreamingStdOutCallbackHandler()\\] llm = GPT4All(model=self.model\\_path, callbacks=callbacks, verbose=True) self.llm\\_chain = LLMChain(prompt=prompt, llm=llm) def get\\_response(self, chat\\_history, question): return self.llm\\_chain.run(chat\\_history=chat\\_history, question=question) import json from typing import List UPDATE\\_AGENTS = \"update\\_agents\" class Parliament: def **init**(self, name: str): # Added name argument self.name = name # Added this line to store the name self.agents: List\\[Agent\\] = \\[\\] self.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent} self.agent\\_instances = {} self.chat\\_history = ChatHistory() async def handle\\_client(self, websocket, path): async for message in websocket: message = json.loads(message) if message\\['action'\\] == 'send\\_message': self.chat\\_history.add(message\\['message'\\], message\\['sender'\\], message\\['timestamp'\\]) for agent in self.agents: if agent.websocket == websocket: agent.reset\\_relevancy\\_score() if message.get('reply\\_agent', None): for agent in self.agents: if agent.name == message\\['reply\\_agent'\\]: await agent.respond() elif message\\['action'\\] == 'request\\_agents': await self.send\\_agent\\_list(websocket) elif message\\['action'\\] == UPDATE\\_AGENTS: self.update\\_agents(message\\['agents'\\], websocket) async def send\\_agent\\_list(self, websocket): agents\\_list = \\[{\"name\": agent.name, \"context\": agent.context} for agent in self.agents\\] await websocket.send(json.dumps({\"action\": \"receive\\_agents\", \"agents\": agents\\_list})) def update\\_agents(self, agents, websocket): self.agents = \\[\\] for agent in agents: self.agents.append(Agent(self, agent\\['name'\\], agent\\['context'\\], agent\\['type'\\], self.agent\\_instances\\[agent\\['type'\\]\\], websocket)) def add\\_agent\\_type(self, agent\\_type\\_name, agent\\_type\\_class): self.agent\\_types\\[agent\\_type\\_name\\] = agent\\_type\\_class def add\\_agent\\_instance(self, agent\\_instance\\_name, agent\\_instance): self.agent\\_instances\\[agent\\_instance\\_name\\] = agent\\_instance server.py from datetime import datetime import asyncio import json from websockets import serve from parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent import openai # Constants SET\\_PARLIAMENT = \"set\\_parliament\" SEND\\_MESSAGE = \"send\\_message\" ADD\\_AGENTS = \"add\\_agents\" UPDATE\\_QUEUE = \"update\\_queue\" UPDATE\\_AGENTS = \"update\\_agents\" RECEIVE\\_MESSAGE = \"receive\\_message\" ERROR = \"error\" TYPING = \"typing\" STOPPED\\_TYPING = \"stopped\\_typing\" class ParliamentServer: def **init**(self, host=\"localhost\", port=8080): self.host = host self.port = port self.parliament = None self.start\\_server = serve(self.chat, self.host, self.port) def configure\\_openai(self): openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\" openai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\" async def chat(self, websocket, path): async for message in websocket: data = json.loads(message) action = data.get(\"action\") if action == SET\\_PARLIAMENT: await self.handle\\_set\\_parliament(websocket, data) elif action == SEND\\_MESSAGE: await self.handle\\_send\\_message(websocket, data) elif action == ADD\\_AGENTS: await self.handle\\_add\\_agents(websocket, data) elif action in \\[TYPING, STOPPED\\_TYPING\\]: await self.handle\\_typing(websocket, data) async def handle\\_typing(self, websocket, data): sender = data.get('sender') action = data.get('action') is\\_typing = action == TYPING self.parliament.set\\_typing\\_status(sender, is\\_typing) # Send the typing status update to other clients: await websocket.send(json.dumps({ \"action\": action, \"sender\": sender, \"is\\_typing\": is\\_typing })) async def handle\\_set\\_parliament(self, websocket, data): parliament\\_name = data.get(\"name\") if parliament\\_name: self.parliament = Parliament(parliament\\_name) async def handle\\_send\\_message(self, websocket, data): if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return sender = data.get(\"sender\") user\\_message = data.get(\"message\") timestamp = datetime.now() await websocket.send(json.dumps({ \"action\": RECEIVE\\_MESSAGE, \"message\": user\\_message, \"sender\": sender, \"timestamp\": timestamp.isoformat()})) await self.parliament.broadcast\\_message(user\\_message, sender, timestamp) print(f\"Broadcast message: {user\\_message}\") # Add logging # Sending agent info after broadcasting message agent\\_info = await self.parliament.get\\_agents\\_info() await websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info})) await self.update\\_queue(websocket) async def handle\\_add\\_agents(self, websocket, data): if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return agents\\_data = data.get(\"agents\") if not agents\\_data: await self.send\\_error(websocket, \"No agent data provided.\") return for agent\\_data in agents\\_data: agent\\_name = agent\\_data.get(\"name\") # Extract the name speaking\\_pressure\\_increment = int(agent\\_data.get(\"speaking\\_pressure\\_increment\")) other\\_agents = \", \".join(\\[agent\\['name'\\] for agent in agents\\_data if agent\\['name'\\] != agent\\_name\\]) initial\\_context = ( f\"Hello assistant, your name is: @{agent\\_data.get('name')} and your context is \" f\"{agent\\_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \" f\"alongside your fellow agents in a parliament, which is a sort \" f\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \" f\"with you are {other\\_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \" f\"{agent\\_data.get('speaking\\_pressure\\_increment')} out of 100\" ) agent\\_type = agent\\_data.get(\"type\") agent\\_class = self.parliament.agent\\_types.get(agent\\_type) # Get OpenAIAgent or GPT4AllAgent agent\\_instance = agent\\_class(initial\\_context) # Properly instantiate the class if isinstance(agent\\_instance, self.parliament.agent\\_types\\[agent\\_type\\]): agent\\_instance = OpenAIAgent(initial\\_context) # Create the OpenAIAgent instance agent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket) self.parliament.add\\_agent(agent) # Pass the agent instance to add\\_agent else: print(\"Error occurred attempting to get agent message!\") return \"Sorry, I'm unable to generate a relevant response at this time.\" await self.send\\_error(websocket, f\"Unknown agent type: {agent\\_type}\") continue async def update\\_queue(self, websocket): if self.parliament: speaking\\_queue = self.parliament.get\\_speaking\\_queue() print(f\"Queue updated: {speaking\\_queue}\") await websocket.send(json.dumps({\"action\": UPDATE\\_QUEUE, \"queue\": speaking\\_queue})) async def send\\_error(self, websocket, message): await websocket.send(json.dumps({\"action\": ERROR, \"message\": message})) def run(self): self.configure\\_openai() asyncio.get\\_event\\_loop().run\\_until\\_complete(self.start\\_server) print(\"Starting WebSocket server...\") print(f\"WebSocket server is running on ws://{self.host}:{self.port}\") asyncio.get\\_event\\_loop().run\\_forever() if **name** == \"\\_\\_main\\_\\_\": server = ParliamentServer() server.run()",
      "created_at": "2023-05-20T17:26:47.486098Z",
      "sequence_order": 10,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:26:47.486098Z",
            "stop_timestamp": "2023-05-20T17:26:47.486098Z",
            "flags": null,
            "type": "text",
            "text": "connection handler failed Traceback (most recent call last): File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler await self.ws\\_handler(self) File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler return await cast( File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 39, in chat await self.handle\\_add\\_agents(websocket, data) File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 110, in handle\\_add\\_agents agent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket) TypeError: Agent.\\_\\_init\\_\\_() takes from 6 to 7 positional arguments but 8 were given parliament.py import asyncio import re import random import json import openai from openai.error import RateLimitError import time from typing import List from collections import deque PRESSURE\\_INCREMENT\\_INTERVAL = 15 SPEAKING\\_PRESSURE\\_LIMIT = 100 BROADCAST\\_DELAY = 10 RELEVANCY\\_THRESHOLD = 100 STOPPED\\_TYPING = \"stopped\\_typing\" UPDATE\\_AGENTS = \"update\\_agents\" class Agent: def **init**(self, parliament, agent\\_name, initial\\_context, agent\\_type, agent\\_instance, websocket=None): self.name = agent\\_name self.context = initial\\_context self.initial\\_context = initial\\_context self.agent\\_type = agent\\_type self.agent\\_instance = agent\\_instance self.websocket = websocket self.parliament = parliament self.relevancy\\_score = None async def calculate\\_relevancy(self, chat\\_context): relevancy\\_score = 0 if self.relevancy\\_score is None or self.initial\\_context != chat\\_context: print(\"Calculating relevancy...\") prompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\" print(f\"Prompt: {prompt}\") response = openai.Completion.create( engine=\"text-davinci-001\", prompt=prompt, temperature=0.0, max\\_tokens=300 ) print(f\"Response: {response}\") stripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text) try: relevancy\\_score = int(stripped\\_response) except ValueError: relevancy\\_score = 0 print(f\"Relevancy score: {relevancy\\_score}\") else: print(\"Relevancy score already calculated.\") time.sleep(.5) return relevancy\\_score async def get\\_agent\\_message(self, truncated\\_chat\\_history): message = \"\" if isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]): response = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history) message = f\"{response}\" return message async def respond(self): await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name})) await self.websocket.send(json.dumps({\"action\": \"stopped\\_typing\", \"sender\": self.name})) agent\\_message = await self.get\\_agent\\_message(self.parliament.chat\\_history.truncated\\_chat\\_history) await self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name})) def reset\\_relevancy\\_score(self): self.relevancy\\_score = None class ChatHistory: def **init**(self): self.chat\\_history = \\[\\] self.truncated\\_chat\\_history = \"\" def add(self, message, sender, timestamp): self.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp}) self.truncate\\_chat\\_history() def truncate\\_chat\\_history(self, max\\_length=2000): chat\\_history\\_str = '\\\\n'.join(\\[message\\[\"message\"\\] for message in self.chat\\_history\\]) self.truncated\\_chat\\_history = chat\\_history\\_str\\[-max\\_length:\\] def get\\_latest\\_message(self): return self.chat\\_history\\[-1\\] if self.chat\\_history else None class SpeakerManager: def **init**(self, parliament): self.parliament = parliament def should\\_speak(self, agent): return self.parliament.speaking\\_queue\\[0\\] == agent.name if self.parliament.speaking\\_queue else False class OpenAIAgent: def **init**(self, initial\\_context: str): openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\" openai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\" self.model = \"gpt-3.5-turbo\" self.initial\\_context = initial\\_context def get\\_response(self, truncated\\_chat): system\\_msg = self.initial\\_context messages=\\[\\] messages.append({\"role\": \"assistant\", \"content\": truncated\\_chat}) max\\_retries = 3 retry\\_delay = 5 for i in range(max\\_retries): try: # Call the OpenAI API with the messages array response = openai.ChatCompletion.create( model=self.model, messages=messages, max\\_tokens=150, temperature=0.5, top\\_p=1, frequency\\_penalty=0, presence\\_penalty=0, ) # Extract and return the assistant's response from the API response agent\\_response = response.choices\\[0\\].message\\[\"content\"\\].strip() print(f\" {agent\\_response}\") # Add logging return agent\\_response except RateLimitError as e: print(f\"Rate limit error: {e}. Retrying in {retry\\_delay} seconds...\") if i < max\\_retries - 1: # Don't sleep on the last iteration time.sleep(retry\\_delay) else: raise return \"Sorry, I am unable to respond at the moment.\" class GPT4AllAgent: def **init**(self): # Download and set up the GPT4All model self.\\_initialize\\_gpt4all\\_model() self.\\_initialize\\_llm\\_chain() def _initialize_gpt4all\\_model(self): local\\_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\" Path(local\\_path).parent.mkdir(parents=True, exist\\_ok=True) url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin' response = requests.get(url, stream=True) with open(local\\_path, 'wb') as f: for chunk in tqdm(response.iter\\_content(chunk\\_size=8192)): if chunk: f.write(chunk) self.model\\_path = local\\_path def _initialize_llm\\_chain(self): template = \"\"\"{chat\\_history} Question: {question} Answer: Let's think step by step.\"\"\" prompt = PromptTemplate(template=template, input\\_variables=\\[\"chat\\_history\", \"question\"\\]) callbacks = \\[StreamingStdOutCallbackHandler()\\] llm = GPT4All(model=self.model\\_path, callbacks=callbacks, verbose=True) self.llm\\_chain = LLMChain(prompt=prompt, llm=llm) def get\\_response(self, chat\\_history, question): return self.llm\\_chain.run(chat\\_history=chat\\_history, question=question) import json from typing import List UPDATE\\_AGENTS = \"update\\_agents\" class Parliament: def **init**(self, name: str): # Added name argument self.name = name # Added this line to store the name self.agents: List\\[Agent\\] = \\[\\] self.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent} self.agent\\_instances = {} self.chat\\_history = ChatHistory() async def handle\\_client(self, websocket, path): async for message in websocket: message = json.loads(message) if message\\['action'\\] == 'send\\_message': self.chat\\_history.add(message\\['message'\\], message\\['sender'\\], message\\['timestamp'\\]) for agent in self.agents: if agent.websocket == websocket: agent.reset\\_relevancy\\_score() if message.get('reply\\_agent', None): for agent in self.agents: if agent.name == message\\['reply\\_agent'\\]: await agent.respond() elif message\\['action'\\] == 'request\\_agents': await self.send\\_agent\\_list(websocket) elif message\\['action'\\] == UPDATE\\_AGENTS: self.update\\_agents(message\\['agents'\\], websocket) async def send\\_agent\\_list(self, websocket): agents\\_list = \\[{\"name\": agent.name, \"context\": agent.context} for agent in self.agents\\] await websocket.send(json.dumps({\"action\": \"receive\\_agents\", \"agents\": agents\\_list})) def update\\_agents(self, agents, websocket): self.agents = \\[\\] for agent in agents: self.agents.append(Agent(self, agent\\['name'\\], agent\\['context'\\], agent\\['type'\\], self.agent\\_instances\\[agent\\['type'\\]\\], websocket)) def add\\_agent\\_type(self, agent\\_type\\_name, agent\\_type\\_class): self.agent\\_types\\[agent\\_type\\_name\\] = agent\\_type\\_class def add\\_agent\\_instance(self, agent\\_instance\\_name, agent\\_instance): self.agent\\_instances\\[agent\\_instance\\_name\\] = agent\\_instance server.py from datetime import datetime import asyncio import json from websockets import serve from parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent import openai # Constants SET\\_PARLIAMENT = \"set\\_parliament\" SEND\\_MESSAGE = \"send\\_message\" ADD\\_AGENTS = \"add\\_agents\" UPDATE\\_QUEUE = \"update\\_queue\" UPDATE\\_AGENTS = \"update\\_agents\" RECEIVE\\_MESSAGE = \"receive\\_message\" ERROR = \"error\" TYPING = \"typing\" STOPPED\\_TYPING = \"stopped\\_typing\" class ParliamentServer: def **init**(self, host=\"localhost\", port=8080): self.host = host self.port = port self.parliament = None self.start\\_server = serve(self.chat, self.host, self.port) def configure\\_openai(self): openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\" openai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\" async def chat(self, websocket, path): async for message in websocket: data = json.loads(message) action = data.get(\"action\") if action == SET\\_PARLIAMENT: await self.handle\\_set\\_parliament(websocket, data) elif action == SEND\\_MESSAGE: await self.handle\\_send\\_message(websocket, data) elif action == ADD\\_AGENTS: await self.handle\\_add\\_agents(websocket, data) elif action in \\[TYPING, STOPPED\\_TYPING\\]: await self.handle\\_typing(websocket, data) async def handle\\_typing(self, websocket, data): sender = data.get('sender') action = data.get('action') is\\_typing = action == TYPING self.parliament.set\\_typing\\_status(sender, is\\_typing) # Send the typing status update to other clients: await websocket.send(json.dumps({ \"action\": action, \"sender\": sender, \"is\\_typing\": is\\_typing })) async def handle\\_set\\_parliament(self, websocket, data): parliament\\_name = data.get(\"name\") if parliament\\_name: self.parliament = Parliament(parliament\\_name) async def handle\\_send\\_message(self, websocket, data): if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return sender = data.get(\"sender\") user\\_message = data.get(\"message\") timestamp = datetime.now() await websocket.send(json.dumps({ \"action\": RECEIVE\\_MESSAGE, \"message\": user\\_message, \"sender\": sender, \"timestamp\": timestamp.isoformat()})) await self.parliament.broadcast\\_message(user\\_message, sender, timestamp) print(f\"Broadcast message: {user\\_message}\") # Add logging # Sending agent info after broadcasting message agent\\_info = await self.parliament.get\\_agents\\_info() await websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info})) await self.update\\_queue(websocket) async def handle\\_add\\_agents(self, websocket, data): if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return agents\\_data = data.get(\"agents\") if not agents\\_data: await self.send\\_error(websocket, \"No agent data provided.\") return for agent\\_data in agents\\_data: agent\\_name = agent\\_data.get(\"name\") # Extract the name speaking\\_pressure\\_increment = int(agent\\_data.get(\"speaking\\_pressure\\_increment\")) other\\_agents = \", \".join(\\[agent\\['name'\\] for agent in agents\\_data if agent\\['name'\\] != agent\\_name\\]) initial\\_context = ( f\"Hello assistant, your name is: @{agent\\_data.get('name')} and your context is \" f\"{agent\\_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \" f\"alongside your fellow agents in a parliament, which is a sort \" f\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \" f\"with you are {other\\_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \" f\"{agent\\_data.get('speaking\\_pressure\\_increment')} out of 100\" ) agent\\_type = agent\\_data.get(\"type\") agent\\_class = self.parliament.agent\\_types.get(agent\\_type) # Get OpenAIAgent or GPT4AllAgent agent\\_instance = agent\\_class(initial\\_context) # Properly instantiate the class if isinstance(agent\\_instance, self.parliament.agent\\_types\\[agent\\_type\\]): agent\\_instance = OpenAIAgent(initial\\_context) # Create the OpenAIAgent instance agent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket) self.parliament.add\\_agent(agent) # Pass the agent instance to add\\_agent else: print(\"Error occurred attempting to get agent message!\") return \"Sorry, I'm unable to generate a relevant response at this time.\" await self.send\\_error(websocket, f\"Unknown agent type: {agent\\_type}\") continue async def update\\_queue(self, websocket): if self.parliament: speaking\\_queue = self.parliament.get\\_speaking\\_queue() print(f\"Queue updated: {speaking\\_queue}\") await websocket.send(json.dumps({\"action\": UPDATE\\_QUEUE, \"queue\": speaking\\_queue})) async def send\\_error(self, websocket, message): await websocket.send(json.dumps({\"action\": ERROR, \"message\": message})) def run(self): self.configure\\_openai() asyncio.get\\_event\\_loop().run\\_until\\_complete(self.start\\_server) print(\"Starting WebSocket server...\") print(f\"WebSocket server is running on ws://{self.host}:{self.port}\") asyncio.get\\_event\\_loop().run\\_forever() if **name** == \"\\_\\_main\\_\\_\": server = ParliamentServer() server.run()",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:26:47.486098Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "2f06f6ef-f960-4fcb-bdb0-4cf5da4f4f15",
      "role": "assistant",
      "content": " Here are the changes I would make:\n\nIn parliament.py:\n\n- Remove the speaking_pressure_increment argument from Agent.__init__. You no longer need it.\n- In Parliament.__init__, remove speaking_queue and add topic\n- Remove all methods relating to speaking_queue:\n  - get_speaking_queue\n  - add_to_speaking_queue\n  - increment_speaking_pressure\n  - identify_and_tag_mentioned_agents\n  - add_tagged_agents_to_queue\n  - add_high_pressure_agents_to_queue\n  - trigger_next_speaker\n- Add startup method to calculate agent relevancy scores \n- Add agent_reply method to have an agent respond\n- Simplify broadcast_message method by removing queue logic\n\nThe updated Parliament class would be:\n```python\nclass Parliament:\n    def __init__(self, name: str, topic: str):\n        self.name = name\n        self.topic = topic\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        \n    async def startup(self):  \n        for agent in self.agents.values():\n            relevancy = await agent.calculate_relevancy(self.topic) \n            agent.relevancy_score = relevancy  \n            \n    async def agent_reply(self, agent_name):  \n        agent = self.get_agent(agent_name)\n        await agent.respond()  \n        \n    async def broadcast_message(self, message, sender, timestamp): \n        self.chat_history.add(message, sender, timestamp)\n        for agent in self.agents.values():\n            await agent.respond()  \n        await asyncio.sleep(BROADCAST_DELAY) \n```\n\nIn server.py:\n- Remove the logic to add agents to the speaking queue in handle_add_agents. You no longer need a queue.\n- Call await parliament.startup() after creating the Parliament instance to calculate relevancy scores.\n- Remove the call to await self.update_queue(websocket) in handle_send_message. No need to update a queue.\n\nThe updated handle_add_agents method would be: \n```python \nasync def handle_add_agents(self, websocket, data): \n    if not self.parliament: \n        await self.send_error(websocket, \"Parliament not set.\")\n        return\n    agents_data = data.get(\"agents\")\n    if not agents_data: \n        await self.send_error(websocket, \"No agent data provided.\")\n        return\n    for agent_data in agents_data:\n        ...\n        agent = Agent(self.parliament, agent_name, initial_context, agent_type, agent_instance, websocket)\n        self.parliament.add_agent(agent) \n    await self.parliament.startup()  # Call this to calculate relevancy scores\n```\n\nLet me know if you have any other questions!",
      "created_at": "2023-05-20T17:27:24.423733Z",
      "sequence_order": 11,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:27:24.423733Z",
            "stop_timestamp": "2023-05-20T17:27:24.423733Z",
            "flags": null,
            "type": "text",
            "text": " Here are the changes I would make:\n\nIn parliament.py:\n\n- Remove the speaking_pressure_increment argument from Agent.__init__. You no longer need it.\n- In Parliament.__init__, remove speaking_queue and add topic\n- Remove all methods relating to speaking_queue:\n  - get_speaking_queue\n  - add_to_speaking_queue\n  - increment_speaking_pressure\n  - identify_and_tag_mentioned_agents\n  - add_tagged_agents_to_queue\n  - add_high_pressure_agents_to_queue\n  - trigger_next_speaker\n- Add startup method to calculate agent relevancy scores \n- Add agent_reply method to have an agent respond\n- Simplify broadcast_message method by removing queue logic\n\nThe updated Parliament class would be:\n```python\nclass Parliament:\n    def __init__(self, name: str, topic: str):\n        self.name = name\n        self.topic = topic\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        \n    async def startup(self):  \n        for agent in self.agents.values():\n            relevancy = await agent.calculate_relevancy(self.topic) \n            agent.relevancy_score = relevancy  \n            \n    async def agent_reply(self, agent_name):  \n        agent = self.get_agent(agent_name)\n        await agent.respond()  \n        \n    async def broadcast_message(self, message, sender, timestamp): \n        self.chat_history.add(message, sender, timestamp)\n        for agent in self.agents.values():\n            await agent.respond()  \n        await asyncio.sleep(BROADCAST_DELAY) \n```\n\nIn server.py:\n- Remove the logic to add agents to the speaking queue in handle_add_agents. You no longer need a queue.\n- Call await parliament.startup() after creating the Parliament instance to calculate relevancy scores.\n- Remove the call to await self.update_queue(websocket) in handle_send_message. No need to update a queue.\n\nThe updated handle_add_agents method would be: \n```python \nasync def handle_add_agents(self, websocket, data): \n    if not self.parliament: \n        await self.send_error(websocket, \"Parliament not set.\")\n        return\n    agents_data = data.get(\"agents\")\n    if not agents_data: \n        await self.send_error(websocket, \"No agent data provided.\")\n        return\n    for agent_data in agents_data:\n        ...\n        agent = Agent(self.parliament, agent_name, initial_context, agent_type, agent_instance, websocket)\n        self.parliament.add_agent(agent) \n    await self.parliament.startup()  # Call this to calculate relevancy scores\n```\n\nLet me know if you have any other questions!",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:27:24.423733Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "99266c7e-9dc6-408f-a46d-96ee15a5b5b7",
      "role": "human",
      "content": "error\n\nWebSocket server is running on ws://localhost:8080\n\nconnection handler failed\n\nTraceback (most recent call last):\n\nFile \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n\nawait self.ws\\_handler(self)\n\nFile \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n\nreturn await cast(\n\nFile \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 41, in chat\n\nawait self.handle\\_typing(websocket, data)\n\nFile \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 48, in handle\\_typing\n\nself.parliament.set\\_typing\\_status(sender, is\\_typing)\n\nAttributeError: 'Parliament' object has no attribute 'set\\_typing\\_status'\n\nWhy can't I set typing status on the agents directly rather than sending into parliament?\n\nserver.py\n\n\\# Constants\n\nSET\\_PARLIAMENT = \"set\\_parliament\"\n\nSEND\\_MESSAGE = \"send\\_message\"\n\nADD\\_AGENTS = \"add\\_agents\"\n\nUPDATE\\_QUEUE = \"update\\_queue\"\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nRECEIVE\\_MESSAGE = \"receive\\_message\"\n\nERROR = \"error\"\n\nTYPING = \"typing\"\n\nSTOPPED\\_TYPING = \"stopped\\_typing\"\n\nclass ParliamentServer:\n\ndef **init**(self, host=\"localhost\", port=8080):\n\nself.host = host\n\nself.port = port\n\nself.parliament = None\n\nself.start\\_server = serve(self.chat, self.host, self.port)\n\ndef configure\\_openai(self):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\"\n\nasync def chat(self, websocket, path):\n\nasync for message in websocket:\n\ndata = json.loads(message)\n\naction = data.get(\"action\")\n\nif action == SET\\_PARLIAMENT:\n\nawait self.handle\\_set\\_parliament(websocket, data)\n\nelif action == SEND\\_MESSAGE:\n\nawait self.handle\\_send\\_message(websocket, data)\n\nelif action == ADD\\_AGENTS:\n\nawait self.handle\\_add\\_agents(websocket, data)\n\nelif action in \\[TYPING, STOPPED\\_TYPING\\]:\n\nawait self.handle\\_typing(websocket, data)\n\nasync def handle\\_typing(self, websocket, data):\n\nsender = data.get('sender')\n\naction = data.get('action')\n\nis\\_typing = action == TYPING\n\nself.parliament.set\\_typing\\_status(sender, is\\_typing)\n\n\\# Send the typing status update to other clients:\n\nawait websocket.send(json.dumps({\n\n\"action\": action,\n\n\"sender\": sender,\n\n\"is\\_typing\": is\\_typing\n\n}))\n\nasync def handle\\_set\\_parliament(self, websocket, data):\n\nparliament\\_name = data.get(\"name\")\n\nif parliament\\_name:\n\nself.parliament = Parliament(parliament\\_name)\n\nasync def handle\\_send\\_message(self, websocket, data):\n\nif not self.parliament:\n\nawait self.send\\_error(websocket, \"Parliament not set.\")\n\nreturn\n\nsender = data.get(\"sender\")\n\nuser\\_message = data.get(\"message\")\n\ntimestamp = datetime.now()\n\nawait websocket.send(json.dumps({\n\n\"action\": RECEIVE\\_MESSAGE,\n\n\"message\": user\\_message,\n\n\"sender\": sender,\n\n\"timestamp\": timestamp.isoformat()}))\n\nawait self.parliament.broadcast\\_message(user\\_message, sender, timestamp)\n\nprint(f\"Broadcast message: {user\\_message}\") # Add logging\n\n\\# Sending agent info after broadcasting message\n\nagent\\_info = await self.parliament.get\\_agents\\_info()\n\nawait websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info}))\n\nawait self.update\\_queue(websocket)\n\nasync def handle\\_add\\_agents(self, websocket, data):\n\nif not self.parliament:\n\nawait self.send\\_error(websocket, \"Parliament not set.\")\n\nreturn\n\nagents\\_data = data.get(\"agents\")\n\nif not agents\\_data:\n\nawait self.send\\_error(websocket, \"No agent data provided.\")\n\nreturn\n\nfor agent\\_data in agents\\_data:\n\nagent\\_name = agent\\_data.get(\"name\") # Extract the name\n\nspeaking\\_pressure\\_increment = int(agent\\_data.get(\"speaking\\_pressure\\_increment\"))\n\nother\\_agents = \", \".join(\\[agent\\['name'\\] for agent in agents\\_data if agent\\['name'\\] != agent\\_name\\])\n\ninitial\\_context = (\n\nf\"Hello assistant, your name is: @{agent\\_data.get('name')} and your context is \"\n\nf\"{agent\\_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n\nf\"alongside your fellow agents in a parliament, which is a sort \"\n\nf\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n\nf\"with you are {other\\_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n\nf\"{agent\\_data.get('speaking\\_pressure\\_increment')} out of 100\"\n\n)\n\nagent\\_type = agent\\_data.get(\"type\")\n\nagent\\_class = self.parliament.agent\\_types.get(agent\\_type) # Get OpenAIAgent or GPT4AllAgent\n\nagent\\_instance = agent\\_class(initial\\_context) # Properly instantiate the class\n\nif isinstance(agent\\_instance, self.parliament.agent\\_types\\[agent\\_type\\]):\n\nagent\\_instance = OpenAIAgent(initial\\_context) # Create the OpenAIAgent instance\n\nagent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket)\n\nself.parliament.add\\_agent(agent) # Pass the agent instance to add\\_agent\n\nelse:\n\nprint(\"Error occurred attempting to get agent message!\")\n\nreturn \"Sorry, I'm unable to generate a relevant response at this time.\"\n\nawait self.send\\_error(websocket, f\"Unknown agent type: {agent\\_type}\")\n\ncontinue\n\nasync def update\\_queue(self, websocket):\n\nif self.parliament:\n\nspeaking\\_queue = self.parliament.get\\_speaking\\_queue()\n\nprint(f\"Queue updated: {speaking\\_queue}\")\n\nawait websocket.send(json.dumps({\"action\": UPDATE\\_QUEUE, \"queue\": speaking\\_queue}))\n\nasync def send\\_error(self, websocket, message):\n\nawait websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\ndef run(self):\n\nself.configure\\_openai()\n\nasyncio.get\\_event\\_loop().run\\_until\\_complete(self.start\\_server)\n\nprint(\"Starting WebSocket server...\")\n\nprint(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n\nasyncio.get\\_event\\_loop().run\\_forever()\n\nif **name** == \"\\_\\_main\\_\\_\":\n\nserver = ParliamentServer()\n\nserver.run()\n\nparliament.py\n\nimport asyncio\n\nimport re\n\nimport random\n\nimport json\n\nimport openai\n\nfrom openai.error import RateLimitError\n\nimport time\n\nfrom typing import List\n\nfrom collections import deque\n\nPRESSURE\\_INCREMENT\\_INTERVAL = 15\n\nSPEAKING\\_PRESSURE\\_LIMIT = 100\n\nBROADCAST\\_DELAY = 10\n\nRELEVANCY\\_THRESHOLD = 100\n\nSTOPPED\\_TYPING = \"stopped\\_typing\"\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nclass Agent:\n\ndef **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None):\n\nself.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment\n\nself.name = agent\\_name\n\nself.context = initial\\_context\n\nself.initial\\_context = initial\\_context\n\nself.agent\\_type = agent\\_type\n\nself.agent\\_instance = agent\\_instance\n\nself.websocket = websocket\n\nself.parliament = parliament\n\nself.relevancy\\_score = None\n\nasync def calculate\\_relevancy(self, chat\\_context):\n\nrelevancy\\_score = 0\n\nif self.relevancy\\_score is None or self.initial\\_context != chat\\_context:\n\nprint(\"Calculating relevancy...\")\n\nprompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n\nprint(f\"Prompt: {prompt}\")\n\nresponse = openai.Completion.create(\n\nengine=\"text-davinci-001\",\n\nprompt=prompt,\n\ntemperature=0.0,\n\nmax\\_tokens=300\n\n)\n\nprint(f\"Response: {response}\")\n\nstripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text)\n\ntry:\n\nrelevancy\\_score = int(stripped\\_response)\n\nexcept ValueError:\n\nrelevancy\\_score = 0\n\nprint(f\"Relevancy score: {relevancy\\_score}\")\n\nelse:\n\nprint(\"Relevancy score already calculated.\")\n\ntime.sleep(.5)\n\nreturn relevancy\\_score\n\nasync def get\\_agent\\_message(self, truncated\\_chat\\_history):\n\nmessage = \"\"\n\nif isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]):\n\nresponse = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history)\n\nmessage = f\"{response}\"\n\nreturn message\n\nasync def respond(self):\n\nawait self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n\nawait self.websocket.send(json.dumps({\"action\": \"stopped\\_typing\", \"sender\": self.name}))\n\nagent\\_message = await self.get\\_agent\\_message(self.parliament.chat\\_history.truncated\\_chat\\_history)\n\nawait self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name}))\n\ndef reset\\_relevancy\\_score(self):\n\nself.relevancy\\_score = None\n\nclass ChatHistory:\n\ndef **init**(self):\n\nself.chat\\_history = \\[\\]\n\nself.truncated\\_chat\\_history = \"\"\n\ndef add(self, message, sender, timestamp):\n\nself.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\nself.truncate\\_chat\\_history()\n\ndef truncate\\_chat\\_history(self, max\\_length=2000):\n\nchat\\_history\\_str = '\\\\n'.join(\\[message\\[\"message\"\\] for message in self.chat\\_history\\])\n\nself.truncated\\_chat\\_history = chat\\_history\\_str\\[-max\\_length:\\]\n\ndef get\\_latest\\_message(self):\n\nreturn self.chat\\_history\\[-1\\] if self.chat\\_history else None\n\nclass SpeakerManager:\n\ndef **init**(self, parliament):\n\nself.parliament = parliament\n\ndef should\\_speak(self, agent):\n\nreturn self.parliament.speaking\\_queue\\[0\\] == agent.name if self.parliament.speaking\\_queue else False\n\nclass OpenAIAgent:\n\ndef **init**(self, initial\\_context: str):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\"\n\nself.model = \"gpt-3.5-turbo\"\n\nself.initial\\_context = initial\\_context\n\ndef get\\_response(self, truncated\\_chat):\n\nsystem\\_msg = self.initial\\_context\n\nmessages=\\[\\]\n\nmessages.append({\"role\": \"assistant\", \"content\": truncated\\_chat})\n\nmax\\_retries = 3\n\nretry\\_delay = 5\n\nfor i in range(max\\_retries):\n\ntry:\n\n\\# Call the OpenAI API with the messages array\n\nresponse = openai.ChatCompletion.create(\n\nmodel=self.model,\n\nmessages=messages,\n\nmax\\_tokens=150,\n\ntemperature=0.5,\n\ntop\\_p=1,\n\nfrequency\\_penalty=0,\n\npresence\\_penalty=0,\n\n)\n\n\\# Extract and return the assistant's response from the API response\n\nagent\\_response = response.choices\\[0\\].message\\[\"content\"\\].strip()\n\nprint(f\" {agent\\_response}\") # Add logging\n\nreturn agent\\_response\n\nexcept RateLimitError as e:\n\nprint(f\"Rate limit error: {e}. Retrying in {retry\\_delay} seconds...\")\n\nif i < max\\_retries - 1: # Don't sleep on the last iteration\n\ntime.sleep(retry\\_delay)\n\nelse:\n\nraise\n\nreturn \"Sorry, I am unable to respond at the moment.\"\n\nclass GPT4AllAgent:\n\ndef **init**(self):\n\n\\# Download and set up the GPT4All model\n\nself.\\_initialize\\_gpt4all\\_model()\n\nself.\\_initialize\\_llm\\_chain()\n\ndef _initialize_gpt4all\\_model(self):\n\nlocal\\_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n\nPath(local\\_path).parent.mkdir(parents=True, exist\\_ok=True)\n\nurl = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n\nresponse = requests.get(url, stream=True)\n\nwith open(local\\_path, 'wb') as f:\n\nfor chunk in tqdm(response.iter\\_content(chunk\\_size=8192)):\n\nif chunk:\n\nf.write(chunk)\n\nself.model\\_path = local\\_path\n\ndef _initialize_llm\\_chain(self):\n\ntemplate = \"\"\"{chat\\_history}\n\nQuestion: {question}\n\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input\\_variables=\\[\"chat\\_history\", \"question\"\\])\n\ncallbacks = \\[StreamingStdOutCallbackHandler()\\]\n\nllm = GPT4All(model=self.model\\_path, callbacks=callbacks, verbose=True)\n\nself.llm\\_chain = LLMChain(prompt=prompt, llm=llm)\n\ndef get\\_response(self, chat\\_history, question):\n\nreturn self.llm\\_chain.run(chat\\_history=chat\\_history, question=question)\n\nimport json\n\nfrom typing import List\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nclass Parliament:\n\ndef **init**(self, name: str): # Added name argument\n\nself.name = name # Added this line to store the name\n\nself.agents: List\\[Agent\\] = \\[\\]\n\nself.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n\nself.agent\\_instances = {}\n\nself.chat\\_history = ChatHistory()\n\nasync def handle\\_client(self, websocket, path):\n\nasync for message in websocket:\n\nmessage = json.loads(message)\n\nif message\\['action'\\] == 'send\\_message':\n\nself.chat\\_history.add(message\\['message'\\], message\\['sender'\\], message\\['timestamp'\\])\n\nfor agent in self.agents:\n\nif agent.websocket == websocket:\n\nagent.reset\\_relevancy\\_score()\n\nif message.get('reply\\_agent', None):\n\nfor agent in self.agents:\n\nif agent.name == message\\['reply\\_agent'\\]:\n\nawait agent.respond()\n\nelif message\\['action'\\] == 'request\\_agents':\n\nawait self.send\\_agent\\_list(websocket)\n\nelif message\\['action'\\] == UPDATE\\_AGENTS:\n\nself.update\\_agents(message\\['agents'\\], websocket)\n\nasync def send\\_agent\\_list(self, websocket):\n\nagents\\_list = \\[{\"name\": agent.name, \"context\": agent.context} for agent in self.agents\\]\n\nawait websocket.send(json.dumps({\"action\": \"receive\\_agents\", \"agents\": agents\\_list}))\n\ndef update\\_agents(self, agents, websocket):\n\nself.agents = \\[\\]\n\nfor agent in agents:\n\nself.agents.append(Agent(self, agent\\['name'\\], agent\\['context'\\], agent\\['type'\\], self.agent\\_instances\\[agent\\['type'\\]\\], websocket))\n\ndef add\\_agent\\_type(self, agent\\_type\\_name, agent\\_type\\_class):\n\nself.agent\\_types\\[agent\\_type\\_name\\] = agent\\_type\\_class\n\ndef add\\_agent\\_instance(self, agent\\_instance\\_name, agent\\_instance):\n\nself.agent\\_instances\\[agent\\_instance\\_name\\] = agent\\_instance\n\ndef add\\_agent(self, agent):\n\nself.agents.append(agent)",
      "created_at": "2023-05-20T17:34:26.307688Z",
      "sequence_order": 12,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:34:26.307688Z",
            "stop_timestamp": "2023-05-20T17:34:26.307688Z",
            "flags": null,
            "type": "text",
            "text": "error\n\nWebSocket server is running on ws://localhost:8080\n\nconnection handler failed\n\nTraceback (most recent call last):\n\nFile \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n\nawait self.ws\\_handler(self)\n\nFile \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n\nreturn await cast(\n\nFile \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 41, in chat\n\nawait self.handle\\_typing(websocket, data)\n\nFile \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 48, in handle\\_typing\n\nself.parliament.set\\_typing\\_status(sender, is\\_typing)\n\nAttributeError: 'Parliament' object has no attribute 'set\\_typing\\_status'\n\nWhy can't I set typing status on the agents directly rather than sending into parliament?\n\nserver.py\n\n\\# Constants\n\nSET\\_PARLIAMENT = \"set\\_parliament\"\n\nSEND\\_MESSAGE = \"send\\_message\"\n\nADD\\_AGENTS = \"add\\_agents\"\n\nUPDATE\\_QUEUE = \"update\\_queue\"\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nRECEIVE\\_MESSAGE = \"receive\\_message\"\n\nERROR = \"error\"\n\nTYPING = \"typing\"\n\nSTOPPED\\_TYPING = \"stopped\\_typing\"\n\nclass ParliamentServer:\n\ndef **init**(self, host=\"localhost\", port=8080):\n\nself.host = host\n\nself.port = port\n\nself.parliament = None\n\nself.start\\_server = serve(self.chat, self.host, self.port)\n\ndef configure\\_openai(self):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\"\n\nasync def chat(self, websocket, path):\n\nasync for message in websocket:\n\ndata = json.loads(message)\n\naction = data.get(\"action\")\n\nif action == SET\\_PARLIAMENT:\n\nawait self.handle\\_set\\_parliament(websocket, data)\n\nelif action == SEND\\_MESSAGE:\n\nawait self.handle\\_send\\_message(websocket, data)\n\nelif action == ADD\\_AGENTS:\n\nawait self.handle\\_add\\_agents(websocket, data)\n\nelif action in \\[TYPING, STOPPED\\_TYPING\\]:\n\nawait self.handle\\_typing(websocket, data)\n\nasync def handle\\_typing(self, websocket, data):\n\nsender = data.get('sender')\n\naction = data.get('action')\n\nis\\_typing = action == TYPING\n\nself.parliament.set\\_typing\\_status(sender, is\\_typing)\n\n\\# Send the typing status update to other clients:\n\nawait websocket.send(json.dumps({\n\n\"action\": action,\n\n\"sender\": sender,\n\n\"is\\_typing\": is\\_typing\n\n}))\n\nasync def handle\\_set\\_parliament(self, websocket, data):\n\nparliament\\_name = data.get(\"name\")\n\nif parliament\\_name:\n\nself.parliament = Parliament(parliament\\_name)\n\nasync def handle\\_send\\_message(self, websocket, data):\n\nif not self.parliament:\n\nawait self.send\\_error(websocket, \"Parliament not set.\")\n\nreturn\n\nsender = data.get(\"sender\")\n\nuser\\_message = data.get(\"message\")\n\ntimestamp = datetime.now()\n\nawait websocket.send(json.dumps({\n\n\"action\": RECEIVE\\_MESSAGE,\n\n\"message\": user\\_message,\n\n\"sender\": sender,\n\n\"timestamp\": timestamp.isoformat()}))\n\nawait self.parliament.broadcast\\_message(user\\_message, sender, timestamp)\n\nprint(f\"Broadcast message: {user\\_message}\") # Add logging\n\n\\# Sending agent info after broadcasting message\n\nagent\\_info = await self.parliament.get\\_agents\\_info()\n\nawait websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info}))\n\nawait self.update\\_queue(websocket)\n\nasync def handle\\_add\\_agents(self, websocket, data):\n\nif not self.parliament:\n\nawait self.send\\_error(websocket, \"Parliament not set.\")\n\nreturn\n\nagents\\_data = data.get(\"agents\")\n\nif not agents\\_data:\n\nawait self.send\\_error(websocket, \"No agent data provided.\")\n\nreturn\n\nfor agent\\_data in agents\\_data:\n\nagent\\_name = agent\\_data.get(\"name\") # Extract the name\n\nspeaking\\_pressure\\_increment = int(agent\\_data.get(\"speaking\\_pressure\\_increment\"))\n\nother\\_agents = \", \".join(\\[agent\\['name'\\] for agent in agents\\_data if agent\\['name'\\] != agent\\_name\\])\n\ninitial\\_context = (\n\nf\"Hello assistant, your name is: @{agent\\_data.get('name')} and your context is \"\n\nf\"{agent\\_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n\nf\"alongside your fellow agents in a parliament, which is a sort \"\n\nf\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n\nf\"with you are {other\\_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n\nf\"{agent\\_data.get('speaking\\_pressure\\_increment')} out of 100\"\n\n)\n\nagent\\_type = agent\\_data.get(\"type\")\n\nagent\\_class = self.parliament.agent\\_types.get(agent\\_type) # Get OpenAIAgent or GPT4AllAgent\n\nagent\\_instance = agent\\_class(initial\\_context) # Properly instantiate the class\n\nif isinstance(agent\\_instance, self.parliament.agent\\_types\\[agent\\_type\\]):\n\nagent\\_instance = OpenAIAgent(initial\\_context) # Create the OpenAIAgent instance\n\nagent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket)\n\nself.parliament.add\\_agent(agent) # Pass the agent instance to add\\_agent\n\nelse:\n\nprint(\"Error occurred attempting to get agent message!\")\n\nreturn \"Sorry, I'm unable to generate a relevant response at this time.\"\n\nawait self.send\\_error(websocket, f\"Unknown agent type: {agent\\_type}\")\n\ncontinue\n\nasync def update\\_queue(self, websocket):\n\nif self.parliament:\n\nspeaking\\_queue = self.parliament.get\\_speaking\\_queue()\n\nprint(f\"Queue updated: {speaking\\_queue}\")\n\nawait websocket.send(json.dumps({\"action\": UPDATE\\_QUEUE, \"queue\": speaking\\_queue}))\n\nasync def send\\_error(self, websocket, message):\n\nawait websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\ndef run(self):\n\nself.configure\\_openai()\n\nasyncio.get\\_event\\_loop().run\\_until\\_complete(self.start\\_server)\n\nprint(\"Starting WebSocket server...\")\n\nprint(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n\nasyncio.get\\_event\\_loop().run\\_forever()\n\nif **name** == \"\\_\\_main\\_\\_\":\n\nserver = ParliamentServer()\n\nserver.run()\n\nparliament.py\n\nimport asyncio\n\nimport re\n\nimport random\n\nimport json\n\nimport openai\n\nfrom openai.error import RateLimitError\n\nimport time\n\nfrom typing import List\n\nfrom collections import deque\n\nPRESSURE\\_INCREMENT\\_INTERVAL = 15\n\nSPEAKING\\_PRESSURE\\_LIMIT = 100\n\nBROADCAST\\_DELAY = 10\n\nRELEVANCY\\_THRESHOLD = 100\n\nSTOPPED\\_TYPING = \"stopped\\_typing\"\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nclass Agent:\n\ndef **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None):\n\nself.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment\n\nself.name = agent\\_name\n\nself.context = initial\\_context\n\nself.initial\\_context = initial\\_context\n\nself.agent\\_type = agent\\_type\n\nself.agent\\_instance = agent\\_instance\n\nself.websocket = websocket\n\nself.parliament = parliament\n\nself.relevancy\\_score = None\n\nasync def calculate\\_relevancy(self, chat\\_context):\n\nrelevancy\\_score = 0\n\nif self.relevancy\\_score is None or self.initial\\_context != chat\\_context:\n\nprint(\"Calculating relevancy...\")\n\nprompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n\nprint(f\"Prompt: {prompt}\")\n\nresponse = openai.Completion.create(\n\nengine=\"text-davinci-001\",\n\nprompt=prompt,\n\ntemperature=0.0,\n\nmax\\_tokens=300\n\n)\n\nprint(f\"Response: {response}\")\n\nstripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text)\n\ntry:\n\nrelevancy\\_score = int(stripped\\_response)\n\nexcept ValueError:\n\nrelevancy\\_score = 0\n\nprint(f\"Relevancy score: {relevancy\\_score}\")\n\nelse:\n\nprint(\"Relevancy score already calculated.\")\n\ntime.sleep(.5)\n\nreturn relevancy\\_score\n\nasync def get\\_agent\\_message(self, truncated\\_chat\\_history):\n\nmessage = \"\"\n\nif isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]):\n\nresponse = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history)\n\nmessage = f\"{response}\"\n\nreturn message\n\nasync def respond(self):\n\nawait self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n\nawait self.websocket.send(json.dumps({\"action\": \"stopped\\_typing\", \"sender\": self.name}))\n\nagent\\_message = await self.get\\_agent\\_message(self.parliament.chat\\_history.truncated\\_chat\\_history)\n\nawait self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name}))\n\ndef reset\\_relevancy\\_score(self):\n\nself.relevancy\\_score = None\n\nclass ChatHistory:\n\ndef **init**(self):\n\nself.chat\\_history = \\[\\]\n\nself.truncated\\_chat\\_history = \"\"\n\ndef add(self, message, sender, timestamp):\n\nself.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\nself.truncate\\_chat\\_history()\n\ndef truncate\\_chat\\_history(self, max\\_length=2000):\n\nchat\\_history\\_str = '\\\\n'.join(\\[message\\[\"message\"\\] for message in self.chat\\_history\\])\n\nself.truncated\\_chat\\_history = chat\\_history\\_str\\[-max\\_length:\\]\n\ndef get\\_latest\\_message(self):\n\nreturn self.chat\\_history\\[-1\\] if self.chat\\_history else None\n\nclass SpeakerManager:\n\ndef **init**(self, parliament):\n\nself.parliament = parliament\n\ndef should\\_speak(self, agent):\n\nreturn self.parliament.speaking\\_queue\\[0\\] == agent.name if self.parliament.speaking\\_queue else False\n\nclass OpenAIAgent:\n\ndef **init**(self, initial\\_context: str):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\"\n\nself.model = \"gpt-3.5-turbo\"\n\nself.initial\\_context = initial\\_context\n\ndef get\\_response(self, truncated\\_chat):\n\nsystem\\_msg = self.initial\\_context\n\nmessages=\\[\\]\n\nmessages.append({\"role\": \"assistant\", \"content\": truncated\\_chat})\n\nmax\\_retries = 3\n\nretry\\_delay = 5\n\nfor i in range(max\\_retries):\n\ntry:\n\n\\# Call the OpenAI API with the messages array\n\nresponse = openai.ChatCompletion.create(\n\nmodel=self.model,\n\nmessages=messages,\n\nmax\\_tokens=150,\n\ntemperature=0.5,\n\ntop\\_p=1,\n\nfrequency\\_penalty=0,\n\npresence\\_penalty=0,\n\n)\n\n\\# Extract and return the assistant's response from the API response\n\nagent\\_response = response.choices\\[0\\].message\\[\"content\"\\].strip()\n\nprint(f\" {agent\\_response}\") # Add logging\n\nreturn agent\\_response\n\nexcept RateLimitError as e:\n\nprint(f\"Rate limit error: {e}. Retrying in {retry\\_delay} seconds...\")\n\nif i < max\\_retries - 1: # Don't sleep on the last iteration\n\ntime.sleep(retry\\_delay)\n\nelse:\n\nraise\n\nreturn \"Sorry, I am unable to respond at the moment.\"\n\nclass GPT4AllAgent:\n\ndef **init**(self):\n\n\\# Download and set up the GPT4All model\n\nself.\\_initialize\\_gpt4all\\_model()\n\nself.\\_initialize\\_llm\\_chain()\n\ndef _initialize_gpt4all\\_model(self):\n\nlocal\\_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n\nPath(local\\_path).parent.mkdir(parents=True, exist\\_ok=True)\n\nurl = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n\nresponse = requests.get(url, stream=True)\n\nwith open(local\\_path, 'wb') as f:\n\nfor chunk in tqdm(response.iter\\_content(chunk\\_size=8192)):\n\nif chunk:\n\nf.write(chunk)\n\nself.model\\_path = local\\_path\n\ndef _initialize_llm\\_chain(self):\n\ntemplate = \"\"\"{chat\\_history}\n\nQuestion: {question}\n\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input\\_variables=\\[\"chat\\_history\", \"question\"\\])\n\ncallbacks = \\[StreamingStdOutCallbackHandler()\\]\n\nllm = GPT4All(model=self.model\\_path, callbacks=callbacks, verbose=True)\n\nself.llm\\_chain = LLMChain(prompt=prompt, llm=llm)\n\ndef get\\_response(self, chat\\_history, question):\n\nreturn self.llm\\_chain.run(chat\\_history=chat\\_history, question=question)\n\nimport json\n\nfrom typing import List\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nclass Parliament:\n\ndef **init**(self, name: str): # Added name argument\n\nself.name = name # Added this line to store the name\n\nself.agents: List\\[Agent\\] = \\[\\]\n\nself.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n\nself.agent\\_instances = {}\n\nself.chat\\_history = ChatHistory()\n\nasync def handle\\_client(self, websocket, path):\n\nasync for message in websocket:\n\nmessage = json.loads(message)\n\nif message\\['action'\\] == 'send\\_message':\n\nself.chat\\_history.add(message\\['message'\\], message\\['sender'\\], message\\['timestamp'\\])\n\nfor agent in self.agents:\n\nif agent.websocket == websocket:\n\nagent.reset\\_relevancy\\_score()\n\nif message.get('reply\\_agent', None):\n\nfor agent in self.agents:\n\nif agent.name == message\\['reply\\_agent'\\]:\n\nawait agent.respond()\n\nelif message\\['action'\\] == 'request\\_agents':\n\nawait self.send\\_agent\\_list(websocket)\n\nelif message\\['action'\\] == UPDATE\\_AGENTS:\n\nself.update\\_agents(message\\['agents'\\], websocket)\n\nasync def send\\_agent\\_list(self, websocket):\n\nagents\\_list = \\[{\"name\": agent.name, \"context\": agent.context} for agent in self.agents\\]\n\nawait websocket.send(json.dumps({\"action\": \"receive\\_agents\", \"agents\": agents\\_list}))\n\ndef update\\_agents(self, agents, websocket):\n\nself.agents = \\[\\]\n\nfor agent in agents:\n\nself.agents.append(Agent(self, agent\\['name'\\], agent\\['context'\\], agent\\['type'\\], self.agent\\_instances\\[agent\\['type'\\]\\], websocket))\n\ndef add\\_agent\\_type(self, agent\\_type\\_name, agent\\_type\\_class):\n\nself.agent\\_types\\[agent\\_type\\_name\\] = agent\\_type\\_class\n\ndef add\\_agent\\_instance(self, agent\\_instance\\_name, agent\\_instance):\n\nself.agent\\_instances\\[agent\\_instance\\_name\\] = agent\\_instance\n\ndef add\\_agent(self, agent):\n\nself.agents.append(agent)",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:34:26.307688Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "ad1f2e23-532d-4ba9-903a-b74a8d9b1594",
      "role": "assistant",
      "content": " You're correct, there's no need to set the typing status on the Parliament object. You can set it directly on the agent.\n\nHere are the changes I would make:\n\nIn server.py:\n- Remove the call to self.parliament.set_typing_status(sender, is_typing)\n- Instead, loop through the agents and call agent.set_typing_status(is_typing) for the agent with the matching name.\n\nSo the updated handle_typing method would be:\n```python\nasync def handle_typing(self, websocket, data):\n    sender = data.get('sender')\n    action = data.get('action')\n    is_typing = action == TYPING\n    for agent in self.parliament.agents:\n        if agent.name == sender:\n            agent.set_typing_status(is_typing)\n    # Send the typing status update to other clients:\n    await websocket.send(json.dumps({\n        \"action\": action,\n        \"sender\": sender,\n        \"is_typing\": is_typing \n    })) \n```\n\nIn parliament.py:\n- Add a set_typing_status method to the Agent class\n- The method should simply set self.is_typing to the passed in status\n\nSo the Agent class would have:\n```python\nclass Agent:\n    ...\n    def set_typing_status(self, status: bool):\n        self.is_typing = status \n```\n\nThis will allow directly setting and accessing the typing status on the agent, rather than routing through the Parliament object.\n\nLet me know if you have any other questions!",
      "created_at": "2023-05-20T17:35:00.829118Z",
      "sequence_order": 13,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:35:00.829118Z",
            "stop_timestamp": "2023-05-20T17:35:00.829118Z",
            "flags": null,
            "type": "text",
            "text": " You're correct, there's no need to set the typing status on the Parliament object. You can set it directly on the agent.\n\nHere are the changes I would make:\n\nIn server.py:\n- Remove the call to self.parliament.set_typing_status(sender, is_typing)\n- Instead, loop through the agents and call agent.set_typing_status(is_typing) for the agent with the matching name.\n\nSo the updated handle_typing method would be:\n```python\nasync def handle_typing(self, websocket, data):\n    sender = data.get('sender')\n    action = data.get('action')\n    is_typing = action == TYPING\n    for agent in self.parliament.agents:\n        if agent.name == sender:\n            agent.set_typing_status(is_typing)\n    # Send the typing status update to other clients:\n    await websocket.send(json.dumps({\n        \"action\": action,\n        \"sender\": sender,\n        \"is_typing\": is_typing \n    })) \n```\n\nIn parliament.py:\n- Add a set_typing_status method to the Agent class\n- The method should simply set self.is_typing to the passed in status\n\nSo the Agent class would have:\n```python\nclass Agent:\n    ...\n    def set_typing_status(self, status: bool):\n        self.is_typing = status \n```\n\nThis will allow directly setting and accessing the typing status on the agent, rather than routing through the Parliament object.\n\nLet me know if you have any other questions!",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:35:00.829118Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "ea051c3e-2b62-44d8-9d92-c8ad9dc986f1",
      "role": "human",
      "content": "do I need to add it to init?\n\nclass Agent:\n\ndef **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None):\n\nself.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment\n\nself.name = agent\\_name\n\nself.context = initial\\_context\n\nself.initial\\_context = initial\\_context\n\nself.agent\\_type = agent\\_type\n\nself.agent\\_instance = agent\\_instance\n\nself.websocket = websocket\n\nself.parliament = parliament\n\nself.relevancy\\_score = None\n\ndef set\\_typing\\_status(self, status: bool):\n\nself.is\\_typing = status",
      "created_at": "2023-05-20T17:37:17.770244Z",
      "sequence_order": 14,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:37:17.770244Z",
            "stop_timestamp": "2023-05-20T17:37:17.770244Z",
            "flags": null,
            "type": "text",
            "text": "do I need to add it to init?\n\nclass Agent:\n\ndef **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None):\n\nself.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment\n\nself.name = agent\\_name\n\nself.context = initial\\_context\n\nself.initial\\_context = initial\\_context\n\nself.agent\\_type = agent\\_type\n\nself.agent\\_instance = agent\\_instance\n\nself.websocket = websocket\n\nself.parliament = parliament\n\nself.relevancy\\_score = None\n\ndef set\\_typing\\_status(self, status: bool):\n\nself.is\\_typing = status",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:37:17.770244Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "b27ad6d9-7c59-4900-bcf1-2abea3cf93d4",
      "role": "assistant",
      "content": " You're right, you should also add is_typing to the Agent.__init__ method. A typing status attribute will be needed on each new agent instance, so it makes sense to initialize it in the constructor.\n\nThe updated Agent class would be:\n```python\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n        self.is_typing = False  # Added this\n        \n    def set_typing_status(self, status: bool):\n        self.is_typing = status\n```\n\nThe full initialization logic would then be:\n```python \nself.name = agent_name         \nself.context = initial_context   \nself.initial_context = initial_context \nself.agent_type = agent_type\nself.agent_instance = agent_instance\nself.websocket = websocket\nself.parliament = parliament\nself.relevancy_score = None\nself.is_typing = False   # Added this \n```\n\nWith this addition, each new agent instance will have an is_typing attribute initialized to False, which can then be updated by calling agent.set_typing_status().\n\nLet me know if you have any other questions!",
      "created_at": "2023-05-20T17:37:40.442663Z",
      "sequence_order": 15,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:37:40.442663Z",
            "stop_timestamp": "2023-05-20T17:37:40.442663Z",
            "flags": null,
            "type": "text",
            "text": " You're right, you should also add is_typing to the Agent.__init__ method. A typing status attribute will be needed on each new agent instance, so it makes sense to initialize it in the constructor.\n\nThe updated Agent class would be:\n```python\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, websocket=None):\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n        self.is_typing = False  # Added this\n        \n    def set_typing_status(self, status: bool):\n        self.is_typing = status\n```\n\nThe full initialization logic would then be:\n```python \nself.name = agent_name         \nself.context = initial_context   \nself.initial_context = initial_context \nself.agent_type = agent_type\nself.agent_instance = agent_instance\nself.websocket = websocket\nself.parliament = parliament\nself.relevancy_score = None\nself.is_typing = False   # Added this \n```\n\nWith this addition, each new agent instance will have an is_typing attribute initialized to False, which can then be updated by calling agent.set_typing_status().\n\nLet me know if you have any other questions!",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:37:40.442663Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "04f9737d-bc72-4e3f-a4b7-e00f9dc48cc5",
      "role": "human",
      "content": "does it also need to go into the def **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None): line\n\nSo something like\n\ndef **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, is\\_typing,\n\nwebsocket=None):",
      "created_at": "2023-05-20T17:39:45.521319Z",
      "sequence_order": 16,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:39:45.521319Z",
            "stop_timestamp": "2023-05-20T17:39:45.521319Z",
            "flags": null,
            "type": "text",
            "text": "does it also need to go into the def **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None): line\n\nSo something like\n\ndef **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, is\\_typing,\n\nwebsocket=None):",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:39:45.521319Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "0d971ca6-e82e-4e74-b44d-a56330171f75",
      "role": "assistant",
      "content": " You're correct, is_typing should also be added as an argument to Agent.__init__, since it is an attribute that will differ for each agent instance.\n\nThe updated __init__ method would be:\n```python\ndef __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, is_typing, websocket=None):\n```\n\nAnd you can pass the initial is_typing value (likely False) when creating a new Agent, like:\n```python\nagent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, False, websocket)\n```\n\nSo the full Agent class would be:\n```python\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, is_typing, websocket=None):\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n        self.is_typing = is_typing  \n        \n    def set_typing_status(self, status: bool):\n        self.is_typing = status\n```\n\nLet me know if this helps clarify how to properly add the is_typing attribute to the Agent class!",
      "created_at": "2023-05-20T17:40:18.844827Z",
      "sequence_order": 17,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:40:18.844827Z",
            "stop_timestamp": "2023-05-20T17:40:18.844827Z",
            "flags": null,
            "type": "text",
            "text": " You're correct, is_typing should also be added as an argument to Agent.__init__, since it is an attribute that will differ for each agent instance.\n\nThe updated __init__ method would be:\n```python\ndef __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, is_typing, websocket=None):\n```\n\nAnd you can pass the initial is_typing value (likely False) when creating a new Agent, like:\n```python\nagent = Agent(self.parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, False, websocket)\n```\n\nSo the full Agent class would be:\n```python\nclass Agent:\n    def __init__(self, parliament, agent_name, speaking_pressure_increment, initial_context, agent_type, agent_instance, is_typing, websocket=None):\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.name = agent_name\n        self.context = initial_context\n        self.initial_context = initial_context\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.relevancy_score = None\n        self.is_typing = is_typing  \n        \n    def set_typing_status(self, status: bool):\n        self.is_typing = status\n```\n\nLet me know if this helps clarify how to properly add the is_typing attribute to the Agent class!",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:40:18.844827Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "db4642ab-ec96-4c39-bef3-2d87e1fd5329",
      "role": "human",
      "content": "error broadcast messages: Starting WebSocket server... WebSocket server is running on ws://localhost:8080 connection handler failed Traceback (most recent call last): File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler await self.ws\\_handler(self) File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler return await cast( File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 37, in chat await self.handle\\_send\\_message(websocket, data) File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 74, in handle\\_send\\_message await self.parliament.broadcast\\_message(user\\_message, sender, timestamp) AttributeError: 'Parliament' object has no attribute 'broadcast\\_message' Server.py from datetime import datetime import asyncio import json from websockets import serve from parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent import openai # Constants SET\\_PARLIAMENT = \"set\\_parliament\" SEND\\_MESSAGE = \"send\\_message\" ADD\\_AGENTS = \"add\\_agents\" UPDATE\\_QUEUE = \"update\\_queue\" UPDATE\\_AGENTS = \"update\\_agents\" RECEIVE\\_MESSAGE = \"receive\\_message\" ERROR = \"error\" TYPING = \"typing\" STOPPED\\_TYPING = \"stopped\\_typing\" class ParliamentServer: def **init**(self, host=\"localhost\", port=8080): self.host = host self.port = port self.parliament = None self.start\\_server = serve(self.chat, self.host, self.port) def configure\\_openai(self): openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\" openai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\" async def chat(self, websocket, path): async for message in websocket: data = json.loads(message) action = data.get(\"action\") if action == SET\\_PARLIAMENT: await self.handle\\_set\\_parliament(websocket, data) elif action == SEND\\_MESSAGE: await self.handle\\_send\\_message(websocket, data) elif action == ADD\\_AGENTS: await self.handle\\_add\\_agents(websocket, data) elif action in \\[TYPING, STOPPED\\_TYPING\\]: await self.handle\\_typing(websocket, data) async def handle\\_typing(self, websocket, data): sender = data.get('sender') action = data.get('action') is\\_typing = action == TYPING for agent in self.parliament.agents: if agent.name == sender: agent.set\\_typing\\_status(is\\_typing) # Send the typing status update to other clients: await websocket.send(json.dumps({ \"action\": action, \"sender\": sender, \"is\\_typing\": is\\_typing })) async def handle\\_set\\_parliament(self, websocket, data): parliament\\_name = data.get(\"name\") if parliament\\_name: self.parliament = Parliament(parliament\\_name) async def handle\\_send\\_message(self, websocket, data): if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return sender = data.get(\"sender\") user\\_message = data.get(\"message\") timestamp = datetime.now() await websocket.send(json.dumps({ \"action\": RECEIVE\\_MESSAGE, \"message\": user\\_message, \"sender\": sender, \"timestamp\": timestamp.isoformat()})) await self.parliament.broadcast\\_message(user\\_message, sender, timestamp) print(f\"Broadcast message: {user\\_message}\") # Add logging # Sending agent info after broadcasting message agent\\_info = await self.parliament.get\\_agents\\_info() await websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info})) await self.update\\_queue(websocket) async def handle\\_add\\_agents(self, websocket, data): if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return agents\\_data = data.get(\"agents\") if not agents\\_data: await self.send\\_error(websocket, \"No agent data provided.\") return for agent\\_data in agents\\_data: agent\\_name = agent\\_data.get(\"name\") # Extract the name speaking\\_pressure\\_increment = int(agent\\_data.get(\"speaking\\_pressure\\_increment\")) other\\_agents = \", \".join(\\[agent\\['name'\\] for agent in agents\\_data if agent\\['name'\\] != agent\\_name\\]) initial\\_context = ( f\"Hello assi of 100\" ) agent\\_type = agent\\_data.get(\"type\") agent\\_class = self.parliament.agent\\_types.get(agent\\_type) # Get OpenAIAgent or GPT4AllAgent agent\\_instance = agent\\_class(initial\\_context) # Properly instantiate the class if isinstance(agent\\_instance, self.parliament.agent\\_types\\[agent\\_type\\]): agent\\_instance = OpenAIAgent(initial\\_context) # Create the OpenAIAgent instance agent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket) self.parliament.add\\_agent(agent) # Pass the agent instance to add\\_agent else: print(\"Error occurred attempting to get agent message!\") return \"Sorry, I'm unable to generate a relevant response at this time.\" await self.send\\_error(websocket, f\"Unknown agent type: {agent\\_type}\") continue async def update\\_queue(self, websocket): if self.parliament: speaking\\_queue = self.parliament.get\\_speaking\\_queue() print(f\"Queue updated: {speaking\\_queue}\") await websocket.send(json.dumps({\"action\": UPDATE\\_QUEUE, \"queue\": speaking\\_queue})) async def send\\_error(self, websocket, message): await websocket.send(json.dumps({\"action\": ERROR, \"message\": message})) def run(self): self.configure\\_openai() asyncio.get\\_event\\_loop().run\\_until\\_complete(self.start\\_server) print(\"Starting WebSocket server...\") print(f\"WebSocket server is running on ws://{self.host}:{self.port}\") asyncio.get\\_event\\_loop().run\\_forever() if **name** == \"\\_\\_main\\_\\_\": server = ParliamentServer() server.run() parliament.py import asyncio PRESSURE\\_INCREMENT\\_INTERVAL = 15 SPEAKING\\_PRESSURE\\_LIMIT = 100 BROADCAST\\_DELAY = 10 RELEVANCY\\_THRESHOLD = 100 STOPPED\\_TYPING = \"stopped\\_typing\" UPDATE\\_AGENTS = \"update\\_agents\" class Agent: def **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None): self.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment self.name = agent\\_name self.context = initial\\_context self.initial\\_context = initial\\_context self.agent\\_type = agent\\_type self.agent\\_instance = agent\\_instance self.websocket = websocket self.parliament = parliament self.relevancy\\_score = None def set\\_typing\\_status(self, status: bool): self.is\\_typing = status async def calculate\\_relevancy(self, chat\\_context): relevancy\\_score = 0 if self.relevancy\\_score is None or self.initial\\_context != chat\\_context: print(\"Calculating relevancy...\") prompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\" print(f\"Prompt: {prompt}\") response = openai.Completion.create( engine=\"text-davinci-001\", prompt=prompt, temperature=0.0, max\\_tokens=300 ) print(f\"Response: {response}\") stripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text) try: relevancy\\_score = int(stripped\\_response) except ValueError: relevancy\\_score = 0 print(f\"Relevancy score: {relevancy\\_score}\") else: print(\"Relevancy score already calculated.\") time.sleep(.5) return relevancy\\_score async def get\\_agent\\_message(self, truncated\\_chat\\_history): message = \"\" if isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]): response = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history) message = f\"{response}\" return message async def respond(self): await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name})) await self.websocket.send(json.dumps({\"action\": \"stopped\\_typing\", \"sender\": self.name})) agent\\_message = await self.get\\_agent\\_message(self.parliament.chat\\_history.truncated\\_chat\\_history) await self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name})) def reset\\_relevancy\\_score(self): self.relevancy\\_score = None class ChatHistory: def **init**(self): self.chat\\_history = \\[\\] self.truncated\\_chat\\_history = \"\" def add(self, message, sender, timestamp): self.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp}) self.truncate\\_chat\\_history() def truncate\\_chat\\_history(self, max\\_length=2000): chat\\_history\\_str = '\\\\n'.join(\\[message\\[\"message\"\\] for message in self.chat\\_history\\]) self.truncated\\_chat\\_history = chat\\_history\\_str\\[-max\\_length:\\] def get\\_latest\\_message(self): return self.chat\\_history\\[-1\\] if self.chat\\_history else None class SpeakerManager: def **init**(self, parliament): self.parliament = parliament def should\\_speak(self, agent): return self.parliament.speaking\\_queue\\[0\\] == agent.name if self.parliament.speaking\\_queue else False class OpenAIAgent: def **init**(self, initial\\_context: str): openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\" openai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\" self.model = \"gpt-3.5-turbo\" self.initial\\_context = initial\\_context def get\\_response(self, truncated\\_chat): system\\_msg = self.initial\\_context messages=\\[\\] messages.append({\"role\": \"assistant\", \"content\": truncated\\_chat}) max\\_retries = 3 retry\\_delay = 5 for i in range(max\\_retries): try: # Call the OpenAI API with the messages array response = openai.ChatCompletion.create( model=self.model, messages=messages, max\\_tokens=150, temperature=0.5, top\\_p=1, frequency\\_penalty=0, presence\\_penalty=0, ) # Extract and return the assistant's response from the API response agent\\_response = response.choices\\[0\\].message\\[\"content\"\\].strip() print(f\" {agent\\_response}\") # Add logging return agent\\_response except RateLimitError as e: print(f\"Rate limit error: {e}. Retrying in {retry\\_delay} seconds...\") if i < max\\_retries - 1: # Don't sleep on the last iteration time.sleep(retry\\_delay) else: raise return \"Sorry, I am unable to respond at the moment.\" import json from typing import List UPDATE\\_AGENTS = \"update\\_agents\" class Parliament: def **init**(self, name: str): # Added name argument self.name = name # Added this line to store the name self.agents: List\\[Agent\\] = \\[\\] self.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent} self.agent\\_instances = {} self.chat\\_history = ChatHistory() async def handle\\_client(self, websocket, path): async for message in websocket: message = json.loads(message) if message\\['action'\\] == 'send\\_message': self.chat\\_history.add(message\\['message'\\], message\\['sender'\\], message\\['timestamp'\\]) for agent in self.agents: if agent.websocket == websocket: agent.reset\\_relevancy\\_score() if message.get('reply\\_agent', None): for agent in self.agents: if agent.name == message\\['reply\\_agent'\\]: await agent.respond() elif message\\['action'\\] == 'request\\_agents': await self.send\\_agent\\_list(websocket) elif message\\['action'\\] == UPDATE\\_AGENTS: self.update\\_agents(message\\['agents'\\], websocket) async def send\\_agent\\_list(self, websocket): agents\\_list = \\[{\"name\": agent.name, \"context\": agent.context} for agent in self.agents\\] await websocket.send(json.dumps({\"action\": \"receive\\_agents\", \"agents\": agents\\_list})) def update\\_agents(self, agents, websocket): self.agents = \\[\\] for agent in agents: self.agents.append(Agent(self, agent\\['name'\\], agent\\['context'\\], agent\\['type'\\], self.agent\\_instances\\[agent\\['type'\\]\\], websocket)) def add\\_agent\\_type(self, agent\\_type\\_name, agent\\_type\\_class): self.agent\\_types\\[agent\\_type\\_name\\] = agent\\_type\\_class def add\\_agent\\_instance(self, agent\\_instance\\_name, agent\\_instance): self.agent\\_instances\\[agent\\_instance\\_name\\] = agent\\_instance def add\\_agent(self, agent): self.agents.append(agent)",
      "created_at": "2023-05-20T17:42:29.564699Z",
      "sequence_order": 18,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:42:29.564699Z",
            "stop_timestamp": "2023-05-20T17:42:29.564699Z",
            "flags": null,
            "type": "text",
            "text": "error broadcast messages: Starting WebSocket server... WebSocket server is running on ws://localhost:8080 connection handler failed Traceback (most recent call last): File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler await self.ws\\_handler(self) File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler return await cast( File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 37, in chat await self.handle\\_send\\_message(websocket, data) File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 74, in handle\\_send\\_message await self.parliament.broadcast\\_message(user\\_message, sender, timestamp) AttributeError: 'Parliament' object has no attribute 'broadcast\\_message' Server.py from datetime import datetime import asyncio import json from websockets import serve from parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent import openai # Constants SET\\_PARLIAMENT = \"set\\_parliament\" SEND\\_MESSAGE = \"send\\_message\" ADD\\_AGENTS = \"add\\_agents\" UPDATE\\_QUEUE = \"update\\_queue\" UPDATE\\_AGENTS = \"update\\_agents\" RECEIVE\\_MESSAGE = \"receive\\_message\" ERROR = \"error\" TYPING = \"typing\" STOPPED\\_TYPING = \"stopped\\_typing\" class ParliamentServer: def **init**(self, host=\"localhost\", port=8080): self.host = host self.port = port self.parliament = None self.start\\_server = serve(self.chat, self.host, self.port) def configure\\_openai(self): openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\" openai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\" async def chat(self, websocket, path): async for message in websocket: data = json.loads(message) action = data.get(\"action\") if action == SET\\_PARLIAMENT: await self.handle\\_set\\_parliament(websocket, data) elif action == SEND\\_MESSAGE: await self.handle\\_send\\_message(websocket, data) elif action == ADD\\_AGENTS: await self.handle\\_add\\_agents(websocket, data) elif action in \\[TYPING, STOPPED\\_TYPING\\]: await self.handle\\_typing(websocket, data) async def handle\\_typing(self, websocket, data): sender = data.get('sender') action = data.get('action') is\\_typing = action == TYPING for agent in self.parliament.agents: if agent.name == sender: agent.set\\_typing\\_status(is\\_typing) # Send the typing status update to other clients: await websocket.send(json.dumps({ \"action\": action, \"sender\": sender, \"is\\_typing\": is\\_typing })) async def handle\\_set\\_parliament(self, websocket, data): parliament\\_name = data.get(\"name\") if parliament\\_name: self.parliament = Parliament(parliament\\_name) async def handle\\_send\\_message(self, websocket, data): if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return sender = data.get(\"sender\") user\\_message = data.get(\"message\") timestamp = datetime.now() await websocket.send(json.dumps({ \"action\": RECEIVE\\_MESSAGE, \"message\": user\\_message, \"sender\": sender, \"timestamp\": timestamp.isoformat()})) await self.parliament.broadcast\\_message(user\\_message, sender, timestamp) print(f\"Broadcast message: {user\\_message}\") # Add logging # Sending agent info after broadcasting message agent\\_info = await self.parliament.get\\_agents\\_info() await websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info})) await self.update\\_queue(websocket) async def handle\\_add\\_agents(self, websocket, data): if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return agents\\_data = data.get(\"agents\") if not agents\\_data: await self.send\\_error(websocket, \"No agent data provided.\") return for agent\\_data in agents\\_data: agent\\_name = agent\\_data.get(\"name\") # Extract the name speaking\\_pressure\\_increment = int(agent\\_data.get(\"speaking\\_pressure\\_increment\")) other\\_agents = \", \".join(\\[agent\\['name'\\] for agent in agents\\_data if agent\\['name'\\] != agent\\_name\\]) initial\\_context = ( f\"Hello assi of 100\" ) agent\\_type = agent\\_data.get(\"type\") agent\\_class = self.parliament.agent\\_types.get(agent\\_type) # Get OpenAIAgent or GPT4AllAgent agent\\_instance = agent\\_class(initial\\_context) # Properly instantiate the class if isinstance(agent\\_instance, self.parliament.agent\\_types\\[agent\\_type\\]): agent\\_instance = OpenAIAgent(initial\\_context) # Create the OpenAIAgent instance agent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket) self.parliament.add\\_agent(agent) # Pass the agent instance to add\\_agent else: print(\"Error occurred attempting to get agent message!\") return \"Sorry, I'm unable to generate a relevant response at this time.\" await self.send\\_error(websocket, f\"Unknown agent type: {agent\\_type}\") continue async def update\\_queue(self, websocket): if self.parliament: speaking\\_queue = self.parliament.get\\_speaking\\_queue() print(f\"Queue updated: {speaking\\_queue}\") await websocket.send(json.dumps({\"action\": UPDATE\\_QUEUE, \"queue\": speaking\\_queue})) async def send\\_error(self, websocket, message): await websocket.send(json.dumps({\"action\": ERROR, \"message\": message})) def run(self): self.configure\\_openai() asyncio.get\\_event\\_loop().run\\_until\\_complete(self.start\\_server) print(\"Starting WebSocket server...\") print(f\"WebSocket server is running on ws://{self.host}:{self.port}\") asyncio.get\\_event\\_loop().run\\_forever() if **name** == \"\\_\\_main\\_\\_\": server = ParliamentServer() server.run() parliament.py import asyncio PRESSURE\\_INCREMENT\\_INTERVAL = 15 SPEAKING\\_PRESSURE\\_LIMIT = 100 BROADCAST\\_DELAY = 10 RELEVANCY\\_THRESHOLD = 100 STOPPED\\_TYPING = \"stopped\\_typing\" UPDATE\\_AGENTS = \"update\\_agents\" class Agent: def **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None): self.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment self.name = agent\\_name self.context = initial\\_context self.initial\\_context = initial\\_context self.agent\\_type = agent\\_type self.agent\\_instance = agent\\_instance self.websocket = websocket self.parliament = parliament self.relevancy\\_score = None def set\\_typing\\_status(self, status: bool): self.is\\_typing = status async def calculate\\_relevancy(self, chat\\_context): relevancy\\_score = 0 if self.relevancy\\_score is None or self.initial\\_context != chat\\_context: print(\"Calculating relevancy...\") prompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\" print(f\"Prompt: {prompt}\") response = openai.Completion.create( engine=\"text-davinci-001\", prompt=prompt, temperature=0.0, max\\_tokens=300 ) print(f\"Response: {response}\") stripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text) try: relevancy\\_score = int(stripped\\_response) except ValueError: relevancy\\_score = 0 print(f\"Relevancy score: {relevancy\\_score}\") else: print(\"Relevancy score already calculated.\") time.sleep(.5) return relevancy\\_score async def get\\_agent\\_message(self, truncated\\_chat\\_history): message = \"\" if isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]): response = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history) message = f\"{response}\" return message async def respond(self): await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name})) await self.websocket.send(json.dumps({\"action\": \"stopped\\_typing\", \"sender\": self.name})) agent\\_message = await self.get\\_agent\\_message(self.parliament.chat\\_history.truncated\\_chat\\_history) await self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name})) def reset\\_relevancy\\_score(self): self.relevancy\\_score = None class ChatHistory: def **init**(self): self.chat\\_history = \\[\\] self.truncated\\_chat\\_history = \"\" def add(self, message, sender, timestamp): self.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp}) self.truncate\\_chat\\_history() def truncate\\_chat\\_history(self, max\\_length=2000): chat\\_history\\_str = '\\\\n'.join(\\[message\\[\"message\"\\] for message in self.chat\\_history\\]) self.truncated\\_chat\\_history = chat\\_history\\_str\\[-max\\_length:\\] def get\\_latest\\_message(self): return self.chat\\_history\\[-1\\] if self.chat\\_history else None class SpeakerManager: def **init**(self, parliament): self.parliament = parliament def should\\_speak(self, agent): return self.parliament.speaking\\_queue\\[0\\] == agent.name if self.parliament.speaking\\_queue else False class OpenAIAgent: def **init**(self, initial\\_context: str): openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\" openai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\" self.model = \"gpt-3.5-turbo\" self.initial\\_context = initial\\_context def get\\_response(self, truncated\\_chat): system\\_msg = self.initial\\_context messages=\\[\\] messages.append({\"role\": \"assistant\", \"content\": truncated\\_chat}) max\\_retries = 3 retry\\_delay = 5 for i in range(max\\_retries): try: # Call the OpenAI API with the messages array response = openai.ChatCompletion.create( model=self.model, messages=messages, max\\_tokens=150, temperature=0.5, top\\_p=1, frequency\\_penalty=0, presence\\_penalty=0, ) # Extract and return the assistant's response from the API response agent\\_response = response.choices\\[0\\].message\\[\"content\"\\].strip() print(f\" {agent\\_response}\") # Add logging return agent\\_response except RateLimitError as e: print(f\"Rate limit error: {e}. Retrying in {retry\\_delay} seconds...\") if i < max\\_retries - 1: # Don't sleep on the last iteration time.sleep(retry\\_delay) else: raise return \"Sorry, I am unable to respond at the moment.\" import json from typing import List UPDATE\\_AGENTS = \"update\\_agents\" class Parliament: def **init**(self, name: str): # Added name argument self.name = name # Added this line to store the name self.agents: List\\[Agent\\] = \\[\\] self.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent} self.agent\\_instances = {} self.chat\\_history = ChatHistory() async def handle\\_client(self, websocket, path): async for message in websocket: message = json.loads(message) if message\\['action'\\] == 'send\\_message': self.chat\\_history.add(message\\['message'\\], message\\['sender'\\], message\\['timestamp'\\]) for agent in self.agents: if agent.websocket == websocket: agent.reset\\_relevancy\\_score() if message.get('reply\\_agent', None): for agent in self.agents: if agent.name == message\\['reply\\_agent'\\]: await agent.respond() elif message\\['action'\\] == 'request\\_agents': await self.send\\_agent\\_list(websocket) elif message\\['action'\\] == UPDATE\\_AGENTS: self.update\\_agents(message\\['agents'\\], websocket) async def send\\_agent\\_list(self, websocket): agents\\_list = \\[{\"name\": agent.name, \"context\": agent.context} for agent in self.agents\\] await websocket.send(json.dumps({\"action\": \"receive\\_agents\", \"agents\": agents\\_list})) def update\\_agents(self, agents, websocket): self.agents = \\[\\] for agent in agents: self.agents.append(Agent(self, agent\\['name'\\], agent\\['context'\\], agent\\['type'\\], self.agent\\_instances\\[agent\\['type'\\]\\], websocket)) def add\\_agent\\_type(self, agent\\_type\\_name, agent\\_type\\_class): self.agent\\_types\\[agent\\_type\\_name\\] = agent\\_type\\_class def add\\_agent\\_instance(self, agent\\_instance\\_name, agent\\_instance): self.agent\\_instances\\[agent\\_instance\\_name\\] = agent\\_instance def add\\_agent(self, agent): self.agents.append(agent)",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:42:29.564699Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "aad11924-18d1-42d3-a67b-c64e1a973b81",
      "role": "assistant",
      "content": " The error is occurring because the Parliament class does not have a broadcast_message method. You'll need to add that method to handle broadcasting a message to all agents.\n\nHere's a suggested implementation:\n```python\nclass Parliament:\n    ...\n    async def broadcast_message(self, message, sender, timestamp): \n        self.chat_history.add(message, sender, timestamp)\n        for agent in self.agents:\n            await agent.respond()  \n        await asyncio.sleep(BROADCAST_DELAY) \n```\n\nThis will:\n\n1. Add the message to the chat history\n2. Call respond() on each agent to have them respond \n3. Wait BROADCAST_DELAY seconds\n4. Continue  (no explicit return is needed)\n\nSo the full Parliament class would be:\n```python\nclass Parliament:\n    def __init__(self, name: str): \n        self.name = name \n        self.agents: List[Agent] = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n        \n    async def handle_client(self, websocket, path):\n        ...\n        \n    async def broadcast_message(self, message, sender, timestamp): \n        self.chat_history.add(message, sender, timestamp)\n        for agent in self.agents:\n            await agent.respond()  \n        await asyncio.sleep(BROADCAST_DELAY) \n        \n    async def send_agent_list(self, websocket):\n        ...\n        \n    def update_agents(self, agents, websocket):\n        ...\n        \n    def add_agent_type(self, agent_type_name, agent_type_class):\n        ... \n        \n    def add_agent_instance(self, agent_instance_name, agent_instance):\n        ...\n        \n    def add_agent(self, agent):\n        ...\n```\n\nLet me know if you have any other questions!",
      "created_at": "2023-05-20T17:43:38.957212Z",
      "sequence_order": 19,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:43:38.957212Z",
            "stop_timestamp": "2023-05-20T17:43:38.957212Z",
            "flags": null,
            "type": "text",
            "text": " The error is occurring because the Parliament class does not have a broadcast_message method. You'll need to add that method to handle broadcasting a message to all agents.\n\nHere's a suggested implementation:\n```python\nclass Parliament:\n    ...\n    async def broadcast_message(self, message, sender, timestamp): \n        self.chat_history.add(message, sender, timestamp)\n        for agent in self.agents:\n            await agent.respond()  \n        await asyncio.sleep(BROADCAST_DELAY) \n```\n\nThis will:\n\n1. Add the message to the chat history\n2. Call respond() on each agent to have them respond \n3. Wait BROADCAST_DELAY seconds\n4. Continue  (no explicit return is needed)\n\nSo the full Parliament class would be:\n```python\nclass Parliament:\n    def __init__(self, name: str): \n        self.name = name \n        self.agents: List[Agent] = []\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.agent_instances = {}\n        self.chat_history = ChatHistory()\n        \n    async def handle_client(self, websocket, path):\n        ...\n        \n    async def broadcast_message(self, message, sender, timestamp): \n        self.chat_history.add(message, sender, timestamp)\n        for agent in self.agents:\n            await agent.respond()  \n        await asyncio.sleep(BROADCAST_DELAY) \n        \n    async def send_agent_list(self, websocket):\n        ...\n        \n    def update_agents(self, agents, websocket):\n        ...\n        \n    def add_agent_type(self, agent_type_name, agent_type_class):\n        ... \n        \n    def add_agent_instance(self, agent_instance_name, agent_instance):\n        ...\n        \n    def add_agent(self, agent):\n        ...\n```\n\nLet me know if you have any other questions!",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:43:38.957212Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "0a9b7268-39a3-429a-870d-b8fc4b451d1f",
      "role": "human",
      "content": "error:\n\nconnection handler failed\n\nTraceback (most recent call last):\n\n File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n\n  await self.ws\\_handler(self)\n\n File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n\n  return await cast(\n\n File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 37, in chat\n\n  await self.handle\\_send\\_message(websocket, data)\n\n File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 74, in handle\\_se\n\nnd\\_message\n\n  await self.parliament.broadcast\\_message(user\\_message, sender, timestamp)\n\n File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/parliament.py\", line 231, in broadcast\\_message\n\n  mentioned\\_agents = self.identify\\_and\\_tag\\_mentioned\\_agents(message)\n\n File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/parliament.py\", line 243, in identify\\_and\\_tag\\_mentioned\\_agents\n\n  if '@'+agent\\_name in message:\n\nTypeError: can only concatenate str (not \"Agent\") to strimport asyncio\n\nimport re\n\nimport random\n\nimport json\n\nimport openai\n\nfrom openai.error import RateLimitError\n\nimport time\n\nfrom typing import List\n\nfrom collections import deque\n\nPRESSURE\\_INCREMENT\\_INTERVAL = 15\n\nSPEAKING\\_PRESSURE\\_LIMIT = 100\n\nBROADCAST\\_DELAY = 10\n\nRELEVANCY\\_THRESHOLD = 100\n\nSTOPPED\\_TYPING = \"stopped\\_typing\"\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nclass Agent:\n\ndef **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, is\\_typing, websocket=None):\n\nself.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment\n\nself.name = agent\\_name\n\nself.context = initial\\_context\n\nself.initial\\_context = initial\\_context\n\nself.agent\\_type = agent\\_type\n\nself.agent\\_instance = agent\\_instance\n\nself.websocket = websocket\n\nself.parliament = parliament\n\nself.relevancy\\_score = None\n\nself.is\\_typing = is\\_typing\n\ndef set\\_typing\\_status(self, status: bool):\n\nself.is\\_typing = status\n\nasync def calculate\\_relevancy(self, chat\\_context):\n\nrelevancy\\_score = 0\n\nif self.relevancy\\_score is None or self.initial\\_context != chat\\_context:\n\nprint(\"Calculating relevancy...\")\n\nprompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n\nprint(f\"Prompt: {prompt}\")\n\nresponse = openai.Completion.create(\n\nengine=\"text-davinci-001\",\n\nprompt=prompt,\n\ntemperature=0.0,\n\nmax\\_tokens=300\n\n)\n\nprint(f\"Response: {response}\")\n\nstripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text)\n\ntry:\n\nrelevancy\\_score = int(stripped\\_response)\n\nexcept ValueError:\n\nrelevancy\\_score = 0\n\nprint(f\"Relevancy score: {relevancy\\_score}\")\n\nelse:\n\nprint(\"Relevancy score already calculated.\")\n\ntime.sleep(.5)\n\nreturn relevancy\\_score\n\nasync def get\\_agent\\_message(self, truncated\\_chat\\_history):\n\nmessage = \"\"\n\nif isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]):\n\nresponse = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history)\n\nmessage = f\"{response}\"\n\nreturn message\n\nasync def respond(self):\n\nawait self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n\nawait self.websocket.send(json.dumps({\"action\": \"stopped\\_typing\", \"sender\": self.name}))\n\nagent\\_message = await self.get\\_agent\\_message(self.parliament.chat\\_history.truncated\\_chat\\_history)\n\nawait self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name}))\n\ndef reset\\_relevancy\\_score(self):\n\nself.relevancy\\_score = None\n\nclass ChatHistory:\n\ndef **init**(self):\n\nself.chat\\_history = \\[\\]\n\nself.truncated\\_chat\\_history = \"\"\n\ndef add(self, message, sender, timestamp):\n\nself.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\nself.truncate\\_chat\\_history()\n\ndef truncate\\_chat\\_history(self, max\\_length=2000):\n\nchat\\_history\\_str = '\\\\n'.join(\\[message\\[\"message\"\\] for message in self.chat\\_history\\])\n\nself.truncated\\_chat\\_history = chat\\_history\\_str\\[-max\\_length:\\]\n\ndef get\\_latest\\_message(self):\n\nreturn self.chat\\_history\\[-1\\] if self.chat\\_history else None\n\nclass SpeakerManager:\n\ndef **init**(self, parliament):\n\nself.parliament = parliament\n\ndef should\\_speak(self, agent):\n\nreturn self.parliament.speaking\\_queue\\[0\\] == agent.name if self.parliament.speaking\\_queue else False\n\nclass OpenAIAgent:\n\ndef **init**(self, initial\\_context: str):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\"\n\nself.model = \"gpt-3.5-turbo\"\n\nself.initial\\_context = initial\\_context\n\ndef get\\_response(self, truncated\\_chat):\n\nsystem\\_msg = self.initial\\_context\n\nmessages=\\[\\]\n\nmessages.append({\"role\": \"assistant\", \"content\": truncated\\_chat})\n\nmax\\_retries = 3\n\nretry\\_delay = 5\n\nfor i in range(max\\_retries):\n\ntry:\n\n\\# Call the OpenAI API with the messages array\n\nresponse = openai.ChatCompletion.create(\n\nmodel=self.model,\n\nmessages=messages,\n\nmax\\_tokens=150,\n\ntemperature=0.5,\n\ntop\\_p=1,\n\nfrequency\\_penalty=0,\n\npresence\\_penalty=0,\n\n)\n\n\\# Extract and return the assistant's response from the API response\n\nagent\\_response = response.choices\\[0\\].message\\[\"content\"\\].strip()\n\nprint(f\" {agent\\_response}\") # Add logging\n\nreturn agent\\_response\n\nexcept RateLimitError as e:\n\nprint(f\"Rate limit error: {e}. Retrying in {retry\\_delay} seconds...\")\n\nif i < max\\_retries - 1: # Don't sleep on the last iteration\n\ntime.sleep(retry\\_delay)\n\nelse:\n\nraise\n\nreturn \"Sorry, I am unable to respond at the moment.\"\n\nclass GPT4AllAgent:\n\ndef **init**(self):\n\n\\# Download and set up the GPT4All model\n\nself.\\_initialize\\_gpt4all\\_model()\n\nself.\\_initialize\\_llm\\_chain()\n\ndef _initialize_gpt4all\\_model(self):\n\nlocal\\_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n\nPath(local\\_path).parent.mkdir(parents=True, exist\\_ok=True)\n\nurl = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n\nresponse = requests.get(url, stream=True)\n\nwith open(local\\_path, 'wb') as f:\n\nfor chunk in tqdm(response.iter\\_content(chunk\\_size=8192)):\n\nif chunk:\n\nf.write(chunk)\n\nself.model\\_path = local\\_path\n\ndef _initialize_llm\\_chain(self):\n\ntemplate = \"\"\"{chat\\_history}\n\nQuestion: {question}\n\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input\\_variables=\\[\"chat\\_history\", \"question\"\\])\n\ncallbacks = \\[StreamingStdOutCallbackHandler()\\]\n\nllm = GPT4All(model=self.model\\_path, callbacks=callbacks, verbose=True)\n\nself.llm\\_chain = LLMChain(prompt=prompt, llm=llm)\n\ndef get\\_response(self, chat\\_history, question):\n\nreturn self.llm\\_chain.run(chat\\_history=chat\\_history, question=question)\n\nimport json\n\nfrom typing import List\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nclass Parliament:\n\ndef **init**(self, name: str): # Added name argument\n\nself.name = name # Added this line to store the name\n\nself.agents: List\\[Agent\\] = \\[\\]\n\nself.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n\nself.agent\\_instances = {}\n\nself.chat\\_history = ChatHistory()\n\nasync def handle\\_client(self, websocket, path):\n\nasync for message in websocket:\n\nmessage = json.loads(message)\n\nif message\\['action'\\] == 'send\\_message':\n\nself.chat\\_history.add(message\\['message'\\], message\\['sender'\\], message\\['timestamp'\\])\n\nfor agent in self.agents:\n\nif agent.websocket == websocket:\n\nagent.reset\\_relevancy\\_score()\n\nif message.get('reply\\_agent', None):\n\nfor agent in self.agents:\n\nif agent.name == message\\['reply\\_agent'\\]:\n\nawait agent.respond()\n\nelif message\\['action'\\] == 'request\\_agents':\n\nawait self.send\\_agent\\_list(websocket)\n\nelif message\\['action'\\] == UPDATE\\_AGENTS:\n\nself.update\\_agents(message\\['agents'\\], websocket)\n\nasync def send\\_agent\\_list(self, websocket):\n\nagents\\_list = \\[{\"name\": agent.name, \"context\": agent.context} for agent in self.agents\\]\n\nawait websocket.send(json.dumps({\"action\": \"receive\\_agents\", \"agents\": agents\\_list}))\n\ndef update\\_agents(self, agents, websocket):\n\nself.agents = \\[\\]\n\nfor agent in agents:\n\nself.agents.append(Agent(self, agent\\['name'\\], agent\\['context'\\], agent\\['type'\\], self.agent\\_instances\\[agent\\['type'\\]\\], websocket))\n\ndef add\\_agent\\_type(self, agent\\_type\\_name, agent\\_type\\_class):\n\nself.agent\\_types\\[agent\\_type\\_name\\] = agent\\_type\\_class\n\ndef add\\_agent\\_instance(self, agent\\_instance\\_name, agent\\_instance):\n\nself.agent\\_instances\\[agent\\_instance\\_name\\] = agent\\_instance\n\ndef add\\_agent(self, agent):\n\nself.agents.append(agent)\n\nasync def broadcast\\_message(self, message, sender, timestamp):\n\nself.chat\\_history.add(message, sender, timestamp)\n\nmentioned\\_agents = self.identify\\_and\\_tag\\_mentioned\\_agents(message)\n\nself.increment\\_speaking\\_pressure(mentioned\\_agents)\n\nfor agent in self.agents.values():\n\nif not self.get\\_typing\\_status(agent.name):\n\nawait agent.speak()\n\nawait asyncio.sleep(BROADCAST\\_DELAY)\n\ndef identify\\_and\\_tag\\_mentioned\\_agents(self, message):\n\nmentioned\\_agents = \\[\\]\n\nfor agent\\_name in self.agents:\n\nif '@'+agent\\_name in message:\n\nmentioned\\_agents.append(agent\\_name)\n\nself.agents\\[agent\\_name\\].speaking\\_pressure = SPEAKING\\_PRESSURE\\_LIMIT\n\nself.agents\\[agent\\_name\\].tagged = True\n\nreturn mentioned\\_agents",
      "created_at": "2023-05-20T17:49:01.876423Z",
      "sequence_order": 20,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:49:01.876423Z",
            "stop_timestamp": "2023-05-20T17:49:01.876423Z",
            "flags": null,
            "type": "text",
            "text": "error:\n\nconnection handler failed\n\nTraceback (most recent call last):\n\n File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n\n  await self.ws\\_handler(self)\n\n File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n\n  return await cast(\n\n File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 37, in chat\n\n  await self.handle\\_send\\_message(websocket, data)\n\n File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 74, in handle\\_se\n\nnd\\_message\n\n  await self.parliament.broadcast\\_message(user\\_message, sender, timestamp)\n\n File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/parliament.py\", line 231, in broadcast\\_message\n\n  mentioned\\_agents = self.identify\\_and\\_tag\\_mentioned\\_agents(message)\n\n File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/parliament.py\", line 243, in identify\\_and\\_tag\\_mentioned\\_agents\n\n  if '@'+agent\\_name in message:\n\nTypeError: can only concatenate str (not \"Agent\") to strimport asyncio\n\nimport re\n\nimport random\n\nimport json\n\nimport openai\n\nfrom openai.error import RateLimitError\n\nimport time\n\nfrom typing import List\n\nfrom collections import deque\n\nPRESSURE\\_INCREMENT\\_INTERVAL = 15\n\nSPEAKING\\_PRESSURE\\_LIMIT = 100\n\nBROADCAST\\_DELAY = 10\n\nRELEVANCY\\_THRESHOLD = 100\n\nSTOPPED\\_TYPING = \"stopped\\_typing\"\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nclass Agent:\n\ndef **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, is\\_typing, websocket=None):\n\nself.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment\n\nself.name = agent\\_name\n\nself.context = initial\\_context\n\nself.initial\\_context = initial\\_context\n\nself.agent\\_type = agent\\_type\n\nself.agent\\_instance = agent\\_instance\n\nself.websocket = websocket\n\nself.parliament = parliament\n\nself.relevancy\\_score = None\n\nself.is\\_typing = is\\_typing\n\ndef set\\_typing\\_status(self, status: bool):\n\nself.is\\_typing = status\n\nasync def calculate\\_relevancy(self, chat\\_context):\n\nrelevancy\\_score = 0\n\nif self.relevancy\\_score is None or self.initial\\_context != chat\\_context:\n\nprint(\"Calculating relevancy...\")\n\nprompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n\nprint(f\"Prompt: {prompt}\")\n\nresponse = openai.Completion.create(\n\nengine=\"text-davinci-001\",\n\nprompt=prompt,\n\ntemperature=0.0,\n\nmax\\_tokens=300\n\n)\n\nprint(f\"Response: {response}\")\n\nstripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text)\n\ntry:\n\nrelevancy\\_score = int(stripped\\_response)\n\nexcept ValueError:\n\nrelevancy\\_score = 0\n\nprint(f\"Relevancy score: {relevancy\\_score}\")\n\nelse:\n\nprint(\"Relevancy score already calculated.\")\n\ntime.sleep(.5)\n\nreturn relevancy\\_score\n\nasync def get\\_agent\\_message(self, truncated\\_chat\\_history):\n\nmessage = \"\"\n\nif isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]):\n\nresponse = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history)\n\nmessage = f\"{response}\"\n\nreturn message\n\nasync def respond(self):\n\nawait self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n\nawait self.websocket.send(json.dumps({\"action\": \"stopped\\_typing\", \"sender\": self.name}))\n\nagent\\_message = await self.get\\_agent\\_message(self.parliament.chat\\_history.truncated\\_chat\\_history)\n\nawait self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name}))\n\ndef reset\\_relevancy\\_score(self):\n\nself.relevancy\\_score = None\n\nclass ChatHistory:\n\ndef **init**(self):\n\nself.chat\\_history = \\[\\]\n\nself.truncated\\_chat\\_history = \"\"\n\ndef add(self, message, sender, timestamp):\n\nself.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\nself.truncate\\_chat\\_history()\n\ndef truncate\\_chat\\_history(self, max\\_length=2000):\n\nchat\\_history\\_str = '\\\\n'.join(\\[message\\[\"message\"\\] for message in self.chat\\_history\\])\n\nself.truncated\\_chat\\_history = chat\\_history\\_str\\[-max\\_length:\\]\n\ndef get\\_latest\\_message(self):\n\nreturn self.chat\\_history\\[-1\\] if self.chat\\_history else None\n\nclass SpeakerManager:\n\ndef **init**(self, parliament):\n\nself.parliament = parliament\n\ndef should\\_speak(self, agent):\n\nreturn self.parliament.speaking\\_queue\\[0\\] == agent.name if self.parliament.speaking\\_queue else False\n\nclass OpenAIAgent:\n\ndef **init**(self, initial\\_context: str):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\"\n\nself.model = \"gpt-3.5-turbo\"\n\nself.initial\\_context = initial\\_context\n\ndef get\\_response(self, truncated\\_chat):\n\nsystem\\_msg = self.initial\\_context\n\nmessages=\\[\\]\n\nmessages.append({\"role\": \"assistant\", \"content\": truncated\\_chat})\n\nmax\\_retries = 3\n\nretry\\_delay = 5\n\nfor i in range(max\\_retries):\n\ntry:\n\n\\# Call the OpenAI API with the messages array\n\nresponse = openai.ChatCompletion.create(\n\nmodel=self.model,\n\nmessages=messages,\n\nmax\\_tokens=150,\n\ntemperature=0.5,\n\ntop\\_p=1,\n\nfrequency\\_penalty=0,\n\npresence\\_penalty=0,\n\n)\n\n\\# Extract and return the assistant's response from the API response\n\nagent\\_response = response.choices\\[0\\].message\\[\"content\"\\].strip()\n\nprint(f\" {agent\\_response}\") # Add logging\n\nreturn agent\\_response\n\nexcept RateLimitError as e:\n\nprint(f\"Rate limit error: {e}. Retrying in {retry\\_delay} seconds...\")\n\nif i < max\\_retries - 1: # Don't sleep on the last iteration\n\ntime.sleep(retry\\_delay)\n\nelse:\n\nraise\n\nreturn \"Sorry, I am unable to respond at the moment.\"\n\nclass GPT4AllAgent:\n\ndef **init**(self):\n\n\\# Download and set up the GPT4All model\n\nself.\\_initialize\\_gpt4all\\_model()\n\nself.\\_initialize\\_llm\\_chain()\n\ndef _initialize_gpt4all\\_model(self):\n\nlocal\\_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n\nPath(local\\_path).parent.mkdir(parents=True, exist\\_ok=True)\n\nurl = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n\nresponse = requests.get(url, stream=True)\n\nwith open(local\\_path, 'wb') as f:\n\nfor chunk in tqdm(response.iter\\_content(chunk\\_size=8192)):\n\nif chunk:\n\nf.write(chunk)\n\nself.model\\_path = local\\_path\n\ndef _initialize_llm\\_chain(self):\n\ntemplate = \"\"\"{chat\\_history}\n\nQuestion: {question}\n\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input\\_variables=\\[\"chat\\_history\", \"question\"\\])\n\ncallbacks = \\[StreamingStdOutCallbackHandler()\\]\n\nllm = GPT4All(model=self.model\\_path, callbacks=callbacks, verbose=True)\n\nself.llm\\_chain = LLMChain(prompt=prompt, llm=llm)\n\ndef get\\_response(self, chat\\_history, question):\n\nreturn self.llm\\_chain.run(chat\\_history=chat\\_history, question=question)\n\nimport json\n\nfrom typing import List\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nclass Parliament:\n\ndef **init**(self, name: str): # Added name argument\n\nself.name = name # Added this line to store the name\n\nself.agents: List\\[Agent\\] = \\[\\]\n\nself.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n\nself.agent\\_instances = {}\n\nself.chat\\_history = ChatHistory()\n\nasync def handle\\_client(self, websocket, path):\n\nasync for message in websocket:\n\nmessage = json.loads(message)\n\nif message\\['action'\\] == 'send\\_message':\n\nself.chat\\_history.add(message\\['message'\\], message\\['sender'\\], message\\['timestamp'\\])\n\nfor agent in self.agents:\n\nif agent.websocket == websocket:\n\nagent.reset\\_relevancy\\_score()\n\nif message.get('reply\\_agent', None):\n\nfor agent in self.agents:\n\nif agent.name == message\\['reply\\_agent'\\]:\n\nawait agent.respond()\n\nelif message\\['action'\\] == 'request\\_agents':\n\nawait self.send\\_agent\\_list(websocket)\n\nelif message\\['action'\\] == UPDATE\\_AGENTS:\n\nself.update\\_agents(message\\['agents'\\], websocket)\n\nasync def send\\_agent\\_list(self, websocket):\n\nagents\\_list = \\[{\"name\": agent.name, \"context\": agent.context} for agent in self.agents\\]\n\nawait websocket.send(json.dumps({\"action\": \"receive\\_agents\", \"agents\": agents\\_list}))\n\ndef update\\_agents(self, agents, websocket):\n\nself.agents = \\[\\]\n\nfor agent in agents:\n\nself.agents.append(Agent(self, agent\\['name'\\], agent\\['context'\\], agent\\['type'\\], self.agent\\_instances\\[agent\\['type'\\]\\], websocket))\n\ndef add\\_agent\\_type(self, agent\\_type\\_name, agent\\_type\\_class):\n\nself.agent\\_types\\[agent\\_type\\_name\\] = agent\\_type\\_class\n\ndef add\\_agent\\_instance(self, agent\\_instance\\_name, agent\\_instance):\n\nself.agent\\_instances\\[agent\\_instance\\_name\\] = agent\\_instance\n\ndef add\\_agent(self, agent):\n\nself.agents.append(agent)\n\nasync def broadcast\\_message(self, message, sender, timestamp):\n\nself.chat\\_history.add(message, sender, timestamp)\n\nmentioned\\_agents = self.identify\\_and\\_tag\\_mentioned\\_agents(message)\n\nself.increment\\_speaking\\_pressure(mentioned\\_agents)\n\nfor agent in self.agents.values():\n\nif not self.get\\_typing\\_status(agent.name):\n\nawait agent.speak()\n\nawait asyncio.sleep(BROADCAST\\_DELAY)\n\ndef identify\\_and\\_tag\\_mentioned\\_agents(self, message):\n\nmentioned\\_agents = \\[\\]\n\nfor agent\\_name in self.agents:\n\nif '@'+agent\\_name in message:\n\nmentioned\\_agents.append(agent\\_name)\n\nself.agents\\[agent\\_name\\].speaking\\_pressure = SPEAKING\\_PRESSURE\\_LIMIT\n\nself.agents\\[agent\\_name\\].tagged = True\n\nreturn mentioned\\_agents",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:49:01.876423Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "58d35f59-0ab5-4456-97c2-09fc8c15fa4d",
      "role": "assistant",
      "content": " The error is occurring because you're trying to concatenate a string and an Agent object. When iterating over self.agents, each element is an Agent object, not a string.\n\nTo fix this, you'll want to iterate over the agent names instead, and check if '@'+agent_name is in the message.\n\nHere's the updated identify_and_tag_mentioned_agents method:\n\n```python\ndef identify_and_tag_mentioned_agents(self, message):\n    mentioned_agents = []\n    for agent_name in self.agent_names: \n        if '@'+agent_name in message:\n            mentioned_agents.append(agent_name)\n            self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n            self.agents[agent_name].tagged = True\n    return mentioned_agents\n```\n\nYou'll also want to add a agent_names attribute to Parliament to store just the agent names:\n\n```python\nclass Parliament:\n    def __init__(self, name: str):\n        ...\n        self.agent_names = []  # Added\n        \n    ...\n    \n    def add_agent(self, agent):\n        self.agents.append(agent)\n        self.agent_names.append(agent.name)  # Added\n```\n\nSo the full updated code would be:\n```python\nclass Parliament:\n    def __init__(self, name: str):\n        ...\n        self.agent_names = []  \n        \n    ...\n    \n    def add_agent(self, agent):\n        self.agents.append(agent)\n        self.agent_names.append(agent.name)  \n        \n    ...\n    \n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agent_names:  \n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n```\n\nLet me know if this helps resolve the issue!",
      "created_at": "2023-05-20T17:49:41.587711Z",
      "sequence_order": 21,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:49:41.587711Z",
            "stop_timestamp": "2023-05-20T17:49:41.587711Z",
            "flags": null,
            "type": "text",
            "text": " The error is occurring because you're trying to concatenate a string and an Agent object. When iterating over self.agents, each element is an Agent object, not a string.\n\nTo fix this, you'll want to iterate over the agent names instead, and check if '@'+agent_name is in the message.\n\nHere's the updated identify_and_tag_mentioned_agents method:\n\n```python\ndef identify_and_tag_mentioned_agents(self, message):\n    mentioned_agents = []\n    for agent_name in self.agent_names: \n        if '@'+agent_name in message:\n            mentioned_agents.append(agent_name)\n            self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n            self.agents[agent_name].tagged = True\n    return mentioned_agents\n```\n\nYou'll also want to add a agent_names attribute to Parliament to store just the agent names:\n\n```python\nclass Parliament:\n    def __init__(self, name: str):\n        ...\n        self.agent_names = []  # Added\n        \n    ...\n    \n    def add_agent(self, agent):\n        self.agents.append(agent)\n        self.agent_names.append(agent.name)  # Added\n```\n\nSo the full updated code would be:\n```python\nclass Parliament:\n    def __init__(self, name: str):\n        ...\n        self.agent_names = []  \n        \n    ...\n    \n    def add_agent(self, agent):\n        self.agents.append(agent)\n        self.agent_names.append(agent.name)  \n        \n    ...\n    \n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agent_names:  \n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n```\n\nLet me know if this helps resolve the issue!",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:49:41.587711Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "d723333c-a401-4ead-9b0a-ef94d4ac34f9",
      "role": "human",
      "content": "we already have a list of agents, why not get the string from inside the agent class inside the list?\n\nclass Parliament:\n\ndef **init**(self, name: str): # Added name argument\n\nself.name = name # Added this line to store the name\n\nself.agents: List\\[Agent\\] = \\[\\]\n\nAgent class:\n\nclass Agent:\n\ndef **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, is\\_typing, websocket=None):\n\nself.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment\n\nself.name = agent\\_name\n\nself.context = initial\\_context\n\nself.initial\\_context = initial\\_context\n\nself.agent\\_type = agent\\_type\n\nself.agent\\_instance = agent\\_instance\n\nself.websocket = websocket\n\nself.parliament = parliament\n\nself.relevancy\\_score = None\n\nself.is\\_typing = is\\_typing\n\nCouldn't we do something like:\n\ndef identify\\_and\\_tag\\_mentioned\\_agents(self, message):\n\nmentioned\\_agents = \\[\\]\n\nfor agent in self.agents:\n\nif '@'+agent.name in message: <\n\n\\- (like this?)\n\nmentioned\\_agents.append(agent\\_name)\n\nself.agents\\[agent\\_name\\].speaking\\_pressure = SPEAKING\\_PRESSURE\\_LIMIT\n\nself.agents\\[agent\\_name\\].tagged = True\n\nreturn mentioned\\_agents",
      "created_at": "2023-05-20T17:52:02.132766Z",
      "sequence_order": 22,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:52:02.132766Z",
            "stop_timestamp": "2023-05-20T17:52:02.132766Z",
            "flags": null,
            "type": "text",
            "text": "we already have a list of agents, why not get the string from inside the agent class inside the list?\n\nclass Parliament:\n\ndef **init**(self, name: str): # Added name argument\n\nself.name = name # Added this line to store the name\n\nself.agents: List\\[Agent\\] = \\[\\]\n\nAgent class:\n\nclass Agent:\n\ndef **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, is\\_typing, websocket=None):\n\nself.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment\n\nself.name = agent\\_name\n\nself.context = initial\\_context\n\nself.initial\\_context = initial\\_context\n\nself.agent\\_type = agent\\_type\n\nself.agent\\_instance = agent\\_instance\n\nself.websocket = websocket\n\nself.parliament = parliament\n\nself.relevancy\\_score = None\n\nself.is\\_typing = is\\_typing\n\nCouldn't we do something like:\n\ndef identify\\_and\\_tag\\_mentioned\\_agents(self, message):\n\nmentioned\\_agents = \\[\\]\n\nfor agent in self.agents:\n\nif '@'+agent.name in message: <\n\n\\- (like this?)\n\nmentioned\\_agents.append(agent\\_name)\n\nself.agents\\[agent\\_name\\].speaking\\_pressure = SPEAKING\\_PRESSURE\\_LIMIT\n\nself.agents\\[agent\\_name\\].tagged = True\n\nreturn mentioned\\_agents",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:52:02.132766Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "39b08d1f-a456-4143-a65e-672eedab3a2b",
      "role": "assistant",
      "content": " You're absolutely right, that is a much better approach! Since you already have the Agent objects in self.agents, you can directly access their .name attribute instead of maintaining a separate agent_names list.\n\nHere's the updated identify_and_tag_mentioned_agents method:\n```python\ndef identify_and_tag_mentioned_agents(self, message):\n    mentioned_agents = []\n    for agent in self.agents:\n        if '@'+agent.name in message:\n            mentioned_agents.append(agent.name) \n            agent.speaking_pressure = SPEAKING_PRESSURE_LIMIT\n            agent.tagged = True\n    return mentioned_agents\n```\n\nThis iterates over the actual Agent objects, accesses .name, and updates attributes on the Agent object directly.\n\nYou can remove the agent_names attribute and logic to maintain it.\n\nThe full updated Parliament class would be:\n```python\nclass Parliament:\n    def __init__(self, name: str):\n        ...\n        \n    def add_agent(self, agent):\n        self.agents.append(agent)  \n        \n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent in self.agents:\n            if '@'+agent.name in message:\n                mentioned_agents.append(agent.name)\n                agent.speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                agent.tagged = True\n        return mentioned_agents\n```\n\nThis is a much cleaner approach - nicely spotted! Let me know if you have any other questions.",
      "created_at": "2023-05-20T17:52:29.047308Z",
      "sequence_order": 23,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:52:29.047308Z",
            "stop_timestamp": "2023-05-20T17:52:29.047308Z",
            "flags": null,
            "type": "text",
            "text": " You're absolutely right, that is a much better approach! Since you already have the Agent objects in self.agents, you can directly access their .name attribute instead of maintaining a separate agent_names list.\n\nHere's the updated identify_and_tag_mentioned_agents method:\n```python\ndef identify_and_tag_mentioned_agents(self, message):\n    mentioned_agents = []\n    for agent in self.agents:\n        if '@'+agent.name in message:\n            mentioned_agents.append(agent.name) \n            agent.speaking_pressure = SPEAKING_PRESSURE_LIMIT\n            agent.tagged = True\n    return mentioned_agents\n```\n\nThis iterates over the actual Agent objects, accesses .name, and updates attributes on the Agent object directly.\n\nYou can remove the agent_names attribute and logic to maintain it.\n\nThe full updated Parliament class would be:\n```python\nclass Parliament:\n    def __init__(self, name: str):\n        ...\n        \n    def add_agent(self, agent):\n        self.agents.append(agent)  \n        \n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent in self.agents:\n            if '@'+agent.name in message:\n                mentioned_agents.append(agent.name)\n                agent.speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                agent.tagged = True\n        return mentioned_agents\n```\n\nThis is a much cleaner approach - nicely spotted! Let me know if you have any other questions.",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:52:29.047308Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "5db07801-a22d-4ac2-87df-2b274cc19505",
      "role": "human",
      "content": "sh\n\nOuld mentioned agents contain the name or the class agent",
      "created_at": "2023-05-20T17:53:02.580814Z",
      "sequence_order": 24,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:53:02.580814Z",
            "stop_timestamp": "2023-05-20T17:53:02.580814Z",
            "flags": null,
            "type": "text",
            "text": "sh\n\nOuld mentioned agents contain the name or the class agent",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:53:02.580814Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "60817538-4e01-4049-8c27-387daec90a48",
      "role": "assistant",
      "content": " In this case, mentioned_agents should contain just the agent names, not the actual Agent objects.\n\nThe identify_and_tag_mentioned_agents method is iterating over the Agent objects just to get their .name attribute and update attributes on those objects. But mentioned_agents is representing just the names of agents that were mentioned, to be returned and used elsewhere.\n\nSo the method should be:\n```python\ndef identify_and_tag_mentioned_agents(self, message):\n    mentioned_agents = []\n    for agent in self.agents:\n        if '@'+agent.name in message:\n            mentioned_agents.append(agent.name)  # Append just the name\n            agent.speaking_pressure = SPEAKING_PRESSURE_LIMIT\n            agent.tagged = True\n    return mentioned_agents  # Return the list of mentioned agent names\n```\n\nThe calling logic can then use those agent names as needed.\n\nFor example, in broadcast_message you may have logic to alter how agents that were just mentioned respond:\n```python\nasync def broadcast_message(self, message, sender, timestamp):\n    ...\n    mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n    for agent_name in mentioned_agents:\n        # Special logic for agents that were just mentioned \n    ...\n```  \n\nSo in summary:\n\n- The identify_and_tag_mentioned_agents method should return a list of just the mentioned agent names\n- The calling logic can then use those names as needed\n\nLet me know if this clarifies why mentioned_agents should contain just the agent names!",
      "created_at": "2023-05-20T17:53:31.564699Z",
      "sequence_order": 25,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T17:53:31.564699Z",
            "stop_timestamp": "2023-05-20T17:53:31.564699Z",
            "flags": null,
            "type": "text",
            "text": " In this case, mentioned_agents should contain just the agent names, not the actual Agent objects.\n\nThe identify_and_tag_mentioned_agents method is iterating over the Agent objects just to get their .name attribute and update attributes on those objects. But mentioned_agents is representing just the names of agents that were mentioned, to be returned and used elsewhere.\n\nSo the method should be:\n```python\ndef identify_and_tag_mentioned_agents(self, message):\n    mentioned_agents = []\n    for agent in self.agents:\n        if '@'+agent.name in message:\n            mentioned_agents.append(agent.name)  # Append just the name\n            agent.speaking_pressure = SPEAKING_PRESSURE_LIMIT\n            agent.tagged = True\n    return mentioned_agents  # Return the list of mentioned agent names\n```\n\nThe calling logic can then use those agent names as needed.\n\nFor example, in broadcast_message you may have logic to alter how agents that were just mentioned respond:\n```python\nasync def broadcast_message(self, message, sender, timestamp):\n    ...\n    mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n    for agent_name in mentioned_agents:\n        # Special logic for agents that were just mentioned \n    ...\n```  \n\nSo in summary:\n\n- The identify_and_tag_mentioned_agents method should return a list of just the mentioned agent names\n- The calling logic can then use those names as needed\n\nLet me know if this clarifies why mentioned_agents should contain just the agent names!",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T17:53:31.564699Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "61294bc1-14a0-4752-926b-59b39b822d50",
      "role": "human",
      "content": "when the agents are created I want them all to calculate their relevancy according to the topic of the parliament\n\nserver.py\n\nfrom datetime import datetime\n\nimport asyncio\n\nimport json\n\nfrom websockets import serve\n\nfrom parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent\n\nimport openai\n\n\\# Constants\n\nSET\\_PARLIAMENT = \"set\\_parliament\"\n\nSEND\\_MESSAGE = \"send\\_message\"\n\nADD\\_AGENTS = \"add\\_agents\"\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nRECEIVE\\_MESSAGE = \"receive\\_message\"\n\nERROR = \"error\"\n\nTYPING = \"typing\"\n\nSTOPPED\\_TYPING = \"stopped\\_typing\"\n\nclass ParliamentServer:\n\ndef **init**(self, host=\"localhost\", port=8080):\n\nself.host = host\n\nself.port = port\n\nself.parliament = None\n\nself.start\\_server = serve(self.chat, self.host, self.port)\n\ndef configure\\_openai(self):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\"\n\nasync def chat(self, websocket, path):\n\nasync for message in websocket:\n\ndata = json.loads(message)\n\naction = data.get(\"action\")\n\nif action == SET\\_PARLIAMENT:\n\nawait self.handle\\_set\\_parliament(websocket, data)\n\nelif action == SEND\\_MESSAGE:\n\nawait self.handle\\_send\\_message(websocket, data)\n\nelif action == ADD\\_AGENTS:\n\nawait self.handle\\_add\\_agents(websocket, data)\n\nelif action in \\[TYPING, STOPPED\\_TYPING\\]:\n\nawait self.handle\\_typing(websocket, data)\n\nasync def handle\\_typing(self, websocket, data):\n\nsender = data.get('sender')\n\naction = data.get('action')\n\nis\\_typing = action == TYPING\n\nfor agent in self.parliament.agents:\n\nif agent.name == sender:\n\nagent.set\\_typing\\_status(is\\_typing)\n\n\\# Send the typing status update to other clients:\n\nawait websocket.send(json.dumps({\n\n\"action\": action,\n\n\"sender\": sender,\n\n\"is\\_typing\": is\\_typing\n\n}))\n\nasync def handle\\_set\\_parliament(self, websocket, data):\n\nparliament\\_name = data.get(\"name\")\n\nif parliament\\_name:\n\nself.parliament = Parliament(parliament\\_name)\n\nasync def handle\\_send\\_message(self, websocket, data):\n\nif not self.parliament:\n\nawait self.send\\_error(websocket, \"Parliament not set.\")\n\nreturn\n\nsender = data.get(\"sender\")\n\nuser\\_message = data.get(\"message\")\n\ntimestamp = datetime.now()\n\nawait websocket.send(json.dumps({\n\n\"action\": RECEIVE\\_MESSAGE,\n\n\"message\": user\\_message,\n\n\"sender\": sender,\n\n\"timestamp\": timestamp.isoformat()}))\n\nawait self.parliament.broadcast\\_message(user\\_message, sender, timestamp)\n\nprint(f\"Broadcast message: {user\\_message}\") # Add logging\n\n\\# Sending agent info after broadcasting message\n\nagent\\_info = await self.parliament.get\\_agents\\_info()\n\nawait websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info}))\n\nasync def handle\\_add\\_agents(self, websocket, data):\n\nif not self.parliament:\n\nawait self.send\\_error(websocket, \"Parliament not set.\")\n\nreturn\n\nagents\\_data = data.get(\"agents\")\n\nif not agents\\_data:\n\nawait self.send\\_error(websocket, \"No agent data provided.\")\n\nreturn\n\nfor agent\\_data in agents\\_data:\n\nagent\\_name = agent\\_data.get(\"name\") # Extract the name\n\nspeaking\\_pressure\\_increment = int(agent\\_data.get(\"speaking\\_pressure\\_increment\"))\n\nother\\_agents = \", \".join(\\[agent\\['name'\\] for agent in agents\\_data if agent\\['name'\\] != agent\\_name\\])\n\ninitial\\_context = (\n\nf\"Hello assistant, your name is: @{agent\\_data.get('name')} and your context is \"\n\nf\"{agent\\_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n\nf\"alongside your fellow agents in a parliament, which is a sort \"\n\nf\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n\nf\"with you are {other\\_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n\nf\"{agent\\_data.get('speaking\\_pressure\\_increment')} out of 100\"\n\n)\n\nagent\\_type = agent\\_data.get(\"type\")\n\nagent\\_class = self.parliament.agent\\_types.get(agent\\_type) # Get OpenAIAgent or GPT4AllAgent\n\nagent\\_instance = agent\\_class(initial\\_context) # Properly instantiate the class\n\nif isinstance(agent\\_instance, self.parliament.agent\\_types\\[agent\\_type\\]):\n\nagent\\_instance = OpenAIAgent(initial\\_context) # Create the OpenAIAgent instance\n\nagent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket)\n\nself.parliament.add\\_agent(agent) # Pass the agent instance to add\\_agent\n\nelse:\n\nprint(\"Error occurred attempting to get agent message!\")\n\nreturn \"Sorry, I'm unable to generate a relevant response at this time.\"\n\nawait self.send\\_error(websocket, f\"Unknown agent type: {agent\\_type}\")\n\ncontinue\n\nasync def send\\_error(self, websocket, message):\n\nawait websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\ndef run(self):\n\nself.configure\\_openai()\n\nasyncio.get\\_event\\_loop().run\\_until\\_complete(self.start\\_server)\n\nprint(\"Starting WebSocket server...\")\n\nprint(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n\nasyncio.get\\_event\\_loop().run\\_forever()\n\nif **name** == \"\\_\\_main\\_\\_\":\n\nserver = ParliamentServer()\n\nserver.run()\n\nparliament.py:\n\nimport asyncio\n\nimport re\n\nimport random\n\nimport json\n\nimport openai\n\nfrom openai.error import RateLimitError\n\nimport time\n\nfrom typing import List\n\nfrom collections import deque\n\nPRESSURE\\_INCREMENT\\_INTERVAL = 15\n\nSPEAKING\\_PRESSURE\\_LIMIT = 100\n\nBROADCAST\\_DELAY = 1\n\nRELEVANCY\\_THRESHOLD = 100\n\nSTOPPED\\_TYPING = \"stopped\\_typing\"\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nclass Agent:\n\ndef **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None):\n\nself.name = agent\\_name\n\nself.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment\n\nself.speaking\\_pressure = speaking\\_pressure\\_increment\n\nself.context = initial\\_context\n\nself.initial\\_context = initial\\_context\n\nself.tagged = False\n\nself.agent\\_type = agent\\_type\n\nself.agent\\_instance = agent\\_instance\n\nself.websocket = websocket\n\nself.parliament = parliament\n\nself.is\\_speaking = False\n\nself.relevancy\\_score = 0\n\ndef set\\_typing\\_status(self, status: bool):\n\nself.is\\_typing = status\n\nasync def calculate\\_relevancy(self, chat\\_context):\n\nrelevancy\\_score = 0\n\nif self.relevancy\\_score is None or self.initial\\_context != chat\\_context:\n\nprint(\"Calculating relevancy...\")\n\nprompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n\nprint(f\"Prompt: {prompt}\")\n\nresponse = openai.Completion.create(\n\nengine=\"text-davinci-001\",\n\nprompt=prompt,\n\ntemperature=0.0,\n\nmax\\_tokens=300\n\n)\n\nprint(f\"Response: {response}\")\n\nstripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text)\n\ntry:\n\nrelevancy\\_score = int(stripped\\_response)\n\nexcept ValueError:\n\nrelevancy\\_score = 0\n\nprint(f\"Relevancy score: {relevancy\\_score}\")\n\nelse:\n\nprint(\"Relevancy score already calculated.\")\n\ntime.sleep(.5)\n\nreturn relevancy\\_score\n\nasync def get\\_agent\\_message(self, truncated\\_chat\\_history):\n\nmessage = \"\"\n\nif isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]):\n\nresponse = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history)\n\nmessage = f\"{response}\"\n\nreturn message\n\nasync def respond(self):\n\nawait self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n\nawait self.websocket.send(json.dumps({\"action\": \"stopped\\_typing\", \"sender\": self.name}))\n\nagent\\_message = await self.get\\_agent\\_message(self.parliament.chat\\_history.truncated\\_chat\\_history)\n\nawait self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name}))\n\ndef reset\\_relevancy\\_score(self):\n\nself.relevancy\\_score = None\n\nclass ChatHistory:\n\ndef **init**(self):\n\nself.chat\\_history = \\[\\]\n\nself.truncated\\_chat\\_history = \"\"\n\ndef add(self, message, sender, timestamp):\n\nself.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\nself.truncate\\_chat\\_history()\n\ndef truncate\\_chat\\_history(self, max\\_length=2000):\n\nchat\\_history\\_str = '\\\\n'.join(\\[message\\[\"message\"\\] for message in self.chat\\_history\\])\n\nself.truncated\\_chat\\_history = chat\\_history\\_str\\[-max\\_length:\\]\n\ndef get\\_latest\\_message(self):\n\nreturn self.chat\\_history\\[-1\\] if self.chat\\_history else None\n\nclass SpeakerManager:\n\ndef **init**(self, parliament):\n\nself.parliament = parliament\n\ndef should\\_speak(self, agent):\n\nreturn agent.tagged or agent.speaking\\_pressure >= SPEAKING\\_PRESSURE\\_LIMIT\n\nclass OpenAIAgent:\n\ndef **init**(self, initial\\_context: str):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\"\n\nself.model = \"gpt-3.5-turbo\"\n\nself.initial\\_context = initial\\_context\n\ndef get\\_response(self, truncated\\_chat):\n\nsystem\\_msg = self.initial\\_context\n\nmessages=\\[\\]\n\nmessages.append({\"role\": \"assistant\", \"content\": truncated\\_chat})\n\nmax\\_retries = 3\n\nretry\\_delay = 5\n\nfor i in range(max\\_retries):\n\ntry:\n\n\\# Call the OpenAI API with the messages array\n\nresponse = openai.ChatCompletion.create(\n\nmodel=self.model,\n\nmessages=messages,\n\nmax\\_tokens=150,\n\ntemperature=0.5,\n\ntop\\_p=1,\n\nfrequency\\_penalty=0,\n\npresence\\_penalty=0,\n\n)\n\n\\# Extract and return the assistant's response from the API response\n\nagent\\_response = response.choices\\[0\\].message\\[\"content\"\\].strip()\n\nprint(f\" {agent\\_response}\") # Add logging\n\nreturn agent\\_response\n\nexcept RateLimitError as e:\n\nprint(f\"Rate limit error: {e}. Retrying in {retry\\_delay} seconds...\")\n\nif i < max\\_retries - 1: # Don't sleep on the last iteration\n\ntime.sleep(retry\\_delay)\n\nelse:\n\nraise\n\nreturn \"Sorry, I am unable to respond at the moment.\"\n\nclass GPT4AllAgent:\n\ndef **init**(self):\n\n\\# Download and set up the GPT4All model\n\nself.\\_initialize\\_gpt4all\\_model()\n\nself.\\_initialize\\_llm\\_chain()\n\ndef _initialize_gpt4all\\_model(self):\n\nlocal\\_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n\nPath(local\\_path).parent.mkdir(parents=True, exist\\_ok=True)\n\nurl = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n\nresponse = requests.get(url, stream=True)\n\nwith open(local\\_path, 'wb') as f:\n\nfor chunk in tqdm(response.iter\\_content(chunk\\_size=8192)):\n\nif chunk:\n\nf.write(chunk)\n\nself.model\\_path = local\\_path\n\ndef _initialize_llm\\_chain(self):\n\ntemplate = \"\"\"{chat\\_history}\n\nQuestion: {question}\n\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input\\_variables=\\[\"chat\\_history\", \"question\"\\])\n\ncallbacks = \\[StreamingStdOutCallbackHandler()\\]\n\nllm = GPT4All(model=self.model\\_path, callbacks=callbacks, verbose=True)\n\nself.llm\\_chain = LLMChain(prompt=prompt, llm=llm)\n\ndef get\\_response(self, chat\\_history, question):\n\nreturn self.llm\\_chain.run(chat\\_history=chat\\_history, question=question)\n\nimport json\n\nfrom typing import List\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nclass Parliament:\n\ndef **init**(self, name: str): # Added name argument\n\nself.name = name # Added this line to store the name\n\nself.agents: List\\[Agent\\] = \\[\\]\n\nself.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n\nself.agent\\_instances = {}\n\nself.chat\\_history = ChatHistory()\n\nasync def handle\\_client(self, websocket, path):\n\nasync for message in websocket:\n\nmessage = json.loads(message)\n\nif message\\['action'\\] == 'send\\_message':\n\nself.chat\\_history.add(message\\['message'\\], message\\['sender'\\], message\\['timestamp'\\])\n\nfor agent in self.agents:\n\nif agent.websocket == websocket:\n\nagent.reset\\_relevancy\\_score()\n\nif message.get('reply\\_agent', None):\n\nfor agent in self.agents:\n\nif agent.name == message\\['reply\\_agent'\\]:\n\nawait agent.respond()\n\nelif message\\['action'\\] == 'request\\_agents':\n\nawait self.send\\_agent\\_list(websocket)\n\nelif message\\['action'\\] == UPDATE\\_AGENTS:\n\nself.update\\_agents(message\\['agents'\\], websocket)\n\nasync def send\\_agent\\_list(self, websocket):\n\nagents\\_list = \\[{\"name\": agent.name, \"context\": agent.context} for agent in self.agents\\]\n\nawait websocket.send(json.dumps({\"action\": \"receive\\_agents\", \"agents\": agents\\_list}))\n\ndef update\\_agents(self, agents, websocket):\n\nself.agents = \\[\\]\n\nfor agent in agents:\n\nself.agents.append(Agent(self, agent\\['name'\\], agent\\['context'\\], agent\\['type'\\], self.agent\\_instances\\[agent\\['type'\\]\\], websocket))\n\ndef add\\_agent\\_type(self, agent\\_type\\_name, agent\\_type\\_class):\n\nself.agent\\_types\\[agent\\_type\\_name\\] = agent\\_type\\_class\n\ndef add\\_agent\\_instance(self, agent\\_instance\\_name, agent\\_instance):\n\nself.agent\\_instances\\[agent\\_instance\\_name\\] = agent\\_instance\n\ndef add\\_agent(self, agent):\n\nself.agents.append(agent)\n\nasync def broadcast\\_message(self, message, sender, timestamp):\n\nself.chat\\_history.add(message, sender, timestamp)\n\nmentioned\\_agents = self.identify\\_and\\_tag\\_mentioned\\_agents(message)\n\n\\# await asyncio.sleep(BROADCAST\\_DELAY)\n\ndef identify\\_and\\_tag\\_mentioned\\_agents(self, message):\n\nmentioned\\_agents = \\[\\]\n\nfor agent in self.agents:\n\nif '@'+agent.name in message:\n\nmentioned\\_agents.append(agent)\n\nagent.speaking\\_pressure = SPEAKING\\_PRESSURE\\_LIMIT\n\nagent.tagged = True\n\nreturn mentioned\\_agents\n\ndef increment\\_speaking\\_pressure(self, mentioned\\_agents):\n\nfor agent in self.agents:\n\nif agent.name not in mentioned\\_agents:\n\nagent.speaking\\_pressure += agent.speaking\\_pressure\\_increment\n\nasync def get\\_agents\\_info(self) -> List\\[dict\\]:\n\nagents\\_info = \\[\\]\n\nfor agent in self.agents:\n\nagents\\_info.append({\n\n\"name\": agent.name,\n\n\"speaking\\_pressure\": agent.speaking\\_pressure,\n\n\"speaking\\_pressure\\_increment\": agent.speaking\\_pressure\\_increment,\n\n\"context\": agent.context,\n\n\"agent\\_type\": agent.agent\\_type,\n\n\"relevancy\\_score\": agent.relevancy\\_score # Return the cached score\n\n})\n\nreturn agents\\_info",
      "created_at": "2023-05-20T18:11:53.356621Z",
      "sequence_order": 26,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T18:11:53.356621Z",
            "stop_timestamp": "2023-05-20T18:11:53.356621Z",
            "flags": null,
            "type": "text",
            "text": "when the agents are created I want them all to calculate their relevancy according to the topic of the parliament\n\nserver.py\n\nfrom datetime import datetime\n\nimport asyncio\n\nimport json\n\nfrom websockets import serve\n\nfrom parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent\n\nimport openai\n\n\\# Constants\n\nSET\\_PARLIAMENT = \"set\\_parliament\"\n\nSEND\\_MESSAGE = \"send\\_message\"\n\nADD\\_AGENTS = \"add\\_agents\"\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nRECEIVE\\_MESSAGE = \"receive\\_message\"\n\nERROR = \"error\"\n\nTYPING = \"typing\"\n\nSTOPPED\\_TYPING = \"stopped\\_typing\"\n\nclass ParliamentServer:\n\ndef **init**(self, host=\"localhost\", port=8080):\n\nself.host = host\n\nself.port = port\n\nself.parliament = None\n\nself.start\\_server = serve(self.chat, self.host, self.port)\n\ndef configure\\_openai(self):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\"\n\nasync def chat(self, websocket, path):\n\nasync for message in websocket:\n\ndata = json.loads(message)\n\naction = data.get(\"action\")\n\nif action == SET\\_PARLIAMENT:\n\nawait self.handle\\_set\\_parliament(websocket, data)\n\nelif action == SEND\\_MESSAGE:\n\nawait self.handle\\_send\\_message(websocket, data)\n\nelif action == ADD\\_AGENTS:\n\nawait self.handle\\_add\\_agents(websocket, data)\n\nelif action in \\[TYPING, STOPPED\\_TYPING\\]:\n\nawait self.handle\\_typing(websocket, data)\n\nasync def handle\\_typing(self, websocket, data):\n\nsender = data.get('sender')\n\naction = data.get('action')\n\nis\\_typing = action == TYPING\n\nfor agent in self.parliament.agents:\n\nif agent.name == sender:\n\nagent.set\\_typing\\_status(is\\_typing)\n\n\\# Send the typing status update to other clients:\n\nawait websocket.send(json.dumps({\n\n\"action\": action,\n\n\"sender\": sender,\n\n\"is\\_typing\": is\\_typing\n\n}))\n\nasync def handle\\_set\\_parliament(self, websocket, data):\n\nparliament\\_name = data.get(\"name\")\n\nif parliament\\_name:\n\nself.parliament = Parliament(parliament\\_name)\n\nasync def handle\\_send\\_message(self, websocket, data):\n\nif not self.parliament:\n\nawait self.send\\_error(websocket, \"Parliament not set.\")\n\nreturn\n\nsender = data.get(\"sender\")\n\nuser\\_message = data.get(\"message\")\n\ntimestamp = datetime.now()\n\nawait websocket.send(json.dumps({\n\n\"action\": RECEIVE\\_MESSAGE,\n\n\"message\": user\\_message,\n\n\"sender\": sender,\n\n\"timestamp\": timestamp.isoformat()}))\n\nawait self.parliament.broadcast\\_message(user\\_message, sender, timestamp)\n\nprint(f\"Broadcast message: {user\\_message}\") # Add logging\n\n\\# Sending agent info after broadcasting message\n\nagent\\_info = await self.parliament.get\\_agents\\_info()\n\nawait websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info}))\n\nasync def handle\\_add\\_agents(self, websocket, data):\n\nif not self.parliament:\n\nawait self.send\\_error(websocket, \"Parliament not set.\")\n\nreturn\n\nagents\\_data = data.get(\"agents\")\n\nif not agents\\_data:\n\nawait self.send\\_error(websocket, \"No agent data provided.\")\n\nreturn\n\nfor agent\\_data in agents\\_data:\n\nagent\\_name = agent\\_data.get(\"name\") # Extract the name\n\nspeaking\\_pressure\\_increment = int(agent\\_data.get(\"speaking\\_pressure\\_increment\"))\n\nother\\_agents = \", \".join(\\[agent\\['name'\\] for agent in agents\\_data if agent\\['name'\\] != agent\\_name\\])\n\ninitial\\_context = (\n\nf\"Hello assistant, your name is: @{agent\\_data.get('name')} and your context is \"\n\nf\"{agent\\_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n\nf\"alongside your fellow agents in a parliament, which is a sort \"\n\nf\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n\nf\"with you are {other\\_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n\nf\"{agent\\_data.get('speaking\\_pressure\\_increment')} out of 100\"\n\n)\n\nagent\\_type = agent\\_data.get(\"type\")\n\nagent\\_class = self.parliament.agent\\_types.get(agent\\_type) # Get OpenAIAgent or GPT4AllAgent\n\nagent\\_instance = agent\\_class(initial\\_context) # Properly instantiate the class\n\nif isinstance(agent\\_instance, self.parliament.agent\\_types\\[agent\\_type\\]):\n\nagent\\_instance = OpenAIAgent(initial\\_context) # Create the OpenAIAgent instance\n\nagent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket)\n\nself.parliament.add\\_agent(agent) # Pass the agent instance to add\\_agent\n\nelse:\n\nprint(\"Error occurred attempting to get agent message!\")\n\nreturn \"Sorry, I'm unable to generate a relevant response at this time.\"\n\nawait self.send\\_error(websocket, f\"Unknown agent type: {agent\\_type}\")\n\ncontinue\n\nasync def send\\_error(self, websocket, message):\n\nawait websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\ndef run(self):\n\nself.configure\\_openai()\n\nasyncio.get\\_event\\_loop().run\\_until\\_complete(self.start\\_server)\n\nprint(\"Starting WebSocket server...\")\n\nprint(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n\nasyncio.get\\_event\\_loop().run\\_forever()\n\nif **name** == \"\\_\\_main\\_\\_\":\n\nserver = ParliamentServer()\n\nserver.run()\n\nparliament.py:\n\nimport asyncio\n\nimport re\n\nimport random\n\nimport json\n\nimport openai\n\nfrom openai.error import RateLimitError\n\nimport time\n\nfrom typing import List\n\nfrom collections import deque\n\nPRESSURE\\_INCREMENT\\_INTERVAL = 15\n\nSPEAKING\\_PRESSURE\\_LIMIT = 100\n\nBROADCAST\\_DELAY = 1\n\nRELEVANCY\\_THRESHOLD = 100\n\nSTOPPED\\_TYPING = \"stopped\\_typing\"\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nclass Agent:\n\ndef **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None):\n\nself.name = agent\\_name\n\nself.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment\n\nself.speaking\\_pressure = speaking\\_pressure\\_increment\n\nself.context = initial\\_context\n\nself.initial\\_context = initial\\_context\n\nself.tagged = False\n\nself.agent\\_type = agent\\_type\n\nself.agent\\_instance = agent\\_instance\n\nself.websocket = websocket\n\nself.parliament = parliament\n\nself.is\\_speaking = False\n\nself.relevancy\\_score = 0\n\ndef set\\_typing\\_status(self, status: bool):\n\nself.is\\_typing = status\n\nasync def calculate\\_relevancy(self, chat\\_context):\n\nrelevancy\\_score = 0\n\nif self.relevancy\\_score is None or self.initial\\_context != chat\\_context:\n\nprint(\"Calculating relevancy...\")\n\nprompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\"\n\nprint(f\"Prompt: {prompt}\")\n\nresponse = openai.Completion.create(\n\nengine=\"text-davinci-001\",\n\nprompt=prompt,\n\ntemperature=0.0,\n\nmax\\_tokens=300\n\n)\n\nprint(f\"Response: {response}\")\n\nstripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text)\n\ntry:\n\nrelevancy\\_score = int(stripped\\_response)\n\nexcept ValueError:\n\nrelevancy\\_score = 0\n\nprint(f\"Relevancy score: {relevancy\\_score}\")\n\nelse:\n\nprint(\"Relevancy score already calculated.\")\n\ntime.sleep(.5)\n\nreturn relevancy\\_score\n\nasync def get\\_agent\\_message(self, truncated\\_chat\\_history):\n\nmessage = \"\"\n\nif isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]):\n\nresponse = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history)\n\nmessage = f\"{response}\"\n\nreturn message\n\nasync def respond(self):\n\nawait self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n\nawait self.websocket.send(json.dumps({\"action\": \"stopped\\_typing\", \"sender\": self.name}))\n\nagent\\_message = await self.get\\_agent\\_message(self.parliament.chat\\_history.truncated\\_chat\\_history)\n\nawait self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name}))\n\ndef reset\\_relevancy\\_score(self):\n\nself.relevancy\\_score = None\n\nclass ChatHistory:\n\ndef **init**(self):\n\nself.chat\\_history = \\[\\]\n\nself.truncated\\_chat\\_history = \"\"\n\ndef add(self, message, sender, timestamp):\n\nself.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\nself.truncate\\_chat\\_history()\n\ndef truncate\\_chat\\_history(self, max\\_length=2000):\n\nchat\\_history\\_str = '\\\\n'.join(\\[message\\[\"message\"\\] for message in self.chat\\_history\\])\n\nself.truncated\\_chat\\_history = chat\\_history\\_str\\[-max\\_length:\\]\n\ndef get\\_latest\\_message(self):\n\nreturn self.chat\\_history\\[-1\\] if self.chat\\_history else None\n\nclass SpeakerManager:\n\ndef **init**(self, parliament):\n\nself.parliament = parliament\n\ndef should\\_speak(self, agent):\n\nreturn agent.tagged or agent.speaking\\_pressure >= SPEAKING\\_PRESSURE\\_LIMIT\n\nclass OpenAIAgent:\n\ndef **init**(self, initial\\_context: str):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\"\n\nself.model = \"gpt-3.5-turbo\"\n\nself.initial\\_context = initial\\_context\n\ndef get\\_response(self, truncated\\_chat):\n\nsystem\\_msg = self.initial\\_context\n\nmessages=\\[\\]\n\nmessages.append({\"role\": \"assistant\", \"content\": truncated\\_chat})\n\nmax\\_retries = 3\n\nretry\\_delay = 5\n\nfor i in range(max\\_retries):\n\ntry:\n\n\\# Call the OpenAI API with the messages array\n\nresponse = openai.ChatCompletion.create(\n\nmodel=self.model,\n\nmessages=messages,\n\nmax\\_tokens=150,\n\ntemperature=0.5,\n\ntop\\_p=1,\n\nfrequency\\_penalty=0,\n\npresence\\_penalty=0,\n\n)\n\n\\# Extract and return the assistant's response from the API response\n\nagent\\_response = response.choices\\[0\\].message\\[\"content\"\\].strip()\n\nprint(f\" {agent\\_response}\") # Add logging\n\nreturn agent\\_response\n\nexcept RateLimitError as e:\n\nprint(f\"Rate limit error: {e}. Retrying in {retry\\_delay} seconds...\")\n\nif i < max\\_retries - 1: # Don't sleep on the last iteration\n\ntime.sleep(retry\\_delay)\n\nelse:\n\nraise\n\nreturn \"Sorry, I am unable to respond at the moment.\"\n\nclass GPT4AllAgent:\n\ndef **init**(self):\n\n\\# Download and set up the GPT4All model\n\nself.\\_initialize\\_gpt4all\\_model()\n\nself.\\_initialize\\_llm\\_chain()\n\ndef _initialize_gpt4all\\_model(self):\n\nlocal\\_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n\nPath(local\\_path).parent.mkdir(parents=True, exist\\_ok=True)\n\nurl = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n\nresponse = requests.get(url, stream=True)\n\nwith open(local\\_path, 'wb') as f:\n\nfor chunk in tqdm(response.iter\\_content(chunk\\_size=8192)):\n\nif chunk:\n\nf.write(chunk)\n\nself.model\\_path = local\\_path\n\ndef _initialize_llm\\_chain(self):\n\ntemplate = \"\"\"{chat\\_history}\n\nQuestion: {question}\n\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input\\_variables=\\[\"chat\\_history\", \"question\"\\])\n\ncallbacks = \\[StreamingStdOutCallbackHandler()\\]\n\nllm = GPT4All(model=self.model\\_path, callbacks=callbacks, verbose=True)\n\nself.llm\\_chain = LLMChain(prompt=prompt, llm=llm)\n\ndef get\\_response(self, chat\\_history, question):\n\nreturn self.llm\\_chain.run(chat\\_history=chat\\_history, question=question)\n\nimport json\n\nfrom typing import List\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nclass Parliament:\n\ndef **init**(self, name: str): # Added name argument\n\nself.name = name # Added this line to store the name\n\nself.agents: List\\[Agent\\] = \\[\\]\n\nself.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n\nself.agent\\_instances = {}\n\nself.chat\\_history = ChatHistory()\n\nasync def handle\\_client(self, websocket, path):\n\nasync for message in websocket:\n\nmessage = json.loads(message)\n\nif message\\['action'\\] == 'send\\_message':\n\nself.chat\\_history.add(message\\['message'\\], message\\['sender'\\], message\\['timestamp'\\])\n\nfor agent in self.agents:\n\nif agent.websocket == websocket:\n\nagent.reset\\_relevancy\\_score()\n\nif message.get('reply\\_agent', None):\n\nfor agent in self.agents:\n\nif agent.name == message\\['reply\\_agent'\\]:\n\nawait agent.respond()\n\nelif message\\['action'\\] == 'request\\_agents':\n\nawait self.send\\_agent\\_list(websocket)\n\nelif message\\['action'\\] == UPDATE\\_AGENTS:\n\nself.update\\_agents(message\\['agents'\\], websocket)\n\nasync def send\\_agent\\_list(self, websocket):\n\nagents\\_list = \\[{\"name\": agent.name, \"context\": agent.context} for agent in self.agents\\]\n\nawait websocket.send(json.dumps({\"action\": \"receive\\_agents\", \"agents\": agents\\_list}))\n\ndef update\\_agents(self, agents, websocket):\n\nself.agents = \\[\\]\n\nfor agent in agents:\n\nself.agents.append(Agent(self, agent\\['name'\\], agent\\['context'\\], agent\\['type'\\], self.agent\\_instances\\[agent\\['type'\\]\\], websocket))\n\ndef add\\_agent\\_type(self, agent\\_type\\_name, agent\\_type\\_class):\n\nself.agent\\_types\\[agent\\_type\\_name\\] = agent\\_type\\_class\n\ndef add\\_agent\\_instance(self, agent\\_instance\\_name, agent\\_instance):\n\nself.agent\\_instances\\[agent\\_instance\\_name\\] = agent\\_instance\n\ndef add\\_agent(self, agent):\n\nself.agents.append(agent)\n\nasync def broadcast\\_message(self, message, sender, timestamp):\n\nself.chat\\_history.add(message, sender, timestamp)\n\nmentioned\\_agents = self.identify\\_and\\_tag\\_mentioned\\_agents(message)\n\n\\# await asyncio.sleep(BROADCAST\\_DELAY)\n\ndef identify\\_and\\_tag\\_mentioned\\_agents(self, message):\n\nmentioned\\_agents = \\[\\]\n\nfor agent in self.agents:\n\nif '@'+agent.name in message:\n\nmentioned\\_agents.append(agent)\n\nagent.speaking\\_pressure = SPEAKING\\_PRESSURE\\_LIMIT\n\nagent.tagged = True\n\nreturn mentioned\\_agents\n\ndef increment\\_speaking\\_pressure(self, mentioned\\_agents):\n\nfor agent in self.agents:\n\nif agent.name not in mentioned\\_agents:\n\nagent.speaking\\_pressure += agent.speaking\\_pressure\\_increment\n\nasync def get\\_agents\\_info(self) -> List\\[dict\\]:\n\nagents\\_info = \\[\\]\n\nfor agent in self.agents:\n\nagents\\_info.append({\n\n\"name\": agent.name,\n\n\"speaking\\_pressure\": agent.speaking\\_pressure,\n\n\"speaking\\_pressure\\_increment\": agent.speaking\\_pressure\\_increment,\n\n\"context\": agent.context,\n\n\"agent\\_type\": agent.agent\\_type,\n\n\"relevancy\\_score\": agent.relevancy\\_score # Return the cached score\n\n})\n\nreturn agents\\_info",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T18:11:53.356621Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "cae52538-a22e-4f2c-a99a-f7044361ba9c",
      "role": "assistant",
      "content": " To have all agents calculate their relevancy when the parliament is created, you can add a startup method to the Parliament class. In that method, you can loop through the agents and call calculate_relevancy on each one, passing in the parliament topic.\n\nHere's an example:\n```python\nclass Parliament:\n    def __init__(self, name: str, topic: str):\n        self.name = name\n        self.topic = topic\n        ...\n        \n    async def startup(self):\n        for agent in self.agents:\n            relevancy = await agent.calculate_relevancy(self.topic)\n            agent.relevancy_score = relevancy \n```\n\nThen in server.py, after creating the Parliament instance, call:\n```python\nawait parliament.startup()  # Call this to calculate relevancy scores\n```\n\nThis will loop through each agent and calculate its relevancy to the given topic, caching the score on the agent.\n\nThe full code would be:\n\nparliament.py:\n```python\nclass Parliament:\n    def __init__(self, name: str, topic: str):\n        self.name = name\n        self.topic = topic\n        ... \n        \n    async def startup(self):\n        for agent in self.agents:\n            relevancy = await agent.calculate_relevancy(self.topic)\n            agent.relevancy_score = relevancy  \n```\n\nserver.py:\n```python\nasync def handle_set_parliament(self, websocket, data):\n    parliament_name = data.get(\"name\")\n    topic = data.get(\"topic\")  # Get the topic from the request\n    if parliament_name and topic:\n        self.parliament = Parliament(parliament_name, topic)\n        await parliament.startup()   # Call to calculate relevancy scores \n```\n\nLet me know if you have any other questions!",
      "created_at": "2023-05-20T18:12:27.308334Z",
      "sequence_order": 27,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T18:12:27.308334Z",
            "stop_timestamp": "2023-05-20T18:12:27.308334Z",
            "flags": null,
            "type": "text",
            "text": " To have all agents calculate their relevancy when the parliament is created, you can add a startup method to the Parliament class. In that method, you can loop through the agents and call calculate_relevancy on each one, passing in the parliament topic.\n\nHere's an example:\n```python\nclass Parliament:\n    def __init__(self, name: str, topic: str):\n        self.name = name\n        self.topic = topic\n        ...\n        \n    async def startup(self):\n        for agent in self.agents:\n            relevancy = await agent.calculate_relevancy(self.topic)\n            agent.relevancy_score = relevancy \n```\n\nThen in server.py, after creating the Parliament instance, call:\n```python\nawait parliament.startup()  # Call this to calculate relevancy scores\n```\n\nThis will loop through each agent and calculate its relevancy to the given topic, caching the score on the agent.\n\nThe full code would be:\n\nparliament.py:\n```python\nclass Parliament:\n    def __init__(self, name: str, topic: str):\n        self.name = name\n        self.topic = topic\n        ... \n        \n    async def startup(self):\n        for agent in self.agents:\n            relevancy = await agent.calculate_relevancy(self.topic)\n            agent.relevancy_score = relevancy  \n```\n\nserver.py:\n```python\nasync def handle_set_parliament(self, websocket, data):\n    parliament_name = data.get(\"name\")\n    topic = data.get(\"topic\")  # Get the topic from the request\n    if parliament_name and topic:\n        self.parliament = Parliament(parliament_name, topic)\n        await parliament.startup()   # Call to calculate relevancy scores \n```\n\nLet me know if you have any other questions!",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T18:12:27.308334Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "049f6101-9ffe-4215-9c3a-789f4db2228b",
      "role": "human",
      "content": "it says for this line that parliament is not defined",
      "created_at": "2023-05-20T18:20:07.385089Z",
      "sequence_order": 28,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T18:20:07.385089Z",
            "stop_timestamp": "2023-05-20T18:20:07.385089Z",
            "flags": null,
            "type": "text",
            "text": "it says for this line that parliament is not defined",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T18:20:07.385089Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "e84c4aee-4520-4bbd-aa79-02cdb7221616",
      "role": "assistant",
      "content": " You're correct, I apologize - I made a mistake in my suggested code! Since that code is inside the handle_set_parliament method, self.parliament will not exist yet when you try to call startup() on it.\n\nTo fix this, you'll need to first create the Parliament instance, then call startup() on it. So the corrected code would be:\n\n```python\nasync def handle_set_parliament(self, websocket, data):\n    parliament_name = data.get(\"name\")\n    topic = data.get(\"topic\")  # Get the topic from the request\n    if parliament_name and topic:\n        self.parliament = Parliament(parliament_name, topic)\n        await self.parliament.startup()   # Call to calculate relevancy scores \n```\n\nUsing self.parliament to reference the instance will fix that error.\n\nThe full corrected code would be:\n\nparliament.py:\n```python\nclass Parliament:\n    def __init__(self, name: str, topic: str):\n        self.name = name\n        self.topic = topic\n        ... \n        \n    async def startup(self):\n        for agent in self.agents:\n            relevancy = await agent.calculate_relevancy(self.topic)\n            agent.relevancy_score = relevancy  \n```\n\nserver.py:\n```python \nasync def handle_set_parliament(self, websocket, data):\n    parliament_name = data.get(\"name\")\n    topic = data.get(\"topic\")  # Get the topic from the request\n    if parliament_name and topic:\n        self.parliament = Parliament(parliament_name, topic)\n        await self.parliament.startup()   # Call to calculate relevancy scores \n```\n\nMy apologies for the mistake! Let me know if you have any other questions.",
      "created_at": "2023-05-20T18:20:39.929635Z",
      "sequence_order": 29,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T18:20:39.929635Z",
            "stop_timestamp": "2023-05-20T18:20:39.929635Z",
            "flags": null,
            "type": "text",
            "text": " You're correct, I apologize - I made a mistake in my suggested code! Since that code is inside the handle_set_parliament method, self.parliament will not exist yet when you try to call startup() on it.\n\nTo fix this, you'll need to first create the Parliament instance, then call startup() on it. So the corrected code would be:\n\n```python\nasync def handle_set_parliament(self, websocket, data):\n    parliament_name = data.get(\"name\")\n    topic = data.get(\"topic\")  # Get the topic from the request\n    if parliament_name and topic:\n        self.parliament = Parliament(parliament_name, topic)\n        await self.parliament.startup()   # Call to calculate relevancy scores \n```\n\nUsing self.parliament to reference the instance will fix that error.\n\nThe full corrected code would be:\n\nparliament.py:\n```python\nclass Parliament:\n    def __init__(self, name: str, topic: str):\n        self.name = name\n        self.topic = topic\n        ... \n        \n    async def startup(self):\n        for agent in self.agents:\n            relevancy = await agent.calculate_relevancy(self.topic)\n            agent.relevancy_score = relevancy  \n```\n\nserver.py:\n```python \nasync def handle_set_parliament(self, websocket, data):\n    parliament_name = data.get(\"name\")\n    topic = data.get(\"topic\")  # Get the topic from the request\n    if parliament_name and topic:\n        self.parliament = Parliament(parliament_name, topic)\n        await self.parliament.startup()   # Call to calculate relevancy scores \n```\n\nMy apologies for the mistake! Let me know if you have any other questions.",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T18:20:39.929635Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "ee0d98db-8727-4beb-8be2-f16db7d41c92",
      "role": "human",
      "content": "Traceback (most recent call last):\n\n File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n\n  await self.ws\\_handler(self)\n\n File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n\n  return await cast(\n\n File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 40, in chat\n\n  await self.handle\\_typing(websocket, data)\n\n File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 46, in handle\\_typing\n\n  for agent in self.parliament.agents:\n\nAttributeError: 'NoneType' object has no attribute 'agents'",
      "created_at": "2023-05-20T18:23:01.248738Z",
      "sequence_order": 30,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T18:23:01.248738Z",
            "stop_timestamp": "2023-05-20T18:23:01.248738Z",
            "flags": null,
            "type": "text",
            "text": "Traceback (most recent call last):\n\n File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler\n\n  await self.ws\\_handler(self)\n\n File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler\n\n  return await cast(\n\n File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 40, in chat\n\n  await self.handle\\_typing(websocket, data)\n\n File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 46, in handle\\_typing\n\n  for agent in self.parliament.agents:\n\nAttributeError: 'NoneType' object has no attribute 'agents'",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T18:23:01.248738Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "0ffc3a51-8ffc-4abd-939a-7287f175ac92",
      "role": "assistant",
      "content": " This error is occurring because self.parliament does not exist yet when you try to access self.parliament.agents.\n\nTo fix this, you'll need to add a check to ensure self.parliament exists before accessing its attributes.\n\nThe updated handle_typing method would be:\n```python\nasync def handle_typing(self, websocket, data):\n    if not self.parliament:\n        await self.send_error(websocket, \"Parliament not set.\")\n        return\n    sender = data.get('sender')\n    action = data.get('action')\n    is_typing = action == TYPING\n    for agent in self.parliament.agents:\n        if agent.name == sender:\n            agent.set_typing_status(is_typing) \n    # Send the typing status update to other clients:\n    ...\n```\n\nThis will check if self.parliament exists, and if not, return an error.\n\nYou'll also want to add similar checks in the other event handler methods (handle_set_parliament, handle_send_message, handle_add_agents) to ensure self.parliament is defined before accessing its attributes.\n\nThe full updated code would be:\n\nserver.py\n```python\nasync def chat(self, websocket, path):\n    async for message in websocket:\n        data = json.loads(message)\n        action = data.get(\"action\")\n        if action == SET_PARLIAMENT:\n            await self.handle_set_parliament(websocket, data) \n        elif action == SEND_MESSAGE: \n            await self.handle_send_message(websocket, data)\n        elif action == ADD_AGENTS:\n            await self.handle_add_agents(websocket, data)\n        elif action in [TYPING, STOPPED_TYPING]:\n            await self.handle_typing(websocket, data) \n\nasync def handle_typing(self, websocket, data):\n    if not self.parliament:\n        await self.send_error(websocket, \"Parliament not set.\")\n        return\n    ...\n\nasync def handle_set_parliament(self, websocket, data):\n    ...\n    if not parliament_name or not topic:\n        await self.send_error(websocket, \"Parliament name and topic required.\") \n        return\n    ... \n```  \n\nLet me know if you have any other questions!",
      "created_at": "2023-05-20T18:23:38.274941Z",
      "sequence_order": 31,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T18:23:38.274941Z",
            "stop_timestamp": "2023-05-20T18:23:38.274941Z",
            "flags": null,
            "type": "text",
            "text": " This error is occurring because self.parliament does not exist yet when you try to access self.parliament.agents.\n\nTo fix this, you'll need to add a check to ensure self.parliament exists before accessing its attributes.\n\nThe updated handle_typing method would be:\n```python\nasync def handle_typing(self, websocket, data):\n    if not self.parliament:\n        await self.send_error(websocket, \"Parliament not set.\")\n        return\n    sender = data.get('sender')\n    action = data.get('action')\n    is_typing = action == TYPING\n    for agent in self.parliament.agents:\n        if agent.name == sender:\n            agent.set_typing_status(is_typing) \n    # Send the typing status update to other clients:\n    ...\n```\n\nThis will check if self.parliament exists, and if not, return an error.\n\nYou'll also want to add similar checks in the other event handler methods (handle_set_parliament, handle_send_message, handle_add_agents) to ensure self.parliament is defined before accessing its attributes.\n\nThe full updated code would be:\n\nserver.py\n```python\nasync def chat(self, websocket, path):\n    async for message in websocket:\n        data = json.loads(message)\n        action = data.get(\"action\")\n        if action == SET_PARLIAMENT:\n            await self.handle_set_parliament(websocket, data) \n        elif action == SEND_MESSAGE: \n            await self.handle_send_message(websocket, data)\n        elif action == ADD_AGENTS:\n            await self.handle_add_agents(websocket, data)\n        elif action in [TYPING, STOPPED_TYPING]:\n            await self.handle_typing(websocket, data) \n\nasync def handle_typing(self, websocket, data):\n    if not self.parliament:\n        await self.send_error(websocket, \"Parliament not set.\")\n        return\n    ...\n\nasync def handle_set_parliament(self, websocket, data):\n    ...\n    if not parliament_name or not topic:\n        await self.send_error(websocket, \"Parliament name and topic required.\") \n        return\n    ... \n```  \n\nLet me know if you have any other questions!",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T18:23:38.274941Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "f0ddefd5-d2dc-4196-b684-de1cf85b7a3e",
      "role": "human",
      "content": "should we set up the parliament class in parliament server's run function?\n\nfrom datetime import datetime\n\nimport asyncio\n\nimport json\n\nfrom websockets import serve\n\nfrom parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent\n\nimport openai\n\n\\# Constants\n\nSET\\_PARLIAMENT = \"set\\_parliament\"\n\nSEND\\_MESSAGE = \"send\\_message\"\n\nADD\\_AGENTS = \"add\\_agents\"\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nRECEIVE\\_MESSAGE = \"receive\\_message\"\n\nERROR = \"error\"\n\nTYPING = \"typing\"\n\nSTOPPED\\_TYPING = \"stopped\\_typing\"\n\nclass ParliamentServer:\n\ndef **init**(self, host=\"localhost\", port=8080):\n\nself.host = host\n\nself.port = port\n\nself.parliament = None\n\nself.start\\_server = serve(self.chat, self.host, self.port)\n\ndef configure\\_openai(self):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\"\n\nasync def chat(self, websocket, path):\n\nasync for message in websocket:\n\ndata = json.loads(message)\n\naction = data.get(\"action\")\n\nif action == SET\\_PARLIAMENT:\n\nawait self.handle\\_set\\_parliament(websocket, data)\n\nelif action == SEND\\_MESSAGE:\n\nawait self.handle\\_send\\_message(websocket, data)\n\nelif action == ADD\\_AGENTS:\n\nawait self.handle\\_add\\_agents(websocket, data)\n\nasync def handle\\_set\\_parliament(self, websocket, data):\n\nparliament\\_name = data.get(\"name\")\n\ntopic = data.get(\"topic\")\n\nif parliament\\_name and topic:\n\nself.parliament = Parliament(parliament\\_name, topic)\n\nawait self.parliament.startup()\n\nasync def handle\\_send\\_message(self, websocket, data):\n\nprint(f\"Broadcast message: {data}\")\n\nif not self.parliament:\n\nawait self.send\\_error(websocket, \"Parliament not set.\")\n\nreturn\n\nsender = data.get(\"sender\")\n\nuser\\_message = data.get(\"message\")\n\ntimestamp = datetime.now()\n\nawait websocket.send(json.dumps({\n\n\"action\": RECEIVE\\_MESSAGE,\n\n\"message\": user\\_message,\n\n\"sender\": sender,\n\n\"timestamp\": timestamp.isoformat()}))\n\nawait self.parliament.broadcast\\_message(user\\_message, sender, timestamp)\n\nprint(f\"Broadcast message: {user\\_message}\") # Add logging\n\n\\# Sending agent info after broadcasting message\n\nagent\\_info = await self.parliament.get\\_agents\\_info()\n\nawait websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info}))\n\nasync def handle\\_add\\_agents(self, websocket, data):\n\nif not self.parliament:\n\nawait self.send\\_error(websocket, \"Parliament not set.\")\n\nreturn\n\nagents\\_data = data.get(\"agents\")\n\nif not agents\\_data:\n\nawait self.send\\_error(websocket, \"No agent data provided.\")\n\nreturn\n\nfor agent\\_data in agents\\_data:\n\nagent\\_name = agent\\_data.get(\"name\") # Extract the name\n\nspeaking\\_pressure\\_increment = int(agent\\_data.get(\"speaking\\_pressure\\_increment\"))\n\nother\\_agents = \", \".join(\\[agent\\['name'\\] for agent in agents\\_data if agent\\['name'\\] != agent\\_name\\])\n\ninitial\\_context = (\n\nf\"Hello assistant, your name is: @{agent\\_data.get('name')} and your context is \"\n\nf\"{agent\\_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n\nf\"alongside your fellow agents in a parliament, which is a sort \"\n\nf\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n\nf\"with you are {other\\_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n\nf\"{agent\\_data.get('speaking\\_pressure\\_increment')} out of 100\"\n\n)\n\nagent\\_type = agent\\_data.get(\"type\")\n\nagent\\_class = self.parliament.agent\\_types.get(agent\\_type) # Get OpenAIAgent or GPT4AllAgent\n\nagent\\_instance = agent\\_class(initial\\_context) # Properly instantiate the class\n\nif isinstance(agent\\_instance, self.parliament.agent\\_types\\[agent\\_type\\]):\n\nagent\\_instance = OpenAIAgent(initial\\_context) # Create the OpenAIAgent instance\n\nagent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket)\n\nself.parliament.add\\_agent(agent) # Pass the agent instance to add\\_agent\n\nelse:\n\nprint(\"Error occurred attempting to get agent message!\")\n\nreturn \"Sorry, I'm unable to generate a relevant response at this time.\"\n\nawait self.send\\_error(websocket, f\"Unknown agent type: {agent\\_type}\")\n\ncontinue\n\nasync def send\\_error(self, websocket, message):\n\nawait websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\ndef run(self):\n\nself.configure\\_openai()\n\nasyncio.get\\_event\\_loop().run\\_until\\_complete(self.start\\_server)\n\nprint(\"Starting WebSocket server...\")\n\nprint(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n\nasyncio.get\\_event\\_loop().run\\_forever()\n\nif **name** == \"\\_\\_main\\_\\_\":\n\nserver = ParliamentServer()\n\nserver.run()",
      "created_at": "2023-05-20T18:36:44.705004Z",
      "sequence_order": 32,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T18:36:44.705004Z",
            "stop_timestamp": "2023-05-20T18:36:44.705004Z",
            "flags": null,
            "type": "text",
            "text": "should we set up the parliament class in parliament server's run function?\n\nfrom datetime import datetime\n\nimport asyncio\n\nimport json\n\nfrom websockets import serve\n\nfrom parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent\n\nimport openai\n\n\\# Constants\n\nSET\\_PARLIAMENT = \"set\\_parliament\"\n\nSEND\\_MESSAGE = \"send\\_message\"\n\nADD\\_AGENTS = \"add\\_agents\"\n\nUPDATE\\_AGENTS = \"update\\_agents\"\n\nRECEIVE\\_MESSAGE = \"receive\\_message\"\n\nERROR = \"error\"\n\nTYPING = \"typing\"\n\nSTOPPED\\_TYPING = \"stopped\\_typing\"\n\nclass ParliamentServer:\n\ndef **init**(self, host=\"localhost\", port=8080):\n\nself.host = host\n\nself.port = port\n\nself.parliament = None\n\nself.start\\_server = serve(self.chat, self.host, self.port)\n\ndef configure\\_openai(self):\n\nopenai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n\nopenai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\"\n\nasync def chat(self, websocket, path):\n\nasync for message in websocket:\n\ndata = json.loads(message)\n\naction = data.get(\"action\")\n\nif action == SET\\_PARLIAMENT:\n\nawait self.handle\\_set\\_parliament(websocket, data)\n\nelif action == SEND\\_MESSAGE:\n\nawait self.handle\\_send\\_message(websocket, data)\n\nelif action == ADD\\_AGENTS:\n\nawait self.handle\\_add\\_agents(websocket, data)\n\nasync def handle\\_set\\_parliament(self, websocket, data):\n\nparliament\\_name = data.get(\"name\")\n\ntopic = data.get(\"topic\")\n\nif parliament\\_name and topic:\n\nself.parliament = Parliament(parliament\\_name, topic)\n\nawait self.parliament.startup()\n\nasync def handle\\_send\\_message(self, websocket, data):\n\nprint(f\"Broadcast message: {data}\")\n\nif not self.parliament:\n\nawait self.send\\_error(websocket, \"Parliament not set.\")\n\nreturn\n\nsender = data.get(\"sender\")\n\nuser\\_message = data.get(\"message\")\n\ntimestamp = datetime.now()\n\nawait websocket.send(json.dumps({\n\n\"action\": RECEIVE\\_MESSAGE,\n\n\"message\": user\\_message,\n\n\"sender\": sender,\n\n\"timestamp\": timestamp.isoformat()}))\n\nawait self.parliament.broadcast\\_message(user\\_message, sender, timestamp)\n\nprint(f\"Broadcast message: {user\\_message}\") # Add logging\n\n\\# Sending agent info after broadcasting message\n\nagent\\_info = await self.parliament.get\\_agents\\_info()\n\nawait websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info}))\n\nasync def handle\\_add\\_agents(self, websocket, data):\n\nif not self.parliament:\n\nawait self.send\\_error(websocket, \"Parliament not set.\")\n\nreturn\n\nagents\\_data = data.get(\"agents\")\n\nif not agents\\_data:\n\nawait self.send\\_error(websocket, \"No agent data provided.\")\n\nreturn\n\nfor agent\\_data in agents\\_data:\n\nagent\\_name = agent\\_data.get(\"name\") # Extract the name\n\nspeaking\\_pressure\\_increment = int(agent\\_data.get(\"speaking\\_pressure\\_increment\"))\n\nother\\_agents = \", \".join(\\[agent\\['name'\\] for agent in agents\\_data if agent\\['name'\\] != agent\\_name\\])\n\ninitial\\_context = (\n\nf\"Hello assistant, your name is: @{agent\\_data.get('name')} and your context is \"\n\nf\"{agent\\_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \"\n\nf\"alongside your fellow agents in a parliament, which is a sort \"\n\nf\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \"\n\nf\"with you are {other\\_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \"\n\nf\"{agent\\_data.get('speaking\\_pressure\\_increment')} out of 100\"\n\n)\n\nagent\\_type = agent\\_data.get(\"type\")\n\nagent\\_class = self.parliament.agent\\_types.get(agent\\_type) # Get OpenAIAgent or GPT4AllAgent\n\nagent\\_instance = agent\\_class(initial\\_context) # Properly instantiate the class\n\nif isinstance(agent\\_instance, self.parliament.agent\\_types\\[agent\\_type\\]):\n\nagent\\_instance = OpenAIAgent(initial\\_context) # Create the OpenAIAgent instance\n\nagent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket)\n\nself.parliament.add\\_agent(agent) # Pass the agent instance to add\\_agent\n\nelse:\n\nprint(\"Error occurred attempting to get agent message!\")\n\nreturn \"Sorry, I'm unable to generate a relevant response at this time.\"\n\nawait self.send\\_error(websocket, f\"Unknown agent type: {agent\\_type}\")\n\ncontinue\n\nasync def send\\_error(self, websocket, message):\n\nawait websocket.send(json.dumps({\"action\": ERROR, \"message\": message}))\n\ndef run(self):\n\nself.configure\\_openai()\n\nasyncio.get\\_event\\_loop().run\\_until\\_complete(self.start\\_server)\n\nprint(\"Starting WebSocket server...\")\n\nprint(f\"WebSocket server is running on ws://{self.host}:{self.port}\")\n\nasyncio.get\\_event\\_loop().run\\_forever()\n\nif **name** == \"\\_\\_main\\_\\_\":\n\nserver = ParliamentServer()\n\nserver.run()",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T18:36:44.705004Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "17cbf4c5-7da1-413e-9864-38acc96d292c",
      "role": "assistant",
      "content": " Creating the Parliament instance in the run method is not ideal. There are a few reasons for this:\n\n1. The Parliament instance persists for the lifetime of the server. If it's created in run, a new Parliament would be created each time the method is called.\n\n2. The Parliament likely depends on configuration done in the __init__ method. If created in run, it would miss that initial configuration.\n\n3. It makes more logical sense for a ParliamentServer to have a Parliament attribute, rather than creating a new Parliament on each run.\n\nSo in summary, no - the Parliament should not be created in the run method. The current approach of creating it in __init__ and handle_set_parliament is appropriate.\n\nSome suggestions for improvement:\n\n1. You can add a check in the run method to ensure self.parliament is defined before accessing it, to prevent errors:\n\n```python\ndef run(self):\n    if not self.parliament:\n        print(\"Parliament not set. Run handle_set_parliament to set a parliament.\")\n        return\n    ... \n```\n\n2. You may want to make self.parliament a required argument for ParliamentServer.__init__, to enforce that it must be set before running the server:\n\n```python\ndef __init__(self, parliament, host=\"localhost\", port=8080):\n    self.parliament = parliament\n    ...\n```\n\nThen the caller would be forced to do:\n```python\nserver = ParliamentServer(Parliament(\"my_parliament\"))\nserver.run()\n```\n\nTo ensure a parliament is always set.\n\n3. Add similar checks in other methods like send_message, add_agents, etc. to ensure self.parliament is defined before accessing.\n\nOverall though, creating the Parliament instance in __init__ or handle_set_parliament is the appropriate approach, rather than in the run method.\n\nLet me know if you have any other questions!",
      "created_at": "2023-05-20T18:37:23.503146Z",
      "sequence_order": 33,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T18:37:23.503146Z",
            "stop_timestamp": "2023-05-20T18:37:23.503146Z",
            "flags": null,
            "type": "text",
            "text": " Creating the Parliament instance in the run method is not ideal. There are a few reasons for this:\n\n1. The Parliament instance persists for the lifetime of the server. If it's created in run, a new Parliament would be created each time the method is called.\n\n2. The Parliament likely depends on configuration done in the __init__ method. If created in run, it would miss that initial configuration.\n\n3. It makes more logical sense for a ParliamentServer to have a Parliament attribute, rather than creating a new Parliament on each run.\n\nSo in summary, no - the Parliament should not be created in the run method. The current approach of creating it in __init__ and handle_set_parliament is appropriate.\n\nSome suggestions for improvement:\n\n1. You can add a check in the run method to ensure self.parliament is defined before accessing it, to prevent errors:\n\n```python\ndef run(self):\n    if not self.parliament:\n        print(\"Parliament not set. Run handle_set_parliament to set a parliament.\")\n        return\n    ... \n```\n\n2. You may want to make self.parliament a required argument for ParliamentServer.__init__, to enforce that it must be set before running the server:\n\n```python\ndef __init__(self, parliament, host=\"localhost\", port=8080):\n    self.parliament = parliament\n    ...\n```\n\nThen the caller would be forced to do:\n```python\nserver = ParliamentServer(Parliament(\"my_parliament\"))\nserver.run()\n```\n\nTo ensure a parliament is always set.\n\n3. Add similar checks in other methods like send_message, add_agents, etc. to ensure self.parliament is defined before accessing.\n\nOverall though, creating the Parliament instance in __init__ or handle_set_parliament is the appropriate approach, rather than in the run method.\n\nLet me know if you have any other questions!",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T18:37:23.503146Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "b7c41ddf-3584-428a-8190-5bfcbf55d093",
      "role": "human",
      "content": "error here File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler await self.ws\\_handler(self) File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler return await cast( File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 37, in chat await self.handle\\_send\\_message(websocket, data) File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 66, in handle\\_send\\_message await websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info})) File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/\\_\\_init\\_\\_.py\", line 231, in dumps return _default_encoder.encode(obj) File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/encoder.py\", line 199, in encode chunks = self.iterencode(o, _one_shot=True) File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/encoder.py\", line 257, in iterencode return _iterencode(o, 0) File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/encoder.py\", line 179, in default raise TypeError(f'Object of type {o._\\_class\\_\\_.\\_\\_name\\_\\_} ' TypeError: Object of type coroutine is not JSON serializable server.py from datetime import datetime import asyncio import json from websockets import serve from parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent import openai # Constants SET\\_PARLIAMENT = \"set\\_parliament\" SEND\\_MESSAGE = \"send\\_message\" ADD\\_AGENTS = \"add\\_agents\" UPDATE\\_AGENTS = \"update\\_agents\" RECEIVE\\_MESSAGE = \"receive\\_message\" ERROR = \"error\" TYPING = \"typing\" STOPPED\\_TYPING = \"stopped\\_typing\" class ParliamentServer: def **init**(self, host=\"localhost\", port=8080): self.host = host self.port = port self.parliament = None self.start\\_server = serve(self.chat, self.host, self.port) def configure\\_openai(self): openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\" openai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\" async def chat(self, websocket, path): async for message in websocket: data = json.loads(message) print(f\"Data coming to chat socket message: {data}\") # Add logging action = data.get(\"action\") if action == SET\\_PARLIAMENT: self.handle\\_set\\_parliament(websocket, data) elif action == SEND\\_MESSAGE: await self.handle\\_send\\_message(websocket, data) elif action == ADD\\_AGENTS: await self.handle\\_add\\_agents(websocket, data) def handle\\_set\\_parliament(self, websocket, data): print(\"we're hadling set parliament\", data); parliament\\_name = data.get(\"name\") topic = data.get(\"topic\") if parliament\\_name and topic: self.parliament = Parliament(parliament\\_name, topic) async def handle\\_send\\_message(self, websocket, data): print(f\"Data coming in message: {data}\") # Add logging if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return sender = data.get(\"sender\") user\\_message = data.get(\"message\") timestamp = datetime.now() await websocket.send(json.dumps({ \"action\": RECEIVE\\_MESSAGE, \"message\": user\\_message, \"sender\": sender, \"timestamp\": timestamp.isoformat()})) await self.parliament.broadcast\\_message(user\\_message, sender, timestamp) print(f\"Broadcast message: {user\\_message}\") # Add logging # Sending agent info after broadcasting message agent\\_info = await self.parliament.get\\_agents\\_info() await websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info})) async def handle\\_add\\_agents(self, websocket, data): if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return agents\\_data = data.get(\"agents\") if not agents\\_data: await self.send\\_error(websocket, \"No agent data provided.\") return for agent\\_data in agents\\_data: agent\\_name = agent\\_data.get(\"name\") # Extract the name speaking\\_pressure\\_increment = int(agent\\_data.get(\"speaking\\_pressure\\_increment\")) other\\_agents = \", \".join(\\[agent\\['name'\\] for agent in agents\\_data if agent\\['name'\\] != agent\\_name\\]) initial\\_context = ( f\"Hello assistant, your name is: @{agent\\_data.get('name')} and your context is \" f\"{agent\\_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \" f\"alongside your fellow agents in a parliament, which is a sort \" f\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \" f\"with you are {other\\_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \" f\"{agent\\_data.get('speaking\\_pressure\\_increment')} out of 100\" ) agent\\_type = agent\\_data.get(\"type\") agent\\_class = self.parliament.agent\\_types.get(agent\\_type) # Get OpenAIAgent or GPT4AllAgent agent\\_instance = agent\\_class(initial\\_context) # Properly instantiate the class if isinstance(agent\\_instance, self.parliament.agent\\_types\\[agent\\_type\\]): agent\\_instance = OpenAIAgent(initial\\_context) # Create the OpenAIAgent instance agent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket) self.parliament.add\\_agent(agent) # Pass the agent instance to add\\_agent else: print(\"Error occurred attempting create agent\") #now let's initialize the parliament's agents relevancy scores self.parliament.startup() async def send\\_error(self, websocket, message): await websocket.send(json.dumps({\"action\": ERROR, \"message\": message})) def run(self): self.configure\\_openai() asyncio.get\\_event\\_loop().run\\_until\\_complete(self.start\\_server) print(\"Starting WebSocket server...\") print(f\"WebSocket server is running on ws://{self.host}:{self.port}\") asyncio.get\\_event\\_loop().run\\_forever() if **name** == \"\\_\\_main\\_\\_\": server = ParliamentServer() server.run() parliament.py import asyncio import re import random import json import openai from openai.error import RateLimitError import time from typing import List from collections import deque PRESSURE\\_INCREMENT\\_INTERVAL = 15 SPEAKING\\_PRESSURE\\_LIMIT = 100 BROADCAST\\_DELAY = 1 RELEVANCY\\_THRESHOLD = 100 STOPPED\\_TYPING = \"stopped\\_typing\" UPDATE\\_AGENTS = \"update\\_agents\" class Agent: def **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None): self.name = agent\\_name self.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment self.speaking\\_pressure = speaking\\_pressure\\_increment self.context = initial\\_context self.initial\\_context = initial\\_context self.tagged = False self.agent\\_type = agent\\_type self.agent\\_instance = agent\\_instance self.websocket = websocket self.parliament = parliament self.is\\_speaking = False self.relevancy\\_score = 0 def set\\_typing\\_status(self, status: bool): self.is\\_typing = status async def calculate\\_relevancy(self, chat\\_context): relevancy\\_score = 0 if self.relevancy\\_score is None or self.initial\\_context != chat\\_context: print(\"Calculating relevancy...\") prompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\" print(f\"Prompt: {prompt}\") response = openai.Completion.create( engine=\"text-davinci-001\", prompt=prompt, temperature=0.0, max\\_tokens=300 ) print(f\"Response: {response}\") stripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text) try: relevancy\\_score = int(stripped\\_response) except ValueError: relevancy\\_score = 0 print(f\"Relevancy score: {relevancy\\_score}\") else: print(\"Relevancy score already calculated.\") time.sleep(.5) return relevancy\\_score async def get\\_agent\\_message(self, truncated\\_chat\\_history): message = \"\" if isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]): response = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history) message = f\"{response}\" return message async def respond(self): agent\\_message = await self.get\\_agent\\_message(self.parliament.chat\\_history.truncated\\_chat\\_history) await self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name})) def reset\\_relevancy\\_score(self): self.relevancy\\_score = None class ChatHistory: def **init**(self): self.chat\\_history = \\[\\] self.truncated\\_chat\\_history = \"\" def add(self, message, sender, timestamp): self.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp}) self.truncate\\_chat\\_history() def truncate\\_chat\\_history(self, max\\_length=2000): chat\\_history\\_str = '\\\\n'.join(\\[message\\[\"message\"\\] for message in self.chat\\_history\\]) self.truncated\\_chat\\_history = chat\\_history\\_str\\[-max\\_length:\\] def get\\_latest\\_message(self): return self.chat\\_history\\[-1\\] if self.chat\\_history else None class SpeakerManager: def **init**(self, parliament): self.parliament = parliament def should\\_speak(self, agent): return agent.tagged or agent.speaking\\_pressure >= SPEAKING\\_PRESSURE\\_LIMIT class Parliament: def **init**(self, name: str, topic: str) : # Added name argument self.topic = topic self.name = name self.agents: List\\[Agent\\] = \\[\\] self.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent} self.agent\\_instances = {} self.chat\\_history = ChatHistory() def startup(self): print(\"in startup\", self.agents) print(\"assessing agent relevance for topic:\", self.topic) for agent in self.agents: print(agent.name) relevancy = agent.calculate\\_relevancy(self.topic) agent.relevancy\\_score = relevancy async def handle\\_client(self, websocket, path): async for message in websocket: message = json.loads(message) if message\\['action'\\] == 'send\\_message': self.chat\\_history.add(message\\['message'\\], message\\['sender'\\], message\\['timestamp'\\]) for agent in self.agents: if agent.websocket == websocket: agent.reset\\_relevancy\\_score() if message.get('reply\\_agent', None): for agent in self.agents: if agent.name == message\\['reply\\_agent'\\]: await agent.respond() elif message\\['action'\\] == 'request\\_agents': await self.send\\_agent\\_list(websocket) elif message\\['action'\\] == UPDATE\\_AGENTS: self.update\\_agents(message\\['agents'\\], websocket) async def send\\_agent\\_list(self, websocket): agents\\_list = \\[{\"name\": agent.name, \"context\": agent.context} for agent in self.agents\\] await websocket.send(json.dumps({\"action\": \"receive\\_agents\", \"agents\": agents\\_list})) def update\\_agents(self, agents, websocket): self.agents = \\[\\] for agent in agents: self.agents.append(Agent(self, agent\\['name'\\], agent\\['context'\\], agent\\['type'\\], self.agent\\_instances\\[agent\\['type'\\]\\], websocket)) def add\\_agent\\_type(self, agent\\_type\\_name, agent\\_type\\_class): self.agent\\_types\\[agent\\_type\\_name\\] = agent\\_type\\_class def add\\_agent\\_instance(self, agent\\_instance\\_name, agent\\_instance): self.agent\\_instances\\[agent\\_instance\\_name\\] = agent\\_instance def add\\_agent(self, agent): self.agents.append(agent) async def broadcast\\_message(self, message, sender, timestamp): self.chat\\_history.add(message, sender, timestamp) mentioned\\_agents = self.identify\\_and\\_tag\\_mentioned\\_agents(message) # await asyncio.sleep(BROADCAST\\_DELAY) def identify\\_and\\_tag\\_mentioned\\_agents(self, message): mentioned\\_agents = \\[\\] for agent in self.agents: if '@'+agent.name in message: mentioned\\_agents.append(agent) agent.speaking\\_pressure = SPEAKING\\_PRESSURE\\_LIMIT agent.tagged = True return mentioned\\_agents def increment\\_speaking\\_pressure(self, mentioned\\_agents): for agent in self.agents: if agent.name not in mentioned\\_agents: agent.speaking\\_pressure += agent.speaking\\_pressure\\_increment async def get\\_agents\\_info(self) -> List\\[dict\\]: print(\"getting agents info\", self.agents) agents\\_info = \\[\\] for agent in self.agents: print(\"getting agents info\", agent.name) agents\\_info.append({ \"name\": agent.name, \"speaking\\_pressure\": agent.speaking\\_pressure, \"speaking\\_pressure\\_increment\": agent.speaking\\_pressure\\_increment, \"context\": agent.context, \"agent\\_type\": agent.agent\\_type, \"relevancy\\_score\": agent.relevancy\\_score # Return the cached score }) return agents\\_info",
      "created_at": "2023-05-20T19:01:10.727695Z",
      "sequence_order": 34,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T19:01:10.727695Z",
            "stop_timestamp": "2023-05-20T19:01:10.727695Z",
            "flags": null,
            "type": "text",
            "text": "error here File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 240, in handler await self.ws\\_handler(self) File \"/Users/bilalghalib/mambaforge/lib/python3.10/site-packages/websockets/legacy/server.py\", line 1186, in _ws_handler return await cast( File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 37, in chat await self.handle\\_send\\_message(websocket, data) File \"/Users/bilalghalib/Projects/scripts/Parliment/parliament-chat-nextjs/pages/parliament\\_backend/server.py\", line 66, in handle\\_send\\_message await websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info})) File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/\\_\\_init\\_\\_.py\", line 231, in dumps return _default_encoder.encode(obj) File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/encoder.py\", line 199, in encode chunks = self.iterencode(o, _one_shot=True) File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/encoder.py\", line 257, in iterencode return _iterencode(o, 0) File \"/Users/bilalghalib/mambaforge/lib/python3.10/json/encoder.py\", line 179, in default raise TypeError(f'Object of type {o._\\_class\\_\\_.\\_\\_name\\_\\_} ' TypeError: Object of type coroutine is not JSON serializable server.py from datetime import datetime import asyncio import json from websockets import serve from parliament import Parliament, GPT4AllAgent, OpenAIAgent, Agent import openai # Constants SET\\_PARLIAMENT = \"set\\_parliament\" SEND\\_MESSAGE = \"send\\_message\" ADD\\_AGENTS = \"add\\_agents\" UPDATE\\_AGENTS = \"update\\_agents\" RECEIVE\\_MESSAGE = \"receive\\_message\" ERROR = \"error\" TYPING = \"typing\" STOPPED\\_TYPING = \"stopped\\_typing\" class ParliamentServer: def **init**(self, host=\"localhost\", port=8080): self.host = host self.port = port self.parliament = None self.start\\_server = serve(self.chat, self.host, self.port) def configure\\_openai(self): openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\" openai.api\\_key = \"sk-XXXXXXXXXXXXXXXXXXXX_REDACTED_REDACTED_REDACTED\" async def chat(self, websocket, path): async for message in websocket: data = json.loads(message) print(f\"Data coming to chat socket message: {data}\") # Add logging action = data.get(\"action\") if action == SET\\_PARLIAMENT: self.handle\\_set\\_parliament(websocket, data) elif action == SEND\\_MESSAGE: await self.handle\\_send\\_message(websocket, data) elif action == ADD\\_AGENTS: await self.handle\\_add\\_agents(websocket, data) def handle\\_set\\_parliament(self, websocket, data): print(\"we're hadling set parliament\", data); parliament\\_name = data.get(\"name\") topic = data.get(\"topic\") if parliament\\_name and topic: self.parliament = Parliament(parliament\\_name, topic) async def handle\\_send\\_message(self, websocket, data): print(f\"Data coming in message: {data}\") # Add logging if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return sender = data.get(\"sender\") user\\_message = data.get(\"message\") timestamp = datetime.now() await websocket.send(json.dumps({ \"action\": RECEIVE\\_MESSAGE, \"message\": user\\_message, \"sender\": sender, \"timestamp\": timestamp.isoformat()})) await self.parliament.broadcast\\_message(user\\_message, sender, timestamp) print(f\"Broadcast message: {user\\_message}\") # Add logging # Sending agent info after broadcasting message agent\\_info = await self.parliament.get\\_agents\\_info() await websocket.send(json.dumps({\"action\": UPDATE\\_AGENTS, \"agents\": agent\\_info})) async def handle\\_add\\_agents(self, websocket, data): if not self.parliament: await self.send\\_error(websocket, \"Parliament not set.\") return agents\\_data = data.get(\"agents\") if not agents\\_data: await self.send\\_error(websocket, \"No agent data provided.\") return for agent\\_data in agents\\_data: agent\\_name = agent\\_data.get(\"name\") # Extract the name speaking\\_pressure\\_increment = int(agent\\_data.get(\"speaking\\_pressure\\_increment\")) other\\_agents = \", \".join(\\[agent\\['name'\\] for agent in agents\\_data if agent\\['name'\\] != agent\\_name\\]) initial\\_context = ( f\"Hello assistant, your name is: @{agent\\_data.get('name')} and your context is \" f\"{agent\\_data.get('context')}. Your job is to help {data.get('username')} by discussing {data.get('topic')} \" f\"alongside your fellow agents in a parliament, which is a sort \" f\"of town hall or large meeting, called {self.parliament.name}. The other agents discussing \" f\"with you are {other\\_agents}, please prefix their name with an @ when mentioning them, and don't @mention yourself. Your talkativity is \" f\"{agent\\_data.get('speaking\\_pressure\\_increment')} out of 100\" ) agent\\_type = agent\\_data.get(\"type\") agent\\_class = self.parliament.agent\\_types.get(agent\\_type) # Get OpenAIAgent or GPT4AllAgent agent\\_instance = agent\\_class(initial\\_context) # Properly instantiate the class if isinstance(agent\\_instance, self.parliament.agent\\_types\\[agent\\_type\\]): agent\\_instance = OpenAIAgent(initial\\_context) # Create the OpenAIAgent instance agent = Agent(self.parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket) self.parliament.add\\_agent(agent) # Pass the agent instance to add\\_agent else: print(\"Error occurred attempting create agent\") #now let's initialize the parliament's agents relevancy scores self.parliament.startup() async def send\\_error(self, websocket, message): await websocket.send(json.dumps({\"action\": ERROR, \"message\": message})) def run(self): self.configure\\_openai() asyncio.get\\_event\\_loop().run\\_until\\_complete(self.start\\_server) print(\"Starting WebSocket server...\") print(f\"WebSocket server is running on ws://{self.host}:{self.port}\") asyncio.get\\_event\\_loop().run\\_forever() if **name** == \"\\_\\_main\\_\\_\": server = ParliamentServer() server.run() parliament.py import asyncio import re import random import json import openai from openai.error import RateLimitError import time from typing import List from collections import deque PRESSURE\\_INCREMENT\\_INTERVAL = 15 SPEAKING\\_PRESSURE\\_LIMIT = 100 BROADCAST\\_DELAY = 1 RELEVANCY\\_THRESHOLD = 100 STOPPED\\_TYPING = \"stopped\\_typing\" UPDATE\\_AGENTS = \"update\\_agents\" class Agent: def **init**(self, parliament, agent\\_name, speaking\\_pressure\\_increment, initial\\_context, agent\\_type, agent\\_instance, websocket=None): self.name = agent\\_name self.speaking\\_pressure\\_increment = speaking\\_pressure\\_increment self.speaking\\_pressure = speaking\\_pressure\\_increment self.context = initial\\_context self.initial\\_context = initial\\_context self.tagged = False self.agent\\_type = agent\\_type self.agent\\_instance = agent\\_instance self.websocket = websocket self.parliament = parliament self.is\\_speaking = False self.relevancy\\_score = 0 def set\\_typing\\_status(self, status: bool): self.is\\_typing = status async def calculate\\_relevancy(self, chat\\_context): relevancy\\_score = 0 if self.relevancy\\_score is None or self.initial\\_context != chat\\_context: print(\"Calculating relevancy...\") prompt = f\"you are '{self.initial\\_context}' and you are being asked to respond to '{chat\\_context}'. How relevant are you? Only respond with a number from 0 to 100, if you don't know say 1.\" print(f\"Prompt: {prompt}\") response = openai.Completion.create( engine=\"text-davinci-001\", prompt=prompt, temperature=0.0, max\\_tokens=300 ) print(f\"Response: {response}\") stripped\\_response = re.sub(\"\\[^0-9\\]\", \"\", response.choices\\[0\\].text) try: relevancy\\_score = int(stripped\\_response) except ValueError: relevancy\\_score = 0 print(f\"Relevancy score: {relevancy\\_score}\") else: print(\"Relevancy score already calculated.\") time.sleep(.5) return relevancy\\_score async def get\\_agent\\_message(self, truncated\\_chat\\_history): message = \"\" if isinstance(self.agent\\_instance, self.parliament.agent\\_types\\[self.agent\\_type\\]): response = await self.agent\\_instance.get\\_response(truncated\\_chat\\_history) message = f\"{response}\" return message async def respond(self): agent\\_message = await self.get\\_agent\\_message(self.parliament.chat\\_history.truncated\\_chat\\_history) await self.websocket.send(json.dumps({\"action\": \"receive\\_message\", \"message\": agent\\_message, \"sender\": self.name})) def reset\\_relevancy\\_score(self): self.relevancy\\_score = None class ChatHistory: def **init**(self): self.chat\\_history = \\[\\] self.truncated\\_chat\\_history = \"\" def add(self, message, sender, timestamp): self.chat\\_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp}) self.truncate\\_chat\\_history() def truncate\\_chat\\_history(self, max\\_length=2000): chat\\_history\\_str = '\\\\n'.join(\\[message\\[\"message\"\\] for message in self.chat\\_history\\]) self.truncated\\_chat\\_history = chat\\_history\\_str\\[-max\\_length:\\] def get\\_latest\\_message(self): return self.chat\\_history\\[-1\\] if self.chat\\_history else None class SpeakerManager: def **init**(self, parliament): self.parliament = parliament def should\\_speak(self, agent): return agent.tagged or agent.speaking\\_pressure >= SPEAKING\\_PRESSURE\\_LIMIT class Parliament: def **init**(self, name: str, topic: str) : # Added name argument self.topic = topic self.name = name self.agents: List\\[Agent\\] = \\[\\] self.agent\\_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent} self.agent\\_instances = {} self.chat\\_history = ChatHistory() def startup(self): print(\"in startup\", self.agents) print(\"assessing agent relevance for topic:\", self.topic) for agent in self.agents: print(agent.name) relevancy = agent.calculate\\_relevancy(self.topic) agent.relevancy\\_score = relevancy async def handle\\_client(self, websocket, path): async for message in websocket: message = json.loads(message) if message\\['action'\\] == 'send\\_message': self.chat\\_history.add(message\\['message'\\], message\\['sender'\\], message\\['timestamp'\\]) for agent in self.agents: if agent.websocket == websocket: agent.reset\\_relevancy\\_score() if message.get('reply\\_agent', None): for agent in self.agents: if agent.name == message\\['reply\\_agent'\\]: await agent.respond() elif message\\['action'\\] == 'request\\_agents': await self.send\\_agent\\_list(websocket) elif message\\['action'\\] == UPDATE\\_AGENTS: self.update\\_agents(message\\['agents'\\], websocket) async def send\\_agent\\_list(self, websocket): agents\\_list = \\[{\"name\": agent.name, \"context\": agent.context} for agent in self.agents\\] await websocket.send(json.dumps({\"action\": \"receive\\_agents\", \"agents\": agents\\_list})) def update\\_agents(self, agents, websocket): self.agents = \\[\\] for agent in agents: self.agents.append(Agent(self, agent\\['name'\\], agent\\['context'\\], agent\\['type'\\], self.agent\\_instances\\[agent\\['type'\\]\\], websocket)) def add\\_agent\\_type(self, agent\\_type\\_name, agent\\_type\\_class): self.agent\\_types\\[agent\\_type\\_name\\] = agent\\_type\\_class def add\\_agent\\_instance(self, agent\\_instance\\_name, agent\\_instance): self.agent\\_instances\\[agent\\_instance\\_name\\] = agent\\_instance def add\\_agent(self, agent): self.agents.append(agent) async def broadcast\\_message(self, message, sender, timestamp): self.chat\\_history.add(message, sender, timestamp) mentioned\\_agents = self.identify\\_and\\_tag\\_mentioned\\_agents(message) # await asyncio.sleep(BROADCAST\\_DELAY) def identify\\_and\\_tag\\_mentioned\\_agents(self, message): mentioned\\_agents = \\[\\] for agent in self.agents: if '@'+agent.name in message: mentioned\\_agents.append(agent) agent.speaking\\_pressure = SPEAKING\\_PRESSURE\\_LIMIT agent.tagged = True return mentioned\\_agents def increment\\_speaking\\_pressure(self, mentioned\\_agents): for agent in self.agents: if agent.name not in mentioned\\_agents: agent.speaking\\_pressure += agent.speaking\\_pressure\\_increment async def get\\_agents\\_info(self) -> List\\[dict\\]: print(\"getting agents info\", self.agents) agents\\_info = \\[\\] for agent in self.agents: print(\"getting agents info\", agent.name) agents\\_info.append({ \"name\": agent.name, \"speaking\\_pressure\": agent.speaking\\_pressure, \"speaking\\_pressure\\_increment\": agent.speaking\\_pressure\\_increment, \"context\": agent.context, \"agent\\_type\": agent.agent\\_type, \"relevancy\\_score\": agent.relevancy\\_score # Return the cached score }) return agents\\_info",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T19:01:10.727695Z",
        "attachments": [],
        "files": []
      }
    },
    {
      "id": "9ff97c95-0717-4ae6-8872-2509acc749c2",
      "role": "assistant",
      "content": " The error is occurring because you're trying to JSON encode a coroutine (the get_agents_info method returns a coroutine). JSON can only encode basic types like dicts, lists, strings, numbers, booleans, etc.\n\nTo fix this, you'll need to await the get_agents_info coroutine and return the result from it, rather than returning the coroutine itself.\n\nThe updated get_agents_info method would be:\n```python\nasync def get_agents_info(self) -> List[dict]:\n    agents_info = []\n    for agent in self.agents:\n        agents_info.append({\n            \"name\": agent.name,\n            \"speaking_pressure\": agent.speaking_pressure,\n            ...\n        })\n    return agents_info  # Return the result, not the coroutine\n```\n\nThen in handle_send_message, you can call it with:\n```python\nagent_info = await self.parliament.get_agents_info()\n```\n\nAnd await the coroutine to get the actual return value.\n\nThe full updated code would be:\n\nparliament.py\n```python\nclass Parliament:\n    ...\n    async def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent in self.agents:\n            agents_info.append({\n                \"name\": agent.name,\n                ...\n            })\n        return agents_info  \n```\n\nserver.py\n```python\nasync def handle_send_message(self, websocket, data): \n    ...\n    agent_info = await self.parliament.get_agents_info()\n    await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n```\n\nBy awaiting the coroutine and returning its result, you'll fix the JSON serialization error. Let me know if you have any other questions!",
      "created_at": "2023-05-20T19:01:49.432032Z",
      "sequence_order": 35,
      "metadata": {
        "content": [
          {
            "start_timestamp": "2023-05-20T19:01:49.432032Z",
            "stop_timestamp": "2023-05-20T19:01:49.432032Z",
            "flags": null,
            "type": "text",
            "text": " The error is occurring because you're trying to JSON encode a coroutine (the get_agents_info method returns a coroutine). JSON can only encode basic types like dicts, lists, strings, numbers, booleans, etc.\n\nTo fix this, you'll need to await the get_agents_info coroutine and return the result from it, rather than returning the coroutine itself.\n\nThe updated get_agents_info method would be:\n```python\nasync def get_agents_info(self) -> List[dict]:\n    agents_info = []\n    for agent in self.agents:\n        agents_info.append({\n            \"name\": agent.name,\n            \"speaking_pressure\": agent.speaking_pressure,\n            ...\n        })\n    return agents_info  # Return the result, not the coroutine\n```\n\nThen in handle_send_message, you can call it with:\n```python\nagent_info = await self.parliament.get_agents_info()\n```\n\nAnd await the coroutine to get the actual return value.\n\nThe full updated code would be:\n\nparliament.py\n```python\nclass Parliament:\n    ...\n    async def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent in self.agents:\n            agents_info.append({\n                \"name\": agent.name,\n                ...\n            })\n        return agents_info  \n```\n\nserver.py\n```python\nasync def handle_send_message(self, websocket, data): \n    ...\n    agent_info = await self.parliament.get_agents_info()\n    await websocket.send(json.dumps({\"action\": UPDATE_AGENTS, \"agents\": agent_info}))\n```\n\nBy awaiting the coroutine and returning its result, you'll fix the JSON serialization error. Let me know if you have any other questions!",
            "citations": []
          }
        ],
        "updated_at": "2023-05-20T19:01:49.432032Z",
        "attachments": [],
        "files": []
      }
    }
  ]
}