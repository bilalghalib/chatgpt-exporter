{
  "id": "8e68d98e-c370-4268-82fb-f8cb60b7e780",
  "source": "chatgpt",
  "title": "\"Managing Speaking Queue Updates\"",
  "created_at": "2023-05-12T17:25:16.304058",
  "updated_at": "2023-05-12T17:30:35",
  "summary": null,
  "message_count": 4,
  "messages": [
    {
      "id": "aaa2088c-2a39-49a6-a5f2-6690ef332b09",
      "role": "user",
      "content": "do we have two update speaking queues and does it make sense to trigger update speaking queue as soon as an agent is created? \nimport asyncio\nimport random\nimport json\nimport openai\nfrom openai.error import RateLimitError\nimport time\nfrom typing import List\nfrom collections import deque\n\nPRESSURE_INCREMENT_INTERVAL = 15\nSPEAKING_PRESSURE_LIMIT = 100\nBROADCAST_DELAY = 10\nRELEVANCY_THRESHOLD = 100\n\nclass Agent:\n    def __init__(self, name: str, speaking_pressure_increment: int, context: str, agent_type: str, parliament, agent_instance=None, websocket=None):\n        self.name = name\n        self.speaking_pressure_increment = speaking_pressure_increment\n        self.context = context\n        self.speaking_pressure = speaking_pressure_increment\n        self.tagged = False\n        self.agent_type = agent_type\n        self.agent_instance = agent_instance\n        self.websocket = websocket\n        self.parliament = parliament\n        self.is_speaking = False\n\n    def should_speak(self):\n        return self.parliament.speaker_manager.should_speak(self)\n\n    async def try_to_speak(self):\n        if self.should_speak() and not self.is_speaking:\n            await self.speak()\n\n    async def increment_pressure(self):\n        while True:\n            await asyncio.sleep(PRESSURE_INCREMENT_INTERVAL)\n            self.speaking_pressure += self.speaking_pressure_increment\n            await self.try_to_speak()\n\n    def get_agent_message(self, chat_history):\n        \"\"\"\n        Generate a message from this agent based on the current chat history.\n        \"\"\"\n        message = \"\"\n        if isinstance(self.agent_instance, self.parliament.agent_types[self.agent_type]):\n            response = self.agent_instance.get_response(chat_history)\n            message = f\"{response}\"\n        return message\n    \n    def in_queue(self):\n        return self.name in self.parliament.speaking_queue.queue\n    \n    def calculate_relevancy(self, chat_context: str) -> int:\n        # Replace this with your actual relevancy calculation logic\n        return random.randint(0, 100)\n\n    async def speak(self):\n        self.is_speaking = True\n        await self.websocket.send(json.dumps({\"action\": \"typing\", \"sender\": self.name}))\n        agent_message = self.get_agent_message(self.parliament.chat_history)\n        await self.websocket.send(json.dumps({\"action\": \"receive_message\", \"message\": agent_message, \"sender\": self.name}))\n        self.speaking_pressure = 0\n        self.is_speaking = False\n        if self.in_queue():\n            self.parliament.speaking_queue.remove(self.name)\n\n    def reset_pressure(self):\n        self.speaking_pressure = 0\n\nclass ChatHistory:\n    def __init__(self):\n        self.chat_history = []\n        self.truncated_chat_history = [] \n\n    def add(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n        self.truncate_chat_history() \n\n    def truncate_chat_history(self, max_length=2000):\n        \"\"\"\n        Truncate the chat history to the last max_length characters.\n        \"\"\"\n        chat_history_str = '\\n'.join([message[\"message\"] for message in self.chat_history])\n        self.truncated_chat_history = chat_history_str[-max_length:]\n\n    def last_message(self):\n        return self.chat_history[-1] if self.chat_history else None\n\nclass SpeakingQueue:\n    def __init__(self):\n        self.queue = deque()\n\n    def add(self, agent_name):\n        self.queue.append(agent_name)\n\n    def pop(self):\n        if len(self.queue) > 0:\n            return self.queue.pop()\n        else:\n            return None\n        \n    def enqueue(self, name):\n        self.queue.append(name)\n\n    def dequeue(self):\n        return self.queue.popleft() if self.queue else None\n\n    def front(self):\n        return self.queue[0] if self.queue else None\n\n    def remove(self, name):\n        self.queue.remove(name)\n\n    def contains(self, name):\n        return name in self.queue\n\n    def to_json(self):\n        return list(self.queue)\n    \nclass SpeakerManager:\n    def __init__(self, parliament):\n        self.parliament = parliament\n\n    def should_speak(self, agent):\n        return self.parliament.speaking_queue.front() == agent.name and agent.speaking_pressure >= SPEAKING_PRESSURE_LIMIT\n\nclass OpenAIAgent:\n    def __init__(self, initial_context: str):\n        openai.organization = \"org-ADENd47ZFNjAt0kqYo7foBYK\"\n        openai.api_key = \"REDACTED_API_KEY\"\n        self.model = \"gpt-3.5-turbo\"\n        self.initial_context = initial_context\n\n    def get_response(self, chat_history):\n        system_msg = self.initial_context\n\n        messages = [{\"role\": \"system\", \"content\": system_msg}]\n        for message in self.chat_history.truncated_chat_history:  # Use the truncated chat history instead of the full chat history\n            role = message[\"sender\"]\n            msg = message[\"message\"]\n            messages.append({\"role\": \"assistant\" if role != \"assistant\" else role, \"content\": msg})\n\n        max_retries = 3\n        retry_delay = 5\n\n        for i in range(max_retries):\n            try:\n                # Call the OpenAI API with the messages array\n                response = openai.ChatCompletion.create(\n                    model=self.model,\n                    messages=messages,\n                    max_tokens=150,\n                    temperature=0.5,\n                    top_p=1,\n                    frequency_penalty=0,\n                    presence_penalty=0,\n                )\n                # Extract and return the assistant's response from the API response\n                return response.choices[0].message[\"content\"].strip()\n\n            except RateLimitError as e:\n                print(f\"Rate limit error: {e}. Retrying in {retry_delay} seconds...\")\n                if i < max_retries - 1:  # Don't sleep on the last iteration\n                    time.sleep(retry_delay)\n                else:\n                    raise\n        return \"Sorry, I am unable to respond at the moment.\"\n\n\nclass GPT4AllAgent:\n    def __init__(self):\n        # Download and set up the GPT4All model\n        self._initialize_gpt4all_model()\n        self._initialize_llm_chain()\n\n    def _initialize_gpt4all_model(self):\n        local_path = \"/Users/bilalghalib/Projects/scripts/models/ggml-gpt4all-j.bin\"\n        Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n\n        url = 'http://gpt4all.io/models/ggml-gpt4all-l13b-snoozy.bin'\n        response = requests.get(url, stream=True)\n\n        with open(local_path, 'wb') as f:\n            for chunk in tqdm(response.iter_content(chunk_size=8192)):\n                if chunk:\n                    f.write(chunk)\n\n        self.model_path = local_path\n\n    def _initialize_llm_chain(self):\n        template = \"\"\"{chat_history}\n\n        Question: {question}\n\n        Answer: Let's think step by step.\"\"\"\n        prompt = PromptTemplate(template=template, input_variables=[\"chat_history\", \"question\"])\n\n        callbacks = [StreamingStdOutCallbackHandler()]\n        llm = GPT4All(model=self.model_path, callbacks=callbacks, verbose=True)\n        self.llm_chain = LLMChain(prompt=prompt, llm=llm)\n\n    def get_response(self, chat_history, question):\n        return self.llm_chain.run(chat_history=chat_history, question=question)\n\n\n\nclass Parliament:\n    def __init__(self, name: str):\n        self.name = name\n        self.agents = {}\n        self.chat_history = ChatHistory()\n        self.speaking_queue = SpeakingQueue()\n        self.speaker_manager = SpeakerManager(self)\n        self.agent_types = {\"openai\": OpenAIAgent, \"gpt4all\": GPT4AllAgent}\n        self.typing_status = {} \n\n    def set_typing_status(self, agent_name: str, status: bool):\n        self.typing_status[agent_name] = status\n\n    def get_typing_status(self, agent_name: str):\n        return self.typing_status.get(agent_name, False)\n\n    async def broadcast_message(self, message, sender, timestamp):\n        self.chat_history.add(message, sender, timestamp)\n        mentioned_agents = self.identify_and_tag_mentioned_agents(message)\n        self.increment_speaking_pressure(mentioned_agents)\n        self.update_speaking_queue()\n\n        for agent in self.agents.values():\n            if not self.get_typing_status(agent.name):\n                await agent.try_to_speak()\n\n        await asyncio.sleep(BROADCAST_DELAY)\n\n        first_agent_in_queue = self.speaking_queue.dequeue()\n        if first_agent_in_queue and not self.get_typing_status(first_agent_in_queue):\n            await self.agents[first_agent_in_queue].speak()\n\n    def add_to_speaking_queue(self, agent):\n        if not self.speaking_queue.contains(agent.name):\n            self.speaking_queue.enqueue(agent.name)\n\n    def update_speaking_queue(self):\n        for agent in self.agents.values():\n            if agent.tagged:\n                self.add_to_speaking_queue(agent)\n                agent.tagged = False\n\n        for agent in self.agents.values():\n            if agent.speaking_pressure >= RELEVANCY_THRESHOLD:\n                self.add_to_speaking_queue(agent)\n\n        most_relevant_agent = max(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history.last_message()), default=None)\n        if most_relevant_agent:\n            self.add_to_speaking_queue(most_relevant_agent)\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = SPEAKING_PRESSURE_LIMIT\n                self.agents[agent_name].tagged = True\n        return mentioned_agents\n    \n    def get_speaking_queue(self):\n        return self.speaking_queue\n            \n    def add_agent(self, name: str, speaking_pressure_increment: int, context: str, agent_type: str, agent_instance=None, websocket=None):\n        agent = Agent(name, speaking_pressure_increment, context, agent_type, self, agent_instance, websocket)\n        self.agents[name] = agent\n        self.typing_status[name] = False  # Initialize typing status when adding an agent\n        asyncio.create_task(agent.increment_pressure())\n        self.update_speaking_queue()\n\n    def remove_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        del self.agents[agent_name]\n\n    def get_agent(self, agent_name: str):\n        if agent_name not in self.agents:\n            raise ValueError(f\"Agent '{agent_name}' not found.\")\n        return self.agents[agent_name]\n\n    def add_to_chat_history(self, message, sender, timestamp):\n        self.chat_history.append({\"sender\": sender, \"message\": message, \"timestamp\": timestamp})\n\n    def identify_and_tag_mentioned_agents(self, message):\n        mentioned_agents = []\n        for agent_name in self.agents:\n            if '@'+agent_name in message:\n                mentioned_agents.append(agent_name)\n                self.agents[agent_name].speaking_pressure = 100\n                self.agents[agent_name].tagged = True\n                print(f\"Tagged agent: {agent_name}\")  # Debug print\n        return mentioned_agents\n\n\n    def increment_speaking_pressure(self, mentioned_agents):\n        for agent in self.agents.values():\n            if agent.name not in mentioned_agents:\n                agent.speaking_pressure += agent.speaking_pressure_increment\n\n    def add_tagged_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.tagged and agent.name not in self.speaking_queue.queue:    \n                self.speaking_queue.add(agent.name)\n                agent.tagged = False\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def add_high_pressure_agents_to_queue(self):\n        for agent in self.agents.values():\n            if agent.speaking_pressure > 100 and agent.name not in self.speaking_queue.queue:\n                self.speaking_queue.add(agent.name)\n                agent.speaking_pressure = 0  # Reset speaking pressure\n\n    def trigger_next_speaker(self):\n        if self.speaking_queue:\n            next_speaker = self.get_agent(self.speaking_queue.pop())  # Remove the agent from the queue\n\n    def update_speaking_queue(self):\n        sorted_agents = self.get_sorted_agents_based_on_relevancy()\n        most_relevant_agent = sorted_agents[0]\n        most_relevant_agent.speaking_pressure = 100\n        self.speaking_queue.add(most_relevant_agent.name)\n        self.add_tagged_agents_to_queue()\n        self.add_high_pressure_agents_to_queue()\n        for agent in self.agents.values():\n            if agent.tagged and not agent.is_speaking:\n                self.add_to_speaking_queue(agent)\n                agent.tagged = False\n                agent.speaking_pressure = 0  # Reset speaking pressure\n        self.trigger_next_speaker()\n\n    def get_sorted_agents_based_on_relevancy(self):\n        return sorted(self.agents.values(), key=lambda agent: agent.calculate_relevancy(self.chat_history), reverse=True)\n\n\n    def get_agents_info(self) -> List[dict]:\n        agents_info = []\n        for agent_name, agent in self.agents.items():\n            agents_info.append({\n                \"name\": agent_name,\n                \"speaking_pressure\": agent.speaking_pressure,\n                \"speaking_pressure_increment\": agent.speaking_pressure_increment,\n                \"context\": agent.context,\n                \"agent_type\": agent.agent_type\n                # Add more fields as needed\n            })\n        return agents_info",
      "created_at": "2023-05-12T17:25:16.307902",
      "sequence_order": 0,
      "parent_id": "8f804d8f-daa7-4b78-b111-f5509a56b67b",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "124bffd6-56da-4196-8275-3e99fae116b5",
      "role": "assistant",
      "content": "In the given code, there is a single speaking queue implemented using a deque data structure. The speaking queue is responsible for maintaining the order in which agents should speak. The `SpeakingQueue` class contains methods to add agents to the queue (`enqueue`), remove agents from the queue (`dequeue`), check the front of the queue (`front`), and check if a particular agent is in the queue (`contains`).\n\nTo answer your question, there is only one speaking queue in the code provided. If you need to have two separate speaking queues, you would need to modify the code accordingly. You can create another instance of the `SpeakingQueue` class to represent the second queue.\n\nAs for triggering the update of the speaking queue as soon as an agent is created, it depends on your specific requirements. If you want the speaking queue to reflect the newly created agent immediately, you can trigger the update after adding the agent. In the `Parliament` class, after adding an agent using the `add_agent` method, you can call the `update_speaking_queue` method to update the speaking queue based on the new agent's information.\n\nHere's an example of how you can modify the code to trigger the update of the speaking queue after adding an agent:\n\n```python\nclass Parliament:\n    # ...\n\n    def add_agent(self, name: str, speaking_pressure_increment: int, context: str, agent_type: str, agent_instance=None, websocket=None):\n        agent = Agent(name, speaking_pressure_increment, context, agent_type, self, agent_instance, websocket)\n        self.agents[name] = agent\n        self.typing_status[name] = False  # Initialize typing status when adding an agent\n        asyncio.create_task(agent.increment_pressure())\n        self.update_speaking_queue()  # Update the speaking queue after adding the agent\n```\n\nBy calling `self.update_speaking_queue()` immediately after adding the agent, the speaking queue will be updated to include the newly added agent.\n\nRemember to make the necessary adjustments to your code based on your specific requirements and the desired behavior of the speaking queues.",
      "created_at": "2023-05-12T17:25:24.111975",
      "sequence_order": 1,
      "parent_id": "aaa2088c-2a39-49a6-a5f2-6690ef332b09",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    },
    {
      "id": "aaa26269-2ed4-437e-a05e-e553ce579e0c",
      "role": "user",
      "content": "what's my error here: Running \"yarn install\" in the root dir of your repository \nyarn install v1.22.17\n[stderr] \nwarning package-lock.json found. Your project contains lock files generated by tools other than Yarn. It is advised not to mix package managers in order to avoid resolution inconsistencies caused by unsynchronized lock files. To clear this warning, remove package-lock.json.\n[1/4] Resolving packages...\n[2/4] Fetching packages...\n[stderr] \nerror Command failed.\n[stderr] \nExit code: 128\n[stderr] \nCommand: git\n[stderr] \nArguments: ls-remote --tags --heads ssh://git@github.com/samsaffron/react-native-key-pair.git\n[stderr] \nDirectory: /home/expo/workingdir/build\n[stderr] \nOutput:\n[stderr] \nHost key verification failed.\n[stderr] \nfatal: Could not read from remote repository.\n[stderr] \n[stderr] \nPlease make sure you have the correct access rights\n[stderr] \nand the repository exists.\ninfo Visit https://yarnpkg.com/en/docs/cli/install for documentation about this command.\nyarn exited with non-zero code: 128",
      "created_at": "2023-05-12T17:30:35.776504",
      "sequence_order": 2,
      "parent_id": "124bffd6-56da-4196-8275-3e99fae116b5",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": null
      }
    },
    {
      "id": "84d670cf-bd5a-4cfd-b8d9-4b7597433fed",
      "role": "assistant",
      "content": "The error message suggests that there is an issue with accessing the remote repository specified in the `yarn install` command. Here are a few possible reasons for the error:\n\n1. **Incorrect SSH key or authentication issue:** Make sure you have the correct SSH key configured and associated with your GitHub account. Verify that the SSH key is correctly set up and has the necessary permissions to access the repository.\n\n2. **Host key verification failed:** This error can occur if the SSH host key for the remote repository has changed or is not recognized by your system. You can try removing the SSH host key for the repository from your known_hosts file and then try running `yarn install` again. The known_hosts file is typically located in the `.ssh` directory in your home directory.\n\n3. **Network connectivity issue:** Check your internet connection and ensure that you have proper network connectivity. If you are behind a firewall or using a proxy, make sure the necessary configurations are in place to allow access to the remote repository.\n\n4. **Repository does not exist or incorrect URL:** Double-check the repository URL specified in the `yarn install` command. Ensure that the repository exists and that the URL is correct.\n\n5. **Permission issues:** If the repository is private, ensure that you have the necessary permissions to access it. If you are using a personal access token, verify that the token has the required permissions.\n\n6. **Lock file conflicts:** The warning about the `package-lock.json` file suggests that there may be conflicts between lock files generated by different package managers. It is generally recommended to use a single package manager to avoid inconsistencies. If possible, remove the `package-lock.json` file and try running `yarn install` again.\n\nInspecting and addressing these potential issues should help you resolve the error you encountered when running `yarn install`.",
      "created_at": "2023-05-12T17:30:42.506306",
      "sequence_order": 3,
      "parent_id": "aaa26269-2ed4-437e-a05e-e553ce579e0c",
      "metadata": {
        "status": "finished_successfully",
        "weight": 1,
        "end_turn": true
      }
    }
  ]
}